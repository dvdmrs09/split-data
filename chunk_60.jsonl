{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_package(name, version, paths=None):\n    if isinstance(version, basestring):\n        range_ = VersionRange(\"==%s\" % version)\n    else:\n        range_ = VersionRange.from_version(version, \"==\")\n\n    it = iter_packages(name, range_, paths)\n    try:\n        return it.next()\n    except StopIteration:\n        return None", "response": "Get an exact version of a package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_package_from_handle(package_handle):\n    if isinstance(package_handle, dict):\n        package_handle = ResourceHandle.from_dict(package_handle)\n    package_resource = package_repository_manager.get_resource_from_handle(package_handle)\n    package = Package(package_resource)\n    return package", "response": "Create a package given its handle or serialized dict representation from\n            ResourceHandle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_package_from_string(txt, paths=None):\n    o = VersionedObject(txt)\n    return get_package(o.name, o.version, paths=paths)", "response": "Get a package given a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a developer package.", "response": "def get_developer_package(path, format=None):\n    \"\"\"Create a developer package.\n\n    Args:\n        path (str): Path to dir containing package definition file.\n        format (str): Package definition file format, detected if None.\n\n    Returns:\n        `DeveloperPackage`.\n    \"\"\"\n    from rez.developer_package import DeveloperPackage\n    return DeveloperPackage.from_path(path, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a package given data.", "response": "def create_package(name, data, package_cls=None):\n    \"\"\"Create a package given package data.\n\n    Args:\n        name (str): Package name.\n        data (dict): Package data. Must conform to `package_maker.package_schema`.\n\n    Returns:\n        `Package` object.\n    \"\"\"\n    from rez.package_maker__ import PackageMaker\n    maker = PackageMaker(name, data, package_cls=package_cls)\n    return maker.get_package()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a variant given its handle or serialized dict representation.", "response": "def get_variant(variant_handle, context=None):\n    \"\"\"Create a variant given its handle (or serialized dict equivalent)\n\n    Args:\n        variant_handle (`ResourceHandle` or dict): Resource handle, or\n            equivalent serialized dict representation from\n            ResourceHandle.to_dict\n        context (`ResolvedContext`): The context this variant is associated\n            with, if any.\n\n    Returns:\n        `Variant`.\n    \"\"\"\n    if isinstance(variant_handle, dict):\n        variant_handle = ResourceHandle.from_dict(variant_handle)\n\n    variant_resource = package_repository_manager.get_resource_from_handle(variant_handle)\n    variant = Variant(variant_resource, context=context)\n    return variant"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_last_release_time(name, paths=None):\n    entries = _get_families(name, paths)\n    max_time = 0\n\n    for repo, family_resource in entries:\n        time_ = repo.get_last_release_time(family_resource)\n        if time_ == 0:\n            return 0\n        max_time = max(max_time, time_)\n    return max_time", "response": "Returns the most recent time this package was released."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_completions(prefix, paths=None, family_only=False):\n    op = None\n    if prefix:\n        if prefix[0] in ('!', '~'):\n            if family_only:\n                return set()\n            op = prefix[0]\n            prefix = prefix[1:]\n\n    fam = None\n    for ch in ('-', '@', '#'):\n        if ch in prefix:\n            if family_only:\n                return set()\n            fam = prefix.split(ch)[0]\n            break\n\n    words = set()\n    if not fam:\n        words = set(x.name for x in iter_package_families(paths=paths)\n                    if x.name.startswith(prefix))\n        if len(words) == 1:\n            fam = iter(words).next()\n\n    if family_only:\n        return words\n\n    if fam:\n        it = iter_packages(fam, paths=paths)\n        words.update(x.qualified_name for x in it\n                     if x.qualified_name.startswith(prefix))\n\n    if op:\n        words = set(op + x for x in words)\n    return words", "response": "Get autocompletion options given a prefix string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over the packages within this family in no particular order.", "response": "def iter_packages(self):\n        \"\"\"Iterate over the packages within this family, in no particular order.\n\n        Returns:\n            `Package` iterator.\n        \"\"\"\n        for package in self.repository.iter_packages(self.resource):\n            yield Package(package)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_local(self):\n        local_repo = package_repository_manager.get_repository(\n            self.config.local_packages_path)\n        return (self.resource._repository.uid == local_repo.uid)", "response": "Returns True if the package is in the local package repository"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the contents of the Variant instance to the given buffer.", "response": "def print_info(self, buf=None, format_=FileFormat.yaml,\n                   skip_attributes=None, include_release=False):\n        \"\"\"Print the contents of the package.\n\n        Args:\n            buf (file-like object): Stream to write to.\n            format_ (`FileFormat`): Format to write in.\n            skip_attributes (list of str): List of attributes to not print.\n            include_release (bool): If True, include release-related attributes,\n                such as 'timestamp' and 'changelog'\n        \"\"\"\n        data = self.validated_data().copy()\n\n        # config is a special case. We only really want to show any config settings\n        # that were in the package.py, not the entire Config contents that get\n        # grafted onto the Package/Variant instance. However Variant has an empy\n        # 'data' dict property, since it forwards data from its parent package.\n        data.pop(\"config\", None)\n        if self.config:\n            if isinstance(self, Package):\n                config_dict = self.data.get(\"config\")\n            else:\n                config_dict = self.parent.data.get(\"config\")\n            data[\"config\"] = config_dict\n\n        if not include_release:\n            skip_attributes = list(skip_attributes or []) + list(package_release_keys)\n\n        buf = buf or sys.stdout\n        dump_package_data(data, buf=buf, format_=format_,\n                          skip_attributes=skip_attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the qualified name of the package.", "response": "def qualified_name(self):\n        \"\"\"Get the qualified name of the package.\n\n        Returns:\n            str: Name of the package with version, eg \"maya-2016.1\".\n        \"\"\"\n        o = VersionedObject.construct(self.name, self.version)\n        return str(o)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parent(self):\n        family = self.repository.get_parent_package_family(self.resource)\n        return PackageFamily(family) if family else None", "response": "Get the parent package family."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\niterates over the variants within this package in index order.", "response": "def iter_variants(self):\n        \"\"\"Iterate over the variants within this package, in index order.\n\n        Returns:\n            `Variant` iterator.\n        \"\"\"\n        for variant in self.repository.iter_variants(self.resource):\n            yield Variant(variant, context=self.context, parent=self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the variant with the associated index.", "response": "def get_variant(self, index=None):\n        \"\"\"Get the variant with the associated index.\n\n        Returns:\n            `Variant` object, or None if no variant with the given index exists.\n        \"\"\"\n        for variant in self.iter_variants():\n            if variant.index == index:\n                return variant"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the qualified name of the variant.", "response": "def qualified_name(self):\n        \"\"\"Get the qualified name of the variant.\n\n        Returns:\n            str: Name of the variant with version and index, eg \"maya-2016.1[1]\".\n        \"\"\"\n        idxstr = '' if self.index is None else str(self.index)\n        return \"%s[%s]\" % (self.qualified_package_name, idxstr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parent(self):\n        if self._parent is not None:\n            return self._parent\n\n        try:\n            package = self.repository.get_parent_package(self.resource)\n            self._parent = Package(package, context=self.context)\n        except AttributeError as e:\n            reraise(e, ValueError)\n\n        return self._parent", "response": "Get the parent package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the requirements of the variant.", "response": "def get_requires(self, build_requires=False, private_build_requires=False):\n        \"\"\"Get the requirements of the variant.\n\n        Args:\n            build_requires (bool): If True, include build requirements.\n            private_build_requires (bool): If True, include private build\n                requirements.\n\n        Returns:\n            List of `Requirement` objects.\n        \"\"\"\n        requires = self.requires or []\n\n        if build_requires:\n            requires = requires + (self.build_requires or [])\n        if private_build_requires:\n            requires = requires + (self.private_build_requires or [])\n\n        return requires"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling this variant into another package repository.", "response": "def install(self, path, dry_run=False, overrides=None):\n        \"\"\"Install this variant into another package repository.\n\n        If the package already exists, this variant will be correctly merged\n        into the package. If the variant already exists in this package, the\n        existing variant is returned.\n\n        Args:\n            path (str): Path to destination package repository.\n            dry_run (bool): If True, do not actually install the variant. In this\n                mode, a `Variant` instance is only returned if the equivalent\n                variant already exists in this repository; otherwise, None is\n                returned.\n            overrides (dict): Use this to change or add attributes to the\n                installed variant.\n\n        Returns:\n            `Variant` object - the (existing or newly created) variant in the\n            specified repository. If `dry_run` is True, None may be returned.\n        \"\"\"\n        repo = package_repository_manager.get_repository(path)\n        resource = repo.install_variant(self.resource,\n                                        dry_run=dry_run,\n                                        overrides=overrides)\n        if resource is None:\n            return None\n        elif resource is self.resource:\n            return self\n        else:\n            return Variant(resource)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a file for writing and cache it.", "response": "def open_file_for_write(filepath, mode=None):\n    \"\"\"Writes both to given filepath, and tmpdir location.\n\n    This is to get around the problem with some NFS's where immediately reading\n    a file that has just been written is problematic. Instead, any files that we\n    write, we also write to /tmp, and reads of these files are redirected there.\n\n    Args:\n        filepath (str): File to write.\n        mode (int): Same mode arg as you would pass to `os.chmod`.\n\n    Yields:\n        File-like object.\n    \"\"\"\n    stream = StringIO()\n    yield stream\n    content = stream.getvalue()\n\n    filepath = os.path.realpath(filepath)\n    tmpdir = tmpdir_manager.mkdtemp()\n    cache_filepath = os.path.join(tmpdir, os.path.basename(filepath))\n\n    debug_print(\"Writing to %s (local cache of %s)\", cache_filepath, filepath)\n\n    with atomic_write(filepath, overwrite=True) as f:\n        f.write(content)\n\n    if mode is not None:\n        os.chmod(filepath, mode)\n\n    with open(cache_filepath, 'w') as f:\n        f.write(content)\n\n    file_cache[filepath] = cache_filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_from_file(filepath, format_=FileFormat.py, update_data_callback=None,\n                   disable_memcache=False):\n    \"\"\"Load data from a file.\n\n    Note:\n        Any functions from a .py file will be converted to `SourceCode` objects.\n\n    Args:\n        filepath (str): File to load.\n        format_ (`FileFormat`): Format of file contents.\n        update_data_callback (callable): Used to change data before it is\n            returned or cached.\n        disable_memcache (bool): If True, don't r/w to memcache.\n\n    Returns:\n        dict.\n    \"\"\"\n    filepath = os.path.realpath(filepath)\n    cache_filepath = file_cache.get(filepath)\n\n    if cache_filepath:\n        # file has been written by this process, read it from /tmp to avoid\n        # potential write-then-read issues over NFS\n        return _load_file(filepath=cache_filepath,\n                          format_=format_,\n                          update_data_callback=update_data_callback,\n                          original_filepath=filepath)\n    elif disable_memcache:\n        return _load_file(filepath=filepath,\n                          format_=format_,\n                          update_data_callback=update_data_callback)\n    else:\n        return _load_from_file(filepath=filepath,\n                               format_=format_,\n                               update_data_callback=update_data_callback)", "response": "Load data from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_py(stream, filepath=None):\n    with add_sys_paths(config.package_definition_build_python_paths):\n        return _load_py(stream, filepath=filepath)", "response": "Load python - formatted data from a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_python_objects(data, filepath=None):\n    def _process(value):\n        if isinstance(value, dict):\n            for k, v in value.items():\n                value[k] = _process(v)\n\n            return value\n        elif isfunction(value):\n            func = value\n\n            if hasattr(func, \"_early\"):\n                # run the function now, and replace with return value\n                #\n\n                # make a copy of the func with its own globals, and add 'this'\n                import types\n                fn = types.FunctionType(func.func_code,\n                                        func.func_globals.copy(),\n                                        name=func.func_name,\n                                        argdefs=func.func_defaults,\n                                        closure=func.func_closure)\n\n                # apply globals\n                fn.func_globals[\"this\"] = EarlyThis(data)\n                fn.func_globals.update(get_objects())\n\n                # execute the function\n                spec = getargspec(func)\n                args = spec.args or []\n                if len(args) not in (0, 1):\n                    raise ResourceError(\"@early decorated function must \"\n                                        \"take zero or one args only\")\n                if args:\n                    # this 'data' arg support isn't needed anymore, but I'm\n                    # supporting it til I know nobody is using it...\n                    #\n                    value_ = fn(data)\n                else:\n                    value_ = fn()\n\n                # process again in case this is a function returning a function\n                return _process(value_)\n\n            elif hasattr(func, \"_late\"):\n                return SourceCode(func=func, filepath=filepath,\n                                  eval_as_function=True)\n\n            elif func.__name__ in package_rex_keys:\n                # if a rex function, the code has to be eval'd NOT as a function,\n                # otherwise the globals dict doesn't get updated with any vars\n                # defined in the code, and that means rex code like this:\n                #\n                # rr = 'test'\n                # env.RR = '{rr}'\n                #\n                # ..won't work. It was never intentional that the above work, but\n                # it does, so now we have to keep it so.\n                #\n                return SourceCode(func=func, filepath=filepath,\n                                  eval_as_function=False)\n\n            else:\n                # a normal function. Leave unchanged, it will be stripped after\n                return func\n        else:\n            return value\n\n    def _trim(value):\n        if isinstance(value, dict):\n            for k, v in value.items():\n                if isfunction(v):\n                    if v.__name__ == \"preprocess\":\n                        # preprocess is a special case. It has to stay intact\n                        # until the `DeveloperPackage` has a chance to apply it;\n                        # after which it gets removed from the package attributes.\n                        #\n                        pass\n                    else:\n                        del value[k]\n                elif ismodule(v) or k.startswith(\"__\"):\n                    del value[k]\n                else:\n                    value[k] = _trim(v)\n\n        return value\n\n    data = _process(data)\n    data = _trim(data)\n    return data", "response": "Processes python objects in the given dict and returns a new dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_yaml(stream, **kwargs):\n    # if there's an error parsing the yaml, and you pass yaml.load a string,\n    # it will print lines of context, but will print \"<string>\" instead of a\n    # filename; if you pass a stream, it will print the filename, but no lines\n    # of context.\n    # Get the best of both worlds, by passing it a string, then replacing\n    # \"<string>\" with the filename if there's an error...\n    content = stream.read()\n    try:\n        return yaml.load(content) or {}\n    except Exception, e:\n        if stream.name and stream.name != '<string>':\n            for mark_name in 'context_mark', 'problem_mark':\n                mark = getattr(e, mark_name, None)\n                if mark is None:\n                    continue\n                if getattr(mark, 'name') == '<string>':\n                    mark.name = stream.name\n        raise e", "response": "Load a yaml - formatted data from a stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _close(self, args):\n        reply_code = args.read_short()\n        reply_text = args.read_shortstr()\n        class_id = args.read_short()\n        method_id = args.read_short()\n\n        self._x_close_ok()\n\n        raise error_for_code(reply_code, reply_text,\n                             (class_id, method_id), ConnectionError)", "response": "Request a connection close to the broker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _x_secure_ok(self, response):\n        args = AMQPWriter()\n        args.write_longstr(response)\n        self._send_method((10, 21), args)", "response": "This method is called when the server is authenticated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _x_start_ok(self, client_properties, mechanism, response, locale):\n        if self.server_capabilities.get('consumer_cancel_notify'):\n            if 'capabilities' not in client_properties:\n                client_properties['capabilities'] = {}\n            client_properties['capabilities']['consumer_cancel_notify'] = True\n        if self.server_capabilities.get('connection.blocked'):\n            if 'capabilities' not in client_properties:\n                client_properties['capabilities'] = {}\n            client_properties['capabilities']['connection.blocked'] = True\n        args = AMQPWriter()\n        args.write_table(client_properties)\n        args.write_shortstr(mechanism)\n        args.write_longstr(response)\n        args.write_shortstr(locale)\n        self._send_method((10, 11), args)", "response": "This method is called when the client is ready to start a new SASL security mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nproposes connection tuning parameters", "response": "def _tune(self, args):\n        \"\"\"Propose connection tuning parameters\n\n        This method proposes a set of connection configuration values\n        to the client.  The client can accept and/or adjust these.\n\n        PARAMETERS:\n            channel_max: short\n\n                proposed maximum channels\n\n                The maximum total number of channels that the server\n                allows per connection. Zero means that the server does\n                not impose a fixed limit, but the number of allowed\n                channels may be limited by available server resources.\n\n            frame_max: long\n\n                proposed maximum frame size\n\n                The largest frame size that the server proposes for\n                the connection. The client can negotiate a lower\n                value.  Zero means that the server does not impose any\n                specific limit but may reject very large frames if it\n                cannot allocate resources for them.\n\n                RULE:\n\n                    Until the frame-max has been negotiated, both\n                    peers MUST accept frames of up to 4096 octets\n                    large. The minimum non-zero value for the frame-\n                    max field is 4096.\n\n            heartbeat: short\n\n                desired heartbeat delay\n\n                The delay, in seconds, of the connection heartbeat\n                that the server wants.  Zero means the server does not\n                want a heartbeat.\n\n        \"\"\"\n        client_heartbeat = self.client_heartbeat or 0\n        self.channel_max = args.read_short() or self.channel_max\n        self.frame_max = args.read_long() or self.frame_max\n        self.method_writer.frame_max = self.frame_max\n        self.server_heartbeat = args.read_short() or 0\n\n        # negotiate the heartbeat interval to the smaller of the\n        # specified values\n        if self.server_heartbeat == 0 or client_heartbeat == 0:\n            self.heartbeat = max(self.server_heartbeat, client_heartbeat)\n        else:\n            self.heartbeat = min(self.server_heartbeat, client_heartbeat)\n\n        # Ignore server heartbeat if client_heartbeat is disabled\n        if not self.client_heartbeat:\n            self.heartbeat = 0\n\n        self._x_tune_ok(self.channel_max, self.frame_max, self.heartbeat)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending heartbeat packets if necessary and fail if none have been received recently.", "response": "def heartbeat_tick(self, rate=2):\n        \"\"\"Send heartbeat packets, if necessary, and fail if none have been\n        received recently.  This should be called frequently, on the order of\n        once per second.\n\n        :keyword rate: Ignored\n        \"\"\"\n        if not self.heartbeat:\n            return\n\n        # treat actual data exchange in either direction as a heartbeat\n        sent_now = self.method_writer.bytes_sent\n        recv_now = self.method_reader.bytes_recv\n        if self.prev_sent is None or self.prev_sent != sent_now:\n            self.last_heartbeat_sent = monotonic()\n        if self.prev_recv is None or self.prev_recv != recv_now:\n            self.last_heartbeat_received = monotonic()\n        self.prev_sent, self.prev_recv = sent_now, recv_now\n\n        # send a heartbeat if it's time to do so\n        if monotonic() > self.last_heartbeat_sent + self.heartbeat:\n            self.send_heartbeat()\n            self.last_heartbeat_sent = monotonic()\n\n        # if we've missed two intervals' heartbeats, fail; this gives the\n        # server enough time to send heartbeats a little late\n        if (self.last_heartbeat_received and\n                self.last_heartbeat_received + 2 *\n                self.heartbeat < monotonic()):\n            raise ConnectionForced('Too many heartbeats missed')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _x_tune_ok(self, channel_max, frame_max, heartbeat):\n        args = AMQPWriter()\n        args.write_short(channel_max)\n        args.write_long(frame_max)\n        args.write_short(heartbeat or 0)\n        self._send_method((10, 31), args)\n        self._wait_tune_ok = False", "response": "Negotiate connection tuning parameters to the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the current parent suite.", "response": "def parent_suite(self):\n        \"\"\"Get the current parent suite.\n\n        A parent suite exists when a context within a suite is active. That is,\n        during execution of a tool within a suite, or after a user has entered\n        an interactive shell in a suite context, for example via the command-\n        line syntax 'tool +i', where 'tool' is an alias in a suite.\n\n        Returns:\n            `Suite` object, or None if there is no current parent suite.\n        \"\"\"\n        if self.context and self.context.parent_suite_path:\n            return Suite.load(self.context.parent_suite_path)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_info(self, obj=None, buf=sys.stdout):\n        if not obj:\n            self._print_info(buf)\n            return True\n\n        b = False\n        for fn in (self._print_tool_info,\n                   self._print_package_info,\n                   self._print_suite_info,\n                   self._print_context_info):\n            b_ = fn(obj, buf, b)\n            b |= b_\n            if b_:\n                print >> buf, ''\n\n        if not b:\n            print >> buf, \"Rez does not know what '%s' is\" % obj\n        return b", "response": "Print a status message about the given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_tools(self, pattern=None, buf=sys.stdout):\n        seen = set()\n        rows = []\n\n        context = self.context\n        if context:\n            data = context.get_tools()\n            conflicts = set(context.get_conflicting_tools().keys())\n            for _, (variant, tools) in sorted(data.items()):\n                pkg_str = variant.qualified_package_name\n                for tool in tools:\n                    if pattern and not fnmatch(tool, pattern):\n                        continue\n\n                    if tool in conflicts:\n                        label = \"(in conflict)\"\n                        color = critical\n                    else:\n                        label = ''\n                        color = None\n\n                    rows.append([tool, '-', pkg_str, \"active context\", label, color])\n                    seen.add(tool)\n\n        for suite in self.suites:\n            for tool, d in suite.get_tools().iteritems():\n                if tool in seen:\n                    continue\n                if pattern and not fnmatch(tool, pattern):\n                    continue\n\n                label = []\n                color = None\n                path = which(tool)\n                if path:\n                    path_ = os.path.join(suite.tools_path, tool)\n                    if path != path_:\n                        label.append(\"(hidden by unknown tool '%s')\" % path)\n                        color = warning\n\n                variant = d[\"variant\"]\n                if isinstance(variant, set):\n                    pkg_str = \", \".join(variant)\n                    label.append(\"(in conflict)\")\n                    color = critical\n                else:\n                    pkg_str = variant.qualified_package_name\n\n                orig_tool = d[\"tool_name\"]\n                if orig_tool == tool:\n                    orig_tool = '-'\n\n                label = ' '.join(label)\n                source = (\"context '%s' in suite '%s'\"\n                          % (d[\"context_name\"], suite.load_path))\n\n                rows.append([tool, orig_tool, pkg_str, source, label, color])\n                seen.add(tool)\n\n        _pr = Printer(buf)\n        if not rows:\n            _pr(\"No matching tools.\")\n            return False\n\n        headers = [[\"TOOL\", \"ALIASING\", \"PACKAGE\", \"SOURCE\", \"\", None],\n                   [\"----\", \"--------\", \"-------\", \"------\", \"\", None]]\n        rows = headers + sorted(rows, key=lambda x: x[0].lower())\n        print_colored_columns(_pr, rows)\n        return True", "response": "Print a list of visible tools."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a developer package from a path.", "response": "def from_path(cls, path, format=None):\n        \"\"\"Load a developer package.\n\n        A developer package may for example be a package.yaml or package.py in a\n        user's source directory.\n\n        Args:\n            path: Directory containing the package definition file, or file\n                path for the package file itself\n            format: which FileFormat to use, or None to check both .py and .yaml\n\n        Returns:\n            `Package` object.\n        \"\"\"\n        name = None\n        data = None\n\n        if format is None:\n            formats = (FileFormat.py, FileFormat.yaml)\n        else:\n            formats = (format,)\n\n        try:\n            mode = os.stat(path).st_mode\n        except (IOError, OSError):\n            raise PackageMetadataError(\n                \"Path %r did not exist, or was not accessible\" % path)\n        is_dir = stat.S_ISDIR(mode)\n\n        for name_ in config.plugins.package_repository.filesystem.package_filenames:\n            for format_ in formats:\n                if is_dir:\n                    filepath = os.path.join(path, \"%s.%s\" % (name_,\n                                                             format_.extension))\n                    exists = os.path.isfile(filepath)\n                else:\n                    # if format was not specified, verify that it has the\n                    # right extension before trying to load\n                    if format is None:\n                        if os.path.splitext(path)[1] != format_.extension:\n                            continue\n                    filepath = path\n                    exists = True\n\n                if exists:\n                    data = load_from_file(filepath, format_, disable_memcache=True)\n                    break\n            if data:\n                name = data.get(\"name\")\n                if name is not None or isinstance(name, basestring):\n                    break\n\n        if data is None:\n            raise PackageMetadataError(\"No package definition file found at %s\" % path)\n\n        if name is None or not isinstance(name, basestring):\n            raise PackageMetadataError(\n                \"Error in %r - missing or non-string field 'name'\" % filepath)\n\n        package = create_package(name, data, package_cls=cls)\n\n        # preprocessing\n        result = package._get_preprocessed(data)\n\n        if result:\n            package, data = result\n\n        package.filepath = filepath\n\n        # find all includes, this is needed at install time to copy the right\n        # py sourcefiles into the package installation\n        package.includes = set()\n\n        def visit(d):\n            for k, v in d.iteritems():\n                if isinstance(v, SourceCode):\n                    package.includes |= (v.includes or set())\n                elif isinstance(v, dict):\n                    visit(v)\n\n        visit(data)\n\n        package._validate_includes()\n\n        return package"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_preprocessed(self, data):\n        from rez.serialise import process_python_objects\n        from rez.utils.data_utils import get_dict_diff_str\n        from copy import deepcopy\n\n        with add_sys_paths(config.package_definition_build_python_paths):\n            preprocess_func = getattr(self, \"preprocess\", None)\n\n            if preprocess_func:\n                print_info(\"Applying preprocess from package.py\")\n            else:\n                # load globally configured preprocess function\n                dotted = self.config.package_preprocess_function\n\n                if not dotted:\n                    return None\n\n                if '.' not in dotted:\n                    print_error(\n                        \"Setting 'package_preprocess_function' must be of \"\n                        \"form 'module[.module.module...].funcname'. Package  \"\n                        \"preprocessing has not been applied.\")\n                    return None\n\n                name, funcname = dotted.rsplit('.', 1)\n\n                try:\n                    module = __import__(name=name, fromlist=[funcname])\n                except Exception as e:\n                    print_error(\"Failed to load preprocessing function '%s': %s\"\n                                % (dotted, str(e)))\n                    return None\n\n                setattr(module, \"InvalidPackageError\", InvalidPackageError)\n                preprocess_func = getattr(module, funcname)\n\n                if not preprocess_func or not isfunction(isfunction):\n                    print_error(\"Function '%s' not found\" % dotted)\n                    return None\n\n                print_info(\"Applying preprocess function %s\" % dotted)\n\n            preprocessed_data = deepcopy(data)\n\n            # apply preprocessing\n            try:\n                preprocess_func(this=self, data=preprocessed_data)\n            except InvalidPackageError:\n                raise\n            except Exception as e:\n                print_error(\"Failed to apply preprocess: %s: %s\"\n                            % (e.__class__.__name__, str(e)))\n                return None\n\n        # if preprocess added functions, these may need to be converted to\n        # SourceCode instances\n        preprocessed_data = process_python_objects(preprocessed_data)\n\n        if preprocessed_data == data:\n            return None\n\n        # recreate package from modified package data\n        package = create_package(self.name, preprocessed_data,\n                                 package_cls=self.__class__)\n\n        # print summary of changed package attributes\n        txt = get_dict_diff_str(\n            data,\n            preprocessed_data,\n            title=\"Package attributes were changed in preprocessing:\"\n        )\n        print_info(txt)\n\n        return package, preprocessed_data", "response": "Returns the preprocessed version of the package."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(stream, Loader=Loader):\n    loader = Loader(stream)\n    try:\n        return loader.get_single_data()\n    finally:\n        loader.dispose()", "response": "Parse the first YAML document in a stream and produce a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses all YAML documents in a stream and produce corresponding Python objects.", "response": "def load_all(stream, Loader=Loader):\n    \"\"\"\n    Parse all YAML documents in a stream\n    and produce corresponding Python objects.\n    \"\"\"\n    loader = Loader(stream)\n    try:\n        while loader.check_data():\n            yield loader.get_data()\n    finally:\n        loader.dispose()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump_all(documents, stream=None, Dumper=Dumper,\n        default_style=None, default_flow_style=None,\n        canonical=None, indent=None, width=None,\n        allow_unicode=None, line_break=None,\n        encoding='utf-8', explicit_start=None, explicit_end=None,\n        version=None, tags=None):\n    \"\"\"\n    Serialize a sequence of Python objects into a YAML stream.\n    If stream is None, return the produced string instead.\n    \"\"\"\n    getvalue = None\n    if stream is None:\n        if encoding is None:\n            from StringIO import StringIO\n        else:\n            from cStringIO import StringIO\n        stream = StringIO()\n        getvalue = stream.getvalue\n    dumper = Dumper(stream, default_style=default_style,\n            default_flow_style=default_flow_style,\n            canonical=canonical, indent=indent, width=width,\n            allow_unicode=allow_unicode, line_break=line_break,\n            encoding=encoding, version=version, tags=tags,\n            explicit_start=explicit_start, explicit_end=explicit_end)\n    try:\n        dumper.open()\n        for data in documents:\n            dumper.represent(data)\n        dumper.close()\n    finally:\n        dumper.dispose()\n    if getvalue:\n        return getvalue()", "response": "Serialize a sequence of Python objects into a YAML stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef running_instances(self, context, process_name):\n        handle = (id(context), process_name)\n        it = self.processes.get(handle, {}).itervalues()\n        entries = [x for x in it if x[0].poll() is None]\n        return entries", "response": "Get a list of running instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of methods on this class for executing actions.", "response": "def get_action_methods(self):\n        \"\"\"\n        return a list of methods on this class for executing actions.\n        methods are return as a list of (name, func) tuples\n        \"\"\"\n        return [(name, getattr(self, name))\n                for name, _ in Action.get_command_types()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of public methods on this class which should be exposed in the rex API.", "response": "def get_public_methods(self):\n        \"\"\"\n        return a list of methods on this class which should be exposed in the rex\n        API.\n        \"\"\"\n        return self.get_action_methods() + [\n            ('getenv', self.getenv),\n            ('expandvars', self.expandvars),\n            ('defined', self.defined),\n            ('undefined', self.undefined)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_environ(self):\n        if self.manager is None:\n            raise RezSystemError(\"You must call 'set_manager' on a Python rex \"\n                                 \"interpreter before using it.\")\n\n        self.target_environ.update(self.manager.environ)", "response": "Apply changes to target environ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef formatted(self, func):\n        other = EscapedString.__new__(EscapedString)\n        other.strings = []\n\n        for is_literal, value in self.strings:\n            if not is_literal:\n                value = func(value)\n            other.strings.append((is_literal, value))\n        return other", "response": "Return the string with non - literal parts formatted."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append_system_paths(self):\n        from rez.shells import Shell, create_shell\n        sh = self.interpreter if isinstance(self.interpreter, Shell) \\\n            else create_shell()\n\n        paths = sh.get_syspaths()\n        paths_str = os.pathsep.join(paths)\n        self.env.PATH.append(paths_str)", "response": "Append system paths to the environment PATH."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_rez_path(self):\n        if system.rez_bin_path:\n            self.env.PATH.append(system.rez_bin_path)", "response": "Append rez path to environment path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_code(cls, code, filename=None, exec_namespace=None):\n        if filename is None:\n            if isinstance(code, SourceCode):\n                filename = code.sourcename\n            else:\n                filename = \"<string>\"\n\n        # compile\n        try:\n            if isinstance(code, SourceCode):\n                pyc = code.compiled\n            else:\n                pyc = compile(code, filename, 'exec')\n        except SourceCodeError as e:\n            reraise(e, RexError)\n        except Exception as e:\n            stack = traceback.format_exc()\n            raise RexError(\"Failed to compile %s:\\n\\n%s\" % (filename, stack))\n\n        error_class = Exception if config.catch_rex_errors else None\n\n        # execute\n        if exec_namespace is not None:\n            try:\n                if isinstance(code, SourceCode):\n                    code.exec_(globals_=exec_namespace)\n                else:\n                    exec pyc in exec_namespace\n            except RexError:\n                raise\n            except SourceCodeError as e:\n                reraise(e, RexError)\n            except error_class as e:\n                stack = traceback.format_exc()\n                raise RexError(\"Failed to exec %s:\\n\\n%s\" % (filename, stack))\n\n        return pyc", "response": "Compile and possibly execute rex code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute the code within the execution context.", "response": "def execute_code(self, code, filename=None, isolate=False):\n        \"\"\"Execute code within the execution context.\n\n        Args:\n            code (str or SourceCode): Rex code to execute.\n            filename (str): Filename to report if there are syntax errors.\n            isolate (bool): If True, do not affect `self.globals` by executing\n                this code.\n        \"\"\"\n        def _apply():\n            self.compile_code(code=code,\n                              filename=filename,\n                              exec_namespace=self.globals)\n\n        # we want to execute the code using self.globals - if for no other\n        # reason that self.formatter is pointing at self.globals, so if we\n        # passed in a copy, we would also need to make self.formatter \"look\" at\n        # the same copy - but we don't want to \"pollute\" our namespace, because\n        # the same executor may be used to run multiple packages. Therefore,\n        # we save a copy of self.globals before execution, and restore it after\n        #\n        if isolate:\n            saved_globals = dict(self.globals)\n\n            try:\n                _apply()\n            finally:\n                self.globals.clear()\n                self.globals.update(saved_globals)\n        else:\n            _apply()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a function object within the execution context.", "response": "def execute_function(self, func, *nargs, **kwargs):\n        \"\"\"\n        Execute a function object within the execution context.\n        @returns The result of the function call.\n        \"\"\"\n        # makes a copy of the func\n        import types\n        fn = types.FunctionType(func.func_code,\n                                func.func_globals.copy(),\n                                name=func.func_name,\n                                argdefs=func.func_defaults,\n                                closure=func.func_closure)\n        fn.func_globals.update(self.globals)\n\n        error_class = Exception if config.catch_rex_errors else None\n\n        try:\n            return fn(*nargs, **kwargs)\n        except RexError:\n            raise\n        except error_class as e:\n            from inspect import getfile\n\n            stack = traceback.format_exc()\n            filename = getfile(func)\n\n            raise RexError(\"Failed to exec %s:\\n\\n%s\" % (filename, stack))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_output(self, style=OutputStyle.file):\n        return self.manager.get_output(style=style)", "response": "Returns the result of all previous calls to execute_code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef configure(self, graph, spanning_tree):\n        self.graph = graph\n        self.spanning_tree = spanning_tree", "response": "Configure the filter.\n        \n        @type  graph: graph\n        @param graph: Graph.\n        \n        @type  spanning_tree: dictionary\n        @param spanning_tree: Spanning tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterator over the packages in packages. py.", "response": "def iter_packages(self, name, range_=None, paths=None):\n        \"\"\"Same as iter_packages in packages.py, but also applies this filter.\n\n        Args:\n            name (str): Name of the package, eg 'maya'.\n            range_ (VersionRange or str): If provided, limits the versions returned\n                to those in `range_`.\n            paths (list of str, optional): paths to search for packages, defaults\n                to `config.packages_path`.\n\n        Returns:\n            `Package` iterator.\n        \"\"\"\n        for package in iter_packages(name, range_, paths):\n            if not self.excludes(package):\n                yield package"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self):\n        other = PackageFilter.__new__(PackageFilter)\n        other._excludes = self._excludes.copy()\n        other._includes = self._includes.copy()\n        return other", "response": "Return a shallow copy of the filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cost(self):\n        total = 0.0\n        for family, rules in self._excludes.iteritems():\n            cost = sum(x.cost() for x in rules)\n            if family:\n                cost = cost / float(10)\n            total += cost\n        return total", "response": "Get the approximate cost of this filter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a filter to the list.", "response": "def add_filter(self, package_filter):\n        \"\"\"Add a filter to the list.\n\n        Args:\n            package_filter (`PackageFilter`): Filter to add.\n        \"\"\"\n        filters = self.filters + [package_filter]\n        self.filters = sorted(filters, key=lambda x: x.cost)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a copy of the filter list.", "response": "def copy(self):\n        \"\"\"Return a copy of the filter list.\n\n        Adding rules to the copy will not alter the source.\n        \"\"\"\n        other = PackageFilterList.__new__(PackageFilterList)\n        other.filters = [x.copy() for x in self.filters]\n        return other"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a rule from a string.", "response": "def parse_rule(cls, txt):\n        \"\"\"Parse a rule from a string.\n\n        See rezconfig.package_filter for an overview of valid strings.\n\n        Args:\n            txt (str): String to parse.\n\n        Returns:\n            `Rule` instance.\n        \"\"\"\n        types = {\"glob\": GlobRule,\n                 \"regex\": RegexRule,\n                 \"range\": RangeRule,\n                 \"before\": TimestampRule,\n                 \"after\": TimestampRule}\n\n        # parse form 'x(y)' into x, y\n        label, txt = Rule._parse_label(txt)\n        if label is None:\n            if '*' in txt:\n                label = \"glob\"\n            else:\n                label = \"range\"\n        elif label not in types:\n            raise ConfigurationError(\n                \"'%s' is not a valid package filter type\" % label)\n\n        rule_cls = types[label]\n        txt_ = \"%s(%s)\" % (label, txt)\n\n        try:\n            rule = rule_cls._parse(txt_)\n        except Exception as e:\n            raise ConfigurationError(\"Error parsing package filter '%s': %s: %s\"\n                                     % (txt_, e.__class__.__name__, str(e)))\n        return rule"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_bit(self):\n        if not self.bitcount:\n            self.bits = ord(self.input.read(1))\n            self.bitcount = 8\n        result = (self.bits & 1) == 1\n        self.bits >>= 1\n        self.bitcount -= 1\n        return result", "response": "Read a single boolean value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_octet(self):\n        self.bitcount = self.bits = 0\n        return unpack('B', self.input.read(1))[0]", "response": "Read one byte return as an integer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_short(self):\n        self.bitcount = self.bits = 0\n        return unpack('>H', self.input.read(2))[0]", "response": "Read an unsigned 16 - bit integer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread an unsigned 32 - bit integer from the input stream.", "response": "def read_long(self):\n        \"\"\"Read an unsigned 32-bit integer\"\"\"\n        self.bitcount = self.bits = 0\n        return unpack('>I', self.input.read(4))[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_longlong(self):\n        self.bitcount = self.bits = 0\n        return unpack('>Q', self.input.read(8))[0]", "response": "Read an unsigned 64 - bit integer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a short string that s stored in up to 255 bytes.", "response": "def read_shortstr(self):\n        \"\"\"Read a short string that's stored in up to 255 bytes.\n\n        The encoding isn't specified in the AMQP spec, so\n        assume it's utf-8\n\n        \"\"\"\n        self.bitcount = self.bits = 0\n        slen = unpack('B', self.input.read(1))[0]\n        return self.input.read(slen).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread an AMQP table and return as a Python dictionary.", "response": "def read_table(self):\n        \"\"\"Read an AMQP table, and return as a Python dictionary.\"\"\"\n        self.bitcount = self.bits = 0\n        tlen = unpack('>I', self.input.read(4))[0]\n        table_data = AMQPReader(self.input.read(tlen))\n        result = {}\n        while table_data.input.tell() < tlen:\n            name = table_data.read_shortstr()\n            val = table_data.read_item()\n            result[name] = val\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting an integer as an unsigned 16 - bit value.", "response": "def write_short(self, n):\n        \"\"\"Write an integer as an unsigned 16-bit value.\"\"\"\n        if n < 0 or n > 65535:\n            raise FrameSyntaxError(\n                'Octet {0!r} out of range 0..65535'.format(n))\n        self._flushbits()\n        self.out.write(pack('>H', int(n)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites an integer as an unsigned2 32 - bit value.", "response": "def write_long(self, n):\n        \"\"\"Write an integer as an unsigned2 32-bit value.\"\"\"\n        if n < 0 or n >= 4294967296:\n            raise FrameSyntaxError(\n                'Octet {0!r} out of range 0..2**31-1'.format(n))\n        self._flushbits()\n        self.out.write(pack('>I', n))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_shortstr(self, s):\n        self._flushbits()\n        if isinstance(s, string):\n            s = s.encode('utf-8')\n        if len(s) > 255:\n            raise FrameSyntaxError(\n                'Shortstring overflow ({0} > 255)'.format(len(s)))\n        self.write_octet(len(s))\n        self.out.write(s)", "response": "Write a string up to 255 bytes long."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite out a Python dictionary made of up string keys and values that are strings signed integers Decimal datetime. datetime or or sub - dictionaries following the same constraints.", "response": "def write_table(self, d):\n        \"\"\"Write out a Python dictionary made of up string keys, and values\n        that are strings, signed integers, Decimal, datetime.datetime, or\n        sub-dictionaries following the same constraints.\"\"\"\n        self._flushbits()\n        table_data = AMQPWriter()\n        for k, v in items(d):\n            table_data.write_shortstr(k)\n            table_data.write_item(v, k)\n        table_data = table_data.getvalue()\n        self.write_long(len(table_data))\n        self.out.write(table_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting out a Python datetime. datetime object as a 64 - bit integer containing seconds since the Unix epoch.", "response": "def write_timestamp(self, v):\n        \"\"\"Write out a Python datetime.datetime object as a 64-bit integer\n        representing seconds since the Unix epoch.\"\"\"\n        self.out.write(pack('>Q', long_t(calendar.timegm(v.utctimetuple()))))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the raw bytes containing the property - flags and property - list from a content - frame - header and insert into a dictionary containing the properties of this object.", "response": "def _load_properties(self, raw_bytes):\n        \"\"\"Given the raw bytes containing the property-flags and property-list\n        from a content-frame-header, parse and insert into a dictionary\n        stored in this object as an attribute named 'properties'.\"\"\"\n        r = AMQPReader(raw_bytes)\n\n        #\n        # Read 16-bit shorts until we get one with a low bit set to zero\n        #\n        flags = []\n        while 1:\n            flag_bits = r.read_short()\n            flags.append(flag_bits)\n            if flag_bits & 1 == 0:\n                break\n\n        shift = 0\n        d = {}\n        for key, proptype in self.PROPERTIES:\n            if shift == 0:\n                if not flags:\n                    break\n                flag_bits, flags = flags[0], flags[1:]\n                shift = 15\n            if flag_bits & (1 << shift):\n                d[key] = getattr(r, 'read_' + proptype)()\n            shift -= 1\n\n        self.properties = d"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _serialize_properties(self):\n        shift = 15\n        flag_bits = 0\n        flags = []\n        raw_bytes = AMQPWriter()\n        for key, proptype in self.PROPERTIES:\n            val = self.properties.get(key, None)\n            if val is not None:\n                if shift == 0:\n                    flags.append(flag_bits)\n                    flag_bits = 0\n                    shift = 15\n\n                flag_bits |= (1 << shift)\n                if proptype != 'bit':\n                    getattr(raw_bytes, 'write_' + proptype)(val)\n\n            shift -= 1\n\n        flags.append(flag_bits)\n        result = AMQPWriter()\n        for flag_bits in flags:\n            result.write_short(flag_bits)\n        result.write(raw_bytes.getvalue())\n\n        return result.getvalue()", "response": "serialize the properties attribute into the raw bytes making up a set of property flags and a\n        property list suitable for putting into a content frame header."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an executable script.", "response": "def create_executable_script(filepath, body, program=None):\n    \"\"\"Create an executable script.\n\n    Args:\n        filepath (str): File to create.\n        body (str or callable): Contents of the script. If a callable, its code\n            is used as the script body.\n        program (str): Name of program to launch the script, 'python' if None\n    \"\"\"\n    program = program or \"python\"\n    if callable(body):\n        from rez.utils.sourcecode import SourceCode\n        code = SourceCode(func=body)\n        body = code.source\n\n    if not body.endswith('\\n'):\n        body += '\\n'\n\n    with open(filepath, 'w') as f:\n        # TODO: make cross platform\n        f.write(\"#!/usr/bin/env %s\\n\" % program)\n        f.write(body)\n\n    # TODO: Although Windows supports os.chmod you can only set the readonly\n    # flag. Setting the file readonly breaks the unit tests that expect to\n    # clean up the files once the test has run.  Temporarily we don't bother\n    # setting the permissions, but this will need to change.\n    if os.name == \"posix\":\n    \tos.chmod(filepath, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH\n             | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a forwarding script that executes some arbitrary Rez function.", "response": "def create_forwarding_script(filepath, module, func_name, *nargs, **kwargs):\n    \"\"\"Create a 'forwarding' script.\n\n    A forwarding script is one that executes some arbitrary Rez function. This\n    is used internally by Rez to dynamically create a script that uses Rez,\n    even though the parent environment may not be configured to do so.\n    \"\"\"\n    doc = dict(\n        module=module,\n        func_name=func_name)\n\n    if nargs:\n        doc[\"nargs\"] = nargs\n    if kwargs:\n        doc[\"kwargs\"] = kwargs\n\n    body = dump_yaml(doc)\n    create_executable_script(filepath, body, \"_rez_fwd\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove duplicates from a list while keeping order.", "response": "def dedup(seq):\n    \"\"\"Remove duplicates from a list while keeping order.\"\"\"\n    seen = set()\n    for item in seq:\n        if item not in seen:\n            seen.add(item)\n            yield item"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a list find the last occurance of a sublist within it.", "response": "def find_last_sublist(list_, sublist):\n    \"\"\"Given a list, find the last occurance of a sublist within it.\n\n    Returns:\n        Index where the sublist starts, or None if there is no match.\n    \"\"\"\n    for i in reversed(range(len(list_) - len(sublist) + 1)):\n        if list_[i] == sublist[0] and list_[i:i + len(sublist)] == sublist:\n            return i\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlaunches a help section.", "response": "def open(self, section_index=0):\n        \"\"\"Launch a help section.\"\"\"\n        uri = self._sections[section_index][1]\n        if len(uri.split()) == 1:\n            self._open_url(uri)\n        else:\n            if self._verbose:\n                print \"running command: %s\" % uri\n            p = popen(uri, shell=True)\n            p.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_servers(self, servers):\n        self.servers = [_Host(s, self.debug, dead_retry=self.dead_retry,\n                socket_timeout=self.socket_timeout,\n                flush_on_reconnect=self.flush_on_reconnect)\n                    for s in servers]\n        self._init_buckets()", "response": "Sets the pool of servers used by this client."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_stats(self, stat_args = None):\n        '''Get statistics from each of the servers.\n\n        @param stat_args: Additional arguments to pass to the memcache\n            \"stats\" command.\n\n        @return: A list of tuples ( server_identifier, stats_dictionary ).\n            The dictionary contains a number of name/value pairs specifying\n            the name of the status field and the string value associated with\n            it.  The values are not converted from strings.\n        '''\n        data = []\n        for s in self.servers:\n            if not s.connect(): continue\n            if s.family == socket.AF_INET:\n                name = '%s:%s (%s)' % ( s.ip, s.port, s.weight )\n            elif s.family == socket.AF_INET6:\n                name = '[%s]:%s (%s)' % ( s.ip, s.port, s.weight )\n            else:\n                name = 'unix:%s (%s)' % ( s.address, s.weight )\n            if not stat_args:\n                s.send_cmd('stats')\n            else:\n                s.send_cmd('stats ' + stat_args)\n            serverData = {}\n            data.append(( name, serverData ))\n            readline = s.readline\n            while 1:\n                line = readline()\n                if not line or line.strip() in ('END', 'RESET'):\n                    break\n                stats = line.split(' ', 2)\n                serverData[stats[1]] = stats[2]\n\n        return(data)", "response": "Get statistics from each of the servers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_multi(self, keys, time=0, key_prefix=''):\n        '''\n        Delete multiple keys in the memcache doing just one query.\n\n        >>> notset_keys = mc.set_multi({'key1' : 'val1', 'key2' : 'val2'})\n        >>> mc.get_multi(['key1', 'key2']) == {'key1' : 'val1', 'key2' : 'val2'}\n        1\n        >>> mc.delete_multi(['key1', 'key2'])\n        1\n        >>> mc.get_multi(['key1', 'key2']) == {}\n        1\n\n\n        This method is recommended over iterated regular L{delete}s as it reduces total latency, since\n        your app doesn't have to wait for each round-trip of L{delete} before sending\n        the next one.\n\n        @param keys: An iterable of keys to clear\n        @param time: number of seconds any subsequent set / update commands should fail. Defaults to 0 for no delay.\n        @param key_prefix:  Optional string to prepend to each key when sending to memcache.\n            See docs for L{get_multi} and L{set_multi}.\n\n        @return: 1 if no failure in communication with any memcacheds.\n        @rtype: int\n\n        '''\n\n        self._statlog('delete_multi')\n\n        server_keys, prefixed_to_orig_key = self._map_and_prefix_keys(keys, key_prefix)\n\n        # send out all requests on each server before reading anything\n        dead_servers = []\n\n        rc = 1\n        for server in server_keys.iterkeys():\n            bigcmd = []\n            write = bigcmd.append\n            if time != None:\n                 for key in server_keys[server]: # These are mangled keys\n                     write(\"delete %s %d\\r\\n\" % (key, time))\n            else:\n                for key in server_keys[server]: # These are mangled keys\n                  write(\"delete %s\\r\\n\" % key)\n            try:\n                server.send_cmds(''.join(bigcmd))\n            except socket.error, msg:\n                rc = 0\n                if isinstance(msg, tuple): msg = msg[1]\n                server.mark_dead(msg)\n                dead_servers.append(server)\n\n        # if any servers died on the way, don't expect them to respond.\n        for server in dead_servers:\n            del server_keys[server]\n\n        for server, keys in server_keys.iteritems():\n            try:\n                for key in keys:\n                    server.expect(\"DELETED\")\n            except socket.error, msg:\n                if isinstance(msg, tuple): msg = msg[1]\n                server.mark_dead(msg)\n                rc = 0\n        return rc", "response": "Delete multiple keys in the memcache doing just one query."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a key from the memcache.", "response": "def delete(self, key, time=0):\n        '''Deletes a key from the memcache.\n\n        @return: Nonzero on success.\n        @param time: number of seconds any subsequent set / update commands\n        should fail. Defaults to None for no delay.\n        @rtype: int\n        '''\n        if self.do_check_key:\n            self.check_key(key)\n        server, key = self._get_server(key)\n        if not server:\n            return 0\n        self._statlog('delete')\n        if time != None and time != 0:\n            cmd = \"delete %s %d\" % (key, time)\n        else:\n            cmd = \"delete %s\" % key\n\n        try:\n            server.send_cmd(cmd)\n            line = server.readline()\n            if line and line.strip() in ['DELETED', 'NOT_FOUND']: return 1\n            self.debuglog('Delete expected DELETED or NOT_FOUND, got: %s'\n                    % repr(line))\n        except socket.error, msg:\n            if isinstance(msg, tuple): msg = msg[1]\n            server.mark_dead(msg)\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding new key with value.", "response": "def add(self, key, val, time = 0, min_compress_len = 0):\n        '''\n        Add new key with value.\n\n        Like L{set}, but only stores in memcache if the key doesn't already exist.\n\n        @return: Nonzero on success.\n        @rtype: int\n        '''\n        return self._set(\"add\", key, val, time, min_compress_len)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nappend the value to the end of the existing key s value.", "response": "def append(self, key, val, time=0, min_compress_len=0):\n        '''Append the value to the end of the existing key's value.\n\n        Only stores in memcache if key already exists.\n        Also see L{prepend}.\n\n        @return: Nonzero on success.\n        @rtype: int\n        '''\n        return self._set(\"append\", key, val, time, min_compress_len)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace(self, key, val, time=0, min_compress_len=0):\n        '''Replace existing key with value.\n\n        Like L{set}, but only stores in memcache if the key already exists.\n        The opposite of L{add}.\n\n        @return: Nonzero on success.\n        @rtype: int\n        '''\n        return self._set(\"replace\", key, val, time, min_compress_len)", "response": "Replace existing key with value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, key, val, time=0, min_compress_len=0):\n        '''Unconditionally sets a key to a given value in the memcache.\n\n        The C{key} can optionally be an tuple, with the first element\n        being the server hash value and the second being the key.\n        If you want to avoid making this module calculate a hash value.\n        You may prefer, for example, to keep all of a given user's objects\n        on the same memcache server, so you could use the user's unique\n        id as the hash value.\n\n        @return: Nonzero on success.\n        @rtype: int\n        @param time: Tells memcached the time which this value should expire, either\n        as a delta number of seconds, or an absolute unix time-since-the-epoch\n        value. See the memcached protocol docs section \"Storage Commands\"\n        for more info on <exptime>. We default to 0 == cache forever.\n        @param min_compress_len: The threshold length to kick in auto-compression\n        of the value using the zlib.compress() routine. If the value being cached is\n        a string, then the length of the string is measured, else if the value is an\n        object, then the length of the pickle result is measured. If the resulting\n        attempt at compression yeilds a larger string than the input, then it is\n        discarded. For backwards compatability, this parameter defaults to 0,\n        indicating don't ever try to compress.\n        '''\n        return self._set(\"set\", key, val, time, min_compress_len)", "response": "Unconditionally sets a key to a given value in the memcache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cas(self, key, val, time=0, min_compress_len=0):\n        '''Sets a key to a given value in the memcache if it hasn't been\n        altered since last fetched. (See L{gets}).\n\n        The C{key} can optionally be an tuple, with the first element\n        being the server hash value and the second being the key.\n        If you want to avoid making this module calculate a hash value.\n        You may prefer, for example, to keep all of a given user's objects\n        on the same memcache server, so you could use the user's unique\n        id as the hash value.\n\n        @return: Nonzero on success.\n        @rtype: int\n        @param time: Tells memcached the time which this value should expire,\n        either as a delta number of seconds, or an absolute unix\n        time-since-the-epoch value. See the memcached protocol docs section\n        \"Storage Commands\" for more info on <exptime>. We default to\n        0 == cache forever.\n        @param min_compress_len: The threshold length to kick in\n        auto-compression of the value using the zlib.compress() routine. If\n        the value being cached is a string, then the length of the string is\n        measured, else if the value is an object, then the length of the\n        pickle result is measured. If the resulting attempt at compression\n        yeilds a larger string than the input, then it is discarded. For\n        backwards compatability, this parameter defaults to 0, indicating\n        don't ever try to compress.\n        '''\n        return self._set(\"cas\", key, val, time, min_compress_len)", "response": "Sets a key to a given value in the memcache if it hasn t been altered since last fetched."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _map_and_prefix_keys(self, key_iterable, key_prefix):\n        # Check it just once ...\n        key_extra_len=len(key_prefix)\n        if key_prefix and self.do_check_key:\n            self.check_key(key_prefix)\n\n        # server (_Host) -> list of unprefixed server keys in mapping\n        server_keys = {}\n\n        prefixed_to_orig_key = {}\n        # build up a list for each server of all the keys we want.\n        for orig_key in key_iterable:\n            if isinstance(orig_key, tuple):\n                # Tuple of hashvalue, key ala _get_server(). Caller is essentially telling us what server to stuff this on.\n                # Ensure call to _get_server gets a Tuple as well.\n                str_orig_key = str(orig_key[1])\n                server, key = self._get_server((orig_key[0], key_prefix + str_orig_key)) # Gotta pre-mangle key before hashing to a server. Returns the mangled key.\n            else:\n                str_orig_key = str(orig_key) # set_multi supports int / long keys.\n                server, key = self._get_server(key_prefix + str_orig_key)\n\n            # Now check to make sure key length is proper ...\n            if self.do_check_key:\n                self.check_key(str_orig_key, key_extra_len=key_extra_len)\n\n            if not server:\n                continue\n\n            if server not in server_keys:\n                server_keys[server] = []\n            server_keys[server].append(key)\n            prefixed_to_orig_key[key] = orig_key\n\n        return (server_keys, prefixed_to_orig_key)", "response": "Map the keys to stuff onto that server and prefix the keys to the original key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_multi(self, mapping, time=0, key_prefix='', min_compress_len=0):\n        '''\n        Sets multiple keys in the memcache doing just one query.\n\n        >>> notset_keys = mc.set_multi({'key1' : 'val1', 'key2' : 'val2'})\n        >>> mc.get_multi(['key1', 'key2']) == {'key1' : 'val1', 'key2' : 'val2'}\n        1\n\n\n        This method is recommended over regular L{set} as it lowers the\n        number of total packets flying around your network, reducing\n        total latency, since your app doesn't have to wait for each\n        round-trip of L{set} before sending the next one.\n\n        @param mapping: A dict of key/value pairs to set.\n        @param time: Tells memcached the time which this value should\n            expire, either as a delta number of seconds, or an absolute\n            unix time-since-the-epoch value. See the memcached protocol\n            docs section \"Storage Commands\" for more info on <exptime>. We\n            default to 0 == cache forever.\n        @param key_prefix:  Optional string to prepend to each key when\n            sending to memcache. Allows you to efficiently stuff these\n            keys into a pseudo-namespace in memcache:\n\n            >>> notset_keys = mc.set_multi(\n            ...     {'key1' : 'val1', 'key2' : 'val2'}, key_prefix='subspace_')\n            >>> len(notset_keys) == 0\n            True\n            >>> mc.get_multi(['subspace_key1', 'subspace_key2']) == {'subspace_key1' : 'val1', 'subspace_key2' : 'val2'}\n            True\n\n            Causes key 'subspace_key1' and 'subspace_key2' to be\n            set. Useful in conjunction with a higher-level layer which\n            applies namespaces to data in memcache.  In this case, the\n            return result would be the list of notset original keys,\n            prefix not applied.\n\n        @param min_compress_len: The threshold length to kick in\n            auto-compression of the value using the zlib.compress()\n            routine. If the value being cached is a string, then\n            the length of the string is measured, else if the value\n            is an object, then the length of the pickle result is\n            measured. If the resulting attempt at compression yeilds\n            a larger string than the input, then it is discarded. For\n            backwards compatability, this parameter defaults to 0,\n            indicating don't ever try to compress.\n        @return: List of keys which failed to be stored [ memcache out of\n           memory, etc. ].\n        @rtype: list\n\n        '''\n\n        self._statlog('set_multi')\n\n        server_keys, prefixed_to_orig_key = self._map_and_prefix_keys(\n                mapping.iterkeys(), key_prefix)\n\n        # send out all requests on each server before reading anything\n        dead_servers = []\n        notstored = [] # original keys.\n\n        for server in server_keys.iterkeys():\n            bigcmd = []\n            write = bigcmd.append\n            try:\n                for key in server_keys[server]: # These are mangled keys\n                    store_info = self._val_to_store_info(\n                            mapping[prefixed_to_orig_key[key]],\n                            min_compress_len)\n                    if store_info:\n                        write(\"set %s %d %d %d\\r\\n%s\\r\\n\" % (key, store_info[0],\n                                time, store_info[1], store_info[2]))\n                    else:\n                        notstored.append(prefixed_to_orig_key[key])\n                server.send_cmds(''.join(bigcmd))\n            except socket.error, msg:\n                if isinstance(msg, tuple): msg = msg[1]\n                server.mark_dead(msg)\n                dead_servers.append(server)\n\n        # if any servers died on the way, don't expect them to respond.\n        for server in dead_servers:\n            del server_keys[server]\n\n        #  short-circuit if there are no servers, just return all keys\n        if not server_keys: return(mapping.keys())\n\n        for server, keys in server_keys.iteritems():\n            try:\n                for key in keys:\n                    if server.readline() == 'STORED':\n                        continue\n                    else:\n                        notstored.append(prefixed_to_orig_key[key]) #un-mangle.\n            except (_Error, socket.error), msg:\n                if isinstance(msg, tuple): msg = msg[1]\n                server.mark_dead(msg)\n        return notstored", "response": "Set multiple keys in memcached using a single request."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms val to a storable representation returning a tuple of the flags length and the new value.", "response": "def _val_to_store_info(self, val, min_compress_len):\n        \"\"\"\n           Transform val to a storable representation, returning a tuple of the flags, the length of the new value, and the new value itself.\n        \"\"\"\n        flags = 0\n        if isinstance(val, str):\n            pass\n        elif isinstance(val, int):\n            flags |= Client._FLAG_INTEGER\n            val = \"%d\" % val\n            # force no attempt to compress this silly string.\n            min_compress_len = 0\n        elif isinstance(val, long):\n            flags |= Client._FLAG_LONG\n            val = \"%d\" % val\n            # force no attempt to compress this silly string.\n            min_compress_len = 0\n        else:\n            flags |= Client._FLAG_PICKLE\n            file = StringIO()\n            if self.picklerIsKeyword:\n                pickler = self.pickler(file, protocol = self.pickleProtocol)\n            else:\n                pickler = self.pickler(file, self.pickleProtocol)\n            if self.persistent_id:\n                pickler.persistent_id = self.persistent_id\n            pickler.dump(val)\n            val = file.getvalue()\n\n        lv = len(val)\n        # We should try to compress if min_compress_len > 0 and we could\n        # import zlib and this string is longer than our min threshold.\n        if min_compress_len and _supports_compress and lv > min_compress_len:\n            comp_val = compress(val)\n            # Only retain the result if the compression result is smaller\n            # than the original.\n            if len(comp_val) < lv:\n                flags |= Client._FLAG_COMPRESSED\n                val = comp_val\n\n        #  silently do not store if value length exceeds maximum\n        if self.server_max_value_length != 0 and \\\n           len(val) > self.server_max_value_length: return(0)\n\n        return (flags, len(val), val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves multiple keys from the memcache doing just one query. >>> success = mc.set(\"foo\", \"bar\") >>> success = mc.set(\"baz\", 42) >>> mc.get_multi([\"foo\", \"baz\", \"foobar\"]) == {\"foo\": \"bar\", \"baz\": 42} 1 >>> mc.set_multi({'k1' : 1, 'k2' : 2}, key_prefix='pfx_') == [] 1 This looks up keys 'pfx_k1', 'pfx_k2', ... . Returned dict will just have unprefixed keys 'k1', 'k2'. >>> mc.get_multi(['k1', 'k2', 'nonexist'], key_prefix='pfx_') == {'k1' : 1, 'k2' : 2} 1 get_mult [ and L{set_multi} ] can take str()-ables like ints / longs as keys too. Such as your db pri key fields. They're rotored through str() before being passed off to memcache, with or without the use of a key_prefix. In this mode, the key_prefix could be a table name, and the key itself a db primary key number. >>> mc.set_multi({42: 'douglass adams', 46 : 'and 2 just ahead of me'}, key_prefix='numkeys_') == [] 1 >>> mc.get_multi([46, 42], key_prefix='numkeys_') == {42: 'douglass adams', 46 : 'and 2 just ahead of me'} 1 This method is recommended over regular L{get} as it lowers the number of total packets flying around your network, reducing total latency, since your app doesn't have to wait for each round-trip of L{get} before sending the next one. See also L{set_multi}. @param keys: An array of keys. @param key_prefix: A string to prefix each key when we communicate with memcache. Facilitates pseudo-namespaces within memcache. Returned dictionary keys will not have this prefix. @return: A dictionary of key/value pairs that were available. If key_prefix was provided, the keys in the retured dictionary will not have it present.", "response": "def get_multi(self, keys, key_prefix=''):\n        '''\n        Retrieves multiple keys from the memcache doing just one query.\n\n        >>> success = mc.set(\"foo\", \"bar\")\n        >>> success = mc.set(\"baz\", 42)\n        >>> mc.get_multi([\"foo\", \"baz\", \"foobar\"]) == {\"foo\": \"bar\", \"baz\": 42}\n        1\n        >>> mc.set_multi({'k1' : 1, 'k2' : 2}, key_prefix='pfx_') == []\n        1\n\n        This looks up keys 'pfx_k1', 'pfx_k2', ... . Returned dict will just have unprefixed keys 'k1', 'k2'.\n        >>> mc.get_multi(['k1', 'k2', 'nonexist'], key_prefix='pfx_') == {'k1' : 1, 'k2' : 2}\n        1\n\n        get_mult [ and L{set_multi} ] can take str()-ables like ints / longs as keys too. Such as your db pri key fields.\n        They're rotored through str() before being passed off to memcache, with or without the use of a key_prefix.\n        In this mode, the key_prefix could be a table name, and the key itself a db primary key number.\n\n        >>> mc.set_multi({42: 'douglass adams', 46 : 'and 2 just ahead of me'}, key_prefix='numkeys_') == []\n        1\n        >>> mc.get_multi([46, 42], key_prefix='numkeys_') == {42: 'douglass adams', 46 : 'and 2 just ahead of me'}\n        1\n\n        This method is recommended over regular L{get} as it lowers the number of\n        total packets flying around your network, reducing total latency, since\n        your app doesn't have to wait for each round-trip of L{get} before sending\n        the next one.\n\n        See also L{set_multi}.\n\n        @param keys: An array of keys.\n        @param key_prefix: A string to prefix each key when we communicate with memcache.\n            Facilitates pseudo-namespaces within memcache. Returned dictionary keys will not have this prefix.\n        @return:  A dictionary of key/value pairs that were available. If key_prefix was provided, the keys in the retured dictionary will not have it present.\n\n        '''\n\n        self._statlog('get_multi')\n\n        server_keys, prefixed_to_orig_key = self._map_and_prefix_keys(keys, key_prefix)\n\n        # send out all requests on each server before reading anything\n        dead_servers = []\n        for server in server_keys.iterkeys():\n            try:\n                server.send_cmd(\"get %s\" % \" \".join(server_keys[server]))\n            except socket.error, msg:\n                if isinstance(msg, tuple): msg = msg[1]\n                server.mark_dead(msg)\n                dead_servers.append(server)\n\n        # if any servers died on the way, don't expect them to respond.\n        for server in dead_servers:\n            del server_keys[server]\n\n        retvals = {}\n        for server in server_keys.iterkeys():\n            try:\n                line = server.readline()\n                while line and line != 'END':\n                    rkey, flags, rlen = self._expectvalue(server, line)\n                    #  Bo Yang reports that this can sometimes be None\n                    if rkey is not None:\n                        val = self._recv_value(server, flags, rlen)\n                        retvals[prefixed_to_orig_key[rkey]] = val   # un-prefix returned key.\n                    line = server.readline()\n            except (_Error, socket.error), msg:\n                if isinstance(msg, tuple): msg = msg[1]\n                server.mark_dead(msg)\n        return retvals"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck sanity of key.", "response": "def check_key(self, key, key_extra_len=0):\n        \"\"\"Checks sanity of key.  Fails if:\n            Key length is > SERVER_MAX_KEY_LENGTH (Raises MemcachedKeyLength).\n            Contains control characters  (Raises MemcachedKeyCharacterError).\n            Is not a string (Raises MemcachedStringEncodingError)\n            Is an unicode string (Raises MemcachedStringEncodingError)\n            Is not a string (Raises MemcachedKeyError)\n            Is None (Raises MemcachedKeyError)\n        \"\"\"\n        if isinstance(key, tuple): key = key[1]\n        if not key:\n            raise Client.MemcachedKeyNoneError(\"Key is None\")\n        if isinstance(key, unicode):\n            raise Client.MemcachedStringEncodingError(\n                    \"Keys must be str()'s, not unicode.  Convert your unicode \"\n                    \"strings using mystring.encode(charset)!\")\n        if not isinstance(key, str):\n            raise Client.MemcachedKeyTypeError(\"Key must be str()'s\")\n\n        if isinstance(key, basestring):\n            if self.server_max_key_length != 0 and \\\n                len(key) + key_extra_len > self.server_max_key_length:\n                raise Client.MemcachedKeyLengthError(\"Key length is > %s\"\n                         % self.server_max_key_length)\n            if not valid_key_chars_re.match(key):\n                raise Client.MemcachedKeyCharacterError(\n                        \"Control characters not allowed\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readline(self, raise_exception=False):\n        buf = self.buffer\n        if self.socket:\n            recv = self.socket.recv\n        else:\n            recv = lambda bufsize: ''\n\n        while True:\n            index = buf.find('\\r\\n')\n            if index >= 0:\n                break\n            data = recv(4096)\n            if not data:\n                # connection close, let's kill it and raise\n                self.mark_dead('connection closed in readline()')\n                if raise_exception:\n                    raise _ConnectionDeadError()\n                else:\n                    return ''\n\n            buf += data\n        self.buffer = buf[index+2:]\n        return buf[:index]", "response": "Read a line and return it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a standalone in - memory repository.", "response": "def create_repository(cls, repository_data):\n        \"\"\"Create a standalone, in-memory repository.\n\n        Using this function bypasses the `package_repository_manager` singleton.\n        This is usually desired however, since in-memory repositories are for\n        temporarily storing programmatically created packages, which we do not\n        want to cache and that do not persist.\n\n        Args:\n            repository_data (dict): Repository data, see class docstring.\n\n        Returns:\n            `MemoryPackageRepository` object.\n        \"\"\"\n        location = \"memory{%s}\" % hex(id(repository_data))\n        resource_pool = ResourcePool(cache_size=None)\n        repo = MemoryPackageRepository(location, resource_pool)\n        repo.data = repository_data\n        return repo"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _best_version(fields):\n    def _has_marker(keys, markers):\n        for marker in markers:\n            if marker in keys:\n                return True\n        return False\n\n    keys = []\n    for key, value in fields.items():\n        if value in ([], 'UNKNOWN', None):\n            continue\n        keys.append(key)\n\n    possible_versions = ['1.0', '1.1', '1.2', '2.0']\n\n    # first let's try to see if a field is not part of one of the version\n    for key in keys:\n        if key not in _241_FIELDS and '1.0' in possible_versions:\n            possible_versions.remove('1.0')\n        if key not in _314_FIELDS and '1.1' in possible_versions:\n            possible_versions.remove('1.1')\n        if key not in _345_FIELDS and '1.2' in possible_versions:\n            possible_versions.remove('1.2')\n        if key not in _426_FIELDS and '2.0' in possible_versions:\n            possible_versions.remove('2.0')\n\n    # possible_version contains qualified versions\n    if len(possible_versions) == 1:\n        return possible_versions[0]   # found !\n    elif len(possible_versions) == 0:\n        raise MetadataConflictError('Unknown metadata set')\n\n    # let's see if one unique marker is found\n    is_1_1 = '1.1' in possible_versions and _has_marker(keys, _314_MARKERS)\n    is_1_2 = '1.2' in possible_versions and _has_marker(keys, _345_MARKERS)\n    is_2_0 = '2.0' in possible_versions and _has_marker(keys, _426_MARKERS)\n    if int(is_1_1) + int(is_1_2) + int(is_2_0) > 1:\n        raise MetadataConflictError('You used incompatible 1.1/1.2/2.0 fields')\n\n    # we have the choice, 1.0, or 1.2, or 2.0\n    #   - 1.0 has a broken Summary field but works with all tools\n    #   - 1.1 is to avoid\n    #   - 1.2 fixes Summary but has little adoption\n    #   - 2.0 adds more features and is very new\n    if not is_1_1 and not is_1_2 and not is_2_0:\n        # we couldn't find any specific marker\n        if PKG_INFO_PREFERRED_VERSION in possible_versions:\n            return PKG_INFO_PREFERRED_VERSION\n    if is_1_1:\n        return '1.1'\n    if is_1_2:\n        return '1.2'\n\n    return '2.0'", "response": "Detect the best version depending on the fields used."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the metadata values from a file object.", "response": "def read_file(self, fileob):\n        \"\"\"Read the metadata values from a file object.\"\"\"\n        msg = message_from_file(fileob)\n        self._fields['Metadata-Version'] = msg['metadata-version']\n\n        # When reading, get all the fields we can\n        for field in _ALL_FIELDS:\n            if field not in msg:\n                continue\n            if field in _LISTFIELDS:\n                # we can have multiple lines\n                values = msg.get_all(field)\n                if field in _LISTTUPLEFIELDS and values is not None:\n                    values = [tuple(value.split(',')) for value in values]\n                self.set(field, values)\n            else:\n                # single line\n                value = msg[field]\n                if value is not None and value != 'UNKNOWN':\n                    self.set(field, value)\n        self.set_metadata_version()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the metadata is compliant.", "response": "def check(self, strict=False):\n        \"\"\"Check if the metadata is compliant. If strict is True then raise if\n        no Name or Version are provided\"\"\"\n        self.set_metadata_version()\n\n        # XXX should check the versions (if the file was loaded)\n        missing, warnings = [], []\n\n        for attr in ('Name', 'Version'):  # required by PEP 345\n            if attr not in self:\n                missing.append(attr)\n\n        if strict and missing != []:\n            msg = 'missing required metadata: %s' % ', '.join(missing)\n            raise MetadataMissingError(msg)\n\n        for attr in ('Home-page', 'Author'):\n            if attr not in self:\n                missing.append(attr)\n\n        # checking metadata 1.2 (XXX needs to check 1.1, 1.0)\n        if self['Metadata-Version'] != '1.2':\n            return missing, warnings\n\n        scheme = get_scheme(self.scheme)\n\n        def are_valid_constraints(value):\n            for v in value:\n                if not scheme.is_valid_matcher(v.split(';')[0]):\n                    return False\n            return True\n\n        for fields, controller in ((_PREDICATE_FIELDS, are_valid_constraints),\n                                   (_VERSIONS_FIELDS,\n                                    scheme.is_valid_constraint_list),\n                                   (_VERSION_FIELDS,\n                                    scheme.is_valid_version)):\n            for field in fields:\n                value = self.get(field, None)\n                if value is not None and not controller(value):\n                    warnings.append('Wrong value for %r: %s' % (field, value))\n\n        return missing, warnings"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_pane(widgets, horizontal, parent_widget=None, compact=False,\n                compact_spacing=2):\n    \"\"\"Create a widget containing an aligned set of widgets.\n\n    Args:\n        widgets (list of `QWidget`).\n        horizontal (bool).\n        align (str): One of:\n            - 'left', 'right' (horizontal);\n            - 'top', 'bottom' (vertical)\n        parent_widget (`QWidget`): Owner widget, QWidget is created if this\n            is not provided.\n\n    Returns:\n        `QWidget`\n    \"\"\"\n    pane = parent_widget or QtGui.QWidget()\n    type_ = QtGui.QHBoxLayout if horizontal else QtGui.QVBoxLayout\n    layout = type_()\n    if compact:\n        layout.setSpacing(compact_spacing)\n        layout.setContentsMargins(compact_spacing, compact_spacing,\n                                  compact_spacing, compact_spacing)\n\n    for widget in widgets:\n        stretch = 0\n        if isinstance(widget, tuple):\n            widget, stretch = widget\n\n        if isinstance(widget, int):\n            layout.addSpacing(widget)\n        elif widget:\n            layout.addWidget(widget, stretch)\n        else:\n            layout.addStretch()\n\n    pane.setLayout(layout)\n    return pane", "response": "Create a new pane containing a list of widgets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_icon(name, as_qicon=False):\n    filename = name + \".png\"\n    icon = icons.get(filename)\n    if not icon:\n        path = os.path.dirname(__file__)\n        path = os.path.join(path, \"icons\")\n        filepath = os.path.join(path, filename)\n        if not os.path.exists(filepath):\n            filepath = os.path.join(path, \"pink.png\")\n\n        icon = QtGui.QPixmap(filepath)\n        icons[filename] = icon\n\n    return QtGui.QIcon(icon) if as_qicon else icon", "response": "Returns a QPixmap containing the given image or a QIcon if as_qicon is True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interp_color(a, b, f):\n    a_ = (a.redF(), a.greenF(), a.blueF())\n    b_ = (b.redF(), b.greenF(), b.blueF())\n    a_ = [x * (1 - f) for x in a_]\n    b_ = [x * f for x in b_]\n    c = [x + y for x, y in zip(a_, b_)]\n    return QtGui.QColor.fromRgbF(*c)", "response": "Interpolate between two colors."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a toolbutton. Args: entries: List of (label, slot) tuples. Returns: `QtGui.QToolBar`.", "response": "def create_toolbutton(entries, parent=None):\n    \"\"\"Create a toolbutton.\n\n    Args:\n        entries: List of (label, slot) tuples.\n\n    Returns:\n        `QtGui.QToolBar`.\n    \"\"\"\n    btn = QtGui.QToolButton(parent)\n    menu = QtGui.QMenu()\n    actions = []\n\n    for label, slot in entries:\n        action = add_menu_action(menu, label, slot)\n        actions.append(action)\n\n    btn.setPopupMode(QtGui.QToolButton.MenuButtonPopup)\n    btn.setDefaultAction(actions[0])\n    btn.setMenu(menu)\n    return btn, actions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_distribution_names(url=None):\n    if url is None:\n        url = DEFAULT_INDEX\n    client = ServerProxy(url, timeout=3.0)\n    return client.list_packages()", "response": "Return all distribution names known by an index."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a dictionary with a dictionary for a specific version of an anatomical class.", "response": "def _update_version_data(self, result, info):\n        \"\"\"\n        Update a result dictionary (the final result from _get_project) with a dictionary for a\n        specific version, whih typically holds information gleaned from a filename or URL for an\n        archive for the distribution.\n        \"\"\"\n        name = info.pop('name')\n        version = info.pop('version')\n        if version in result:\n            dist = result[version]\n            md = dist.metadata\n        else:\n            dist = make_dist(name, version, scheme=self.scheme)\n            md = dist.metadata\n        dist.digest = self._get_digest(info)\n        if md.source_url != info['url']:\n            md.source_url = self.prefer_url(md.source_url, info['url'])\n        dist.locator = self\n        result[version] = dist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching the URL to fetch from the work queue and process the links for download and further scraping.", "response": "def _fetch(self):\n        \"\"\"\n        Get a URL to fetch from the work queue, get the HTML page, examine its\n        links for download candidates and candidates for further scraping.\n\n        This is a handy method to run in a thread.\n        \"\"\"\n        while True:\n            url = self._to_fetch.get()\n            try:\n                if url:\n                    page = self.get_page(url)\n                    if page is None:    # e.g. after an error\n                        continue\n                    for link, rel in page.links:\n                        if link not in self._seen:\n                            self._seen.add(link)\n                            if (not self._process_download(link) and\n                                self._should_queue(link, url, rel)):\n                                logger.debug('Queueing %s from %s', link, url)\n                                self._to_fetch.put(link)\n            finally:\n                # always do this, to avoid hangs :-)\n                self._to_fetch.task_done()\n            if not url:\n                #logger.debug('Sentinel seen, quitting.')\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the HTML for a URL possibly from an in - memory cache.", "response": "def get_page(self, url):\n        \"\"\"\n        Get the HTML for an URL, possibly from an in-memory cache.\n\n        XXX TODO Note: this cache is never actually cleared. It's assumed that\n        the data won't get stale over the lifetime of a locator instance (not\n        necessarily true for the default_locator).\n        \"\"\"\n        # http://peak.telecommunity.com/DevCenter/EasyInstall#package-index-api\n        scheme, netloc, path, _, _, _ = urlparse(url)\n        if scheme == 'file' and os.path.isdir(url2pathname(path)):\n            url = urljoin(ensure_slash(url), 'index.html')\n\n        if url in self._page_cache:\n            result = self._page_cache[url]\n            logger.debug('Returning %s from cache: %s', url, result)\n        else:\n            host = netloc.split(':', 1)[0]\n            result = None\n            if host in self._bad_hosts:\n                logger.debug('Skipping %s due to bad host %s', url, host)\n            else:\n                req = Request(url, headers={'Accept-encoding': 'identity'})\n                try:\n                    logger.debug('Fetching %s', url)\n                    resp = self.opener.open(req, timeout=self.timeout)\n                    logger.debug('Fetched %s', url)\n                    headers = resp.info()\n                    content_type = headers.get('Content-Type', '')\n                    if HTML_CONTENT_TYPE.match(content_type):\n                        final_url = resp.geturl()\n                        data = resp.read()\n                        encoding = headers.get('Content-Encoding')\n                        if encoding:\n                            decoder = self.decoders[encoding]   # fail if not found\n                            data = decoder(data)\n                        encoding = 'utf-8'\n                        m = CHARSET.search(content_type)\n                        if m:\n                            encoding = m.group(1)\n                        try:\n                            data = data.decode(encoding)\n                        except UnicodeError:\n                            data = data.decode('latin-1')    # fallback\n                        result = Page(data, final_url)\n                        self._page_cache[final_url] = result\n                except HTTPError as e:\n                    if e.code != 404:\n                        logger.exception('Fetch failed: %s: %s', url, e)\n                except URLError as e:\n                    logger.exception('Fetch failed: %s: %s', url, e)\n                    with self._lock:\n                        self._bad_hosts.add(host)\n                except Exception as e:\n                    logger.exception('Fetch failed: %s: %s', url, e)\n                finally:\n                    self._page_cache[url] = result   # even if None (failure)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_reverse_dependency_tree(package_name, depth=None, paths=None,\n                                build_requires=False,\n                                private_build_requires=False):\n    \"\"\"Find packages that depend on the given package.\n\n    This is a reverse dependency lookup. A tree is constructed, showing what\n    packages depend on the given package, with an optional depth limit. A\n    resolve does not occur. Only the latest version of each package is used,\n    and requirements from all variants of that package are used.\n\n    Args:\n        package_name (str): Name of the package depended on.\n        depth (int): Tree depth limit, unlimited if None.\n        paths (list of str): paths to search for packages, defaults to\n            `config.packages_path`.\n        build_requires (bool): If True, includes packages' build_requires.\n        private_build_requires (bool): If True, include `package_name`'s\n            private_build_requires.\n\n    Returns:\n        A 2-tuple:\n        - (list of list of str): Lists of package names, where each list is a\n          single depth in the tree. The first list is always [`package_name`].\n        - `pygraph.digraph` object, where nodes are package names, and\n          `package_name` is always the leaf node.\n    \"\"\"\n    pkgs_list = [[package_name]]\n    g = digraph()\n    g.add_node(package_name)\n\n    # build reverse lookup\n    it = iter_package_families(paths)\n    package_names = set(x.name for x in it)\n    if package_name not in package_names:\n        raise PackageFamilyNotFoundError(\"No such package family %r\" % package_name)\n\n    if depth == 0:\n        return pkgs_list, g\n\n    bar = ProgressBar(\"Searching\", len(package_names))\n    lookup = defaultdict(set)\n\n    for i, package_name_ in enumerate(package_names):\n        it = iter_packages(name=package_name_, paths=paths)\n        packages = list(it)\n        if not packages:\n            continue\n\n        pkg = max(packages, key=lambda x: x.version)\n        requires = []\n\n        for variant in pkg.iter_variants():\n            pbr = (private_build_requires and pkg.name == package_name)\n\n            requires += variant.get_requires(\n                build_requires=build_requires,\n                private_build_requires=pbr\n            )\n\n        for req in requires:\n            if not req.conflict:\n                lookup[req.name].add(package_name_)\n\n        bar.next()\n\n    bar.finish()\n\n    # perform traversal\n    n = 0\n    consumed = set([package_name])\n    working_set = set([package_name])\n\n    node_color = \"#F6F6F6\"\n    node_fontsize = 10\n    node_attrs = [(\"fillcolor\", node_color),\n                  (\"style\", \"filled\"),\n                  (\"fontsize\", node_fontsize)]\n\n    while working_set and (depth is None or n < depth):\n        working_set_ = set()\n\n        for child in working_set:\n            parents = lookup[child] - consumed\n            working_set_.update(parents)\n            consumed.update(parents)\n\n            for parent in parents:\n                g.add_node(parent, attrs=node_attrs)\n                g.add_edge((parent, child))\n\n        if working_set_:\n            pkgs_list.append(sorted(list(working_set_)))\n\n        working_set = working_set_\n        n += 1\n\n    return pkgs_list, g", "response": "This function returns a tree of packages that depend on the given package."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_plugins(package_name, paths=None):\n    pkg = get_latest_package(package_name, paths=paths, error=True)\n    if not pkg.has_plugins:\n        return []\n\n    it = iter_package_families(paths)\n    package_names = set(x.name for x in it)\n    bar = ProgressBar(\"Searching\", len(package_names))\n\n    plugin_pkgs = []\n    for package_name_ in package_names:\n        bar.next()\n        if package_name_ == package_name:\n            continue  # not a plugin of itself\n\n        plugin_pkg = get_latest_package(package_name_, paths=paths)\n        if not plugin_pkg.plugin_for:\n            continue\n        for plugin_for in plugin_pkg.plugin_for:\n            if plugin_for == pkg.name:\n                plugin_pkgs.append(package_name_)\n\n    bar.finish()\n    return plugin_pkgs", "response": "Returns a list of packages that are plugins of the given package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search(self, resources_request=None):\n\n        # Find matching package families\n        name_pattern, version_range = self._parse_request(resources_request)\n\n        family_names = set(\n            x.name for x in iter_package_families(paths=self.package_paths)\n            if fnmatch.fnmatch(x.name, name_pattern)\n        )\n\n        family_names = sorted(family_names)\n\n        # determine what type of resource we're searching for\n        if self.resource_type:\n            resource_type = self.resource_type\n        elif version_range or len(family_names) == 1:\n            resource_type = \"package\"\n        else:\n            resource_type = \"family\"\n\n        if not family_names:\n            return resource_type, []\n\n        # return list of family names (validation is n/a in this case)\n        if resource_type == \"family\":\n            results = [ResourceSearchResult(x, \"family\") for x in family_names]\n            return \"family\", results\n\n        results = []\n\n        # iterate over packages/variants\n        for name in family_names:\n            it = iter_packages(name, version_range, paths=self.package_paths)\n            packages = sorted(it, key=lambda x: x.version)\n\n            if self.latest and packages:\n                packages = [packages[-1]]\n\n            for package in packages:\n                # validate and check time (accessing timestamp may cause\n                # validation fail)\n                try:\n                    if package.timestamp:\n                        if self.after_time and package.timestamp < self.after_time:\n                            continue\n                        if self.before_time and package.timestamp >= self.before_time:\n                            continue\n\n                    if self.validate:\n                        package.validate_data()\n\n                except ResourceContentError as e:\n                    if resource_type == \"package\":\n                        result = ResourceSearchResult(package, \"package\", str(e))\n                        results.append(result)\n\n                    continue\n\n                if resource_type == \"package\":\n                    result = ResourceSearchResult(package, \"package\")\n                    results.append(result)\n                    continue\n\n                # iterate variants\n                try:\n                    for variant in package.iter_variants():\n                        if self.validate:\n                            try:\n                                variant.validate_data()\n                            except ResourceContentError as e:\n                                result = ResourceSearchResult(\n                                    variant, \"variant\", str(e))\n                                results.append(result)\n                                continue\n\n                        result = ResourceSearchResult(variant, \"variant\")\n                        results.append(result)\n\n                except ResourceContentError:\n                    # this may happen if 'variants' in package is malformed\n                    continue\n\n        return resource_type, results", "response": "Search for resources in the specified list of resources_request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_search_results(self, search_results, buf=sys.stdout):\n        formatted_lines = self.format_search_results(search_results)\n        pr = Printer(buf)\n\n        for txt, style in formatted_lines:\n            pr(txt, style)", "response": "Print formatted search results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat search results. Args: search_results (list of `ResourceSearchResult`): Search to format. Returns: List of 2-tuple: Text and color to print in.", "response": "def format_search_results(self, search_results):\n        \"\"\"Format search results.\n\n        Args:\n            search_results (list of `ResourceSearchResult`): Search to format.\n\n        Returns:\n            List of 2-tuple: Text and color to print in.\n        \"\"\"\n        formatted_lines = []\n\n        for search_result in search_results:\n            lines = self._format_search_result(search_result)\n            formatted_lines.extend(lines)\n\n        return formatted_lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a graph from a string in Dot language and returns it.", "response": "def read(string):\n    \"\"\"\n    Read a graph from a string in Dot language and return it. Nodes and edges specified in the\n    input will be added to the current graph.\n    \n    @type  string: string\n    @param string: Input string in Dot format specifying a graph.\n    \n    @rtype: graph\n    @return: Graph\n    \"\"\"\n    \n    dotG = pydot.graph_from_dot_data(string)\n    \n    if (dotG.get_type() == \"graph\"):\n        G = graph()\n    elif (dotG.get_type() == \"digraph\"):\n        G = digraph()\n    elif (dotG.get_type() == \"hypergraph\"):\n        return read_hypergraph(string)\n    else:\n        raise InvalidGraphType\n    \n    # Read nodes...\n    # Note: If the nodes aren't explicitly listed, they need to be\n    for each_node in dotG.get_nodes():\n        G.add_node(each_node.get_name())\n        for each_attr_key, each_attr_val in each_node.get_attributes().items():\n            G.add_node_attribute(each_node.get_name(), (each_attr_key, each_attr_val))\n    \n    # Read edges...\n    for each_edge in dotG.get_edges():\n        # Check if the nodes have been added\n        if not G.has_node(each_edge.get_source()):\n            G.add_node(each_edge.get_source())\n        if not G.has_node(each_edge.get_destination()):\n            G.add_node(each_edge.get_destination())\n        \n        # See if there's a weight\n        if 'weight' in each_edge.get_attributes().keys():\n            _wt = each_edge.get_attributes()['weight']\n        else:\n            _wt = 1\n        \n        # See if there is a label\n        if 'label' in each_edge.get_attributes().keys():\n            _label = each_edge.get_attributes()['label']\n        else:\n            _label = ''\n        \n        G.add_edge((each_edge.get_source(), each_edge.get_destination()), wt = _wt, label = _label)\n        \n        for each_attr_key, each_attr_val in each_edge.get_attributes().items():\n            if not each_attr_key in ['weight', 'label']:\n                G.add_edge_attribute((each_edge.get_source(), each_edge.get_destination()), \\\n                                            (each_attr_key, each_attr_val))\n    \n    return G"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(G, weighted=False):\n    dotG = pydot.Dot()\n    \n    if not 'name' in dir(G):\n        dotG.set_name('graphname')\n    else:\n        dotG.set_name(G.name)\n    \n    if (isinstance(G, graph)):\n        dotG.set_type('graph')\n        directed = False\n    elif (isinstance(G, digraph)):\n        dotG.set_type('digraph')\n        directed = True\n    elif (isinstance(G, hypergraph)):\n        return write_hypergraph(G)\n    else:\n        raise InvalidGraphType(\"Expected graph or digraph, got %s\" %  repr(G) )\n    \n    for node in G.nodes():\n        attr_list = {}\n        for attr in G.node_attributes(node):\n            attr_list[str(attr[0])] = str(attr[1])\n        \n        newNode = pydot.Node(str(node), **attr_list)\n        \n        dotG.add_node(newNode)\n        \n    # Pydot doesn't work properly with the get_edge, so we use\n    #  our own set to keep track of what's been added or not.\n    seen_edges = set([])\n    for edge_from, edge_to in G.edges():\n        if (str(edge_from) + \"-\" + str(edge_to)) in seen_edges:\n            continue\n\n        if (not directed) and (str(edge_to) + \"-\" + str(edge_from)) in seen_edges:\n            continue\n        \n        attr_list = {}\n        for attr in G.edge_attributes((edge_from, edge_to)):\n            attr_list[str(attr[0])] = str(attr[1])\n        \n        if str(G.edge_label((edge_from, edge_to))):\n            attr_list['label'] = str(G.edge_label((edge_from, edge_to)))\n\n        elif weighted:\n            attr_list['label'] = str(G.edge_weight((edge_from, edge_to)))\n        \n        if weighted:\n            attr_list['weight'] = str(G.edge_weight((edge_from, edge_to)))\n        \n        newEdge = pydot.Edge(str(edge_from), str(edge_to), **attr_list)\n        \n        dotG.add_edge(newEdge)\n        \n        seen_edges.add(str(edge_from) + \"-\" + str(edge_to))\n        \n    return dotG.to_string()", "response": "Returns a string representation of the given graph in Dot Language."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a hypergraph from a string in dot format.", "response": "def read_hypergraph(string):\n    \"\"\"\n    Read a hypergraph from a string in dot format. Nodes and edges specified in the input will be\n    added to the current hypergraph.\n    \n    @type  string: string\n    @param string: Input string in dot format specifying a graph.\n    \n    @rtype:  hypergraph\n    @return: Hypergraph\n    \"\"\"\n    hgr = hypergraph()\n    dotG = pydot.graph_from_dot_data(string)\n    \n    # Read the hypernode nodes...\n    # Note 1: We need to assume that all of the nodes are listed since we need to know if they\n    #           are a hyperedge or a normal node\n    # Note 2: We should read in all of the nodes before putting in the links\n    for each_node in dotG.get_nodes():\n        if 'hypernode' == each_node.get('hyper_node_type'):\n            hgr.add_node(each_node.get_name())\n        elif 'hyperedge' == each_node.get('hyper_node_type'):\n            hgr.add_hyperedge(each_node.get_name())\n    \n    # Now read in the links to connect the hyperedges\n    for each_link in dotG.get_edges():\n        if hgr.has_node(each_link.get_source()):\n            link_hypernode = each_link.get_source()\n            link_hyperedge = each_link.get_destination()\n        elif hgr.has_node(each_link.get_destination()):\n            link_hypernode = each_link.get_destination()\n            link_hyperedge = each_link.get_source()\n        hgr.link(link_hypernode, link_hyperedge)\n    \n    return hgr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_hypergraph(hgr, colored = False):\n    dotG = pydot.Dot()\n    \n    if not 'name' in dir(hgr):\n        dotG.set_name('hypergraph')\n    else:\n        dotG.set_name(hgr.name)\n    \n    colortable = {}\n    colorcount = 0\n    \n    # Add all of the nodes first\n    for node in hgr.nodes():\n        newNode = pydot.Node(str(node), hyper_node_type = 'hypernode')\n        \n        dotG.add_node(newNode)\n    \n    for hyperedge in hgr.hyperedges():\n        \n        if (colored):\n            colortable[hyperedge] = colors[colorcount % len(colors)]\n            colorcount += 1\n            \n            newNode = pydot.Node(str(hyperedge), hyper_node_type = 'hyperedge', \\\n                                                 color = str(colortable[hyperedge]), \\\n                                                 shape = 'point')\n        else:\n            newNode = pydot.Node(str(hyperedge), hyper_node_type = 'hyperedge')\n        \n        dotG.add_node(newNode)\n        \n        for link in hgr.links(hyperedge):\n            newEdge = pydot.Edge(str(hyperedge), str(link))\n            dotG.add_edge(newEdge)\n    \n    return dotG.to_string()", "response": "Returns a string representation of the given hypergraph in DOT Language."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether a string is solely composed of a dot language ID.", "response": "def needs_quotes( s ):\n    \"\"\"Checks whether a string is a dot language ID.\n    \n    It will check whether the string is solely composed\n    by the characters allowed in an ID or not.\n    If the string is one of the reserved keywords it will\n    need quotes too but the user will need to add them\n    manually.\n    \"\"\"\n    \n    # If the name is a reserved keyword it will need quotes but pydot\n    # can't tell when it's being used as a keyword or when it's simply\n    # a name. Hence the user needs to supply the quotes when an element\n    # would use a reserved keyword as name. This function will return\n    # false indicating that a keyword string, if provided as-is, won't\n    # need quotes.\n    if s in dot_keywords:\n        return False\n\n    chars = [ord(c) for c in s if ord(c)>0x7f or ord(c)==0]\n    if chars and not id_re_dbl_quoted.match(s) and not id_re_html.match(s):\n        return True\n        \n    for test_re in [id_re_alpha_nums, id_re_num, id_re_dbl_quoted, id_re_html, id_re_alpha_nums_with_ports]:\n        if test_re.match(s):\n            return False\n\n    m = id_re_with_port.match(s)\n    if m:\n        return needs_quotes(m.group(1)) or needs_quotes(m.group(2))\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a graph from a DOT file.", "response": "def graph_from_dot_file(path):\n    \"\"\"Load graph as defined by a DOT file.\n    \n    The file is assumed to be in DOT format. It will\n    be loaded, parsed and a Dot class will be returned, \n    representing the graph.\n    \"\"\"\n    \n    fd = file(path, 'rb')\n    data = fd.read()\n    fd.close()\n    \n    return graph_from_dot_data(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a basic graph out of an edge list.", "response": "def graph_from_edges(edge_list, node_prefix='', directed=False):\n    \"\"\"Creates a basic graph out of an edge list.\n    \n    The edge list has to be a list of tuples representing\n    the nodes connected by the edge.\n    The values can be anything: bool, int, float, str.\n    \n    If the graph is undirected by default, it is only\n    calculated from one of the symmetric halves of the matrix.\n    \"\"\"\n    \n    if directed:\n        graph = Dot(graph_type='digraph')\n        \n    else:\n        graph = Dot(graph_type='graph')\n        \n    for edge in edge_list:\n        \n        if isinstance(edge[0], str):\n            src = node_prefix + edge[0]\n        else:\n            src = node_prefix + str(edge[0])\n            \n        if isinstance(edge[1], str):\n            dst = node_prefix + edge[1]\n        else:\n            dst = node_prefix + str(edge[1])\n\n        e = Edge( src, dst )\n        graph.add_edge(e)\n        \n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __find_executables(path):\n    \n    success = False\n    progs = {'dot': '', 'twopi': '', 'neato': '', 'circo': '', 'fdp': '', 'sfdp': ''}\n    \n    was_quoted = False\n    path = path.strip()\n    if path.startswith('\"') and path.endswith('\"'):\n        path = path[1:-1]\n        was_quoted =  True\n    \n    if os.path.isdir(path) : \n    \n        for prg in progs.iterkeys():\n    \n            if progs[prg]:\n                continue\n               \n            if os.path.exists( os.path.join(path, prg) ):\n                \n                if was_quoted:\n                    progs[prg] = '\"' + os.path.join(path, prg) + '\"'\n                else:\n                    progs[prg] = os.path.join(path, prg)\n                    \n                success = True\n               \n            elif os.path.exists( os.path.join(path, prg + '.exe') ):\n\n                if was_quoted:\n                    progs[prg] = '\"' + os.path.join(path, prg + '.exe') + '\"'\n                else:\n                    progs[prg] = os.path.join(path, prg + '.exe')\n                    \n                success = True\n    \n    if success:\n    \n        return progs\n        \n    else:\n    \n        return None", "response": "Used by find_graphviz\n    \n    path - single directory as a string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_string(self):\n\n        src = self.parse_node_ref( self.get_source() )\n        dst = self.parse_node_ref( self.get_destination() )\n        \n        if isinstance(src, frozendict):\n            edge = [ Subgraph(obj_dict=src).to_string() ]\n        elif isinstance(src, (int, long)):\n            edge = [ str(src) ]\n        else:\n            edge = [ src ]\n        \n        if\t(self.get_parent_graph() and\n            self.get_parent_graph().get_top_graph_type() and\n            self.get_parent_graph().get_top_graph_type() == 'digraph' ):\n\n            edge.append( '->' )\n            \n        else:\n            edge.append( '--' )\n            \n        if isinstance(dst, frozendict):\n            edge.append( Subgraph(obj_dict=dst).to_string() )\n        elif isinstance(dst, (int, long)):\n            edge.append( str(dst) )\n        else:\n            edge.append( dst )\n\n\n        edge_attr = list()\n        \n        for attr, value in self.obj_dict['attributes'].iteritems():\n        \n            if value is not None:\n                edge_attr.append( '%s=%s' % (attr, quote_if_necessary(value) ) )\n            else:\n                edge_attr.append( attr )\n\n        edge_attr = ', '.join(edge_attr)\n        \n        if edge_attr:\n            edge.append( ' [' + edge_attr + ']' )\n\n        return ' '.join(edge) + ';'", "response": "Returns a string representation of the edge in dot language."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_node(self, name):\n        \n        match = list()\n        \n        if self.obj_dict['nodes'].has_key(name):\n        \n            match.extend( [ Node( obj_dict = obj_dict ) for obj_dict in self.obj_dict['nodes'][name] ])\n        \n        return match", "response": "Retrieve a node from the graph. Given a node s name the corresponding Node\n        instance will be returned."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_edge(self, graph_edge):\n\n        if not isinstance(graph_edge, Edge):\n            raise TypeError('add_edge() received a non edge class object: ' + str(graph_edge))\n\n        edge_points = ( graph_edge.get_source(), graph_edge.get_destination() )\n\n        if self.obj_dict['edges'].has_key(edge_points):\n\n            edge_list = self.obj_dict['edges'][edge_points]\n            edge_list.append(graph_edge.obj_dict)\n\n        else:\n\n            self.obj_dict['edges'][edge_points] = [ graph_edge.obj_dict ]\n\n\n        graph_edge.set_sequence( self.get_next_sequence_number() )\n\n        graph_edge.set_parent_graph( self.get_parent_graph() )", "response": "Adds an edge object to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an subgraph object to the graph.", "response": "def add_subgraph(self, sgraph):\n        \"\"\"Adds an subgraph object to the graph.\n        \n        It takes a subgraph object as its only argument and returns\n        None.\n        \"\"\"\n\n        if not isinstance(sgraph, Subgraph) and not isinstance(sgraph, Cluster):\n            raise TypeError('add_subgraph() received a non subgraph class object:' + str(sgraph))\n            \n        if self.obj_dict['subgraphs'].has_key(sgraph.get_name()):\n        \n            sgraph_list = self.obj_dict['subgraphs'][ sgraph.get_name() ]\n            sgraph_list.append( sgraph.obj_dict )\n                \n        else:\n            self.obj_dict['subgraphs'][ sgraph.get_name() ] = [ sgraph.obj_dict ]\n         \n        sgraph.set_sequence( self.get_next_sequence_number() )\n        \n        sgraph.set_parent_graph( self.get_parent_graph() )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_string(self):\n        \n        \n        graph = list()\n        \n        if self.obj_dict.get('strict', None) is not None:\n        \n            if self==self.get_parent_graph() and self.obj_dict['strict']:\n            \n                graph.append('strict ')\n\n        if self.obj_dict['name'] == '':\n            if 'show_keyword' in self.obj_dict and self.obj_dict['show_keyword']:\n                graph.append( 'subgraph {\\n' )\n            else:\n                graph.append( '{\\n' )\n        else:\n            graph.append( '%s %s {\\n' % (self.obj_dict['type'], self.obj_dict['name']) )\n\n\n        for attr in self.obj_dict['attributes'].iterkeys():\n        \n            if self.obj_dict['attributes'].get(attr, None) is not None:\n       \n                val = self.obj_dict['attributes'].get(attr)\n                if val is not None:\n                    graph.append( '%s=%s' % (attr, quote_if_necessary(val)) )\n                else:\n                    graph.append( attr )\n                    \n                graph.append( ';\\n' )\n\n\n        edges_done = set()\n        \n        edge_obj_dicts = list()\n        for e in self.obj_dict['edges'].itervalues():\n            edge_obj_dicts.extend(e)\n            \n        if edge_obj_dicts:\n            edge_src_set, edge_dst_set = zip( *[obj['points'] for obj in edge_obj_dicts] )\n            edge_src_set, edge_dst_set = set(edge_src_set), set(edge_dst_set)\n        else:\n            edge_src_set, edge_dst_set = set(), set()\n            \n        node_obj_dicts = list()\n        for e in self.obj_dict['nodes'].itervalues():\n            node_obj_dicts.extend(e)\n\n        sgraph_obj_dicts = list()\n        for sg in self.obj_dict['subgraphs'].itervalues():\n            sgraph_obj_dicts.extend(sg)\n\n        \n        obj_list = [ (obj['sequence'], obj) for obj in (edge_obj_dicts + node_obj_dicts + sgraph_obj_dicts) ]\n        obj_list.sort()\n        \n        for idx, obj in obj_list:\n        \n            if obj['type'] == 'node':\n\n                node = Node(obj_dict=obj)\n            \n                if self.obj_dict.get('suppress_disconnected', False):\n                \n                    if (node.get_name() not in edge_src_set and\n                        node.get_name() not in edge_dst_set):\n                        \n                        continue\n                        \n                graph.append( node.to_string()+'\\n' )\n\n            elif obj['type'] == 'edge':\n\n                edge = Edge(obj_dict=obj)\n                \n                if self.obj_dict.get('simplify', False) and edge in edges_done:\n                    continue\n                \n                graph.append( edge.to_string() + '\\n' )\n                edges_done.add(edge)\n                \n            else:\n            \n                sgraph = Subgraph(obj_dict=obj)\n                \n                graph.append( sgraph.to_string()+'\\n' )\n\n        graph.append( '}\\n' )\n        \n        return ''.join(graph)", "response": "Returns a string representation of the object in dot language."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the paths of the required image files to the internal list of image files that are required to be rendered.", "response": "def set_shape_files(self, file_paths):\n        \"\"\"Add the paths of the required image files.\n        \n        If the graph needs graphic objects to be used as shapes or otherwise\n        those need to be in the same folder as the graph is going to be rendered\n        from. Alternatively the absolute path to the files can be specified when\n        including the graphics in the graph.\n        \n        The files in the location pointed to by the path(s) specified as arguments\n        to this method will be copied to the same temporary location where the\n        graph is going to be rendered.\n        \"\"\"\n        \n        if isinstance( file_paths, basestring ):\n            self.shape_files.append( file_paths )\n            \n        if isinstance( file_paths, (list, tuple) ):\n            self.shape_files.extend( file_paths )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a graph to a file.", "response": "def write(self, path, prog=None, format='raw'):\n        \"\"\"Writes a graph to a file.\n\n        Given a filename 'path' it will open/create and truncate\n        such file and write on it a representation of the graph\n        defined by the dot object and in the format specified by\n        'format'.\n        The format 'raw' is used to dump the string representation\n        of the Dot object, without further processing.\n        The output can be processed by any of graphviz tools, defined\n        in 'prog', which defaults to 'dot'\n        Returns True or False according to the success of the write\n        operation.\n        \n        There's also the preferred possibility of using:\n        \n            write_'format'(path, prog='program')\n            \n        which are automatically defined for all the supported formats.\n        [write_ps(), write_gif(), write_dia(), ...]\n        \"\"\"\n\n        if prog is None:\n            prog = self.prog\n        \n        dot_fd = file(path, \"w+b\")\n        if format == 'raw':\n            data = self.to_string()\n            if isinstance(data, basestring):\n                if not isinstance(data, unicode):\n                    try:\n                        data = unicode(data, 'utf-8')\n                    except:\n                        pass\n                        \n            try:\n                data = data.encode('utf-8')\n            except:\n                pass\n            dot_fd.write(data)\n        else:\n            dot_fd.write(self.create(prog, format))\n        dot_fd.close()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, prog=None, format='ps'):\n        \n        if prog is None:\n            prog = self.prog\n            \n        if isinstance(prog, (list, tuple)):\n            prog, args = prog[0], prog[1:]\n        else:\n            args = []\n            \n        if self.progs is None:\n            self.progs = find_graphviz()\n            if self.progs is None:\n                raise InvocationException(\n                    'GraphViz\\'s executables not found' )\n                \n        if not self.progs.has_key(prog):\n            raise InvocationException(\n                'GraphViz\\'s executable \"%s\" not found' % prog )\n            \n        if not os.path.exists( self.progs[prog] ) or not os.path.isfile( self.progs[prog] ):\n            raise InvocationException(\n                'GraphViz\\'s executable \"%s\" is not a file or doesn\\'t exist' % self.progs[prog] )\n            \n            \n        tmp_fd, tmp_name = tempfile.mkstemp()\n        os.close(tmp_fd)\n        self.write(tmp_name)\n        tmp_dir = os.path.dirname(tmp_name )\n        \n        # For each of the image files...\n        #\n        for img in self.shape_files:\n        \n            # Get its data\n            #\n            f = file(img, 'rb')\n            f_data = f.read()\n            f.close()\n            \n            # And copy it under a file with the same name in the temporary directory\n            #\n            f = file( os.path.join( tmp_dir, os.path.basename(img) ), 'wb' )\n            f.write(f_data)\n            f.close()\n        \n        cmdline = [self.progs[prog], '-T'+format, tmp_name] + args\n        \n        p = subprocess.Popen(\n            cmdline,\n            cwd=tmp_dir,\n            stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n            \n        stderr = p.stderr\n        stdout = p.stdout\n        \n        stdout_output = list()\n        while True:\n            data = stdout.read()\n            if not data:\n                break\n            stdout_output.append(data)\n        stdout.close()\n            \n        stdout_output = ''.join(stdout_output)\n        \n        if not stderr.closed:\n            stderr_output = list()\n            while True:\n                data = stderr.read()\n                if not data:\n                    break\n                stderr_output.append(data)\n            stderr.close()\n                \n            if stderr_output:\n                stderr_output = ''.join(stderr_output)\n            \n        #pid, status = os.waitpid(p.pid, 0)\n        status = p.wait()\n        \n        if status != 0 :\n            raise InvocationException(\n                'Program terminated with status: %d. stderr follows: %s' % (\n                    status, stderr_output) )\n        elif stderr_output:\n            print stderr_output\n        \n        # For each of the image files...\n        #\n        for img in self.shape_files:\n        \n            # remove it\n            #\n            os.unlink( os.path.join( tmp_dir, os.path.basename(img) ) )\n\n        os.unlink(tmp_name)\n        \n        return stdout_output", "response": "Creates and returns a Postscript representation of the graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump_yaml(data, Dumper=_Dumper, default_flow_style=False):\n    content = yaml.dump(data,\n                        default_flow_style=default_flow_style,\n                        Dumper=Dumper)\n    return content.strip()", "response": "Returns data as yaml - formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef memcached_client(servers=config.memcached_uri, debug=config.debug_memcache):\n    key = None\n    try:\n        client, key = scoped_instance_manager.acquire(servers, debug=debug)\n        yield client\n    finally:\n        if key:\n            scoped_instance_manager.release(key)", "response": "A context manager that returns a Memcached client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pool_memcached_connections(func):\n    if isgeneratorfunction(func):\n        def wrapper(*nargs, **kwargs):\n            with memcached_client():\n                for result in func(*nargs, **kwargs):\n                    yield result\n    else:\n        def wrapper(*nargs, **kwargs):\n            with memcached_client():\n                return func(*nargs, **kwargs)\n\n    return update_wrapper(wrapper, func)", "response": "Decorator to pool memcached connections."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef memcached(servers, key=None, from_cache=None, to_cache=None, time=0,\n              min_compress_len=0, debug=False):\n    \"\"\"memcached memoization function decorator.\n\n    The wrapped function is expected to return a value that is stored to a\n    memcached server, first translated by `to_cache` if provided. In the event\n    of a cache hit, the data is translated by `from_cache` if provided, before\n    being returned. If you do not want a result to be cached, wrap the return\n    value of your function in a `DoNotCache` object.\n\n    Example:\n\n        @memcached('127.0.0.1:11211')\n        def _listdir(path):\n            return os.path.listdir(path)\n\n    Note:\n        If using the default key function, ensure that repr() is implemented on\n        all your arguments and that they are hashable.\n\n    Note:\n        `from_cache` and `to_cache` both accept the value as first parameter,\n        then the target function's arguments follow.\n\n    Args:\n        servers (str or list of str): memcached server uri(s), eg '127.0.0.1:11211'.\n            This arg can be None also, in which case memcaching is disabled.\n        key (callable, optional): Function that, given the target function's args,\n            returns the string key to use in memcached.\n        from_cache (callable, optional): If provided, and a cache hit occurs, the\n            cached value will be translated by this function before being returned.\n        to_cache (callable, optional): If provided, and a cache miss occurs, the\n            function's return value will be translated by this function before\n            being cached.\n        time (int): Tells memcached the time which this value should expire, either\n            as a delta number of seconds, or an absolute unix time-since-the-epoch\n            value. See the memcached protocol docs section \"Storage Commands\"\n            for more info on <exptime>. We default to 0 == cache forever.\n        min_compress_len (int): The threshold length to kick in auto-compression\n            of the value using the zlib.compress() routine. If the value being cached is\n            a string, then the length of the string is measured, else if the value is an\n            object, then the length of the pickle result is measured. If the resulting\n            attempt at compression yeilds a larger string than the input, then it is\n            discarded. For backwards compatability, this parameter defaults to 0,\n            indicating don't ever try to compress.\n        debug (bool): If True, memcache keys are kept human readable, so you can\n            read them if running a foreground memcached proc with 'memcached -vv'.\n            However this increases chances of key clashes so should not be left\n            turned on.\n    \"\"\"\n    def default_key(func, *nargs, **kwargs):\n        parts = [func.__module__]\n\n        argnames = getargspec(func).args\n        if argnames:\n            if argnames[0] == \"cls\":\n                cls_ = nargs[0]\n                parts.append(cls_.__name__)\n                nargs = nargs[1:]\n            elif argnames[0] == \"self\":\n                cls_ = nargs[0].__class__\n                parts.append(cls_.__name__)\n                nargs = nargs[1:]\n\n        parts.append(func.__name__)\n\n        value = ('.'.join(parts), nargs, tuple(sorted(kwargs.items())))\n        # make sure key is hashable. We don't strictly need it to be, but this\n        # is a way of hopefully avoiding object types that are not ordered (these\n        # would give an unreliable key). If you need to key on unhashable args,\n        # you should provide your own `key` functor.\n        _ = hash(value)\n        return repr(value)\n\n    def identity(value, *nargs, **kwargs):\n        return value\n\n    from_cache = from_cache or identity\n    to_cache = to_cache or identity\n\n    def decorator(func):\n        if servers:\n            def wrapper(*nargs, **kwargs):\n                with memcached_client(servers, debug=debug) as client:\n                    if key:\n                        cache_key = key(*nargs, **kwargs)\n                    else:\n                        cache_key = default_key(func, *nargs, **kwargs)\n\n                    # get\n                    result = client.get(cache_key)\n                    if result is not client.miss:\n                        return from_cache(result, *nargs, **kwargs)\n\n                    # cache miss - run target function\n                    result = func(*nargs, **kwargs)\n                    if isinstance(result, DoNotCache):\n                        return result.result\n\n                    # store\n                    cache_result = to_cache(result, *nargs, **kwargs)\n                    client.set(key=cache_key,\n                               val=cache_result,\n                               time=time,\n                               min_compress_len=min_compress_len)\n                    return result\n        else:\n            def wrapper(*nargs, **kwargs):\n                result = func(*nargs, **kwargs)\n                if isinstance(result, DoNotCache):\n                    return result.result\n                return result\n\n        def forget():\n            \"\"\"Forget entries in the cache.\n\n            Note that this does not delete entries from a memcached server - that\n            would be slow and error-prone. Calling this function only ensures\n            that entries set by the current process will no longer be seen during\n            this process.\n            \"\"\"\n            with memcached_client(servers, debug=debug) as client:\n                client.flush()\n\n        wrapper.forget = forget\n        wrapper.__wrapped__ = func\n        return update_wrapper(wrapper, func)\n    return decorator", "response": "Decorator for memcached memoization functions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the native memcache client.", "response": "def client(self):\n        \"\"\"Get the native memcache client.\n\n        Returns:\n            `memcache.Client` instance.\n        \"\"\"\n        if self._client is None:\n            self._client = Client_(self.servers)\n        return self._client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the value of the key in memcache.", "response": "def set(self, key, val, time=0, min_compress_len=0):\n        \"\"\"See memcache.Client.\"\"\"\n        if not self.servers:\n            return\n\n        key = self._qualified_key(key)\n        hashed_key = self.key_hasher(key)\n        val = (key, val)\n\n        self.client.set(key=hashed_key,\n                        val=val,\n                        time=time,\n                        min_compress_len=min_compress_len)\n        self.logger(\"SET: %s\", key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, key):\n        if not self.servers:\n            return self.miss\n\n        key = self._qualified_key(key)\n        hashed_key = self.key_hasher(key)\n        entry = self.client.get(hashed_key)\n\n        if isinstance(entry, tuple) and len(entry) == 2:\n            key_, result = entry\n            if key_ == key:\n                self.logger(\"HIT: %s\", key)\n                return result\n\n        self.logger(\"MISS: %s\", key)\n        return self.miss", "response": "See memcache. Client.\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete an item from the cache.", "response": "def delete(self, key):\n        \"\"\"See memcache.Client.\"\"\"\n        if self.servers:\n            key = self._qualified_key(key)\n            hashed_key = self.key_hasher(key)\n            self.client.delete(hashed_key)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flush(self, hard=False):\n        if not self.servers:\n            return\n        if hard:\n            self.client.flush_all()\n            self.reset_stats()\n        else:\n            from uuid import uuid4\n            tag = uuid4().hex\n            if self.debug:\n                tag = \"flushed\" + tag\n            self.current = tag", "response": "Drop existing entries from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef depth_first_search(graph, root=None, filter=null()):\n    \n    recursionlimit = getrecursionlimit()\n    setrecursionlimit(max(len(graph.nodes())*2,recursionlimit))\n\n    def dfs(node):\n        \"\"\"\n        Depth-first search subfunction.\n        \"\"\"\n        visited[node] = 1\n        pre.append(node)\n        # Explore recursively the connected component\n        for each in graph[node]:\n            if (each not in visited and filter(each, node)):\n                spanning_tree[each] = node\n                dfs(each)\n        post.append(node)\n\n    visited = {}            # List for marking visited and non-visited nodes\n    spanning_tree = {}      # Spanning tree\n    pre = []                # Graph's preordering\n    post = []               # Graph's postordering\n    filter.configure(graph, spanning_tree)\n\n    # DFS from one node only\n    if (root is not None):\n        if filter(root, None):\n            spanning_tree[root] = None\n            dfs(root)\n        setrecursionlimit(recursionlimit)\n        return spanning_tree, pre, post\n    \n    # Algorithm loop\n    for each in graph:\n        # Select a non-visited node\n        if (each not in visited and filter(each, None)):\n            spanning_tree[each] = None\n            # Explore node's connected component\n            dfs(each)\n\n    setrecursionlimit(recursionlimit)\n    \n    return (spanning_tree, pre, post)", "response": "Depth - first search of a graph."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef breadth_first_search(graph, root=None, filter=null()):\n\n    def bfs():\n        \"\"\"\n        Breadth-first search subfunction.\n        \"\"\"\n        while (queue != []):\n            node = queue.pop(0)\n            \n            for other in graph[node]:\n                if (other not in spanning_tree and filter(other, node)):\n                    queue.append(other)\n                    ordering.append(other)\n                    spanning_tree[other] = node\n    \n    queue = []            # Visiting queue\n    spanning_tree = {}    # Spanning tree\n    ordering = []\n    filter.configure(graph, spanning_tree)\n    \n    # BFS from one node only\n    if (root is not None):\n        if filter(root, None):\n            queue.append(root)\n            ordering.append(root)\n            spanning_tree[root] = None\n            bfs()\n        return spanning_tree, ordering\n\n    # Algorithm\n    for each in graph:\n        if (each not in spanning_tree):\n            if filter(each, None):\n                queue.append(each)\n                ordering.append(each)\n                spanning_tree[each] = None\n                bfs()\n\n    return spanning_tree, ordering", "response": "Breadth - first search of a graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake sure version is treated consistently", "response": "def normalize_variables(cls, variables):\n        \"\"\"Make sure version is treated consistently\n        \"\"\"\n        # if the version is False, empty string, etc, throw it out\n        if variables.get('version', True) in ('', False, '_NO_VERSION', None):\n            del variables['version']\n        return super(PackageResource, cls).normalize_variables(variables)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push_source(self, newstream, newfile=None):\n        \"Push an input source onto the lexer's input source stack.\"\n        if isinstance(newstream, basestring):\n            newstream = StringIO(newstream)\n        self.filestack.appendleft((self.infile, self.instream, self.lineno))\n        self.infile = newfile\n        self.instream = newstream\n        self.lineno = 1", "response": "Push an input source onto the lexer s input source stack."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pop_source(self):\n        \"Pop the input source stack.\"\n        self.instream.close()\n        (self.infile, self.instream, self.lineno) = self.filestack.popleft()\n        self.state = ' '", "response": "Pop the input source stack."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a token from the input stream or from stack if it s nonempty", "response": "def get_token(self):\n        \"Get a token from the input stream (or from stack if it's nonempty)\"\n        if self.pushback:\n            tok = self.pushback.popleft()\n            return tok\n        # No pushback.  Get a token.\n        raw = self.read_token()\n        # Handle inclusions\n        if self.source is not None:\n            while raw == self.source:\n                spec = self.sourcehook(self.read_token())\n                if spec:\n                    (newfile, newstream) = spec\n                    self.push_source(newstream, newfile)\n                raw = self.get_token()\n        # Maybe we got EOF instead?\n        while raw == self.eof:\n            if not self.filestack:\n                return self.eof\n            else:\n                self.pop_source()\n                raw = self.get_token()\n        # Neither inclusion nor EOF\n        return raw"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nemitting a C - compiler - like Emacs - friendly error - message leader.", "response": "def error_leader(self, infile=None, lineno=None):\n        \"Emit a C-compiler-like, Emacs-friendly error-message leader.\"\n        if infile is None:\n            infile = self.infile\n        if lineno is None:\n            lineno = self.lineno\n        return \"\\\"%s\\\", line %d: \" % (infile, lineno)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_pod(self):\n        orderers = {}\n        packages = {}\n\n        # group package fams by orderer they use\n        for fam, orderer in self.order_dict.iteritems():\n            k = id(orderer)\n            orderers[k] = orderer\n            packages.setdefault(k, set()).add(fam)\n\n        orderlist = []\n        for k, fams in packages.iteritems():\n            orderer = orderers[k]\n            data = to_pod(orderer)\n            data[\"packages\"] = sorted(fams)\n            orderlist.append(data)\n\n        result = {\"orderers\": orderlist}\n\n        if self.default_order is not None:\n            result[\"default_order\"] = to_pod(self.default_order)\n\n        return result", "response": "Convert the object to a pod format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the current shell.", "response": "def shell(self):\n        \"\"\"Get the current shell.\n        @returns The current shell this process is running in. Examples:\n\n            bash\n            tcsh\n        \"\"\"\n        from rez.shells import get_shell_types\n        shells = set(get_shell_types())\n        if not shells:\n            raise RezSystemError(\"no shells available\")\n\n        if self.platform == \"windows\":\n            return \"cmd\"\n        else:\n            import subprocess as sp\n            shell = None\n\n            # check parent process via ps\n            try:\n                args = ['ps', '-o', 'args=', '-p', str(os.getppid())]\n                proc = sp.Popen(args, stdout=sp.PIPE)\n                output = proc.communicate()[0]\n                shell = os.path.basename(output.strip().split()[0]).replace('-', '')\n            except Exception:\n                pass\n\n            # check $SHELL\n            if shell not in shells:\n                shell = os.path.basename(os.getenv(\"SHELL\", ''))\n\n            # traverse parent procs via /proc/(pid)/status\n            if shell not in shells:\n                pid = str(os.getppid())\n                found = False\n\n                while not found:\n                    try:\n                        file = os.path.join(os.sep, \"proc\", pid, \"status\")\n                        with open(file) as f:\n                            loc = f.read().split('\\n')\n\n                        for line in loc:\n                            line = line.strip()\n                            toks = line.split()\n                            if len(toks) == 2:\n                                if toks[0] == \"Name:\":\n                                    name = toks[1]\n                                    if name in shells:\n                                        shell = name\n                                        found = True\n                                        break\n                                elif toks[0] == \"PPid:\":\n                                    pid = toks[1]\n                    except Exception:\n                        break\n\n            if (shell not in shells) and (\"sh\" in shells):\n                shell = \"sh\"  # failed detection, fall back on 'sh'\n            elif (shell not in shells) and (\"bash\" in shells):\n                shell = \"bash\"  # failed detection, fall back on 'bash'\n            elif shell not in shells:\n                shell = iter(shells).next()  # give up - just choose a shell\n\n            # sh has to be handled as a special case\n            if shell == \"sh\":\n                if os.path.islink(\"/bin/sh\"):\n                    path = os.readlink(\"/bin/sh\")\n                    shell2 = os.path.split(path)[-1]\n\n                    if shell2 == \"bash\":\n                        # bash switches to sh-like shell when invoked as sh,\n                        # so we want to use the sh shell plugin\n                        pass\n                    elif shell2 == \"dash\":\n                        # dash doesn't have an sh emulation mode, so we have\n                        # to use the dash shell plugin\n                        if \"dash\" in shells:\n                            shell = \"dash\"\n                        else:\n                            # this isn't good!\n                            if \"bash\" in shells:\n                                shell = \"bash\"  # fall back on bash\n                            else:\n                                shell = iter(shells).next()  # give up - just choose a shell\n\n            # TODO: remove this when/if dash support added\n            if shell == \"dash\":\n                shell = \"bash\"\n\n            return shell"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the path containing the rez binaries or None if no binaries are available.", "response": "def rez_bin_path(self):\n        \"\"\"Get path containing rez binaries, or None if no binaries are\n        available, or Rez is not a production install.\n        \"\"\"\n        binpath = None\n        if sys.argv and sys.argv[0]:\n            executable = sys.argv[0]\n            path = which(\"rezolve\", env={\"PATH\":os.path.dirname(executable),\n                                         \"PATHEXT\":os.environ.get(\"PATHEXT\",\n                                                                  \"\")})\n            binpath = os.path.dirname(path) if path else None\n\n        # TODO: improve this, could still pick up non-production 'rezolve'\n        if not binpath:\n            path = which(\"rezolve\")\n            if path:\n                binpath = os.path.dirname(path)\n\n        if binpath:\n            validation_file = os.path.join(binpath, \".rez_production_install\")\n            if os.path.exists(validation_file):\n                return os.path.realpath(binpath)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a string summarising the state of Rez as a whole.", "response": "def get_summary_string(self):\n        \"\"\"Get a string summarising the state of Rez as a whole.\n\n        Returns:\n            String.\n        \"\"\"\n        from rez.plugin_managers import plugin_manager\n\n        txt = \"Rez %s\" % __version__\n        txt += \"\\n\\n%s\" % plugin_manager.get_summary_string()\n        return txt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear_caches(self, hard=False):\n        from rez.package_repository import package_repository_manager\n        from rez.utils.memcached import memcached_client\n\n        package_repository_manager.clear_caches()\n        if hard:\n            with memcached_client() as client:\n                client.flush()", "response": "Clear all caches in Rez."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_cached_solve(self):\n        if not (self.caching and self.memcached_servers):\n            return None\n\n        # these caches avoids some potentially repeated file stats\n        variant_states = {}\n        last_release_times = {}\n\n        def _hit(data):\n            solver_dict, _, _ = data\n            return solver_dict\n\n        def _miss():\n            self._print(\"No cache key retrieved\")\n            return None\n\n        def _delete_cache_entry(key):\n            with self._memcached_client() as client:\n                client.delete(key)\n            self._print(\"Discarded entry: %r\", key)\n\n        def _retrieve(timestamped):\n            key = self._memcache_key(timestamped=timestamped)\n            self._print(\"Retrieving memcache key: %r\", key)\n            with self._memcached_client() as client:\n                data = client.get(key)\n            return key, data\n\n        def _packages_changed(key, data):\n            solver_dict, _, variant_states_dict = data\n            for variant_handle in solver_dict.get(\"variant_handles\", []):\n                variant = self._get_variant(variant_handle)\n                old_state = variant_states_dict.get(variant.name)\n\n                new_state = variant_states.get(variant)\n                if new_state is None:\n                    try:\n                        repo = variant.resource._repository\n                        new_state = repo.get_variant_state_handle(variant.resource)\n                    except (IOError, OSError) as e:\n                        # if, ie a package file was deleted on disk, then\n                        # an IOError or OSError will be raised when we try to\n                        # read from it - assume that the packages have changed!\n                        self._print(\"Error loading %r (assuming cached state \"\n                                    \"changed): %s\", variant.qualified_name,\n                                    e)\n                        return True\n                    variant_states[variant] = new_state\n\n                if old_state != new_state:\n                    self._print(\"%r has been modified\", variant.qualified_name)\n                    return True\n            return False\n\n        def _releases_since_solve(key, data):\n            _, release_times_dict, _ = data\n            for package_name, release_time in release_times_dict.iteritems():\n                time_ = last_release_times.get(package_name)\n                if time_ is None:\n                    time_ = get_last_release_time(package_name, self.package_paths)\n                    last_release_times[package_name] = time_\n\n                if time_ != release_time:\n                    self._print(\n                        \"A newer version of %r (%d) has been released since the \"\n                        \"resolve was cached (latest release in cache was %d) \"\n                        \"(entry: %r)\", package_name, time_, release_time, key)\n                    return True\n            return False\n\n        def _timestamp_is_earlier(key, data):\n            _, release_times_dict, _ = data\n            for package_name, release_time in release_times_dict.iteritems():\n                if self.timestamp < release_time:\n                    self._print(\"Resolve timestamp (%d) is earlier than %r in \"\n                                \"solve (%d) (entry: %r)\", self.timestamp,\n                                package_name, release_time, key)\n                    return True\n            return False\n\n        key, data = _retrieve(False)\n\n        if self.timestamp:\n            if data:\n                if _packages_changed(key, data) or _releases_since_solve(key, data):\n                    _delete_cache_entry(key)\n                elif not _timestamp_is_earlier(key, data):\n                    return _hit(data)\n\n            key, data = _retrieve(True)\n            if not data:\n                return _miss()\n            if _packages_changed(key, data):\n                _delete_cache_entry(key)\n                return _miss()\n            else:\n                return _hit(data)\n        else:\n            if not data:\n                return _miss()\n            if _packages_changed(key, data) or _releases_since_solve(key, data):\n                _delete_cache_entry(key)\n                return _miss()\n            else:\n                return _hit(data)", "response": "Find a memcached resolve."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstoring a solve to memcached.", "response": "def _set_cached_solve(self, solver_dict):\n        \"\"\"Store a solve to memcached.\n\n        If there is NOT a resolve timestamp:\n            - store the solve to a non-timestamped entry.\n\n        If there IS a resolve timestamp (let us call this T):\n            - if NO newer package in the solve has been released since T,\n              - then store the solve to a non-timestamped entry;\n            - else:\n              - store the solve to a timestamped entry.\n        \"\"\"\n        if self.status_ != ResolverStatus.solved:\n            return  # don't cache failed solves\n\n        if not (self.caching and self.memcached_servers):\n            return\n\n        # most recent release times get stored with solve result in the cache\n        releases_since_solve = False\n        release_times_dict = {}\n        variant_states_dict = {}\n\n        for variant in self.resolved_packages_:\n            time_ = get_last_release_time(variant.name, self.package_paths)\n\n            # don't cache if a release time isn't known\n            if time_ == 0:\n                self._print(\"Did not send memcache key: a repository could \"\n                            \"not provide a most recent release time for %r\",\n                            variant.name)\n                return\n\n            if self.timestamp and self.timestamp < time_:\n                releases_since_solve = True\n\n            release_times_dict[variant.name] = time_\n            repo = variant.resource._repository\n            variant_states_dict[variant.name] = \\\n                repo.get_variant_state_handle(variant.resource)\n\n        timestamped = (self.timestamp and releases_since_solve)\n        key = self._memcache_key(timestamped=timestamped)\n        data = (solver_dict, release_times_dict, variant_states_dict)\n        with self._memcached_client() as client:\n            client.set(key, data)\n        self._print(\"Sent memcache key: %r\", key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _memcache_key(self, timestamped=False):\n        request = tuple(map(str, self.package_requests))\n        repo_ids = []\n        for path in self.package_paths:\n            repo = package_repository_manager.get_repository(path)\n            repo_ids.append(repo.uid)\n\n        t = [\"resolve\",\n             request,\n             tuple(repo_ids),\n             self.package_filter_hash,\n             self.package_orderers_hash,\n             self.building,\n             config.prune_failed_graph]\n\n        if timestamped and self.timestamp:\n            t.append(self.timestamp)\n\n        return str(tuple(t))", "response": "Makes a key suitable as a memcache entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Shell of the given type or the current shell type.", "response": "def create_shell(shell=None, **kwargs):\n    \"\"\"Returns a Shell of the given type, or the current shell type if shell\n    is None.\"\"\"\n    if not shell:\n        shell = config.default_shell\n        if not shell:\n            from rez.system import system\n            shell = system.shell\n\n    from rez.plugin_managers import plugin_manager\n    return plugin_manager.create_instance('shell', shell, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef startup_capabilities(cls, rcfile=False, norc=False, stdin=False,\n                             command=False):\n        \"\"\"\n        Given a set of options related to shell startup, return the actual\n        options that will be applied.\n        @returns 4-tuple representing applied value of each option.\n        \"\"\"\n        raise NotImplementedError", "response": "Returns the actual set of startup capabilities for the current command line or rcfile."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind an executable. Args: name (str): Program name. check_syspaths (bool): If True, check the standard system paths as well, if program was not found on current $PATH. Returns: str: Full filepath of executable.", "response": "def find_executable(cls, name, check_syspaths=False):\n        \"\"\"Find an executable.\n\n        Args:\n            name (str): Program name.\n            check_syspaths (bool): If True, check the standard system paths as\n                well, if program was not found on current $PATH.\n\n        Returns:\n            str: Full filepath of executable.\n        \"\"\"\n        exe = which(name)\n\n        if not exe and check_syspaths:\n            paths = cls.get_syspaths()\n            env = os.environ.copy()\n            env[\"PATH\"] = os.pathsep.join(paths)\n            exe = which(name, env=env)\n\n        if not exe:\n            raise RuntimeError(\"Couldn't find executable '%s'.\" % name)\n        return exe"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spawn_shell(self, context_file, tmpdir, rcfile=None, norc=False,\n                    stdin=False, command=None, env=None, quiet=False,\n                    pre_command=None, add_rez=True,\n                    package_commands_sourced_first=None, **Popen_args):\n        \"\"\"Spawn a possibly interactive subshell.\n        Args:\n            context:_file File that must be sourced in the new shell, this\n                configures the Rez environment.\n            tmpdir: Tempfiles, if needed, should be created within this path.\n            rcfile: Custom startup script.\n            norc: Don't run startup scripts. Overrides rcfile.\n            stdin: If True, read commands from stdin in a non-interactive shell.\n                If a different non-False value, such as subprocess.PIPE, the same\n                occurs, but stdin is also passed to the resulting subprocess.Popen\n                object.\n            command: If not None, execute this command in a non-interactive shell.\n                If an empty string, don't run a command, but don't open an\n                interactive shell either.\n            env: Environ dict to execute the shell within; uses the current\n                environment if None.\n            quiet: If True, don't show the configuration summary, and suppress\n                any stdout from startup scripts.\n            pre_command: Command to inject before the shell command itself. This\n                is for internal use.\n            add_rez: If True, assume this shell is being used with rez, and do\n                things such as set the prompt etc.\n            package_commands_sourced_first: If True, source the context file before\n                sourcing startup scripts (such as .bashrc). If False, source\n                the context file AFTER. If None, use the configured setting.\n            popen_args: args to pass to the shell process object constructor.\n\n        Returns:\n            A subprocess.Popen object representing the shell process.\n        \"\"\"\n        raise NotImplementedError", "response": "Spawns a possibly interactive subshell."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupload a file to the index.", "response": "def upload_file(self, metadata, filename, signer=None, sign_password=None,\n                    filetype='sdist', pyversion='source', keystore=None):\n        \"\"\"\n        Upload a release file to the index.\n\n        :param metadata: A :class:`Metadata` instance defining at least a name\n                         and version number for the file to be uploaded.\n        :param filename: The pathname of the file to be uploaded.\n        :param signer: The identifier of the signer of the file.\n        :param sign_password: The passphrase for the signer's\n                              private key used for signing.\n        :param filetype: The type of the file being uploaded. This is the\n                        distutils command which produced that file, e.g.\n                        ``sdist`` or ``bdist_wheel``.\n        :param pyversion: The version of Python which the release relates\n                          to. For code compatible with any Python, this would\n                          be ``source``, otherwise it would be e.g. ``3.2``.\n        :param keystore: The path to a directory which contains the keys\n                         used in signing. If not specified, the instance's\n                         ``gpg_home`` attribute is used instead.\n        :return: The HTTP response received from PyPI upon submission of the\n                request.\n        \"\"\"\n        self.check_credentials()\n        if not os.path.exists(filename):\n            raise DistlibException('not found: %s' % filename)\n        metadata.validate()\n        d = metadata.todict()\n        sig_file = None\n        if signer:\n            if not self.gpg:\n                logger.warning('no signing program available - not signed')\n            else:\n                sig_file = self.sign_file(filename, signer, sign_password,\n                                          keystore)\n        with open(filename, 'rb') as f:\n            file_data = f.read()\n        md5_digest = hashlib.md5(file_data).hexdigest()\n        sha256_digest = hashlib.sha256(file_data).hexdigest()\n        d.update({\n            ':action': 'file_upload',\n            'protcol_version': '1',\n            'filetype': filetype,\n            'pyversion': pyversion,\n            'md5_digest': md5_digest,\n            'sha256_digest': sha256_digest,\n        })\n        files = [('content', os.path.basename(filename), file_data)]\n        if sig_file:\n            with open(sig_file, 'rb') as f:\n                sig_data = f.read()\n            files.append(('gpg_signature', os.path.basename(sig_file),\n                         sig_data))\n            shutil.rmtree(os.path.dirname(sig_file))\n        request = self.encode_request(d.items(), files)\n        return self.send_request(request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncopying a package from one package repository to another.", "response": "def copy_package(package, dest_repository, variants=None, shallow=False,\n                 dest_name=None, dest_version=None, overwrite=False, force=False,\n                 follow_symlinks=False, dry_run=False, keep_timestamp=False,\n                 skip_payload=False, overrides=None, verbose=False):\n    \"\"\"Copy a package from one package repository to another.\n\n    This copies the package definition and payload. The package can also be\n    re-named and/or re-versioned using the `dest_name` and `dest_version` args.\n\n    The result is a dict describing which package variants were and were not\n    copied. For example:\n\n        {\n            \"copied\": [\n                (`Variant`, `Variant`)\n            ],\n            \"skipped\": [\n                (`Variant`, `Variant`)\n            ]\n        }\n\n    Each 2-tuple in the 'copied' or 'skipped' list contains the source and\n    destination variant respectively. In the 'skipped' list, the source variant\n    is the variant that was NOT copied, and the dest variant is the existing\n    target variant that caused the source not to be copied. Skipped variants\n    will only be present when `overwrite` is False.\n\n    Note:\n        Whether or not a package can be copied is determined by its 'relocatable'\n        attribute (see the `default_relocatable` config setting for more details).\n        An attempt to copy a non-relocatable package will fail. You can override\n        this behaviour with the `force` argument.\n\n    Args:\n        package (`Package`): Package to copy.\n        dest_repository (`PackageRepository` or str): The package repository, or\n            a package repository path, to copy the package into.\n        variants (list of int): Indexes of variants to build, or all if None.\n        shallow (bool): If True, symlinks of each variant's root directory are\n            created, rather than the payload being copied.\n        dest_name (str): If provided, copy the package to a new package name.\n        dest_version (str or `Version`): If provided, copy the package to a new\n            version.\n        overwrite (bool): Overwrite variants if they already exist in the\n            destination package. In this case, the existing payload is removed\n            before the new payload is copied.\n        force (bool): Copy the package regardless of its relocatable attribute.\n            Use at your own risk (there is no guarantee the resulting package\n            will be functional).\n        follow_symlinks (bool): Follow symlinks when copying package payload,\n            rather than copying the symlinks themselves.\n        keep_timestamp (bool): By default, a newly copied package will get a\n            new timestamp (because that's when it was added to the target repo).\n            By setting this option to True, the original package's timestamp\n            is kept intact. Note that this will have no effect if variant(s)\n            are copied into an existing package.\n        skip_payload (bool): If True, do not copy the package payload.\n        overrides (dict): See `PackageRepository.install_variant`.\n        verbose (bool): Verbose mode.\n        dry_run (bool): Dry run mode. Dest variants in the result will be None\n            in this case.\n\n    Returns:\n        Dict: See comments above.\n    \"\"\"\n    copied = []\n    skipped = []\n\n    def finalize():\n        return {\n            \"copied\": copied,\n            \"skipped\": skipped\n        }\n\n    # check that package is relocatable\n    if not force and not skip_payload and not package.is_relocatable:\n        raise PackageCopyError(\n            \"Cannot copy non-relocatable package: %s\" % package.uri\n        )\n\n    if isinstance(dest_repository, basestring):\n        repo_path = dest_repository\n        dest_pkg_repo = package_repository_manager.get_repository(repo_path)\n    else:\n        dest_pkg_repo = dest_repository\n\n    # cannot copy package over the top of itself\n    if package.repository == dest_pkg_repo and \\\n            (dest_name is None or dest_name == package.name) and \\\n            (dest_version is None or str(dest_version) == str(package.version)):\n        raise PackageCopyError(\n            \"Cannot copy package over itself: %s.\" % package.uri\n        )\n\n    # determine variants to potentially install\n    src_variants = []\n    for variant in package.iter_variants():\n        if variants is None or variant.index in variants:\n            src_variants.append(variant)\n\n    if not src_variants:\n        return finalize()\n\n    # Construct overrides.\n    #\n    overrides = (overrides or {}).copy()\n\n    if dest_name:\n        overrides[\"name\"] = dest_name\n    if dest_version:\n        overrides[\"version\"] = dest_version\n\n    # Find variants that already exist in the dest package, and remove them\n    # from the copy candidates if overwriting is disabled.\n    #\n    new_src_variants = []\n\n    for src_variant in src_variants:\n        existing_variant = dest_pkg_repo.install_variant(\n            src_variant.resource,\n            overrides=overrides,\n            dry_run=True\n        )\n\n        if existing_variant:\n            if overwrite:\n                if verbose:\n                    print_info(\"Source variant %s will overwrite %s\",\n                               src_variant.uri, existing_variant.uri)\n            else:\n                if verbose:\n                    print_info(\n                        \"Skipping source variant %s - already exists in \"\n                        \"destination package at %s\",\n                        src_variant.uri, existing_variant.uri\n                    )\n\n                skipped.append((src_variant, existing_variant))\n                continue\n\n        new_src_variants.append(src_variant)\n\n    src_variants = new_src_variants\n\n    # Install each variant and associated payload.\n    #\n    for i, src_variant in enumerate(src_variants):\n        if verbose:\n            print_info(\"Copying source variant %s into repository %s...\",\n                       src_variant.uri, str(dest_pkg_repo))\n\n        if dry_run:\n            dest_variant = None\n        else:\n            if not skip_payload:\n                # Perform pre-install steps. For eg, a \"building\" marker file is\n                # created in the filesystem pkg repo, so that the package dir\n                # (which doesn't have variants copied into it yet) is not picked\n                # up as a valid package.\n                #\n                dest_pkg_repo.pre_variant_install(src_variant.resource)\n\n                # copy include modules before the first variant install\n                if i == 0:\n                    _copy_package_include_modules(\n                        src_variant.parent,\n                        dest_pkg_repo,\n                        overrides=overrides\n                    )\n\n                # copy the variant's payload\n                _copy_variant_payload(\n                    src_variant=src_variant,\n                    dest_pkg_repo=dest_pkg_repo,\n                    shallow=shallow,\n                    follow_symlinks=follow_symlinks,\n                    overrides=overrides,\n                    verbose=verbose\n                )\n\n            # construct overrides\n            overrides_ = overrides.copy()\n\n            if not keep_timestamp and \"timestamp\" not in overrides:\n                overrides_[\"timestamp\"] = int(time.time())\n\n            # install the variant into the package definition\n            dest_variant = dest_pkg_repo.install_variant(\n                variant_resource=src_variant.resource,\n                overrides=overrides_\n            )\n\n        if verbose:\n            print_info(\"Copied source variant %s to target variant %s\",\n                       src_variant, dest_variant)\n\n        copied.append((src_variant, dest_variant))\n\n    return finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn list of nodes as close as possible to the ordering in node_list but with child nodes earlier in the list than parents.", "response": "def _get_dependency_order(g, node_list):\n    \"\"\"Return list of nodes as close as possible to the ordering in node_list,\n    but with child nodes earlier in the list than parents.\"\"\"\n    access_ = accessibility(g)\n    deps = dict((k, set(v) - set([k])) for k, v in access_.iteritems())\n    nodes = node_list + list(set(g.nodes()) - set(node_list))\n    ordered_nodes = []\n\n    while nodes:\n        n_ = nodes[0]\n        n_deps = deps.get(n_)\n        if (n_ in ordered_nodes) or (n_deps is None):\n            nodes = nodes[1:]\n            continue\n\n        moved = False\n        for i, n in enumerate(nodes[1:]):\n            if n in n_deps:\n                nodes = [nodes[i + 1]] + nodes[:i + 1] + nodes[i + 2:]\n                moved = True\n                break\n\n        if not moved:\n            ordered_nodes.append(n_)\n            nodes = nodes[1:]\n\n    return ordered_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints shortened version of ==X| == Y| == Z ranged requests.", "response": "def _short_req_str(package_request):\n    \"\"\"print shortened version of '==X|==Y|==Z' ranged requests.\"\"\"\n    if not package_request.conflict:\n        versions = package_request.range.to_versions()\n        if versions and len(versions) == len(package_request.range) \\\n                and len(versions) > 1:\n            return \"%s-%s(%d)\" % (package_request.name,\n                                  str(package_request.range.span()),\n                                  len(versions))\n    return str(package_request)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requires_list(self):\n        requires = self.variant.get_requires(build_requires=self.building)\n        reqlist = RequirementList(requires)\n\n        if reqlist.conflict:\n            raise ResolveError(\n                \"The package %s has an internal requirements conflict: %s\"\n                % (str(self), str(reqlist)))\n\n        return reqlist", "response": "Returns the internal requirements list for this variant."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsort variants from most correct to consume to least.", "response": "def sort(self):\n        \"\"\"Sort variants from most correct to consume, to least.\n\n        Sort rules:\n\n        version_priority:\n        - sort by highest versions of packages shared with request;\n        - THEN least number of additional packages added to solve;\n        - THEN highest versions of additional packages;\n        - THEN alphabetical on name of additional packages;\n        - THEN variant index.\n\n        intersection_priority:\n        - sort by highest number of packages shared with request;\n        - THEN sort according to version_priority\n\n        Note:\n            In theory 'variant.index' should never factor into the sort unless\n            two variants are identical (which shouldn't happen) - this is just\n            here as a safety measure so that sorting is guaranteed repeatable\n            regardless.\n        \"\"\"\n        if self.sorted:\n            return\n\n        def key(variant):\n            requested_key = []\n            names = set()\n\n            for i, request in enumerate(self.solver.request_list):\n                if not request.conflict:\n                    req = variant.requires_list.get(request.name)\n                    if req is not None:\n                        requested_key.append((-i, req.range))\n                        names.add(req.name)\n\n            additional_key = []\n            for request in variant.requires_list:\n                if not request.conflict and request.name not in names:\n                    additional_key.append((request.range, request.name))\n\n            if (VariantSelectMode[config.variant_select_mode] ==\n                    VariantSelectMode.version_priority):\n                k = (requested_key,\n                     -len(additional_key),\n                     additional_key,\n                     variant.index)\n            else:  # VariantSelectMode.intersection_priority\n                k = (len(requested_key),\n                     requested_key,\n                     -len(additional_key),\n                     additional_key,\n                     variant.index)\n\n            return k\n\n        self.variants.sort(key=key, reverse=True)\n        self.sorted = True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_intersection(self, range_):\n        result = []\n\n        for entry in self.entries:\n            package, value = entry\n\n            if value is None:\n                continue  # package was blocked by package filters\n\n            if package.version not in range_:\n                continue\n\n            if isinstance(value, list):\n                variants = value\n                entry_ = _PackageEntry(package, variants, self.solver)\n                result.append(entry_)\n                continue\n\n            # apply package filter\n            if self.solver.package_filter:\n                rule = self.solver.package_filter.excludes(package)\n                if rule:\n                    if config.debug_package_exclusions:\n                        print_debug(\"Package '%s' was excluded by rule '%s'\"\n                                    % (package.qualified_name, str(rule)))\n                    entry[1] = None\n                    continue\n\n            # expand package entry into list of variants\n            if self.solver.package_load_callback:\n                self.solver.package_load_callback(package)\n\n            variants_ = []\n            for var in package.iter_variants():\n                variant = PackageVariant(var, self.solver.building)\n                variants_.append(variant)\n\n            entry[1] = variants_\n            entry_ = _PackageEntry(package, variants_, self.solver)\n            result.append(entry_)\n\n        return result or None", "response": "Get a list of variants that intersect with the given range."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef intersect(self, range_):\n        self.solver.intersection_broad_tests_count += 1\n\n        \"\"\"Remove variants whose version fall outside of the given range.\"\"\"\n        if range_.is_any():\n            return self\n\n        if self.solver.optimised:\n            if range_ in self.been_intersected_with:\n                return self\n\n        if self.pr:\n            self.pr.passive(\"intersecting %s wrt range '%s'...\", self, range_)\n\n        self.solver.intersection_tests_count += 1\n\n        with self.solver.timed(self.solver.intersection_time):\n            # this is faster than iter_intersecting :(\n            entries = [x for x in self.entries if x.version in range_]\n\n        if not entries:\n            return None\n        elif len(entries) < len(self.entries):\n            copy_ = self._copy(entries)\n            copy_.been_intersected_with.add(range_)\n            return copy_\n        else:\n            self.been_intersected_with.add(range_)\n            return self", "response": "Remove variants whose version fall outside of the given range."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reduce_by(self, package_request):\n        if self.pr:\n            reqstr = _short_req_str(package_request)\n            self.pr.passive(\"reducing %s wrt %s...\", self, reqstr)\n\n        if self.solver.optimised:\n            if package_request in self.been_reduced_by:\n                return (self, [])\n\n        if (package_request.range is None) or \\\n                (package_request.name not in self.fam_requires):\n            return (self, [])\n\n        with self.solver.timed(self.solver.reduction_time):\n            return self._reduce_by(package_request)", "response": "Remove variants whos dependencies conflict with the given package_request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting a common dependency.", "response": "def extract(self):\n        \"\"\"Extract a common dependency.\n\n        Note that conflict dependencies are never extracted, they are always\n        resolved via reduction.\n        \"\"\"\n        if not self.extractable:\n            return self, None\n\n        extractable = self.common_fams - self.extracted_fams\n\n        # the sort is necessary to ensure solves are deterministic\n        fam = sorted(extractable)[0]\n\n        last_range = None\n        ranges = set()\n\n        for variant in self.iter_variants():\n            req = variant.get(fam)\n            if req.range != last_range:  # will match often, avoids set search\n                ranges.add(req.range)\n                last_range = req.range\n\n        slice_ = copy.copy(self)\n        slice_.extracted_fams = self.extracted_fams | set([fam])\n\n        ranges = list(ranges)\n        range_ = ranges[0].union(ranges[1:])\n        common_req = Requirement.construct(fam, range_)\n        return slice_, common_req"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split(self):\n\n        # We sort here in the split in order to sort as late as possible.\n        # Because splits usually happen after intersections/reductions, this\n        # means there can be less entries to sort.\n        #\n        self.sort_versions()\n\n        def _split(i_entry, n_variants, common_fams=None):\n            # perform a split at a specific point\n            result = self.entries[i_entry].split(n_variants)\n\n            if result:\n                entry, next_entry = result\n                entries = self.entries[:i_entry] + [entry]\n                next_entries = [next_entry] + self.entries[i_entry + 1:]\n            else:\n                entries = self.entries[:i_entry + 1]\n                next_entries = self.entries[i_entry + 1:]\n\n            slice_ = self._copy(entries)\n            next_slice = self._copy(next_entries)\n\n            if self.pr:\n                if common_fams:\n                    if len(common_fams) == 1:\n                        reason_str = iter(common_fams).next()\n                    else:\n                        reason_str = \", \".join(common_fams)\n                else:\n                    reason_str = \"first variant\"\n                self.pr(\"split (reason: %s) %s into %s and %s\",\n                        reason_str, self, slice_, next_slice)\n\n            return slice_, next_slice\n\n        # determine if we need to find first variant without common dependency\n        if len(self) > 2:\n            fams = self.first_variant.request_fams - self.extracted_fams\n        else:\n            fams = None\n\n        if not fams:\n            # trivial case, split on first variant\n            return _split(0, 1)\n\n        # find split point - first variant with no dependency shared with previous\n        prev = None\n        for i, entry in enumerate(self.entries):\n            # sort the variants. This is done here in order to do the sort as\n            # late as possible, simply to avoid the cost.\n            entry.sort()\n\n            for j, variant in enumerate(entry.variants):\n                fams = fams & variant.request_fams\n                if not fams:\n                    return _split(*prev)\n\n                prev = (i, j + 1, fams)\n\n        # should never get here - it's only possible if there's a common\n        # dependency, but if there's a common dependency, split() should never\n        # have been called.\n        raise RezSystemError(\n            \"Unexpected solver error: common family(s) still in slice being \"\n            \"split: slice: %s, family(s): %s\" % (self, str(fams)))", "response": "Splits the slice into two lists where the first slice is the preferred slice."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort_versions(self):\n        if self.sorted:\n            return\n\n        for orderer in (self.solver.package_orderers or []):\n            entries = orderer.reorder(self.entries, key=lambda x: x.package)\n            if entries is not None:\n                self.entries = entries\n                self.sorted = True\n\n                if self.pr:\n                    self.pr(\"sorted: %s packages: %s\", self.package_name, repr(orderer))\n                return\n\n        # default ordering is version descending\n        self.entries = sorted(self.entries, key=lambda x: x.version, reverse=True)\n        self.sorted = True\n\n        if self.pr:\n            self.pr(\"sorted: %s packages: version descending\", self.package_name)", "response": "Sort entries by version."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_variant_slice(self, package_name, range_):\n        variant_list = self.variant_lists.get(package_name)\n\n        if variant_list is None:\n            variant_list = _PackageVariantList(package_name, self.solver)\n            self.variant_lists[package_name] = variant_list\n\n        entries = variant_list.get_intersection(range_)\n        if not entries:\n            return None\n\n        slice_ = _PackageVariantSlice(package_name,\n                                      entries=entries,\n                                      solver=self.solver)\n        return slice_", "response": "Returns a list of variants from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new scope with variants whos version fall outside of the given range.", "response": "def intersect(self, range_):\n        \"\"\"Intersect this scope with a package range.\n\n        Returns:\n            A new copy of this scope, with variants whos version fall outside\n            of the given range removed. If there were no removals, self is\n            returned. If all variants were removed, None is returned.\n        \"\"\"\n        new_slice = None\n\n        if self.package_request.conflict:\n            if self.package_request.range is None:\n                new_slice = self.solver._get_variant_slice(\n                    self.package_name, range_)\n            else:\n                new_range = range_ - self.package_request.range\n                if new_range is not None:\n                    new_slice = self.solver._get_variant_slice(\n                        self.package_name, new_range)\n        else:\n            new_slice = self.variant_slice.intersect(range_)\n\n        # intersection reduced the scope to nothing\n        if new_slice is None:\n            if self.pr:\n                self.pr(\"%s intersected with range '%s' resulted in no packages\",\n                        self, range_)\n            return None\n\n        # intersection narrowed the scope\n        if new_slice is not self.variant_slice:\n            scope = self._copy(new_slice)\n            if self.pr:\n                self.pr(\"%s was intersected to %s by range '%s'\",\n                        self, scope, range_)\n            return scope\n\n        # intersection did not change the scope\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reduce_by(self, package_request):\n        self.solver.reduction_broad_tests_count += 1\n\n        if self.package_request.conflict:\n            # conflict scopes don't reduce. Instead, other scopes will be\n            # reduced against a conflict scope.\n            return (self, [])\n\n        # perform the reduction\n        new_slice, reductions = self.variant_slice.reduce_by(package_request)\n\n        # there was total reduction\n        if new_slice is None:\n            self.solver.reductions_count += 1\n\n            if self.pr:\n                reqstr = _short_req_str(package_request)\n                self.pr(\"%s was reduced to nothing by %s\", self, reqstr)\n                self.pr.br()\n\n            return (None, reductions)\n\n        # there was some reduction\n        if new_slice is not self.variant_slice:\n            self.solver.reductions_count += 1\n            scope = self._copy(new_slice)\n\n            if self.pr:\n                reqstr = _short_req_str(package_request)\n                self.pr(\"%s was reduced to %s by %s\", self, scope, reqstr)\n                self.pr.br()\n            return (scope, reductions)\n\n        # there was no reduction\n        return (self, [])", "response": "Reduce this scope wrt a package request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts a common dependency.", "response": "def extract(self):\n        \"\"\"Extract a common dependency.\n\n        Returns:\n            A (_PackageScope, Requirement) tuple, containing the new scope copy\n            with the extraction, and the extracted package range. If no package\n            was extracted, then (self,None) is returned.\n        \"\"\"\n        if not self.package_request.conflict:\n            new_slice, package_request = self.variant_slice.extract()\n            if package_request:\n                assert(new_slice is not self.variant_slice)\n                scope = copy.copy(self)\n                scope.variant_slice = new_slice\n                if self.pr:\n                    self.pr(\"extracted %s from %s\", package_request, self)\n                return (scope, package_request)\n\n        return (self, None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsplitting the scope. Returns: A (_PackageScope, _PackageScope) tuple, where the first scope is guaranteed to have a common dependency. Or None, if splitting is not applicable to this scope.", "response": "def split(self):\n        \"\"\"Split the scope.\n\n        Returns:\n            A (_PackageScope, _PackageScope) tuple, where the first scope is\n            guaranteed to have a common dependency. Or None, if splitting is\n            not applicable to this scope.\n        \"\"\"\n        if self.package_request.conflict or (len(self.variant_slice) == 1):\n            return None\n        else:\n            r = self.variant_slice.split()\n            if r is None:\n                return None\n            else:\n                slice, next_slice = r\n                scope = self._copy(slice)\n                next_scope = self._copy(next_slice)\n                return (scope, next_scope)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef solve(self):\n        if self.status != SolverStatus.pending:\n            return self\n\n        scopes = self.scopes[:]\n        failure_reason = None\n        extractions = {}\n\n        changed_scopes_i = self.changed_scopes_i.copy()\n\n        def _create_phase(status=None):\n            phase = copy.copy(self)\n            phase.scopes = scopes\n            phase.failure_reason = failure_reason\n            phase.extractions = extractions\n            phase.changed_scopes_i = set()\n\n            if status is None:\n                phase.status = (SolverStatus.solved if phase._is_solved()\n                                else SolverStatus.exhausted)\n            else:\n                phase.status = status\n            return phase\n\n        # iteratively reduce until no more reductions possible\n        while True:\n            prev_num_scopes = len(scopes)\n            widened_scopes_i = set()\n\n            # iteratively extract until no more extractions possible\n            while True:\n                self.pr.subheader(\"EXTRACTING:\")\n                extracted_requests = []\n\n                # perform all possible extractions\n                with self.solver.timed(self.solver.extraction_time):\n                    for i in range(len(scopes)):\n                        while True:\n                            scope_, extracted_request = scopes[i].extract()\n\n                            if extracted_request:\n                                extracted_requests.append(extracted_request)\n                                k = (scopes[i].package_name, extracted_request.name)\n                                extractions[k] = extracted_request\n                                self.solver.extractions_count += 1\n                                scopes[i] = scope_\n                            else:\n                                break\n\n                if not extracted_requests:\n                    break\n\n                # simplify extractions (there may be overlaps)\n                self.pr.subheader(\"MERGE-EXTRACTIONS:\")\n                extracted_requests = RequirementList(extracted_requests)\n\n                if extracted_requests.conflict:  # extractions are in conflict\n                    req1, req2 = extracted_requests.conflict\n                    conflict = DependencyConflict(req1, req2)\n                    failure_reason = DependencyConflicts([conflict])\n                    return _create_phase(SolverStatus.failed)\n                elif self.pr:\n                    self.pr(\"merged extractions: %s\", extracted_requests)\n\n                # intersect extracted requests with current scopes\n                self.pr.subheader(\"INTERSECTING:\")\n                req_fams = []\n\n                with self.solver.timed(self.solver.intersection_test_time):\n                    for i, scope in enumerate(scopes):\n                        extracted_req = extracted_requests.get(scope.package_name)\n\n                        if extracted_req is None:\n                            continue\n\n                        # perform the intersection\n                        scope_ = scope.intersect(extracted_req.range)\n\n                        req_fams.append(extracted_req.name)\n\n                        if scope_ is None:\n                            # the scope conflicted with the extraction\n                            conflict = DependencyConflict(\n                                extracted_req, scope.package_request)\n                            failure_reason = DependencyConflicts([conflict])\n                            return _create_phase(SolverStatus.failed)\n\n                        if scope_ is not scope:\n                            # the scope was narrowed because it intersected\n                            # with an extraction\n                            scopes[i] = scope_\n                            changed_scopes_i.add(i)\n                            self.solver.intersections_count += 1\n\n                            # if the intersection caused a conflict scope to turn\n                            # into a non-conflict scope, then it has to be reduced\n                            # against all other scopes.\n                            #\n                            # In the very common case, if a scope changes then it\n                            # has been narrowed, so there is no need to reduce it\n                            # against other unchanged scopes. In this case however,\n                            # the scope actually widens! For eg, '~foo-1' may be\n                            # intersected with 'foo' to become 'foo-1', which might\n                            # then reduce against existing scopes.\n                            #\n                            if scope.is_conflict and not scope_.is_conflict:\n                                widened_scopes_i.add(i)\n\n                # add new scopes\n                new_extracted_reqs = [\n                    x for x in extracted_requests.requirements\n                    if x.name not in req_fams]\n\n                if new_extracted_reqs:\n                    self.pr.subheader(\"ADDING:\")\n                    #n = len(scopes)\n\n                    for req in new_extracted_reqs:\n                        scope = _PackageScope(req, solver=self.solver)\n                        scopes.append(scope)\n                        if self.pr:\n                            self.pr(\"added %s\", scope)\n\n            num_scopes = len(scopes)\n\n            # no further reductions to do\n            if (num_scopes == prev_num_scopes) \\\n                    and not changed_scopes_i \\\n                    and not widened_scopes_i:\n                break\n\n            # iteratively reduce until no more reductions possible\n            self.pr.subheader(\"REDUCING:\")\n\n            if not self.solver.optimised:\n                # force reductions across all scopes\n                changed_scopes_i = set(range(num_scopes))\n                prev_num_scopes = num_scopes\n\n            # create set of pending reductions from the list of changed scopes\n            # and list of added scopes. We use a sorted set because the solver\n            # must be deterministic, ie its behavior must always be the same for\n            # a given solve. A normal set does not guarantee order.\n            #\n            # Each item is an (x, y) tuple, where scope[x] will reduce by\n            # scope[y].package_request.\n            #\n            pending_reducts = SortedSet()\n            all_scopes_i = range(num_scopes)\n            added_scopes_i = range(prev_num_scopes, num_scopes)\n\n            for x in range(prev_num_scopes):\n                # existing scopes must reduce against changed scopes\n                for y in changed_scopes_i:\n                    if x != y:\n                        pending_reducts.add((x, y))\n\n                # existing scopes must reduce against newly added scopes\n                for y in added_scopes_i:\n                    pending_reducts.add((x, y))\n\n            # newly added scopes must reduce against all other scopes\n            for x in added_scopes_i:\n                for y in all_scopes_i:\n                    if x != y:\n                        pending_reducts.add((x, y))\n\n            # 'widened' scopes (see earlier comment in this func) must reduce\n            # against all other scopes\n            for x in widened_scopes_i:\n                for y in all_scopes_i:\n                    if x != y:\n                        pending_reducts.add((x, y))\n\n            # iteratively reduce until there are no more pending reductions.\n            # Note that if a scope is reduced, then other scopes need to reduce\n            # against it once again.\n            with self.solver.timed(self.solver.reduction_test_time):\n                while pending_reducts:\n                    x, y = pending_reducts.pop()\n\n                    new_scope, reductions = scopes[x].reduce_by(\n                        scopes[y].package_request)\n\n                    if new_scope is None:\n                        failure_reason = TotalReduction(reductions)\n                        return _create_phase(SolverStatus.failed)\n\n                    elif new_scope is not scopes[x]:\n                        scopes[x] = new_scope\n\n                        # other scopes need to reduce against x again\n                        for j in all_scopes_i:\n                            if j != x:\n                                pending_reducts.add((j, x))\n\n            changed_scopes_i = set()\n\n        return _create_phase()", "response": "Attempt to solve the phase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new copy of the phase with conflict requests detected and packages correctly ordered.", "response": "def finalise(self):\n        \"\"\"Remove conflict requests, detect cyclic dependencies, and reorder\n        packages wrt dependency and then request order.\n\n        Returns:\n            A new copy of the phase with conflict requests removed and packages\n            correctly ordered; or, if cyclic dependencies were detected, a new\n            phase marked as cyclic.\n        \"\"\"\n        assert(self._is_solved())\n        g = self._get_minimal_graph()\n        scopes = dict((x.package_name, x) for x in self.scopes\n                      if not x.package_request.conflict)\n\n        # check for cyclic dependencies\n        fam_cycle = find_cycle(g)\n        if fam_cycle:\n            cycle = []\n            for fam in fam_cycle:\n                scope = scopes[fam]\n                variant = scope._get_solved_variant()\n                stmt = VersionedObject.construct(fam, variant.version)\n                cycle.append(stmt)\n\n            phase = copy.copy(self)\n            phase.scopes = scopes.values()\n            phase.failure_reason = Cycle(cycle)\n            phase.status = SolverStatus.cyclic\n            return phase\n\n        # reorder wrt dependencies, keeping original request order where possible\n        fams = [x.name for x in self.solver.request_list]\n        ordered_fams = _get_dependency_order(g, fams)\n\n        scopes_ = []\n        for fam in ordered_fams:\n            scope = scopes[fam]\n            if not scope.package_request.conflict:\n                scopes_.append(scope)\n\n        phase = copy.copy(self)\n        phase.scopes = scopes_\n        return phase"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting the phase into two sets of _ResolvePhase objects.", "response": "def split(self):\n        \"\"\"Split the phase.\n\n        When a phase is exhausted, it gets split into a pair of phases to be\n        further solved. The split happens like so:\n        1) Select the first unsolved package scope.\n        2) Find some common dependency in the first N variants of the scope.\n        3) Split the scope into two: [:N] and [N:].\n        4) Create two copies of the phase, containing each half of the split\n           scope.\n\n        The result of this split is that we have a new phase (the first phase),\n        which contains a package scope with a common dependency. This\n        dependency can now be intersected with the current resolve, thus\n        progressing it.\n\n        Returns:\n            A 2-tuple of _ResolvePhase objects, where the first phase is the\n            best contender for resolving.\n        \"\"\"\n        assert(self.status == SolverStatus.exhausted)\n\n        scopes = []\n        next_scopes = []\n        split_i = None\n\n        for i, scope in enumerate(self.scopes):\n            if split_i is None:\n                r = scope.split()\n                if r is not None:\n                    scope_, next_scope = r\n                    scopes.append(scope_)\n                    next_scopes.append(next_scope)\n                    split_i = i\n                    continue\n\n            scopes.append(scope)\n            next_scopes.append(scope)\n\n        assert split_i is not None\n\n        phase = copy.copy(self)\n        phase.scopes = scopes\n        phase.status = SolverStatus.pending\n        phase.changed_scopes_i = set([split_i])\n\n        # because a scope was narrowed by a split, other scopes need to be\n        # reduced against it\n        #for i in range(len(phase.scopes)):\n        #    if i != split_i:\n        #        phase.pending_reducts.add((i, split_i))\n\n        next_phase = copy.copy(phase)\n        next_phase.scopes = next_scopes\n        return (phase, next_phase)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the resolve graph.", "response": "def get_graph(self):\n        \"\"\"Get the resolve graph.\n\n        The resolve graph shows what packages were resolved, and the\n        relationships between them. A failed phase also has a graph, which\n        will shows the conflict(s) that caused the resolve to fail.\n\n        Returns:\n            A pygraph.digraph object.\n        \"\"\"\n        g = digraph()\n        scopes = dict((x.package_name, x) for x in self.scopes)\n        failure_nodes = set()\n        request_nodes = {}  # (request, node_id)\n        scope_nodes = {}  # (package_name, node_id)\n\n        # -- graph creation basics\n\n        node_color = \"#F6F6F6\"\n        request_color = \"#FFFFAA\"\n        solved_color = \"#AAFFAA\"\n        node_fontsize = 10\n        counter = [1]\n\n        def _uid():\n            id_ = counter[0]\n            counter[0] += 1\n            return \"_%d\" % id_\n\n        def _add_edge(id1, id2, arrowsize=0.5):\n            e = (id1, id2)\n            if g.has_edge(e):\n                g.del_edge(e)\n            g.add_edge(e)\n            g.add_edge_attribute(e, (\"arrowsize\", str(arrowsize)))\n            return e\n\n        def _add_extraction_merge_edge(id1, id2):\n            e = _add_edge(id1, id2, 1)\n            g.add_edge_attribute(e, (\"arrowhead\", \"odot\"))\n\n        def _add_conflict_edge(id1, id2):\n            e = _add_edge(id1, id2, 1)\n            g.set_edge_label(e, \"CONFLICT\")\n            g.add_edge_attribute(e, (\"style\", \"bold\"))\n            g.add_edge_attribute(e, (\"color\", \"red\"))\n            g.add_edge_attribute(e, (\"fontcolor\", \"red\"))\n\n        def _add_cycle_edge(id1, id2):\n            e = _add_edge(id1, id2, 1)\n            g.set_edge_label(e, \"CYCLE\")\n            g.add_edge_attribute(e, (\"style\", \"bold\"))\n            g.add_edge_attribute(e, (\"color\", \"red\"))\n            g.add_edge_attribute(e, (\"fontcolor\", \"red\"))\n\n        def _add_reduct_edge(id1, id2, label):\n            e = _add_edge(id1, id2, 1)\n            g.set_edge_label(e, label)\n            g.add_edge_attribute(e, (\"fontsize\", node_fontsize))\n\n        def _add_node(label, color, style):\n            attrs = [(\"label\", label),\n                     (\"fontsize\", node_fontsize),\n                     (\"fillcolor\", color),\n                     (\"style\", '\"%s\"' % style)]\n            id_ = _uid()\n            g.add_node(id_, attrs=attrs)\n            return id_\n\n        def _add_request_node(request, initial_request=False):\n            id_ = request_nodes.get(request)\n            if id_ is not None:\n                return id_\n\n            label = str(request)\n            if initial_request:\n                color = request_color\n            else:\n                color = node_color\n\n            id_ = _add_node(label, color, \"filled,dashed\")\n            request_nodes[request] = id_\n            return id_\n\n        def _add_scope_node(scope):\n            id_ = scope_nodes.get(scope.package_name)\n            if id_ is not None:\n                return id_\n\n            variant = scope._get_solved_variant()\n            if variant:\n                label = str(variant)\n                color = solved_color\n                style = \"filled\"\n            elif scope.is_conflict:\n                label = str(scope)\n                color = node_color\n                style = \"filled,dashed\"\n            else:\n                label = str(scope)\n                color = node_color\n                style = \"filled\"\n\n            id_ = _add_node(label, color, style)\n            scope_nodes[scope.package_name] = id_\n            return id_\n\n        def _add_reduct_node(request):\n            return _add_node(str(request), node_color, \"filled,dashed\")\n\n        # -- generate the graph\n\n        # create initial request nodes\n        for request in self.solver.request_list:\n            _add_request_node(request, True)\n\n        # create scope nodes\n        for scope in self.scopes:\n            if scope.is_conflict:\n                id1 = request_nodes.get(scope.package_request)\n                if id1 is not None:\n                    # special case - a scope that matches an initial conflict request,\n                    # we switch nodes so the request node becomes a scope node\n                    scope_nodes[scope.package_name] = id1\n                    del request_nodes[scope.package_request]\n                    continue\n\n            _add_scope_node(scope)\n\n        # create (initial request -> scope) edges\n        for request in self.solver.request_list:\n            id1 = request_nodes.get(request)\n            if id1 is not None:\n                id2 = scope_nodes.get(request.name)\n                if id2 is not None:\n                    _add_edge(id1, id2)\n\n        # for solved scopes, create (scope -> requirement) edge\n        for scope in self.scopes:\n            variant = scope._get_solved_variant()\n            if variant:\n                id1 = scope_nodes[scope.package_name]\n\n                for request in variant.requires_list.requirements:\n                    id2 = _add_request_node(request)\n                    _add_edge(id1, id2)\n\n        # add extractions\n        for (src_fam, _), dest_req in self.extractions.iteritems():\n            id1 = scope_nodes.get(src_fam)\n            if id1 is not None:\n                id2 = _add_request_node(dest_req)\n                _add_edge(id1, id2)\n\n        # add extraction intersections\n        extracted_fams = set(x[1] for x in self.extractions.iterkeys())\n        for fam in extracted_fams:\n            requests = [v for k, v in self.extractions.iteritems() if k[1] == fam]\n            if len(requests) > 1:\n                reqlist = RequirementList(requests)\n                if not reqlist.conflict:\n                    merged_request = reqlist.get(fam)\n                    for request in requests:\n                        if merged_request != request:\n                            id1 = _add_request_node(request)\n                            id2 = _add_request_node(merged_request)\n                            _add_extraction_merge_edge(id1, id2)\n\n        # add conflicts\n        fr = self.failure_reason\n        if fr:\n            if isinstance(fr, DependencyConflicts):\n                for conflict in fr.conflicts:\n                    id1 = _add_request_node(conflict.dependency)\n                    id2 = scope_nodes.get(conflict.conflicting_request.name)\n                    if id2 is None:\n                        id2 = _add_request_node(conflict.conflicting_request)\n                    _add_conflict_edge(id1, id2)\n\n                    failure_nodes.add(id1)\n                    failure_nodes.add(id2)\n            elif isinstance(fr, TotalReduction):\n                if len(fr.reductions) == 1:\n                    # special case - singular total reduction\n                    reduct = fr.reductions[0]\n                    id1 = scope_nodes[reduct.name]\n                    id2 = _add_request_node(reduct.dependency)\n                    id3 = scope_nodes[reduct.conflicting_request.name]\n                    _add_edge(id1, id2)\n                    _add_conflict_edge(id2, id3)\n\n                    failure_nodes.add(id1)\n                    failure_nodes.add(id2)\n                    failure_nodes.add(id3)\n                else:\n                    for reduct in fr.reductions:\n                        id1 = scope_nodes[reduct.name]\n                        id2 = _add_reduct_node(reduct.dependency)\n                        id3 = scope_nodes[reduct.conflicting_request.name]\n                        _add_reduct_edge(id1, id2, reduct.reducee_str())\n                        _add_conflict_edge(id2, id3)\n\n                        failure_nodes.add(id1)\n                        failure_nodes.add(id2)\n                        failure_nodes.add(id3)\n            elif isinstance(fr, Cycle):\n                for i, pkg in enumerate(fr.packages):\n                    id1 = scope_nodes[pkg.name]\n                    failure_nodes.add(id1)\n                    pkg2 = fr.packages[(i + 1) % len(fr.packages)]\n                    id2 = scope_nodes[pkg2.name]\n                    _add_cycle_edge(id1, id2)\n\n        # connect leaf-node requests to a matching scope, if any\n        for request, id1 in request_nodes.iteritems():\n            if not g.neighbors(id1):  # leaf node\n                id2 = scope_nodes.get(request.name)\n                if id2 is not None:\n                    scope = scopes.get(request.name)\n                    if not request.conflicts_with(scope.package_request):\n                        _add_edge(id1, id2)\n\n        # prune nodes not related to failure\n        if self.solver.prune_unfailed and failure_nodes:\n            access_dict = accessibility(g)\n            del_nodes = set()\n\n            for n, access_nodes in access_dict.iteritems():\n                if not (set(access_nodes) & failure_nodes):\n                    del_nodes.add(n)\n\n            for n in del_nodes:\n                g.del_node(n)\n\n        return g"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the current status of the solver.", "response": "def status(self):\n        \"\"\"Return the current status of the solve.\n\n        Returns:\n          SolverStatus: Enum representation of the state of the solver.\n        \"\"\"\n        if self.request_list.conflict:\n            return SolverStatus.failed\n\n        if self.callback_return == SolverCallbackReturn.fail:\n            # the solve has failed because a callback has nominated the most\n            # recent failure as the reason.\n            return SolverStatus.failed\n\n        st = self.phase_stack[-1].status\n        if st == SolverStatus.cyclic:\n            return SolverStatus.failed\n        elif len(self.phase_stack) > 1:\n            if st == SolverStatus.solved:\n                return SolverStatus.solved\n            else:\n                return SolverStatus.unsolved\n        elif st in (SolverStatus.pending, SolverStatus.exhausted):\n            return SolverStatus.unsolved\n        else:\n            return st"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of failed solve steps that have been executed.", "response": "def num_fails(self):\n        \"\"\"Return the number of failed solve steps that have been executed.\n        Note that num_solves is inclusive of failures.\"\"\"\n        n = len(self.failed_phase_list)\n        if self.phase_stack[-1].status in (SolverStatus.failed, SolverStatus.cyclic):\n            n += 1\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolved_packages(self):\n        if (self.status != SolverStatus.solved):\n            return None\n\n        final_phase = self.phase_stack[-1]\n        return final_phase._get_solved_variants()", "response": "Return a list of PackageVariant objects that are currently resolved."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset(self):\n        if not self.request_list.conflict:\n            phase = _ResolvePhase(self.request_list.requirements, solver=self)\n            self.pr(\"resetting...\")\n            self._init()\n            self._push_phase(phase)", "response": "Reset the solver removing any current solve."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef solve(self):\n        if self.solve_begun:\n            raise ResolveError(\"cannot run solve() on a solve that has \"\n                               \"already been started\")\n\n        t1 = time.time()\n        pt1 = package_repo_stats.package_load_time\n\n        # iteratively solve phases\n        while self.status == SolverStatus.unsolved:\n            self.solve_step()\n            if self.status == SolverStatus.unsolved and not self._do_callback():\n                break\n\n        self.load_time = package_repo_stats.package_load_time - pt1\n        self.solve_time = time.time() - t1\n\n        # print stats\n        if self.pr.verbosity > 2:\n            from pprint import pformat\n            self.pr.subheader(\"SOLVE STATS:\")\n            self.pr(pformat(self.solve_stats))\n\n        elif self.print_stats:\n            from pprint import pformat\n            data = {\"solve_stats\": self.solve_stats}\n            print >> (self.buf or sys.stdout), pformat(data)", "response": "Solve the current package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform a single solve step.", "response": "def solve_step(self):\n        \"\"\"Perform a single solve step.\n        \"\"\"\n        self.solve_begun = True\n        if self.status != SolverStatus.unsolved:\n            return\n\n        if self.pr:\n            self.pr.header(\"SOLVE #%d (%d fails so far)...\",\n                           self.solve_count + 1, self.num_fails)\n\n        phase = self._pop_phase()\n\n        if phase.status == SolverStatus.failed:  # a previously failed phase\n            self.pr(\"discarded failed phase, fetching previous unsolved phase...\")\n            self.failed_phase_list.append(phase)\n            phase = self._pop_phase()\n\n        if phase.status == SolverStatus.exhausted:\n            self.pr.subheader(\"SPLITTING:\")\n            phase, next_phase = phase.split()\n            self._push_phase(next_phase)\n            if self.pr:\n                self.pr(\"new phase: %s\", phase)\n\n        new_phase = phase.solve()\n        self.solve_count += 1\n\n        if new_phase.status == SolverStatus.failed:\n            self.pr.subheader(\"FAILED:\")\n            self._push_phase(new_phase)\n            if self.pr and len(self.phase_stack) == 1:\n                self.pr.header(\"FAIL: there is no solution\")\n\n        elif new_phase.status == SolverStatus.solved:\n            # solved, but there may be cyclic dependencies\n            self.pr.subheader(\"SOLVED:\")\n            final_phase = new_phase.finalise()\n            self._push_phase(final_phase)\n\n            if self.pr:\n                if final_phase.status == SolverStatus.cyclic:\n                    self.pr.header(\"FAIL: a cycle was detected\")\n                else:\n                    self.pr.header(\"SUCCESS\")\n\n        else:\n            self.pr.subheader(\"EXHAUSTED:\")\n            assert(new_phase.status == SolverStatus.exhausted)\n            self._push_phase(new_phase)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef failure_reason(self, failure_index=None):\n        phase, _ = self._get_failed_phase(failure_index)\n        return phase.failure_reason", "response": "Get the reason for a failure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of packages involved in a failure.", "response": "def failure_packages(self, failure_index=None):\n        \"\"\"Get packages involved in a failure.\n\n        Args:\n            failure_index: See `failure_reason`.\n\n        Returns:\n            A list of Requirement objects.\n        \"\"\"\n        phase, _ = self._get_failed_phase(failure_index)\n        fr = phase.failure_reason\n        return fr.involved_requirements() if fr else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the most recent solve graph.", "response": "def get_graph(self):\n        \"\"\"Returns the most recent solve graph.\n\n        This gives a graph showing the latest state of the solve. The specific\n        graph returned depends on the solve status. When status is:\n        unsolved: latest unsolved graph is returned;\n        solved:   final solved graph is returned;\n        failed:   most appropriate failure graph is returned (see `failure_reason`);\n        cyclic:   last failure is returned (contains cycle).\n\n        Returns:\n            A pygraph.digraph object.\n        \"\"\"\n        st = self.status\n        if st in (SolverStatus.solved, SolverStatus.unsolved):\n            phase = self._latest_nonfailed_phase()\n            return phase.get_graph()\n        else:\n            return self.get_fail_graph()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a graph showing a solve failure.", "response": "def get_fail_graph(self, failure_index=None):\n        \"\"\"Returns a graph showing a solve failure.\n\n        Args:\n            failure_index: See `failure_reason`\n\n        Returns:\n            A pygraph.digraph object.\n        \"\"\"\n        phase, _ = self._get_failed_phase(failure_index)\n        return phase.get_graph()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump(self):\n        from rez.utils.formatting import columnise\n\n        rows = []\n        for i, phase in enumerate(self.phase_stack):\n            rows.append((self._depth_label(i), phase.status, str(phase)))\n\n        print \"status: %s (%s)\" % (self.status.name, self.status.description)\n        print \"initial request: %s\" % str(self.request_list)\n        print\n        print \"solve stack:\"\n        print '\\n'.join(columnise(rows))\n\n        if self.failed_phase_list:\n            rows = []\n            for i, phase in enumerate(self.failed_phase_list):\n                rows.append((\"#%d\" % i, phase.status, str(phase)))\n            print\n            print \"previous failures:\"\n            print '\\n'.join(columnise(rows))", "response": "Print a formatted summary of the current solve state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_path_writable(path):\n    from rez.config import config\n\n    try:\n        orig_mode = os.stat(path).st_mode\n        new_mode = orig_mode\n\n        if config.make_package_temporarily_writable and \\\n                not os.access(path, os.W_OK):\n            new_mode = orig_mode | stat.S_IWUSR\n\n        # make writable\n        if new_mode != orig_mode:\n            os.chmod(path, new_mode)\n\n    except OSError:\n        # ignore access errors here, and just do nothing. It will be more\n        # intuitive for the calling code to fail on access instead.\n        #\n        orig_mode = None\n        new_mode = None\n\n    # yield, then reset mode back to original\n    try:\n        yield\n    finally:\n        if new_mode != orig_mode:\n            os.chmod(path, orig_mode)", "response": "Temporarily make path writable if possible."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_existing_path(path, topmost_path=None):\n    prev_path = None\n\n    if topmost_path:\n        topmost_path = os.path.normpath(topmost_path)\n\n    while True:\n        if os.path.exists(path):\n            return path\n\n        path = os.path.dirname(path)\n        if path == prev_path:\n            return None\n\n        if topmost_path and os.path.normpath(path) == topmost_path:\n            return None\n\n        prev_path = path", "response": "Get the longest parent path in path that exists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsafing makedirs. Works in a multithreaded scenario.", "response": "def safe_makedirs(path):\n    \"\"\"Safe makedirs.\n\n    Works in a multithreaded scenario.\n    \"\"\"\n    if not os.path.exists(path):\n        try:\n            os.makedirs(path)\n        except OSError:\n            if not os.path.exists(path):\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef safe_remove(path):\n    if not os.path.exists(path):\n        return\n\n    try:\n        if os.path.isdir(path) and not os.path.islink(path):\n            shutil.rmtree(path)\n        else:\n            os.remove(path)\n    except OSError:\n        if os.path.exists(path):\n            raise", "response": "Safely remove the given file or directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a symlink that overwrites any existing target.", "response": "def replacing_symlink(source, link_name):\n    \"\"\"Create symlink that overwrites any existing target.\n    \"\"\"\n    with make_tmp_name(link_name) as tmp_link_name:\n        os.symlink(source, tmp_link_name)\n        replace_file_or_dir(link_name, tmp_link_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replacing_copy(src, dest, follow_symlinks=False):\n    with make_tmp_name(dest) as tmp_dest:\n        if os.path.islink(src) and not follow_symlinks:\n            # special case - copy just a symlink\n            src_ = os.readlink(src)\n            os.symlink(src_, tmp_dest)\n        elif os.path.isdir(src):\n            # copy a dir\n            shutil.copytree(src, tmp_dest, symlinks=(not follow_symlinks))\n        else:\n            # copy a file\n            shutil.copy2(src, tmp_dest)\n\n        replace_file_or_dir(dest, tmp_dest)", "response": "Perform a copy that overwrites any existing target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace dest with source.", "response": "def replace_file_or_dir(dest, source):\n    \"\"\"Replace `dest` with `source`.\n\n    Acts like an `os.rename` if `dest` does not exist. Otherwise, `dest` is\n    deleted and `src` is renamed to `dest`.\n    \"\"\"\n    from rez.vendor.atomicwrites import replace_atomic\n\n    if not os.path.exists(dest):\n        try:\n            os.rename(source, dest)\n            return\n        except:\n            if not os.path.exists(dest):\n                raise\n\n    try:\n        replace_atomic(source, dest)\n        return\n    except:\n        pass\n\n    with make_tmp_name(dest) as tmp_dest:\n        os.rename(dest, tmp_dest)\n        os.rename(source, dest)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a tmp name for a file or dir.", "response": "def make_tmp_name(name):\n    \"\"\"Generates a tmp name for a file or dir.\n\n    This is a tempname that sits in the same dir as `name`. If it exists on\n    disk at context exit time, it is deleted.\n    \"\"\"\n    path, base = os.path.split(name)\n    tmp_base = \".tmp-%s-%s\" % (base, uuid4().hex)\n    tmp_name = os.path.join(path, tmp_base)\n\n    try:\n        yield tmp_name\n    finally:\n        safe_remove(tmp_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if path_a is a subdirectory of path_b.", "response": "def is_subdirectory(path_a, path_b):\n    \"\"\"Returns True if `path_a` is a subdirectory of `path_b`.\"\"\"\n    path_a = os.path.realpath(path_a)\n    path_b = os.path.realpath(path_b)\n    relative = os.path.relpath(path_a, path_b)\n    return (not relative.startswith(os.pardir + os.sep))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a symlink under path that points at source.", "response": "def find_matching_symlink(path, source):\n    \"\"\"Find a symlink under `path` that points at `source`.\n\n    If source is relative, it is considered relative to `path`.\n\n    Returns:\n        str: Name of symlink found, or None.\n    \"\"\"\n    def to_abs(target):\n        if os.path.isabs(target):\n            return target\n        else:\n            return os.path.normpath(os.path.join(path, target))\n\n    abs_source = to_abs(source)\n\n    for name in os.listdir(path):\n        linkpath = os.path.join(path, name)\n        if os.path.islink:\n            source_ = os.readlink(linkpath)\n            if to_abs(source_) == abs_source:\n                return name\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to copy with mode and replace it with dst", "response": "def copy_or_replace(src, dst):\n    '''try to copy with mode, and if it fails, try replacing\n    '''\n    try:\n        shutil.copy(src, dst)\n    except (OSError, IOError), e:\n        # It's possible that the file existed, but was owned by someone\n        # else - in that situation, shutil.copy might then fail when it\n        # tries to copy perms.\n        # However, it's possible that we have write perms to the dir -\n        # in which case, we can just delete and replace\n        import errno\n\n        if e.errno == errno.EPERM:\n            import tempfile\n            # try copying into a temporary location beside the old\n            # file - if we have perms to do that, we should have perms\n            # to then delete the old file, and move the new one into\n            # place\n            if os.path.isdir(dst):\n                dst = os.path.join(dst, os.path.basename(src))\n\n            dst_dir, dst_name = os.path.split(dst)\n            dst_temp = tempfile.mktemp(prefix=dst_name + '.', dir=dst_dir)\n            shutil.copy(src, dst_temp)\n            if not os.path.isfile(dst_temp):\n                raise RuntimeError(\n                    \"shutil.copy completed successfully, but path\"\n                    \" '%s' still did not exist\" % dst_temp)\n            os.remove(dst)\n            shutil.move(dst_temp, dst)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattempts a move to dst and attempts to delete src", "response": "def movetree(src, dst):\n    \"\"\"Attempts a move, and falls back to a copy+delete if this fails\n    \"\"\"\n    try:\n        shutil.move(src, dst)\n    except:\n        copytree(src, dst, symlinks=True, hardlinks=True)\n        shutil.rmtree(src)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the permissions mode on path but only if it differs from the current mode.", "response": "def safe_chmod(path, mode):\n    \"\"\"Set the permissions mode on path, but only if it differs from the current mode.\n    \"\"\"\n    if stat.S_IMODE(os.stat(path).st_mode) != mode:\n        os.chmod(path, mode)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode_filesystem_name(input_str):\n    if isinstance(input_str, str):\n        input_str = unicode(input_str)\n    elif not isinstance(input_str, unicode):\n        raise TypeError(\"input_str must be a basestring\")\n\n    as_is = u'abcdefghijklmnopqrstuvwxyz0123456789.-'\n    uppercase = u'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n    result = []\n    for char in input_str:\n        if char in as_is:\n            result.append(char)\n        elif char == u'_':\n            result.append('__')\n        elif char in uppercase:\n            result.append('_%s' % char.lower())\n        else:\n            utf8 = char.encode('utf8')\n            N = len(utf8)\n            if N == 1:\n                N = 0\n            HH = ''.join('%x' % ord(c) for c in utf8)\n            result.append('_%d%s' % (N, HH))\n    return ''.join(result)", "response": "Encodes an arbitrary unicode string to a generic filesystem - compatible non - unicode filename."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode a filename encoded using the rules given in encode_filesystem_name to a unicode string.", "response": "def decode_filesystem_name(filename):\n    \"\"\"Decodes a filename encoded using the rules given in encode_filesystem_name\n    to a unicode string.\n    \"\"\"\n    result = []\n    remain = filename\n    i = 0\n    while remain:\n        # use match, to ensure it matches from the start of the string...\n        match = _FILESYSTEM_TOKEN_RE.match(remain)\n        if not match:\n            raise ValueError(\"incorrectly encoded filesystem name %r\"\n                             \" (bad index: %d - %r)\" % (filename, i,\n                                                        remain[:2]))\n        match_str = match.group(0)\n        match_len = len(match_str)\n        i += match_len\n        remain = remain[match_len:]\n        match_dict = match.groupdict()\n        if match_dict['as_is']:\n            result.append(unicode(match_str))\n        elif match_dict['underscore']:\n            result.append(u'_')\n        elif match_dict['uppercase']:\n            result.append(unicode(match_dict['uppercase'].upper()))\n        elif match_dict['N']:\n            N = int(match_dict['N'])\n            if N == 0:\n                N = 1\n            # hex-encoded, so need to grab 2*N chars\n            bytes_len = 2 * N\n            i += bytes_len\n            bytes = remain[:bytes_len]\n            remain = remain[bytes_len:]\n\n            # need this check to ensure that we don't end up eval'ing\n            # something nasty...\n            if not _HEX_RE.match(bytes):\n                raise ValueError(\"Bad utf8 encoding in name %r\"\n                                 \" (bad index: %d - %r)\" % (filename, i, bytes))\n\n            bytes_repr = ''.join('\\\\x%s' % bytes[i:i + 2]\n                                 for i in xrange(0, bytes_len, 2))\n            bytes_repr = \"'%s'\" % bytes_repr\n            result.append(eval(bytes_repr).decode('utf8'))\n        else:\n            raise ValueError(\"Unrecognized match type in filesystem name %r\"\n                             \" (bad index: %d - %r)\" % (filename, i, remain[:2]))\n\n    return u''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding absolute directories starting with the given path and iterating up through all its parents until it reaches a root directory.", "response": "def walk_up_dirs(path):\n    \"\"\"Yields absolute directories starting with the given path, and iterating\n    up through all it's parents, until it reaches a root directory\"\"\"\n    prev_path = None\n    current_path = os.path.abspath(path)\n    while current_path != prev_path:\n        yield current_path\n        prev_path = current_path\n        current_path = os.path.dirname(prev_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, *args):\n        if self.prefix_char is None:\n            prefix_char = config.suite_alias_prefix_char\n        else:\n            prefix_char = self.prefix_char\n\n        if prefix_char == '':\n            # empty prefix char means we don't support the '+' args\n            return self._run_no_args(args)\n        else:\n            return self._run(prefix_char, args)", "response": "Invoke the wrapped script."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints an info message about the tool.", "response": "def print_about(self):\n        \"\"\"Print an info message about the tool.\"\"\"\n        filepath = os.path.join(self.suite_path, \"bin\", self.tool_name)\n        print \"Tool:     %s\" % self.tool_name\n        print \"Path:     %s\" % filepath\n        print \"Suite:    %s\" % self.suite_path\n\n        msg = \"%s (%r)\" % (self.context.load_path, self.context_name)\n        print \"Context:  %s\" % msg\n\n        variants = self.context.get_tool_variants(self.tool_name)\n        if variants:\n            if len(variants) > 1:\n                self._print_conflicting(variants)\n            else:\n                variant = iter(variants).next()\n                print \"Package:  %s\" % variant.qualified_package_name\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_package_versions(self):\n        variants = self.context.get_tool_variants(self.tool_name)\n        if variants:\n            if len(variants) > 1:\n                self._print_conflicting(variants)\n                return 1\n            else:\n                from rez.packages_ import iter_packages\n                variant = iter(variants).next()\n                it = iter_packages(name=variant.name)\n                rows = []\n                colors = []\n\n                for pkg in sorted(it, key=lambda x: x.version, reverse=True):\n                    if pkg.version == variant.version:\n                        name = \"* %s\" % pkg.qualified_name\n                        col = heading\n                    else:\n                        name = \"  %s\" % pkg.qualified_name\n                        col = local if pkg.is_local else None\n\n                    label = \"(local)\" if pkg.is_local else \"\"\n                    rows.append((name, pkg.path, label))\n                    colors.append(col)\n\n                _pr = Printer()\n                for col, line in zip(colors, columnise(rows)):\n                    _pr(line, col)\n        return 0", "response": "Print a list of versions of the package this tool comes from and the andical version of the package this tool comes from."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random node - level graph.", "response": "def generate(num_nodes, num_edges, directed=False, weight_range=(1, 1)):\n    \"\"\"\n    Create a random graph.\n    \n    @type  num_nodes: number\n    @param num_nodes: Number of nodes.\n    \n    @type  num_edges: number\n    @param num_edges: Number of edges.\n    \n    @type  directed: bool\n    @param directed: Whether the generated graph should be directed or not.  \n\n    @type  weight_range: tuple\n    @param weight_range: tuple of two integers as lower and upper limits on randomly generated\n    weights (uniform distribution).\n    \"\"\"\n    # Graph creation\n    if directed:\n        random_graph = digraph()\n    else:\n        random_graph = graph()\n\n    # Nodes\n    nodes = range(num_nodes)\n    random_graph.add_nodes(nodes)\n    \n    # Build a list of all possible edges\n    edges = []\n    edges_append = edges.append\n    for x in nodes:\n        for y in nodes:\n            if ((directed and x != y) or (x > y)):\n                edges_append((x, y))\n    \n    # Randomize the list\n    shuffle(edges)\n    \n    # Add edges to the graph\n    min_wt = min(weight_range)\n    max_wt = max(weight_range)\n    for i in range(num_edges):\n        each = edges[i]\n        random_graph.add_edge((each[0], each[1]), wt = randint(min_wt, max_wt))\n\n    return random_graph"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_hypergraph(num_nodes, num_edges, r = 0):\n    # Graph creation\n    random_graph = hypergraph()\n    \n    # Nodes\n    nodes = list(map(str, list(range(num_nodes))))\n    random_graph.add_nodes(nodes)\n    \n    # Base edges\n    edges = list(map(str, list(range(num_nodes, num_nodes+num_edges))))\n    random_graph.add_hyperedges(edges)\n    \n    # Connect the edges\n    if 0 == r:\n        # Add each edge with 50/50 probability\n        for e in edges:\n            for n in nodes:\n                if choice([True, False]):\n                    random_graph.link(n, e)\n    \n    else:\n        # Add only uniform edges\n        for e in edges:\n            # First shuffle the nodes\n            shuffle(nodes)\n            \n            # Then take the first r nodes\n            for i in range(r):\n                random_graph.link(nodes[i], e)\n    \n    return random_graph", "response": "Generate a random hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_version(version, range_=None):\n    if range_ and version not in range_:\n        raise RezBindError(\"found version %s is not within range %s\"\n                           % (str(version), str(range_)))", "response": "Checks that the found software version is within the supplied range."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind an executable. Args: name: Name of the program, eg 'python'. filepath: Path to executable, a search is performed if None. Returns: Path to the executable if found, otherwise an error is raised.", "response": "def find_exe(name, filepath=None):\n    \"\"\"Find an executable.\n\n    Args:\n        name: Name of the program, eg 'python'.\n        filepath: Path to executable, a search is performed if None.\n\n    Returns:\n        Path to the executable if found, otherwise an error is raised.\n    \"\"\"\n    if filepath:\n        if not os.path.exists(filepath):\n            open(filepath)  # raise IOError\n        elif not os.path.isfile(filepath):\n            raise RezBindError(\"not a file: %s\" % filepath)\n    else:\n        filepath = which(name)\n        if not filepath:\n            raise RezBindError(\"could not find executable: %s\" % name)\n\n    return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning an executable and get the program version.", "response": "def extract_version(exepath, version_arg, word_index=-1, version_rank=3):\n    \"\"\"Run an executable and get the program version.\n\n    Args:\n        exepath: Filepath to executable.\n        version_arg: Arg to pass to program, eg \"-V\". Can also be a list.\n        word_index: Expect the Nth word of output to be the version.\n        version_rank: Cap the version to this many tokens.\n\n    Returns:\n        `Version` object.\n    \"\"\"\n    if isinstance(version_arg, basestring):\n        version_arg = [version_arg]\n    args = [exepath] + version_arg\n\n    stdout, stderr, returncode = _run_command(args)\n    if returncode:\n        raise RezBindError(\"failed to execute %s: %s\\n(error code %d)\"\n                           % (exepath, stderr, returncode))\n\n    stdout = stdout.strip().split('\\n')[0].strip()\n    log(\"extracting version from output: '%s'\" % stdout)\n\n    try:\n        strver = stdout.split()[word_index]\n        toks = strver.replace('.', ' ').replace('-', ' ').split()\n        strver = '.'.join(toks[:version_rank])\n        version = Version(strver)\n    except Exception as e:\n        raise RezBindError(\"failed to parse version from output '%s': %s\"\n                           % (stdout, str(e)))\n\n    log(\"extracted version: '%s'\" % str(version))\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a VersionedObject directly from an object name and version.", "response": "def construct(cls, name, version=None):\n        \"\"\"Create a VersionedObject directly from an object name and version.\n\n        Args:\n            name: Object name string.\n            version: Version object.\n        \"\"\"\n        other = VersionedObject(None)\n        other.name_ = name\n        other.version_ = Version() if version is None else version\n        return other"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct(cls, name, range=None):\n        other = Requirement(None)\n        other.name_ = name\n        other.range_ = VersionRange() if range is None else range\n        return other", "response": "Constructs a requirement directly from an object name and VersionRange object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if this requirement conflicts with another Requirement or VersionedObject.", "response": "def conflicts_with(self, other):\n        \"\"\"Returns True if this requirement conflicts with another `Requirement`\n        or `VersionedObject`.\"\"\"\n        if isinstance(other, Requirement):\n            if (self.name_ != other.name_) or (self.range is None) \\\n                    or (other.range is None):\n                return False\n            elif self.conflict:\n                return False if other.conflict \\\n                    else self.range_.issuperset(other.range_)\n            elif other.conflict:\n                return other.range_.issuperset(self.range_)\n            else:\n                return not self.range_.intersects(other.range_)\n        else:  # VersionedObject\n            if (self.name_ != other.name_) or (self.range is None):\n                return False\n            if self.conflict:\n                return (other.version_ in self.range_)\n            else:\n                return (other.version_ not in self.range_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the merged result of two requirements.", "response": "def merged(self, other):\n        \"\"\"Returns the merged result of two requirements.\n\n        Two requirements can be in conflict and if so, this function returns\n        None. For example, requests for \"foo-4\" and \"foo-6\" are in conflict,\n        since both cannot be satisfied with a single version of foo.\n\n        Some example successful requirements merges are:\n        - \"foo-3+\" and \"!foo-5+\" == \"foo-3+<5\"\n        - \"foo-1\" and \"foo-1.5\" == \"foo-1.5\"\n        - \"!foo-2\" and \"!foo-5\" == \"!foo-2|5\"\n        \"\"\"\n        if self.name_ != other.name_:\n            return None  # cannot merge across object names\n\n        def _r(r_):\n            r = Requirement(None)\n            r.name_ = r_.name_\n            r.negate_ = r_.negate_\n            r.conflict_ = r_.conflict_\n            r.sep_ = r_.sep_\n            return r\n\n        if self.range is None:\n            return other\n        elif other.range is None:\n            return self\n        elif self.conflict:\n            if other.conflict:\n                r = _r(self)\n                r.range_ = self.range_ | other.range_\n                r.negate_ = (self.negate_ and other.negate_\n                             and not r.range_.is_any())\n                return r\n            else:\n                range_ = other.range - self.range\n                if range_ is None:\n                    return None\n                else:\n                    r = _r(other)\n                    r.range_ = range_\n                    return r\n        elif other.conflict:\n            range_ = self.range_ - other.range_\n            if range_ is None:\n                return None\n            else:\n                r = _r(self)\n                r.range_ = range_\n                return r\n        else:\n            range_ = self.range_ & other.range_\n            if range_ is None:\n                return None\n            else:\n                r = _r(self)\n                r.range_ = range_\n                return r"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_graph_from_string(txt):\n    if not txt.startswith('{'):\n        return read_dot(txt)  # standard dot format\n\n    def conv(value):\n        if isinstance(value, basestring):\n            return '\"' + value + '\"'\n        else:\n            return value\n\n    # our compacted format\n    doc = literal_eval(txt)\n    g = digraph()\n\n    for attrs, values in doc.get(\"nodes\", []):\n        attrs = [(k, conv(v)) for k, v in attrs]\n\n        for value in values:\n            if isinstance(value, basestring):\n                node_name = value\n                attrs_ = attrs\n            else:\n                node_name, label = value\n                attrs_ = attrs + [(\"label\", conv(label))]\n\n            g.add_node(node_name, attrs=attrs_)\n\n    for attrs, values in doc.get(\"edges\", []):\n        attrs_ = [(k, conv(v)) for k, v in attrs]\n\n        for value in values:\n            if len(value) == 3:\n                edge = value[:2]\n                label = value[-1]\n            else:\n                edge = value\n                label = ''\n\n            g.add_edge(edge, label=label, attrs=attrs_)\n\n    return g", "response": "Read a graph from a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a graph in our own compacted format.", "response": "def write_compacted(g):\n    \"\"\"Write a graph in our own compacted format.\n\n    Returns:\n        str.\n    \"\"\"\n    d_nodes = {}\n    d_edges = {}\n\n    def conv(value):\n        if isinstance(value, basestring):\n            return value.strip('\"')\n        else:\n            return value\n\n    for node in g.nodes():\n        label = None\n        attrs = []\n\n        for k, v in sorted(g.node_attributes(node)):\n            v_ = conv(v)\n            if k == \"label\":\n                label = v_\n            else:\n                attrs.append((k, v_))\n\n        value = (node, label) if label else node\n        d_nodes.setdefault(tuple(attrs), []).append(value)\n\n    for edge in g.edges():\n        attrs = [(k, conv(v)) for k, v in sorted(g.edge_attributes(edge))]\n        label = str(g.edge_label(edge))\n        value = tuple(list(edge) + [label]) if label else edge\n        d_edges.setdefault(tuple(attrs), []).append(tuple(value))\n\n    doc = dict(nodes=d_nodes.items(), edges=d_edges.items())\n    contents = str(doc)\n    return contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prune_graph(graph_str, package_name):\n    # find nodes of interest\n    g = read_dot(graph_str)\n    nodes = set()\n\n    for node, attrs in g.node_attr.iteritems():\n        attr = [x for x in attrs if x[0] == \"label\"]\n        if attr:\n            label = attr[0][1]\n            try:\n                req_str = _request_from_label(label)\n                request = PackageRequest(req_str)\n            except PackageRequestError:\n                continue\n\n            if request.name == package_name:\n                nodes.add(node)\n\n    if not nodes:\n        raise ValueError(\"The package %r does not appear in the graph.\"\n                         % package_name)\n\n    # find nodes upstream from these nodes\n    g_rev = g.reverse()\n    accessible_nodes = set()\n    access = accessibility(g_rev)\n    for node in nodes:\n        nodes_ = access.get(node, [])\n        accessible_nodes |= set(nodes_)\n\n    # remove inaccessible nodes\n    inaccessible_nodes = set(g.nodes()) - accessible_nodes\n    for node in inaccessible_nodes:\n        g.del_node(node)\n\n    return write_dot(g)", "response": "Prune a package graph so it only contains nodes accessible from the\n    given package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender a graph string to an image file.", "response": "def save_graph(graph_str, dest_file, fmt=None, image_ratio=None):\n    \"\"\"Render a graph to an image file.\n\n    Args:\n        graph_str (str): Dot-language graph string.\n        dest_file (str): Filepath to save the graph to.\n        fmt (str): Format, eg \"png\", \"jpg\".\n        image_ratio (float): Image ratio.\n\n    Returns:\n        String representing format that was written, such as 'png'.\n    \"\"\"\n    g = pydot.graph_from_dot_data(graph_str)\n\n    # determine the dest format\n    if fmt is None:\n        fmt = os.path.splitext(dest_file)[1].lower().strip('.') or \"png\"\n    if hasattr(g, \"write_\" + fmt):\n        write_fn = getattr(g, \"write_\" + fmt)\n    else:\n        raise Exception(\"Unsupported graph format: '%s'\" % fmt)\n\n    if image_ratio:\n        g.set_ratio(str(image_ratio))\n    write_fn(dest_file)\n    return fmt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nview a dot graph in an image viewer.", "response": "def view_graph(graph_str, dest_file=None):\n    \"\"\"View a dot graph in an image viewer.\"\"\"\n    from rez.system import system\n    from rez.config import config\n\n    if (system.platform == \"linux\") and (not os.getenv(\"DISPLAY\")):\n        print >> sys.stderr, \"Unable to open display.\"\n        sys.exit(1)\n\n    dest_file = _write_graph(graph_str, dest_file=dest_file)\n\n    # view graph\n    viewed = False\n    prog = config.image_viewer or 'browser'\n    print \"loading image viewer (%s)...\" % prog\n\n    if config.image_viewer:\n        proc = popen([config.image_viewer, dest_file])\n        proc.wait()\n        viewed = not bool(proc.returncode)\n\n    if not viewed:\n        import webbrowser\n        webbrowser.open_new(\"file://\" + dest_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of physical cpu cores on the system.", "response": "def physical_cores(self):\n        \"\"\"Return the number of physical cpu cores on the system.\"\"\"\n        try:\n            return self._physical_cores_base()\n        except Exception as e:\n            from rez.utils.logging_ import print_error\n            print_error(\"Error detecting physical core count, defaulting to 1: %s\"\n                        % str(e))\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef logical_cores(self):\n        try:\n            return self._logical_cores()\n        except Exception as e:\n            from rez.utils.logging_ import print_error\n            print_error(\"Error detecting logical core count, defaulting to 1: %s\"\n                        % str(e))\n        return 1", "response": "Return the number of cpu cores as reported to the os.\n        may be different from physical_cores."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_colon_table_to_dict(cls, table_text):\n        '''Given a simple text output where each line gives a key-value pair\n      of the form \"key: value\", parse and return a dict'''\n        lines = [l.strip() for l in table_text.splitlines()]\n        lines = [l for l in lines if l]\n        pairs = [l.split(':', 1) for l in lines]\n        pairs = [(k.strip(), v.strip()) for k, v in pairs]\n        data = dict(pairs)\n        assert len(data) == len(pairs)\n        return data", "response": "Given a simple text output where each line gives a key - value pair\n      of the form key : value parse and return a dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the given text to our wrapped stream stripping any ANSICOS sequences from the text and optionally converting them into win32 calls.", "response": "def write_and_convert(self, text):\n        '''\n        Write the given text to our wrapped stream, stripping any ANSI\n        sequences from the text, and optionally converting them into win32\n        calls.\n        '''\n        cursor = 0\n        for match in self.ANSI_RE.finditer(text):\n            start, end = match.span()\n            self.write_plain_text(text, cursor, start)\n            self.convert_ansi(*match.groups())\n            cursor = end\n        self.write_plain_text(text, cursor, len(text))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy(self):\n        other = ContextModel(self._context, self.parent())\n        other._stale = self._stale\n        other._modified = self._modified\n        other.request = self.request[:]\n        other.packages_path = self.packages_path\n        other.implicit_packages = self.implicit_packages\n        other.package_filter = self.package_filter\n        other.caching = self.caching\n        other.default_patch_lock = self.default_patch_lock\n        other.patch_locks = copy.deepcopy(self.patch_locks)\n        return other", "response": "Returns a copy of the context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef package_depends_on(self, name_a, name_b):\n        assert self._context\n        if self._dependency_lookup is None:\n            self._dependency_graph = self._context.get_dependency_graph()\n            self._dependency_lookup = accessibility(self._dependency_graph)\n\n        downstream = self._dependency_lookup.get(name_a, [])\n        accessible = (name_b in downstream)\n        if accessible:\n            neighbours = self._dependency_graph.neighbors(name_a)\n            return 2 if name_b in neighbours else 1\n        else:\n            return 0", "response": "Returns the dependency information about two packages."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking the current context and the current patch locks and determine the effective requests that will be added to the main request.", "response": "def get_lock_requests(self):\n        \"\"\"Take the current context, and the current patch locks, and determine\n        the effective requests that will be added to the main request.\n\n        Returns:\n            A dict of (PatchLock, [Requirement]) tuples. Each requirement will be\n            a weak package reference. If there is no current context, an empty\n            dict will be returned.\n        \"\"\"\n        d = defaultdict(list)\n        if self._context:\n            for variant in self._context.resolved_packages:\n                name = variant.name\n                version = variant.version\n                lock = self.patch_locks.get(name)\n                if lock is None:\n                    lock = self.default_patch_lock\n\n                request = get_lock_request(name, version, lock)\n                if request is not None:\n                    d[lock].append(request)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_context(self, verbosity=0, max_fails=-1, timestamp=None,\n                        callback=None, buf=None, package_load_callback=None):\n        \"\"\"Update the current context by performing a re-resolve.\n\n        The newly resolved context is only applied if it is a successful solve.\n\n        Returns:\n            `ResolvedContext` object, which may be a successful or failed solve.\n        \"\"\"\n        package_filter = PackageFilterList.from_pod(self.package_filter)\n\n        context = ResolvedContext(\n            self.request,\n            package_paths=self.packages_path,\n            package_filter=package_filter,\n            verbosity=verbosity,\n            max_fails=max_fails,\n            timestamp=timestamp,\n            buf=buf,\n            callback=callback,\n            package_load_callback=package_load_callback,\n            caching=self.caching)\n\n        if context.success:\n            if self._context and self._context.load_path:\n                context.set_load_path(self._context.load_path)\n            self._set_context(context)\n            self._modified = True\n        return context", "response": "Update the current context by performing a re - resolve."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing the current context with another.", "response": "def set_context(self, context):\n        \"\"\"Replace the current context with another.\"\"\"\n        self._set_context(context, emit=False)\n        self._modified = (not context.load_path)\n        self.dataChanged.emit(self.CONTEXT_CHANGED |\n                              self.REQUEST_CHANGED |\n                              self.PACKAGES_PATH_CHANGED |\n                              self.LOCKS_CHANGED |\n                              self.LOADPATH_CHANGED |\n                              self.PACKAGE_FILTER_CHANGED |\n                              self.CACHING_CHANGED)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_resources_dests(resources_root, rules):\n\n    def get_rel_path(base, path):\n        # normalizes and returns a lstripped-/-separated path\n        base = base.replace(os.path.sep, '/')\n        path = path.replace(os.path.sep, '/')\n        assert path.startswith(base)\n        return path[len(base):].lstrip('/')\n\n\n    destinations = {}\n    for base, suffix, dest in rules:\n        prefix = os.path.join(resources_root, base)\n        for abs_base in iglob(prefix):\n            abs_glob = os.path.join(abs_base, suffix)\n            for abs_path in iglob(abs_glob):\n                resource_file = get_rel_path(resources_root, abs_path)\n                if dest is None:  # remove the entry if it was here\n                    destinations.pop(resource_file, None)\n                else:\n                    rel_path = get_rel_path(abs_base, abs_path)\n                    rel_dest = dest.replace(os.path.sep, '/').rstrip('/')\n                    destinations[resource_file] = rel_dest + '/' + rel_path\n    return destinations", "response": "Find destinations for resources files"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a cycle in the given graph. This function will return a list of nodes which form a cycle in the graph or an empty list if no cycle exists. @type graph: graph, digraph @param graph: Graph. @rtype: list @return: List of nodes.", "response": "def find_cycle(graph):\n    \"\"\"\n    Find a cycle in the given graph.\n    \n    This function will return a list of nodes which form a cycle in the graph or an empty list if\n    no cycle exists.\n    \n    @type graph: graph, digraph\n    @param graph: Graph.\n    \n    @rtype: list\n    @return: List of nodes. \n    \"\"\"\n    \n    if (isinstance(graph, graph_class)):\n        directed = False\n    elif (isinstance(graph, digraph_class)):\n        directed = True\n    else:\n        raise InvalidGraphType\n\n    def find_cycle_to_ancestor(node, ancestor):\n        \"\"\"\n        Find a cycle containing both node and ancestor.\n        \"\"\"\n        path = []\n        while (node != ancestor):\n            if (node is None):\n                return []\n            path.append(node)\n            node = spanning_tree[node]\n        path.append(node)\n        path.reverse()\n        return path\n    \n    def dfs(node):\n        \"\"\"\n        Depth-first search subfunction.\n        \"\"\"\n        visited[node] = 1\n        # Explore recursively the connected component\n        for each in graph[node]:\n            if (cycle):\n                return\n            if (each not in visited):\n                spanning_tree[each] = node\n                dfs(each)\n            else:\n                if (directed or spanning_tree[node] != each):\n                    cycle.extend(find_cycle_to_ancestor(node, each))\n\n    recursionlimit = getrecursionlimit()\n    setrecursionlimit(max(len(graph.nodes())*2,recursionlimit))\n\n    visited = {}              # List for marking visited and non-visited nodes\n    spanning_tree = {}        # Spanning tree\n    cycle = []\n\n    # Algorithm outer-loop\n    for each in graph:\n        # Select a non-visited node\n        if (each not in visited):\n            spanning_tree[each] = None\n            # Explore node's connected component\n            dfs(each)\n            if (cycle):\n                setrecursionlimit(recursionlimit)\n                return cycle\n\n    setrecursionlimit(recursionlimit)\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new release VCS that can release from this source path.", "response": "def create_release_vcs(path, vcs_name=None):\n    \"\"\"Return a new release VCS that can release from this source path.\"\"\"\n    from rez.plugin_managers import plugin_manager\n    vcs_types = get_release_vcs_types()\n    if vcs_name:\n        if vcs_name not in vcs_types:\n            raise ReleaseVCSError(\"Unknown version control system: %r\" % vcs_name)\n        cls = plugin_manager.get_plugin_class('release_vcs', vcs_name)\n        return cls(path)\n\n    classes_by_level = {}\n    for vcs_name in vcs_types:\n        cls = plugin_manager.get_plugin_class('release_vcs', vcs_name)\n        result = cls.find_vcs_root(path)\n        if not result:\n            continue\n        vcs_path, levels_up = result\n        classes_by_level.setdefault(levels_up, []).append((cls, vcs_path))\n\n    if not classes_by_level:\n        raise ReleaseVCSError(\"No version control system for package \"\n                      \"releasing is associated with the path %s\" % path)\n\n    # it's ok to have multiple results, as long as there is only one at the\n    # \"closest\" directory up from this dir - ie, if we start at:\n    #    /blah/foo/pkg_root\n    # and these dirs exist:\n    #    /blah/.hg\n    #    /blah/foo/.git\n    # ...then this is ok, because /blah/foo/.git is \"closer\" to the original\n    # dir, and will be picked. However, if these two directories exist:\n    #    /blah/foo/.git\n    #    /blah/foo/.hg\n    # ...then we error, because we can't decide which to use\n\n    lowest_level = sorted(classes_by_level)[0]\n    clss = classes_by_level[lowest_level]\n    if len(clss) > 1:\n        clss_str = \", \".join(x[0].name() for x in clss)\n        raise ReleaseVCSError(\"Several version control systems are associated \"\n                              \"with the path %s: %s. Use rez-release --vcs to \"\n                              \"choose.\" % (path, clss_str))\n    else:\n        cls, vcs_root = clss[0]\n        return cls(pkg_root=path, vcs_root=vcs_root)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_vcs_root(cls, path):\n        if cls.search_parents_for_root():\n            valid_dirs = walk_up_dirs(path)\n        else:\n            valid_dirs = [path]\n        for i, current_path in enumerate(valid_dirs):\n            if cls.is_valid_root(current_path):\n                return current_path, i\n        return None", "response": "Try to find a version control root directory of this type for the given path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntearing down this object after we have agreed to close with the server.", "response": "def _do_close(self):\n        \"\"\"Tear down this object, after we've agreed to close\n        with the server.\"\"\"\n        AMQP_LOGGER.debug('Closed channel #%d', self.channel_id)\n        self.is_open = False\n        channel_id, self.channel_id = self.channel_id, None\n        connection, self.connection = self.connection, None\n        if connection:\n            connection.channels.pop(channel_id, None)\n            connection._avail_channel_ids.append(channel_id)\n        self.callbacks.clear()\n        self.cancel_callbacks.clear()\n        self.events.clear()\n        self.no_ack_consumers.clear()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _close(self, args):\n\n        reply_code = args.read_short()\n        reply_text = args.read_shortstr()\n        class_id = args.read_short()\n        method_id = args.read_short()\n\n        self._send_method((20, 41))\n        self._do_revive()\n\n        raise error_for_code(\n            reply_code, reply_text, (class_id, method_id), ChannelError,\n        )", "response": "This method is used to request a close of the channel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flow(self, active):\n        args = AMQPWriter()\n        args.write_bit(active)\n        self._send_method((20, 20), args)\n        return self.wait(allowed_methods=[\n            (20, 21),  # Channel.flow_ok\n        ])", "response": "Enable or disable flow from peer\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenable or disable flow from peer", "response": "def _flow(self, args):\n        \"\"\"Enable/disable flow from peer\n\n        This method asks the peer to pause or restart the flow of\n        content data. This is a simple flow-control mechanism that a\n        peer can use to avoid oveflowing its queues or otherwise\n        finding itself receiving more messages than it can process.\n        Note that this method is not intended for window control.  The\n        peer that receives a request to stop sending content should\n        finish sending the current content, if any, and then wait\n        until it receives a Flow restart method.\n\n        RULE:\n\n            When a new channel is opened, it is active.  Some\n            applications assume that channels are inactive until\n            started.  To emulate this behaviour a client MAY open the\n            channel, then pause it.\n\n        RULE:\n\n            When sending content data in multiple frames, a peer\n            SHOULD monitor the channel for incoming methods and\n            respond to a Channel.Flow as rapidly as possible.\n\n        RULE:\n\n            A peer MAY use the Channel.Flow method to throttle\n            incoming content data for internal reasons, for example,\n            when exchangeing data over a slower connection.\n\n        RULE:\n\n            The peer that requests a Channel.Flow method MAY\n            disconnect and/or ban a peer that does not respect the\n            request.\n\n        PARAMETERS:\n            active: boolean\n\n                start/stop content frames\n\n                If True, the peer starts sending content frames.  If\n                False, the peer stops sending content frames.\n\n        \"\"\"\n        self.active = args.read_bit()\n        self._x_flow_ok(self.active)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _x_flow_ok(self, active):\n        args = AMQPWriter()\n        args.write_bit(active)\n        self._send_method((20, 21), args)", "response": "Confirm a flow command was received and has been processed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _x_open(self):\n        if self.is_open:\n            return\n\n        args = AMQPWriter()\n        args.write_shortstr('')  # out_of_band: deprecated\n        self._send_method((20, 10), args)\n        return self.wait(allowed_methods=[\n            (20, 11),  # Channel.open_ok\n        ])", "response": "Open a virtual connection for use in a channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exchange_declare(self, exchange, type, passive=False, durable=False,\n                         auto_delete=True, nowait=False, arguments=None):\n        \"\"\"Declare exchange, create if needed\n\n        This method creates an exchange if it does not already exist,\n        and if the exchange exists, verifies that it is of the correct\n        and expected class.\n\n        RULE:\n\n            The server SHOULD support a minimum of 16 exchanges per\n            virtual host and ideally, impose no limit except as\n            defined by available resources.\n\n        PARAMETERS:\n            exchange: shortstr\n\n                RULE:\n\n                    Exchange names starting with \"amq.\" are reserved\n                    for predeclared and standardised exchanges.  If\n                    the client attempts to create an exchange starting\n                    with \"amq.\", the server MUST raise a channel\n                    exception with reply code 403 (access refused).\n\n            type: shortstr\n\n                exchange type\n\n                Each exchange belongs to one of a set of exchange\n                types implemented by the server.  The exchange types\n                define the functionality of the exchange - i.e. how\n                messages are routed through it.  It is not valid or\n                meaningful to attempt to change the type of an\n                existing exchange.\n\n                RULE:\n\n                    If the exchange already exists with a different\n                    type, the server MUST raise a connection exception\n                    with a reply code 507 (not allowed).\n\n                RULE:\n\n                    If the server does not support the requested\n                    exchange type it MUST raise a connection exception\n                    with a reply code 503 (command invalid).\n\n            passive: boolean\n\n                do not create exchange\n\n                If set, the server will not create the exchange.  The\n                client can use this to check whether an exchange\n                exists without modifying the server state.\n\n                RULE:\n\n                    If set, and the exchange does not already exist,\n                    the server MUST raise a channel exception with\n                    reply code 404 (not found).\n\n            durable: boolean\n\n                request a durable exchange\n\n                If set when creating a new exchange, the exchange will\n                be marked as durable.  Durable exchanges remain active\n                when a server restarts. Non-durable exchanges\n                (transient exchanges) are purged if/when a server\n                restarts.\n\n                RULE:\n\n                    The server MUST support both durable and transient\n                    exchanges.\n\n                RULE:\n\n                    The server MUST ignore the durable field if the\n                    exchange already exists.\n\n            auto_delete: boolean\n\n                auto-delete when unused\n\n                If set, the exchange is deleted when all queues have\n                finished using it.\n\n                RULE:\n\n                    The server SHOULD allow for a reasonable delay\n                    between the point when it determines that an\n                    exchange is not being used (or no longer used),\n                    and the point when it deletes the exchange.  At\n                    the least it must allow a client to create an\n                    exchange and then bind a queue to it, with a small\n                    but non-zero delay between these two actions.\n\n                RULE:\n\n                    The server MUST ignore the auto-delete field if\n                    the exchange already exists.\n\n            nowait: boolean\n\n                do not send a reply method\n\n                If set, the server will not respond to the method. The\n                client should not wait for a reply method.  If the\n                server could not complete the method it will raise a\n                channel or connection exception.\n\n            arguments: table\n\n                arguments for declaration\n\n                A set of arguments for the declaration. The syntax and\n                semantics of these arguments depends on the server\n                implementation.  This field is ignored if passive is\n                True.\n\n        \"\"\"\n        arguments = {} if arguments is None else arguments\n        args = AMQPWriter()\n        args.write_short(0)\n        args.write_shortstr(exchange)\n        args.write_shortstr(type)\n        args.write_bit(passive)\n        args.write_bit(durable)\n        args.write_bit(auto_delete)\n        args.write_bit(False)  # internal: deprecated\n        args.write_bit(nowait)\n        args.write_table(arguments)\n        self._send_method((40, 10), args)\n\n        if auto_delete:\n            warn(VDeprecationWarning(EXCHANGE_AUTODELETE_DEPRECATED))\n\n        if not nowait:\n            return self.wait(allowed_methods=[\n                (40, 11),  # Channel.exchange_declare_ok\n            ])", "response": "Declare exchange create if needed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeclaring queue, create if needed This method creates or checks a queue. When creating a new queue the client can specify various properties that control the durability of the queue and its contents, and the level of sharing for the queue. RULE: The server MUST create a default binding for a newly- created queue to the default exchange, which is an exchange of type 'direct'. RULE: The server SHOULD support a minimum of 256 queues per virtual host and ideally, impose no limit except as defined by available resources. PARAMETERS: queue: shortstr RULE: The queue name MAY be empty, in which case the server MUST create a new queue with a unique generated name and return this to the client in the Declare-Ok method. RULE: Queue names starting with \"amq.\" are reserved for predeclared and standardised server queues. If the queue name starts with \"amq.\" and the passive option is False, the server MUST raise a connection exception with reply code 403 (access refused). passive: boolean do not create queue If set, the server will not create the queue. The client can use this to check whether a queue exists without modifying the server state. RULE: If set, and the queue does not already exist, the server MUST respond with a reply code 404 (not found) and raise a channel exception. durable: boolean request a durable queue If set when creating a new queue, the queue will be marked as durable. Durable queues remain active when a server restarts. Non-durable queues (transient queues) are purged if/when a server restarts. Note that durable queues do not necessarily hold persistent messages, although it does not make sense to send persistent messages to a transient queue. RULE: The server MUST recreate the durable queue after a restart. RULE: The server MUST support both durable and transient queues. RULE: The server MUST ignore the durable field if the queue already exists. exclusive: boolean request an exclusive queue Exclusive queues may only be consumed from by the current connection. Setting the 'exclusive' flag always implies 'auto-delete'. RULE: The server MUST support both exclusive (private) and non-exclusive (shared) queues. RULE: The server MUST raise a channel exception if 'exclusive' is specified and the queue already exists and is owned by a different connection. auto_delete: boolean auto-delete queue when unused If set, the queue is deleted when all consumers have finished using it. Last consumer can be cancelled either explicitly or because its channel is closed. If there was no consumer ever on the queue, it won't be deleted. RULE: The server SHOULD allow for a reasonable delay between the point when it determines that a queue is not being used (or no longer used), and the point when it deletes the queue. At the least it must allow a client to create a queue and then create a consumer to read from it, with a small but non-zero delay between these two actions. The server should equally allow for clients that may be disconnected prematurely, and wish to re- consume from the same queue without losing messages. We would recommend a configurable timeout, with a suitable default value being one minute. RULE: The server MUST ignore the auto-delete field if the queue already exists. nowait: boolean do not send a reply method If set, the server will not respond to the method. The client should not wait for a reply method. If the server could not complete the method it will raise a channel or connection exception. arguments: table arguments for declaration A set of arguments for the declaration. The syntax and semantics of these arguments depends on the server implementation. This field is ignored if passive is True. Returns a tuple containing 3 items: the name of the queue (essential for automatically-named queues) message count consumer count", "response": "def queue_declare(self, queue='', passive=False, durable=False,\n                      exclusive=False, auto_delete=True, nowait=False,\n                      arguments=None):\n        \"\"\"Declare queue, create if needed\n\n        This method creates or checks a queue.  When creating a new\n        queue the client can specify various properties that control\n        the durability of the queue and its contents, and the level of\n        sharing for the queue.\n\n        RULE:\n\n            The server MUST create a default binding for a newly-\n            created queue to the default exchange, which is an\n            exchange of type 'direct'.\n\n        RULE:\n\n            The server SHOULD support a minimum of 256 queues per\n            virtual host and ideally, impose no limit except as\n            defined by available resources.\n\n        PARAMETERS:\n            queue: shortstr\n\n                RULE:\n\n                    The queue name MAY be empty, in which case the\n                    server MUST create a new queue with a unique\n                    generated name and return this to the client in\n                    the Declare-Ok method.\n\n                RULE:\n\n                    Queue names starting with \"amq.\" are reserved for\n                    predeclared and standardised server queues.  If\n                    the queue name starts with \"amq.\" and the passive\n                    option is False, the server MUST raise a connection\n                    exception with reply code 403 (access refused).\n\n            passive: boolean\n\n                do not create queue\n\n                If set, the server will not create the queue.  The\n                client can use this to check whether a queue exists\n                without modifying the server state.\n\n                RULE:\n\n                    If set, and the queue does not already exist, the\n                    server MUST respond with a reply code 404 (not\n                    found) and raise a channel exception.\n\n            durable: boolean\n\n                request a durable queue\n\n                If set when creating a new queue, the queue will be\n                marked as durable.  Durable queues remain active when\n                a server restarts. Non-durable queues (transient\n                queues) are purged if/when a server restarts.  Note\n                that durable queues do not necessarily hold persistent\n                messages, although it does not make sense to send\n                persistent messages to a transient queue.\n\n                RULE:\n\n                    The server MUST recreate the durable queue after a\n                    restart.\n\n                RULE:\n\n                    The server MUST support both durable and transient\n                    queues.\n\n                RULE:\n\n                    The server MUST ignore the durable field if the\n                    queue already exists.\n\n            exclusive: boolean\n\n                request an exclusive queue\n\n                Exclusive queues may only be consumed from by the\n                current connection. Setting the 'exclusive' flag\n                always implies 'auto-delete'.\n\n                RULE:\n\n                    The server MUST support both exclusive (private)\n                    and non-exclusive (shared) queues.\n\n                RULE:\n\n                    The server MUST raise a channel exception if\n                    'exclusive' is specified and the queue already\n                    exists and is owned by a different connection.\n\n            auto_delete: boolean\n\n                auto-delete queue when unused\n\n                If set, the queue is deleted when all consumers have\n                finished using it. Last consumer can be cancelled\n                either explicitly or because its channel is closed. If\n                there was no consumer ever on the queue, it won't be\n                deleted.\n\n                RULE:\n\n                    The server SHOULD allow for a reasonable delay\n                    between the point when it determines that a queue\n                    is not being used (or no longer used), and the\n                    point when it deletes the queue.  At the least it\n                    must allow a client to create a queue and then\n                    create a consumer to read from it, with a small\n                    but non-zero delay between these two actions.  The\n                    server should equally allow for clients that may\n                    be disconnected prematurely, and wish to re-\n                    consume from the same queue without losing\n                    messages.  We would recommend a configurable\n                    timeout, with a suitable default value being one\n                    minute.\n\n                RULE:\n\n                    The server MUST ignore the auto-delete field if\n                    the queue already exists.\n\n            nowait: boolean\n\n                do not send a reply method\n\n                If set, the server will not respond to the method. The\n                client should not wait for a reply method.  If the\n                server could not complete the method it will raise a\n                channel or connection exception.\n\n            arguments: table\n\n                arguments for declaration\n\n                A set of arguments for the declaration. The syntax and\n                semantics of these arguments depends on the server\n                implementation.  This field is ignored if passive is\n                True.\n\n        Returns a tuple containing 3 items:\n            the name of the queue (essential for automatically-named queues)\n            message count\n            consumer count\n\n        \"\"\"\n        arguments = {} if arguments is None else arguments\n        args = AMQPWriter()\n        args.write_short(0)\n        args.write_shortstr(queue)\n        args.write_bit(passive)\n        args.write_bit(durable)\n        args.write_bit(exclusive)\n        args.write_bit(auto_delete)\n        args.write_bit(nowait)\n        args.write_table(arguments)\n        self._send_method((50, 10), args)\n\n        if not nowait:\n            return self.wait(allowed_methods=[\n                (50, 11),  # Channel.queue_declare_ok\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfirm a queue definition This method confirms a Declare method and confirms the name of the queue, essential for automatically-named queues. PARAMETERS: queue: shortstr Reports the name of the queue. If the server generated a queue name, this field contains that name. message_count: long number of messages in queue Reports the number of messages in the queue, which will be zero for newly-created queues. consumer_count: long number of consumers Reports the number of active consumers for the queue. Note that consumers can suspend activity (Channel.Flow) in which case they do not appear in this count.", "response": "def _queue_declare_ok(self, args):\n        \"\"\"Confirms a queue definition\n\n        This method confirms a Declare method and confirms the name of\n        the queue, essential for automatically-named queues.\n\n        PARAMETERS:\n            queue: shortstr\n\n                Reports the name of the queue. If the server generated\n                a queue name, this field contains that name.\n\n            message_count: long\n\n                number of messages in queue\n\n                Reports the number of messages in the queue, which\n                will be zero for newly-created queues.\n\n            consumer_count: long\n\n                number of consumers\n\n                Reports the number of active consumers for the queue.\n                Note that consumers can suspend activity\n                (Channel.Flow) in which case they do not appear in\n                this count.\n\n        \"\"\"\n        return queue_declare_ok_t(\n            args.read_shortstr(),\n            args.read_long(),\n            args.read_long(),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef queue_delete(self, queue='',\n                     if_unused=False, if_empty=False, nowait=False):\n        \"\"\"Delete a queue\n\n        This method deletes a queue.  When a queue is deleted any\n        pending messages are sent to a dead-letter queue if this is\n        defined in the server configuration, and all consumers on the\n        queue are cancelled.\n\n        RULE:\n\n            The server SHOULD use a dead-letter queue to hold messages\n            that were pending on a deleted queue, and MAY provide\n            facilities for a system administrator to move these\n            messages back to an active queue.\n\n        PARAMETERS:\n            queue: shortstr\n\n                Specifies the name of the queue to delete. If the\n                queue name is empty, refers to the current queue for\n                the channel, which is the last declared queue.\n\n                RULE:\n\n                    If the client did not previously declare a queue,\n                    and the queue name in this method is empty, the\n                    server MUST raise a connection exception with\n                    reply code 530 (not allowed).\n\n                RULE:\n\n                    The queue must exist. Attempting to delete a non-\n                    existing queue causes a channel exception.\n\n            if_unused: boolean\n\n                delete only if unused\n\n                If set, the server will only delete the queue if it\n                has no consumers. If the queue has consumers the\n                server does does not delete it but raises a channel\n                exception instead.\n\n                RULE:\n\n                    The server MUST respect the if-unused flag when\n                    deleting a queue.\n\n            if_empty: boolean\n\n                delete only if empty\n\n                If set, the server will only delete the queue if it\n                has no messages. If the queue is not empty the server\n                raises a channel exception.\n\n            nowait: boolean\n\n                do not send a reply method\n\n                If set, the server will not respond to the method. The\n                client should not wait for a reply method.  If the\n                server could not complete the method it will raise a\n                channel or connection exception.\n\n        \"\"\"\n        args = AMQPWriter()\n        args.write_short(0)\n        args.write_shortstr(queue)\n        args.write_bit(if_unused)\n        args.write_bit(if_empty)\n        args.write_bit(nowait)\n        self._send_method((50, 40), args)\n\n        if not nowait:\n            return self.wait(allowed_methods=[\n                (50, 41),  # Channel.queue_delete_ok\n            ])", "response": "This method deletes a queue from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef queue_purge(self, queue='', nowait=False):\n        args = AMQPWriter()\n        args.write_short(0)\n        args.write_shortstr(queue)\n        args.write_bit(nowait)\n        self._send_method((50, 30), args)\n\n        if not nowait:\n            return self.wait(allowed_methods=[\n                (50, 31),  # Channel.queue_purge_ok\n            ])", "response": "This method deletes all messages from a queue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef basic_ack(self, delivery_tag, multiple=False):\n        args = AMQPWriter()\n        args.write_longlong(delivery_tag)\n        args.write_bit(multiple)\n        self._send_method((60, 80), args)", "response": "This method acknowledges one or more messages delivered via the Deliver or Get - Ok methods."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nends a queue consumer with a specific consumer_tag. This method is used to cancel a consumer.", "response": "def basic_cancel(self, consumer_tag, nowait=False):\n        \"\"\"End a queue consumer\n\n        This method cancels a consumer. This does not affect already\n        delivered messages, but it does mean the server will not send\n        any more messages for that consumer.  The client may receive\n        an abitrary number of messages in between sending the cancel\n        method and receiving the cancel-ok reply.\n\n        RULE:\n\n            If the queue no longer exists when the client sends a\n            cancel command, or the consumer has been cancelled for\n            other reasons, this command has no effect.\n\n        PARAMETERS:\n            consumer_tag: shortstr\n\n                consumer tag\n\n                Identifier for the consumer, valid within the current\n                connection.\n\n                RULE:\n\n                    The consumer tag is valid only within the channel\n                    from which the consumer was created. I.e. a client\n                    MUST NOT create a consumer in one channel and then\n                    use it in another.\n\n            nowait: boolean\n\n                do not send a reply method\n\n                If set, the server will not respond to the method. The\n                client should not wait for a reply method.  If the\n                server could not complete the method it will raise a\n                channel or connection exception.\n\n        \"\"\"\n        if self.connection is not None:\n            self.no_ack_consumers.discard(consumer_tag)\n            args = AMQPWriter()\n            args.write_shortstr(consumer_tag)\n            args.write_bit(nowait)\n            self._send_method((60, 30), args)\n            return self.wait(allowed_methods=[\n                (60, 31),  # Channel.basic_cancel_ok\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _basic_cancel_notify(self, args):\n        consumer_tag = args.read_shortstr()\n        callback = self._on_cancel(consumer_tag)\n        if callback:\n            callback(consumer_tag)\n        else:\n            raise ConsumerCancelled(consumer_tag, (60, 30))", "response": "Internal method to handle the cancel notification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnotifying the client of a consumer message This method delivers a message to the client, via a consumer. In the asynchronous message delivery model, the client starts a consumer using the Consume method, then the server responds with Deliver methods as and when messages arrive for that consumer. RULE: The server SHOULD track the number of times a message has been delivered to clients and when a message is redelivered a certain number of times - e.g. 5 times - without being acknowledged, the server SHOULD consider the message to be unprocessable (possibly causing client applications to abort), and move the message to a dead letter queue. PARAMETERS: consumer_tag: shortstr consumer tag Identifier for the consumer, valid within the current connection. RULE: The consumer tag is valid only within the channel from which the consumer was created. I.e. a client MUST NOT create a consumer in one channel and then use it in another. delivery_tag: longlong server-assigned delivery tag The server-assigned and channel-specific delivery tag RULE: The delivery tag is valid only within the channel from which the message was received. I.e. a client MUST NOT receive a message on one channel and then acknowledge it on another. RULE: The server MUST NOT use a zero value for delivery tags. Zero is reserved for client use, meaning \"all messages so far received\". redelivered: boolean message is being redelivered This indicates that the message has been previously delivered to this or another client. exchange: shortstr Specifies the name of the exchange that the message was originally published to. routing_key: shortstr Message routing key Specifies the routing key name specified when the message was published.", "response": "def _basic_deliver(self, args, msg):\n        \"\"\"Notify the client of a consumer message\n\n        This method delivers a message to the client, via a consumer.\n        In the asynchronous message delivery model, the client starts\n        a consumer using the Consume method, then the server responds\n        with Deliver methods as and when messages arrive for that\n        consumer.\n\n        RULE:\n\n            The server SHOULD track the number of times a message has\n            been delivered to clients and when a message is\n            redelivered a certain number of times - e.g. 5 times -\n            without being acknowledged, the server SHOULD consider the\n            message to be unprocessable (possibly causing client\n            applications to abort), and move the message to a dead\n            letter queue.\n\n        PARAMETERS:\n            consumer_tag: shortstr\n\n                consumer tag\n\n                Identifier for the consumer, valid within the current\n                connection.\n\n                RULE:\n\n                    The consumer tag is valid only within the channel\n                    from which the consumer was created. I.e. a client\n                    MUST NOT create a consumer in one channel and then\n                    use it in another.\n\n            delivery_tag: longlong\n\n                server-assigned delivery tag\n\n                The server-assigned and channel-specific delivery tag\n\n                RULE:\n\n                    The delivery tag is valid only within the channel\n                    from which the message was received.  I.e. a client\n                    MUST NOT receive a message on one channel and then\n                    acknowledge it on another.\n\n                RULE:\n\n                    The server MUST NOT use a zero value for delivery\n                    tags.  Zero is reserved for client use, meaning \"all\n                    messages so far received\".\n\n            redelivered: boolean\n\n                message is being redelivered\n\n                This indicates that the message has been previously\n                delivered to this or another client.\n\n            exchange: shortstr\n\n                Specifies the name of the exchange that the message\n                was originally published to.\n\n            routing_key: shortstr\n\n                Message routing key\n\n                Specifies the routing key name specified when the\n                message was published.\n\n        \"\"\"\n        consumer_tag = args.read_shortstr()\n        delivery_tag = args.read_longlong()\n        redelivered = args.read_bit()\n        exchange = args.read_shortstr()\n        routing_key = args.read_shortstr()\n\n        msg.channel = self\n        msg.delivery_info = {\n            'consumer_tag': consumer_tag,\n            'delivery_tag': delivery_tag,\n            'redelivered': redelivered,\n            'exchange': exchange,\n            'routing_key': routing_key,\n        }\n\n        try:\n            fun = self.callbacks[consumer_tag]\n        except KeyError:\n            pass\n        else:\n            fun(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _basic_get_ok(self, args, msg):\n        delivery_tag = args.read_longlong()\n        redelivered = args.read_bit()\n        exchange = args.read_shortstr()\n        routing_key = args.read_shortstr()\n        message_count = args.read_long()\n\n        msg.channel = self\n        msg.delivery_info = {\n            'delivery_tag': delivery_tag,\n            'redelivered': redelivered,\n            'exchange': exchange,\n            'routing_key': routing_key,\n            'message_count': message_count\n        }\n        return msg", "response": "Provide a client with a message delivered by get - ok."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish a message This method publishes a message to a specific exchange. The message will be routed to queues as defined by the exchange configuration and distributed to any active consumers when the transaction, if any, is committed. PARAMETERS: exchange: shortstr Specifies the name of the exchange to publish to. The exchange name can be empty, meaning the default exchange. If the exchange name is specified, and that exchange does not exist, the server will raise a channel exception. RULE: The server MUST accept a blank exchange name to mean the default exchange. RULE: The exchange MAY refuse basic content in which case it MUST raise a channel exception with reply code 540 (not implemented). routing_key: shortstr Message routing key Specifies the routing key for the message. The routing key is used for routing messages depending on the exchange configuration. mandatory: boolean indicate mandatory routing This flag tells the server how to react if the message cannot be routed to a queue. If this flag is True, the server will return an unroutable message with a Return method. If this flag is False, the server silently drops the message. RULE: The server SHOULD implement the mandatory flag. immediate: boolean request immediate delivery This flag tells the server how to react if the message cannot be routed to a queue consumer immediately. If this flag is set, the server will return an undeliverable message with a Return method. If this flag is zero, the server will queue the message, but with no guarantee that it will ever be consumed. RULE: The server SHOULD implement the immediate flag.", "response": "def _basic_publish(self, msg, exchange='', routing_key='',\n                       mandatory=False, immediate=False):\n        \"\"\"Publish a message\n\n        This method publishes a message to a specific exchange. The\n        message will be routed to queues as defined by the exchange\n        configuration and distributed to any active consumers when the\n        transaction, if any, is committed.\n\n        PARAMETERS:\n            exchange: shortstr\n\n                Specifies the name of the exchange to publish to.  The\n                exchange name can be empty, meaning the default\n                exchange.  If the exchange name is specified, and that\n                exchange does not exist, the server will raise a\n                channel exception.\n\n                RULE:\n\n                    The server MUST accept a blank exchange name to\n                    mean the default exchange.\n\n                RULE:\n\n                    The exchange MAY refuse basic content in which\n                    case it MUST raise a channel exception with reply\n                    code 540 (not implemented).\n\n            routing_key: shortstr\n\n                Message routing key\n\n                Specifies the routing key for the message.  The\n                routing key is used for routing messages depending on\n                the exchange configuration.\n\n            mandatory: boolean\n\n                indicate mandatory routing\n\n                This flag tells the server how to react if the message\n                cannot be routed to a queue.  If this flag is True, the\n                server will return an unroutable message with a Return\n                method.  If this flag is False, the server silently\n                drops the message.\n\n                RULE:\n\n                    The server SHOULD implement the mandatory flag.\n\n            immediate: boolean\n\n                request immediate delivery\n\n                This flag tells the server how to react if the message\n                cannot be routed to a queue consumer immediately.  If\n                this flag is set, the server will return an\n                undeliverable message with a Return method. If this\n                flag is zero, the server will queue the message, but\n                with no guarantee that it will ever be consumed.\n\n                RULE:\n\n                    The server SHOULD implement the immediate flag.\n\n        \"\"\"\n        args = AMQPWriter()\n        args.write_short(0)\n        args.write_shortstr(exchange)\n        args.write_shortstr(routing_key)\n        args.write_bit(mandatory)\n        args.write_bit(immediate)\n\n        self._send_method((60, 40), args, msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nspecify quality of service This method requests a specific quality of service. The QoS can be specified for the current channel or for all channels on the connection. The particular properties and semantics of a qos method always depend on the content class semantics. Though the qos method could in principle apply to both peers, it is currently meaningful only for the server. PARAMETERS: prefetch_size: long prefetch window in octets The client can request that messages be sent in advance so that when the client finishes processing a message, the following message is already held locally, rather than needing to be sent down the channel. Prefetching gives a performance improvement. This field specifies the prefetch window size in octets. The server will send a message in advance if it is equal to or smaller in size than the available prefetch size (and also falls into other prefetch limits). May be set to zero, meaning \"no specific limit\", although other prefetch limits may still apply. The prefetch-size is ignored if the no-ack option is set. RULE: The server MUST ignore this setting when the client is not processing any messages - i.e. the prefetch size does not limit the transfer of single messages to a client, only the sending in advance of more messages while the client still has one or more unacknowledged messages. prefetch_count: short prefetch window in messages Specifies a prefetch window in terms of whole messages. This field may be used in combination with the prefetch-size field; a message will only be sent in advance if both prefetch windows (and those at the channel and connection level) allow it. The prefetch- count is ignored if the no-ack option is set. RULE: The server MAY send less data in advance than allowed by the client's specified prefetch windows but it MUST NOT send more. a_global: boolean apply to entire connection By default the QoS settings apply to the current channel only. If this field is set, they are applied to the entire connection.", "response": "def basic_qos(self, prefetch_size, prefetch_count, a_global):\n        \"\"\"Specify quality of service\n\n        This method requests a specific quality of service.  The QoS\n        can be specified for the current channel or for all channels\n        on the connection.  The particular properties and semantics of\n        a qos method always depend on the content class semantics.\n        Though the qos method could in principle apply to both peers,\n        it is currently meaningful only for the server.\n\n        PARAMETERS:\n            prefetch_size: long\n\n                prefetch window in octets\n\n                The client can request that messages be sent in\n                advance so that when the client finishes processing a\n                message, the following message is already held\n                locally, rather than needing to be sent down the\n                channel.  Prefetching gives a performance improvement.\n                This field specifies the prefetch window size in\n                octets.  The server will send a message in advance if\n                it is equal to or smaller in size than the available\n                prefetch size (and also falls into other prefetch\n                limits). May be set to zero, meaning \"no specific\n                limit\", although other prefetch limits may still\n                apply. The prefetch-size is ignored if the no-ack\n                option is set.\n\n                RULE:\n\n                    The server MUST ignore this setting when the\n                    client is not processing any messages - i.e. the\n                    prefetch size does not limit the transfer of\n                    single messages to a client, only the sending in\n                    advance of more messages while the client still\n                    has one or more unacknowledged messages.\n\n            prefetch_count: short\n\n                prefetch window in messages\n\n                Specifies a prefetch window in terms of whole\n                messages.  This field may be used in combination with\n                the prefetch-size field; a message will only be sent\n                in advance if both prefetch windows (and those at the\n                channel and connection level) allow it. The prefetch-\n                count is ignored if the no-ack option is set.\n\n                RULE:\n\n                    The server MAY send less data in advance than\n                    allowed by the client's specified prefetch windows\n                    but it MUST NOT send more.\n\n            a_global: boolean\n\n                apply to entire connection\n\n                By default the QoS settings apply to the current\n                channel only.  If this field is set, they are applied\n                to the entire connection.\n\n        \"\"\"\n        args = AMQPWriter()\n        args.write_long(prefetch_size)\n        args.write_short(prefetch_count)\n        args.write_bit(a_global)\n        self._send_method((60, 10), args)\n        return self.wait(allowed_methods=[\n            (60, 11),  # Channel.basic_qos_ok\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _basic_return(self, args, msg):\n        self.returned_messages.put(basic_return_t(\n            args.read_short(),\n            args.read_shortstr(),\n            args.read_shortstr(),\n            args.read_shortstr(),\n            msg,\n        ))", "response": "This method returns a failed message that was not published with the immediate flag set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef confirm_select(self, nowait=False):\n        args = AMQPWriter()\n        args.write_bit(nowait)\n\n        self._send_method((85, 10), args)\n        if not nowait:\n            self.wait(allowed_methods=[\n                (85, 11),  # Confirm.select_ok\n            ])", "response": "Enables publisher confirms for this channel."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a BuildProcess instance.", "response": "def create_build_process(process_type, working_dir, build_system, package=None,\n                         vcs=None, ensure_latest=True, skip_repo_errors=False,\n                         ignore_existing_tag=False, verbose=False, quiet=False):\n    \"\"\"Create a `BuildProcess` instance.\"\"\"\n    from rez.plugin_managers import plugin_manager\n    process_types = get_build_process_types()\n    if process_type not in process_types:\n        raise BuildProcessError(\"Unknown build process: %r\" % process_type)\n\n    cls = plugin_manager.get_plugin_class('build_process', process_type)\n\n    return cls(working_dir,  # ignored (deprecated)\n               build_system,\n               package=package,  # ignored (deprecated)\n               vcs=vcs,\n               ensure_latest=ensure_latest,\n               skip_repo_errors=skip_repo_errors,\n               ignore_existing_tag=ignore_existing_tag,\n               verbose=verbose,\n               quiet=quiet)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visit_variants(self, func, variants=None, **kwargs):\n        if variants:\n            present_variants = range(self.package.num_variants)\n            invalid_variants = set(variants) - set(present_variants)\n            if invalid_variants:\n                raise BuildError(\n                    \"The package does not contain the variants: %s\"\n                    % \", \".join(str(x) for x in sorted(invalid_variants)))\n\n        # iterate over variants\n        results = []\n        num_visited = 0\n\n        for variant in self.package.iter_variants():\n            if variants and variant.index not in variants:\n                self._print_header(\n                    \"Skipping variant %s (%s)...\"\n                    % (variant.index, self._n_of_m(variant)))\n                continue\n\n            # visit the variant\n            result = func(variant, **kwargs)\n            results.append(result)\n            num_visited += 1\n\n        return num_visited, results", "response": "Iterate over variants and call a function on each."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the installation path for a package.", "response": "def get_package_install_path(self, path):\n        \"\"\"Return the installation path for a package (where its payload goes).\n\n        Args:\n            path (str): Package repository path.\n        \"\"\"\n        from rez.package_repository import package_repository_manager\n\n        pkg_repo = package_repository_manager.get_repository(path)\n\n        return pkg_repo.get_package_payload_path(\n            package_name=self.package.name,\n            package_version=self.package.version\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a resolved context to build the variant within.", "response": "def create_build_context(self, variant, build_type, build_path):\n        \"\"\"Create a context to build the variant within.\"\"\"\n        request = variant.get_requires(build_requires=True,\n                                       private_build_requires=True)\n\n        req_strs = map(str, request)\n        quoted_req_strs = map(quote, req_strs)\n        self._print(\"Resolving build environment: %s\", ' '.join(quoted_req_strs))\n\n        if build_type == BuildType.local:\n            packages_path = self.package.config.packages_path\n        else:\n            packages_path = self.package.config.nonlocal_packages_path\n\n        if self.package.config.is_overridden(\"package_filter\"):\n            from rez.package_filter import PackageFilterList\n\n            data = self.package.config.package_filter\n            package_filter = PackageFilterList.from_pod(data)\n        else:\n            package_filter = None\n\n        context = ResolvedContext(request,\n                                  package_paths=packages_path,\n                                  package_filter=package_filter,\n                                  building=True)\n        if self.verbose:\n            context.print_info()\n\n        # save context before possible fail, so user can debug\n        rxt_filepath = os.path.join(build_path, \"build.rxt\")\n        context.save(rxt_filepath)\n\n        if context.status != ResolverStatus.solved:\n            raise BuildContextResolveError(context)\n        return context, rxt_filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_release_data(self):\n        previous_package = self.get_previous_release()\n        if previous_package:\n            previous_version = previous_package.version\n            previous_revision = previous_package.revision\n        else:\n            previous_version = None\n            previous_revision = None\n\n        if self.vcs is None:\n            return dict(vcs=\"None\",\n                        previous_version=previous_version)\n\n        revision = None\n        with self.repo_operation():\n            revision = self.vcs.get_current_revision()\n\n        changelog = self.get_changelog()\n\n        # truncate changelog - very large changelogs can cause package load\n        # times to be very high, we don't want that\n        maxlen = config.max_package_changelog_chars\n        if maxlen and changelog and len(changelog) > maxlen + 3:\n            changelog = changelog[:maxlen] + \"...\"\n\n        return dict(vcs=self.vcs.name(),\n                    revision=revision,\n                    changelog=changelog,\n                    previous_version=previous_version,\n                    previous_revision=previous_revision)", "response": "Get release data for this release."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pop(self, key, default=NONE):\n        if key in self:\n            self._list_remove(key)\n            return self._pop(key)\n        else:\n            if default is NONE:\n                raise KeyError(key)\n            else:\n                return default", "response": "Removes the entry with the given key from the dictionary. If the key is not in the dictionary a KeyError is raised. If the default is given the value is returned. If the key is not in the dictionary a KeyError is raised."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef peekitem(self, index=-1):\n        key = self._list[index]\n        return key, self[key]", "response": "Return the next item pair at index."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the dictionary with the key value pairs from *other* overwriting any existing keys.", "response": "def update(self, *args, **kwargs):\n        \"\"\"\n        Update the dictionary with the key/value pairs from *other*, overwriting\n        existing keys.\n\n        *update* accepts either another dictionary object or an iterable of\n        key/value pairs (as a tuple or other iterable of length two).  If\n        keyword arguments are specified, the dictionary is then updated with\n        those key/value pairs: ``d.update(red=1, blue=2)``.\n        \"\"\"\n        if not self:\n            self._dict_update(*args, **kwargs)\n            self._list_update(self._iter())\n            return\n\n        if not kwargs and len(args) == 1 and isinstance(args[0], dict):\n            pairs = args[0]\n        else:\n            pairs = dict(*args, **kwargs)\n\n        if (10 * len(pairs)) > len(self):\n            self._dict_update(pairs)\n            self._list_clear()\n            self._list_update(self._iter())\n        else:\n            for key in pairs:\n                self[key] = pairs[key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the index of value in the dict. Raises ValueError if value is not found.", "response": "def index(self, value):\n        \"\"\"\n        Return index of *value* in self.\n\n        Raises ValueError if *value* is not found.\n        \"\"\"\n        # pylint: disable=arguments-differ\n        for idx, val in enumerate(self):\n            if value == val:\n                return idx\n        raise ValueError('{0!r} is not in dict'.format(value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the index of the key in the set.", "response": "def index(self, key, start=None, stop=None):\n        \"\"\"\n        Return the smallest *k* such that `itemssview[k] == key` and `start <= k\n        < end`.  Raises `KeyError` if *key* is not present.  *stop* defaults\n        to the end of the set.  *start* defaults to the beginning.  Negative\n        indexes are supported, as for slice indices.\n        \"\"\"\n        # pylint: disable=arguments-differ\n        temp, value = key\n        pos = self._list.index(temp, start, stop)\n        if value == self._dict[temp]:\n            return pos\n        else:\n            raise ValueError('{0!r} is not in dict'.format(key))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef count(self, item):\n        # pylint: disable=arguments-differ\n        key, value = item\n        return 1 if key in self._dict and self._dict[key] == value else 0", "response": "Return the number of occurrences of item in the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef minimal_spanning_tree(graph, root=None):\n    visited = []            # List for marking visited and non-visited nodes\n    spanning_tree = {}        # MInimal Spanning tree\n\n    # Initialization\n    if (root is not None):\n        visited.append(root)\n        nroot = root\n        spanning_tree[root] = None\n    else:\n        nroot = 1\n    \n    # Algorithm loop\n    while (nroot is not None):\n        ledge = _lightest_edge(graph, visited)\n        if (ledge == None):\n            if (root is not None):\n                break\n            nroot = _first_unvisited(graph, visited)\n            if (nroot is not None):\n                spanning_tree[nroot] = None\n            visited.append(nroot)\n        else:\n            spanning_tree[ledge[1]] = ledge[0]\n            visited.append(ledge[1])\n\n    return spanning_tree", "response": "Minimal spanning tree.\n\n    @attention: Minimal spanning tree is meaningful only for weighted graphs.\n\n    @type  graph: graph\n    @param graph: Graph.\n    \n    @type  root: node\n    @param root: Optional root node (will explore only root's connected component)\n\n    @rtype:  dictionary\n    @return: Generated spanning tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind a maximum flow and minimum cut of a directed graph.", "response": "def maximum_flow(graph, source, sink, caps = None):\n    \"\"\"\n    Find a maximum flow and minimum cut of a directed graph by the Edmonds-Karp algorithm.\n\n    @type graph: digraph\n    @param graph: Graph\n\n    @type source: node\n    @param source: Source of the flow\n\n    @type sink: node\n    @param sink: Sink of the flow\n\n    @type caps: dictionary\n    @param caps: Dictionary specifying a maximum capacity for each edge. If not given, the weight of the edge\n    will be used as its capacity. Otherwise, for each edge (a,b), caps[(a,b)] should be given.\n    \n    @rtype: tuple\n    @return: A tuple containing two dictionaries\n        1. contains the flow through each edge for a maximal flow through the graph\n        2. contains to which component of a minimum cut each node belongs\n    \"\"\"\n\n    #handle optional argument, if weights are available, use them, if not, assume one\n    if caps == None:\n        caps = {}\n        for edge in graph.edges():\n            caps[edge] = graph.edge_weight((edge[0],edge[1]))    \n    \n    #data structures to maintain\n    f = {}.fromkeys(graph.edges(),0)    \n    label = {}.fromkeys(graph.nodes(),[])\n    label[source] = ['-',float('Inf')]\n    u = {}.fromkeys(graph.nodes(),False)\n    d = {}.fromkeys(graph.nodes(),float('Inf'))\n    #queue for labelling\n    q = [source]\n\n    finished = False\n    while not finished:\n        #choose first labelled vertex with u == false\n        for i in range(len(q)):\n            if not u[q[i]]:\n                v = q.pop(i)\n                break\n\n        #find augmenting path\n        for w in graph.neighbors(v):\n            if label[w] == [] and f[(v,w)] < caps[(v,w)]:\n                d[w] = min(caps[(v,w)] - f[(v,w)],d[v])\n                label[w] = [v,'+',d[w]]\n                q.append(w)\n        for w in graph.incidents(v):\n            if label[w] == [] and f[(w,v)] > 0:\n                d[w] = min(f[(w,v)],d[v])\n                label[w] = [v,'-',d[w]]\n                q.append(w)\n\n        u[v] = True\n\n        #extend flow by augmenting path        \n        if label[sink] != []:\n            delta = label[sink][-1]\n            w = sink\n            while w != source:\n                v = label[w][0]\n                if label[w][1] == '-':\n                    f[(w,v)] = f[(w,v)] - delta\n                else:\n                    f[(v,w)] = f[(v,w)] + delta\n                w = v\n            #reset labels\n            label = {}.fromkeys(graph.nodes(),[])\n            label[source] = ['-',float('Inf')]\n            q = [source]\n            u = {}.fromkeys(graph.nodes(),False)\n            d = {}.fromkeys(graph.nodes(),float('Inf'))\n\n        #check whether finished\n        finished = True\n        for node in graph.nodes():\n            if label[node] != [] and u[node] == False:\n                finished = False\n\n    #find the two components of the cut\n    cut = {}\n    for node in graph.nodes():\n        if label[node] == []:\n            cut[node] = 1\n        else:\n            cut[node] = 0\n    return (f,cut)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cut_value(graph, flow, cut):\n    #max flow/min cut value calculation\n    S = []\n    T = []\n    for node in cut.keys():\n        if cut[node] == 0:\n            S.append(node)\n        elif cut[node] == 1:\n            T.append(node)\n    value = 0\n    for node in S:\n        for neigh in graph.neighbors(node):\n            if neigh in T:\n                value = value + flow[(node,neigh)]\n        for inc in graph.incidents(node):\n            if inc in T:\n                value = value - flow[(inc,node)]    \n    return value", "response": "Calculate the value of a cut."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cut_tree(igraph, caps = None):\n\n    #maximum flow needs a digraph, we get a graph\n    #I think this conversion relies on implementation details outside the api and may break in the future\n    graph = digraph()\n    graph.add_graph(igraph)\n\n    #handle optional argument\n    if not caps:\n        caps = {}\n        for edge in graph.edges():\n            caps[edge] = igraph.edge_weight(edge)\n\n    #temporary flow variable\n    f = {}\n\n    #we use a numbering of the nodes for easier handling\n    n = {}\n    N = 0\n    for node in graph.nodes():\n        n[N] = node\n        N = N + 1\n\n    #predecessor function\n    p = {}.fromkeys(range(N),0)\n    p[0] = None\n\n    for s in range(1,N):\n        t = p[s]\n        S = []\n        #max flow calculation\n        (flow,cut) = maximum_flow(graph,n[s],n[t],caps)\n        for i in range(N):\n            if cut[n[i]] == 0:\n                S.append(i)\n        \n        value = cut_value(graph,flow,cut)\n\n        f[s] = value\n\n        for i in range(N):\n            if i == s:\n                continue\n            if i in S and p[i] == t:\n                p[i] = s\n        if p[t] in S:\n            p[s] = p[t]\n            p[t] = s\n            f[s] = f[t]\n            f[t] = value\n\n    #cut tree is a dictionary, where each edge is associated with its weight\n    b = {}\n    for i in range(1,N):\n        b[(n[i],n[p[i]])] = f[i]\n    return b", "response": "Construct a Gomory - Hu cut tree by applying the algorithm of Gusfield."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_url_to_download_info(self, url, project_name):\n        def same_project(name1, name2):\n            return normalize_name(name1) == normalize_name(name2)\n\n        result = None\n        scheme, netloc, path, params, query, frag = urlparse(url)\n        if frag.lower().startswith('egg='):\n            logger.debug('%s: version hint in fragment: %r',\n                         project_name, frag)\n        m = HASHER_HASH.match(frag)\n        if m:\n            algo, digest = m.groups()\n        else:\n            algo, digest = None, None\n        origpath = path\n        if path and path[-1] == '/':\n            path = path[:-1]\n        if path.endswith('.whl'):\n            try:\n                wheel = Wheel(path)\n                if is_compatible(wheel, self.wheel_tags):\n                    if project_name is None:\n                        include = True\n                    else:\n                        include = same_project(wheel.name, project_name)\n                    if include:\n                        result = {\n                            'name': wheel.name,\n                            'version': wheel.version,\n                            'filename': wheel.filename,\n                            'url': urlunparse((scheme, netloc, origpath,\n                                               params, query, '')),\n                            'python-version': ', '.join(\n                                ['.'.join(list(v[2:])) for v in wheel.pyver]),\n                        }\n            except Exception as e:\n                logger.warning('invalid path for wheel: %s', path)\n        elif path.endswith(self.downloadable_extensions):\n            path = filename = posixpath.basename(path)\n            for ext in self.downloadable_extensions:\n                if path.endswith(ext):\n                    path = path[:-len(ext)]\n                    t = self.split_filename(path, project_name)\n                    if not t:\n                        logger.debug('No match for project/version: %s', path)\n                    else:\n                        name, version, pyver = t\n                        if not project_name or same_project(project_name, name):\n                            result = {\n                                'name': name,\n                                'version': version,\n                                'filename': filename,\n                                'url': urlunparse((scheme, netloc, origpath,\n                                                   params, query, '')),\n                                #'packagetype': 'sdist',\n                            }\n                            if pyver:\n                                result['python-version'] = pyver\n                    break\n        if result and algo:\n            result['%s_digest' % algo] = digest\n        return result", "response": "Convert a URL to a dictionary of download information."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef locate(self, requirement, prereleases=False):\n        result = None\n        r = parse_requirement(requirement)\n        if r is None:\n            raise DistlibException('Not a valid requirement: %r' % requirement)\n        scheme = get_scheme(self.scheme)\n        self.matcher = matcher = scheme.matcher(r.requirement)\n        logger.debug('matcher: %s (%s)', matcher, type(matcher).__name__)\n        versions = self.get_project(r.name)\n        if len(versions) > 2:   # urls and digests keys are present\n            # sometimes, versions are invalid\n            slist = []\n            vcls = matcher.version_class\n            for k in versions:\n                if k in ('urls', 'digests'):\n                    continue\n                try:\n                    if not matcher.match(k):\n                        logger.debug('%s did not match %r', matcher, k)\n                    else:\n                        if prereleases or not vcls(k).is_prerelease:\n                            slist.append(k)\n                        else:\n                            logger.debug('skipping pre-release '\n                                         'version %s of %s', k, matcher.name)\n                except Exception:  # pragma: no cover\n                    logger.warning('error matching %s with %r', matcher, k)\n                    pass # slist.append(k)\n            if len(slist) > 1:\n                slist = sorted(slist, key=scheme.key)\n            if slist:\n                logger.debug('sorted list: %s', slist)\n                version = slist[-1]\n                result = versions[version]\n        if result:\n            if r.extras:\n                result.extras = r.extras\n            result.download_urls = versions.get('urls', {}).get(version, set())\n            d = {}\n            sd = versions.get('digests', {})\n            for url in result.download_urls:\n                if url in sd:\n                    d[url] = sd[url]\n            result.digests = d\n        self.matcher = None\n        return result", "response": "Locate the most recent distribution which matches the given requirement."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bind_modules(verbose=False):\n    builtin_path = os.path.join(module_root_path, \"bind\")\n    searchpaths = config.bind_module_path + [builtin_path]\n    bindnames = {}\n\n    for path in searchpaths:\n        if verbose:\n            print \"searching %s...\" % path\n        if not os.path.isdir(path):\n            continue\n\n        for filename in os.listdir(path):\n            fpath = os.path.join(path, filename)\n            fname, ext = os.path.splitext(filename)\n            if os.path.isfile(fpath) and ext == \".py\" \\\n                    and not fname.startswith('_'):\n                bindnames[fname] = fpath\n\n    return bindnames", "response": "Get available bind modules."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_bind_module(name, verbose=False):\n    bindnames = get_bind_modules(verbose=verbose)\n    bindfile = bindnames.get(name)\n\n    if bindfile:\n        return bindfile\n\n    if not verbose:\n        return None\n\n    # suggest close matches\n    fuzzy_matches = get_close_pkgs(name, bindnames.keys())\n\n    if fuzzy_matches:\n        rows = [(x[0], bindnames[x[0]]) for x in fuzzy_matches]\n        print \"'%s' not found. Close matches:\" % name\n        print '\\n'.join(columnise(rows))\n    else:\n        print \"No matches.\"\n\n    return None", "response": "Find the bind module matching the given name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind_package(name, path=None, version_range=None, no_deps=False,\n                 bind_args=None, quiet=False):\n    \"\"\"Bind software available on the current system, as a rez package.\n\n    Note:\n        `bind_args` is provided when software is bound via the 'rez-bind'\n        command line tool. Bind modules can define their own command line\n        options, and they will be present in `bind_args` if applicable.\n\n    Args:\n        name (str): Package name.\n        path (str): Package path to install into; local packages path if None.\n        version_range (`VersionRange`): If provided, only bind the software if\n            it falls within this version range.\n        no_deps (bool): If True, don't bind dependencies.\n        bind_args (list of str): Command line options.\n        quiet (bool): If True, suppress superfluous output.\n\n    Returns:\n        List of `Variant`: The variant(s) that were installed as a result of\n        binding this package.\n    \"\"\"\n    pending = set([name])\n    installed_variants = []\n    installed_package_names = set()\n    primary = True\n\n    # bind package and possibly dependencies\n    while pending:\n        pending_ = pending\n        pending = set()\n        exc_type = None\n\n        for name_ in pending_:\n            # turn error on binding of dependencies into a warning - we don't\n            # want to skip binding some dependencies because others failed\n            try:\n                variants_ = _bind_package(name_,\n                                          path=path,\n                                          version_range=version_range,\n                                          bind_args=bind_args,\n                                          quiet=quiet)\n            except exc_type as e:\n                print_error(\"Could not bind '%s': %s: %s\"\n                            % (name_, e.__class__.__name__, str(e)))\n                continue\n\n            installed_variants.extend(variants_)\n\n            for variant in variants_:\n                installed_package_names.add(variant.name)\n\n            # add dependencies\n            if not no_deps:\n                for variant in variants_:\n                    for requirement in variant.requires:\n                        if not requirement.conflict:\n                            pending.add(requirement.name)\n\n            # non-primary packages are treated a little differently\n            primary = False\n            version_range = None\n            bind_args = None\n            exc_type = RezBindError\n\n    if installed_variants and not quiet:\n        print \"The following packages were installed:\"\n        print\n        _print_package_list(installed_variants)\n\n    return installed_variants", "response": "Bind a software to a local package."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns priority for a given object.", "response": "def priority(s):\n    \"\"\"Return priority for a given object.\"\"\"\n    # REZ: Previously this value was calculated in place many times which is\n    #      expensive.  Do it once early.\n    # REZ: Changed this to output a list, so that can nicely sort \"validate\"\n    #      items by the sub-priority of their schema\n    type_of_s = type(s)\n    if type_of_s in (list, tuple, set, frozenset):\n        return [ITERABLE]\n    if type_of_s is dict:\n        return [DICT]\n    if issubclass(type_of_s, type):\n        return [TYPE]\n    if hasattr(s, 'validate'):\n        p = [VALIDATOR]\n        if hasattr(s, \"_schema\"):\n            p.extend(priority(s._schema))\n        return p\n    if callable(s):\n        return [CALLABLE]\n    else:\n        return [COMPARABLE]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_release_hook(name, source_path):\n    from rez.plugin_managers import plugin_manager\n    return plugin_manager.create_instance('release_hook',\n                                          name,\n                                          source_path=source_path)", "response": "Return a new release hook of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the parse would raise an error if no more arguments are given to this action.", "response": "def action_is_satisfied(action):\n    ''' Returns False if the parse would raise an error if no more arguments are given to this action, True otherwise.\n    '''\n    num_consumed_args = getattr(action, 'num_consumed_args', 0)\n\n    if action.nargs == ONE_OR_MORE and num_consumed_args < 1:\n        return False\n    else:\n        if action.nargs is None:\n            action.nargs = 1\n        try:\n            return num_consumed_args == action.nargs\n        except:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntraverses the node tree in the given order.", "response": "def traversal(graph, node, order):\n    \"\"\"\n    Graph traversal iterator.\n\n    @type  graph: graph, digraph\n    @param graph: Graph.\n    \n    @type  node: node\n    @param node: Node.\n    \n    @type  order: string\n    @param order: traversal ordering. Possible values are:\n        2. 'pre' - Preordering (default)\n        1. 'post' - Postordering\n    \n    @rtype:  iterator\n    @return: Traversal iterator.\n    \"\"\"\n    visited = {}\n    if (order == 'pre'):\n        pre = 1\n        post = 0\n    elif (order == 'post'):\n        pre = 0\n        post = 1\n    \n    for each in _dfs(graph, visited, node, pre, post):\n        yield each"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_zipfile(filename):\n    try:\n        fpin = open(filename, \"rb\")\n        endrec = _EndRecData(fpin)\n        fpin.close()\n        if endrec:\n            return True                 # file has correct magic number\n    except IOError:\n        pass\n    return False", "response": "Quickly see if a file is a ZIP file by checking the magic number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning data from the End of Central Directory record or None.", "response": "def _EndRecData(fpin):\n    \"\"\"Return data from the \"End of Central Directory\" record, or None.\n\n    The data is a list of the nine items in the ZIP \"End of central dir\"\n    record followed by a tenth item, the file seek offset of this record.\"\"\"\n\n    # Determine file size\n    fpin.seek(0, 2)\n    filesize = fpin.tell()\n\n    # Check to see if this is ZIP file with no archive comment (the\n    # \"end of central directory\" structure should be the last item in the\n    # file if this is the case).\n    try:\n        fpin.seek(-sizeEndCentDir, 2)\n    except IOError:\n        return None\n    data = fpin.read()\n    if data[0:4] == stringEndArchive and data[-2:] == \"\\000\\000\":\n        # the signature is correct and there's no comment, unpack structure\n        endrec = struct.unpack(structEndArchive, data)\n        endrec=list(endrec)\n\n        # Append a blank comment and record start offset\n        endrec.append(\"\")\n        endrec.append(filesize - sizeEndCentDir)\n\n        # Try to read the \"Zip64 end of central directory\" structure\n        return _EndRecData64(fpin, -sizeEndCentDir, endrec)\n\n    # Either this is not a ZIP file, or it is a ZIP file with an archive\n    # comment.  Search the end of the file for the \"end of central directory\"\n    # record signature. The comment is the last item in the ZIP file and may be\n    # up to 64K long.  It is assumed that the \"end of central directory\" magic\n    # number does not appear in the comment.\n    maxCommentStart = max(filesize - (1 << 16) - sizeEndCentDir, 0)\n    fpin.seek(maxCommentStart, 0)\n    data = fpin.read()\n    start = data.rfind(stringEndArchive)\n    if start >= 0:\n        # found the magic number; attempt to unpack and interpret\n        recData = data[start:start+sizeEndCentDir]\n        endrec = list(struct.unpack(structEndArchive, recData))\n        comment = data[start+sizeEndCentDir:]\n        # check that comment length is correct\n        if endrec[_ECD_COMMENT_SIZE] == len(comment):\n            # Append the archive comment and start offset\n            endrec.append(comment)\n            endrec.append(maxCommentStart + start)\n\n            # Try to read the \"Zip64 end of central directory\" structure\n            return _EndRecData64(fpin, maxCommentStart + start - filesize,\n                                 endrec)\n\n    # Unable to find a valid end of central directory structure\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the per - file header as a string.", "response": "def FileHeader(self):\n        \"\"\"Return the per-file header as a string.\"\"\"\n        dt = self.date_time\n        dosdate = (dt[0] - 1980) << 9 | dt[1] << 5 | dt[2]\n        dostime = dt[3] << 11 | dt[4] << 5 | (dt[5] // 2)\n        if self.flag_bits & 0x08:\n            # Set these to zero because we write them after the file data\n            CRC = compress_size = file_size = 0\n        else:\n            CRC = self.CRC\n            compress_size = self.compress_size\n            file_size = self.file_size\n\n        extra = self.extra\n\n        if file_size > ZIP64_LIMIT or compress_size > ZIP64_LIMIT:\n            # File is larger than what fits into a 4 byte integer,\n            # fall back to the ZIP64 extension\n            fmt = '<HHQQ'\n            extra = extra + struct.pack(fmt,\n                    1, struct.calcsize(fmt)-4, file_size, compress_size)\n            file_size = 0xffffffff\n            compress_size = 0xffffffff\n            self.extract_version = max(45, self.extract_version)\n            self.create_version = max(45, self.extract_version)\n\n        filename, flag_bits = self._encodeFilenameFlags()\n        header = struct.pack(structFileHeader, stringFileHeader,\n                 self.extract_version, self.reserved, flag_bits,\n                 self.compress_type, dostime, dosdate, CRC,\n                 compress_size, file_size,\n                 len(filename), len(extra))\n        return header + filename + extra"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a CRC - 32 table.", "response": "def _GenerateCRCTable():\n        \"\"\"Generate a CRC-32 table.\n\n        ZIP encryption uses the CRC32 one-byte primitive for scrambling some\n        internal keys. We noticed that a direct implementation is faster than\n        relying on binascii.crc32().\n        \"\"\"\n        poly = 0xedb88320\n        table = [0] * 256\n        for i in range(256):\n            crc = i\n            for j in range(8):\n                if crc & 1:\n                    crc = ((crc >> 1) & 0x7FFFFFFF) ^ poly\n                else:\n                    crc = ((crc >> 1) & 0x7FFFFFFF)\n            table[i] = crc\n        return table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the CRC32 primitive on one byte.", "response": "def _crc32(self, ch, crc):\n        \"\"\"Compute the CRC32 primitive on one byte.\"\"\"\n        return ((crc >> 8) & 0xffffff) ^ self.crctable[(crc ^ ord(ch)) & 0xff]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a line with approx. size.", "response": "def readline(self, size = -1):\n        \"\"\"Read a line with approx. size. If size is negative,\n           read a whole line.\n        \"\"\"\n        if size < 0:\n            size = sys.maxint\n        elif size == 0:\n            return ''\n\n        # check for a newline already in buffer\n        nl, nllen = self._checkfornewline()\n\n        if nl >= 0:\n            # the next line was already in the buffer\n            nl = min(nl, size)\n        else:\n            # no line break in buffer - try to read more\n            size -= len(self.linebuffer)\n            while nl < 0 and size > 0:\n                buf = self.read(min(size, 100))\n                if not buf:\n                    break\n                self.linebuffer += buf\n                size -= len(buf)\n\n                # check for a newline in buffer\n                nl, nllen = self._checkfornewline()\n\n            # we either ran out of bytes in the file, or\n            # met the specified size limit without finding a newline,\n            # so return current buffer\n            if nl < 0:\n                s = self.linebuffer\n                self.linebuffer = ''\n                return s\n\n        buf = self.linebuffer[:nl]\n        self.lastdiscard = self.linebuffer[nl:nl + nllen]\n        self.linebuffer = self.linebuffer[nl + nllen:]\n\n        # line is always returned with \\n as newline char (except possibly\n        # for a final incomplete line in the file, which is handled above).\n        return buf + \"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all lines in the file.", "response": "def readlines(self, sizehint = -1):\n        \"\"\"Return a list with all (following) lines. The sizehint parameter\n        is ignored in this implementation.\n        \"\"\"\n        result = []\n        while True:\n            line = self.readline()\n            if not line: break\n            result.append(line)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the directory and return the contents.", "response": "def _GetContents(self):\n        \"\"\"Read the directory, making sure we close the file if the format\n        is bad.\"\"\"\n        try:\n            self._RealGetContents()\n        except BadZipfile:\n            if not self._filePassed:\n                self.fp.close()\n                self.fp = None\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of file names in the archive.", "response": "def namelist(self):\n        \"\"\"Return a list of file names in the archive.\"\"\"\n        l = []\n        for data in self.filelist:\n            l.append(data.filename)\n        return l"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef printdir(self):\n        print \"%-46s %19s %12s\" % (\"File Name\", \"Modified    \", \"Size\")\n        for zinfo in self.filelist:\n            date = \"%d-%02d-%02d %02d:%02d:%02d\" % zinfo.date_time[:6]\n            print \"%-46s %s %12d\" % (zinfo.filename, date, zinfo.file_size)", "response": "Print a table of contents for the zip file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the instance of ZipInfo given name.", "response": "def getinfo(self, name):\n        \"\"\"Return the instance of ZipInfo given 'name'.\"\"\"\n        info = self.NameToInfo.get(name)\n        if info is None:\n            raise KeyError(\n                'There is no item named %r in the archive' % name)\n\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting a member from the archive to the current working directory pwd is the pwd of the member.", "response": "def extract(self, member, path=None, pwd=None):\n        \"\"\"Extract a member from the archive to the current working directory,\n           using its full name. Its file information is extracted as accurately\n           as possible. `member' may be a filename or a ZipInfo object. You can\n           specify a different directory using `path'.\n        \"\"\"\n        if not isinstance(member, ZipInfo):\n            member = self.getinfo(member)\n\n        if path is None:\n            path = os.getcwd()\n\n        return self._extract_member(member, path, pwd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract all members from the archive to the current working directory.", "response": "def extractall(self, path=None, members=None, pwd=None):\n        \"\"\"Extract all members from the archive to the current working\n           directory. `path' specifies a different directory to extract to.\n           `members' is optional and must be a subset of the list returned\n           by namelist().\n        \"\"\"\n        if members is None:\n            members = self.namelist()\n\n        for zipinfo in members:\n            self.extract(zipinfo, path, pwd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _extract_member(self, member, targetpath, pwd):\n        # build the destination pathname, replacing\n        # forward slashes to platform specific separators.\n        # Strip trailing path separator, unless it represents the root.\n        if (targetpath[-1:] in (os.path.sep, os.path.altsep)\n            and len(os.path.splitdrive(targetpath)[1]) > 1):\n            targetpath = targetpath[:-1]\n\n        # don't include leading \"/\" from file name if present\n        if member.filename[0] == '/':\n            targetpath = os.path.join(targetpath, member.filename[1:])\n        else:\n            targetpath = os.path.join(targetpath, member.filename)\n\n        targetpath = os.path.normpath(targetpath)\n\n        # Create all upper directories if necessary.\n        upperdirs = os.path.dirname(targetpath)\n        if upperdirs and not os.path.exists(upperdirs):\n            os.makedirs(upperdirs)\n\n        if member.filename[-1] == '/':\n            if not os.path.isdir(targetpath):\n                os.mkdir(targetpath)\n            return targetpath\n\n        source = self.open(member, pwd=pwd)\n        target = file(targetpath, \"wb\")\n        shutil.copyfileobj(source, target)\n        source.close()\n        target.close()\n\n        return targetpath", "response": "Extract the ZipInfo object member to a physical entry file on the path targetpath."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _writecheck(self, zinfo):\n        if zinfo.filename in self.NameToInfo:\n            if self.debug:      # Warning for duplicate names\n                print \"Duplicate name:\", zinfo.filename\n        if self.mode not in (\"w\", \"a\"):\n            raise RuntimeError, 'write() requires mode \"w\" or \"a\"'\n        if not self.fp:\n            raise RuntimeError, \\\n                  \"Attempt to write ZIP archive that was already closed\"\n        if zinfo.compress_type == ZIP_DEFLATED and not zlib:\n            raise RuntimeError, \\\n                  \"Compression requires the (missing) zlib module\"\n        if zinfo.compress_type not in (ZIP_STORED, ZIP_DEFLATED):\n            raise RuntimeError, \\\n                  \"That compression method is not supported\"\n        if zinfo.file_size > ZIP64_LIMIT:\n            if not self._allowZip64:\n                raise LargeZipFile(\"Filesize would require ZIP64 extensions\")\n        if zinfo.header_offset > ZIP64_LIMIT:\n            if not self._allowZip64:\n                raise LargeZipFile(\"Zipfile size would require ZIP64 extensions\")", "response": "Check for errors before writing a file to the archive."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the bytes from filename into the archive under the name arcname.", "response": "def write(self, filename, arcname=None, compress_type=None):\n        \"\"\"Put the bytes from filename into the archive under the name\n        arcname.\"\"\"\n        if not self.fp:\n            raise RuntimeError(\n                  \"Attempt to write to ZIP archive that was already closed\")\n\n        st = os.stat(filename)\n        isdir = stat.S_ISDIR(st.st_mode)\n        mtime = time.localtime(st.st_mtime)\n        date_time = mtime[0:6]\n        # Create ZipInfo instance to store file information\n        if arcname is None:\n            arcname = filename\n        arcname = os.path.normpath(os.path.splitdrive(arcname)[1])\n        while arcname[0] in (os.sep, os.altsep):\n            arcname = arcname[1:]\n        if isdir:\n            arcname += '/'\n        zinfo = ZipInfo(arcname, date_time)\n        zinfo.external_attr = (st[0] & 0xFFFF) << 16L      # Unix attributes\n        if compress_type is None:\n            zinfo.compress_type = self.compression\n        else:\n            zinfo.compress_type = compress_type\n\n        zinfo.file_size = st.st_size\n        zinfo.flag_bits = 0x00\n        zinfo.header_offset = self.fp.tell()    # Start of header bytes\n\n        self._writecheck(zinfo)\n        self._didModify = True\n\n        if isdir:\n            zinfo.file_size = 0\n            zinfo.compress_size = 0\n            zinfo.CRC = 0\n            self.filelist.append(zinfo)\n            self.NameToInfo[zinfo.filename] = zinfo\n            self.fp.write(zinfo.FileHeader())\n            return\n\n        fp = open(filename, \"rb\")\n        # Must overwrite CRC and sizes with correct data later\n        zinfo.CRC = CRC = 0\n        zinfo.compress_size = compress_size = 0\n        zinfo.file_size = file_size = 0\n        self.fp.write(zinfo.FileHeader())\n        if zinfo.compress_type == ZIP_DEFLATED:\n            cmpr = zlib.compressobj(zlib.Z_DEFAULT_COMPRESSION,\n                 zlib.DEFLATED, -15)\n        else:\n            cmpr = None\n        while 1:\n            buf = fp.read(1024 * 8)\n            if not buf:\n                break\n            file_size = file_size + len(buf)\n            CRC = crc32(buf, CRC) & 0xffffffff\n            if cmpr:\n                buf = cmpr.compress(buf)\n                compress_size = compress_size + len(buf)\n            self.fp.write(buf)\n        fp.close()\n        if cmpr:\n            buf = cmpr.flush()\n            compress_size = compress_size + len(buf)\n            self.fp.write(buf)\n            zinfo.compress_size = compress_size\n        else:\n            zinfo.compress_size = file_size\n        zinfo.CRC = CRC\n        zinfo.file_size = file_size\n        # Seek backwards and write CRC and file sizes\n        position = self.fp.tell()       # Preserve current position in file\n        self.fp.seek(zinfo.header_offset + 14, 0)\n        self.fp.write(struct.pack(\"<LLL\", zinfo.CRC, zinfo.compress_size,\n              zinfo.file_size))\n        self.fp.seek(position, 0)\n        self.filelist.append(zinfo)\n        self.NameToInfo[zinfo.filename] = zinfo"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds all files from \"pathname\" to the ZIP archive. If pathname is a package directory, search the directory and all package subdirectories recursively for all *.py and enter the modules into the archive. If pathname is a plain directory, listdir *.py and enter all modules. Else, pathname must be a Python *.py file and the module will be put into the archive. Added modules are always module.pyo or module.pyc. This method will compile the module.py into module.pyc if necessary.", "response": "def writepy(self, pathname, basename = \"\"):\n        \"\"\"Add all files from \"pathname\" to the ZIP archive.\n\n        If pathname is a package directory, search the directory and\n        all package subdirectories recursively for all *.py and enter\n        the modules into the archive.  If pathname is a plain\n        directory, listdir *.py and enter all modules.  Else, pathname\n        must be a Python *.py file and the module will be put into the\n        archive.  Added modules are always module.pyo or module.pyc.\n        This method will compile the module.py into module.pyc if\n        necessary.\n        \"\"\"\n        dir, name = os.path.split(pathname)\n        if os.path.isdir(pathname):\n            initname = os.path.join(pathname, \"__init__.py\")\n            if os.path.isfile(initname):\n                # This is a package directory, add it\n                if basename:\n                    basename = \"%s/%s\" % (basename, name)\n                else:\n                    basename = name\n                if self.debug:\n                    print \"Adding package in\", pathname, \"as\", basename\n                fname, arcname = self._get_codename(initname[0:-3], basename)\n                if self.debug:\n                    print \"Adding\", arcname\n                self.write(fname, arcname)\n                dirlist = os.listdir(pathname)\n                dirlist.remove(\"__init__.py\")\n                # Add all *.py files and package subdirectories\n                for filename in dirlist:\n                    path = os.path.join(pathname, filename)\n                    root, ext = os.path.splitext(filename)\n                    if os.path.isdir(path):\n                        if os.path.isfile(os.path.join(path, \"__init__.py\")):\n                            # This is a package directory, add it\n                            self.writepy(path, basename)  # Recursive call\n                    elif ext == \".py\":\n                        fname, arcname = self._get_codename(path[0:-3],\n                                         basename)\n                        if self.debug:\n                            print \"Adding\", arcname\n                        self.write(fname, arcname)\n            else:\n                # This is NOT a package directory, add its files at top level\n                if self.debug:\n                    print \"Adding files from directory\", pathname\n                for filename in os.listdir(pathname):\n                    path = os.path.join(pathname, filename)\n                    root, ext = os.path.splitext(filename)\n                    if ext == \".py\":\n                        fname, arcname = self._get_codename(path[0:-3],\n                                         basename)\n                        if self.debug:\n                            print \"Adding\", arcname\n                        self.write(fname, arcname)\n        else:\n            if pathname[-3:] != \".py\":\n                raise RuntimeError, \\\n                      'Files added with writepy() must end with \".py\"'\n            fname, arcname = self._get_codename(pathname[0:-3], basename)\n            if self.debug:\n                print \"Adding file\", arcname\n            self.write(fname, arcname)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the temporary file to use.", "response": "def get_fileobject(self, dir=None, **kwargs):\n        '''Return the temporary file to use.'''\n        if dir is None:\n            dir = os.path.normpath(os.path.dirname(self._path))\n        descriptor, name = tempfile.mkstemp(dir=dir)\n        # io.open() will take either the descriptor or the name, but we need\n        # the name later for commit()/replace_atomic() and couldn't find a way\n        # to get the filename from the descriptor.\n        os.close(descriptor)\n        kwargs['mode'] = self._mode\n        kwargs['file'] = name\n        return io.open(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves the temporary file to the target location.", "response": "def commit(self, f):\n        '''Move the temporary file to the target location.'''\n        if self._overwrite:\n            replace_atomic(f.name, self._path)\n        else:\n            move_atomic(f.name, self._path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the PID recorded in the named PID file and returns the numeric PID.", "response": "def read_pid_from_pidfile(pidfile_path):\n    \"\"\" Read the PID recorded in the named PID file.\n\n        Read and return the numeric PID recorded as text in the named\n        PID file. If the PID file cannot be read, or if the content is\n        not a valid PID, return ``None``.\n\n        \"\"\"\n    pid = None\n    try:\n        pidfile = open(pidfile_path, 'r')\n    except IOError:\n        pass\n    else:\n        # According to the FHS 2.3 section on PID files in /var/run:\n        # \n        #   The file must consist of the process identifier in\n        #   ASCII-encoded decimal, followed by a newline character.\n        # \n        #   Programs that read PID files should be somewhat flexible\n        #   in what they accept; i.e., they should ignore extra\n        #   whitespace, leading zeroes, absence of the trailing\n        #   newline, or additional lines in the PID file.\n\n        line = pidfile.readline().strip()\n        try:\n            pid = int(line)\n        except ValueError:\n            pass\n        pidfile.close()\n\n    return pid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nacquiring the lock. Creates the PID file for this lock, or raises an error if the lock could not be acquired.", "response": "def acquire(self, timeout=None):\n        \"\"\" Acquire the lock.\n\n        Creates the PID file for this lock, or raises an error if\n        the lock could not be acquired.\n        \"\"\"\n\n        timeout = timeout is not None and timeout or self.timeout\n        end_time = time.time()\n        if timeout is not None and timeout > 0:\n            end_time += timeout\n\n        while True:\n            try:\n                write_pid_to_pidfile(self.path)\n            except OSError as exc:\n                if exc.errno == errno.EEXIST:\n                    # The lock creation failed.  Maybe sleep a bit.\n                    if timeout is not None and time.time() > end_time:\n                        if timeout > 0:\n                            raise LockTimeout(\"Timeout waiting to acquire\"\n                                              \" lock for %s\" %\n                                              self.path)\n                        else:\n                            raise AlreadyLocked(\"%s is already locked\" %\n                                                self.path)\n                    time.sleep(timeout is not None and timeout/10 or 0.1)\n                else:\n                    raise LockFailed(\"failed to create %s\" % self.path)\n            else:\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls this after adding your child widgets.", "response": "def apply_saved_layout(self):\n        \"\"\"Call this after adding your child widgets.\"\"\"\n        num_widgets = self.config.get(self.config_key + \"/num_widgets\", int)\n        if num_widgets:\n            sizes = []\n            for i in range(num_widgets):\n                key = \"%s/size_%d\" % (self.config_key, i)\n                size = self.config.get(key, int)\n                sizes.append(size)\n            self.setSizes(sizes)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning diict with nones removed.", "response": "def remove_nones(**kwargs):\n    \"\"\"Return diict copy with nones removed.\n    \"\"\"\n    return dict((k, v) for k, v in kwargs.iteritems() if v is not None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming a deep merge of dict2 into dict1.", "response": "def deep_update(dict1, dict2):\n    \"\"\"Perform a deep merge of `dict2` into `dict1`.\n\n    Note that `dict2` and any nested dicts are unchanged.\n\n    Supports `ModifyList` instances.\n    \"\"\"\n    def flatten(v):\n        if isinstance(v, ModifyList):\n            return v.apply([])\n        elif isinstance(v, dict):\n            return dict((k, flatten(v_)) for k, v_ in v.iteritems())\n        else:\n            return v\n\n    def merge(v1, v2):\n        if isinstance(v1, dict) and isinstance(v2, dict):\n            deep_update(v1, v2)\n            return v1\n        elif isinstance(v2, ModifyList):\n            v1 = flatten(v1)\n            return v2.apply(v1)\n        else:\n            return flatten(v2)\n\n    for k1, v1 in dict1.iteritems():\n        if k1 not in dict2:\n            dict1[k1] = flatten(v1)\n\n    for k2, v2 in dict2.iteritems():\n        v1 = dict1.get(k2)\n\n        if v1 is KeyError:\n            dict1[k2] = flatten(v2)\n        else:\n            dict1[k2] = merge(v1, v2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deep_del(data, fn):\n    result = {}\n\n    for k, v in data.iteritems():\n        if not fn(v):\n            if isinstance(v, dict):\n                result[k] = deep_del(v, fn)\n            else:\n                result[k] = v\n\n    return result", "response": "Create dict copy with removed items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget added removed and changed keys between two dicts.", "response": "def get_dict_diff(d1, d2):\n    \"\"\"Get added/removed/changed keys between two dicts.\n\n    Each key in the return value is a list, which is the namespaced key that\n    was affected.\n\n    Returns:\n        3-tuple:\n        - list of added keys;\n        - list of removed key;\n        - list of changed keys.\n    \"\"\"\n    def _diff(d1_, d2_, namespace):\n        added = []\n        removed = []\n        changed = []\n\n        for k1, v1 in d1_.iteritems():\n            if k1 not in d2_:\n                removed.append(namespace + [k1])\n            else:\n                v2 = d2_[k1]\n                if v2 != v1:\n                    if isinstance(v1, dict) and isinstance(v2, dict):\n                        namespace_ = namespace + [k1]\n                        added_, removed_, changed_ = _diff(v1, v2, namespace_)\n                        added.extend(added_)\n                        removed.extend(removed_)\n                        changed.extend(changed_)\n                    else:\n                        changed.append(namespace + [k1])\n\n        for k2 in d2_.iterkeys():\n            if k2 not in d1_:\n                added.append(namespace + [k2])\n\n        return added, removed, changed\n\n    return _diff(d1, d2, [])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dict_diff_str(d1, d2, title):\n    added, removed, changed = get_dict_diff(d1, d2)\n    lines = [title]\n\n    if added:\n        lines.append(\"Added attributes: %s\"\n                     % ['.'.join(x) for x in added])\n    if removed:\n        lines.append(\"Removed attributes: %s\"\n                     % ['.'.join(x) for x in removed])\n    if changed:\n        lines.append(\"Changed attributes: %s\"\n                     % ['.'.join(x) for x in changed])\n\n    return '\\n'.join(lines)", "response": "Returns same as get_dict_diff but as a readable string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_object_completions(instance, prefix, types=None, instance_types=None):\n    word_toks = []\n    toks = prefix.split('.')\n    while len(toks) > 1:\n        attr = toks[0]\n        toks = toks[1:]\n        word_toks.append(attr)\n        try:\n            instance = getattr(instance, attr)\n        except AttributeError:\n            return []\n        if instance_types and not isinstance(instance, instance_types):\n            return []\n\n    prefix = toks[-1]\n    words = []\n\n    attrs = dir(instance)\n    try:\n        for attr in instance:\n            if isinstance(attr, basestring):\n                attrs.append(attr)\n    except TypeError:\n        pass\n\n    for attr in attrs:\n        if attr.startswith(prefix) and not attr.startswith('_') \\\n                and not hasattr(instance.__class__, attr):\n            value = getattr(instance, attr)\n            if types and not isinstance(value, types):\n                continue\n            if not callable(value):\n                words.append(attr)\n\n    qual_words = ['.'.join(word_toks + [x]) for x in words]\n\n    if len(words) == 1 and value is not None and \\\n            (instance_types is None or isinstance(value, instance_types)):\n        qual_word = qual_words[0]\n        words = get_object_completions(value, '', types)\n        for word in words:\n            qual_words.append(\"%s.%s\" % (qual_word, word))\n\n    return qual_words", "response": "Returns a list of strings based on an object s attributes and keys."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the base of the current variant.", "response": "def _set_packagebase(self, variant):\n        self.setEnabled(variant is not None)\n        self.variant = variant\n        is_package = isinstance(variant, Package)\n        prev_index = self.currentIndex()\n        disabled_tabs = set()\n\n        for d in self.tabs.itervalues():\n            index = d[\"index\"]\n            if (not d[\"lazy\"]) or (self.currentIndex() == index):\n                self.widget(index).set_variant(variant)\n\n        tab_index = self.tabs[\"variants\"][\"index\"]\n        if (isinstance(variant, Variant) and variant.index is not None) \\\n                or (is_package and variant.num_variants):\n            n = variant.num_variants if is_package else variant.parent.num_variants\n            label = \"variants (%d)\" % n\n            self.setTabEnabled(tab_index, True)\n        else:\n            label = \"variants\"\n            self.setTabEnabled(tab_index, False)\n            disabled_tabs.add(tab_index)\n        self.setTabText(tab_index, label)\n\n        tab_index = self.tabs[\"tools\"][\"index\"]\n        if variant and variant.tools:\n            label = \"tools (%d)\" % len(variant.tools)\n            self.setTabEnabled(tab_index, True)\n        else:\n            label = \"tools\"\n            self.setTabEnabled(tab_index, False)\n            disabled_tabs.add(tab_index)\n        self.setTabText(tab_index, label)\n\n        \"\"\"\n        tab_index = self.tabs[\"help\"]\n        if self.help_widget.success:\n            self.setTabEnabled(tab_index, True)\n        else:\n            self.setTabEnabled(tab_index, False)\n            disabled_tabs.add(tab_index)\n        \"\"\"\n\n        if prev_index in disabled_tabs:\n            self.setCurrentIndex(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses this around code in your package repository that is loading a package, for example from file or cache.", "response": "def package_loading(self):\n        \"\"\"Use this around code in your package repository that is loading a\n        package, for example from file or cache.\n        \"\"\"\n        t1 = time.time()\n        yield None\n\n        t2 = time.time()\n        self.package_load_time += t2 - t1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_empty(self):\n        for family in self.iter_package_families():\n            for pkg in self.iter_packages(family):\n                return False\n\n        return True", "response": "Determine if the repository contains any packages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_resource_handle(self, resource_key, **variables):\n        if variables.get(\"repository_type\", self.name()) != self.name():\n            raise ResourceError(\"repository_type mismatch - requested %r, \"\n                                \"repository_type is %r\"\n                                % (variables[\"repository_type\"], self.name()))\n\n        variables[\"repository_type\"] = self.name()\n\n        if variables.get(\"location\", self.location) != self.location:\n            raise ResourceError(\"location mismatch - requested %r, repository \"\n                                \"location is %r\" % (variables[\"location\"],\n                                                    self.location))\n        variables[\"location\"] = self.location\n\n        resource_cls = self.pool.get_resource_class(resource_key)\n        variables = resource_cls.normalize_variables(variables)\n        return ResourceHandle(resource_key, variables)", "response": "Create a ResourceHandle object for the given resource key and variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a resource object from the cache if it is available.", "response": "def get_resource(self, resource_key, **variables):\n        \"\"\"Get a resource.\n\n        Attempts to get and return a cached version of the resource if\n        available, otherwise a new resource object is created and returned.\n\n        Args:\n            resource_key (`str`):  Name of the type of `Resources` to find\n            variables: data to identify / store on the resource\n\n        Returns:\n            `PackageRepositoryResource` instance.\n        \"\"\"\n        handle = self.make_resource_handle(resource_key, **variables)\n        return self.get_resource_from_handle(handle, verify_repo=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_resource_from_handle(self, resource_handle, verify_repo=True):\n        if verify_repo:\n            # we could fix the handle at this point, but handles should\n            # always be made from repo.make_resource_handle... for now,\n            # at least, error to catch any \"incorrect\" construction of\n            # handles...\n            if resource_handle.variables.get(\"repository_type\") != self.name():\n                raise ResourceError(\"repository_type mismatch - requested %r, \"\n                                    \"repository_type is %r\"\n                                    % (resource_handle.variables[\"repository_type\"],\n                                       self.name()))\n\n            if resource_handle.variables.get(\"location\") != self.location:\n                raise ResourceError(\"location mismatch - requested %r, \"\n                                    \"repository location is %r \"\n                                    % (resource_handle.variables[\"location\"],\n                                       self.location))\n\n        resource = self.pool.get_resource_from_handle(resource_handle)\n        resource._repository = self\n        return resource", "response": "Get a resource from a resource handle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a package repository instance from the packages_path config setting.", "response": "def get_repository(self, path):\n        \"\"\"Get a package repository.\n\n        Args:\n            path (str): Entry from the 'packages_path' config setting. This may\n                simply be a path (which is managed by the 'filesystem' package\n                repository plugin), or a string in the form \"type@location\",\n                where 'type' identifies the repository plugin type to use.\n\n        Returns:\n            `PackageRepository` instance.\n        \"\"\"\n        # normalise\n        parts = path.split('@', 1)\n        if len(parts) == 1:\n            parts = (\"filesystem\", parts[0])\n\n        repo_type, location = parts\n        if repo_type == \"filesystem\":\n            # choice of abspath here vs realpath is deliberate. Realpath gives\n            # canonical path, which can be a problem if two studios are sharing\n            # packages, and have mirrored package paths, but some are actually\n            # different paths, symlinked to look the same. It happened!\n            location = os.path.abspath(location)\n\n        normalised_path = \"%s@%s\" % (repo_type, location)\n        return self._get_repository(normalised_path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef are_same(self, path_1, path_2):\n        if path_1 == path_2:\n            return True\n\n        repo_1 = self.get_repository(path_1)\n        repo_2 = self.get_repository(path_2)\n        return (repo_1.uid == repo_2.uid)", "response": "Test that two paths refer to the same repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_resource(self, resource_key, repository_type, location,\n                     **variables):\n        \"\"\"Get a resource.\n\n        Attempts to get and return a cached version of the resource if\n        available, otherwise a new resource object is created and returned.\n\n        Args:\n            resource_key (`str`):  Name of the type of `Resources` to find\n            repository_type (`str`): What sort of repository to look for the\n                resource in\n            location (`str`): location for the repository\n            variables: data to identify / store on the resource\n\n        Returns:\n            `PackageRepositoryResource` instance.\n        \"\"\"\n        path = \"%s@%s\" % (repository_type, location)\n        repo = self.get_repository(path)\n        resource = repo.get_resource(**variables)\n        return resource", "response": "Gets a resource from the repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a resource from a resource_handle.", "response": "def get_resource_from_handle(self, resource_handle):\n        \"\"\"Get a resource.\n\n        Args:\n            resource_handle (`ResourceHandle`): Handle of the resource.\n\n        Returns:\n            `PackageRepositoryResource` instance.\n        \"\"\"\n        repo_type = resource_handle.get(\"repository_type\")\n        location = resource_handle.get(\"location\")\n        if not (repo_type and location):\n            raise ValueError(\"PackageRepositoryManager requires \"\n                             \"resource_handle objects to have a \"\n                             \"repository_type and location defined\")\n        path = \"%s@%s\" % (repo_type, location)\n        repo = self.get_repository(path)\n        resource = repo.get_resource_from_handle(resource_handle)\n        return resource"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear_caches(self):\n        self.get_repository.cache_clear()\n        self._get_repository.cache_clear()\n        self.pool.clear_caches()", "response": "Clear all cached data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_transport(host, connect_timeout, ssl=False):\n    if ssl:\n        return SSLTransport(host, connect_timeout, ssl)\n    else:\n        return TCPTransport(host, connect_timeout)", "response": "Create a subclass of _AbstractTransport."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap the socket in an SSL object.", "response": "def _setup_transport(self):\n        \"\"\"Wrap the socket in an SSL object.\"\"\"\n        if hasattr(self, 'sslopts'):\n            self.sock = ssl.wrap_socket(self.sock, **self.sslopts)\n        else:\n            self.sock = ssl.wrap_socket(self.sock)\n        self.sock.do_handshake()\n        self._quick_recv = self.sock.read"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _write(self, s):\n        try:\n            write = self.sock.write\n        except AttributeError:\n            # Works around a bug in python socket library\n            raise IOError('Socket closed')\n        else:\n            while s:\n                n = write(s)\n                if not n:\n                    raise IOError('Socket closed')\n                s = s[n:]", "response": "Write a string out to the SSL socket fully."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read(self, n, initial=False, _errnos=(errno.EAGAIN, errno.EINTR)):\n        recv = self._quick_recv\n        rbuf = self._read_buffer\n        try:\n            while len(rbuf) < n:\n                try:\n                    s = recv(n - len(rbuf))\n                except socket.error as exc:\n                    if not initial and exc.errno in _errnos:\n                        continue\n                    raise\n                if not s:\n                    raise IOError('Socket closed')\n                rbuf += s\n        except:\n            self._read_buffer = rbuf\n            raise\n\n        result, self._read_buffer = rbuf[:n], rbuf[n:]\n        return result", "response": "Read exactly n bytes from the socket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of tuples that are compatible with this Python version.", "response": "def compatible_tags():\n    \"\"\"\n    Return (pyver, abi, arch) tuples compatible with this Python.\n    \"\"\"\n    versions = [VER_SUFFIX]\n    major = VER_SUFFIX[0]\n    for minor in range(sys.version_info[1] - 1, - 1, -1):\n        versions.append(''.join([major, str(minor)]))\n\n    abis = []\n    for suffix, _, _ in imp.get_suffixes():\n        if suffix.startswith('.abi'):\n            abis.append(suffix.split('.', 2)[1])\n    abis.sort()\n    if ABI != 'none':\n        abis.insert(0, ABI)\n    abis.append('none')\n    result = []\n\n    arches = [ARCH]\n    if sys.platform == 'darwin':\n        m = re.match('(\\w+)_(\\d+)_(\\d+)_(\\w+)$', ARCH)\n        if m:\n            name, major, minor, arch = m.groups()\n            minor = int(minor)\n            matches = [arch]\n            if arch in ('i386', 'ppc'):\n                matches.append('fat')\n            if arch in ('i386', 'ppc', 'x86_64'):\n                matches.append('fat3')\n            if arch in ('ppc64', 'x86_64'):\n                matches.append('fat64')\n            if arch in ('i386', 'x86_64'):\n                matches.append('intel')\n            if arch in ('i386', 'x86_64', 'intel', 'ppc', 'ppc64'):\n                matches.append('universal')\n            while minor >= 0:\n                for match in matches:\n                    s = '%s_%s_%s_%s' % (name, major, minor, match)\n                    if s != ARCH:   # already there\n                        arches.append(s)\n                minor -= 1\n\n    # Most specific - our Python version, ABI and arch\n    for abi in abis:\n        for arch in arches:\n            result.append((''.join((IMP_PREFIX, versions[0])), abi, arch))\n\n    # where no ABI / arch dependency, but IMP_PREFIX dependency\n    for i, version in enumerate(versions):\n        result.append((''.join((IMP_PREFIX, version)), 'none', 'any'))\n        if i == 0:\n            result.append((''.join((IMP_PREFIX, version[0])), 'none', 'any'))\n\n    # no IMP_PREFIX, ABI or arch dependency\n    for i, version in enumerate(versions):\n        result.append((''.join(('py', version)), 'none', 'any'))\n        if i == 0:\n            result.append((''.join(('py', version[0])), 'none', 'any'))\n    return set(result)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extend_path(path, name):\n    if not isinstance(path, list):\n        # This could happen e.g. when this is called from inside a\n        # frozen package.  Return the path unchanged in that case.\n        return path\n\n    pname = os.path.join(*name.split('.'))  # Reconstitute as relative path\n    # Just in case os.extsep != '.'\n    init_py = \"__init__\" + os.extsep + \"py\"\n    path = path[:]\n\n    for dir in config.plugin_path:\n        if not os.path.isdir(dir):\n            if config.debug(\"plugins\"):\n                print_debug(\"skipped nonexistant rez plugin path: %s\" % dir)\n            continue\n\n        subdir = os.path.join(dir, pname)\n        # XXX This may still add duplicate entries to path on\n        # case-insensitive filesystems\n        initfile = os.path.join(subdir, init_py)\n        if subdir not in path and os.path.isfile(initfile):\n            path.append(subdir)\n\n    return path", "response": "Extend a path to include a single logical taxonomy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_plugin_class(self, plugin_name):\n        try:\n            return self.plugin_classes[plugin_name]\n        except KeyError:\n            raise RezPluginError(\"Unrecognised %s plugin: '%s'\"\n                                 % (self.pretty_type_name, plugin_name))", "response": "Returns the class registered under the given plugin name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the module containing the given name.", "response": "def get_plugin_module(self, plugin_name):\n        \"\"\"Returns the module containing the plugin of the given name.\"\"\"\n        try:\n            return self.plugin_modules[plugin_name]\n        except KeyError:\n            raise RezPluginError(\"Unrecognised %s plugin: '%s'\"\n                                 % (self.pretty_type_name, plugin_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef config_schema(self):\n        from rez.config import _plugin_config_dict\n        d = _plugin_config_dict.get(self.type_name, {})\n\n        for name, plugin_class in self.plugin_classes.iteritems():\n            if hasattr(plugin_class, \"schema_dict\") \\\n                    and plugin_class.schema_dict:\n                d_ = {name: plugin_class.schema_dict}\n                deep_update(d, d_)\n        return dict_to_schema(d, required=True, modifier=expand_system_vars)", "response": "Returns the merged configuration data schema for this plugin\n        type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plugin_class(self, plugin_type, plugin_name):\n        plugin = self._get_plugin_type(plugin_type)\n        return plugin.get_plugin_class(plugin_name)", "response": "Return the class registered under the given plugin name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the module defining the class registered under the given plugin name.", "response": "def get_plugin_module(self, plugin_type, plugin_name):\n        \"\"\"Return the module defining the class registered under the given\n        plugin name.\"\"\"\n        plugin = self._get_plugin_type(plugin_type)\n        return plugin.get_plugin_module(plugin_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates and return an instance of the given plugin.", "response": "def create_instance(self, plugin_type, plugin_name, **instance_kwargs):\n        \"\"\"Create and return an instance of the given plugin.\"\"\"\n        plugin_type = self._get_plugin_type(plugin_type)\n        return plugin_type.create_instance(plugin_name, **instance_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_summary_string(self):\n        rows = [[\"PLUGIN TYPE\", \"NAME\", \"DESCRIPTION\", \"STATUS\"],\n                [\"-----------\", \"----\", \"-----------\", \"------\"]]\n        for plugin_type in sorted(self.get_plugin_types()):\n            type_name = plugin_type.replace('_', ' ')\n            for name in sorted(self.get_plugins(plugin_type)):\n                module = self.get_plugin_module(plugin_type, name)\n                desc = (getattr(module, \"__doc__\", None) or '').strip()\n                rows.append((type_name, name, desc, \"loaded\"))\n            for (name, reason) in sorted(self.get_failed_plugins(plugin_type)):\n                msg = \"FAILED: %s\" % reason\n                rows.append((type_name, name, '', msg))\n        return '\\n'.join(columnise(rows))", "response": "Get a formatted string summarising the plugins that were loaded."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_fragment(self, offset):\n        fragment_len = 10\n        s = '%r' % (self.source[offset:offset + fragment_len])\n        if offset + fragment_len < len(self.source):\n            s += '...'\n        return s", "response": "Get the part of the source which is causing a problem."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate a source string or node using filename when displaying errors.", "response": "def evaluate(self, node, filename=None):\n        \"\"\"\n        Evaluate a source string or node, using ``filename`` when\n        displaying errors.\n        \"\"\"\n        if isinstance(node, string_types):\n            self.source = node\n            kwargs = {'mode': 'eval'}\n            if filename:\n                kwargs['filename'] = filename\n            try:\n                node = ast.parse(node, **kwargs)\n            except SyntaxError as e:\n                s = self.get_fragment(e.offset)\n                raise SyntaxError('syntax error %s' % s)\n        node_type = node.__class__.__name__.lower()\n        handler = self.get_handler(node_type)\n        if handler is None:\n            if self.source is None:\n                s = '(source not available)'\n            else:\n                s = self.get_fragment(node.col_offset)\n            raise SyntaxError(\"don't know how to evaluate %r %s\" % (\n                node_type, s))\n        return handler(node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting the sublists at the given position and updates the index when the length is less than double the load level.", "response": "def _expand(self, pos):\n        \"\"\"Splits sublists that are more than double the load level.\n\n        Updates the index when the sublist length is less than double the load\n        level. This requires incrementing the nodes in a traversal from the\n        leaf node to the root. For an example traversal see self._loc.\n\n        \"\"\"\n        _lists = self._lists\n        _index = self._index\n\n        if len(_lists[pos]) > self._dual:\n            _maxes = self._maxes\n            _load = self._load\n\n            _lists_pos = _lists[pos]\n            half = _lists_pos[_load:]\n            del _lists_pos[_load:]\n            _maxes[pos] = _lists_pos[-1]\n\n            _lists.insert(pos + 1, half)\n            _maxes.insert(pos + 1, half[-1])\n\n            del _index[:]\n        else:\n            if _index:\n                child = self._offset + pos\n                while child:\n                    _index[child] += 1\n                    child = (child - 1) >> 1\n                _index[0] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, iterable):\n        _lists = self._lists\n        _maxes = self._maxes\n        values = sorted(iterable)\n\n        if _maxes:\n            if len(values) * 4 >= self._len:\n                values.extend(chain.from_iterable(_lists))\n                values.sort()\n                self._clear()\n            else:\n                _add = self.add\n                for val in values:\n                    _add(val)\n                return\n\n        _load = self._load\n        _lists.extend(values[pos:(pos + _load)]\n                      for pos in range(0, len(values), _load))\n        _maxes.extend(sublist[-1] for sublist in _lists)\n        self._len = len(values)\n        del self._index[:]", "response": "Update the list by adding all elements from iterable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef discard(self, val):\n        _maxes = self._maxes\n\n        if not _maxes:\n            return\n\n        pos = bisect_left(_maxes, val)\n\n        if pos == len(_maxes):\n            return\n\n        _lists = self._lists\n        idx = bisect_left(_lists[pos], val)\n\n        if _lists[pos][idx] == val:\n            self._delete(pos, idx)", "response": "Removes the first occurrence of val."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pos(self, idx):\n        if idx < 0:\n            last_len = len(self._lists[-1])\n\n            if (-idx) <= last_len:\n                return len(self._lists) - 1, last_len + idx\n\n            idx += self._len\n\n            if idx < 0:\n                raise IndexError('list index out of range')\n        elif idx >= self._len:\n            raise IndexError('list index out of range')\n\n        if idx < len(self._lists[0]):\n            return 0, idx\n\n        _index = self._index\n\n        if not _index:\n            self._build_index()\n\n        pos = 0\n        child = 1\n        len_index = len(_index)\n\n        while child < len_index:\n            index_child = _index[child]\n\n            if idx < index_child:\n                pos = child\n            else:\n                idx -= index_child\n                pos = child + 1\n\n            child = (pos << 1) + 1\n\n        return (pos - self._offset, idx)", "response": "Convert an index into a pair that can be used to access the internal list at the corresponding position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild an index for indexing the sorted list.", "response": "def _build_index(self):\n        \"\"\"Build an index for indexing the sorted list.\n\n        Indexes are represented as binary trees in a dense array notation\n        similar to a binary heap.\n\n        For example, given a _lists representation storing integers:\n\n        [0]: 1 2 3\n        [1]: 4 5\n        [2]: 6 7 8 9\n        [3]: 10 11 12 13 14\n\n        The first transformation maps the sub-lists by their length. The\n        first row of the index is the length of the sub-lists.\n\n        [0]: 3 2 4 5\n\n        Each row after that is the sum of consecutive pairs of the previous row:\n\n        [1]: 5 9\n        [2]: 14\n\n        Finally, the index is built by concatenating these lists together:\n\n        _index = 14 5 9 3 2 4 5\n\n        An offset storing the start of the first row is also stored:\n\n        _offset = 3\n\n        When built, the index can be used for efficient indexing into the list.\n        See the comment and notes on self._pos for details.\n        \"\"\"\n        row0 = list(map(len, self._lists))\n\n        if len(row0) == 1:\n            self._index[:] = row0\n            self._offset = 0\n            return\n\n        head = iter(row0)\n        tail = iter(head)\n        row1 = list(starmap(add, zip(head, tail)))\n\n        if len(row0) & 1:\n            row1.append(row0[-1])\n\n        if len(row1) == 1:\n            self._index[:] = row1 + row0\n            self._offset = 1\n            return\n\n        size = 2 ** (int(log_e(len(row1) - 1, 2)) + 1)\n        row1.extend(repeat(0, size - len(row1)))\n        tree = [row0, row1]\n\n        while len(tree[-1]) > 1:\n            head = iter(tree[-1])\n            tail = iter(head)\n            row = list(starmap(add, zip(head, tail)))\n            tree.append(row)\n\n        reduce(iadd, reversed(tree), self._index)\n        self._offset = size * 2 - 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _islice(self, min_pos, min_idx, max_pos, max_idx, reverse):\n        _lists = self._lists\n\n        if min_pos > max_pos:\n            return iter(())\n        elif min_pos == max_pos and not reverse:\n            return iter(_lists[min_pos][min_idx:max_idx])\n        elif min_pos == max_pos and reverse:\n            return reversed(_lists[min_pos][min_idx:max_idx])\n        elif min_pos + 1 == max_pos and not reverse:\n            return chain(_lists[min_pos][min_idx:], _lists[max_pos][:max_idx])\n        elif min_pos + 1 == max_pos and reverse:\n            return chain(\n                reversed(_lists[max_pos][:max_idx]),\n                reversed(_lists[min_pos][min_idx:]),\n            )\n        elif not reverse:\n            return chain(\n                _lists[min_pos][min_idx:],\n                chain.from_iterable(_lists[(min_pos + 1):max_pos]),\n                _lists[max_pos][:max_idx],\n            )\n\n        temp = map(reversed, reversed(_lists[(min_pos + 1):max_pos]))\n        return chain(\n            reversed(_lists[max_pos][:max_idx]),\n            chain.from_iterable(temp),\n            reversed(_lists[min_pos][min_idx:]),\n        )", "response": "Returns an iterator that slices the internal list using two index pairs min_pos and min_idx and max_idx and the second inclusive\n        and the former exclusive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an iterator of values between minimum and maximum.", "response": "def irange(self, minimum=None, maximum=None, inclusive=(True, True),\n               reverse=False):\n        \"\"\"\n        Create an iterator of values between `minimum` and `maximum`.\n\n        `inclusive` is a pair of booleans that indicates whether the minimum\n        and maximum ought to be included in the range, respectively. The\n        default is (True, True) such that the range is inclusive of both\n        minimum and maximum.\n\n        Both `minimum` and `maximum` default to `None` which is automatically\n        inclusive of the start and end of the list, respectively.\n\n        When `reverse` is `True` the values are yielded from the iterator in\n        reverse order; `reverse` defaults to `False`.\n        \"\"\"\n        _maxes = self._maxes\n\n        if not _maxes:\n            return iter(())\n\n        _lists = self._lists\n\n        # Calculate the minimum (pos, idx) pair. By default this location\n        # will be inclusive in our calculation.\n\n        if minimum is None:\n            min_pos = 0\n            min_idx = 0\n        else:\n            if inclusive[0]:\n                min_pos = bisect_left(_maxes, minimum)\n\n                if min_pos == len(_maxes):\n                    return iter(())\n\n                min_idx = bisect_left(_lists[min_pos], minimum)\n            else:\n                min_pos = bisect_right(_maxes, minimum)\n\n                if min_pos == len(_maxes):\n                    return iter(())\n\n                min_idx = bisect_right(_lists[min_pos], minimum)\n\n        # Calculate the maximum (pos, idx) pair. By default this location\n        # will be exclusive in our calculation.\n\n        if maximum is None:\n            max_pos = len(_maxes) - 1\n            max_idx = len(_lists[max_pos])\n        else:\n            if inclusive[1]:\n                max_pos = bisect_right(_maxes, maximum)\n\n                if max_pos == len(_maxes):\n                    max_pos -= 1\n                    max_idx = len(_lists[max_pos])\n                else:\n                    max_idx = bisect_right(_lists[max_pos], maximum)\n            else:\n                max_pos = bisect_left(_maxes, maximum)\n\n                if max_pos == len(_maxes):\n                    max_pos -= 1\n                    max_idx = len(_lists[max_pos])\n                else:\n                    max_idx = bisect_left(_lists[max_pos], maximum)\n\n        return self._islice(min_pos, min_idx, max_pos, max_idx, reverse)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the index of the first entry in the internal list that contains the given value.", "response": "def bisect_left(self, val):\n        \"\"\"\n        Similar to the *bisect* module in the standard library, this returns an\n        appropriate index to insert *val*. If *val* is already present, the\n        insertion point will be before (to the left of) any existing entries.\n        \"\"\"\n        _maxes = self._maxes\n\n        if not _maxes:\n            return 0\n\n        pos = bisect_left(_maxes, val)\n\n        if pos == len(_maxes):\n            return self._len\n\n        idx = bisect_left(self._lists[pos], val)\n\n        return self._loc(pos, idx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count(self, val):\n        # pylint: disable=arguments-differ\n        _maxes = self._maxes\n\n        if not _maxes:\n            return 0\n\n        pos_left = bisect_left(_maxes, val)\n\n        if pos_left == len(_maxes):\n            return 0\n\n        _lists = self._lists\n        idx_left = bisect_left(_lists[pos_left], val)\n        pos_right = bisect_right(_maxes, val)\n\n        if pos_right == len(_maxes):\n            return self._len - self._loc(pos_left, idx_left)\n\n        idx_right = bisect_right(_lists[pos_right], val)\n\n        if pos_left == pos_right:\n            return idx_right - idx_left\n\n        right = self._loc(pos_right, idx_right)\n        left = self._loc(pos_left, idx_left)\n\n        return right - left", "response": "Return the number of occurrences of val in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend the element val to the list. Raises a ValueError if the element val would violate the sort order.", "response": "def append(self, val):\n        \"\"\"\n        Append the element *val* to the list. Raises a ValueError if the *val*\n        would violate the sort order.\n        \"\"\"\n        # pylint: disable=arguments-differ\n        _lists = self._lists\n        _maxes = self._maxes\n\n        if not _maxes:\n            _maxes.append(val)\n            _lists.append([val])\n            self._len = 1\n            return\n\n        pos = len(_lists) - 1\n\n        if val < _lists[pos][-1]:\n            msg = '{0!r} not in sort order at index {1}'.format(val, self._len)\n            raise ValueError(msg)\n\n        _maxes[pos] = val\n        _lists[pos].append(val)\n        self._len += 1\n        self._expand(pos)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove and returns the item at the specified index.", "response": "def pop(self, idx=-1):\n        \"\"\"\n        Remove and return item at *idx* (default last).  Raises IndexError if\n        list is empty or index is out of range.  Negative indices are supported,\n        as for slice indices.\n        \"\"\"\n        # pylint: disable=arguments-differ\n        if not self._len:\n            raise IndexError('pop index out of range')\n\n        _lists = self._lists\n\n        if idx == 0:\n            val = _lists[0][0]\n            self._delete(0, 0)\n            return val\n\n        if idx == -1:\n            pos = len(_lists) - 1\n            loc = len(_lists[pos]) - 1\n            val = _lists[pos][loc]\n            self._delete(pos, loc)\n            return val\n\n        if 0 <= idx < len(_lists[0]):\n            val = _lists[0][idx]\n            self._delete(0, idx)\n            return val\n\n        len_last = len(_lists[-1])\n\n        if -len_last < idx < 0:\n            pos = len(_lists) - 1\n            loc = len_last + idx\n            val = _lists[pos][loc]\n            self._delete(pos, loc)\n            return val\n\n        pos, idx = self._pos(idx)\n        val = _lists[pos][idx]\n        self._delete(pos, idx)\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef index(self, val, start=None, stop=None):\n        # pylint: disable=arguments-differ\n        _len = self._len\n\n        if not _len:\n            raise ValueError('{0!r} is not in list'.format(val))\n\n        if start is None:\n            start = 0\n        if start < 0:\n            start += _len\n        if start < 0:\n            start = 0\n\n        if stop is None:\n            stop = _len\n        if stop < 0:\n            stop += _len\n        if stop > _len:\n            stop = _len\n\n        if stop <= start:\n            raise ValueError('{0!r} is not in list'.format(val))\n\n        _maxes = self._maxes\n        pos_left = bisect_left(_maxes, val)\n\n        if pos_left == len(_maxes):\n            raise ValueError('{0!r} is not in list'.format(val))\n\n        _lists = self._lists\n        idx_left = bisect_left(_lists[pos_left], val)\n\n        if _lists[pos_left][idx_left] != val:\n            raise ValueError('{0!r} is not in list'.format(val))\n\n        stop -= 1\n        left = self._loc(pos_left, idx_left)\n\n        if start <= left:\n            if left <= stop:\n                return left\n        else:\n            right = self._bisect_right(val) - 1\n\n            if start <= right:\n                return start\n\n        raise ValueError('{0!r} is not in list'.format(val))", "response": "Return the index of the key val in the internal list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the element val to the list.", "response": "def add(self, val):\n        \"\"\"Add the element *val* to the list.\"\"\"\n        _lists = self._lists\n        _keys = self._keys\n        _maxes = self._maxes\n\n        key = self._key(val)\n\n        if _maxes:\n            pos = bisect_right(_maxes, key)\n\n            if pos == len(_maxes):\n                pos -= 1\n                _lists[pos].append(val)\n                _keys[pos].append(key)\n                _maxes[pos] = key\n            else:\n                idx = bisect_right(_keys[pos], key)\n                _lists[pos].insert(idx, val)\n                _keys[pos].insert(idx, key)\n\n            self._expand(pos)\n        else:\n            _lists.append([val])\n            _keys.append([key])\n            _maxes.append(key)\n\n        self._len += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _expand(self, pos):\n        _lists = self._lists\n        _keys = self._keys\n        _index = self._index\n\n        if len(_keys[pos]) > self._dual:\n            _maxes = self._maxes\n            _load = self._load\n\n            _lists_pos = _lists[pos]\n            _keys_pos = _keys[pos]\n            half = _lists_pos[_load:]\n            half_keys = _keys_pos[_load:]\n            del _lists_pos[_load:]\n            del _keys_pos[_load:]\n            _maxes[pos] = _keys_pos[-1]\n\n            _lists.insert(pos + 1, half)\n            _keys.insert(pos + 1, half_keys)\n            _maxes.insert(pos + 1, half_keys[-1])\n\n            del _index[:]\n        else:\n            if _index:\n                child = self._offset + pos\n                while child:\n                    _index[child] += 1\n                    child = (child - 1) >> 1\n                _index[0] += 1", "response": "Expand the list at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an iterator of values between min_key and max_key.", "response": "def irange_key(self, min_key=None, max_key=None, inclusive=(True, True),\n                   reverse=False):\n        \"\"\"\n        Create an iterator of values between `min_key` and `max_key`.\n\n        `inclusive` is a pair of booleans that indicates whether the min_key\n        and max_key ought to be included in the range, respectively. The\n        default is (True, True) such that the range is inclusive of both\n        `min_key` and `max_key`.\n\n        Both `min_key` and `max_key` default to `None` which is automatically\n        inclusive of the start and end of the list, respectively.\n\n        When `reverse` is `True` the values are yielded from the iterator in\n        reverse order; `reverse` defaults to `False`.\n        \"\"\"\n        _maxes = self._maxes\n\n        if not _maxes:\n            return iter(())\n\n        _keys = self._keys\n\n        # Calculate the minimum (pos, idx) pair. By default this location\n        # will be inclusive in our calculation.\n\n        if min_key is None:\n            min_pos = 0\n            min_idx = 0\n        else:\n            if inclusive[0]:\n                min_pos = bisect_left(_maxes, min_key)\n\n                if min_pos == len(_maxes):\n                    return iter(())\n\n                min_idx = bisect_left(_keys[min_pos], min_key)\n            else:\n                min_pos = bisect_right(_maxes, min_key)\n\n                if min_pos == len(_maxes):\n                    return iter(())\n\n                min_idx = bisect_right(_keys[min_pos], min_key)\n\n        # Calculate the maximum (pos, idx) pair. By default this location\n        # will be exclusive in our calculation.\n\n        if max_key is None:\n            max_pos = len(_maxes) - 1\n            max_idx = len(_keys[max_pos])\n        else:\n            if inclusive[1]:\n                max_pos = bisect_right(_maxes, max_key)\n\n                if max_pos == len(_maxes):\n                    max_pos -= 1\n                    max_idx = len(_keys[max_pos])\n                else:\n                    max_idx = bisect_right(_keys[max_pos], max_key)\n            else:\n                max_pos = bisect_left(_maxes, max_key)\n\n                if max_pos == len(_maxes):\n                    max_pos -= 1\n                    max_idx = len(_keys[max_pos])\n                else:\n                    max_idx = bisect_left(_keys[max_pos], max_key)\n\n        return self._islice(min_pos, min_idx, max_pos, max_idx, reverse)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the index of the first entry in the set with a given key.", "response": "def bisect_key_left(self, key):\n        \"\"\"\n        Similar to the *bisect* module in the standard library, this returns an\n        appropriate index to insert a value with a given *key*. If values with\n        *key* are already present, the insertion point will be before (to the\n        left of) any existing entries.\n        \"\"\"\n        _maxes = self._maxes\n\n        if not _maxes:\n            return 0\n\n        pos = bisect_left(_maxes, key)\n\n        if pos == len(_maxes):\n            return self._len\n\n        idx = bisect_left(self._keys[pos], key)\n\n        return self._loc(pos, idx)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the index of the first entry in the set of entries with the given key.", "response": "def bisect_key_right(self, key):\n        \"\"\"\n        Same as *bisect_key_left*, but if *key* is already present, the insertion\n        point will be after (to the right of) any existing entries.\n        \"\"\"\n        _maxes = self._maxes\n\n        if not _maxes:\n            return 0\n\n        pos = bisect_right(_maxes, key)\n\n        if pos == len(_maxes):\n            return self._len\n\n        idx = bisect_right(self._keys[pos], key)\n\n        return self._loc(pos, idx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count(self, val):\n        _maxes = self._maxes\n\n        if not _maxes:\n            return 0\n\n        key = self._key(val)\n        pos = bisect_left(_maxes, key)\n\n        if pos == len(_maxes):\n            return 0\n\n        _lists = self._lists\n        _keys = self._keys\n        idx = bisect_left(_keys[pos], key)\n        total = 0\n        len_keys = len(_keys)\n        len_sublist = len(_keys[pos])\n\n        while True:\n            if _keys[pos][idx] != key:\n                return total\n            if _lists[pos][idx] == val:\n                total += 1\n            idx += 1\n            if idx == len_sublist:\n                pos += 1\n                if pos == len_keys:\n                    return total\n                len_sublist = len(_keys[pos])\n                idx = 0", "response": "Return the number of occurrences of val in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index(self, val, start=None, stop=None):\n        _len = self._len\n\n        if not _len:\n            raise ValueError('{0!r} is not in list'.format(val))\n\n        if start is None:\n            start = 0\n        if start < 0:\n            start += _len\n        if start < 0:\n            start = 0\n\n        if stop is None:\n            stop = _len\n        if stop < 0:\n            stop += _len\n        if stop > _len:\n            stop = _len\n\n        if stop <= start:\n            raise ValueError('{0!r} is not in list'.format(val))\n\n        _maxes = self._maxes\n        key = self._key(val)\n        pos = bisect_left(_maxes, key)\n\n        if pos == len(_maxes):\n            raise ValueError('{0!r} is not in list'.format(val))\n\n        stop -= 1\n        _lists = self._lists\n        _keys = self._keys\n        idx = bisect_left(_keys[pos], key)\n        len_keys = len(_keys)\n        len_sublist = len(_keys[pos])\n\n        while True:\n            if _keys[pos][idx] != key:\n                raise ValueError('{0!r} is not in list'.format(val))\n            if _lists[pos][idx] == val:\n                loc = self._loc(pos, idx)\n                if start <= loc <= stop:\n                    return loc\n                elif loc > stop:\n                    break\n            idx += 1\n            if idx == len_sublist:\n                pos += 1\n                if pos == len_keys:\n                    raise ValueError('{0!r} is not in list'.format(val))\n                len_sublist = len(_keys[pos])\n                idx = 0\n\n        raise ValueError('{0!r} is not in list'.format(val))", "response": "Return the index of the key val in the internal list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select_version(self, version_range):\n        row = -1\n        version = None\n        for i, package in self.packages.iteritems():\n            if package.version in version_range \\\n                    and (version is None or version < package.version):\n                version = package.version\n                row = i\n\n        self.clearSelection()\n        if row != -1:\n            self.selectRow(row)\n        return version", "response": "Select the latest versioned package in the given range."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize sorted set from existing set.", "response": "def _fromset(cls, values, key=None):\n        \"\"\"Initialize sorted set from existing set.\"\"\"\n        sorted_set = object.__new__(cls)\n        sorted_set._set = values  # pylint: disable=protected-access\n        sorted_set.__init__(key=key)\n        return sorted_set"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy(self):\n        return self._fromset(set(self._set), key=self._key)", "response": "Create a shallow copy of the sorted set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the first occurrence of value from the set.", "response": "def discard(self, value):\n        \"\"\"\n        Remove the first occurrence of *value*.  If *value* is not a member,\n        does nothing.\n        \"\"\"\n        _set = self._set\n        if value in _set:\n            _set.remove(value)\n            self._list.discard(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves and returns the item at index. Raises IndexError if the set is empty.", "response": "def pop(self, index=-1):\n        \"\"\"\n        Remove and return item at *index* (default last).  Raises IndexError if\n        set is empty or index is out of range.  Negative indexes are supported,\n        as for slice indices.\n        \"\"\"\n        # pylint: disable=arguments-differ\n        value = self._list.pop(index)\n        self._set.remove(value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self, value):\n        self._set.remove(value)\n        self._list.remove(value)", "response": "Removes the first occurrence of value from the set. Raises ValueError if value is not present."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef difference(self, *iterables):\n        diff = self._set.difference(*iterables)\n        return self._fromset(diff, key=self._key)", "response": "Return a new set with elements in the set that are not in the iterable passed in."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the set removing elements found in any of the iterables.", "response": "def difference_update(self, *iterables):\n        \"\"\"\n        Update the set, removing elements found in keeping only elements\n        found in any of the *iterables*.\n        \"\"\"\n        _set = self._set\n        values = set(chain(*iterables))\n        if (4 * len(values)) > len(_set):\n            _list = self._list\n            _set.difference_update(values)\n            _list.clear()\n            _list.update(_set)\n        else:\n            _discard = self.discard\n            for value in values:\n                _discard(value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new set with elements common to the set and all iterables.", "response": "def intersection(self, *iterables):\n        \"\"\"\n        Return a new set with elements common to the set and all *iterables*.\n        \"\"\"\n        comb = self._set.intersection(*iterables)\n        return self._fromset(comb, key=self._key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the set keeping only elements found in it and all iterators.", "response": "def intersection_update(self, *iterables):\n        \"\"\"\n        Update the set, keeping only elements found in it and all *iterables*.\n        \"\"\"\n        _set = self._set\n        _list = self._list\n        _set.intersection_update(*iterables)\n        _list.clear()\n        _list.update(_set)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef symmetric_difference(self, that):\n        diff = self._set.symmetric_difference(that)\n        return self._fromset(diff, key=self._key)", "response": "Return a new set with elements in either self or that but not both."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the set keeping only elements found in self and that but not in both.", "response": "def symmetric_difference_update(self, that):\n        \"\"\"\n        Update the set, keeping only elements found in either *self* or *that*,\n        but not in both.\n        \"\"\"\n        _set = self._set\n        _list = self._list\n        _set.symmetric_difference_update(that)\n        _list.clear()\n        _list.update(_set)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef union(self, *iterables):\n        return self.__class__(chain(iter(self), *iterables), key=self._key)", "response": "Return a new SortedSet with elements from the set and all iterables."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the set adding elements from all iterables.", "response": "def update(self, *iterables):\n        \"\"\"Update the set, adding elements from all *iterables*.\"\"\"\n        _set = self._set\n        values = set(chain(*iterables))\n        if (4 * len(values)) > len(_set):\n            _list = self._list\n            _set.update(values)\n            _list.clear()\n            _list.update(_set)\n        else:\n            _add = self.add\n            for value in values:\n                _add(value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scoped_format(txt, **objects):\n    pretty = objects.pop(\"pretty\", RecursiveAttribute.format_pretty)\n    expand = objects.pop(\"expand\", RecursiveAttribute.format_expand)\n    attr = RecursiveAttribute(objects, read_only=True)\n    formatter = scoped_formatter(**objects)\n    return formatter.format(txt, pretty=pretty, expand=expand)", "response": "Format a string with respect to a set of objects attributes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_dict(self):\n        d = {}\n        for k, v in self.__dict__[\"data\"].iteritems():\n            if isinstance(v, RecursiveAttribute):\n                d[k] = v.to_dict()\n            else:\n                d[k] = v\n        return d", "response": "Get an equivalent dict representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value(self, key, type_=None):\n        if type_ is None:\n            default = self._default_value(key)\n            val = self._value(key, default)\n            if type(val) == type(default):\n                return val\n            else:\n                return self._convert_value(val, type(default))\n        else:\n            val = self._value(key, None)\n            if val is None:\n                return None\n            return self._convert_value(val, type_)", "response": "Get the value of a key in a known setting."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_string_list(self, key):\n        strings = []\n        size = self.beginReadArray(key)\n        for i in range(size):\n            self.setArrayIndex(i)\n            entry = str(self._value(\"entry\"))\n            strings.append(entry)\n        self.endArray()\n        return strings", "response": "Get a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepend_string_list(self, key, value, max_length_key):\n        max_len = self.get(max_length_key)\n        strings = self.get_string_list(key)\n        strings = [value] + [x for x in strings if x != value]\n        strings = strings[:max_len]\n\n        self.beginWriteArray(key)\n        for i in range(len(strings)):\n            self.setArrayIndex(i)\n            self.setValue(\"entry\", strings[i])\n        self.endArray()", "response": "Prepend a fixed - length string list with a new string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts item into the queue with the given priority.", "response": "def insert(self, item, priority):\n        \"\"\"\n        Insert item into the queue, with the given priority.\n        \"\"\"\n        heappush(self.heap, HeapItem(item, priority))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the accessibility matrix for each node in the graph.", "response": "def accessibility(graph):\n    \"\"\"\n    Accessibility matrix (transitive closure).\n\n    @type  graph: graph, digraph, hypergraph\n    @param graph: Graph.\n\n    @rtype:  dictionary\n    @return: Accessibility information for each node.\n    \"\"\"\n    recursionlimit = getrecursionlimit()\n    setrecursionlimit(max(len(graph.nodes())*2,recursionlimit))\n    \n    accessibility = {}        # Accessibility matrix\n\n    # For each node i, mark each node j if that exists a path from i to j.\n    for each in graph:\n        access = {}\n        # Perform DFS to explore all reachable nodes\n        _dfs(graph, access, 1, each)\n        accessibility[each] = list(access.keys())\n    \n    setrecursionlimit(recursionlimit)\n    return accessibility"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mutual_accessibility(graph):\n    recursionlimit = getrecursionlimit()\n    setrecursionlimit(max(len(graph.nodes())*2,recursionlimit))\n    \n    mutual_access = {}\n    stack = []\n    low = {}\n        \n    def visit(node):\n        if node in low:\n            return\n\n        num = len(low)\n        low[node] = num\n        stack_pos = len(stack)\n        stack.append(node)\n        \n        for successor in graph.neighbors(node):\n            visit(successor)\n            low[node] = min(low[node], low[successor])\n        \n        if num == low[node]:\n            component = stack[stack_pos:]\n            del stack[stack_pos:]\n            component.sort()\n            for each in component:\n                mutual_access[each] = component\n\n            for item in component:\n                low[item] = len(graph)\n    \n    for node in graph:\n        visit(node)\n    \n    setrecursionlimit(recursionlimit)\n    return mutual_access", "response": "Returns the mutual - accessibility matrix for each node in a graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connected_components(graph):\n    recursionlimit = getrecursionlimit()\n    setrecursionlimit(max(len(graph.nodes())*2,recursionlimit))\n    \n    visited = {}\n    count = 1\n\n    # For 'each' node not found to belong to a connected component, find its connected\n    # component.\n    for each in graph:\n        if (each not in visited):\n            _dfs(graph, visited, count, each)\n            count = count + 1\n    \n    setrecursionlimit(recursionlimit)\n    return visited", "response": "Returns a dictionary that associates each node to its connected component."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _dfs(graph, visited, count, node):\n    visited[node] = count\n    # Explore recursively the connected component\n    for each in graph[node]:\n        if (each not in visited):\n            _dfs(graph, visited, count, each)", "response": "Depth - first search subfunction adapted for accessibility algorithms."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cut_edges(graph):\n    recursionlimit = getrecursionlimit()\n    setrecursionlimit(max(len(graph.nodes())*2,recursionlimit))\n\n    # Dispatch if we have a hypergraph\n    if 'hypergraph' == graph.__class__.__name__:\n        return _cut_hyperedges(graph)\n\n    pre = {}    # Pre-ordering\n    low = {}    # Lowest pre[] reachable from this node going down the spanning tree + one backedge\n    spanning_tree = {}\n    reply = []\n    pre[None] = 0\n\n    for each in graph:\n        if (each not in pre):\n            spanning_tree[each] = None\n            _cut_dfs(graph, spanning_tree, pre, low, reply, each)\n    \n    setrecursionlimit(recursionlimit)\n    return reply", "response": "Returns the cut - edges of the given graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _cut_hyperedges(hypergraph):\n    edges_ = cut_nodes(hypergraph.graph)\n    edges = []\n    \n    for each in edges_:\n        if (each[1] == 'h'):\n            edges.append(each[0])\n    \n    return edges", "response": "Return the cut - hyperedges of the given hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the cut - nodes of the given graph.", "response": "def cut_nodes(graph):\n    \"\"\"\n    Return the cut-nodes of the given graph.\n    \n    A cut node, or articulation point, is a node of a graph whose removal increases the number of\n    connected components in the graph.\n    \n    @type  graph: graph, hypergraph\n    @param graph: Graph.\n        \n    @rtype:  list\n    @return: List of cut-nodes.\n    \"\"\"\n    recursionlimit = getrecursionlimit()\n    setrecursionlimit(max(len(graph.nodes())*2,recursionlimit))\n    \n    # Dispatch if we have a hypergraph\n    if 'hypergraph' == graph.__class__.__name__:\n        return _cut_hypernodes(graph)\n        \n    pre = {}    # Pre-ordering\n    low = {}    # Lowest pre[] reachable from this node going down the spanning tree + one backedge\n    reply = {}\n    spanning_tree = {}\n    pre[None] = 0\n    \n    # Create spanning trees, calculate pre[], low[]\n    for each in graph:\n        if (each not in pre):\n            spanning_tree[each] = None\n            _cut_dfs(graph, spanning_tree, pre, low, [], each)\n\n    # Find cuts\n    for each in graph:\n        # If node is not a root\n        if (spanning_tree[each] is not None):\n            for other in graph[each]:\n                # If there is no back-edge from descendent to a ancestral of each\n                if (low[other] >= pre[each] and spanning_tree[other] == each):\n                    reply[each] = 1\n        # If node is a root\n        else:\n            children = 0\n            for other in graph:\n                if (spanning_tree[other] == each):\n                    children = children + 1\n            # root is cut-vertex iff it has two or more children\n            if (children >= 2):\n                reply[each] = 1\n\n    setrecursionlimit(recursionlimit)\n    return list(reply.keys())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the cut - nodes of the given hypergraph.", "response": "def _cut_hypernodes(hypergraph):\n    \"\"\"\n    Return the cut-nodes of the given hypergraph.\n    \n    @type  hypergraph: hypergraph\n    @param hypergraph: Hypergraph\n    \n    @rtype:  list\n    @return: List of cut-nodes.\n    \"\"\"\n    nodes_ = cut_nodes(hypergraph.graph)\n    nodes = []\n    \n    for each in nodes_:\n        if (each[1] == 'n'):\n            nodes.append(each[0])\n    \n    return nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a node from the graph.", "response": "def del_node(self, node):\n        \"\"\"\n        Remove a node from the graph.\n        \n        @type  node: node\n        @param node: Node identifier.\n        \"\"\"\n        for each in list(self.neighbors(node)):\n            if (each != node):\n                self.del_edge((each, node))\n        del(self.node_neighbors[node])\n        del(self.node_attr[node])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef del_edge(self, edge):\n        u, v = edge\n        self.node_neighbors[u].remove(v)\n        self.del_edge_labeling((u, v))  \n        if (u != v):\n            self.node_neighbors[v].remove(u)\n            self.del_edge_labeling((v, u))", "response": "Removes an edge from the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edge_weight(self, edge):\n        return self.get_edge_properties( edge ).setdefault( self.WEIGHT_ATTRIBUTE_NAME, self.DEFAULT_WEIGHT )", "response": "Get the weight of an edge."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the weight of an edge.", "response": "def set_edge_weight(self, edge, wt):\n        \"\"\"\n        Set the weight of an edge.\n\n        @type  edge: edge\n        @param edge: One edge.\n\n        @type  wt: number\n        @param wt: Edge weight.\n        \"\"\"\n        self.set_edge_properties(edge, weight=wt )\n        if not self.DIRECTED:\n            self.set_edge_properties((edge[1], edge[0]) , weight=wt )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edge_label(self, edge):\n        return self.get_edge_properties( edge ).setdefault( self.LABEL_ATTRIBUTE_NAME, self.DEFAULT_LABEL )", "response": "Get the label of an edge."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_edge_label(self, edge, label):\n        self.set_edge_properties(edge, label=label )\n        if not self.DIRECTED:\n            self.set_edge_properties((edge[1], edge[0]) , label=label )", "response": "Set the label of an edge."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_edge_attribute(self, edge, attr):\n        self.edge_attr[edge] = self.edge_attributes(edge) + [attr]\n        \n        if (not self.DIRECTED and edge[0] != edge[1]):\n            self.edge_attr[(edge[1],edge[0])] = self.edge_attributes((edge[1], edge[0])) + [attr]", "response": "Adds an attribute to the edge."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends a sequence of attributes to the edge s node attributes.", "response": "def add_edge_attributes(self, edge, attrs):\n        \"\"\"\n        Append a sequence of attributes to the given edge\n        \n        @type  edge: edge\n        @param edge: One edge.\n\n        @type  attrs: tuple\n        @param attrs: Node attributes specified as a sequence of tuples in the form (attribute, value).\n        \"\"\"\n        for attr in attrs:\n            self.add_edge_attribute(edge, attr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_node_attribute(self, node, attr):\n        self.node_attr[node] = self.node_attr[node] + [attr]", "response": "Adds the given node s attribute to the given node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets shell code that should be run to activate this suite.", "response": "def activation_shell_code(self, shell=None):\n        \"\"\"Get shell code that should be run to activate this suite.\"\"\"\n        from rez.shells import create_shell\n        from rez.rex import RexExecutor\n\n        executor = RexExecutor(interpreter=create_shell(shell),\n                               parent_variables=[\"PATH\"],\n                               shebang=False)\n        executor.env.PATH.append(self.tools_path)\n        return executor.get_output().strip()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef context(self, name):\n        data = self._context(name)\n        context = data.get(\"context\")\n        if context:\n            return context\n\n        assert self.load_path\n        context_path = os.path.join(self.load_path, \"contexts\", \"%s.rxt\" % name)\n        context = ResolvedContext.load(context_path)\n        data[\"context\"] = context\n        data[\"loaded\"] = True\n        return context", "response": "Get a context.\n\n        Args:\n            name (str): Name to store the context under.\n\n        Returns:\n            `ResolvedContext` object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_context(self, name, context, prefix_char=None):\n        if name in self.contexts:\n            raise SuiteError(\"Context already in suite: %r\" % name)\n        if not context.success:\n            raise SuiteError(\"Context is not resolved: %r\" % name)\n\n        self.contexts[name] = dict(name=name,\n                                   context=context.copy(),\n                                   tool_aliases={},\n                                   hidden_tools=set(),\n                                   priority=self._next_priority,\n                                   prefix_char=prefix_char)\n        self._flush_tools()", "response": "Add a context to the suite."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_contexts(self, in_request=None, in_resolve=None):\n        names = self.context_names\n        if in_request:\n            def _in_request(name):\n                context = self.context(name)\n                packages = set(x.name for x in context.requested_packages(True))\n                return (in_request in packages)\n\n            names = [x for x in names if _in_request(x)]\n\n        if in_resolve:\n            if isinstance(in_resolve, basestring):\n                in_resolve = PackageRequest(in_resolve)\n\n            def _in_resolve(name):\n                context = self.context(name)\n                variant = context.get_resolved_package(in_resolve.name)\n                if variant:\n                    overlap = (variant.version in in_resolve.range)\n                    return ((in_resolve.conflict and not overlap)\n                            or (overlap and not in_resolve.conflict))\n                else:\n                    return in_resolve.conflict\n\n            names = [x for x in names if _in_resolve(x)]\n        return names", "response": "Find contexts in the suite based on search criteria."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_context(self, name):\n        self._context(name)\n        del self.contexts[name]\n        self._flush_tools()", "response": "Removes a context from the suite."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_context_prefix(self, name, prefix):\n        data = self._context(name)\n        data[\"prefix\"] = prefix\n        self._flush_tools()", "response": "Set a context s prefix. This will be applied to all tools in this context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a context s suffix.", "response": "def set_context_suffix(self, name, suffix):\n        \"\"\"Set a context's suffix.\n\n        This will be applied to all wrappers for the tools in this context. For\n        example, a tool called 'foo' would appear as 'foo<suffix>' in the\n        suite's bin path.\n\n        Args:\n            name (str): Name of the context to suffix.\n            suffix (str): Suffix to apply to tools.\n        \"\"\"\n        data = self._context(name)\n        data[\"suffix\"] = suffix\n        self._flush_tools()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncauses the context s tools to take priority over all others.", "response": "def bump_context(self, name):\n        \"\"\"Causes the context's tools to take priority over all others.\"\"\"\n        data = self._context(name)\n        data[\"priority\"] = self._next_priority\n        self._flush_tools()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hide_tool(self, context_name, tool_name):\n        data = self._context(context_name)\n        hidden_tools = data[\"hidden_tools\"]\n        if tool_name not in hidden_tools:\n            self._validate_tool(context_name, tool_name)\n            hidden_tools.add(tool_name)\n            self._flush_tools()", "response": "Hide a tool so that it is not exposed in the suite."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unhide_tool(self, context_name, tool_name):\n        data = self._context(context_name)\n        hidden_tools = data[\"hidden_tools\"]\n        if tool_name in hidden_tools:\n            hidden_tools.remove(tool_name)\n            self._flush_tools()", "response": "Unhides a tool from a context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef alias_tool(self, context_name, tool_name, tool_alias):\n        data = self._context(context_name)\n        aliases = data[\"tool_aliases\"]\n        if tool_name in aliases:\n            raise SuiteError(\"Tool %r in context %r is already aliased to %r\"\n                             % (tool_name, context_name, aliases[tool_name]))\n        self._validate_tool(context_name, tool_name)\n        aliases[tool_name] = tool_alias\n        self._flush_tools()", "response": "Register an alias for a specific tool."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unalias_tool(self, context_name, tool_name):\n        data = self._context(context_name)\n        aliases = data[\"tool_aliases\"]\n        if tool_name in aliases:\n            del aliases[tool_name]\n            self._flush_tools()", "response": "Deregister an alias for a specific tool."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tool_filepath(self, tool_alias):\n        tools_dict = self.get_tools()\n        if tool_alias in tools_dict:\n            if self.tools_path is None:\n                return None\n            else:\n                return os.path.join(self.tools_path, tool_alias)\n        else:\n            return None", "response": "Given a visible tool alias return the full path to the executable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_tool_context(self, tool_alias):\n        tools_dict = self.get_tools()\n        data = tools_dict.get(tool_alias)\n        if data:\n            return data[\"context_name\"]\n        return None", "response": "Given a visible tool alias return the name of the context it belongs to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the current suite to disk.", "response": "def save(self, path, verbose=False):\n        \"\"\"Save the suite to disk.\n\n        Args:\n            path (str): Path to save the suite to. If a suite is already saved\n                at `path`, then it will be overwritten. Otherwise, if `path`\n                exists, an error is raised.\n        \"\"\"\n        path = os.path.realpath(path)\n        if os.path.exists(path):\n            if self.load_path and self.load_path == path:\n                if verbose:\n                    print \"saving over previous suite...\"\n                for context_name in self.context_names:\n                    self.context(context_name)  # load before dir deleted\n                shutil.rmtree(path)\n            else:\n                raise SuiteError(\"Cannot save, path exists: %r\" % path)\n\n        contexts_path = os.path.join(path, \"contexts\")\n        os.makedirs(contexts_path)\n\n        # write suite data\n        data = self.to_dict()\n        filepath = os.path.join(path, \"suite.yaml\")\n        with open(filepath, \"w\") as f:\n            f.write(dump_yaml(data))\n\n        # write contexts\n        for context_name in self.context_names:\n            context = self.context(context_name)\n            context._set_parent_suite(path, context_name)\n            filepath = self._context_path(context_name, path)\n            if verbose:\n                print \"writing %r...\" % filepath\n            context.save(filepath)\n\n        # create alias wrappers\n        tools_path = os.path.join(path, \"bin\")\n        os.makedirs(tools_path)\n        if verbose:\n            print \"creating alias wrappers in %r...\" % tools_path\n\n        tools = self.get_tools()\n        for tool_alias, d in tools.iteritems():\n            tool_name = d[\"tool_name\"]\n            context_name = d[\"context_name\"]\n\n            data = self._context(context_name)\n            prefix_char = data.get(\"prefix_char\")\n\n            if verbose:\n                print (\"creating %r -> %r (%s context)...\"\n                       % (tool_alias, tool_name, context_name))\n            filepath = os.path.join(tools_path, tool_alias)\n\n            create_forwarding_script(filepath,\n                                     module=\"suite\",\n                                     func_name=\"_FWD__invoke_suite_tool_alias\",\n                                     context_name=context_name,\n                                     tool_name=tool_name,\n                                     prefix_char=prefix_char)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of paths to suites that are visible on the PATH.", "response": "def visible_suite_paths(cls, paths=None):\n        \"\"\"Get a list of paths to suites that are visible on $PATH.\n\n        Returns:\n            List of str.\n        \"\"\"\n        suite_paths = []\n        if paths is None:\n            paths = os.getenv(\"PATH\", \"\").split(os.pathsep)\n        for path in paths:\n            if path and os.path.isdir(path):\n                path_ = os.path.dirname(path)\n                filepath = os.path.join(path_, \"suite.yaml\")\n                if os.path.isfile(filepath):\n                    suite_paths.append(path_)\n        return suite_paths"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of suites whos bin paths are visible on the PATH.", "response": "def load_visible_suites(cls, paths=None):\n        \"\"\"Get a list of suites whos bin paths are visible on $PATH.\n\n        Returns:\n            List of `Suite` objects.\n        \"\"\"\n        suite_paths = cls.visible_suite_paths(paths)\n        suites = [cls.load(x) for x in suite_paths]\n        return suites"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting a message summarising the contents of the suite.", "response": "def print_info(self, buf=sys.stdout, verbose=False):\n        \"\"\"Prints a message summarising the contents of the suite.\"\"\"\n        _pr = Printer(buf)\n\n        if not self.contexts:\n            _pr(\"Suite is empty.\")\n            return\n\n        context_names = sorted(self.contexts.iterkeys())\n        _pr(\"Suite contains %d contexts:\" % len(context_names))\n\n        if not verbose:\n            _pr(' '.join(context_names))\n            return\n\n        tools = self.get_tools().values()\n        context_tools = defaultdict(set)\n        context_variants = defaultdict(set)\n        for entry in tools:\n            context_name = entry[\"context_name\"]\n            context_tools[context_name].add(entry[\"tool_name\"])\n            context_variants[context_name].add(str(entry[\"variant\"]))\n\n        _pr()\n        rows = [[\"NAME\", \"VISIBLE TOOLS\", \"PATH\"],\n                [\"----\", \"-------------\", \"----\"]]\n\n        for context_name in context_names:\n            context_path = self._context_path(context_name) or '-'\n            ntools = len(context_tools.get(context_name, []))\n            if ntools:\n                nvariants = len(context_variants[context_name])\n                short_desc = \"%d tools from %d packages\" % (ntools, nvariants)\n            else:\n                short_desc = \"no tools\"\n            rows.append((context_name, short_desc, context_path))\n\n        _pr(\"\\n\".join(columnise(rows)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint the tools available in the suite.", "response": "def print_tools(self, buf=sys.stdout, verbose=False, context_name=None):\n        \"\"\"Print table of tools available in the suite.\n\n        Args:\n            context_name (str): If provided, only print the tools from this\n                context.\n        \"\"\"\n        def _get_row(entry):\n            context_name_ = entry[\"context_name\"]\n            tool_alias = entry[\"tool_alias\"]\n            tool_name = entry[\"tool_name\"]\n            properties = []\n            col = None\n\n            variant = entry[\"variant\"]\n            if isinstance(variant, set):\n                properties.append(\"(in conflict)\")\n                col = critical\n                if verbose:\n                    package = \", \".join(x.qualified_package_name for x in variant)\n                else:\n                    v = iter(variant).next()\n                    package = \"%s (+%d more)\" % (v.qualified_package_name,\n                                                 len(variant) - 1)\n            else:\n                package = variant.qualified_package_name\n\n            if tool_name == tool_alias:\n                tool_name = \"-\"\n            else:\n                properties.append(\"(aliased)\")\n                if col is None:\n                    col = alias_col\n\n            msg = \" \".join(properties)\n            row = [tool_alias, tool_name, package, context_name_, msg]\n            return row, col\n\n        if context_name:\n            self._context(context_name)  # check context exists\n            context_names = [context_name]\n        else:\n            context_names = sorted(self.contexts.iterkeys())\n\n        rows = [[\"TOOL\", \"ALIASING\", \"PACKAGE\", \"CONTEXT\", \"\"],\n                [\"----\", \"--------\", \"-------\", \"-------\", \"\"]]\n        colors = [None, None]\n\n        entries_dict = defaultdict(list)\n        for d in self.get_tools().itervalues():\n            entries_dict[d[\"context_name\"]].append(d)\n\n        if verbose:\n            # add hidden entries\n            for d in self.hidden_tools:\n                d_ = d.copy()\n                d_[\"hidden\"] = True\n                entries_dict[d[\"context_name\"]].append(d_)\n\n            # add conflicting tools\n            for docs in self.tool_conflicts.itervalues():\n                for d in docs:\n                    d_ = d.copy()\n                    d_[\"conflicting\"] = True\n                    entries_dict[d[\"context_name\"]].append(d_)\n\n        for i, context_name in enumerate(context_names):\n            entries = entries_dict.get(context_name, [])\n            if entries:\n                if i:\n                    rows.append(('', '', '', '', ''))\n                    colors.append(None)\n\n                entries = sorted(entries, key=lambda x: x[\"tool_alias\"].lower())\n                for entry in entries:\n                    row, col = _get_row(entry)\n                    if \"hidden\" in entry:\n                        row[-1] = \"(hidden)\"\n                        rows.append(row)\n                        colors.append(warning)\n                    elif \"conflicting\" in entry:\n                        row[-1] = \"(not visible)\"\n                        rows.append(row)\n                        colors.append(warning)\n                    else:\n                        rows.append(row)\n                        colors.append(col)\n\n        if rows:\n            _pr = Printer(buf)\n            for col, line in zip(colors, columnise(rows)):\n                _pr(line, col)\n        else:\n            _pr(\"No tools available.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of build system classes that could build the source in given dir.", "response": "def get_valid_build_systems(working_dir, package=None):\n    \"\"\"Returns the build system classes that could build the source in given dir.\n\n    Args:\n        working_dir (str): Dir containing the package definition and potentially\n            build files.\n        package (`Package`): Package to be built. This may or may not be needed\n            to determine the build system. For eg, cmake just has to look for\n            a CMakeLists.txt file, whereas the 'build_command' package field\n            must be present for the 'custom' build system type.\n\n    Returns:\n        List of class: Valid build system class types.\n    \"\"\"\n    from rez.plugin_managers import plugin_manager\n    from rez.exceptions import PackageMetadataError\n\n    try:\n        package = package or get_developer_package(working_dir)\n    except PackageMetadataError:\n        # no package, or bad package\n        pass\n\n    if package:\n        if getattr(package, \"build_command\", None) is not None:\n            buildsys_name = \"custom\"\n        else:\n            buildsys_name = getattr(package, \"build_system\", None)\n\n        # package explicitly specifies build system\n        if buildsys_name:\n            cls = plugin_manager.get_plugin_class('build_system', buildsys_name)\n            return [cls]\n\n    # detect valid build systems\n    clss = []\n    for buildsys_name in get_buildsys_types():\n        cls = plugin_manager.get_plugin_class('build_system', buildsys_name)\n        if cls.is_valid_root(working_dir, package=package):\n            clss.append(cls)\n\n    # Sometimes files for multiple build systems can be present, because one\n    # build system uses another (a 'child' build system) - eg, cmake uses\n    # make. Detect this case and ignore files from the child build system.\n    #\n    child_clss = set(x.child_build_system() for x in clss)\n    clss = list(set(clss) - child_clss)\n\n    return clss"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_build_system(working_dir, buildsys_type=None, package=None, opts=None,\n                        write_build_scripts=False, verbose=False,\n                        build_args=[], child_build_args=[]):\n    \"\"\"Return a new build system that can build the source in working_dir.\"\"\"\n    from rez.plugin_managers import plugin_manager\n\n    # detect build system if necessary\n    if not buildsys_type:\n        clss = get_valid_build_systems(working_dir, package=package)\n\n        if not clss:\n            raise BuildSystemError(\n                \"No build system is associated with the path %s\" % working_dir)\n\n        if len(clss) != 1:\n            s = ', '.join(x.name() for x in clss)\n            raise BuildSystemError((\"Source could be built with one of: %s; \"\n                                   \"Please specify a build system\") % s)\n\n        buildsys_type = iter(clss).next().name()\n\n    # create instance of build system\n    cls_ = plugin_manager.get_plugin_class('build_system', buildsys_type)\n\n    return cls_(working_dir,\n                opts=opts,\n                package=package,\n                write_build_scripts=write_build_scripts,\n                verbose=verbose,\n                build_args=build_args,\n                child_build_args=child_build_args)", "response": "Return a new build system that can build the source in working_dir."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimplement this method to perform the actual build.", "response": "def build(self, context, variant, build_path, install_path, install=False,\n              build_type=BuildType.local):\n        \"\"\"Implement this method to perform the actual build.\n\n        Args:\n            context: A ResolvedContext object that the build process must be\n                executed within.\n            variant (`Variant`): The variant being built.\n            build_path: Where to write temporary build files. May be relative\n                to working_dir.\n            install_path (str): The package repository path to install the\n                package to, if installing. If None, defaults to\n                `config.local_packages_path`.\n            install: If True, install the build.\n            build_type: A BuildType (i.e local or central).\n\n        Returns:\n            A dict containing the following information:\n            - success: Bool indicating if the build was successful.\n            - extra_files: List of created files of interest, not including\n                build targets. A good example is the interpreted context file,\n                usually named 'build.rxt.sh' or similar. These files should be\n                located under build_path. Rez may install them for debugging\n                purposes.\n            - build_env_script: If this instance was created with write_build_scripts\n                as True, then the build should generate a script which, when run\n                by the user, places them in the build environment.\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_standard_vars(cls, context, variant, build_type, install,\n                          build_path, install_path=None):\n        \"\"\"Returns a standard set of environment variables that can be set\n        for the build system to use\n        \"\"\"\n        from rez.config import config\n\n        package = variant.parent\n        variant_requires = map(str, variant.variant_requires)\n\n        if variant.index is None:\n            variant_subpath = ''\n        else:\n            variant_subpath = variant._non_shortlinked_subpath\n\n        vars_ = {\n            'REZ_BUILD_ENV': 1,\n            'REZ_BUILD_PATH': build_path,\n            'REZ_BUILD_THREAD_COUNT': package.config.build_thread_count,\n            'REZ_BUILD_VARIANT_INDEX': variant.index or 0,\n            'REZ_BUILD_VARIANT_REQUIRES': ' '.join(variant_requires),\n            'REZ_BUILD_VARIANT_SUBPATH': variant_subpath,\n            'REZ_BUILD_PROJECT_VERSION': str(package.version),\n            'REZ_BUILD_PROJECT_NAME': package.name,\n            'REZ_BUILD_PROJECT_DESCRIPTION': (package.description or '').strip(),\n            'REZ_BUILD_PROJECT_FILE': package.filepath,\n            'REZ_BUILD_SOURCE_PATH': os.path.dirname(package.filepath),\n            'REZ_BUILD_REQUIRES': ' '.join(\n                str(x) for x in context.requested_packages(True)\n            ),\n            'REZ_BUILD_REQUIRES_UNVERSIONED': ' '.join(\n                x.name for x in context.requested_packages(True)\n            ),\n            'REZ_BUILD_TYPE': build_type.name,\n            'REZ_BUILD_INSTALL': 1 if install else 0,\n        }\n\n        if install_path:\n            vars_['REZ_BUILD_INSTALL_PATH'] = install_path\n\n        if config.rez_1_environment_variables and \\\n                not config.disable_rez_1_compatibility and \\\n                build_type == BuildType.central:\n            vars_['REZ_IN_REZ_RELEASE'] = 1\n\n        return vars_", "response": "Returns a set of environment variables that can be set for the build system to use."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a standard set of environment variables for the build system to use", "response": "def set_standard_vars(cls, executor, context, variant, build_type,\n                          install, build_path, install_path=None):\n        \"\"\"Sets a standard set of environment variables for the build system to\n        use\n        \"\"\"\n        vars = cls.get_standard_vars(context=context,\n                                     variant=variant,\n                                     build_type=build_type,\n                                     install=install,\n                                     build_path=build_path,\n                                     install_path=install_path)\n\n        for var, value in vars.iteritems():\n            executor.env[var] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_pip_command(command_args, pip_version=None, python_version=None):\n    pip_exe, context = find_pip(pip_version, python_version)\n    command = [pip_exe] + list(command_args)\n\n    if context is None:\n        return popen(command)\n    else:\n        return context.execute_shell(command=command, block=False)", "response": "Runs a pip command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_pip(pip_version=None, python_version=None):\n    pip_exe = \"pip\"\n\n    try:\n        context = create_context(pip_version, python_version)\n    except BuildError as e:\n        # fall back on system pip. Not ideal but at least it's something\n        from rez.backport.shutilwhich import which\n\n        pip_exe = which(\"pip\")\n\n        if pip_exe:\n            print_warning(\n                \"pip rez package could not be found; system 'pip' command (%s) \"\n                \"will be used instead.\" % pip_exe)\n            context = None\n        else:\n            raise e\n\n    return pip_exe, context", "response": "Find a pip executable using the given python version."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a context containing the specific pip and python.", "response": "def create_context(pip_version=None, python_version=None):\n    \"\"\"Create a context containing the specific pip and python.\n\n    Args:\n        pip_version (str or `Version`): Version of pip to use, or latest if None.\n        python_version (str or `Version`): Python version to use, or latest if\n            None.\n\n    Returns:\n        `ResolvedContext`: Context containing pip and python.\n    \"\"\"\n    # determine pip pkg to use for install, and python variants to install on\n    if pip_version:\n        pip_req = \"pip-%s\" % str(pip_version)\n    else:\n        pip_req = \"pip\"\n\n    if python_version:\n        ver = Version(str(python_version))\n        major_minor_ver = ver.trim(2)\n        py_req = \"python-%s\" % str(major_minor_ver)\n    else:\n        # use latest major.minor\n        package = get_latest_package(\"python\")\n        if package:\n            major_minor_ver = package.version.trim(2)\n        else:\n            # no python package. We're gonna fail, let's just choose current\n            # python version (and fail at context creation time)\n            major_minor_ver = '.'.join(map(str, sys.version_info[:2]))\n\n        py_req = \"python-%s\" % str(major_minor_ver)\n\n    # use pip + latest python to perform pip download operations\n    request = [pip_req, py_req]\n\n    with convert_errors(from_=(PackageFamilyNotFoundError, PackageNotFoundError),\n                        to=BuildError, msg=\"Cannot run - pip or python rez \"\n                        \"package is not present\"):\n        context = ResolvedContext(request)\n\n    # print pip package used to perform the install\n    pip_variant = context.get_resolved_package(\"pip\")\n    pip_package = pip_variant.parent\n    print_info(\"Using %s (%s)\" % (pip_package.qualified_name, pip_variant.uri))\n\n    return context"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pip_install_package(source_name, pip_version=None, python_version=None,\n                        mode=InstallMode.min_deps, release=False):\n    \"\"\"Install a pip-compatible python package as a rez package.\n    Args:\n        source_name (str): Name of package or archive/url containing the pip\n            package source. This is the same as the arg you would pass to\n            the 'pip install' command.\n        pip_version (str or `Version`): Version of pip to use to perform the\n            install, uses latest if None.\n        python_version (str or `Version`): Python version to use to perform the\n            install, and subsequently have the resulting rez package depend on.\n        mode (`InstallMode`): Installation mode, determines how dependencies are\n            managed.\n        release (bool): If True, install as a released package; otherwise, it\n            will be installed as a local package.\n\n    Returns:\n        2-tuple:\n            List of `Variant`: Installed variants;\n            List of `Variant`: Skipped variants (already installed).\n    \"\"\"\n    installed_variants = []\n    skipped_variants = []\n\n    pip_exe, context = find_pip(pip_version, python_version)\n\n    # TODO: should check if packages_path is writable before continuing with pip\n    #\n    packages_path = (config.release_packages_path if release\n                     else config.local_packages_path)\n\n    tmpdir = mkdtemp(suffix=\"-rez\", prefix=\"pip-\")\n    stagingdir = os.path.join(tmpdir, \"rez_staging\")\n    stagingsep = \"\".join([os.path.sep, \"rez_staging\", os.path.sep])\n\n    destpath = os.path.join(stagingdir, \"python\")\n    binpath = os.path.join(stagingdir, \"bin\")\n    incpath = os.path.join(stagingdir, \"include\")\n    datapath = stagingdir\n\n    if context and config.debug(\"package_release\"):\n        buf = StringIO()\n        print >> buf, \"\\n\\npackage download environment:\"\n        context.print_info(buf)\n        _log(buf.getvalue())\n\n    # Build pip commandline\n    cmd = [pip_exe, \"install\",\n           \"--install-option=--install-lib=%s\" % destpath,\n           \"--install-option=--install-scripts=%s\" % binpath,\n           \"--install-option=--install-headers=%s\" % incpath,\n           \"--install-option=--install-data=%s\" % datapath]\n\n    if mode == InstallMode.no_deps:\n        cmd.append(\"--no-deps\")\n    cmd.append(source_name)\n\n    _cmd(context=context, command=cmd)\n    _system = System()\n\n    # Collect resulting python packages using distlib\n    distribution_path = DistributionPath([destpath], include_egg=True)\n    distributions = [d for d in distribution_path.get_distributions()]\n\n    for distribution in distribution_path.get_distributions():\n        requirements = []\n        if distribution.metadata.run_requires:\n            # Handle requirements. Currently handles conditional environment based\n            # requirements and normal requirements\n            # TODO: Handle optional requirements?\n            for requirement in distribution.metadata.run_requires:\n                if \"environment\" in requirement:\n                    if interpret(requirement[\"environment\"]):\n                        requirements.extend(_get_dependencies(requirement, distributions))\n                elif \"extra\" in requirement:\n                    # Currently ignoring optional requirements\n                    pass\n                else:\n                    requirements.extend(_get_dependencies(requirement, distributions))\n\n        tools = []\n        src_dst_lut = {}\n\n        for installed_file in distribution.list_installed_files(allow_fail=True):\n            source_file = os.path.normpath(os.path.join(destpath, installed_file[0]))\n\n            if os.path.exists(source_file):\n                destination_file = installed_file[0].split(stagingsep)[1]\n                exe = False\n\n                if is_exe(source_file) and \\\n                        destination_file.startswith(\"%s%s\" % (\"bin\", os.path.sep)):\n                    _, _file = os.path.split(destination_file)\n                    tools.append(_file)\n                    exe = True\n\n                data = [destination_file, exe]\n                src_dst_lut[source_file] = data\n            else:\n                _log(\"Source file does not exist: \" + source_file + \"!\")\n\n        def make_root(variant, path):\n            \"\"\"Using distlib to iterate over all installed files of the current\n            distribution to copy files to the target directory of the rez package\n            variant\n            \"\"\"\n            for source_file, data in src_dst_lut.items():\n                destination_file, exe = data\n                destination_file = os.path.normpath(os.path.join(path, destination_file))\n\n                if not os.path.exists(os.path.dirname(destination_file)):\n                    os.makedirs(os.path.dirname(destination_file))\n\n                shutil.copyfile(source_file, destination_file)\n                if exe:\n                    shutil.copystat(source_file, destination_file)\n\n        # determine variant requirements\n        # TODO detect if platform/arch/os necessary, no if pure python\n        variant_reqs = []\n        variant_reqs.append(\"platform-%s\" % _system.platform)\n        variant_reqs.append(\"arch-%s\" % _system.arch)\n        variant_reqs.append(\"os-%s\" % _system.os)\n\n        if context is None:\n            # since we had to use system pip, we have to assume system python version\n            py_ver = '.'.join(map(str, sys.version_info[:2]))\n        else:\n            python_variant = context.get_resolved_package(\"python\")\n            py_ver = python_variant.version.trim(2)\n\n        variant_reqs.append(\"python-%s\" % py_ver)\n\n        name, _ = parse_name_and_version(distribution.name_and_version)\n        name = distribution.name[0:len(name)].replace(\"-\", \"_\")\n\n        with make_package(name, packages_path, make_root=make_root) as pkg:\n            pkg.version = distribution.version\n            if distribution.metadata.summary:\n                pkg.description = distribution.metadata.summary\n\n            pkg.variants = [variant_reqs]\n            if requirements:\n                pkg.requires = requirements\n\n            commands = []\n            commands.append(\"env.PYTHONPATH.append('{root}/python')\")\n\n            if tools:\n                pkg.tools = tools\n                commands.append(\"env.PATH.append('{root}/bin')\")\n\n            pkg.commands = '\\n'.join(commands)\n\n        installed_variants.extend(pkg.installed_variants or [])\n        skipped_variants.extend(pkg.skipped_variants or [])\n\n    # cleanup\n    shutil.rmtree(tmpdir)\n\n    return installed_variants, skipped_variants", "response": "Install a pip - compatible python package as a rez package."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a variant handle from serialize_version < 4. 0.", "response": "def convert_old_variant_handle(handle_dict):\n    \"\"\"Convert a variant handle from serialize_version < 4.0.\"\"\"\n    old_variables = handle_dict.get(\"variables\", {})\n    variables = dict(repository_type=\"filesystem\")\n\n    for old_key, key in variant_key_conversions.iteritems():\n        value = old_variables.get(old_key)\n        #if value is not None:\n        variables[key] = value\n\n    path = handle_dict[\"path\"]\n    filename = os.path.basename(path)\n    if os.path.splitext(filename)[0] == \"package\":\n        key = \"filesystem.variant\"\n    else:\n        key = \"filesystem.variant.combined\"\n\n    return dict(key=key, variables=variables)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting expansions from!OLD! style to new style.", "response": "def convert_old_command_expansions(command):\n    \"\"\"Convert expansions from !OLD! style to {new}.\"\"\"\n    command = command.replace(\"!VERSION!\",       \"{version}\")\n    command = command.replace(\"!MAJOR_VERSION!\", \"{version.major}\")\n    command = command.replace(\"!MINOR_VERSION!\", \"{version.minor}\")\n    command = command.replace(\"!BASE!\",          \"{base}\")\n    command = command.replace(\"!ROOT!\",          \"{root}\")\n    command = command.replace(\"!USER!\",          \"{system.user}\")\n    return command"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts old - style package commands into equivalent Rex code.", "response": "def convert_old_commands(commands, annotate=True):\n    \"\"\"Converts old-style package commands into equivalent Rex code.\"\"\"\n    from rez.config import config\n    from rez.utils.logging_ import print_debug\n\n    def _repl(s):\n        return s.replace('\\\\\"', '\"')\n\n    def _encode(s):\n        # this replaces all occurrances of '\\\"' with '\"', *except* for those\n        # occurrances of '\\\"' that are within double quotes, which themselves\n        # are not escaped. In other words, the string:\n        # 'hey \"there \\\"you\\\" \" \\\"dude\\\" '\n        # ..will convert to:\n        # 'hey \"there \\\"you\\\" \" \"dude\" '\n        s_new = ''\n        prev_i = 0\n\n        for m in within_unescaped_quotes_regex.finditer(s):\n            s_ = s[prev_i:m.start()]\n            s_new += _repl(s_)\n\n            s_new += s[m.start():m.end()]\n            prev_i = m.end()\n\n        s_ = s[prev_i:]\n        s_new += _repl(s_)\n        return repr(s_new)\n\n    loc = []\n\n    for cmd in commands:\n        if annotate:\n            txt = \"OLD COMMAND: %s\" % cmd\n            line = \"comment(%s)\" % _encode(txt)\n            loc.append(line)\n\n        cmd = convert_old_command_expansions(cmd)\n        toks = cmd.strip().split()\n\n        try:\n            if toks[0] == \"export\":\n                var, value = cmd.split(' ', 1)[1].split('=', 1)\n                for bookend in ('\"', \"'\"):\n                    if value.startswith(bookend) and value.endswith(bookend):\n                        value = value[1:-1]\n                        break\n\n                # As the only old-style commands were Linux/Bash based,\n                # we assume using the default separator \":\" is ok - we don't\n                # need to use os.pathsep as we don't expected to see a\n                # Windows path here.\n                separator = config.env_var_separators.get(var, \":\")\n\n                # This is a special case.  We don't want to include \"';'\" in\n                # our env var separators map as it's not really the correct\n                # behaviour/something we want to promote.  It's included here for\n                # backwards compatibility only, and to not propogate elsewhere.\n                if var == \"CMAKE_MODULE_PATH\":\n                    value = value.replace(\"'%s'\" % separator, separator)\n                    value = value.replace('\"%s\"' % separator, separator)\n                    value = value.replace(\":\", separator)\n\n                parts = value.split(separator)\n                parts = [x for x in parts if x]\n                if len(parts) > 1:\n                    idx = None\n                    var1 = \"$%s\" % var\n                    var2 = \"${%s}\" % var\n                    if var1 in parts:\n                        idx = parts.index(var1)\n                    elif var2 in parts:\n                        idx = parts.index(var2)\n                    if idx in (0, len(parts) - 1):\n                        func = \"appendenv\" if idx == 0 else \"prependenv\"\n                        parts = parts[1:] if idx == 0 else parts[:-1]\n                        val = separator.join(parts)\n                        loc.append(\"%s('%s', %s)\" % (func, var, _encode(val)))\n                        continue\n\n                loc.append(\"setenv('%s', %s)\" % (var, _encode(value)))\n            elif toks[0].startswith('#'):\n                loc.append(\"comment(%s)\" % _encode(' '.join(toks[1:])))\n            elif toks[0] == \"alias\":\n                match = re.search(\"alias (?P<key>.*?)=(?P<value>.*)\", cmd)\n                key = match.groupdict()['key'].strip()\n                value = match.groupdict()['value'].strip()\n                if (value.startswith('\"') and value.endswith('\"')) or \\\n                        (value.startswith(\"'\") and value.endswith(\"'\")):\n                    value = value[1:-1]\n                loc.append(\"alias('%s', %s)\" % (key, _encode(value)))\n            else:\n                # assume we can execute this as a straight command\n                loc.append(\"command(%s)\" % _encode(cmd))\n        except:\n            # if anything goes wrong, just fall back to bash command\n            loc.append(\"command(%s)\" % _encode(cmd))\n\n    rex_code = '\\n'.join(loc)\n    if config.debug(\"old_commands\"):\n        br = '-' * 80\n        msg = textwrap.dedent(\n            \"\"\"\n            %s\n            OLD COMMANDS:\n            %s\n\n            NEW COMMANDS:\n            %s\n            %s\n            \"\"\") % (br, '\\n'.join(commands), rex_code, br)\n        print_debug(msg)\n    return rex_code"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a dictionary mapping each pair of nodes to a number (the distance between them). @type graph: graph @param graph: Graph.", "response": "def optimize(self, graph):\n        \"\"\"\n        Build a dictionary mapping each pair of nodes to a number (the distance between them).\n        \n        @type  graph: graph\n        @param graph: Graph. \n        \"\"\"        \n        for center in self.centers:\n            shortest_routes = shortest_path(graph, center)[1]\n            for node, weight in list(shortest_routes.items()):\n                self.nodes.setdefault(node, []).append(weight)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_requirement(req):\n    pkg_name = convert_name(req.project_name)\n    if not req.specs:\n        return [pkg_name]\n\n    req_strs = []\n    for spec in req.specs:\n        op, ver = spec\n        ver = convert_version(ver)\n        if op == \"<\":\n            r = \"%s-0+<%s\" % (pkg_name, ver)\n            req_strs.append(r)\n        elif op == \"<=\":\n            r = \"%s-0+<%s|%s\" % (pkg_name, ver, ver)\n            req_strs.append(r)\n        elif op == \"==\":\n            r = \"%s-%s\" % (pkg_name, ver)\n            req_strs.append(r)\n        elif op == \">=\":\n            r = \"%s-%s+\" % (pkg_name, ver)\n            req_strs.append(r)\n        elif op == \">\":\n            r1 = \"%s-%s+\" % (pkg_name, ver)\n            r2 = \"!%s-%s\" % (pkg_name, ver)\n            req_strs.append(r1)\n            req_strs.append(r2)\n        elif op == \"!=\":\n            r = \"!%s-%s\" % (pkg_name, ver)\n            req_strs.append(r)\n        else:\n            print >> sys.stderr, \\\n                \"Warning: Can't understand op '%s', just depending on unversioned package...\" % op\n            req_strs.append(pkg_name)\n\n    return req_strs", "response": "Converts a pkg_resources. Requirement object into a list of Rez package\n            request strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the dependencies of the given already installed distribution.", "response": "def get_dist_dependencies(name, recurse=True):\n    \"\"\"\n    Get the dependencies of the given, already installed distribution.\n    @param recurse If True, recursively find all dependencies.\n    @returns A set of package names.\n    @note The first entry in the list is always the top-level package itself.\n    \"\"\"\n    dist = pkg_resources.get_distribution(name)\n    pkg_name = convert_name(dist.project_name)\n\n    reqs = set()\n    working = set([dist])\n    depth = 0\n\n    while working:\n        deps = set()\n        for distname in working:\n            dist = pkg_resources.get_distribution(distname)\n            pkg_name = convert_name(dist.project_name)\n            reqs.add(pkg_name)\n\n            for req in dist.requires():\n                reqs_ = convert_requirement(req)\n                deps |= set(x.split('-', 1)[0] for x in reqs_\n                            if not x.startswith('!'))\n\n        working = deps - reqs\n        depth += 1\n        if (not recurse) and (depth >= 2):\n            break\n\n    return reqs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_dist(name, dest_path, make_variant=True, ignore_dirs=None,\n                 python_requirement=\"major_minor\"):\n    \"\"\"Convert an already installed python distribution into a rez package.\n\n    Args:\n        dest_path (str): Where to put the rez package. The package will be\n            created under dest_path/<NAME>/<VERSION>/.\n        make_variant (bool): If True, makes a single variant in the rez package\n            based on the MAJOR.MINOR version of python.\n        ignore_dirs (bool): List of directory names to not copy from the dist.\n        python_requirement (str): How the package should depend on python.\n            One of:\n            - \"major\": depend on python-X\n            - \"major_minor\": depend on python-X.X\n            - any other value: this string is used as the literal version\n              range string.\n\n    Returns:\n        Install path of the new Rez package.\n    \"\"\"\n    dist = pkg_resources.get_distribution(name)\n    pkg_name = convert_name(dist.project_name)\n    pkg_version = convert_version(dist.version)\n\n    if python_requirement == \"major\":\n        pyver = str(sys.version_info[0])\n    elif python_requirement == \"major_minor\":\n        pyver = '.'.join(str(x) for x in sys.version_info[:2])\n    else:\n        pyver = python_requirement\n    pypkg = \"python-%s\" % pyver\n\n    pkg_requires = []\n    if not make_variant:\n        pkg_requires.append(pypkg)\n    for req in dist.requires():\n        pkg_requires += convert_requirement(req)\n\n    pkg_path = _mkdirs(dest_path, pkg_name, pkg_version)\n    pkg_file = os.path.join(pkg_path, \"package.py\")\n    root_path = _mkdirs(pkg_path, pypkg) if make_variant else pkg_path\n\n    basename = os.path.basename(dist.location)\n    is_egg = (os.path.splitext(basename)[1] == \".egg\")\n\n    if os.path.isdir(dist.location):\n        if is_egg:\n            # this is an egg-dir\n            for file in os.listdir(dist.location):\n                fpath = os.path.join(dist.location, file)\n                if os.path.isfile(fpath):\n                    shutil.copy(fpath, root_path)\n                else:\n                    shutil.copytree(fpath, os.path.join(root_path, file),\n                                    ignore=shutil.ignore_patterns(ignore_dirs))\n        else:\n            # this is a site dir\n            egginfo_dir = \"%s.egg-info\" % dist.egg_name()\n            eggpath = os.path.join(dist.location, egginfo_dir)\n            file = os.path.join(eggpath, \"installed-files.txt\")\n            if not os.path.isfile(file):\n                raise RezSystemError(\n                    \"There is not enough information on disk to convert the \"\n                    \"python distribution '%s' into a Rez package. The distribution \"\n                    \"is installed to a common site, but the installed file \"\n                    \"information is not present.\" % name)\n\n            with open(file) as f:\n                installed_files = f.read().strip().split()\n\n            dirs = set()\n            files = set()\n            for file in installed_files:\n                path = os.path.join(eggpath, file)\n                path = os.path.realpath(path)\n\n                if os.path.isfile(path) and path.startswith(dist.location + os.sep):\n                    dir_ = os.path.dirname(path)\n                    if ignore_dirs:\n                        reldir = os.path.relpath(dir_, dist.location)\n                        if set(reldir.split(os.sep)) & set(ignore_dirs):\n                            continue\n\n                    files.add(path)\n                    dirs.add(dir_)\n\n            def _dst(p):\n                dst = os.path.relpath(p, dist.location)\n                dst = os.path.join(root_path, dst)\n                return os.path.realpath(dst)\n\n            for dir_ in dirs:\n                dst_dir = _dst(dir_)\n                _mkdirs(dst_dir)\n\n            for file in files:\n                dst_file = _dst(file)\n                shutil.copy(file, dst_file)\n    else:\n        # this is an egg-file\n        import zipfile\n        assert(is_egg and os.path.isfile(dist.location))\n        assert(zipfile.is_zipfile(dist.location))\n        z = zipfile.ZipFile(dist.location)\n        z.extractall(root_path)\n\n    variants_str = \"[['%s']]\" % pypkg if make_variant else ''\n\n    content = textwrap.dedent(\n        \"\"\"\n        config_version = 0\n        name = '%(name)s'\n        version = '%(version)s'\n        %(variants)s\n        requires = %(requires)s\n        def commands():\n            env.PYTHONPATH.append('{this.root}')\n        \"\"\" % dict(\n            name=pkg_name,\n            version=pkg_version,\n            variants=variants_str,\n            requires=str(pkg_requires)))\n\n    content = content.strip() + '\\n'\n    with open(pkg_file, 'w') as f:\n        f.write(content)\n\n    return pkg_path", "response": "Convert an already installed python distribution into a rez package."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _translate_pattern(self, pattern, anchor=True, prefix=None,\n                           is_regex=False):\n        \"\"\"Translate a shell-like wildcard pattern to a compiled regular\n        expression.\n\n        Return the compiled regex.  If 'is_regex' true,\n        then 'pattern' is directly compiled to a regex (if it's a string)\n        or just returned as-is (assumes it's a regex object).\n        \"\"\"\n        if is_regex:\n            if isinstance(pattern, str):\n                return re.compile(pattern)\n            else:\n                return pattern\n\n        if pattern:\n            pattern_re = self._glob_to_re(pattern)\n        else:\n            pattern_re = ''\n\n        base = re.escape(os.path.join(self.base, ''))\n        if prefix is not None:\n            # ditch end of pattern character\n            empty_pattern = self._glob_to_re('')\n            prefix_re = self._glob_to_re(prefix)[:-len(empty_pattern)]\n            sep = os.sep\n            if os.sep == '\\\\':\n                sep = r'\\\\'\n            pattern_re = '^' + base + sep.join((prefix_re,\n                                                '.*' + pattern_re))\n        else:                               # no prefix -- respect anchor flag\n            if anchor:\n                pattern_re = '^' + base + pattern_re\n\n        return re.compile(pattern_re)", "response": "Translate a shell - like wildcard pattern to a compiled regular expression."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_graph(self, other):\n        self.add_nodes( n for n in other.nodes() if not n in self.nodes() )\n        \n        for each_node in other.nodes():\n            for each_edge in other.neighbors(each_node):\n                if (not self.has_edge((each_node, each_edge))):\n                    self.add_edge((each_node, each_edge))", "response": "Add other graph to this one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a spanning tree to the graph.", "response": "def add_spanning_tree(self, st):\n        \"\"\"\n        Add a spanning tree to the graph.\n        \n        @type  st: dictionary\n        @param st: Spanning tree.\n        \"\"\"\n        self.add_nodes(list(st.keys()))\n        for each in st:\n            if (st[each] is not None):\n                self.add_edge((st[each], each))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef complete(self):\n        for each in self.nodes():\n            for other in self.nodes():\n                if (each != other and not self.has_edge((each, other))):\n                    self.add_edge((each, other))", "response": "Make the current graph a complete graph."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inverse(self):\n        inv = self.__class__()\n        inv.add_nodes(self.nodes())\n        inv.complete()\n        for each in self.edges():\n            if (inv.has_edge(each)):\n                inv.del_edge(each)\n        return inv", "response": "Returns the inverse of the graph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the reverse of a directed graph.", "response": "def reverse(self):\n        \"\"\"\n        Generate the reverse of a directed graph, returns an identical graph if not directed.\n        Attributes & weights are preserved.\n        \n        @rtype: digraph\n        @return: The directed graph that should be reversed.\n        \"\"\"\n        assert self.DIRECTED, \"Undirected graph types such as %s cannot be reversed\" % self.__class__.__name__\n        \n        N = self.__class__()\n    \n        #- Add the nodes\n        N.add_nodes( n for n in self.nodes() )\n    \n        #- Add the reversed edges\n        for (u, v) in self.edges():\n            wt = self.edge_weight((u, v))\n            label = self.edge_label((u, v))\n            attributes = self.edge_attributes((u, v))\n            N.add_edge((v, u), wt, label, attributes)\n        return N"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a package and a version return the equivalent request.", "response": "def get_lock_request(name, version, patch_lock, weak=True):\n    \"\"\"Given a package and patch lock, return the equivalent request.\n\n    For example, for object 'foo-1.2.1' and lock type 'lock_3', the equivalent\n    request is '~foo-1.2'. This restricts updates to foo to patch-or-lower\n    version changes only.\n\n    For objects not versioned down to a given lock level, the closest possible\n    lock is applied. So 'lock_3' applied to 'foo-1' would give '~foo-1'.\n\n    Args:\n        name (str): Package name.\n        version (Version): Package version.\n        patch_lock (PatchLock): Lock type to apply.\n\n    Returns:\n        `PackageRequest` object, or None if there is no equivalent request.\n    \"\"\"\n    ch = '~' if weak else ''\n    if patch_lock == PatchLock.lock:\n        s = \"%s%s==%s\" % (ch, name, str(version))\n        return PackageRequest(s)\n    elif (patch_lock == PatchLock.no_lock) or (not version):\n        return None\n    version_ = version.trim(patch_lock.rank)\n    s = \"%s%s-%s\" % (ch, name, str(version_))\n    return PackageRequest(s)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of packages that are requested for this locale.", "response": "def requested_packages(self, include_implicit=False):\n        \"\"\"Get packages in the request.\n\n        Args:\n            include_implicit (bool): If True, implicit packages are appended\n                to the result.\n\n        Returns:\n            List of `PackageRequest` objects.\n        \"\"\"\n        if include_implicit:\n            return self._package_requests + self.implicit_packages\n        else:\n            return self._package_requests"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_resolved_package(self, name):\n        pkgs = [x for x in self._resolved_packages if x.name == name]\n        return pkgs[0] if pkgs else None", "response": "Returns a Variant object or None if the package is not in the resolve. the\n        is not in the resolve. the\n        is not in the resolve. the\n        is not in the resolve. the\n        is not in the resolve. the\n        is not in the resolve. The name parameter is the name of the package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a patched request for the current context.", "response": "def get_patched_request(self, package_requests=None,\n                            package_subtractions=None, strict=False, rank=0):\n        \"\"\"Get a 'patched' request.\n\n        A patched request is a copy of this context's request, but with some\n        changes applied. This can then be used to create a new, 'patched'\n        context.\n\n        New package requests override original requests based on the type -\n        normal, conflict or weak. So 'foo-2' overrides 'foo-1', '!foo-2'\n        overrides '!foo-1' and '~foo-2' overrides '~foo-1', but a request such\n        as '!foo-2' would not replace 'foo-1' - it would be added instead.\n\n        Note that requests in `package_requests` can have the form '^foo'. This\n        is another way of supplying package subtractions.\n\n        Any new requests that don't override original requests are appended,\n        in the order that they appear in `package_requests`.\n\n        Args:\n            package_requests (list of str or list of `PackageRequest`):\n                Overriding requests.\n            package_subtractions (list of str): Any original request with a\n                package name in this list is removed, before the new requests\n                are added.\n            strict (bool): If True, the current context's resolve is used as the\n                original request list, rather than the request.\n            rank (int): If > 1, package versions can only increase in this rank\n                and further - for example, rank=3 means that only version patch\n                numbers are allowed to increase, major and minor versions will\n                not change. This is only applied to packages that have not been\n                explicitly overridden in `package_requests`. If rank <= 1, or\n                `strict` is True, rank is ignored.\n\n        Returns:\n            List of `PackageRequest` objects that can be used to construct a\n            new `ResolvedContext` object.\n        \"\"\"\n        # assemble source request\n        if strict:\n            request = []\n            for variant in self.resolved_packages:\n                req = PackageRequest(variant.qualified_package_name)\n                request.append(req)\n        else:\n            request = self.requested_packages()[:]\n\n        # convert '^foo'-style requests to subtractions\n        if package_requests:\n            package_subtractions = package_subtractions or []\n            indexes = []\n            for i, req in enumerate(package_requests):\n                name = str(req)\n                if name.startswith('^'):\n                    package_subtractions.append(name[1:])\n                    indexes.append(i)\n            for i in reversed(indexes):\n                del package_requests[i]\n\n        # apply subtractions\n        if package_subtractions:\n            request = [x for x in request if x.name not in package_subtractions]\n\n        # apply overrides\n        if package_requests:\n            request_dict = dict((x.name, (i, x)) for i, x in enumerate(request))\n            request_ = []\n\n            for req in package_requests:\n                if isinstance(req, basestring):\n                    req = PackageRequest(req)\n\n                if req.name in request_dict:\n                    i, req_ = request_dict[req.name]\n                    if (req_ is not None) and (req_.conflict == req.conflict) \\\n                            and (req_.weak == req.weak):\n                        request[i] = req\n                        del request_dict[req.name]\n                    else:\n                        request_.append(req)\n                else:\n                    request_.append(req)\n\n            request += request_\n\n        # add rank limiters\n        if not strict and rank > 1:\n            overrides = set(x.name for x in package_requests if not x.conflict)\n            rank_limiters = []\n            for variant in self.resolved_packages:\n                if variant.name not in overrides:\n                    if len(variant.version) >= rank:\n                        version = variant.version.trim(rank - 1)\n                        version = version.next()\n                        req = \"~%s<%s\" % (variant.name, str(version))\n                        rank_limiters.append(req)\n            request += rank_limiters\n\n        return request"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the resolve graph.", "response": "def graph(self, as_dot=False):\n        \"\"\"Get the resolve graph.\n\n        Args:\n            as_dot: If True, get the graph as a dot-language string. Otherwise,\n                a pygraph.digraph object is returned.\n\n        Returns:\n            A string or `pygraph.digraph` object, or None if there is no graph\n            associated with the resolve.\n        \"\"\"\n        if not self.has_graph:\n            return None\n\n        if not as_dot:\n            if self.graph_ is None:\n                # reads either dot format or our compact format\n                self.graph_ = read_graph_from_string(self.graph_string)\n            return self.graph_\n\n        if self.graph_string:\n            if self.graph_string.startswith('{'):  # compact format\n                self.graph_ = read_graph_from_string(self.graph_string)\n            else:\n                # already in dot format. Note that this will only happen in\n                # old rez contexts where the graph is not stored in the newer\n                # compact format.\n                return self.graph_string\n\n        return write_dot(self.graph_)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the context to a buffer.", "response": "def write_to_buffer(self, buf):\n        \"\"\"Save the context to a buffer.\"\"\"\n        doc = self.to_dict()\n\n        if config.rxt_as_yaml:\n            content = dump_yaml(doc)\n        else:\n            content = json.dumps(doc, indent=4, separators=(\",\", \": \"))\n\n        buf.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_current(cls):\n        filepath = os.getenv(\"REZ_RXT_FILE\")\n        if not filepath or not os.path.exists(filepath):\n            return None\n\n        return cls.load(filepath)", "response": "Get the current context for the current env if there is one."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(cls, path):\n        with open(path) as f:\n            context = cls.read_from_buffer(f, path)\n        context.set_load_path(path)\n        return context", "response": "Load a resolved context from file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the context from a buffer.", "response": "def read_from_buffer(cls, buf, identifier_str=None):\n        \"\"\"Load the context from a buffer.\"\"\"\n        try:\n            return cls._read_from_buffer(buf, identifier_str)\n        except Exception as e:\n            cls._load_error(e, identifier_str)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the difference between the resolve in this context and another.", "response": "def get_resolve_diff(self, other):\n        \"\"\"Get the difference between the resolve in this context and another.\n\n        The difference is described from the point of view of the current context\n        - a newer package means that the package in `other` is newer than the\n        package in `self`.\n\n        Diffs can only be compared if their package search paths match, an error\n        is raised otherwise.\n\n        The diff is expressed in packages, not variants - the specific variant\n        of a package is ignored.\n\n        Returns:\n            A dict containing:\n            - 'newer_packages': A dict containing items:\n              - package name (str);\n              - List of `Package` objects. These are the packages up to and\n                including the newer package in `self`, in ascending order.\n            - 'older_packages': A dict containing:\n              - package name (str);\n              - List of `Package` objects. These are the packages down to and\n                including the older package in `self`, in descending order.\n            - 'added_packages': Set of `Package` objects present in `self` but\n               not in `other`;\n            - 'removed_packages': Set of `Package` objects present in `other`,\n               but not in `self`.\n\n            If any item ('added_packages' etc) is empty, it is not added to the\n            resulting dict. Thus, an empty dict is returned if there is no\n            difference between contexts.\n        \"\"\"\n        if self.package_paths != other.package_paths:\n            from difflib import ndiff\n            diff = ndiff(self.package_paths, other.package_paths)\n            raise ResolvedContextError(\"Cannot diff resolves, package search \"\n                                       \"paths differ:\\n%s\" % '\\n'.join(diff))\n\n        d = {}\n        self_pkgs_ = set(x.parent for x in self._resolved_packages)\n        other_pkgs_ = set(x.parent for x in other._resolved_packages)\n        self_pkgs = self_pkgs_ - other_pkgs_\n        other_pkgs = other_pkgs_ - self_pkgs_\n        if not (self_pkgs or other_pkgs):\n            return d\n\n        self_fams = dict((x.name, x) for x in self_pkgs)\n        other_fams = dict((x.name, x) for x in other_pkgs)\n\n        newer_packages = {}\n        older_packages = {}\n        added_packages = set()\n        removed_packages = set()\n\n        for pkg in self_pkgs:\n            if pkg.name not in other_fams:\n                removed_packages.add(pkg)\n            else:\n                other_pkg = other_fams[pkg.name]\n                if other_pkg.version > pkg.version:\n                    r = VersionRange.as_span(lower_version=pkg.version,\n                                             upper_version=other_pkg.version)\n                    it = iter_packages(pkg.name, range_=r)\n                    pkgs = sorted(it, key=lambda x: x.version)\n                    newer_packages[pkg.name] = pkgs\n                elif other_pkg.version < pkg.version:\n                    r = VersionRange.as_span(lower_version=other_pkg.version,\n                                             upper_version=pkg.version)\n                    it = iter_packages(pkg.name, range_=r)\n                    pkgs = sorted(it, key=lambda x: x.version, reverse=True)\n                    older_packages[pkg.name] = pkgs\n\n        for pkg in other_pkgs:\n            if pkg.name not in self_fams:\n                added_packages.add(pkg)\n\n        if newer_packages:\n            d[\"newer_packages\"] = newer_packages\n        if older_packages:\n            d[\"older_packages\"] = older_packages\n        if added_packages:\n            d[\"added_packages\"] = added_packages\n        if removed_packages:\n            d[\"removed_packages\"] = removed_packages\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints a message summarising the contents of the resolved context.", "response": "def print_info(self, buf=sys.stdout, verbosity=0, source_order=False,\n                   show_resolved_uris=False):\n        \"\"\"Prints a message summarising the contents of the resolved context.\n\n        Args:\n            buf (file-like object): Where to print this info to.\n            verbosity (bool): Verbose mode.\n            source_order (bool): If True, print resolved packages in the order\n                they are sourced, rather than alphabetical order.\n            show_resolved_uris (bool): By default, resolved packages have their\n                'root' property listed, or their 'uri' if 'root' is None. Use\n                this option to list 'uri' regardless.\n        \"\"\"\n        _pr = Printer(buf)\n\n        def _rt(t):\n            if verbosity:\n                s = time.strftime(\"%a %b %d %H:%M:%S %Z %Y\", time.localtime(t))\n                return s + \" (%d)\" % int(t)\n            else:\n                return time.strftime(\"%a %b %d %H:%M:%S %Y\", time.localtime(t))\n\n        if self.status_ in (ResolverStatus.failed, ResolverStatus.aborted):\n            _pr(\"The context failed to resolve:\\n%s\"\n                % self.failure_description, critical)\n            return\n\n        t_str = _rt(self.created)\n        _pr(\"resolved by %s@%s, on %s, using Rez v%s\"\n            % (self.user, self.host, t_str, self.rez_version))\n        if self.requested_timestamp:\n            t_str = _rt(self.requested_timestamp)\n            _pr(\"packages released after %s were ignored\" % t_str)\n        _pr()\n\n        if verbosity:\n            _pr(\"search paths:\", heading)\n            rows = []\n            colors = []\n            for path in self.package_paths:\n                if package_repository_manager.are_same(path, config.local_packages_path):\n                    label = \"(local)\"\n                    col = local\n                else:\n                    label = \"\"\n                    col = None\n                rows.append((path, label))\n                colors.append(col)\n\n            for col, line in zip(colors, columnise(rows)):\n                _pr(line, col)\n            _pr()\n\n            if self.package_filter:\n                data = self.package_filter.to_pod()\n                txt = dump_yaml(data)\n                _pr(\"package filters:\", heading)\n                _pr(txt)\n                _pr()\n\n        _pr(\"requested packages:\", heading)\n        rows = []\n        colors = []\n        for request in self._package_requests:\n            rows.append((str(request), \"\"))\n            colors.append(None)\n\n        for request in self.implicit_packages:\n            rows.append((str(request), \"(implicit)\"))\n            colors.append(implicit)\n\n        for col, line in zip(colors, columnise(rows)):\n            _pr(line, col)\n        _pr()\n\n        _pr(\"resolved packages:\", heading)\n        rows = []\n        colors = []\n\n        resolved_packages = self.resolved_packages or []\n        if not source_order:\n            resolved_packages = sorted(resolved_packages, key=lambda x: x.name)\n\n        for pkg in resolved_packages:\n            t = []\n            col = None\n            location = None\n\n            # print root/uri\n            if show_resolved_uris or not pkg.root:\n                location = pkg.uri\n            else:\n                location = pkg.root\n                if not os.path.exists(pkg.root):\n                    t.append('NOT FOUND')\n                    col = critical\n\n            if pkg.is_local:\n                t.append('local')\n                col = local\n\n            t = '(%s)' % ', '.join(t) if t else ''\n            rows.append((pkg.qualified_package_name, location, t))\n            colors.append(col)\n\n        for col, line in zip(colors, columnise(rows)):\n            _pr(line, col)\n\n        if verbosity:\n            _pr()\n            actual_solve_time = self.solve_time - self.load_time\n            _pr(\"resolve details:\", heading)\n            _pr(\"load time:         %.02f secs\" % self.load_time)\n            _pr(\"solve time:        %.02f secs\" % actual_solve_time)\n            _pr(\"packages queried:  %d\" % self.num_loaded_packages)\n            _pr(\"from cache:        %s\" % self.from_cache)\n            if self.load_path:\n                _pr(\"rxt file:          %s\" % self.load_path)\n\n        if verbosity >= 2:\n            _pr()\n            _pr(\"tools:\", heading)\n            self.print_tools(buf=buf)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_resolve_diff(self, other, heading=None):\n        d = self.get_resolve_diff(other)\n        if not d:\n            return\n\n        rows = []\n        if heading is True and self.load_path and other.load_path:\n            a = os.path.basename(self.load_path)\n            b = os.path.basename(other.load_path)\n            heading = (a, b)\n        if isinstance(heading, tuple):\n            rows.append(list(heading) + [\"\"])\n            rows.append(('-' * len(heading[0]), '-' * len(heading[1]), \"\"))\n\n        newer_packages = d.get(\"newer_packages\", {})\n        older_packages = d.get(\"older_packages\", {})\n        added_packages = d.get(\"added_packages\", set())\n        removed_packages = d.get(\"removed_packages\", set())\n\n        if newer_packages:\n            for name, pkgs in newer_packages.iteritems():\n                this_pkg = pkgs[0]\n                other_pkg = pkgs[-1]\n                diff_str = \"(+%d versions)\" % (len(pkgs) - 1)\n                rows.append((this_pkg.qualified_name,\n                            other_pkg.qualified_name,\n                            diff_str))\n\n        if older_packages:\n            for name, pkgs in older_packages.iteritems():\n                this_pkg = pkgs[0]\n                other_pkg = pkgs[-1]\n                diff_str = \"(-%d versions)\" % (len(pkgs) - 1)\n                rows.append((this_pkg.qualified_name,\n                            other_pkg.qualified_name,\n                            diff_str))\n\n        if added_packages:\n            for pkg in sorted(added_packages, key=lambda x: x.name):\n                rows.append((\"-\", pkg.qualified_name, \"\"))\n\n        if removed_packages:\n            for pkg in sorted(removed_packages, key=lambda x: x.name):\n                rows.append((pkg.qualified_name, \"-\", \"\"))\n\n        print '\\n'.join(columnise(rows))", "response": "Prints the difference between the resolve of two contexts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dependency_graph(self):\n        from rez.vendor.pygraph.classes.digraph import digraph\n\n        nodes = {}\n        edges = set()\n        for variant in self._resolved_packages:\n            nodes[variant.name] = variant.qualified_package_name\n            for request in variant.get_requires():\n                if not request.conflict:\n                    edges.add((variant.name, request.name))\n\n        g = digraph()\n        node_color = \"#AAFFAA\"\n        node_fontsize = 10\n        attrs = [(\"fontsize\", node_fontsize),\n                 (\"fillcolor\", node_color),\n                 (\"style\", \"filled\")]\n\n        for name, qname in nodes.iteritems():\n            g.add_node(name, attrs=attrs + [(\"label\", qname)])\n        for edge in edges:\n            g.add_edge(edge)\n        return g", "response": "Generate the dependency graph for the current set of packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_environ(self, parent_environ=None):\n        interp = Python(target_environ={}, passive=True)\n        executor = self._create_executor(interp, parent_environ)\n        self._execute(executor)\n        return executor.get_output()", "response": "Get the environ dict resulting from interpreting this context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_key(self, key, request_only=False):\n        values = {}\n        requested_names = [x.name for x in self._package_requests\n                           if not x.conflict]\n\n        for pkg in self.resolved_packages:\n            if (not request_only) or (pkg.name in requested_names):\n                value = getattr(pkg, key)\n                if value is not None:\n                    values[pkg.name] = (pkg, value)\n\n        return values", "response": "Get a data key value for each resolved package."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tool_variants(self, tool_name):\n        variants = set()\n        tools_dict = self.get_tools(request_only=False)\n        for variant, tools in tools_dict.itervalues():\n            if tool_name in tools:\n                variants.add(variant)\n        return variants", "response": "Returns the set of all the variants that provide the named tool."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_conflicting_tools(self, request_only=False):\n        from collections import defaultdict\n\n        tool_sets = defaultdict(set)\n        tools_dict = self.get_tools(request_only=request_only)\n        for variant, tools in tools_dict.itervalues():\n            for tool in tools:\n                tool_sets[tool].add(variant)\n\n        conflicts = dict((k, v) for k, v in tool_sets.iteritems() if len(v) > 1)\n        return conflicts", "response": "Returns a dictionary of tools that are not present in the request but have more than one package."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_shell_code(self, shell=None, parent_environ=None, style=OutputStyle.file):\n        executor = self._create_executor(interpreter=create_shell(shell),\n                                         parent_environ=parent_environ)\n\n        if self.load_path and os.path.isfile(self.load_path):\n            executor.env.REZ_RXT_FILE = self.load_path\n\n        self._execute(executor)\n        return executor.get_output(style)", "response": "Returns the shell code resulting from intepreting this context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the list of rex. Action objects resulting from interpreting this context.", "response": "def get_actions(self, parent_environ=None):\n        \"\"\"Get the list of rex.Action objects resulting from interpreting this\n        context. This is provided mainly for testing purposes.\n\n        Args:\n            parent_environ Environment to interpret the context within,\n                defaults to os.environ if None.\n\n        Returns:\n            A list of rex.Action subclass instances.\n        \"\"\"\n        interp = Python(target_environ={}, passive=True)\n        executor = self._create_executor(interp, parent_environ)\n        self._execute(executor)\n        return executor.actions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying the context to the current python session.", "response": "def apply(self, parent_environ=None):\n        \"\"\"Apply the context to the current python session.\n\n        Note that this updates os.environ and possibly sys.path, if\n        `parent_environ` is not provided.\n\n        Args:\n            parent_environ: Environment to interpret the context within,\n                defaults to os.environ if None.\n        \"\"\"\n        interpreter = Python(target_environ=os.environ)\n        executor = self._create_executor(interpreter, parent_environ)\n        self._execute(executor)\n        interpreter.apply_environ()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a program in the resolved environment.", "response": "def which(self, cmd, parent_environ=None, fallback=False):\n        \"\"\"Find a program in the resolved environment.\n\n        Args:\n            cmd: String name of the program to find.\n            parent_environ: Environment to interpret the context within,\n                defaults to os.environ if None.\n            fallback: If True, and the program is not found in the context,\n                the current environment will then be searched.\n\n        Returns:\n            Path to the program, or None if the program was not found.\n        \"\"\"\n        env = self.get_environ(parent_environ=parent_environ)\n        path = which(cmd, env=env)\n        if fallback and path is None:\n            path = which(cmd)\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute_command(self, args, parent_environ=None, **subprocess_kwargs):\n        if parent_environ in (None, os.environ):\n            target_environ = {}\n        else:\n            target_environ = parent_environ.copy()\n\n        interpreter = Python(target_environ=target_environ)\n\n        executor = self._create_executor(interpreter, parent_environ)\n        self._execute(executor)\n        return interpreter.subprocess(args, **subprocess_kwargs)", "response": "Execute a command within a resolved context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute_rex_code(self, code, filename=None, shell=None,\n                         parent_environ=None, **Popen_args):\n        \"\"\"Run some rex code in the context.\n\n        Note:\n            This is just a convenience form of `execute_shell`.\n\n        Args:\n            code (str): Rex code to execute.\n            filename (str): Filename to report if there are syntax errors.\n            shell: Shell type, for eg 'bash'. If None, the current shell type\n                is used.\n            parent_environ: Environment to run the shell process in, if None\n                then the current environment is used.\n            Popen_args: args to pass to the shell process object constructor.\n\n        Returns:\n            `subprocess.Popen` object for the shell process.\n        \"\"\"\n        def _actions_callback(executor):\n            executor.execute_code(code, filename=filename)\n\n        return self.execute_shell(shell=shell,\n                                  parent_environ=parent_environ,\n                                  command='',  # don't run any command\n                                  block=False,\n                                  actions_callback=_actions_callback,\n                                  **Popen_args)", "response": "Execute some rex code in the context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute_shell(self, shell=None, parent_environ=None, rcfile=None,\n                      norc=False, stdin=False, command=None, quiet=False,\n                      block=None, actions_callback=None, post_actions_callback=None,\n                      context_filepath=None, start_new_session=False, detached=False,\n                      pre_command=None, **Popen_args):\n        \"\"\"Spawn a possibly-interactive shell.\n\n        Args:\n            shell: Shell type, for eg 'bash'. If None, the current shell type\n                is used.\n            parent_environ: Environment to run the shell process in, if None\n                then the current environment is used.\n            rcfile: Specify a file to source instead of shell startup files.\n            norc: If True, skip shell startup files, if possible.\n            stdin: If True, read commands from stdin, in a non-interactive\n                shell.\n            command: If not None, execute this command in a non-interactive shell.\n                If an empty string or list, don't run a command, but don't open\n                an interactive shell either. Can be a list of args.\n            quiet: If True, skip the welcome message in interactive shells.\n            block: If True, block until the shell is terminated. If False,\n                return immediately. If None, will default to blocking if the\n                shell is interactive.\n            actions_callback: Callback with signature (RexExecutor). This lets\n                the user append custom actions to the context, such as setting\n                extra environment variables. Callback is run prior to context Rex\n                execution.\n            post_actions_callback: Callback with signature (RexExecutor). This lets\n                the user append custom actions to the context, such as setting\n                extra environment variables. Callback is run after context Rex\n                execution.\n            context_filepath: If provided, the context file will be written\n                here, rather than to the default location (which is in a\n                tempdir). If you use this arg, you are responsible for cleaning\n                up the file.\n            start_new_session: If True, change the process group of the target\n                process. Note that this may override the Popen_args keyword\n                'preexec_fn'.\n            detached: If True, open a separate terminal. Note that this may\n                override the `pre_command` argument.\n            pre_command: Command to inject before the shell command itself. This\n                is for internal use.\n            Popen_args: args to pass to the shell process object constructor.\n\n        Returns:\n            If blocking: A 3-tuple of (returncode, stdout, stderr);\n            If non-blocking - A subprocess.Popen object for the shell process.\n        \"\"\"\n        sh = create_shell(shell)\n\n        if hasattr(command, \"__iter__\"):\n            command = sh.join(command)\n\n        # start a new session if specified\n        if start_new_session:\n            Popen_args.update(config.new_session_popen_args)\n\n        # open a separate terminal if specified\n        if detached:\n            term_cmd = config.terminal_emulator_command\n            if term_cmd:\n                pre_command = term_cmd.strip().split()\n\n        # block if the shell is likely to be interactive\n        if block is None:\n            block = not (command or stdin)\n\n        # context and rxt files. If running detached, don't cleanup files, because\n        # rez-env returns too early and deletes the tmp files before the detached\n        # process can use them\n        tmpdir = self.tmpdir_manager.mkdtemp(cleanup=not detached)\n\n        if self.load_path and os.path.isfile(self.load_path):\n            rxt_file = self.load_path\n        else:\n            rxt_file = os.path.join(tmpdir, \"context.rxt\")\n            self.save(rxt_file)\n\n        context_file = context_filepath or \\\n            os.path.join(tmpdir, \"context.%s\" % sh.file_extension())\n\n        # interpret this context and write out the native context file\n        executor = self._create_executor(sh, parent_environ)\n        executor.env.REZ_RXT_FILE = rxt_file\n        executor.env.REZ_CONTEXT_FILE = context_file\n\n        if actions_callback:\n            actions_callback(executor)\n\n        self._execute(executor)\n\n        if post_actions_callback:\n            post_actions_callback(executor)\n\n        context_code = executor.get_output()\n        with open(context_file, 'w') as f:\n            f.write(context_code)\n\n        quiet = quiet or \\\n            (RezToolsVisibility[config.rez_tools_visibility] == RezToolsVisibility.never)\n\n        # spawn the shell subprocess\n        p = sh.spawn_shell(context_file,\n                           tmpdir,\n                           rcfile=rcfile,\n                           norc=norc,\n                           stdin=stdin,\n                           command=command,\n                           env=parent_environ,\n                           quiet=quiet,\n                           pre_command=pre_command,\n                           **Popen_args)\n        if block:\n            stdout, stderr = p.communicate()\n            return p.returncode, stdout, stderr\n        else:\n            return p", "response": "Executes a possibly - interactive shell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert this context to a dict containing only builtin types.", "response": "def to_dict(self, fields=None):\n        \"\"\"Convert context to dict containing only builtin types.\n\n        Args:\n            fields (list of str): If present, only write these fields into the\n                dict. This can be used to avoid constructing expensive fields\n                (such as 'graph') for some cases.\n\n        Returns:\n            dict: Dictified context.\n        \"\"\"\n        data = {}\n\n        def _add(field):\n            return (fields is None or field in fields)\n\n        if _add(\"resolved_packages\"):\n            resolved_packages = []\n            for pkg in (self._resolved_packages or []):\n                resolved_packages.append(pkg.handle.to_dict())\n            data[\"resolved_packages\"] = resolved_packages\n\n        if _add(\"serialize_version\"):\n            data[\"serialize_version\"] = \\\n                '.'.join(map(str, ResolvedContext.serialize_version))\n\n        if _add(\"patch_locks\"):\n            data[\"patch_locks\"] = dict((k, v.name) for k, v in self.patch_locks)\n\n        if _add(\"package_orderers\"):\n            package_orderers = [package_order.to_pod(x)\n                                for x in (self.package_orderers or [])]\n            data[\"package_orderers\"] = package_orderers or None\n\n        if _add(\"package_filter\"):\n            data[\"package_filter\"] = self.package_filter.to_pod()\n\n        if _add(\"graph\"):\n            if self.graph_string and self.graph_string.startswith('{'):\n                graph_str = self.graph_string  # already in compact format\n            else:\n                g = self.graph()\n                graph_str = write_compacted(g)\n\n            data[\"graph\"] = graph_str\n\n        data.update(dict(\n            timestamp=self.timestamp,\n            requested_timestamp=self.requested_timestamp,\n            building=self.building,\n            caching=self.caching,\n            implicit_packages=map(str, self.implicit_packages),\n            package_requests=map(str, self._package_requests),\n            package_paths=self.package_paths,\n\n            default_patch_lock=self.default_patch_lock.name,\n\n            rez_version=self.rez_version,\n            rez_path=self.rez_path,\n            user=self.user,\n            host=self.host,\n            platform=self.platform,\n            arch=self.arch,\n            os=self.os,\n            created=self.created,\n\n            parent_suite_path=self.parent_suite_path,\n            suite_context_name=self.suite_context_name,\n\n            status=self.status_.name,\n            failure_description=self.failure_description,\n\n            from_cache=self.from_cache,\n            solve_time=self.solve_time,\n            load_time=self.load_time,\n            num_loaded_packages=self.num_loaded_packages\n        ))\n\n        if fields:\n            data = dict((k, v) for k, v in data.iteritems() if k in fields)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(cls, d, identifier_str=None):\n        # check serialization version\n        def _print_version(value):\n            return '.'.join(str(x) for x in value)\n\n        toks = str(d[\"serialize_version\"]).split('.')\n        load_ver = tuple(int(x) for x in toks)\n        curr_ver = ResolvedContext.serialize_version\n\n        if load_ver[0] > curr_ver[0]:\n            msg = [\"The context\"]\n            if identifier_str:\n                msg.append(\"in %s\" % identifier_str)\n            msg.append(\"was written by a newer version of Rez. The load may \"\n                       \"fail (serialize version %d > %d)\"\n                       % (_print_version(load_ver), _print_version(curr_ver)))\n            print >> sys.stderr, ' '.join(msg)\n\n        # create and init the context\n        r = ResolvedContext.__new__(ResolvedContext)\n        r.load_path = None\n        r.pre_resolve_bindings = None\n\n        r.timestamp = d[\"timestamp\"]\n        r.building = d[\"building\"]\n        r.caching = d[\"caching\"]\n        r.implicit_packages = [PackageRequest(x) for x in d[\"implicit_packages\"]]\n        r._package_requests = [PackageRequest(x) for x in d[\"package_requests\"]]\n        r.package_paths = d[\"package_paths\"]\n\n        r.rez_version = d[\"rez_version\"]\n        r.rez_path = d[\"rez_path\"]\n        r.user = d[\"user\"]\n        r.host = d[\"host\"]\n        r.platform = d[\"platform\"]\n        r.arch = d[\"arch\"]\n        r.os = d[\"os\"]\n        r.created = d[\"created\"]\n        r.verbosity = d.get(\"verbosity\", 0)\n\n        r.status_ = ResolverStatus[d[\"status\"]]\n        r.failure_description = d[\"failure_description\"]\n\n        r.solve_time = d[\"solve_time\"]\n        r.load_time = d[\"load_time\"]\n\n        r.graph_string = d[\"graph\"]\n        r.graph_ = None\n\n        r._resolved_packages = []\n        for d_ in d[\"resolved_packages\"]:\n            variant_handle = d_\n            if load_ver < (4, 0):\n                # -- SINCE SERIALIZE VERSION 4.0\n                from rez.utils.backcompat import convert_old_variant_handle\n                variant_handle = convert_old_variant_handle(variant_handle)\n\n            variant = get_variant(variant_handle)\n            variant.set_context(r)\n            r._resolved_packages.append(variant)\n\n        # -- SINCE SERIALIZE VERSION 1\n\n        r.requested_timestamp = d.get(\"requested_timestamp\", 0)\n\n        # -- SINCE SERIALIZE VERSION 2\n\n        r.parent_suite_path = d.get(\"parent_suite_path\")\n        r.suite_context_name = d.get(\"suite_context_name\")\n\n        # -- SINCE SERIALIZE VERSION 3\n\n        r.default_patch_lock = PatchLock[d.get(\"default_patch_lock\", \"no_lock\")]\n        patch_locks = d.get(\"patch_locks\", {})\n        r.patch_locks = dict((k, PatchLock[v]) for k, v in patch_locks)\n\n        # -- SINCE SERIALIZE VERSION 4.0\n\n        r.from_cache = d.get(\"from_cache\", False)\n\n        # -- SINCE SERIALIZE VERSION 4.1\n\n        data = d.get(\"package_filter\", [])\n        r.package_filter = PackageFilterList.from_pod(data)\n\n        # -- SINCE SERIALIZE VERSION 4.2\n\n        data = d.get(\"package_orderers\")\n        if data:\n            r.package_orderers = [package_order.from_pod(x) for x in data]\n        else:\n            r.package_orderers = None\n\n        # -- SINCE SERIALIZE VERSION 4.3\n\n        r.num_loaded_packages = d.get(\"num_loaded_packages\", -1)\n\n        # track context usage\n        if config.context_tracking_host:\n            data = dict((k, v) for k, v in d.iteritems()\n                        if k in config.context_tracking_context_fields)\n\n            r._track_context(data, action=\"sourced\")\n\n        return r", "response": "Load a ResolvedContext object from a dictionary containing context data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optimize(self, graph):\n        for start in graph.nodes():\n            for end in graph.nodes():\n                for each in graph.node_attributes(start):\n                    if (each[0] == 'position'):\n                        start_attr = each[1]\n                        break\n                for each in graph.node_attributes(end):\n                    if (each[0] == 'position'):\n                        end_attr = each[1]\n                        break\n                dist = 0\n                for i in range(len(start_attr)):\n                    dist = dist + (float(start_attr[i]) - float(end_attr[i]))**2\n                self.distances[(start,end)] = dist", "response": "This method calculates the distance between two nodes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_sys_paths(paths):\n    original_syspath = sys.path[:]\n    sys.path.extend(paths)\n\n    try:\n        yield\n    finally:\n        sys.path = original_syspath", "response": "Add paths to sys. path and revert on scope exit."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps for subprocess. Popen.", "response": "def popen(args, **kwargs):\n    \"\"\"Wrapper for `subprocess.Popen`.\n\n    Avoids python bug described here: https://bugs.python.org/issue3905. This\n    can arise when apps (maya) install a non-standard stdin handler.\n\n    In newer version of maya and katana, the sys.stdin object can also become\n    replaced by an object with no 'fileno' attribute, this is also taken into\n    account.\n    \"\"\"\n    if \"stdin\" not in kwargs:\n        try:\n            file_no = sys.stdin.fileno()\n        except AttributeError:\n            file_no = sys.__stdin__.fileno()\n\n        if file_no not in (0, 1, 2):\n            kwargs[\"stdin\"] = subprocess.PIPE\n\n    return subprocess.Popen(args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _yield_distributions(self):\n        # We need to check if we've seen some resources already, because on\n        # some Linux systems (e.g. some Debian/Ubuntu variants) there are\n        # symlinks which alias other files in the environment.\n        seen = set()\n        for path in self.path:\n            finder = resources.finder_for_path(path)\n            if finder is None:\n                continue\n            r = finder.find('')\n            if not r or not r.is_container:\n                continue\n            rset = sorted(r.resources)\n            for entry in rset:\n                r = finder.find(entry)\n                if not r or r.path in seen:\n                    continue\n                if self._include_dist and entry.endswith(DISTINFO_EXT):\n                    possible_filenames = [METADATA_FILENAME, WHEEL_METADATA_FILENAME]\n                    for metadata_filename in possible_filenames:\n                        metadata_path = posixpath.join(entry, metadata_filename)\n                        pydist = finder.find(metadata_path)\n                        if pydist:\n                            break\n                    else:\n                        continue\n\n                    with contextlib.closing(pydist.as_stream()) as stream:\n                        metadata = Metadata(fileobj=stream, scheme='legacy')\n                    logger.debug('Found %s', r.path)\n                    seen.add(r.path)\n                    yield new_dist_class(r.path, metadata=metadata,\n                                         env=self)\n                elif self._include_egg and entry.endswith(('.egg-info',\n                                                          '.egg')):\n                    logger.debug('Found %s', r.path)\n                    seen.add(r.path)\n                    yield old_dist_class(r.path, self)", "response": "Yields all distributions and egg - info and. dist - info files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tracking_branch(self):\n        try:\n            remote_uri = self.git(\"rev-parse\", \"--abbrev-ref\",\n                                  \"--symbolic-full-name\", \"@{u}\")[0]\n            return remote_uri.split('/', 1)\n        except Exception as e:\n            # capitalization of message changed sometime between git 1.8.3\n            # and 2.12 - used to be \"No upstream\", now \"no upstream\"..\n            errmsg = str(e).lower()\n            if (\"no upstream branch\" not in errmsg\n                    and \"no upstream configured\" not in errmsg):\n                raise e\n        return (None, None)", "response": "Returns tuple of remote and branch of the current branch of the current branch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all nodes connected by the given hyperedge or all hyperedges connected to the given hypernode.", "response": "def links(self, obj):\n        \"\"\"\n        Return all nodes connected by the given hyperedge or all hyperedges\n        connected to the given hypernode.\n        \n        @type  obj: hyperedge\n        @param obj: Object identifier.\n        \n        @rtype:  list\n        @return: List of node objects linked to the given hyperedge.\n        \"\"\"\n        if obj in self.edge_links:\n            return self.edge_links[obj]\n        else:\n            return self.node_links[obj]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef neighbors(self, obj):\n        neighbors = set([])\n        \n        for e in self.node_links[obj]:\n            neighbors.update(set(self.edge_links[e]))\n        \n        return list(neighbors - set([obj]))", "response": "Return all neighbors adjacent to the given object identifier."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_node(self, node):\n        if (not node in self.node_links):\n            self.node_links[node] = []\n            self.node_attr[node] = []\n            self.graph.add_node((node,'n'))\n        else:\n            raise AdditionError(\"Node %s already in graph\" % node)", "response": "Adds given node to the hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef del_node(self, node):\n        if self.has_node(node):\n            for e in self.node_links[node]:\n                self.edge_links[e].remove(node)\n\n            self.node_links.pop(node)\n            self.graph.del_node((node,'n'))", "response": "Delete a given node from the hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_hyperedge(self, hyperedge):\n        if (not hyperedge in self.edge_links):\n            self.edge_links[hyperedge] = []\n            self.graph.add_node((hyperedge,'h'))", "response": "Adds given hyperedge to the hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the given hyperedge from the set.", "response": "def del_hyperedge(self, hyperedge):\n        \"\"\"\n        Delete the given hyperedge.\n        \n        @type  hyperedge: hyperedge\n        @param hyperedge: Hyperedge identifier.\n        \"\"\"\n        if (hyperedge in self.hyperedges()):\n            for n in self.edge_links[hyperedge]:\n                self.node_links[n].remove(hyperedge)\n\n            del(self.edge_links[hyperedge])\n            self.del_edge_labeling(hyperedge)\n            self.graph.del_node((hyperedge,'h'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlinks given node and hyperedge.", "response": "def link(self, node, hyperedge):\n        \"\"\"\n        Link given node and hyperedge.\n\n        @type  node: node\n        @param node: Node.\n\n        @type  hyperedge: node\n        @param hyperedge: Hyperedge.\n        \"\"\"\n        if (hyperedge not in self.node_links[node]):\n            self.edge_links[hyperedge].append(node)\n            self.node_links[node].append(hyperedge)\n            self.graph.add_edge(((node,'n'), (hyperedge,'h')))\n        else:\n            raise AdditionError(\"Link (%s, %s) already in graph\" % (node, hyperedge))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the rank of the given hypergraph.", "response": "def rank(self):\n        \"\"\"\n        Return the rank of the given hypergraph.\n        \n        @rtype:  int\n        @return: Rank of graph.\n        \"\"\"\n        max_rank = 0\n        \n        for each in self.hyperedges():\n            if len(self.edge_links[each]) > max_rank:\n                max_rank = len(self.edge_links[each])\n                \n        return max_rank"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nincrementing letter - based IDs. Returns next base - 26 ID.", "response": "def get_next_base26(prev=None):\n    \"\"\"Increment letter-based IDs.\n\n    Generates IDs like ['a', 'b', ..., 'z', 'aa', ab', ..., 'az', 'ba', ...]\n\n    Returns:\n        str: Next base-26 ID.\n    \"\"\"\n    if not prev:\n        return 'a'\n\n    r = re.compile(\"^[a-z]*$\")\n    if not r.match(prev):\n        raise ValueError(\"Invalid base26\")\n\n    if not prev.endswith('z'):\n        return prev[:-1] + chr(ord(prev[-1]) + 1)\n\n    return get_next_base26(prev[:-1]) + 'a'"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a base - 26 symlink in path pointing to source.", "response": "def create_unique_base26_symlink(path, source):\n    \"\"\"Create a base-26 symlink in `path` pointing to `source`.\n\n    If such a symlink already exists, it is returned. Note that there is a small\n    chance that this function may create a new symlink when there is already one\n    pointed at `source`.\n\n    Assumes `path` only contains base26 symlinks.\n\n    Returns:\n        str: Path to created symlink.\n    \"\"\"\n    retries = 0\n\n    while True:\n        # if a link already exists that points at `source`, return it\n        name = find_matching_symlink(path, source)\n        if name:\n            return os.path.join(path, name)\n\n        # get highest current symlink in path\n        names = [\n            x for x in os.listdir(path)\n            if os.path.islink(os.path.join(path, x))\n        ]\n\n        if names:\n            prev = max(names)\n        else:\n            prev = None\n\n        linkname = get_next_base26(prev)\n        linkpath = os.path.join(path, linkname)\n\n        # attempt to create the symlink\n        try:\n            os.symlink(source, linkpath)\n            return linkpath\n\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n\n        # if we're here, the same named symlink was created in parallel\n        # somewhere. Try again up to N times.\n        #\n        if retries > 10:\n            raise RuntimeError(\n                \"Variant shortlink not created - there was too much contention.\")\n        retries += 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_wheels(projects, search_dirs):\n\n    wheels = []\n\n    # Look through SEARCH_DIRS for the first suitable wheel. Don't bother\n    # about version checking here, as this is simply to get something we can\n    # then use to install the correct version.\n    for project in projects:\n        for dirname in search_dirs:\n            # This relies on only having \"universal\" wheels available.\n            # The pattern could be tightened to require -py2.py3-none-any.whl.\n            files = glob.glob(os.path.join(dirname, project + '-*.whl'))\n            if files:\n                wheels.append(os.path.abspath(files[0]))\n                break\n        else:\n            # We're out of luck, so quit with a suitable error\n            logger.fatal('Cannot find a wheel for %s' % (project,))\n\n    return wheels", "response": "Find wheels from which we can import PROJECTS."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path_locations(home_dir):\n    # XXX: We'd use distutils.sysconfig.get_python_inc/lib but its\n    # prefix arg is broken: http://bugs.python.org/issue3386\n    if is_win:\n        # Windows has lots of problems with executables with spaces in\n        # the name; this function will remove them (using the ~1\n        # format):\n        mkdir(home_dir)\n        if ' ' in home_dir:\n            import ctypes\n            GetShortPathName = ctypes.windll.kernel32.GetShortPathNameW\n            size = max(len(home_dir)+1, 256)\n            buf = ctypes.create_unicode_buffer(size)\n            try:\n                u = unicode\n            except NameError:\n                u = str\n            ret = GetShortPathName(u(home_dir), buf, size)\n            if not ret:\n                print('Error: the path \"%s\" has a space in it' % home_dir)\n                print('We could not determine the short pathname for it.')\n                print('Exiting.')\n                sys.exit(3)\n            home_dir = str(buf.value)\n        lib_dir = join(home_dir, 'Lib')\n        inc_dir = join(home_dir, 'Include')\n        bin_dir = join(home_dir, 'Scripts')\n    if is_jython:\n        lib_dir = join(home_dir, 'Lib')\n        inc_dir = join(home_dir, 'Include')\n        bin_dir = join(home_dir, 'bin')\n    elif is_pypy:\n        lib_dir = home_dir\n        inc_dir = join(home_dir, 'include')\n        bin_dir = join(home_dir, 'bin')\n    elif not is_win:\n        lib_dir = join(home_dir, 'lib', py_version)\n        multiarch_exec = '/usr/bin/multiarch-platform'\n        if is_executable_file(multiarch_exec):\n            # In Mageia (2) and Mandriva distros the include dir must be like:\n            # virtualenv/include/multiarch-x86_64-linux/python2.7\n            # instead of being virtualenv/include/python2.7\n            p = subprocess.Popen(multiarch_exec, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            stdout, stderr = p.communicate()\n            # stdout.strip is needed to remove newline character\n            inc_dir = join(home_dir, 'include', stdout.strip(), py_version + abiflags)\n        else:\n            inc_dir = join(home_dir, 'include', py_version + abiflags)\n        bin_dir = join(home_dir, 'bin')\n    return home_dir, lib_dir, inc_dir, bin_dir", "response": "Return the path locations for the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fix_local_scheme(home_dir, symlink=True):\n    try:\n        import sysconfig\n    except ImportError:\n        pass\n    else:\n        if sysconfig._get_default_scheme() == 'posix_local':\n            local_path = os.path.join(home_dir, 'local')\n            if not os.path.exists(local_path):\n                os.mkdir(local_path)\n                for subdir_name in os.listdir(home_dir):\n                    if subdir_name == 'local':\n                        continue\n                    copyfile(os.path.abspath(os.path.join(home_dir, subdir_name)), \\\n                                                            os.path.join(local_path, subdir_name), symlink)", "response": "Fixes the local scheme of the current platform."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_interpreter(exe):\n    # If the \"executable\" is a version number, get the installed executable for\n    # that version\n    python_versions = get_installed_pythons()\n    if exe in python_versions:\n        exe = python_versions[exe]\n\n    if os.path.abspath(exe) != exe:\n        paths = os.environ.get('PATH', '').split(os.pathsep)\n        for path in paths:\n            if os.path.exists(os.path.join(path, exe)):\n                exe = os.path.join(path, exe)\n                break\n    if not os.path.exists(exe):\n        logger.fatal('The executable %s (from --python=%s) does not exist' % (exe, exe))\n        raise SystemExit(3)\n    if not is_executable(exe):\n        logger.fatal('The executable %s (from --python=%s) is not executable' % (exe, exe))\n        raise SystemExit(3)\n    return exe", "response": "Resolves the interpreter given by the user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_environment_relocatable(home_dir):\n    home_dir, lib_dir, inc_dir, bin_dir = path_locations(home_dir)\n    activate_this = os.path.join(bin_dir, 'activate_this.py')\n    if not os.path.exists(activate_this):\n        logger.fatal(\n            'The environment doesn\\'t have a file %s -- please re-run virtualenv '\n            'on this environment to update it' % activate_this)\n    fixup_scripts(home_dir, bin_dir)\n    fixup_pth_and_egg_link(home_dir)", "response": "Makes the environment use relative paths and takes out\n    the environment selection in scripts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef relative_script(lines):\n    \"Return a script that'll work in a relocatable environment.\"\n    activate = \"import os; activate_this=os.path.join(os.path.dirname(os.path.realpath(__file__)), 'activate_this.py'); exec(compile(open(activate_this).read(), activate_this, 'exec'), dict(__file__=activate_this)); del os, activate_this\"\n    # Find the last future statement in the script. If we insert the activation\n    # line before a future statement, Python will raise a SyntaxError.\n    activate_at = None\n    for idx, line in reversed(list(enumerate(lines))):\n        if line.split()[:3] == ['from', '__future__', 'import']:\n            activate_at = idx + 1\n            break\n    if activate_at is None:\n        # Activate after the shebang.\n        activate_at = 1\n    return lines[:activate_at] + ['', activate, ''] + lines[activate_at:]", "response": "Return a script that ll work in a relocatable environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes .pth and .egg-link files use relative paths", "response": "def fixup_pth_and_egg_link(home_dir, sys_path=None):\n    \"\"\"Makes .pth and .egg-link files use relative paths\"\"\"\n    home_dir = os.path.normcase(os.path.abspath(home_dir))\n    if sys_path is None:\n        sys_path = sys.path\n    for path in sys_path:\n        if not path:\n            path = '.'\n        if not os.path.isdir(path):\n            continue\n        path = os.path.normcase(os.path.abspath(path))\n        if not path.startswith(home_dir):\n            logger.debug('Skipping system (non-environment) directory %s' % path)\n            continue\n        for filename in os.listdir(path):\n            filename = os.path.join(path, filename)\n            if filename.endswith('.pth'):\n                if not os.access(filename, os.W_OK):\n                    logger.warn('Cannot write .pth file %s, skipping' % filename)\n                else:\n                    fixup_pth_file(filename)\n            if filename.endswith('.egg-link'):\n                if not os.access(filename, os.W_OK):\n                    logger.warn('Cannot write .egg-link file %s, skipping' % filename)\n                else:\n                    fixup_egg_link(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_relative_path(source, dest, dest_is_directory=True):\n    source = os.path.dirname(source)\n    if not dest_is_directory:\n        dest_filename = os.path.basename(dest)\n        dest = os.path.dirname(dest)\n    dest = os.path.normpath(os.path.abspath(dest))\n    source = os.path.normpath(os.path.abspath(source))\n    dest_parts = dest.strip(os.path.sep).split(os.path.sep)\n    source_parts = source.strip(os.path.sep).split(os.path.sep)\n    while dest_parts and source_parts and dest_parts[0] == source_parts[0]:\n        dest_parts.pop(0)\n        source_parts.pop(0)\n    full_parts = ['..']*len(source_parts) + dest_parts\n    if not dest_is_directory:\n        full_parts.append(dest_filename)\n    if not full_parts:\n        # Special case for the current directory (otherwise it'd be '')\n        return './'\n    return os.path.sep.join(full_parts)", "response": "Make a relative path to the source and dest."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_bootstrap_script(extra_text, python_version=''):\n    filename = __file__\n    if filename.endswith('.pyc'):\n        filename = filename[:-1]\n    f = codecs.open(filename, 'r', encoding='utf-8')\n    content = f.read()\n    f.close()\n    py_exe = 'python%s' % python_version\n    content = (('#!/usr/bin/env %s\\n' % py_exe)\n               + '## WARNING: This file is generated\\n'\n               + content)\n    return content.replace('##EXT' 'END##', extra_text)", "response": "Creates a bootstrap script that can be used to create a new virtual environment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_data(file, endian, num=1):\n    res = struct.unpack(endian + 'L' * num, file.read(num * 4))\n    if len(res) == 1:\n        return res[0]\n    return res", "response": "Read a given number of 32 - bits unsigned integers from the given file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing the current log messages in progress.", "response": "def show_progress(self):\n        \"\"\"If we are in a progress scope, and no log messages have been\n        shown, write out another '.'\"\"\"\n        if self.in_progress_hanging:\n            sys.stdout.write('.')\n            sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the level that stdout runs at", "response": "def _stdout_level(self):\n        \"\"\"Returns the level that stdout runs at\"\"\"\n        for level, consumer in self.consumers:\n            if consumer is sys.stdout:\n                return level\n        return self.FATAL"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef level_matches(self, level, consumer_level):\n        if isinstance(level, slice):\n            start, stop = level.start, level.stop\n            if start is not None and start > consumer_level:\n                return False\n            if stop is not None and stop <= consumer_level:\n                return False\n            return True\n        else:\n            return level >= consumer_level", "response": "Return True if the level of the log entry matches the consumer level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the given defaults with values from the config files and the environ variables.", "response": "def update_defaults(self, defaults):\n        \"\"\"\n        Updates the given defaults with values from the config files and\n        the environ. Does a little special handling for certain types of\n        options (lists).\n        \"\"\"\n        # Then go and look for the other sources of configuration:\n        config = {}\n        # 1. config files\n        config.update(dict(self.get_config_section('virtualenv')))\n        # 2. environmental variables\n        config.update(dict(self.get_environ_vars()))\n        # Then set the options with those values\n        for key, val in config.items():\n            key = key.replace('_', '-')\n            if not key.startswith('--'):\n                key = '--%s' % key  # only prefer long opts\n            option = self.get_option(key)\n            if option is not None:\n                # ignore empty values\n                if not val:\n                    continue\n                # handle multiline configs\n                if option.action == 'append':\n                    val = val.split()\n                else:\n                    option.nargs = 1\n                if option.action == 'store_false':\n                    val = not strtobool(val)\n                elif option.action in ('store_true', 'count'):\n                    val = strtobool(val)\n                try:\n                    val = option.convert_value(key, val)\n                except optparse.OptionValueError:\n                    e = sys.exc_info()[1]\n                    print(\"An error occured during configuration: %s\" % e)\n                    sys.exit(3)\n                defaults[option.dest] = val\n        return defaults"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_config_section(self, name):\n        if self.config.has_section(name):\n            return self.config.items(name)\n        return []", "response": "Get a section of a configuration"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a generator with all environmental vars with prefix VIRTUALENV_", "response": "def get_environ_vars(self, prefix='VIRTUALENV_'):\n        \"\"\"\n        Returns a generator with all environmental vars with prefix VIRTUALENV\n        \"\"\"\n        for key, val in os.environ.items():\n            if key.startswith(prefix):\n                yield (key.replace(prefix, '').lower(), val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_default_values(self):\n        if not self.process_default_values:\n            # Old, pre-Optik 1.5 behaviour.\n            return optparse.Values(self.defaults)\n\n        defaults = self.update_defaults(self.defaults.copy())  # ours\n        for option in self._get_all_options():\n            default = defaults.get(option.dest)\n            if isinstance(default, basestring):\n                opt_str = option.get_opt_string()\n                defaults[option.dest] = option.check_value(opt_str, default)\n        return optparse.Values(defaults)", "response": "Returns a list of all the default values for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the next method from the source and put it in the internal queue.", "response": "def _next_method(self):\n        \"\"\"Read the next method from the source, once one complete method has\n        been assembled it is placed in the internal queue.\"\"\"\n        queue = self.queue\n        put = self._quick_put\n        read_frame = self.source.read_frame\n        while not queue:\n            try:\n                frame_type, channel, payload = read_frame()\n            except Exception as exc:\n                #\n                # Connection was closed?  Framing Error?\n                #\n                put(exc)\n                break\n\n            self.bytes_recv += 1\n\n            if frame_type not in (self.expected_types[channel], 8):\n                put((\n                    channel,\n                    UnexpectedFrame(\n                        'Received frame {0} while expecting type: {1}'.format(\n                            frame_type, self.expected_types[channel]))))\n            elif frame_type == 1:\n                self._process_method_frame(channel, payload)\n            elif frame_type == 2:\n                self._process_content_header(channel, payload)\n            elif frame_type == 3:\n                self._process_content_body(channel, payload)\n            elif frame_type == 8:\n                self._process_heartbeat(channel, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_content_header(self, channel, payload):\n        partial = self.partial_messages[channel]\n        partial.add_header(payload)\n\n        if partial.complete:\n            #\n            # a bodyless message, we're done\n            #\n            self._quick_put((channel, partial.method_sig,\n                             partial.args, partial.msg))\n            self.partial_messages.pop(channel, None)\n            self.expected_types[channel] = 1\n        else:\n            #\n            # wait for the content-body\n            #\n            self.expected_types[channel] = 3", "response": "Process the content - header frames."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_content_body(self, channel, payload):\n        partial = self.partial_messages[channel]\n        partial.add_payload(payload)\n        if partial.complete:\n            #\n            # Stick the message in the queue and go back to\n            # waiting for method frames\n            #\n            self._quick_put((channel, partial.method_sig,\n                             partial.args, partial.msg))\n            self.partial_messages.pop(channel, None)\n            self.expected_types[channel] = 1", "response": "Process the content body frames of a specific channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_method(self):\n        self._next_method()\n        m = self._quick_get()\n        if isinstance(m, Exception):\n            raise m\n        if isinstance(m, tuple) and isinstance(m[1], AMQPError):\n            raise m[1]\n        return m", "response": "Read a method from the peer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _patch_argument_parser(self):\n        '''\n        Since argparse doesn't support much introspection, we monkey-patch it to replace the parse_known_args method and\n        all actions with hooks that tell us which action was last taken or about to be taken, and let us have the parser\n        figure out which subparsers need to be activated (then recursively monkey-patch those).\n        We save all active ArgumentParsers to extract all their possible option names later.\n        '''\n        active_parsers = [self._parser]\n        parsed_args = argparse.Namespace()\n        visited_actions = []\n\n        def patch(parser):\n            parser.__class__ = IntrospectiveArgumentParser\n            for action in parser._actions:\n                # TODO: accomplish this with super\n                class IntrospectAction(action.__class__):\n                    def __call__(self, parser, namespace, values, option_string=None):\n                        debug('Action stub called on', self)\n                        debug('\\targs:', parser, namespace, values, option_string)\n                        debug('\\torig class:', self._orig_class)\n                        debug('\\torig callable:', self._orig_callable)\n\n                        visited_actions.append(self)\n\n                        if self._orig_class == argparse._SubParsersAction:\n                            debug('orig class is a subparsers action: patching and running it')\n                            active_subparser = self._name_parser_map[values[0]]\n                            patch(active_subparser)\n                            active_parsers.append(active_subparser)\n                            self._orig_callable(parser, namespace, values, option_string=option_string)\n                        elif self._orig_class in safe_actions:\n                            self._orig_callable(parser, namespace, values, option_string=option_string)\n                if getattr(action, \"_orig_class\", None):\n                    debug(\"Action\", action, \"already patched\")\n                action._orig_class = action.__class__\n                action._orig_callable = action.__call__\n                action.__class__ = IntrospectAction\n\n        patch(self._parser)\n\n        debug(\"Active parsers:\", active_parsers)\n        debug(\"Visited actions:\", visited_actions)\n        debug(\"Parse result namespace:\", parsed_args)\n\n        return active_parsers, parsed_args", "response": "Monkey - patch argparse. ArgumentParser to replace parse_known_args method and parse_args method and all actions with hooks that tell us which action was last taken or about to be taken."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollects completions for the given word prefix.", "response": "def collect_completions(self, active_parsers, parsed_args, cword_prefix, debug):\n        '''\n        Visits the active parsers and their actions, executes their completers or introspects them to collect their\n        option strings. Returns the resulting completions as a list of strings.\n\n        This method is exposed for overriding in subclasses; there is no need to use it directly.\n        '''\n        completions = []\n        for parser in active_parsers:\n            debug(\"Examining parser\", parser)\n            for action in parser._actions:\n                debug(\"Examining action\", action)\n                if isinstance(action, argparse._SubParsersAction):\n                    subparser_activated = False\n                    for subparser in action._name_parser_map.values():\n                        if subparser in active_parsers:\n                            subparser_activated = True\n                    if subparser_activated:\n                        # Parent parser completions are not valid in the subparser, so flush them\n                        completions = []\n                    else:\n                        completions += [subcmd for subcmd in action.choices.keys() if subcmd.startswith(cword_prefix)]\n                elif self.always_complete_options or (len(cword_prefix) > 0 and cword_prefix[0] in parser.prefix_chars):\n                    completions += [option for option in action.option_strings if option.startswith(cword_prefix)]\n\n            debug(\"Active actions (L={l}): {a}\".format(l=len(parser.active_actions), a=parser.active_actions))\n\n            # Only run completers if current word does not start with - (is not an optional)\n            if len(cword_prefix) == 0 or cword_prefix[0] not in parser.prefix_chars:\n                for active_action in parser.active_actions:\n                    if not active_action.option_strings: # action is a positional\n                        if action_is_satisfied(active_action) and not action_is_open(active_action):\n                            debug(\"Skipping\", active_action)\n                            continue\n\n                    debug(\"Activating completion for\", active_action, active_action._orig_class)\n                    #completer = getattr(active_action, 'completer', DefaultCompleter())\n                    completer = getattr(active_action, 'completer', None)\n\n                    if completer is None and active_action.choices is not None:\n                        if not isinstance(active_action, argparse._SubParsersAction):\n                            completer = completers.ChoicesCompleter(active_action.choices)\n\n                    if completer:\n                        if len(active_action.option_strings) > 0: # only for optionals\n                            if not action_is_satisfied(active_action):\n                                # This means the current action will fail to parse if the word under the cursor is not given\n                                # to it, so give it exclusive control over completions (flush previous completions)\n                                debug(\"Resetting completions because\", active_action, \"is unsatisfied\")\n                                completions = []\n                        if callable(completer):\n                            completions += [c for c in completer(prefix=cword_prefix, action=active_action,\n                                                                 parsed_args=parsed_args)\n                                            if self.validator(c, cword_prefix)]\n                        else:\n                            debug(\"Completer is not callable, trying the readline completer protocol instead\")\n                            for i in range(9999):\n                                next_completion = completer.complete(cword_prefix, i)\n                                if next_completion is None:\n                                    break\n                                if self.validator(next_completion, cword_prefix):\n                                    completions.append(next_completion)\n                        debug(\"Completions:\", completions)\n                    elif not isinstance(active_action, argparse._SubParsersAction):\n                        pass\n                        \"\"\"\n                        debug(\"Completer not available, falling back\")\n                        try:\n                            # TODO: what happens if completions contain newlines? How do I make compgen use IFS?\n                            bashcomp_cmd = ['bash', '-c', \"compgen -A file -- '{p}'\".format(p=cword_prefix)]\n                            completions += subprocess.check_output(bashcomp_cmd).decode(sys_encoding).splitlines()\n                        except subprocess.CalledProcessError:\n                            pass\n                        \"\"\"\n        return completions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_completions(self, completions):\n        '''\n        Ensures collected completions are Unicode text, de-duplicates them, and excludes those specified by ``exclude``.\n        Returns the filtered completions as an iterable.\n\n        This method is exposed for overriding in subclasses; there is no need to use it directly.\n        '''\n        # On Python 2, we have to make sure all completions are unicode objects before we continue and output them.\n        # Otherwise, because python disobeys the system locale encoding and uses ascii as the default encoding, it will try\n        # to implicitly decode string objects using ascii, and fail.\n        if USING_PYTHON2:\n            for i in range(len(completions)):\n                if type(completions[i]) != unicode:\n                    completions[i] = completions[i].decode(sys_encoding)\n\n        # De-duplicate completions and remove excluded ones\n        if self.exclude is None:\n            self.exclude = set()\n        seen = set(self.exclude)\n        return [c for c in completions if c not in seen and not seen.add(c)]", "response": "Filter the completions to only contain Unicode text."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nquotes the completions for the current word.", "response": "def quote_completions(self, completions, cword_prequote, first_colon_pos):\n        '''\n        If the word under the cursor started with a quote (as indicated by a nonempty ``cword_prequote``), escapes\n        occurrences of that quote character in the completions, and adds the quote to the beginning of each completion.\n        Otherwise, escapes all characters that bash splits words on (``COMP_WORDBREAKS``), and removes portions of\n        completions before the first colon.\n\n        If there is only one completion, and it doesn't end with a **continuation character** (``/``, ``:``, or ``=``),\n        adds a space after the completion.\n\n        This method is exposed for overriding in subclasses; there is no need to use it directly.\n        '''\n        comp_wordbreaks = os.environ.get('_ARGCOMPLETE_COMP_WORDBREAKS', os.environ.get('COMP_WORDBREAKS', self.wordbreaks))\n        if USING_PYTHON2:\n            comp_wordbreaks = comp_wordbreaks.decode(sys_encoding)\n\n        punctuation_chars = '();<>|&!`'\n        for char in punctuation_chars:\n            if char not in comp_wordbreaks:\n                comp_wordbreaks += char\n\n        # If the word under the cursor was quoted, escape the quote char and add the leading quote back in.\n        # Otherwise, escape all COMP_WORDBREAKS chars.\n        if cword_prequote == '':\n            # Bash mangles completions which contain colons.\n            # This workaround has the same effect as __ltrim_colon_completions in bash_completion.\n            if first_colon_pos:\n                completions = [c[first_colon_pos+1:] for c in completions]\n\n            for wordbreak_char in comp_wordbreaks:\n                completions = [c.replace(wordbreak_char, '\\\\'+wordbreak_char) for c in completions]\n        else:\n            if cword_prequote == '\"':\n                for char in '`$!':\n                    completions = [c.replace(char, '\\\\'+char) for c in completions]\n            completions = [cword_prequote+c.replace(cword_prequote, '\\\\'+cword_prequote) for c in completions]\n\n        # Note: similar functionality in bash is turned off by supplying the \"-o nospace\" option to complete.\n        # We can't use that functionality because bash is not smart enough to recognize continuation characters (/) for\n        # which no space should be added.\n        continuation_chars = '=/:'\n        if len(completions) == 1 and completions[0][-1] not in continuation_chars:\n            if cword_prequote == '' and not completions[0].endswith(' '):\n                completions[0] += ' '\n\n        return completions"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complete(self, text, state):\n        '''\n        Alternate entry point for using the argcomplete completer in a readline-based REPL. See also\n        `rlcompleter <https://docs.python.org/2/library/rlcompleter.html#completer-objects>`_.\n\n        Usage:\n\n        .. code-block:: python\n\n            import argcomplete, argparse, readline\n            parser = argparse.ArgumentParser()\n            ...\n            completer = argcomplete.CompletionFinder(parser)\n            readline.set_completer(completer.complete)\n            readline.parse_and_bind(\"tab: complete\")\n            result = input(\"prompt> \")\n\n        (Use ``raw_input`` instead of ``input`` on Python 2, or use `eight <https://github.com/kislyuk/eight>`_).\n        '''\n        if state == 0:\n            print(\"Retrieving matches for\", text)\n            cword_prequote, cword_prefix, cword_suffix, comp_words, first_colon_pos = split_line(text)\n            print(\"Split line into prequote={}, prefix={}, suffix={}, words={}, fcp={}\".format(cword_prequote, cword_prefix, cword_suffix, comp_words, first_colon_pos))\n            comp_words.insert(0, \"prog\")\n            self.matches = self._get_completions(comp_words, cword_prefix, cword_prequote, first_colon_pos)\n            print(\"Set matches to\", self.matches)\n        if state < len(self.matches):\n            print(\"Returning\", self.matches[state])\n            return self.matches[state]\n        else:\n            return None", "response": "A function that returns the complete string for the given text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexpanding any strings within data such as system. user.", "response": "def expand_system_vars(data):\n    \"\"\"Expands any strings within `data` such as '{system.user}'.\"\"\"\n    def _expanded(value):\n        if isinstance(value, basestring):\n            value = expandvars(value)\n            value = expanduser(value)\n            return scoped_format(value, system=system)\n        elif isinstance(value, (list, tuple, set)):\n            return [_expanded(x) for x in value]\n        elif isinstance(value, dict):\n            return dict((k, _expanded(v)) for k, v in value.iteritems())\n        else:\n            return value\n    return _expanded(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a separate copy of this config.", "response": "def copy(self, overrides=None, locked=False):\n        \"\"\"Create a separate copy of this config.\"\"\"\n        other = copy.copy(self)\n\n        if overrides is not None:\n            other.overrides = overrides\n\n        other.locked = locked\n\n        other._uncache()\n        return other"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a setting to the given value.", "response": "def override(self, key, value):\n        \"\"\"Set a setting to the given value.\n\n        Note that `key` can be in dotted form, eg\n        'plugins.release_hook.emailer.sender'.\n        \"\"\"\n        keys = key.split('.')\n        if len(keys) > 1:\n            if keys[0] != \"plugins\":\n                raise AttributeError(\"no such setting: %r\" % key)\n            self.plugins.override(keys[1:], value)\n        else:\n            self.overrides[key] = value\n            self._uncache(key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a setting override if one exists.", "response": "def remove_override(self, key):\n        \"\"\"Remove a setting override, if one exists.\"\"\"\n        keys = key.split('.')\n        if len(keys) > 1:\n            raise NotImplementedError\n        elif key in self.overrides:\n            del self.overrides[key]\n            self._uncache(key)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef warn(self, key):\n        return (not self.quiet and not self.warn_none and\n                (self.warn_all or getattr(self, \"warn_%s\" % key)))", "response": "Returns True if the warning setting is enabled."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef debug(self, key):\n        return (not self.quiet and not self.debug_none and\n                (self.debug_all or getattr(self, \"debug_%s\" % key)))", "response": "Returns True if the debug setting is enabled."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef data(self):\n        d = {}\n        for key in self._data:\n            if key == \"plugins\":\n                d[key] = self.plugins.data()\n            else:\n                try:\n                    d[key] = getattr(self, key)\n                except AttributeError:\n                    pass  # unknown key, just leave it unchanged\n        return d", "response": "Returns the entire configuration as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nonlocal_packages_path(self):\n        paths = self.packages_path[:]\n        if self.local_packages_path in paths:\n            paths.remove(self.local_packages_path)\n        return paths", "response": "Returns package search paths with local path removed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nswapping this config with another.", "response": "def _swap(self, other):\n        \"\"\"Swap this config with another.\n\n        This is used by the unit tests to swap the config to one that is\n        shielded from any user config updates. Do not use this method unless\n        you have good reason.\n        \"\"\"\n        self.__dict__, other.__dict__ = other.__dict__, self.__dict__"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_main_config(cls, overrides=None):\n        filepaths = []\n        filepaths.append(get_module_root_config())\n        filepath = os.getenv(\"REZ_CONFIG_FILE\")\n        if filepath:\n            filepaths.extend(filepath.split(os.pathsep))\n\n        filepath = os.path.expanduser(\"~/.rezconfig\")\n        filepaths.append(filepath)\n\n        return Config(filepaths, overrides)", "response": "Create a main config object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecorate a function to be used within a config. platform_map dictionary.", "response": "def platform_mapped(func):\n    \"\"\"Decorates functions for lookups within a config.platform_map dictionary.\n\n    The first level key is mapped to the func.__name__ of the decorated function.\n    Regular expressions are used on the second level key, values.\n    Note that there is no guaranteed order within the dictionary evaluation. Only the first matching\n    regular expression is being used.\n    For example:\n\n    config.platform_map = {\n        \"os\": {\n            r\"Scientific Linux-(.*)\": r\"Scientific-\\1\",    # Scientific Linux-x.x -> Scientific-x.x\n            r\"Ubuntu-14.\\d\": r\"Ubuntu-14\",                 # Any Ubuntu-14.x      -> Ubuntu-14\n        },\n        \"arch\": {\n            \"x86_64\": \"64bit\",                             # Maps both x86_64 and amd64 -> 64bit (don't)\n            \"amd64\": \"64bit\",\n        },\n    }\n    \"\"\"\n    def inner(*args, **kwargs):\n\n        # Since platform is being used within config lazy import config to prevent\n        # circular dependencies\n        from rez.config import config\n\n        # Original result\n        result = func(*args, **kwargs)\n\n        # The function name is used as primary key\n        entry = config.platform_map.get(func.__name__)\n        if entry:\n            for key, value in entry.iteritems():\n                result, changes = re.subn(key, value, result)\n                if changes > 0:\n                    break\n\n        return result\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pagerank(graph, damping_factor=0.85, max_iterations=100, min_delta=0.00001):\n    \n    nodes = graph.nodes()\n    graph_size = len(nodes)\n    if graph_size == 0:\n        return {}\n    min_value = (1.0-damping_factor)/graph_size #value for nodes without inbound links\n    \n    # itialize the page rank dict with 1/N for all nodes\n    pagerank = dict.fromkeys(nodes, 1.0/graph_size)\n        \n    for i in range(max_iterations):\n        diff = 0 #total difference compared to last iteraction\n        # computes each node PageRank based on inbound links\n        for node in nodes:\n            rank = min_value\n            for referring_page in graph.incidents(node):\n                rank += damping_factor * pagerank[referring_page] / len(graph.neighbors(referring_page))\n                \n            diff += abs(pagerank[node] - rank)\n            pagerank[node] = rank\n        \n        #stop if PageRank has converged\n        if diff < min_delta:\n            break\n    \n    return pagerank", "response": "Compute and return the PageRank in an directed graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expand_requirement(request, paths=None):\n    if '*' not in request:\n        return request\n\n    from rez.vendor.version.version import VersionRange\n    from rez.vendor.version.requirement import Requirement\n    from rez.packages_ import get_latest_package\n    from uuid import uuid4\n\n    wildcard_map = {}\n    expanded_versions = {}\n    request_ = request\n\n    # replace wildcards with valid version tokens that can be replaced again\n    # afterwards. This produces a horrendous, but both valid and temporary,\n    # version string.\n    #\n    while \"**\" in request_:\n        uid = \"_%s_\" % uuid4().hex\n        request_ = request_.replace(\"**\", uid, 1)\n        wildcard_map[uid] = \"**\"\n\n    while '*' in request_:\n        uid = \"_%s_\" % uuid4().hex\n        request_ = request_.replace('*', uid, 1)\n        wildcard_map[uid] = '*'\n\n    # create the requirement, then expand wildcards\n    #\n    req = Requirement(request_, invalid_bound_error=False)\n\n    def expand_version(version):\n        rank = len(version)\n        wildcard_found = False\n\n        while version and str(version[-1]) in wildcard_map:\n            token = wildcard_map[str(version[-1])]\n            version = version.trim(len(version) - 1)\n\n            if token == \"**\":\n                if wildcard_found:  # catches bad syntax '**.*'\n                    return None\n                else:\n                    wildcard_found = True\n                    rank = 0\n                    break\n\n            wildcard_found = True\n\n        if not wildcard_found:\n            return None\n\n        range_ = VersionRange(str(version))\n        package = get_latest_package(name=req.name, range_=range_, paths=paths)\n\n        if package is None:\n            return version\n\n        if rank:\n            return package.version.trim(rank)\n        else:\n            return package.version\n\n    def visit_version(version):\n        # requirements like 'foo-1' are actually represented internally as\n        # 'foo-1+<1_' - '1_' is the next possible version after '1'. So we have\n        # to detect this case and remap the uid-ified wildcard back here too.\n        #\n        for v, expanded_v in expanded_versions.iteritems():\n            if version == v.next():\n                return expanded_v.next()\n\n        version_ = expand_version(version)\n        if version_ is None:\n            return None\n\n        expanded_versions[version] = version_\n        return version_\n\n    if req.range_ is not None:\n        req.range_.visit_versions(visit_version)\n\n    result = str(req)\n\n    # do some cleanup so that long uids aren't left in invalid wildcarded strings\n    for uid, token in wildcard_map.iteritems():\n        result = result.replace(uid, token)\n\n    # cast back to a Requirement again, then back to a string. This will catch\n    # bad verison ranges, but will also put OR'd version ranges into the correct\n    # order\n    expanded_req = Requirement(result)\n\n    return str(expanded_req)", "response": "Expands a request string like python - 2. 7. 12. 5. 1. 7. 1. 2. 7. 1. 1."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a subproc to calculate a package attribute.", "response": "def exec_command(attr, cmd):\n    \"\"\"Runs a subproc to calculate a package attribute.\n    \"\"\"\n    import subprocess\n\n    p = popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    out, err = p.communicate()\n\n    if p.returncode:\n        from rez.exceptions import InvalidPackageError\n        raise InvalidPackageError(\n            \"Error determining package attribute '%s':\\n%s\" % (attr, err))\n\n    return out.strip(), err.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exec_python(attr, src, executable=\"python\"):\n    import subprocess\n\n    if isinstance(src, basestring):\n        src = [src]\n\n    p = popen([executable, \"-c\", \"; \".join(src)],\n              stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    out, err = p.communicate()\n\n    if p.returncode:\n        from rez.exceptions import InvalidPackageError\n        raise InvalidPackageError(\n            \"Error determining package attribute '%s':\\n%s\" % (attr, err))\n\n    return out.strip()", "response": "Runs a python subproc to calculate a package attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_site_python(module_name, paths=None):\n    from rez.packages_ import iter_packages\n    import subprocess\n    import ast\n    import os\n\n    py_cmd = 'import {x}; print {x}.__path__'.format(x=module_name)\n\n    p = popen([\"python\", \"-c\", py_cmd], stdout=subprocess.PIPE,\n               stderr=subprocess.PIPE)\n    out, err = p.communicate()\n\n    if p.returncode:\n        raise InvalidPackageError(\n            \"Failed to find installed python module '%s':\\n%s\"\n            % (module_name, err))\n\n    module_paths = ast.literal_eval(out.strip())\n\n    def issubdir(path, parent_path):\n        return path.startswith(parent_path + os.sep)\n\n    for package in iter_packages(\"python\", paths=paths):\n        if not hasattr(package, \"_site_paths\"):\n            continue\n\n        contained = True\n\n        for module_path in module_paths:\n            if not any(issubdir(module_path, x) for x in package._site_paths):\n                contained = False\n\n        if contained:\n            return package\n\n    raise InvalidPackageError(\n        \"Failed to find python installation containing the module '%s'. Has \"\n        \"python been installed as a rez package?\" % module_name)", "response": "Find the native python package that contains the given module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the errno attribute of the exception.", "response": "def get_errno(exc):\n    \"\"\":exc:`socket.error` and :exc:`IOError` first got\n    the ``.errno`` attribute in Py2.7\"\"\"\n    try:\n        return exc.errno\n    except AttributeError:\n        try:\n            # e.args = (errno, reason)\n            if isinstance(exc.args, tuple) and len(exc.args) == 2:\n                return exc.args[0]\n        except AttributeError:\n            pass\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _intersection(A,B):\n    intersection = []\n    for i in A:\n        if i in B:\n            intersection.append(i)\n    return intersection", "response": "A simple function to find an intersection between two arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of transitive edges.", "response": "def transitive_edges(graph):\n    \"\"\"\n    Return a list of transitive edges.\n    \n    Example of transitivity within graphs: A -> B, B -> C, A ->  C\n    in this case the transitive edge is: A -> C\n    \n    @attention: This function is only meaningful for directed acyclic graphs.\n    \n    @type graph: digraph\n    @param graph: Digraph\n    \n    @rtype: List\n    @return: List containing tuples with transitive edges (or an empty array if the digraph\n        contains a cycle) \n    \"\"\"\n    #if the graph contains a cycle we return an empty array\n    if not len(find_cycle(graph)) == 0:\n        return []\n    \n    tranz_edges = [] # create an empty array that will contain all the tuples\n    \n    #run trough all the nodes in the graph\n    for start in topological_sorting(graph):\n        #find all the successors on the path for the current node\n        successors = [] \n        for a in traversal(graph,start,'pre'):\n            successors.append(a)\n        del successors[0] #we need all the nodes in it's path except the start node itself\n        \n        for next in successors:\n            #look for an intersection between all the neighbors of the \n            #given node and all the neighbors from the given successor\n            intersect_array = _intersection(graph.neighbors(next), graph.neighbors(start) )\n            for a in intersect_array:\n                if graph.has_edge((start, a)):\n                    ##check for the detected edge and append it to the returned array   \n                    tranz_edges.append( (start,a) )      \n    return tranz_edges"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef critical_path(graph):\n    #if the graph contains a cycle we return an empty array\n    if not len(find_cycle(graph)) == 0:\n        return []\n    \n    #this empty dictionary will contain a tuple for every single node\n    #the tuple contains the information about the most costly predecessor \n    #of the given node and the cost of the path to this node\n    #(predecessor, cost)\n    node_tuples = {}\n        \n    topological_nodes = topological_sorting(graph)\n    \n    #all the tuples must be set to a default value for every node in the graph\n    for node in topological_nodes: \n        node_tuples.update( {node :(None, 0)}  )\n    \n    #run trough all the nodes in a topological order\n    for node in topological_nodes:\n        predecessors =[]\n        #we must check all the predecessors\n        for pre in graph.incidents(node):\n            max_pre = node_tuples[pre][1]\n            predecessors.append( (pre, graph.edge_weight( (pre, node) ) + max_pre )   )\n        \n        max = 0; max_tuple = (None, 0)\n        for i in predecessors:#look for the most costly predecessor\n            if i[1] >= max:\n                max = i[1]\n                max_tuple = i\n        #assign the maximum value to the given node in the node_tuples dictionary\n        node_tuples[node] = max_tuple                 \n    \n    #find the critical node\n    max = 0; critical_node = None\n    for k,v in list(node_tuples.items()):\n        if v[1] >= max:\n            max= v[1]\n            critical_node = k\n            \n    \n    path = []\n    #find the critical path with backtracking trought the dictionary\n    def mid_critical_path(end):\n        if node_tuples[end][0] != None:\n            path.append(end)\n            mid_critical_path(node_tuples[end][0])\n        else:\n            path.append(end)\n    #call the recursive function\n    mid_critical_path(critical_node)\n    \n    path.reverse()\n    return path", "response": "Compute and return the critical path in an acyclic directed weighted graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bind_cli(cls, parser, group):\n        try:\n            with open(\"./parse_build_args.py\") as f:\n                source = f.read()\n        except Exception as e:\n            return\n\n        # detect what extra args have been added\n        before_args = set(x.dest for x in parser._actions)\n\n        try:\n            exec source in {\"parser\": group}\n        except Exception as e:\n            print_warning(\"Error in ./parse_build_args.py: %s\" % str(e))\n\n        after_args = set(x.dest for x in parser._actions)\n        extra_args = after_args - before_args\n\n        # store extra args onto parser so we can get to it in self.build()\n        setattr(parser, \"_rezbuild_extra_args\", list(extra_args))", "response": "Bind the parser to the command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform the build of the specified variant.", "response": "def build(self, context, variant, build_path, install_path, install=False,\n              build_type=BuildType.local):\n        \"\"\"Perform the build.\n\n        Note that most of the func args aren't used here - that's because this\n        info is already passed to the custom build command via environment\n        variables.\n        \"\"\"\n        ret = {}\n\n        if self.write_build_scripts:\n            # write out the script that places the user in a build env, where\n            # they can run bez directly themselves.\n            build_env_script = os.path.join(build_path, \"build-env\")\n            create_forwarding_script(build_env_script,\n                                     module=(\"build_system\", \"custom\"),\n                                     func_name=\"_FWD__spawn_build_shell\",\n                                     working_dir=self.working_dir,\n                                     build_path=build_path,\n                                     variant_index=variant.index,\n                                     install=install,\n                                     install_path=install_path)\n\n            ret[\"success\"] = True\n            ret[\"build_env_script\"] = build_env_script\n            return ret\n\n        # get build command\n        command = self.package.build_command\n\n        # False just means no build command\n        if command is False:\n            ret[\"success\"] = True\n            return ret\n\n        def expand(txt):\n            root = self.package.root\n            install_ = \"install\" if install else ''\n            return txt.format(root=root, install=install_).strip()\n\n        if isinstance(command, basestring):\n            if self.build_args:\n                command = command + ' ' + ' '.join(map(quote, self.build_args))\n\n            command = expand(command)\n            cmd_str = command\n        else:  # list\n            command = command + self.build_args\n            command = map(expand, command)\n            cmd_str = ' '.join(map(quote, command))\n\n        if self.verbose:\n            pr = Printer(sys.stdout)\n            pr(\"Running build command: %s\" % cmd_str, heading)\n\n        # run the build command\n        def _callback(executor):\n            self._add_build_actions(executor,\n                                    context=context,\n                                    package=self.package,\n                                    variant=variant,\n                                    build_type=build_type,\n                                    install=install,\n                                    build_path=build_path,\n                                    install_path=install_path)\n\n            if self.opts:\n                # write args defined in ./parse_build_args.py out as env vars\n                extra_args = getattr(self.opts.parser, \"_rezbuild_extra_args\", [])\n\n                for key, value in vars(self.opts).iteritems():\n                    if key in extra_args:\n                        varname = \"__PARSE_ARG_%s\" % key.upper()\n\n                        # do some value conversions\n                        if isinstance(value, bool):\n                            value = 1 if value else 0\n                        elif isinstance(value, (list, tuple)):\n                            value = map(str, value)\n                            value = map(quote, value)\n                            value = ' '.join(value)\n\n                        executor.env[varname] = value\n\n        retcode, _, _ = context.execute_shell(command=command,\n                                              block=True,\n                                              cwd=build_path,\n                                              actions_callback=_callback)\n        ret[\"success\"] = (not retcode)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nescapes the < and > and ^ and & special characters reserved by Windows.", "response": "def escape_string(self, value):\n        \"\"\"Escape the <, >, ^, and & special characters reserved by Windows.\n\n        Args:\n            value (str/EscapedString): String or already escaped string.\n\n        Returns:\n            str: The value escaped for Windows.\n\n        \"\"\"\n        if isinstance(value, EscapedString):\n            return value.formatted(self._escaper)\n        return self._escaper(value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_tag_lowlevel(self, tag_name, message=None, force=True,\n                             patch=False):\n        \"\"\"Create a tag on the toplevel or patch repo\n\n        If the tag exists, and force is False, no tag is made. If force is True,\n        and a tag exists, but it is a direct ancestor of the current commit,\n        and there is no difference in filestate between the current commit\n        and the tagged commit, no tag is made. Otherwise, the old tag is\n        overwritten to point at the current commit.\n\n        Returns True or False indicating whether the tag was actually committed\n        \"\"\"\n        # check if tag already exists, and if it does, if it is a direct\n        # ancestor, and there is NO difference in the files between the tagged\n        # state and current state\n        #\n        # This check is mainly to avoid re-creating the same tag over and over\n        # on what is essentially the same commit, since tagging will\n        # technically create a new commit, and update the working copy to it.\n        #\n        # Without this check, say you were releasing to three different\n        # locations, one right after another; the first would create the tag,\n        # and a new tag commit.  The second would then recreate the exact same\n        # tag, but now pointing at the commit that made the first tag.\n        # The third would create the tag a THIRD time, but now pointing at the\n        # commit that created the 2nd tag.\n        tags = self.get_tags(patch=patch)\n\n        old_commit = tags.get(tag_name)\n        if old_commit is not None:\n            if not force:\n                return False\n            old_rev = old_commit['rev']\n            # ok, now check to see if direct ancestor...\n            if self.is_ancestor(old_rev, '.', patch=patch):\n                # ...and if filestates are same\n                altered = self.hg('status', '--rev', old_rev, '--rev', '.',\n                                  '--no-status')\n                if not altered or altered == ['.hgtags']:\n                    force = False\n            if not force:\n                return False\n\n        tag_args = ['tag', tag_name]\n        if message:\n            tag_args += ['--message', message]\n\n        # we should be ok with ALWAYS having force flag on now, since we should\n        # have already checked if the commit exists.. but be paranoid, in case\n        # we've missed some edge case...\n        if force:\n            tag_args += ['--force']\n        self.hg(patch=patch, *tag_args)\n        return True", "response": "Create a tag on the toplevel or patch repo."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if commit1 is a direct ancestor of commit2 or False otherwise.", "response": "def is_ancestor(self, commit1, commit2, patch=False):\n        \"\"\"Returns True if commit1 is a direct ancestor of commit2, or False\n        otherwise.\n\n        This method considers a commit to be a direct ancestor of itself\"\"\"\n        result = self.hg(\"log\", \"-r\", \"first(%s::%s)\" % (commit1, commit2),\n                         \"--template\", \"exists\", patch=patch)\n        return \"exists\" in result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new request with the given list of patch args applied to it.", "response": "def get_patched_request(requires, patchlist):\n    \"\"\"Apply patch args to a request.\n\n    For example, consider:\n\n        >>> print get_patched_request([\"foo-5\", \"bah-8.1\"], [\"foo-6\"])\n        [\"foo-6\", \"bah-8.1\"]\n        >>> print get_patched_request([\"foo-5\", \"bah-8.1\"], [\"^bah\"])\n        [\"foo-5\"]\n\n    The following rules apply wrt how normal/conflict/weak patches override\n    (note though that the new request is always added, even if it doesn't\n    override an existing request):\n\n    PATCH  OVERRIDES: foo  !foo  ~foo\n    -----  ---------- ---  ----  -----\n    foo               Y    Y     Y\n    !foo              N    N     N\n    ~foo              N    N     Y\n    ^foo              Y    Y     Y\n\n    Args:\n        requires (list of str or `version.Requirement`): Request.\n        patchlist (list of str): List of patch requests.\n\n    Returns:\n        List of `version.Requirement`: Patched request.\n    \"\"\"\n\n    # rules from table in docstring above\n    rules = {\n        '':  (True,  True,  True ),\n        '!': (False, False, False),\n        '~': (False, False, True ),\n        '^': (True,  True,  True )\n    }\n\n    requires = [Requirement(x) if not isinstance(x, Requirement) else x\n                for x in requires]\n    appended = []\n\n    for patch in patchlist:\n        if patch and patch[0] in ('!', '~', '^'):\n            ch = patch[0]\n            name = Requirement(patch[1:]).name\n        else:\n            ch = ''\n            name = Requirement(patch).name\n\n        rule = rules[ch]\n        replaced = (ch == '^')\n\n        for i, req in enumerate(requires):\n            if req is None or req.name != name:\n                continue\n\n            if not req.conflict:\n                replace = rule[0]  # foo\n            elif not req.weak:\n                replace = rule[1]  # !foo\n            else:\n                replace = rule[2]  # ~foo\n\n            if replace:\n                if replaced:\n                    requires[i] = None\n                else:\n                    requires[i] = Requirement(patch)\n                    replaced = True\n\n        if not replaced:\n            appended.append(Requirement(patch))\n\n    result = [x for x in requires if x is not None] + appended\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the command line and return_code of the application.", "response": "def execute(self, app_path, app_args, version, **kwargs):\n        \"\"\"\n        The execute functon of the hook will be called to start the required application\n\n        :param app_path: (str) The path of the application executable\n        :param app_args: (str) Any arguments the application may require\n        :param version: (str) version of the application being run if set in the \"versions\" settings\n                              of the Launcher instance, otherwise None\n\n        :returns: (dict) The two valid keys are 'command' (str) and 'return_code' (int).\n        \"\"\"\n\n        multi_launchapp = self.parent\n        extra = multi_launchapp.get_setting(\"extra\")\n\n        use_rez = False\n        if self.check_rez():\n            from rez.resolved_context import ResolvedContext\n            from rez.config import config\n\n            # Define variables used to bootstrap tank from overwrite on first reference\n            # PYTHONPATH is used by tk-maya\n            # NUKE_PATH is used by tk-nuke\n            # HIERO_PLUGIN_PATH is used by tk-nuke (nukestudio)\n            # KATANA_RESOURCES is used by tk-katana\n            config.parent_variables = [\"PYTHONPATH\", \"HOUDINI_PATH\", \"NUKE_PATH\", \"HIERO_PLUGIN_PATH\", \"KATANA_RESOURCES\"]\n\n            rez_packages = extra[\"rez_packages\"]\n            context = ResolvedContext(rez_packages)\n\n            use_rez = True\n\n        system = sys.platform\n        shell_type = 'bash'\n        if system == \"linux2\":\n            # on linux, we just run the executable directly\n            cmd = \"%s %s &\" % (app_path, app_args)\n\n        elif self.parent.get_setting(\"engine\") in [\"tk-flame\", \"tk-flare\"]:\n            # flame and flare works in a different way from other DCCs\n            # on both linux and mac, they run unix-style command line\n            # and on the mac the more standardized \"open\" command cannot\n            # be utilized.\n            cmd = \"%s %s &\" % (app_path, app_args)\n\n        elif system == \"darwin\":\n            # on the mac, the executable paths are normally pointing\n            # to the application bundle and not to the binary file\n            # embedded in the bundle, meaning that we should use the\n            # built-in mac open command to execute it\n            cmd = \"open -n \\\"%s\\\"\" % (app_path)\n            if app_args:\n                cmd += \" --args \\\"%s\\\"\" % app_args.replace(\"\\\"\", \"\\\\\\\"\")\n\n        elif system == \"win32\":\n            # on windows, we run the start command in order to avoid\n            # any command shells popping up as part of the application launch.\n            cmd = \"start /B \\\"App\\\" \\\"%s\\\" %s\" % (app_path, app_args)\n            shell_type = 'cmd'\n\n        # Execute App in a Rez context\n        if use_rez:\n            n_env = os.environ.copy()\n            proc = context.execute_shell(\n                command=cmd,\n                parent_environ=n_env,\n                shell=shell_type,\n                stdin=False,\n                block=False\n            )\n            exit_code = proc.wait()\n            context.print_info(verbosity=True)\n\n        else:\n            # run the command to launch the app\n            exit_code = os.system(cmd)\n\n        return {\n            \"command\": cmd,\n            \"return_code\": exit_code\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_rez(self, strict=True):\n\n        system = sys.platform\n\n        if system == \"win32\":\n            rez_cmd = 'rez-env rez -- echo %REZ_REZ_ROOT%'\n        else:\n            rez_cmd = 'rez-env rez -- printenv REZ_REZ_ROOT'\n\n        process = subprocess.Popen(rez_cmd, stdout=subprocess.PIPE, shell=True)\n        rez_path, err = process.communicate()\n\n        if err or not rez_path:\n            if strict:\n                raise ImportError(\"Failed to find Rez as a package in the current \"\n                                  \"environment! Try 'rez-bind rez'!\")\n            else:\n                print >> sys.stderr, (\"WARNING: Failed to find a Rez package in the current \"\n                                      \"environment. Unable to request Rez packages.\")\n\n            rez_path = \"\"\n        else:\n            rez_path = rez_path.strip()\n            print \"Found Rez:\", rez_path\n            print \"Adding Rez to system path...\"\n            sys.path.append(rez_path)\n\n        return rez_path", "response": "Checks to see if a Rez package is available in the current environment and adds it to the system path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_last_changed_revision(client, url):\n    try:\n        svn_entries = client.info2(url,\n                                   pysvn.Revision(pysvn.opt_revision_kind.head),\n                                   recurse=False)\n        if not svn_entries:\n            raise ReleaseVCSError(\"svn.info2() returned no results on url %s\" % url)\n        return svn_entries[0][1].last_changed_rev\n    except pysvn.ClientError, ce:\n        raise ReleaseVCSError(\"svn.info2() raised ClientError: %s\" % ce)", "response": "util func get last changed revision of url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_svn_login(realm, username, may_save):\n    import getpass\n\n    print \"svn requires a password for the user %s:\" % username\n    pwd = ''\n    while not pwd.strip():\n        pwd = getpass.getpass(\"--> \")\n\n    return True, username, pwd, False", "response": "Returns True username password and False if svn requires a password"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a string representing the given graph as a XML document.", "response": "def write(G):\n    \"\"\"\n    Return a string specifying the given graph as a XML document.\n    \n    @type  G: graph\n    @param G: Graph.\n\n    @rtype:  string\n    @return: String specifying the graph as a XML document.\n    \"\"\"\n    \n    # Document root\n    grxml = Document()\n    if (type(G) == graph):\n        grxmlr = grxml.createElement('graph')\n    elif (type(G) == digraph ):\n        grxmlr = grxml.createElement('digraph')\n    elif (type(G) == hypergraph ):\n        return write_hypergraph(G)\n    else:\n        raise InvalidGraphType\n    grxml.appendChild(grxmlr)\n\n    # Each node...\n    for each_node in G.nodes():\n        node = grxml.createElement('node')\n        node.setAttribute('id', str(each_node))\n        grxmlr.appendChild(node)\n        for each_attr in G.node_attributes(each_node):\n            attr = grxml.createElement('attribute')\n            attr.setAttribute('attr', each_attr[0])\n            attr.setAttribute('value', each_attr[1])\n            node.appendChild(attr)\n\n    # Each edge...\n    for edge_from, edge_to in G.edges():\n        edge = grxml.createElement('edge')\n        edge.setAttribute('from', str(edge_from))\n        edge.setAttribute('to', str(edge_to))\n        edge.setAttribute('wt', str(G.edge_weight((edge_from, edge_to))))\n        edge.setAttribute('label', str(G.edge_label((edge_from, edge_to))))\n        grxmlr.appendChild(edge)\n        for attr_name, attr_value in G.edge_attributes((edge_from, edge_to)):\n            attr = grxml.createElement('attribute')\n            attr.setAttribute('attr', attr_name)\n            attr.setAttribute('value', attr_value)\n            edge.appendChild(attr)\n\n    return grxml.toprettyxml()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(string):\n    dom = parseString(string)\n    if dom.getElementsByTagName(\"graph\"):\n        G = graph()\n    elif dom.getElementsByTagName(\"digraph\"):\n        G = digraph()\n    elif dom.getElementsByTagName(\"hypergraph\"):\n        return read_hypergraph(string)\n    else:\n        raise InvalidGraphType\n    \n    # Read nodes...\n    for each_node in dom.getElementsByTagName(\"node\"):\n        G.add_node(each_node.getAttribute('id'))\n        for each_attr in each_node.getElementsByTagName(\"attribute\"):\n            G.add_node_attribute(each_node.getAttribute('id'),\n                                     (each_attr.getAttribute('attr'),\n                each_attr.getAttribute('value')))\n\n    # Read edges...\n    for each_edge in dom.getElementsByTagName(\"edge\"):\n        if (not G.has_edge((each_edge.getAttribute('from'), each_edge.getAttribute('to')))):\n            G.add_edge((each_edge.getAttribute('from'), each_edge.getAttribute('to')), \\\n                wt = float(each_edge.getAttribute('wt')), label = each_edge.getAttribute('label'))\n        for each_attr in each_edge.getElementsByTagName(\"attribute\"):\n            attr_tuple = (each_attr.getAttribute('attr'), each_attr.getAttribute('value'))\n            if (attr_tuple not in G.edge_attributes((each_edge.getAttribute('from'), \\\n                each_edge.getAttribute('to')))):\n                G.add_edge_attribute((each_edge.getAttribute('from'), \\\n                    each_edge.getAttribute('to')), attr_tuple)\n    \n    return G", "response": "Reads a graph from a string and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string representing the given hypergraph as a XML document.", "response": "def write_hypergraph(hgr):\n    \"\"\"\n    Return a string specifying the given hypergraph as a XML document.\n    \n    @type  hgr: hypergraph\n    @param hgr: Hypergraph.\n\n    @rtype:  string\n    @return: String specifying the graph as a XML document.\n    \"\"\"\n\n    # Document root\n    grxml = Document()\n    grxmlr = grxml.createElement('hypergraph')\n    grxml.appendChild(grxmlr)\n\n    # Each node...\n    nodes = hgr.nodes()\n    hyperedges = hgr.hyperedges()\n    for each_node in (nodes + hyperedges):\n        if (each_node in nodes):\n            node = grxml.createElement('node')\n        else:\n            node = grxml.createElement('hyperedge')\n        node.setAttribute('id', str(each_node))\n        grxmlr.appendChild(node)\n\n        # and its outgoing edge\n        if each_node in nodes:\n            for each_edge in hgr.links(each_node):\n                edge = grxml.createElement('link')\n                edge.setAttribute('to', str(each_edge))\n                node.appendChild(edge)\n\n    return grxml.toprettyxml()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_hypergraph(string):\n    \n    hgr = hypergraph()\n    \n    dom = parseString(string)\n    for each_node in dom.getElementsByTagName(\"node\"):\n        hgr.add_node(each_node.getAttribute('id'))\n    for each_node in dom.getElementsByTagName(\"hyperedge\"):\n        hgr.add_hyperedge(each_node.getAttribute('id'))\n    dom = parseString(string)\n    for each_node in dom.getElementsByTagName(\"node\"):\n        for each_edge in each_node.getElementsByTagName(\"link\"):\n            hgr.link(str(each_node.getAttribute('id')), str(each_edge.getAttribute('to')))\n    return hgr", "response": "Reads a hypergraph from a string in XML format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef diff_packages(pkg1, pkg2=None):\n    if pkg2 is None:\n        it = iter_packages(pkg1.name)\n        pkgs = [x for x in it if x.version < pkg1.version]\n        if not pkgs:\n            raise RezError(\"No package to diff with - %s is the earliest \"\n                           \"package version\" % pkg1.qualified_name)\n        pkgs = sorted(pkgs, key=lambda x: x.version)\n        pkg2 = pkgs[-1]\n\n    def _check_pkg(pkg):\n        if not (pkg.vcs and pkg.revision):\n            raise RezError(\"Cannot diff package %s: it is a legacy format \"\n                           \"package that does not contain enough information\"\n                           % pkg.qualified_name)\n\n    _check_pkg(pkg1)\n    _check_pkg(pkg2)\n    path = mkdtemp(prefix=\"rez-pkg-diff\")\n    paths = []\n\n    for pkg in (pkg1, pkg2):\n        print \"Exporting %s...\" % pkg.qualified_name\n        path_ = os.path.join(path, pkg.qualified_name)\n        vcs_cls_1 = plugin_manager.get_plugin_class(\"release_vcs\", pkg1.vcs)\n        vcs_cls_1.export(revision=pkg.revision, path=path_)\n        paths.append(path_)\n\n    difftool = config.difftool\n    print \"Opening diff viewer %s...\" % difftool\n    proc = Popen([difftool] + paths)\n    proc.wait()", "response": "Returns a new version of the packages in the diff editor."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sigint_handler(signum, frame):\n    global _handled_int\n    if not _handled_int:\n        _handled_int = True\n        if not _env_var_true(\"_REZ_QUIET_ON_SIG\"):\n            print >> sys.stderr, \"Interrupted by user\"\n        sigbase_handler(signum, frame)", "response": "Exit gracefully on ctrl - C."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sigterm_handler(signum, frame):\n    global _handled_term\n    if not _handled_term:\n        _handled_term = True\n        if not _env_var_true(\"_REZ_QUIET_ON_SIG\"):\n            print >> sys.stderr, \"Terminated by user\"\n        sigbase_handler(signum, frame)", "response": "Exit gracefully on terminate."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_help(self):\n        if self._subparsers:\n            for action in self._subparsers._actions:\n                if isinstance(action, LazySubParsersAction):\n                    for parser_name, parser in action._name_parser_map.iteritems():\n                        action._setup_subparser(parser_name, parser)\n        return super(LazyArgumentParser, self).format_help()", "response": "Sets up all sub - parsers when help is requested."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting the validity of a package name string.", "response": "def is_valid_package_name(name, raise_error=False):\n    \"\"\"Test the validity of a package name string.\n\n    Args:\n        name (str): Name to test.\n        raise_error (bool): If True, raise an exception on failure\n\n    Returns:\n        bool.\n    \"\"\"\n    is_valid = PACKAGE_NAME_REGEX.match(name)\n    if raise_error and not is_valid:\n        raise PackageRequestError(\"Not a valid package name: %r\" % name)\n    return is_valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expand_abbreviations(txt, fields):\n    def _expand(matchobj):\n        s = matchobj.group(\"var\")\n        if s not in fields:\n            matches = [x for x in fields if x.startswith(s)]\n            if len(matches) == 1:\n                s = matches[0]\n        return \"{%s}\" % s\n    return re.sub(FORMAT_VAR_REGEX, _expand, txt)", "response": "Expand abbreviations in a format string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexpanding shell variables of form $var and ${var.", "response": "def expandvars(text, environ=None):\n    \"\"\"Expand shell variables of form $var and ${var}.\n\n    Unknown variables are left unchanged.\n\n    Args:\n        text (str): String to expand.\n        environ (dict): Environ dict to use for expansions, defaults to\n            os.environ.\n\n    Returns:\n        The expanded string.\n    \"\"\"\n    if '$' not in text:\n        return text\n\n    i = 0\n    if environ is None:\n        environ = os.environ\n\n    while True:\n        m = ENV_VAR_REGEX.search(text, i)\n        if not m:\n            break\n        i, j = m.span(0)\n        name = m.group(1)\n        if name.startswith('{') and name.endswith('}'):\n            name = name[1:-1]\n        if name in environ:\n            tail = text[j:]\n            text = text[:i] + environ[name]\n            i = len(text)\n            text += tail\n        else:\n            i = j\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a nested dict generate a python code equivalent.", "response": "def dict_to_attributes_code(dict_):\n    \"\"\"Given a nested dict, generate a python code equivalent.\n\n    Example:\n        >>> d = {'foo': 'bah', 'colors': {'red': 1, 'blue': 2}}\n        >>> print dict_to_attributes_code(d)\n        foo = 'bah'\n        colors.red = 1\n        colors.blue = 2\n\n    Returns:\n        str.\n    \"\"\"\n    lines = []\n    for key, value in dict_.iteritems():\n        if isinstance(value, dict):\n            txt = dict_to_attributes_code(value)\n            lines_ = txt.split('\\n')\n            for line in lines_:\n                if not line.startswith(' '):\n                    line = \"%s.%s\" % (key, line)\n                lines.append(line)\n        else:\n            value_txt = pformat(value)\n            if '\\n' in value_txt:\n                lines.append(\"%s = \\\\\" % key)\n                value_txt = indent(value_txt)\n                lines.extend(value_txt.split('\\n'))\n            else:\n                line = \"%s = %s\" % (key, value_txt)\n                lines.append(line)\n\n    return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint rows of entries in aligned columns.", "response": "def columnise(rows, padding=2):\n    \"\"\"Print rows of entries in aligned columns.\"\"\"\n    strs = []\n    maxwidths = {}\n\n    for row in rows:\n        for i, e in enumerate(row):\n            se = str(e)\n            nse = len(se)\n            w = maxwidths.get(i, -1)\n            if nse > w:\n                maxwidths[i] = nse\n\n    for row in rows:\n        s = ''\n        for i, e in enumerate(row):\n            se = str(e)\n            if i < len(row) - 1:\n                n = maxwidths[i] + padding - len(se)\n                se += ' ' * n\n            s += se\n        strs.append(s)\n    return strs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlike columnise but with colored rows.", "response": "def print_colored_columns(printer, rows, padding=2):\n    \"\"\"Like `columnise`, but with colored rows.\n\n    Args:\n        printer (`colorize.Printer`): Printer object.\n\n    Note:\n        The last entry in each row is the row color, or None for no coloring.\n    \"\"\"\n    rows_ = [x[:-1] for x in rows]\n    colors = [x[-1] for x in rows]\n    for col, line in zip(colors, columnise(rows_, padding=padding)):\n        printer(line, col)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a string into an epoch time.", "response": "def get_epoch_time_from_str(s):\n    \"\"\"Convert a string into epoch time. Examples of valid strings:\n\n        1418350671  # already epoch time\n        -12s        # 12 seconds ago\n        -5.4m       # 5.4 minutes ago\n    \"\"\"\n    try:\n        return int(s)\n    except:\n        pass\n\n    try:\n        if s.startswith('-'):\n            chars = {'d': 24 * 60 * 60,\n                     'h': 60 * 60,\n                     'm': 60,\n                     's': 1}\n            m = chars.get(s[-1])\n            if m:\n                n = float(s[1:-1])\n                secs = int(n * m)\n                now = int(time.time())\n                return max((now - secs), 0)\n    except:\n        pass\n\n    raise ValueError(\"'%s' is an unrecognised time format.\" % s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint the position string equivalent of a positive integer.", "response": "def positional_number_string(n):\n    \"\"\"Print the position string equivalent of a positive integer. Examples:\n\n        0: zeroeth\n        1: first\n        2: second\n        14: 14th\n        21: 21st\n    \"\"\"\n    if n > 20:\n        suffix = positional_suffix[n % 10]\n        return \"%d%s\" % (n, suffix)\n    elif n > 3:\n        return \"%dth\" % n\n    elif n == 3:\n        return \"third\"\n    elif n == 2:\n        return \"second\"\n    elif n == 1:\n        return \"first\"\n    return \"zeroeth\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expanduser(path):\n    if '~' not in path:\n        return path\n\n    if os.name == \"nt\":\n        if 'HOME' in os.environ:\n            userhome = os.environ['HOME']\n        elif 'USERPROFILE' in os.environ:\n            userhome = os.environ['USERPROFILE']\n        elif 'HOMEPATH' in os.environ:\n            drive = os.environ.get('HOMEDRIVE', '')\n            userhome = os.path.join(drive, os.environ['HOMEPATH'])\n        else:\n            return path\n    else:\n        userhome = os.path.expanduser('~')\n\n    def _expanduser(path):\n        return EXPANDUSER_RE.sub(\n            lambda m: m.groups()[0] + userhome + m.groups()[1],\n            path)\n\n    # only replace '~' if it's at start of string or is preceeded by pathsep or\n    # ';' or whitespace; AND, is followed either by sep, pathsep, ';', ' ' or\n    # end-of-string.\n    #\n    return os.path.normpath(_expanduser(path))", "response": "Expand ~ to home directory in the given string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string formatted as a python block comment string.", "response": "def as_block_string(txt):\n    \"\"\"Return a string formatted as a python block comment string, like the one\n    you're currently reading. Special characters are escaped if necessary.\n    \"\"\"\n    import json\n\n    lines = []\n    for line in txt.split('\\n'):\n        line_ = json.dumps(line)\n        line_ = line_[1:-1].rstrip()  # drop double quotes\n        lines.append(line_)\n\n    return '\"\"\"\\n%s\\n\"\"\"' % '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format(self, s, pretty=None, expand=None):\n        if pretty is None:\n            pretty = self.format_pretty\n        if expand is None:\n            expand = self.format_expand\n\n        formatter = ObjectStringFormatter(self, pretty=pretty, expand=expand)\n        return formatter.format(s)", "response": "Format a string.\n\n        Args:\n            s (str): String to format, eg \"hello {name}\"\n            pretty (bool): If True, references to non-string attributes such as\n                lists are converted to basic form, with characters such as\n                brackets and parenthesis removed. If None, defaults to the\n                object's 'format_pretty' attribute.\n            expand (`StringFormatType`): Expansion mode. If None, will default\n                to the object's 'format_expand' attribute.\n\n        Returns:\n            The formatting string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npublishes an AMQP message.", "response": "def publish_message(host, amqp_settings, routing_key, data, async=False):\n    \"\"\"Publish an AMQP message.\n\n    Returns:\n        bool: True if message was sent successfully.\n    \"\"\"\n    global _thread\n    global _num_pending\n\n    kwargs = {\n        \"host\": host,\n        \"amqp_settings\": amqp_settings,\n        \"routing_key\": routing_key,\n        \"data\": data\n    }\n\n    if not async:\n        return _publish_message(**kwargs)\n\n    if _thread is None:\n        with _lock:\n            if _thread is None:\n                _thread = threading.Thread(target=_publish_messages_async)\n                _thread.daemon = True\n                _thread.start()\n\n    with _lock:\n        _num_pending += 1\n\n    _queue.put(kwargs)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _publish_message(host, amqp_settings, routing_key, data):\n    if host == \"stdout\":\n        print(\"Published to %s: %s\" % (routing_key, data))\n        return True\n\n    try:\n        conn = Connection(**remove_nones(\n            host=host,\n            userid=amqp_settings.get(\"userid\"),\n            password=amqp_settings.get(\"password\"),\n            connect_timeout=amqp_settings.get(\"connect_timeout\")\n        ))\n    except socket.error as e:\n        print_error(\"Cannot connect to the message broker: %s\" % (e))\n        return False\n\n    channel = conn.channel()\n\n    # build the message\n    msg = basic_message.Message(**remove_nones(\n        body=json.dumps(data),\n        delivery_mode=amqp_settings.get(\"message_delivery_mode\"),\n        content_type=\"application/json\",\n        content_encoding=\"utf-8\"\n    ))\n\n    # publish the message\n    try:\n        channel.basic_publish(\n            msg,\n            amqp_settings[\"exchange_name\"],\n            routing_key\n        )\n    except Exception as e:\n        print_error(\"Failed to publish message: %s\" % (e))\n        return False\n\n    return True", "response": "Publish a message to the message broker."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy(self):\n        other = Version(None)\n        other.tokens = self.tokens[:]\n        other.seps = self.seps[:]\n        return other", "response": "Returns a copy of the version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a copy of the version possibly with less tokens.", "response": "def trim(self, len_):\n        \"\"\"Return a copy of the version, possibly with less tokens.\n\n        Args:\n            len_ (int): New version length. If >= current length, an\n                unchanged copy of the version is returned.\n        \"\"\"\n        other = Version(None)\n        other.tokens = self.tokens[:len_]\n        other.seps = self.seps[:len_ - 1]\n        return other"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef next(self):\n        if self.tokens:\n            other = self.copy()\n            tok = other.tokens.pop()\n            other.tokens.append(tok.next())\n            return other\n        else:\n            return Version.inf", "response": "Return next version. Eg next 1. 2_ is 1. 2_"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef union(self, other):\n        if not hasattr(other, \"__iter__\"):\n            other = [other]\n        bounds = self.bounds[:]\n        for range in other:\n            bounds += range.bounds\n\n        bounds = self._union(bounds)\n        range = VersionRange(None)\n        range.bounds = bounds\n        return range", "response": "Calculates the union of this and other version ranges."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef intersection(self, other):\n        if not hasattr(other, \"__iter__\"):\n            other = [other]\n\n        bounds = self.bounds\n        for range in other:\n            bounds = self._intersection(bounds, range.bounds)\n            if not bounds:\n                return None\n\n        range = VersionRange(None)\n        range.bounds = bounds\n        return range", "response": "Calculates the intersection of this and other version ranges."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the inverse of the range.", "response": "def inverse(self):\n        \"\"\"Calculate the inverse of the range.\n\n        Returns:\n            New VersionRange object representing the inverse of this range, or\n            None if there is no inverse (ie, this range is the any range).\n        \"\"\"\n        if self.is_any():\n            return None\n        else:\n            bounds = self._inverse(self.bounds)\n            range = VersionRange(None)\n            range.bounds = bounds\n            return range"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits into separate contiguous ranges.", "response": "def split(self):\n        \"\"\"Split into separate contiguous ranges.\n\n        Returns:\n            A list of VersionRange objects. For example, the range \"3|5+\" will\n            be split into [\"3\", \"5+\"].\n        \"\"\"\n        ranges = []\n        for bound in self.bounds:\n            range = VersionRange(None)\n            range.bounds = [bound]\n            ranges.append(range)\n        return ranges"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_span(cls, lower_version=None, upper_version=None,\n                lower_inclusive=True, upper_inclusive=True):\n        \"\"\"Create a range from lower_version..upper_version.\n\n        Args:\n            lower_version: Version object representing lower bound of the range.\n            upper_version: Version object representing upper bound of the range.\n\n        Returns:\n            `VersionRange` object.\n        \"\"\"\n        lower = (None if lower_version is None\n                 else _LowerBound(lower_version, lower_inclusive))\n        upper = (None if upper_version is None\n                 else _UpperBound(upper_version, upper_inclusive))\n        bound = _Bound(lower, upper)\n\n        range = cls(None)\n        range.bounds = [bound]\n        return range", "response": "Create a range from lower_version.. upper_version."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a range from a version object.", "response": "def from_version(cls, version, op=None):\n        \"\"\"Create a range from a version.\n\n        Args:\n            version: Version object. This is used as the upper/lower bound of\n                the range.\n            op: Operation as a string. One of 'gt'/'>', 'gte'/'>=', lt'/'<',\n                'lte'/'<=', 'eq'/'=='. If None, a bounded range will be created\n                that contains the version superset.\n\n        Returns:\n            `VersionRange` object.\n        \"\"\"\n        lower = None\n        upper = None\n\n        if op is None:\n            lower = _LowerBound(version, True)\n            upper = _UpperBound(version.next(), False)\n        elif op in (\"eq\", \"==\"):\n            lower = _LowerBound(version, True)\n            upper = _UpperBound(version, True)\n        elif op in (\"gt\", \">\"):\n            lower = _LowerBound(version, False)\n        elif op in (\"gte\", \">=\"):\n            lower = _LowerBound(version, True)\n        elif op in (\"lt\", \"<\"):\n            upper = _UpperBound(version, False)\n        elif op in (\"lte\", \"<=\"):\n            upper = _UpperBound(version, True)\n        else:\n            raise VersionError(\"Unknown bound operation '%s'\" % op)\n\n        bound = _Bound(lower, upper)\n        range = cls(None)\n        range.bounds = [bound]\n        return range"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_versions(cls, versions):\n        range = cls(None)\n        range.bounds = []\n        for version in dedup(sorted(versions)):\n            lower = _LowerBound(version, True)\n            upper = _UpperBound(version, True)\n            bound = _Bound(lower, upper)\n            range.bounds.append(bound)\n        return range", "response": "Create a range from a list of versions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_versions(self):\n        versions = []\n        for bound in self.bounds:\n            if bound.lower.inclusive and bound.upper.inclusive \\\n                    and (bound.lower.version == bound.upper.version):\n                versions.append(bound.lower.version)\n\n        return versions or None", "response": "Returns exact version ranges as Version objects or None if there are no exact version ranges present."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if version is contained in this range False otherwise.", "response": "def contains_version(self, version):\n        \"\"\"Returns True if version is contained in this range.\"\"\"\n        if len(self.bounds) < 5:\n            # not worth overhead of binary search\n            for bound in self.bounds:\n                i = bound.version_containment(version)\n                if i == 0:\n                    return True\n                if i == -1:\n                    return False\n        else:\n            _, contains = self._contains_version(version)\n            return contains\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlike iter_intersect_test but returns intersections only.", "response": "def iter_intersecting(self, iterable, key=None, descending=False):\n        \"\"\"Like `iter_intersect_test`, but returns intersections only.\n\n        Returns:\n            An iterator that returns items from `iterable` that intersect.\n        \"\"\"\n        return _ContainsVersionIterator(self, iterable, key, descending,\n            mode=_ContainsVersionIterator.MODE_INTERSECTING)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter_non_intersecting(self, iterable, key=None, descending=False):\n        return _ContainsVersionIterator(self, iterable, key, descending,\n            mode=_ContainsVersionIterator.MODE_NON_INTERSECTING)", "response": "Like iter_intersect_test but returns non - intersections only."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a contiguous range that is a superset of this range.", "response": "def span(self):\n        \"\"\"Return a contiguous range that is a superset of this range.\n\n        Returns:\n            A VersionRange object representing the span of this range. For\n            example, the span of \"2+<4|6+<8\" would be \"2+<8\".\n        \"\"\"\n        other = VersionRange(None)\n        bound = _Bound(self.bounds[0].lower, self.bounds[-1].upper)\n        other.bounds = [bound]\n        return other"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvisit each version in the range and apply a function to each.", "response": "def visit_versions(self, func):\n        \"\"\"Visit each version in the range, and apply a function to each.\n\n        This is for advanced usage only.\n\n        If `func` returns a `Version`, this call will change the versions in\n        place.\n\n        It is possible to change versions in a way that is nonsensical - for\n        example setting an upper bound to a smaller version than the lower bound.\n        Use at your own risk.\n\n        Args:\n            func (callable): Takes a `Version` instance arg, and is applied to\n                every version in the range. If `func` returns a `Version`, it\n                will replace the existing version, updating this `VersionRange`\n                instance in place.\n        \"\"\"\n        for bound in self.bounds:\n            if bound.lower is not _LowerBound.min:\n                result = func(bound.lower.version)\n                if isinstance(result, Version):\n                    bound.lower.version = result\n\n            if bound.upper is not _UpperBound.inf:\n                result = func(bound.upper.version)\n                if isinstance(result, Version):\n                    bound.upper.version = result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef async_send(self, url, data, headers, success_cb, failure_cb):\n        # this can be optimized by making a custom self.send that does not\n        # read the response since we don't use it.\n        self._lock.acquire()\n        return gevent.spawn(\n            super(GeventedHTTPTransport, self).send, url, data, headers\n        ).link(lambda x: self._done(x, success_cb, failure_cb))", "response": "Send a request to a remote webserver."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a request to a remote webserver using HTTP POST.", "response": "def send(self, url, data, headers):\n        \"\"\"\n        Sends a request to a remote webserver using HTTP POST.\n        \"\"\"\n        req = urllib2.Request(url, headers=headers)\n\n        try:\n            response = urlopen(\n                url=req,\n                data=data,\n                timeout=self.timeout,\n                verify_ssl=self.verify_ssl,\n                ca_certs=self.ca_certs,\n            )\n        except urllib2.HTTPError as exc:\n            msg = exc.headers.get('x-sentry-error')\n            code = exc.getcode()\n            if code == 429:\n                try:\n                    retry_after = int(exc.headers.get('retry-after'))\n                except (ValueError, TypeError):\n                    retry_after = 0\n                raise RateLimited(msg, retry_after)\n            elif msg:\n                raise APIError(msg, code)\n            else:\n                raise\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the variables needed to authenticate the user.", "response": "def extract_auth_vars(request):\n    \"\"\"\n    raven-js will pass both Authorization and X-Sentry-Auth depending on the browser\n    and server configurations.\n    \"\"\"\n    if request.META.get('HTTP_X_SENTRY_AUTH', '').startswith('Sentry'):\n        return request.META['HTTP_X_SENTRY_AUTH']\n    elif request.META.get('HTTP_AUTHORIZATION', '').startswith('Sentry'):\n        return request.META['HTTP_AUTHORIZATION']\n    else:\n        # Try to construct from GET request\n        args = [\n            '%s=%s' % i\n            for i in request.GET.items()\n            if i[0].startswith('sentry_') and i[0] != 'sentry_data'\n        ]\n        if args:\n            return 'Sentry %s' % ', '.join(args)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_value(self, exc_type, exc_value, exc_traceback):\n        stack_info = get_stack_info(\n            iter_traceback_frames(exc_traceback),\n            transformer=self.transform,\n            capture_locals=self.client.capture_locals,\n        )\n\n        exc_module = getattr(exc_type, '__module__', None)\n        if exc_module:\n            exc_module = str(exc_module)\n        exc_type = getattr(exc_type, '__name__', '<unknown>')\n\n        return {\n            'value': to_unicode(exc_value),\n            'type': str(exc_type),\n            'module': to_unicode(exc_module),\n            'stacktrace': stack_info,\n        }", "response": "Convert exception info to a value for the values list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrecords a breadcrumb for all active clients.", "response": "def record(message=None, timestamp=None, level=None, category=None,\n           data=None, type=None, processor=None):\n    \"\"\"Records a breadcrumb for all active clients.  This is what integration\n    code should use rather than invoking the `captureBreadcrumb` method\n    on a specific client.\n    \"\"\"\n    if timestamp is None:\n        timestamp = time()\n    for ctx in raven.context.get_active_contexts():\n        ctx.breadcrumbs.record(timestamp, level, message, category,\n                               data, type, processor)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nignore a logger during breadcrumb recording.", "response": "def ignore_logger(name_or_logger, allow_level=None):\n    \"\"\"Ignores a logger during breadcrumb recording.\n    \"\"\"\n    def handler(logger, level, msg, args, kwargs):\n        if allow_level is not None and \\\n           level >= allow_level:\n            return False\n        return True\n    register_special_log_handler(name_or_logger, handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_special_log_handler(name_or_logger, callback):\n    if isinstance(name_or_logger, string_types):\n        name = name_or_logger\n    else:\n        name = name_or_logger.name\n    special_logger_handlers[name] = callback", "response": "Registers a callback for log handling."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls the SQL hook that will be executed when the database is executed.", "response": "def install_sql_hook():\n    \"\"\"If installed this causes Django's queries to be captured.\"\"\"\n    try:\n        from django.db.backends.utils import CursorWrapper\n    except ImportError:\n        from django.db.backends.util import CursorWrapper\n\n    try:\n        real_execute = CursorWrapper.execute\n        real_executemany = CursorWrapper.executemany\n    except AttributeError:\n        # XXX(mitsuhiko): On some very old django versions (<1.6) this\n        # trickery would have to look different but I can't be bothered.\n        return\n\n    def record_many_sql(vendor, alias, start, sql, param_list):\n        duration = time.time() - start\n        for params in param_list:\n            record_sql(vendor, alias, start, duration, sql, params)\n\n    def execute(self, sql, params=None):\n        start = time.time()\n        try:\n            return real_execute(self, sql, params)\n        finally:\n            record_sql(self.db.vendor, getattr(self.db, 'alias', None),\n                       start, time.time() - start, sql, params)\n\n    def executemany(self, sql, param_list):\n        start = time.time()\n        try:\n            return real_executemany(self, sql, param_list)\n        finally:\n            record_many_sql(self.db.vendor, getattr(self.db, 'alias', None),\n                            start, sql, param_list)\n\n    CursorWrapper.execute = execute\n    CursorWrapper.executemany = executemany\n    breadcrumbs.ignore_logger('django.db.backends')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self):\n        self._lock.acquire()\n        try:\n            if not self.is_alive():\n                self._thread = threading.Thread(target=self._target, name=\"raven.AsyncWorker\")\n                self._thread.setDaemon(True)\n                self._thread.start()\n                self._thread_for_pid = os.getpid()\n        finally:\n            self._lock.release()\n            atexit.register(self.main_thread_terminated)", "response": "Starts the task thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, value, **kwargs):\n        if value is None:\n            return None\n\n        objid = id(value)\n        if objid in self.context:\n            return '<...>'\n        self.context.add(objid)\n\n        try:\n            for serializer in self.serializers:\n                try:\n                    if serializer.can(value):\n                        return serializer.serialize(value, **kwargs)\n                except Exception as e:\n                    logger.exception(e)\n                    return text_type(type(value))\n\n            # if all else fails, lets use the repr of the object\n            try:\n                return repr(value)\n            except Exception as e:\n                logger.exception(e)\n                # It's common case that a model's __unicode__ definition\n                # may try to query the database which if it was not\n                # cleaned up correctly, would hit a transaction aborted\n                # exception\n                return text_type(type(value))\n        finally:\n            self.context.remove(objid)", "response": "This function handles recursively transforming the value via the serializers\n            and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserializes the message and passes the payload onto send_encoded.", "response": "def send(self, auth_header=None, callback=None, **data):\n        \"\"\"\n        Serializes the message and passes the payload onto ``send_encoded``.\n        \"\"\"\n        message = self.encode(data)\n\n        return self.send_encoded(message, auth_header=auth_header, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _send_remote(self, url, data, headers=None, callback=None):\n        if headers is None:\n            headers = {}\n\n        return AsyncHTTPClient().fetch(\n            url, callback, method=\"POST\", body=data, headers=headers,\n            validate_cert=self.validate_cert\n        )", "response": "Send a request to the sentry\n        server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the data required for the entry class from the current request.", "response": "def get_sentry_data_from_request(self):\n        \"\"\"\n        Extracts the data required for 'sentry.interfaces.Http' from the\n        current request being handled by the request handler\n\n        :param return: A dictionary.\n        \"\"\"\n        return {\n            'request': {\n                'url': self.request.full_url(),\n                'method': self.request.method,\n                'data': self.request.body,\n                'query_string': self.request.query,\n                'cookies': self.request.headers.get('Cookie', None),\n                'headers': dict(self.request.headers),\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noverriding to capture all exceptions to sentry.", "response": "def log_exception(self, typ, value, tb):\n        \"\"\"Override implementation to report all exceptions to sentry.\n        log_exception() is added in Tornado v3.1.\n        \"\"\"\n        rv = super(SentryMixin, self).log_exception(typ, value, tb)\n        # Do not capture tornado.web.HTTPErrors outside the 500 range.\n        if isinstance(value, WebHTTPError) and (value.status_code < 500 or value.status_code > 599):\n            return rv\n        self.captureException(exc_info=(typ, value, tb))\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding to report all exceptions to sentry", "response": "def send_error(self, status_code=500, **kwargs):\n        \"\"\"Override implementation to report all exceptions to sentry, even\n        after self.flush() or self.finish() is called, for pre-v3.1 Tornado.\n        \"\"\"\n        if hasattr(super(SentryMixin, self), 'log_exception'):\n            return super(SentryMixin, self).send_error(status_code, **kwargs)\n        else:\n            rv = super(SentryMixin, self).send_error(status_code, **kwargs)\n            if 500 <= status_code <= 599:\n                self.captureException(exc_info=kwargs.get('exc_info'))\n            return rv"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef recurse(self, value, max_depth=6, _depth=0, **kwargs):\n        string_max_length = kwargs.get('string_max_length', None)\n\n        _depth += 1\n        if _depth >= max_depth:\n            try:\n                value = text_type(repr(value))[:string_max_length]\n            except Exception as e:\n                import traceback\n                traceback.print_exc()\n                self.manager.logger.exception(e)\n                return text_type(type(value))\n        return self.manager.transform(value, max_depth=max_depth,\n                                      _depth=_depth, **kwargs)", "response": "Given value recurse to handle the new entries in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a public DSN which is consumable by raven - js", "response": "def get_public_dsn(self, scheme=None):\n        \"\"\"\n        Returns a public DSN which is consumable by raven-js\n\n        >>> # Return scheme-less DSN\n        >>> print client.get_public_dsn()\n\n        >>> # Specify a scheme to use (http or https)\n        >>> print client.get_public_dsn('https')\n        \"\"\"\n        if self.is_enabled():\n            url = self.remote.get_public_dsn()\n            if scheme:\n                return '%s:%s' % (scheme, url)\n\n            return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a message from an event.", "response": "def build_msg(self, event_type, data=None, date=None,\n                  time_spent=None, extra=None, stack=None, public_key=None,\n                  tags=None, fingerprint=None, **kwargs):\n        \"\"\"\n        Captures, processes and serializes an event into a dict object\n\n        The result of ``build_msg`` should be a standardized dict, with\n        all default values available.\n        \"\"\"\n        # create ID client-side so that it can be passed to application\n        event_id = uuid.uuid4().hex\n\n        data = merge_dicts(self.context.data, data)\n\n        data.setdefault('tags', {})\n        data.setdefault('extra', {})\n\n        if '.' not in event_type:\n            # Assume it's a builtin\n            event_type = 'raven.events.%s' % event_type\n\n        handler = self.get_handler(event_type)\n        result = handler.capture(**kwargs)\n\n        # data (explicit) culprit takes over auto event detection\n        culprit = result.pop('culprit', None)\n        if data.get('culprit'):\n            culprit = data['culprit']\n\n        for k, v in iteritems(result):\n            if k not in data:\n                data[k] = v\n\n        # auto_log_stacks only applies to events that are not exceptions\n        # due to confusion about which stack is which and the automatic\n        # application of stacktrace to exception objects by Sentry\n        if stack is None and 'exception' not in data:\n            stack = self.auto_log_stacks\n\n        if stack and 'stacktrace' not in data:\n            if stack is True:\n                frames = iter_stack_frames()\n\n            else:\n                frames = stack\n\n            stack_info = get_stack_info(\n                frames,\n                transformer=self.transform,\n                capture_locals=self.capture_locals,\n            )\n            data.update({\n                'stacktrace': stack_info,\n            })\n\n        if self.include_paths:\n            for frame in self._iter_frames(data):\n                if frame.get('in_app') is not None:\n                    continue\n\n                path = frame.get('module')\n                if not path:\n                    continue\n\n                if path.startswith('raven.'):\n                    frame['in_app'] = False\n                else:\n                    frame['in_app'] = (\n                        any(path.startswith(x) for x in self.include_paths)\n                        and not any(path.startswith(x) for x in self.exclude_paths)\n                    )\n\n        transaction = None\n        if not culprit:\n            transaction = self.transaction.peek()\n\n        if not data.get('level'):\n            data['level'] = kwargs.get('level') or logging.ERROR\n\n        if not data.get('server_name'):\n            data['server_name'] = self.name\n\n        if not data.get('modules'):\n            data['modules'] = self.get_module_versions()\n\n        if self.release is not None:\n            data['release'] = self.release\n\n        if self.environment is not None:\n            data['environment'] = self.environment\n\n        data['tags'] = merge_dicts(self.tags, data['tags'], tags)\n        data['extra'] = merge_dicts(self.extra, data['extra'], extra)\n\n        # Legacy support for site attribute\n        site = data.pop('site', None) or self.site\n        if site:\n            data['tags'].setdefault('site', site)\n\n        if transaction:\n            data['transaction'] = transaction\n        elif culprit:\n            data['culprit'] = culprit\n\n        if fingerprint:\n            data['fingerprint'] = fingerprint\n\n        # Run the data through processors\n        for processor in self.get_processors():\n            data.update(processor.process(data))\n\n        if 'message' not in data:\n            data['message'] = kwargs.get('message', handler.to_string(data))\n\n        # tags should only be key=>u'value'\n        for key, value in iteritems(data['tags']):\n            data['tags'][key] = to_unicode(value)\n\n        # extra data can be any arbitrary value\n        for k, v in iteritems(data['extra']):\n            data['extra'][k] = self.transform(v)\n\n        # It's important date is added **after** we serialize\n        data.setdefault('project', self.remote.project)\n        data.setdefault('timestamp', date or datetime.utcnow())\n        data.setdefault('time_spent', time_spent)\n        data.setdefault('event_id', event_id)\n        data.setdefault('platform', PLATFORM_NAME)\n        data.setdefault('sdk', SDK_VALUE)\n        data.setdefault('repos', self.repos)\n\n        # insert breadcrumbs\n        if self.enable_breadcrumbs:\n            crumbs = self.context.breadcrumbs.get_buffer()\n            if crumbs:\n                # Make sure we send the crumbs here as \"values\" as we use the\n                # raven client internally in sentry and the alternative\n                # submission option of a list here is not supported by the\n                # internal sender.\n                data.setdefault('breadcrumbs', {\n                    'values': crumbs\n                })\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncapture and processes an event and pipes it off to SentryClient. send.", "response": "def capture(self, event_type, data=None, date=None, time_spent=None,\n                extra=None, stack=None, tags=None, sample_rate=None,\n                **kwargs):\n        \"\"\"\n        Captures and processes an event and pipes it off to SentryClient.send.\n\n        To use structured data (interfaces) with capture:\n\n        >>> capture('raven.events.Message', message='foo', data={\n        >>>     'request': {\n        >>>         'url': '...',\n        >>>         'data': {},\n        >>>         'query_string': '...',\n        >>>         'method': 'POST',\n        >>>     },\n        >>>     'logger': 'logger.name',\n        >>> }, extra={\n        >>>     'key': 'value',\n        >>> })\n\n        The finalized ``data`` structure contains the following (some optional)\n        builtin values:\n\n        >>> {\n        >>>     # the culprit and version information\n        >>>     'culprit': 'full.module.name', # or /arbitrary/path\n        >>>\n        >>>     # all detectable installed modules\n        >>>     'modules': {\n        >>>         'full.module.name': 'version string',\n        >>>     },\n        >>>\n        >>>     # arbitrary data provided by user\n        >>>     'extra': {\n        >>>         'key': 'value',\n        >>>     }\n        >>> }\n\n        :param event_type: the module path to the Event class. Builtins can use\n                           shorthand class notation and exclude the full module\n                           path.\n        :param data: the data base, useful for specifying structured data\n                           interfaces. Any key which contains a '.' will be\n                           assumed to be a data interface.\n        :param date: the datetime of this event\n        :param time_spent: a integer value representing the duration of the\n                           event (in milliseconds)\n        :param extra: a dictionary of additional standard metadata\n        :param stack: a stacktrace for the event\n        :param tags: dict of extra tags\n        :param sample_rate: a float in the range [0, 1] to sample this message\n        :return: a 32-length string identifying this event\n        \"\"\"\n        if not self.is_enabled():\n            return\n\n        exc_info = kwargs.get('exc_info')\n        if exc_info is not None:\n            if self.skip_error_for_logging(exc_info):\n                return\n            elif not self.should_capture(exc_info):\n                self.logger.info(\n                    'Not capturing exception due to filters: %s', exc_info[0],\n                    exc_info=sys.exc_info())\n                return\n            self.record_exception_seen(exc_info)\n\n        data = self.build_msg(\n            event_type, data, date, time_spent, extra, stack, tags=tags,\n            **kwargs)\n\n        # should this event be sampled?\n        if sample_rate is None:\n            sample_rate = self.sample_rate\n\n        if self._random.random() < sample_rate:\n            self.send(**data)\n\n        self._local_state.last_event_id = data['event_id']\n\n        return data['event_id']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _log_failed_submission(self, data):\n        message = data.pop('message', '<no message value>')\n        output = [message]\n        if 'exception' in data and 'stacktrace' in data['exception']['values'][-1]:\n            # try to reconstruct a reasonable version of the exception\n            for frame in data['exception']['values'][-1]['stacktrace'].get('frames', []):\n                output.append('  File \"%(fn)s\", line %(lineno)s, in %(func)s' % {\n                    'fn': frame.get('filename', 'unknown_filename'),\n                    'lineno': frame.get('lineno', -1),\n                    'func': frame.get('function', 'unknown_function'),\n                })\n\n        self.uncaught_logger.error(output)", "response": "Log a reasonable representation of an event that should have been sent to Sentry\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_encoded(self, message, auth_header=None, **kwargs):\n        client_string = 'raven-python/%s' % (raven.VERSION,)\n\n        if not auth_header:\n            timestamp = time.time()\n            auth_header = get_auth_header(\n                protocol=self.protocol_version,\n                timestamp=timestamp,\n                client=client_string,\n                api_key=self.remote.public_key,\n                api_secret=self.remote.secret_key,\n            )\n\n        headers = {\n            'User-Agent': client_string,\n            'X-Sentry-Auth': auth_header,\n            'Content-Encoding': self.get_content_encoding(),\n            'Content-Type': 'application/octet-stream',\n        }\n\n        return self.send_remote(\n            url=self.remote.store_endpoint,\n            data=message,\n            headers=headers,\n            **kwargs\n        )", "response": "Sends a message to the remote server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an event from an exception.", "response": "def captureException(self, exc_info=None, **kwargs):\n        \"\"\"\n        Creates an event from an exception.\n\n        >>> try:\n        >>>     exc_info = sys.exc_info()\n        >>>     client.captureException(exc_info)\n        >>> finally:\n        >>>     del exc_info\n\n        If exc_info is not provided, or is set to True, then this method will\n        perform the ``exc_info = sys.exc_info()`` and the requisite clean-up\n        for you.\n\n        ``kwargs`` are passed through to ``.capture``.\n        \"\"\"\n        if exc_info is None or exc_info is True:\n            exc_info = sys.exc_info()\n\n        return self.capture(\n            'raven.events.Exception', exc_info=exc_info, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef capture_exceptions(self, function_or_exceptions=None, **kwargs):\n        function = None\n        exceptions = (Exception,)\n        if isinstance(function_or_exceptions, FunctionType):\n            function = function_or_exceptions\n        elif function_or_exceptions is not None:\n            exceptions = function_or_exceptions\n\n        # In python3.2 contextmanager acts both as contextmanager and decorator\n        @contextlib.contextmanager\n        def make_decorator(exceptions):\n            try:\n                yield\n            except exceptions:\n                self.captureException(**kwargs)\n                raise\n\n        decorator = make_decorator(exceptions)\n\n        if function:\n            return decorator(function)\n        return decorator", "response": "A decorator that captures exceptions in a function or code block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef captureQuery(self, query, params=(), engine=None, **kwargs):\n        return self.capture(\n            'raven.events.Query', query=query, params=params, engine=engine,\n            **kwargs)", "response": "Creates an event for a SQL query."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef captureBreadcrumb(self, *args, **kwargs):\n        # Note: framework integration should not call this method but\n        # instead use the raven.breadcrumbs.record_breadcrumb function\n        # which will record to the correct client automatically.\n        self.context.breadcrumbs.record(*args, **kwargs)", "response": "Records a breadcrumb with the current context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a scheme with the given class.", "response": "def register_scheme(self, scheme, cls):\n        \"\"\"\n        It is possible to inject new schemes at runtime\n        \"\"\"\n        if scheme in self._schemes:\n            raise DuplicateScheme()\n\n        urlparse.register_scheme(scheme)\n        # TODO (vng): verify the interface of the new class\n        self._schemes[scheme] = cls"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_user_info(self, request):\n        user_info = {}\n\n        try:\n            ip_address = request.access_route[0]\n        except IndexError:\n            ip_address = request.remote_addr\n\n        if ip_address:\n            user_info['ip_address'] = ip_address\n\n        if not has_flask_login:\n            return user_info\n\n        if not hasattr(current_app, 'login_manager'):\n            return user_info\n\n        try:\n            is_authenticated = current_user.is_authenticated\n        except AttributeError:\n            # HACK: catch the attribute error thrown by flask-login is not attached\n            # >   current_user = LocalProxy(lambda: _request_ctx_stack.top.user)\n            # E   AttributeError: 'RequestContext' object has no attribute 'user'\n            return user_info\n\n        if callable(is_authenticated):\n            is_authenticated = is_authenticated()\n\n        if not is_authenticated:\n            return user_info\n\n        user_info['id'] = current_user.get_id()\n\n        if 'SENTRY_USER_ATTRS' in current_app.config:\n            for attr in current_app.config['SENTRY_USER_ATTRS']:\n                if hasattr(current_user, attr):\n                    user_info[attr] = getattr(current_user, attr)\n\n        return user_info", "response": "Get user info from flask - login request"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_http_info(self, request):\n        if self.is_json_type(request.mimetype):\n            retriever = self.get_json_data\n        else:\n            retriever = self.get_form_data\n        return self.get_http_info_with_retriever(request, retriever)", "response": "Determine how to retrieve the data by using request. mimetype."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_http_info_with_retriever(self, request, retriever=None):\n        if retriever is None:\n            retriever = self.get_form_data\n\n        urlparts = urlparse.urlsplit(request.url)\n\n        try:\n            data = retriever(request)\n        except ClientDisconnected:\n            data = {}\n\n        return {\n            'url': '%s://%s%s' % (urlparts.scheme, urlparts.netloc, urlparts.path),\n            'query_string': urlparts.query,\n            'method': request.method,\n            'data': data,\n            'headers': dict(get_headers(request.environ)),\n            'env': dict(get_environ(request.environ)),\n        }", "response": "Get http info with retriever"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_logging(handler, exclude=EXCLUDE_LOGGER_DEFAULTS):\n    logger = logging.getLogger()\n    if handler.__class__ in map(type, logger.handlers):\n        return False\n\n    logger.addHandler(handler)\n\n    # Add StreamHandler to sentry's default so you can catch missed exceptions\n    for logger_name in exclude:\n        logger = logging.getLogger(logger_name)\n        logger.propagate = False\n        logger.addHandler(logging.StreamHandler())\n\n    return True", "response": "Configure logging to pipe to Sentry."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends data to a remote webserver.", "response": "def send(self, url, data, headers):\n        \"\"\"\n        Spawn an async request to a remote webserver.\n        \"\"\"\n        eventlet.spawn(self._send_payload, (url, data, headers))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_http_info_with_retriever(self, request, retriever):\n        urlparts = urlparse.urlsplit(request.url)\n\n        try:\n            data = retriever(request)\n        except Exception:\n            data = {}\n\n        return {\n            'url': '{0}://{1}{2}'.format(\n                urlparts.scheme, urlparts.netloc, urlparts.path),\n            'query_string': urlparts.query,\n            'method': request.method,\n            'data': data,\n            'cookies': request.cookies,\n            'headers': request.headers,\n            'env': {\n                'REMOTE_ADDR': request.remote_addr,\n            }\n        }", "response": "Return http_info dict with the request data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_dict(dictish):\n    if hasattr(dictish, 'iterkeys'):\n        m = dictish.iterkeys\n    elif hasattr(dictish, 'keys'):\n        m = dictish.keys\n    else:\n        raise ValueError(dictish)\n\n    return dict((k, dictish[k]) for k in m())", "response": "Given something that closely resembles a dictionary we attempt to coerce it into a propery dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_traceback_frames(tb):\n    # Some versions of celery have hacked traceback objects that might\n    # miss tb_frame.\n    while tb and hasattr(tb, 'tb_frame'):\n        # support for __traceback_hide__ which is used by a few libraries\n        # to hide internal frames.\n        f_locals = getattr(tb.tb_frame, 'f_locals', {})\n        if not _getitem_from_frame(f_locals, '__traceback_hide__'):\n            yield tb.tb_frame, getattr(tb, 'tb_lineno', None)\n        tb = tb.tb_next", "response": "Iterate over all traceback frames in the traceback object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over the stack frames.", "response": "def iter_stack_frames(frames=None):\n    \"\"\"\n    Given an optional list of frames (defaults to current stack),\n    iterates over all frames that do not contain the ``__traceback_hide__``\n    local variable.\n    \"\"\"\n    if not frames:\n        frames = inspect.stack()[1:]\n\n    for frame, lineno in ((f[0], f[2]) for f in reversed(frames)):\n        f_locals = getattr(frame, 'f_locals', {})\n        if not _getitem_from_frame(f_locals, '__traceback_hide__'):\n            yield frame, lineno"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves various excess metadata from middle frames which go beyond frame_allowance. Returns the frames in a new order.", "response": "def slim_frame_data(frames, frame_allowance=25):\n    \"\"\"\n    Removes various excess metadata from middle frames which go beyond\n    ``frame_allowance``.\n\n    Returns ``frames``.\n    \"\"\"\n    frames_len = 0\n    app_frames = []\n    system_frames = []\n    for frame in frames:\n        frames_len += 1\n        if frame.get('in_app'):\n            app_frames.append(frame)\n        else:\n            system_frames.append(frame)\n\n    if frames_len <= frame_allowance:\n        return frames\n\n    remaining = frames_len - frame_allowance\n    app_count = len(app_frames)\n    system_allowance = max(frame_allowance - app_count, 0)\n    if system_allowance:\n        half_max = int(system_allowance / 2)\n        # prioritize trimming system frames\n        for frame in system_frames[half_max:-half_max]:\n            frame.pop('vars', None)\n            frame.pop('pre_context', None)\n            frame.pop('post_context', None)\n            remaining -= 1\n\n    else:\n        for frame in system_frames:\n            frame.pop('vars', None)\n            frame.pop('pre_context', None)\n            frame.pop('post_context', None)\n            remaining -= 1\n\n    if remaining:\n        app_allowance = app_count - remaining\n        half_max = int(app_allowance / 2)\n\n        for frame in app_frames[half_max:-half_max]:\n            frame.pop('vars', None)\n            frame.pop('pre_context', None)\n            frame.pop('post_context', None)\n\n    return frames"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a list of frames returns a list of stack information dictionary objects that are JSON - ready.", "response": "def get_stack_info(frames, transformer=transform, capture_locals=True,\n                   frame_allowance=25):\n    \"\"\"\n    Given a list of frames, returns a list of stack information\n    dictionary objects that are JSON-ready.\n\n    We have to be careful here as certain implementations of the\n    _Frame class do not contain the necessary data to lookup all\n    of the information we want.\n    \"\"\"\n    __traceback_hide__ = True  # NOQA\n\n    result = []\n    for frame_info in frames:\n        # Old, terrible API\n        if isinstance(frame_info, (list, tuple)):\n            frame, lineno = frame_info\n\n        else:\n            frame = frame_info\n            lineno = frame_info.f_lineno\n\n        # Support hidden frames\n        f_locals = getattr(frame, 'f_locals', {})\n        if _getitem_from_frame(f_locals, '__traceback_hide__'):\n            continue\n\n        f_globals = getattr(frame, 'f_globals', {})\n\n        f_code = getattr(frame, 'f_code', None)\n        if f_code:\n            abs_path = frame.f_code.co_filename\n            function = frame.f_code.co_name\n        else:\n            abs_path = None\n            function = None\n\n        loader = _getitem_from_frame(f_globals, '__loader__')\n        module_name = _getitem_from_frame(f_globals, '__name__')\n\n        if lineno:\n            lineno -= 1\n\n        if lineno is not None and abs_path:\n            pre_context, context_line, post_context = \\\n                get_lines_from_file(abs_path, lineno, 5, loader, module_name)\n        else:\n            pre_context, context_line, post_context = None, None, None\n\n        # Try to pull a relative file path\n        # This changes /foo/site-packages/baz/bar.py into baz/bar.py\n        try:\n            base_filename = sys.modules[module_name.split('.', 1)[0]].__file__\n            filename = abs_path.split(\n                base_filename.rsplit(os.sep, 2)[0], 1)[-1].lstrip(os.sep)\n        except Exception:\n            filename = abs_path\n\n        if not filename:\n            filename = abs_path\n\n        frame_result = {\n            'abs_path': abs_path,\n            'filename': filename,\n            'module': module_name or None,\n            'function': function or '<unknown>',\n            'lineno': lineno + 1,\n        }\n        if capture_locals:\n            f_vars = get_frame_locals(frame, transformer=transformer)\n            if f_vars:\n                frame_result['vars'] = f_vars\n\n        if context_line is not None:\n            frame_result.update({\n                'pre_context': pre_context,\n                'context_line': context_line,\n                'post_context': post_context,\n            })\n        result.append(frame_result)\n\n    stackinfo = {\n        'frames': slim_frame_data(result, frame_allowance=frame_allowance),\n    }\n\n    return stackinfo"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns request data extracted from web. ctx.", "response": "def get_data_from_request():\n    \"\"\"Returns request data extracted from web.ctx.\"\"\"\n    return {\n        'request': {\n            'url': '%s://%s%s' % (web.ctx['protocol'], web.ctx['host'], web.ctx['path']),\n            'query_string': web.ctx.query,\n            'method': web.ctx.method,\n            'data': web.data(),\n            'headers': dict(get_headers(web.ctx.environ)),\n            'env': dict(get_environ(web.ctx.environ)),\n        }\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_git_sha(path, head=None):\n    if not head:\n        head_path = os.path.join(path, '.git', 'HEAD')\n        if not os.path.exists(head_path):\n            raise InvalidGitRepository(\n                'Cannot identify HEAD for git repository at %s' % (path,))\n\n        with open(head_path, 'r') as fp:\n            head = text_type(fp.read()).strip()\n\n        if head.startswith('ref: '):\n            head = head[5:]\n            revision_file = os.path.join(\n                path, '.git', *head.split('/')\n            )\n        else:\n            return head\n    else:\n        revision_file = os.path.join(path, '.git', 'refs', 'heads', head)\n\n    if not os.path.exists(revision_file):\n        if not os.path.exists(os.path.join(path, '.git')):\n            raise InvalidGitRepository(\n                '%s does not seem to be the root of a git repository' % (path,))\n\n        # Check for our .git/packed-refs' file since a `git gc` may have run\n        # https://git-scm.com/book/en/v2/Git-Internals-Maintenance-and-Data-Recovery\n        packed_file = os.path.join(path, '.git', 'packed-refs')\n        if os.path.exists(packed_file):\n            with open(packed_file) as fh:\n                for line in fh:\n                    line = line.rstrip()\n                    if line and line[:1] not in ('#', '^'):\n                        try:\n                            revision, ref = line.split(' ', 1)\n                        except ValueError:\n                            continue\n                        if ref == head:\n                            return text_type(revision)\n\n        raise InvalidGitRepository(\n            'Unable to find ref to head \"%s\" in repository' % (head,))\n\n    with open(revision_file) as fh:\n        return text_type(fh.read()).strip()", "response": "Fetch the git sha of the current node in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_package_version(dist_name):\n    try:\n        # Importing pkg_resources can be slow, so only import it\n        # if we need it.\n        import pkg_resources\n    except ImportError:\n        # pkg_resource is not available on Google App Engine\n        raise NotImplementedError('pkg_resources is not available '\n                                  'on this Python install')\n    dist = pkg_resources.get_distribution(dist_name)\n    return dist.version", "response": ">>> fetch_package_version ( dist_name ) >>>"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses the request body.", "response": "def process_request(self, request):\n        \"\"\"\n        Access request.body, otherwise it might not be accessible later\n        after request has been read/streamed\n        \"\"\"\n        content_type = request.META.get('CONTENT_TYPE', '')\n        for non_cacheable_type in self.non_cacheable_types:\n            if non_cacheable_type in content_type:\n                return\n        request.body"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_options(settings, defaults=None):\n    if defaults is None:\n        defaults = {}\n\n    if isinstance(settings, dict):\n        def getopt(key, default=None):\n            return settings.get(\n                'SENTRY_%s' % key.upper(),\n                defaults.get(key, default)\n            )\n\n        options = copy.copy(\n            settings.get('SENTRY_CONFIG')\n            or settings.get('RAVEN_CONFIG')\n            or {}\n        )\n    else:\n        def getopt(key, default=None):\n            return getattr(settings, 'SENTRY_%s' % key.upper(), defaults.get(key, default))\n\n        options = copy.copy(\n            getattr(settings, 'SENTRY_CONFIG', None)\n            or getattr(settings, 'RAVEN_CONFIG', None)\n            or {}\n        )\n\n    options.setdefault('include_paths', getopt('include_paths', []))\n    options.setdefault('exclude_paths', getopt('exclude_paths', []))\n    options.setdefault('timeout', getopt('timeout'))\n    options.setdefault('name', getopt('name'))\n    options.setdefault('auto_log_stacks', getopt('auto_log_stacks'))\n    options.setdefault('string_max_length', getopt('string_max_length'))\n    options.setdefault('list_max_length', getopt('list_max_length'))\n    options.setdefault('site', getopt('site'))\n    options.setdefault('processors', getopt('processors'))\n    options.setdefault('sanitize_keys', getopt('sanitize_keys'))\n    options.setdefault('dsn', getopt('dsn', os.environ.get('SENTRY_DSN')))\n    options.setdefault('context', getopt('context'))\n    options.setdefault('tags', getopt('tags'))\n    options.setdefault('release', getopt('release'))\n    options.setdefault('repos', getopt('repos'))\n    options.setdefault('environment', getopt('environment'))\n    options.setdefault('ignore_exceptions', getopt('ignore_exceptions'))\n    options.setdefault('sample_rate', getopt('sample_rate'))\n\n    transport = getopt('transport') or options.get('transport')\n    if isinstance(transport, string_types):\n        transport = import_string(transport)\n    options['transport'] = transport\n\n    return options", "response": "Converts a settings object or dictionary to a new Client instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps a function or code block in try/except and automatically call ``.captureException`` if it raises an exception, then the exception is reraised. By default, it will capture ``Exception`` >>> @client.capture_exceptions >>> def foo(): >>> raise Exception() >>> with client.capture_exceptions(): >>> raise Exception() You can also specify exceptions to be caught specifically >>> @client.capture_exceptions((IOError, LookupError)) >>> def bar(): >>> ... ``kwargs`` are passed through to ``.captureException``.", "response": "def capture_exceptions(self, f=None, exceptions=None):  # TODO: Ash fix kwargs in base\n        \"\"\"\n        Wrap a function or code block in try/except and automatically call\n        ``.captureException`` if it raises an exception, then the exception\n        is reraised.\n\n        By default, it will capture ``Exception``\n\n        >>> @client.capture_exceptions\n        >>> def foo():\n        >>>     raise Exception()\n\n        >>> with client.capture_exceptions():\n        >>>    raise Exception()\n\n        You can also specify exceptions to be caught specifically\n\n        >>> @client.capture_exceptions((IOError, LookupError))\n        >>> def bar():\n        >>>     ...\n\n        ``kwargs`` are passed through to ``.captureException``.\n        \"\"\"\n        if not isinstance(f, FunctionType):\n            # when the decorator has args which is not a function we except\n            # f to be the exceptions tuple\n            return functools.partial(self.capture_exceptions, exceptions=f)\n\n        exceptions = exceptions or (Exception,)\n\n        @functools.wraps(f)\n        def wrapped(event, context, *args, **kwargs):\n            try:\n                return f(event, context, *args, **kwargs)\n            except exceptions:\n                self.captureException(event=event, context=context, **kwargs)\n                self.context.clear()\n                raise\n        return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a thing once and once only.", "response": "def once(func):\n    \"\"\"Runs a thing once and once only.\"\"\"\n    lock = threading.Lock()\n\n    def new_func(*args, **kwargs):\n        if new_func.called:\n            return\n        with lock:\n            if new_func.called:\n                return\n            rv = func(*args, **kwargs)\n            new_func.called = True\n            return rv\n\n    new_func = update_wrapper(new_func, func)\n    new_func.called = False\n    return new_func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_host(request):\n    # We try three options, in order of decreasing preference.\n    if settings.USE_X_FORWARDED_HOST and (\n            'HTTP_X_FORWARDED_HOST' in request.META):\n        host = request.META['HTTP_X_FORWARDED_HOST']\n    elif 'HTTP_HOST' in request.META:\n        host = request.META['HTTP_HOST']\n    else:\n        # Reconstruct the host using the algorithm from PEP 333.\n        host = request.META['SERVER_NAME']\n        server_port = str(request.META['SERVER_PORT'])\n        if server_port != (request.is_secure() and '443' or '80'):\n            host = '%s:%s' % (host, server_port)\n    return host", "response": "A reimplementation of Django s get_host method with the necessary parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when an exception has been raised in the code run by ZeroRPC.", "response": "def server_inspect_exception(self, req_event, rep_event, task_ctx, exc_info):\n        \"\"\"\n        Called when an exception has been raised in the code run by ZeroRPC\n        \"\"\"\n        # Hide the zerorpc internal frames for readability, for a REQ/REP or\n        # REQ/STREAM server the frames to hide are:\n        # - core.ServerBase._async_task\n        # - core.Pattern*.process_call\n        # - core.DecoratorBase.__call__\n        #\n        # For a PUSH/PULL or PUB/SUB server the frame to hide is:\n        # - core.Puller._receiver\n        if self._hide_zerorpc_frames:\n            traceback = exc_info[2]\n            while traceback:\n                zerorpc_frame = traceback.tb_frame\n                zerorpc_frame.f_locals['__traceback_hide__'] = True\n                frame_info = inspect.getframeinfo(zerorpc_frame)\n                # Is there a better way than this (or looking up the filenames\n                # or hardcoding the number of frames to skip) to know when we\n                # are out of zerorpc?\n                if frame_info.function == '__call__' \\\n                        or frame_info.function == '_receiver':\n                    break\n                traceback = traceback.tb_next\n\n        self._sentry_client.captureException(\n            exc_info,\n            extra=task_ctx\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninstall specified middleware in the specified list of middleware names.", "response": "def install_middleware(middleware_name, lookup_names=None):\n    \"\"\"\n    Install specified middleware\n    \"\"\"\n    if lookup_names is None:\n        lookup_names = (middleware_name,)\n    # default settings.MIDDLEWARE is None\n    middleware_attr = 'MIDDLEWARE' if getattr(settings,\n                                              'MIDDLEWARE',\n                                              None) is not None \\\n        else 'MIDDLEWARE_CLASSES'\n    # make sure to get an empty tuple when attr is None\n    middleware = getattr(settings, middleware_attr, ()) or ()\n    if set(lookup_names).isdisjoint(set(middleware)):\n        setattr(settings,\n                middleware_attr,\n                type(middleware)((middleware_name,)) + middleware)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntrains survival model on given data and return its score on test data", "response": "def _fit_and_score(est, x, y, scorer, train_index, test_index, parameters, fit_params, predict_params):\n    \"\"\"Train survival model on given data and return its score on test data\"\"\"\n    X_train, y_train = _safe_split(est, x, y, train_index)\n    train_params = fit_params.copy()\n\n    # Training\n    est.set_params(**parameters)\n    est.fit(X_train, y_train, **train_params)\n\n    # Testing\n    test_predict_params = predict_params.copy()\n    X_test, y_test = _safe_split(est, x, y, test_index, train_index)\n\n    score = scorer(est, X_test, y_test, **test_predict_params)\n    if not isinstance(score, numbers.Number):\n        raise ValueError(\"scoring must return a number, got %s (%s) instead.\"\n                         % (str(score), type(score)))\n\n    return score"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit(self, X, y):\n        X, event_num, time = self._pre_fit(X, y)\n        create_path, alphas, penalty = self._check_params(X.shape[1])\n\n        coef, alphas, deviance_ratio, n_iter = call_fit_coxnet(\n            X, time, event_num, penalty, alphas, create_path,\n            self.alpha_min_ratio, self.l1_ratio, int(self.max_iter),\n            self.tol, self.verbose)\n        assert numpy.isfinite(coef).all()\n\n        if numpy.all(numpy.absolute(coef) < numpy.finfo(numpy.float).eps):\n            warnings.warn('all coefficients are zero, consider decreasing alpha.',\n                          stacklevel=2)\n\n        if n_iter >= self.max_iter:\n            warnings.warn('Optimization terminated early, you might want'\n                          ' to increase the number of iterations (max_iter=%d).'\n                          % self.max_iter,\n                          category=ConvergenceWarning,\n                          stacklevel=2)\n\n        if self.fit_baseline_model:\n            self._baseline_models = tuple(\n                BreslowEstimator().fit(numpy.dot(X, coef[:, i]), event_num, time)\n                for i in range(coef.shape[1])\n            )\n        else:\n            self._baseline_models = None\n\n        self.alphas_ = alphas\n        self.penalty_factor_ = penalty\n        self.coef_ = coef\n        self.deviance_ratio_ = deviance_ratio\n        return self", "response": "Fit the Coxnet estimator to the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _interpolate_coefficients(self, alpha):\n        exact = False\n        coef_idx = None\n        for i, val in enumerate(self.alphas_):\n            if val > alpha:\n                coef_idx = i\n            elif alpha - val < numpy.finfo(numpy.float).eps:\n                coef_idx = i\n                exact = True\n                break\n\n        if coef_idx is None:\n            coef = self.coef_[:, 0]\n        elif exact or coef_idx == len(self.alphas_) - 1:\n            coef = self.coef_[:, coef_idx]\n        else:\n            # interpolate between coefficients\n            a1 = self.alphas_[coef_idx + 1]\n            a2 = self.alphas_[coef_idx]\n            frac = (alpha - a1) / (a2 - a1)\n            coef = frac * self.coef_[:, coef_idx] + (1.0 - frac) * self.coef_[:, coef_idx + 1]\n\n        return coef", "response": "Interpolate coefficients by calculating the weighted average of coefficient vectors corresponding to the neighbors of alpha in the list of alphas constructed during training."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npredict the cumulative hazard function for an individual with feature vectors X.", "response": "def predict_cumulative_hazard_function(self, X, alpha=None):\n        \"\"\"Predict cumulative hazard function.\n\n        Only available if :meth:`fit` has been called with `fit_baseline_model = True`.\n\n        The cumulative hazard function for an individual\n        with feature vector :math:`x_\\\\alpha` is defined as\n\n        .. math::\n\n            H(t \\\\mid x_\\\\alpha) = \\\\exp(x_\\\\alpha^\\\\top \\\\beta) H_0(t) ,\n\n        where :math:`H_0(t)` is the baseline hazard function,\n        estimated by Breslow's estimator.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data matrix.\n\n        alpha : float, optional\n            Constant that multiplies the penalty terms. The same alpha as used during training\n            must be specified. If set to ``None``, the last alpha in the solution path is used.\n\n        Returns\n        -------\n        cum_hazard : ndarray, shape = (n_samples,)\n            Predicted cumulative hazard functions.\n        \"\"\"\n        baseline_model = self._get_baseline_model(alpha)\n\n        return baseline_model.get_cumulative_hazard_function(self.predict(X, alpha=alpha))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npredicts the survival function for an individual with feature vectors x_alpha.", "response": "def predict_survival_function(self, X, alpha=None):\n        \"\"\"Predict survival function.\n\n        Only available if :meth:`fit` has been called with `fit_baseline_model = True`.\n\n        The survival function for an individual\n        with feature vector :math:`x_\\\\alpha` is defined as\n\n        .. math::\n\n            S(t \\\\mid x_\\\\alpha) = S_0(t)^{\\\\exp(x_\\\\alpha^\\\\top \\\\beta)} ,\n\n        where :math:`S_0(t)` is the baseline survival function,\n        estimated by Breslow's estimator.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data matrix.\n\n        alpha : float, optional\n            Constant that multiplies the penalty terms. The same alpha as used during training\n            must be specified. If set to ``None``, the last alpha in the solution path is used.\n\n        Returns\n        -------\n        survival : ndarray, shape = (n_samples,)\n            Predicted survival functions.\n        \"\"\"\n        baseline_model = self._get_baseline_model(alpha)\n\n        return baseline_model.get_survival_function(self.predict(X, alpha=alpha))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_base_ensemble(self, out, n_estimators, n_folds):\n        ensemble_scores = numpy.empty((n_estimators, n_folds))\n        base_ensemble = numpy.empty_like(ensemble_scores, dtype=numpy.object)\n        for model, fold, score, est in out:\n            ensemble_scores[model, fold] = score\n            base_ensemble[model, fold] = est\n\n        return ensemble_scores, base_ensemble", "response": "Create a base estimator for each model trained on each fold."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a numpy array of the average models trained on each fold", "response": "def _create_cv_ensemble(self, base_ensemble, idx_models_included, model_names=None):\n        \"\"\"For each selected base estimator, average models trained on each fold\"\"\"\n        fitted_models = numpy.empty(len(idx_models_included), dtype=numpy.object)\n        for i, idx in enumerate(idx_models_included):\n            model_name = self.base_estimators[idx][0] if model_names is None else model_names[idx]\n            avg_model = EnsembleAverage(base_ensemble[idx, :], name=model_name)\n            fitted_models[i] = avg_model\n\n        return fitted_models"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_base_estimators(self, X):\n        base_estimators = []\n\n        kernel_cache = {}\n        kernel_fns = {}\n        for i, (name, estimator) in enumerate(self.base_estimators):\n            if hasattr(estimator, 'kernel') and callable(estimator.kernel):\n                if not hasattr(estimator, '_get_kernel'):\n                    raise ValueError(\n                        'estimator %s uses a custom kernel function, but does not have a _get_kernel method' % name)\n\n                kernel_mat = kernel_fns.get(estimator.kernel, None)\n                if kernel_mat is None:\n                    kernel_mat = estimator._get_kernel(X)\n                    kernel_cache[i] = kernel_mat\n                    kernel_fns[estimator.kernel] = kernel_mat\n\n                kernel_cache[i] = kernel_mat\n\n                # We precompute kernel, but only for training, for testing use original custom kernel function\n                kernel_estimator = clone(estimator)\n                kernel_estimator.set_params(kernel='precomputed')\n                base_estimators.append((name, kernel_estimator))\n            else:\n                base_estimators.append((name, estimator))\n\n        return base_estimators, kernel_cache", "response": "Takes special care of estimators using custom kernel function\n            uses precomputed kernel matrix from X."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _restore_base_estimators(self, kernel_cache, out, X, cv):\n        train_folds = {fold: train_index for fold, (train_index, _) in enumerate(cv)}\n\n        for idx, fold, _, est in out:\n            if idx in kernel_cache:\n                if not hasattr(est, 'fit_X_'):\n                    raise ValueError(\n                        'estimator %s uses a custom kernel function, '\n                        'but does not have the attribute `fit_X_` after training' % self.base_estimators[idx][0])\n\n                est.set_params(kernel=self.base_estimators[idx][1].kernel)\n                est.fit_X_ = X[train_folds[fold]]\n\n        return out", "response": "Restore custom kernel functions of estimators for predictions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fit_and_score_ensemble(self, X, y, cv, **fit_params):\n        fit_params_steps = self._split_fit_params(fit_params)\n\n        folds = list(cv.split(X, y))\n\n        # Take care of custom kernel functions\n        base_estimators, kernel_cache = self._get_base_estimators(X)\n\n        out = Parallel(\n            n_jobs=self.n_jobs, verbose=self.verbose\n        )(\n            delayed(_fit_and_score_fold)(clone(estimator),\n                                         X if i not in kernel_cache else kernel_cache[i],\n                                         y,\n                                         self.scorer,\n                                         train_index, test_index,\n                                         fit_params_steps[name],\n                                         i, fold)\n            for i, (name, estimator) in enumerate(base_estimators)\n            for fold, (train_index, test_index) in enumerate(folds))\n\n        if len(kernel_cache) > 0:\n            out = self._restore_base_estimators(kernel_cache, out, X, folds)\n\n        return self._create_base_ensemble(out, len(base_estimators), len(folds))", "response": "Create a cross - validated model by training a model for each fold with the same model parameters"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting ensemble of models to data X y = None", "response": "def fit(self, X, y=None, **fit_params):\n        \"\"\"Fit ensemble of models\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Training data.\n\n        y : array-like, optional\n            Target data if base estimators are supervised.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        self._check_params()\n\n        cv = check_cv(self.cv, X)\n        self._fit(X, y, cv, **fit_params)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting data to an ARFF file.", "response": "def writearff(data, filename, relation_name=None, index=True):\n    \"\"\"Write ARFF file\n\n    Parameters\n    ----------\n    data : :class:`pandas.DataFrame`\n        DataFrame containing data\n\n    filename : string or file-like object\n        Path to ARFF file or file-like object. In the latter case,\n        the handle is closed by calling this function.\n\n    relation_name : string, optional, default: \"pandas\"\n        Name of relation in ARFF file.\n\n    index : boolean, optional, default: True\n        Write row names (index)\n    \"\"\"\n    if isinstance(filename, str):\n        fp = open(filename, 'w')\n\n        if relation_name is None:\n            relation_name = os.path.basename(filename)\n    else:\n        fp = filename\n\n        if relation_name is None:\n            relation_name = \"pandas\"\n\n    try:\n        data = _write_header(data, fp, relation_name, index)\n        fp.write(\"\\n\")\n        _write_data(data, fp)\n    finally:\n        fp.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the header of the data.", "response": "def _write_header(data, fp, relation_name, index):\n    \"\"\"Write header containing attribute names and types\"\"\"\n    fp.write(\"@relation {0}\\n\\n\".format(relation_name))\n\n    if index:\n        data = data.reset_index()\n\n    attribute_names = _sanitize_column_names(data)\n\n    for column, series in data.iteritems():\n        name = attribute_names[column]\n        fp.write(\"@attribute {0}\\t\".format(name))\n\n        if is_categorical_dtype(series) or is_object_dtype(series):\n            _write_attribute_categorical(series, fp)\n        elif numpy.issubdtype(series.dtype, numpy.floating):\n            fp.write(\"real\")\n        elif numpy.issubdtype(series.dtype, numpy.integer):\n            fp.write(\"integer\")\n        elif numpy.issubdtype(series.dtype, numpy.datetime64):\n            fp.write(\"date 'yyyy-MM-dd HH:mm:ss'\")\n        else:\n            raise TypeError('unsupported type %s' % series.dtype)\n\n        fp.write(\"\\n\")\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sanitize_column_names(data):\n    new_names = {}\n    for name in data.columns:\n        new_names[name] = _ILLEGAL_CHARACTER_PAT.sub(\"_\", name)\n    return new_names", "response": "Replace illegal characters with underscore"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_str_value(x):\n    if isinstance(x, str):\n        # remove commas, and single quotation marks since loadarff cannot deal with it\n        x = x.replace(\",\", \".\").replace(chr(0x2018), \"'\").replace(chr(0x2019), \"'\")\n\n        # put string in double quotes\n        if \" \" in x:\n            if x[0] in ('\"', \"'\"):\n                x = x[1:]\n            if x[-1] in ('\"', \"'\"):\n                x = x[:len(x) - 1]\n            x = '\"' + x.replace('\"', \"\\\\\\\"\") + '\"'\n    return str(x)", "response": "Check if string is a space and wrap it in double quotes and remove illegal characters"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _write_attribute_categorical(series, fp):\n    if is_categorical_dtype(series.dtype):\n        categories = series.cat.categories\n        string_values = _check_str_array(categories)\n    else:\n        categories = series.dropna().unique()\n        string_values = sorted(_check_str_array(categories), key=lambda x: x.strip('\"'))\n\n    values = \",\".join(string_values)\n    fp.write(\"{\")\n    fp.write(values)\n    fp.write(\"}\")", "response": "Write categorical attributes of a categorical attribute"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the data section", "response": "def _write_data(data, fp):\n    \"\"\"Write the data section\"\"\"\n    fp.write(\"@data\\n\")\n\n    def to_str(x):\n        if pandas.isnull(x):\n            return '?'\n        else:\n            return str(x)\n\n    data = data.applymap(to_str)\n    n_rows = data.shape[0]\n    for i in range(n_rows):\n        str_values = list(data.iloc[i, :].apply(_check_str_array))\n        line = \",\".join(str_values)\n        fp.write(line)\n        fp.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfits base estimators and predict base estimators.", "response": "def fit(self, X, y=None, **fit_params):\n        \"\"\"Fit base estimators.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Training data.\n\n        y : array-like, optional\n            Target data if base estimators are supervised.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        X = numpy.asarray(X)\n        self._fit_estimators(X, y, **fit_params)\n        Xt = self._predict_estimators(X)\n        self.meta_estimator.fit(Xt, y)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms prediction. Only available of the meta estimator has a predict method. Parameters ---------- X : array-like, shape = (n_samples, n_features) Data with samples to predict. Returns ------- prediction : array, shape = (n_samples, n_dim) Prediction of meta estimator that combines predictions of base estimators. `n_dim` depends on the return value of meta estimator's `predict` method.", "response": "def predict(self, X):\n        \"\"\"Perform prediction.\n\n        Only available of the meta estimator has a predict method.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data with samples to predict.\n\n        Returns\n        -------\n        prediction : array, shape = (n_samples, n_dim)\n            Prediction of meta estimator that combines\n            predictions of base estimators. `n_dim` depends\n            on the return value of meta estimator's `predict`\n            method.\n        \"\"\"\n        X = numpy.asarray(X)\n        Xt = self._predict_estimators(X)\n        return self.meta_estimator.predict(Xt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming prediction. Only available of the meta estimator has a predict_proba method. Parameters ---------- X : array-like, shape = (n_samples, n_features) Data with samples to predict. Returns ------- prediction : ndarray, shape = (n_samples, n_dim) Prediction of meta estimator that combines predictions of base estimators. `n_dim` depends on the return value of meta estimator's `predict` method.", "response": "def predict_proba(self, X):\n        \"\"\"Perform prediction.\n\n        Only available of the meta estimator has a predict_proba method.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data with samples to predict.\n\n        Returns\n        -------\n        prediction : ndarray, shape = (n_samples, n_dim)\n            Prediction of meta estimator that combines\n            predictions of base estimators. `n_dim` depends\n            on the return value of meta estimator's `predict`\n            method.\n        \"\"\"\n        X = numpy.asarray(X)\n        Xt = self._predict_estimators(X)\n        return self.meta_estimator.predict_proba(Xt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms prediction. Only available of the meta estimator has a predict_log_proba method. Parameters ---------- X : array-like, shape = (n_samples, n_features) Data with samples to predict. Returns ------- prediction : ndarray, shape = (n_samples, n_dim) Prediction of meta estimator that combines predictions of base estimators. `n_dim` depends on the return value of meta estimator's `predict` method.", "response": "def predict_log_proba(self, X):\n        \"\"\"Perform prediction.\n\n        Only available of the meta estimator has a predict_log_proba method.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data with samples to predict.\n\n        Returns\n        -------\n        prediction : ndarray, shape = (n_samples, n_dim)\n            Prediction of meta estimator that combines\n            predictions of base estimators. `n_dim` depends\n            on the return value of meta estimator's `predict`\n            method.\n        \"\"\"\n        X = numpy.asarray(X)\n        Xt = self._predict_estimators(X)\n        return self.meta_estimator.predict_log_proba(Xt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef standardize(table, with_std=True):\n    if isinstance(table, pandas.DataFrame):\n        cat_columns = table.select_dtypes(include=['category']).columns\n    else:\n        cat_columns = []\n\n    new_frame = _apply_along_column(table, standardize_column, with_std=with_std)\n\n    # work around for apply converting category dtype to object\n    # https://github.com/pydata/pandas/issues/9573\n    for col in cat_columns:\n        new_frame[col] = table[col].copy()\n\n    return new_frame", "response": "Perform Z - Normalization on each numeric column of the given table."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes categorical columns into one - hot scheme.", "response": "def encode_categorical(table, columns=None, **kwargs):\n    \"\"\"\n    Encode categorical columns with `M` categories into `M-1` columns according\n    to the one-hot scheme.\n\n    Parameters\n    ----------\n    table : pandas.DataFrame\n        Table with categorical columns to encode.\n\n    columns : list-like, optional, default: None\n        Column names in the DataFrame to be encoded.\n        If `columns` is None then all the columns with\n        `object` or `category` dtype will be converted.\n\n    allow_drop : boolean, optional, default: True\n        Whether to allow dropping categorical columns that only consist\n        of a single category.\n\n    Returns\n    -------\n    encoded : pandas.DataFrame\n        Table with categorical columns encoded as numeric.\n        Numeric columns in the input table remain unchanged.\n    \"\"\"\n    if isinstance(table, pandas.Series):\n        if not is_categorical_dtype(table.dtype) and not table.dtype.char == \"O\":\n            raise TypeError(\"series must be of categorical dtype, but was {}\".format(table.dtype))\n        return _encode_categorical_series(table, **kwargs)\n\n    def _is_categorical_or_object(series):\n        return is_categorical_dtype(series.dtype) or series.dtype.char == \"O\"\n\n    if columns is None:\n        # for columns containing categories\n        columns_to_encode = {nam for nam, s in table.iteritems() if _is_categorical_or_object(s)}\n    else:\n        columns_to_encode = set(columns)\n\n    items = []\n    for name, series in table.iteritems():\n        if name in columns_to_encode:\n            series = _encode_categorical_series(series, **kwargs)\n            if series is None:\n                continue\n        items.append(series)\n\n    # concat columns of tables\n    new_table = pandas.concat(items, axis=1, copy=False)\n    return new_table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef categorical_to_numeric(table):\n    def transform(column):\n        if is_categorical_dtype(column.dtype):\n            return column.cat.codes\n        if column.dtype.char == \"O\":\n            try:\n                nc = column.astype(numpy.int64)\n            except ValueError:\n                classes = column.dropna().unique()\n                classes.sort(kind=\"mergesort\")\n                nc = column.replace(classes, numpy.arange(classes.shape[0]))\n            return nc\n        elif column.dtype == bool:\n            return column.astype(numpy.int64)\n\n        return column\n\n    if isinstance(table, pandas.Series):\n        return pandas.Series(transform(table), name=table.name, index=table.index)\n    else:\n        if _pandas_version_under0p23:\n            return table.apply(transform, axis=0, reduce=False)\n        else:\n            return table.apply(transform, axis=0, result_type='reduce')", "response": "Encode categorical columns to numeric by converting each category to\nAttributeNames an integer value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a survival support vector machine model from training data.", "response": "def fit(self, X, y, sample_weight=None):\n        \"\"\"Build a survival support vector machine model from training data.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data matrix.\n\n        y : structured array, shape = (n_samples,)\n            A structured array containing the binary event indicator\n            as first field, and time of event or time of censoring as\n            second field.\n\n        sample_weight : array-like, shape = (n_samples,), optional\n            Array of weights that are assigned to individual\n            samples. If not provided,\n            then each sample is given unit weight.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        random_state = check_random_state(self.random_state)\n\n        x_pairs, y_pairs = self._get_survival_pairs(X, y, random_state)\n\n        self.C = self.alpha\n        return super().fit(x_pairs, y_pairs, sample_weight=sample_weight)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_y_survival(y_or_event, *args, allow_all_censored=False):\n    if len(args) == 0:\n        y = y_or_event\n\n        if not isinstance(y, numpy.ndarray) or y.dtype.fields is None or len(y.dtype.fields) != 2:\n            raise ValueError('y must be a structured array with the first field'\n                             ' being a binary class event indicator and the second field'\n                             ' the time of the event/censoring')\n\n        event_field, time_field = y.dtype.names\n        y_event = y[event_field]\n        time_args = (y[time_field],)\n    else:\n        y_event = numpy.asanyarray(y_or_event)\n        time_args = args\n\n    event = check_array(y_event, ensure_2d=False)\n    if not numpy.issubdtype(event.dtype, numpy.bool_):\n        raise ValueError('elements of event indicator must be boolean, but found {0}'.format(event.dtype))\n\n    if not (allow_all_censored or numpy.any(event)):\n        raise ValueError('all samples are censored')\n\n    return_val = [event]\n    for i, yt in enumerate(time_args):\n        if yt is None:\n            return_val.append(yt)\n            continue\n\n        yt = check_array(yt, ensure_2d=False)\n        if not numpy.issubdtype(yt.dtype, numpy.number):\n            raise ValueError('time must be numeric, but found {} for argument {}'.format(yt.dtype, i + 2))\n\n        return_val.append(yt)\n\n    return tuple(return_val)", "response": "Checks that the array correctly represents an outcome for survival analysis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_arrays_survival(X, y, **kwargs):\n    event, time = check_y_survival(y)\n    kwargs.setdefault(\"dtype\", numpy.float64)\n    X = check_array(X, ensure_min_samples=2, **kwargs)\n    check_consistent_length(X, event, time)\n    return X, event, time", "response": "Checks that all arrays have consistent first dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef safe_concat(objs, *args, **kwargs):\n    axis = kwargs.pop(\"axis\", 0)\n    categories = {}\n    for df in objs:\n        if isinstance(df, pandas.Series):\n            if is_categorical_dtype(df.dtype):\n                categories[df.name] = {\"categories\": df.cat.categories, \"ordered\": df.cat.ordered}\n        else:\n            dfc = df.select_dtypes(include=[\"category\"])\n            for name, s in dfc.iteritems():\n                if name in categories:\n                    if axis == 1:\n                        raise ValueError(\"duplicate columns %s\" % name)\n                    if not categories[name][\"categories\"].equals(s.cat.categories):\n                        raise ValueError(\"categories for column %s do not match\" % name)\n                else:\n                    categories[name] = {\"categories\": s.cat.categories, \"ordered\": s.cat.ordered}\n                df[name] = df[name].astype(object)\n\n    concatenated = pandas.concat(objs, *args, axis=axis, **kwargs)\n\n    for name, params in categories.items():\n        concatenated[name] = pandas.Categorical(concatenated[name], **params)\n\n    return concatenated", "response": "Alternative to pandas. concat that preserves categorical variables."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_arrays(event, time, name_event=None, name_time=None):\n        name_event = name_event or 'event'\n        name_time = name_time or 'time'\n        if name_time == name_event:\n            raise ValueError('name_time must be different from name_event')\n\n        time = numpy.asanyarray(time, dtype=numpy.float_)\n        y = numpy.empty(time.shape[0],\n                        dtype=[(name_event, numpy.bool_), (name_time, numpy.float_)])\n        y[name_time] = time\n\n        event = numpy.asanyarray(event)\n        check_consistent_length(time, event)\n\n        if numpy.issubdtype(event.dtype, numpy.bool_):\n            y[name_event] = event\n        else:\n            events = numpy.unique(event)\n            events.sort()\n            if len(events) != 2:\n                raise ValueError('event indicator must be binary')\n\n            if numpy.all(events == numpy.array([0, 1], dtype=events.dtype)):\n                y[name_event] = event.astype(numpy.bool_)\n            else:\n                raise ValueError('non-boolean event indicator must contain 0 and 1 only')\n\n        return y", "response": "Create structured array of the related object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_dataframe(event, time, data):\n        if not isinstance(data, pandas.DataFrame):\n            raise TypeError(\n                \"exepected pandas.DataFrame, but got {!r}\".format(type(data)))\n\n        return Surv.from_arrays(\n            data.loc[:, event].values,\n            data.loc[:, time].values,\n            name_event=str(event),\n            name_time=str(time))", "response": "Create structured array from pandas. DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef negative_gradient(self, y, y_pred, sample_weight=None, **kwargs):\n        ret = coxph_negative_gradient(y['event'].astype(numpy.uint8), y['time'], y_pred.ravel())\n        if sample_weight is not None:\n            ret *= sample_weight\n        return ret", "response": "Negative gradient of partial likelihood\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_terminal_regions(self, tree, X, y, residual, y_pred,\n                                sample_weight, sample_mask,\n                                learning_rate=1.0, k=0):\n        \"\"\"Least squares does not need to update terminal regions.\n\n        But it has to update the predictions.\n        \"\"\"\n        # update predictions\n        y_pred[:, k] += learning_rate * tree.predict(X).ravel()", "response": "Least squares does not need to update the terminal regions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the terminal region for the given leaf.", "response": "def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n                                residual, pred, sample_weight):\n        \"\"\"Least squares does not need to update terminal regions\"\"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef negative_gradient(self, y, y_pred, sample_weight=None, **kwargs):\n        pred_time = y['time'] - y_pred.ravel()\n        mask = (pred_time > 0) | y['event']\n        ret = numpy.zeros(y['event'].shape[0])\n        ret[mask] = pred_time.compress(mask, axis=0)\n        if sample_weight is not None:\n            ret *= sample_weight\n        return ret", "response": "Negative gradient of partial likelihood\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmodifies the extensions to build from the. c and. cpp files.", "response": "def build_from_c_and_cpp_files(extensions):\n    \"\"\"Modify the extensions to build from the .c and .cpp files.\n    This is useful for releases, this way cython is not required to\n    run python setup.py install.\n    \"\"\"\n    for extension in extensions:\n        sources = []\n        for sfile in extension.sources:\n            path, ext = os.path.splitext(sfile)\n            if ext in ('.pyx', '.py'):\n                if extension.language == 'c++':\n                    ext = '.cpp'\n                else:\n                    ext = '.c'\n                sfile = path + ext\n            sources.append(sfile)\n        extension.sources = sources"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef maybe_cythonize_extensions(top_path, config):\n    is_release = os.path.exists(os.path.join(top_path, 'PKG-INFO'))\n\n    if is_release:\n        build_from_c_and_cpp_files(config.ext_modules)\n    else:\n        message = ('Please install cython with a version >= {0} in order '\n                   'to build a scikit-survival development version.').format(\n                       CYTHON_MIN_VERSION)\n        try:\n            import Cython\n            if LooseVersion(Cython.__version__) < CYTHON_MIN_VERSION:\n                message += ' Your version of Cython was {0}.'.format(\n                    Cython.__version__)\n                raise ValueError(message)\n            from Cython.Build import cythonize\n        except ImportError as exc:\n            exc.args += (message,)\n            raise\n\n        # http://docs.cython.org/en/latest/src/userguide/source_files_and_compilation.html#cythonize-arguments\n        directives = {'language_level': '3'}\n        cy_cov = os.environ.get('CYTHON_COVERAGE', False)\n        if cy_cov:\n            directives['linetrace'] = True\n            macros = [('CYTHON_TRACE', '1'), ('CYTHON_TRACE_NOGIL', '1')]\n        else:\n            macros = []\n\n        config.ext_modules = cythonize(\n            config.ext_modules,\n            compiler_directives=directives)\n\n        for e in config.ext_modules:\n            e.define_macros.extend(macros)", "response": "Tweaks for building extensions between release and development mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _count_values(self):\n        indices = {yi: [i] for i, yi in enumerate(self.y) if self.status[i]}\n\n        return indices", "response": "Return dict mapping relevance level to sample index"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits into intercept bias and feature - specific coefficients", "response": "def _split_coefficents(self, w):\n        \"\"\"Split into intercept/bias and feature-specific coefficients\"\"\"\n        if self._fit_intercept:\n            bias = w[0]\n            wf = w[1:]\n        else:\n            bias = 0.0\n            wf = w\n        return bias, wf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_optimizer(self, X, y, status):\n        if self.optimizer is None:\n            self.optimizer = 'avltree'\n\n        times, ranks = y\n\n        if self.optimizer == 'simple':\n            optimizer = SimpleOptimizer(X, status, self.alpha, self.rank_ratio, timeit=self.timeit)\n        elif self.optimizer == 'PRSVM':\n            optimizer = PRSVMOptimizer(X, status, self.alpha, self.rank_ratio, timeit=self.timeit)\n        elif self.optimizer == 'direct-count':\n            optimizer = LargeScaleOptimizer(self.alpha, self.rank_ratio, self.fit_intercept,\n                                            SurvivalCounter(X, ranks, status, len(ranks), times), timeit=self.timeit)\n        elif self.optimizer == 'rbtree':\n            optimizer = LargeScaleOptimizer(self.alpha, self.rank_ratio, self.fit_intercept,\n                                            OrderStatisticTreeSurvivalCounter(X, ranks, status, RBTree, times),\n                                            timeit=self.timeit)\n        elif self.optimizer == 'avltree':\n            optimizer = LargeScaleOptimizer(self.alpha, self.rank_ratio, self.fit_intercept,\n                                            OrderStatisticTreeSurvivalCounter(X, ranks, status, AVLTree, times),\n                                            timeit=self.timeit)\n        else:\n            raise ValueError('unknown optimizer: {0}'.format(self.optimizer))\n\n        return optimizer", "response": "Create an optimizer for the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit(self, X, y):\n        X, event, time = check_arrays_survival(X, y)\n\n        if self.alpha <= 0:\n            raise ValueError(\"alpha must be positive\")\n\n        if not 0 <= self.rank_ratio <= 1:\n            raise ValueError(\"rank_ratio must be in [0; 1]\")\n\n        if self.fit_intercept and self.rank_ratio == 1.0:\n            raise ValueError(\"fit_intercept=True is only meaningful if rank_ratio < 1.0\")\n\n        if self.rank_ratio < 1.0:\n            if self.optimizer in {'simple', 'PRSVM'}:\n                raise ValueError(\"optimizer '%s' does not implement regression objective\" % self.optimizer)\n\n            if (time <= 0).any():\n                raise ValueError(\"observed time contains values smaller or equal to zero\")\n\n            # log-transform time\n            time = numpy.log(time)\n            assert numpy.isfinite(time).all()\n\n        random_state = check_random_state(self.random_state)\n        samples_order = BaseSurvivalSVM._argsort_and_resolve_ties(time, random_state)\n\n        opt_result = self._fit(X, time, event, samples_order)\n        coef = opt_result.x\n        if self.fit_intercept:\n            self.coef_ = coef[1:]\n            self.intercept_ = coef[0]\n        else:\n            self.coef_ = coef\n\n        if not opt_result.success:\n            warnings.warn(('Optimization did not converge: ' + opt_result.message),\n                          category=ConvergenceWarning,\n                          stacklevel=2)\n        self.optimizer_result_ = opt_result\n\n        return self", "response": "Fit a survival support vector machine model from training data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlikes numpy. argsort but resolves ties uniformly at random", "response": "def _argsort_and_resolve_ties(time, random_state):\n        \"\"\"Like numpy.argsort, but resolves ties uniformly at random\"\"\"\n        n_samples = len(time)\n        order = numpy.argsort(time, kind=\"mergesort\")\n\n        i = 0\n        while i < n_samples - 1:\n            inext = i + 1\n            while inext < n_samples and time[order[i]] == time[order[inext]]:\n                inext += 1\n\n            if i + 1 != inext:\n                # resolve ties randomly\n                random_state.shuffle(order[i:inext])\n            i = inext\n        return order"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef predict(self, X):\n        val = numpy.dot(X, self.coef_)\n        if hasattr(self, \"intercept_\"):\n            val += self.intercept_\n\n        # Order by increasing survival time if objective is pure ranking\n        if self.rank_ratio == 1:\n            val *= -1\n        else:\n            # model was fitted on log(time), transform to original scale\n            val = numpy.exp(val)\n\n        return val", "response": "Predict the rank of the given samples according to survival times."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npredict the rank of the given samples according to survival times.", "response": "def predict(self, X):\n        \"\"\"Rank samples according to survival times\n\n        Lower ranks indicate shorter survival, higher ranks longer survival.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        y : ndarray, shape = (n_samples,)\n            Predicted ranks.\n        \"\"\"\n        kernel_mat = self._get_kernel(X, self.fit_X_)\n\n        val = numpy.dot(kernel_mat, self.coef_)\n        if hasattr(self, \"intercept_\"):\n            val += self.intercept_\n\n        # Order by increasing survival time if objective is pure ranking\n        if self.rank_ratio == 1:\n            val *= -1\n        else:\n            # model was fitted on log(time), transform to original scale\n            val = numpy.exp(val)\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild an accelerated failure time model.", "response": "def fit(self, X, y):\n        \"\"\"Build an accelerated failure time model.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data matrix.\n\n        y : structured array, shape = (n_samples,)\n            A structured array containing the binary event indicator\n            as first field, and time of event or time of censoring as\n            second field.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        X, event, time = check_arrays_survival(X, y)\n\n        weights = ipc_weights(event, time)\n        super().fit(X, numpy.log(time), sample_weight=weights)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes baseline cumulative hazard function.", "response": "def fit(self, linear_predictor, event, time):\n        \"\"\"Compute baseline cumulative hazard function.\n\n        Parameters\n        ----------\n        linear_predictor : array-like, shape = (n_samples,)\n            Linear predictor of risk: `X @ coef`.\n\n        event : array-like, shape = (n_samples,)\n            Contains binary event indicators.\n\n        time : array-like, shape = (n_samples,)\n            Contains event/censoring times.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        risk_score = numpy.exp(linear_predictor)\n        order = numpy.argsort(time, kind=\"mergesort\")\n        risk_score = risk_score[order]\n        uniq_times, n_events, n_at_risk = _compute_counts(event, time, order)\n\n        divisor = numpy.empty(n_at_risk.shape, dtype=numpy.float_)\n        value = numpy.sum(risk_score)\n        divisor[0] = value\n        k = 0\n        for i in range(1, len(n_at_risk)):\n            d = n_at_risk[i - 1] - n_at_risk[i]\n            value -= risk_score[k:(k + d)].sum()\n            k += d\n            divisor[i] = value\n\n        assert k == n_at_risk[0] - n_at_risk[-1]\n\n        y = numpy.cumsum(n_events / divisor)\n        self.cum_baseline_hazard_ = StepFunction(uniq_times, y)\n        self.baseline_survival_ = StepFunction(self.cum_baseline_hazard_.x,\n                                               numpy.exp(- self.cum_baseline_hazard_.y))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_cumulative_hazard_function(self, linear_predictor):\n        risk_score = numpy.exp(linear_predictor)\n        n_samples = risk_score.shape[0]\n        funcs = numpy.empty(n_samples, dtype=numpy.object_)\n        for i in range(n_samples):\n            funcs[i] = StepFunction(x=self.cum_baseline_hazard_.x,\n                                    y=self.cum_baseline_hazard_.y,\n                                    a=risk_score[i])\n        return funcs", "response": "Predict cumulative hazard function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npredict survival function. Parameters ---------- linear_predictor : array-like, shape = (n_samples,) Linear predictor of risk: `X @ coef`. Returns ------- survival : ndarray, shape = (n_samples,) Predicted survival functions.", "response": "def get_survival_function(self, linear_predictor):\n        \"\"\"Predict survival function.\n\n        Parameters\n        ----------\n        linear_predictor : array-like, shape = (n_samples,)\n            Linear predictor of risk: `X @ coef`.\n\n        Returns\n        -------\n        survival : ndarray, shape = (n_samples,)\n            Predicted survival functions.\n        \"\"\"\n        risk_score = numpy.exp(linear_predictor)\n        n_samples = risk_score.shape[0]\n        funcs = numpy.empty(n_samples, dtype=numpy.object_)\n        for i in range(n_samples):\n            funcs[i] = StepFunction(x=self.baseline_survival_.x,\n                                    y=numpy.power(self.baseline_survival_.y, risk_score[i]))\n        return funcs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nlog_likelihood(self, w):\n        time = self.time\n        n_samples = self.x.shape[0]\n        xw = numpy.dot(self.x, w)\n\n        loss = 0\n        risk_set = 0\n        k = 0\n        for i in range(n_samples):\n            ti = time[i]\n            while k < n_samples and ti == time[k]:\n                risk_set += numpy.exp(xw[k])\n                k += 1\n\n            if self.event[i]:\n                loss -= (xw[i] - numpy.log(risk_set)) / n_samples\n\n        # add regularization term to log-likelihood\n        return loss + self.alpha * squared_norm(w) / (2. * n_samples)", "response": "Compute negative partial log - likelihood of a set of features."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute gradient and Hessian matrix with respect to w.", "response": "def update(self, w, offset=0):\n        \"\"\"Compute gradient and Hessian matrix with respect to `w`.\"\"\"\n        time = self.time\n        x = self.x\n        exp_xw = numpy.exp(offset + numpy.dot(x, w))\n        n_samples, n_features = x.shape\n\n        gradient = numpy.zeros((1, n_features), dtype=float)\n        hessian = numpy.zeros((n_features, n_features), dtype=float)\n\n        inv_n_samples = 1. / n_samples\n        risk_set = 0\n        risk_set_x = 0\n        risk_set_xx = 0\n        k = 0\n        # iterate time in descending order\n        for i in range(n_samples):\n            ti = time[i]\n            while k < n_samples and ti == time[k]:\n                risk_set += exp_xw[k]\n\n                # preserve 2D shape of row vector\n                xk = x[k:k + 1]\n                risk_set_x += exp_xw[k] * xk\n\n                # outer product\n                xx = numpy.dot(xk.T, xk)\n                risk_set_xx += exp_xw[k] * xx\n\n                k += 1\n\n            if self.event[i]:\n                gradient -= (x[i:i + 1] - risk_set_x / risk_set) * inv_n_samples\n\n                a = risk_set_xx / risk_set\n                z = risk_set_x / risk_set\n                # outer product\n                b = numpy.dot(z.T, z)\n\n                hessian += (a - b) * inv_n_samples\n\n        if self.alpha > 0:\n            gradient += self.alpha * inv_n_samples * w\n\n            diag_idx = numpy.diag_indices(n_features)\n            hessian[diag_idx] += self.alpha * inv_n_samples\n\n        self.gradient = gradient.ravel()\n        self.hessian = hessian"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit(self, X, y):\n        X, event, time = check_arrays_survival(X, y)\n\n        if self.alpha < 0:\n            raise ValueError(\"alpha must be positive, but was %r\" % self.alpha)\n\n        optimizer = CoxPHOptimizer(X, event, time, self.alpha)\n\n        verbose_reporter = VerboseReporter(self.verbose)\n        w = numpy.zeros(X.shape[1])\n        w_prev = w\n        i = 0\n        loss = float('inf')\n        while True:\n            if i >= self.n_iter:\n                verbose_reporter.end_max_iter(i)\n                warnings.warn(('Optimization did not converge: Maximum number of iterations has been exceeded.'),\n                              stacklevel=2, category=ConvergenceWarning)\n                break\n\n            optimizer.update(w)\n            delta = solve(optimizer.hessian, optimizer.gradient,\n                          overwrite_a=False, overwrite_b=False, check_finite=False)\n\n            if not numpy.all(numpy.isfinite(delta)):\n                raise ValueError(\"search direction contains NaN or infinite values\")\n\n            w_new = w - delta\n            loss_new = optimizer.nlog_likelihood(w_new)\n            verbose_reporter.update(i, delta, loss_new)\n            if loss_new > loss:\n                # perform step-halving if negative log-likelihood does not decrease\n                w = (w_prev + w) / 2\n                loss = optimizer.nlog_likelihood(w)\n                verbose_reporter.step_halving(i, loss)\n                i += 1\n                continue\n\n            w_prev = w\n            w = w_new\n\n            res = numpy.abs(1 - (loss_new / loss))\n            if res < self.tol:\n                verbose_reporter.end_converged(i)\n                break\n\n            loss = loss_new\n            i += 1\n\n        self.coef_ = w\n        self._baseline_model.fit(numpy.dot(X, self.coef_), event, time)\n        return self", "response": "Minimize negative partial log - likelihood for provided data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict(self, X):\n        check_is_fitted(self, \"coef_\")\n\n        X = numpy.atleast_2d(X)\n\n        return numpy.dot(X, self.coef_)", "response": "Predicts the risk score of a set of entries in the logarithmic model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the counts of right censored and uncensored samples at each unique time point.", "response": "def _compute_counts(event, time, order=None):\n    \"\"\"Count right censored and uncensored samples at each unique time point.\n\n    Parameters\n    ----------\n    event : array\n        Boolean event indicator.\n\n    time : array\n        Survival time or time of censoring.\n\n    order : array or None\n        Indices to order time in ascending order.\n        If None, order will be computed.\n\n    Returns\n    -------\n    times : array\n        Unique time points.\n\n    n_events : array\n        Number of events at each time point.\n\n    n_at_risk : array\n        Number of samples that are censored or have an event at each time point.\n    \"\"\"\n    n_samples = event.shape[0]\n\n    if order is None:\n        order = numpy.argsort(time, kind=\"mergesort\")\n\n    uniq_times = numpy.empty(n_samples, dtype=time.dtype)\n    uniq_events = numpy.empty(n_samples, dtype=numpy.int_)\n    uniq_counts = numpy.empty(n_samples, dtype=numpy.int_)\n\n    i = 0\n    prev_val = time[order[0]]\n    j = 0\n    while True:\n        count_event = 0\n        count = 0\n        while i < n_samples and prev_val == time[order[i]]:\n            if event[order[i]]:\n                count_event += 1\n\n            count += 1\n            i += 1\n\n        uniq_times[j] = prev_val\n        uniq_events[j] = count_event\n        uniq_counts[j] = count\n        j += 1\n\n        if i == n_samples:\n            break\n\n        prev_val = time[order[i]]\n\n    times = numpy.resize(uniq_times, j)\n    n_events = numpy.resize(uniq_events, j)\n    total_count = numpy.resize(uniq_counts, j)\n\n    # offset cumulative sum by one\n    total_count = numpy.concatenate(([0], total_count))\n    n_at_risk = n_samples - numpy.cumsum(total_count)\n\n    return times, n_events, n_at_risk[:-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes counts for left truncated and right censored survival data.", "response": "def _compute_counts_truncated(event, time_enter, time_exit):\n    \"\"\"Compute counts for left truncated and right censored survival data.\n\n    Parameters\n    ----------\n    event : array\n        Boolean event indicator.\n\n    time_start : array\n        Time when a subject entered the study.\n\n    time_exit : array\n        Time when a subject left the study due to an\n        event or censoring.\n\n    Returns\n    -------\n    times : array\n        Unique time points.\n\n    n_events : array\n        Number of events at each time point.\n\n    n_at_risk : array\n        Number of samples that are censored or have an event at each time point.\n    \"\"\"\n    if (time_enter > time_exit).any():\n        raise ValueError(\"exit time must be larger start time for all samples\")\n\n    n_samples = event.shape[0]\n\n    uniq_times = numpy.sort(numpy.unique(numpy.concatenate((time_enter, time_exit))), kind=\"mergesort\")\n    total_counts = numpy.empty(len(uniq_times), dtype=numpy.int_)\n    event_counts = numpy.empty(len(uniq_times), dtype=numpy.int_)\n\n    order_enter = numpy.argsort(time_enter, kind=\"mergesort\")\n    order_exit = numpy.argsort(time_exit, kind=\"mergesort\")\n    s_time_enter = time_enter[order_enter]\n    s_time_exit = time_exit[order_exit]\n\n    t0 = uniq_times[0]\n    # everything larger is included\n    idx_enter = numpy.searchsorted(s_time_enter, t0, side=\"right\")\n    # everything smaller is excluded\n    idx_exit = numpy.searchsorted(s_time_exit, t0, side=\"left\")\n\n    total_counts[0] = idx_enter\n    # except people die on the day they enter\n    event_counts[0] = 0\n\n    for i in range(1, len(uniq_times)):\n        ti = uniq_times[i]\n\n        while idx_enter < n_samples and s_time_enter[idx_enter] <= ti:\n            idx_enter += 1\n\n        while idx_exit < n_samples and s_time_exit[idx_exit] < ti:\n            idx_exit += 1\n\n        risk_set = numpy.setdiff1d(order_enter[:idx_enter], order_exit[:idx_exit], assume_unique=True)\n        total_counts[i] = len(risk_set)\n\n        count_event = 0\n        k = idx_exit\n        while k < n_samples and s_time_exit[k] == ti:\n            if event[order_exit[k]]:\n                count_event += 1\n            k += 1\n        event_counts[i] = count_event\n\n    return uniq_times, event_counts, total_counts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ipc_weights(event, time):\n    if event.all():\n        return numpy.ones(time.shape[0])\n\n    unique_time, p = kaplan_meier_estimator(~event, time)\n\n    idx = numpy.searchsorted(unique_time, time[event])\n    Ghat = p[idx]\n\n    assert (Ghat > 0).all()\n\n    weights = numpy.zeros(time.shape[0])\n    weights[event] = 1.0 / Ghat\n\n    return weights", "response": "Compute inverse probability of censoring weights for a single object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit(self, y):\n        event, time = check_y_survival(y, allow_all_censored=True)\n\n        unique_time, prob = kaplan_meier_estimator(event, time)\n        self.unique_time_ = numpy.concatenate(([-numpy.infty], unique_time))\n        self.prob_ = numpy.concatenate(([1.], prob))\n\n        return self", "response": "Estimate survival distribution from training data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning probability of an event after given time point.", "response": "def predict_proba(self, time):\n        \"\"\"Return probability of an event after given time point.\n\n        :math:`\\\\hat{S}(t) = P(T > t)`\n\n        Parameters\n        ----------\n        time : array, shape = (n_samples,)\n            Time to estimate probability at.\n\n        Returns\n        -------\n        prob : array, shape = (n_samples,)\n            Probability of an event.\n        \"\"\"\n        check_is_fitted(self, \"unique_time_\")\n        time = check_array(time, ensure_2d=False)\n\n        # K-M is undefined if estimate at last time point is non-zero\n        extends = time > self.unique_time_[-1]\n        if self.prob_[-1] > 0 and extends.any():\n            raise ValueError(\"time must be smaller than largest \"\n                             \"observed time point: {}\".format(self.unique_time_[-1]))\n\n        # beyond last time point is zero probability\n        Shat = numpy.empty(time.shape, dtype=float)\n        Shat[extends] = 0.0\n\n        valid = ~extends\n        time = time[valid]\n        idx = numpy.searchsorted(self.unique_time_, time)\n        # for non-exact matches, we need to shift the index to left\n        eps = numpy.finfo(self.unique_time_.dtype).eps\n        exact = numpy.absolute(self.unique_time_[idx] - time) < eps\n        idx[~exact] -= 1\n        Shat[valid] = self.prob_[idx]\n\n        return Shat"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit(self, y):\n        event, time = check_y_survival(y)\n        if event.all():\n            self.unique_time_ = numpy.unique(time)\n            self.prob_ = numpy.ones(self.unique_time_.shape[0])\n        else:\n            unique_time, prob = kaplan_meier_estimator(~event, time)\n            self.unique_time_ = numpy.concatenate(([-numpy.infty], unique_time))\n            self.prob_ = numpy.concatenate(([1.], prob))\n\n        return self", "response": "Estimate censoring distribution from training data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict_ipcw(self, y):\n        event, time = check_y_survival(y)\n        Ghat = self.predict_proba(time[event])\n\n        if (Ghat == 0.0).any():\n            raise ValueError(\"censoring survival function is zero at one or more time points\")\n\n        weights = numpy.zeros(time.shape[0])\n        weights[event] = 1.0 / Ghat\n\n        return weights", "response": "Predict the inverse probability of censoring weights at given time points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef concordance_index_censored(event_indicator, event_time, estimate, tied_tol=1e-8):\n    event_indicator, event_time, estimate = _check_inputs(\n        event_indicator, event_time, estimate)\n\n    w = numpy.ones_like(estimate)\n\n    return _estimate_concordance_index(event_indicator, event_time, estimate, w, tied_tol)", "response": "Returns the concordance index for the right - censored data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef concordance_index_ipcw(survival_train, survival_test, estimate, tau=None, tied_tol=1e-8):\n    test_event, test_time = check_y_survival(survival_test)\n\n    if tau is not None:\n        survival_test = survival_test[test_time < tau]\n\n    estimate = check_array(estimate, ensure_2d=False)\n    check_consistent_length(test_event, test_time, estimate)\n\n    cens = CensoringDistributionEstimator()\n    cens.fit(survival_train)\n    ipcw = cens.predict_ipcw(survival_test)\n\n    w = numpy.square(ipcw)\n\n    return _estimate_concordance_index(test_event, test_time, estimate, w, tied_tol)", "response": "Concordance index for right - censored data based on inverse probability of censoring weights."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cumulative_dynamic_auc(survival_train, survival_test, estimate, times, tied_tol=1e-8):\n    test_event, test_time = check_y_survival(survival_test)\n\n    estimate = check_array(estimate, ensure_2d=False)\n    check_consistent_length(test_event, test_time, estimate)\n\n    times = check_array(numpy.atleast_1d(times), ensure_2d=False, dtype=test_time.dtype)\n    times = numpy.unique(times)\n\n    if times.max() >= test_time.max() or times.min() < test_time.min():\n        raise ValueError(\n            'all times must be within follow-up time of test data: [{}; {}['.format(\n                test_time.min(), test_time.max()))\n\n    # sort by risk score (descending)\n    o = numpy.argsort(-estimate)\n    test_time = test_time[o]\n    test_event = test_event[o]\n    estimate = estimate[o]\n    survival_test = survival_test[o]\n\n    cens = CensoringDistributionEstimator()\n    cens.fit(survival_train)\n    ipcw = cens.predict_ipcw(survival_test)\n\n    n_samples = test_time.shape[0]\n    scores = numpy.empty(times.shape[0], dtype=float)\n    for k, t in enumerate(times):\n        is_case = (test_time <= t) & test_event\n        is_control = test_time > t\n        n_controls = is_control.sum()\n\n        true_pos = []\n        false_pos = []\n        tp_value = 0.0\n        fp_value = 0.0\n        est_prev = numpy.infty\n\n        for i in range(n_samples):\n            est = estimate[i]\n            if numpy.absolute(est - est_prev) > tied_tol:\n                true_pos.append(tp_value)\n                false_pos.append(fp_value)\n                est_prev = est\n            if is_case[i]:\n                tp_value += ipcw[i]\n            elif is_control[i]:\n                fp_value += 1\n        true_pos.append(tp_value)\n        false_pos.append(fp_value)\n\n        sens = numpy.array(true_pos) / ipcw[is_case].sum()\n        fpr = numpy.array(false_pos) / n_controls\n        scores[k] = trapz(sens, fpr)\n\n    if times.shape[0] == 1:\n        mean_auc = scores[0]\n    else:\n        surv = SurvivalFunctionEstimator()\n        surv.fit(survival_test)\n        s_times = surv.predict_proba(times)\n        # compute integral of AUC over survival function\n        d = -numpy.diff(numpy.concatenate(([1.0], s_times)))\n        integral = (scores * d).sum()\n        mean_auc = integral / (1.0 - s_times[-1])\n\n    return scores, mean_auc", "response": "Estimator of cumulative dynamic AUC for right - censored time - to - event data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _nominal_kernel(x, y, out):\n    for i in range(x.shape[0]):\n        for j in range(y.shape[0]):\n            out[i, j] += (x[i, :] == y[j, :]).sum()\n\n    return out", "response": "Number of features that match exactly"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts array from continuous and ordered categorical columns", "response": "def _get_continuous_and_ordinal_array(x):\n    \"\"\"Convert array from continuous and ordered categorical columns\"\"\"\n    nominal_columns = x.select_dtypes(include=['object', 'category']).columns\n    ordinal_columns = pandas.Index([v for v in nominal_columns if x[v].cat.ordered])\n    continuous_columns = x.select_dtypes(include=[numpy.number]).columns\n\n    x_num = x.loc[:, continuous_columns].astype(numpy.float64).values\n    if len(ordinal_columns) > 0:\n        x = _ordinal_as_numeric(x, ordinal_columns)\n\n        nominal_columns = nominal_columns.difference(ordinal_columns)\n        x_out = numpy.column_stack((x_num, x))\n    else:\n        x_out = x_num\n\n    return x_out, nominal_columns"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the clinical kernel between continuous and nominal variables.", "response": "def clinical_kernel(x, y=None):\n    \"\"\"Computes clinical kernel\n\n    The clinical kernel distinguishes between continuous\n    ordinal,and nominal variables.\n\n    Parameters\n    ----------\n    x : pandas.DataFrame, shape = (n_samples_x, n_features)\n        Training data\n\n    y : pandas.DataFrame, shape = (n_samples_y, n_features)\n        Testing data\n\n    Returns\n    -------\n    kernel : array, shape = (n_samples_x, n_samples_y)\n        Kernel matrix. Values are normalized to lie within [0, 1].\n\n    References\n    ----------\n    .. [1] Daemen, A., De Moor, B.,\n           \"Development of a kernel function for clinical data\".\n           Annual International Conference of the IEEE Engineering in Medicine and Biology Society, 5913-7, 2009\n    \"\"\"\n    if y is not None:\n        if x.shape[1] != y.shape[1]:\n            raise ValueError('x and y have different number of features')\n        if not x.columns.equals(y.columns):\n            raise ValueError('columns do not match')\n    else:\n        y = x\n\n    mat = numpy.zeros((x.shape[0], y.shape[0]), dtype=float)\n\n    x_numeric, nominal_columns = _get_continuous_and_ordinal_array(x)\n    if id(x) != id(y):\n        y_numeric, _ = _get_continuous_and_ordinal_array(y)\n    else:\n        y_numeric = x_numeric\n\n    continuous_ordinal_kernel(x_numeric, y_numeric, mat)\n    _nominal_kernel(x.loc[:, nominal_columns].values,\n                    y.loc[:, nominal_columns].values,\n                    mat)\n    mat /= x.shape[1]\n    return mat"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the data for the cluster class by the dtype of each column.", "response": "def _prepare_by_column_dtype(self, X):\n        \"\"\"Get distance functions for each column's dtype\"\"\"\n        if not isinstance(X, pandas.DataFrame):\n            raise TypeError('X must be a pandas DataFrame')\n\n        numeric_columns = []\n        nominal_columns = []\n        numeric_ranges = []\n\n        fit_data = numpy.empty_like(X)\n\n        for i, dt in enumerate(X.dtypes):\n            col = X.iloc[:, i]\n            if is_categorical_dtype(dt):\n                if col.cat.ordered:\n                    numeric_ranges.append(col.cat.codes.max() - col.cat.codes.min())\n                    numeric_columns.append(i)\n                else:\n                    nominal_columns.append(i)\n\n                col = col.cat.codes\n            elif is_numeric_dtype(dt):\n                numeric_ranges.append(col.max() - col.min())\n                numeric_columns.append(i)\n            else:\n                raise TypeError('unsupported dtype: %r' % dt)\n\n            fit_data[:, i] = col.values\n\n        self._numeric_columns = numpy.asarray(numeric_columns)\n        self._nominal_columns = numpy.asarray(nominal_columns)\n        self._numeric_ranges = numpy.asarray(numeric_ranges, dtype=float)\n        self.X_fit_ = fit_data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit(self, X, y=None, **kwargs):\n        if X.ndim != 2:\n            raise ValueError(\"expected 2d array, but got %d\" % X.ndim)\n\n        if self.fit_once:\n            self.X_fit_ = X\n        else:\n            self._prepare_by_column_dtype(X)\n\n        return self", "response": "Fit the clinical kernel to data in X."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform(self, Y):\n        check_is_fitted(self, 'X_fit_')\n\n        n_samples_x, n_features = self.X_fit_.shape\n\n        Y = numpy.asarray(Y)\n        if Y.shape[1] != n_features:\n            raise ValueError('expected array with %d features, but got %d' % (n_features, Y.shape[1]))\n\n        n_samples_y = Y.shape[0]\n\n        mat = numpy.zeros((n_samples_y, n_samples_x), dtype=float)\n\n        continuous_ordinal_kernel_with_ranges(Y[:, self._numeric_columns].astype(numpy.float64),\n                                              self.X_fit_[:, self._numeric_columns].astype(numpy.float64),\n                                              self._numeric_ranges, mat)\n\n        if len(self._nominal_columns) > 0:\n            _nominal_kernel(Y[:, self._nominal_columns],\n                            self.X_fit_[:, self._nominal_columns],\n                            mat)\n\n        mat /= n_features\n\n        return mat", "response": "r Compute all pairwise distances between self. X_fit_ and Y."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pairwise_kernel(self, X, Y):\n        check_is_fitted(self, 'X_fit_')\n        if X.shape[0] != Y.shape[0]:\n            raise ValueError('X and Y have different number of features')\n\n        val = pairwise_continuous_ordinal_kernel(X[self._numeric_columns], Y[self._numeric_columns],\n                                                 self._numeric_ranges)\n        if len(self._nominal_columns) > 0:\n            val += pairwise_nominal_kernel(X[self._nominal_columns].astype(numpy.int8),\n                                           Y[self._nominal_columns].astype(numpy.int8))\n\n        val /= X.shape[0]\n\n        return val", "response": "Function to use with sklearn. metrics. pairwise. pairwise_kernels"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fit_stage_componentwise(X, residuals, sample_weight, **fit_params):\n    n_features = X.shape[1]\n\n    base_learners = []\n    error = numpy.empty(n_features)\n    for component in range(n_features):\n        learner = ComponentwiseLeastSquares(component).fit(X, residuals, sample_weight)\n        l_pred = learner.predict(X)\n        error[component] = squared_norm(residuals - l_pred)\n        base_learners.append(learner)\n\n    # TODO: could use bottleneck.nanargmin for speed\n    best_component = numpy.nanargmin(error)\n    best_learner = base_learners[best_component]\n    return best_learner", "response": "Fit a component - wise weighted least squares model to a set of data points."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks validity of parameters and raise ValueError if not valid.", "response": "def _check_params(self):\n        \"\"\"Check validity of parameters and raise ValueError if not valid. \"\"\"\n        if self.n_estimators <= 0:\n            raise ValueError(\"n_estimators must be greater than 0 but \"\n                             \"was %r\" % self.n_estimators)\n\n        if not 0.0 < self.subsample <= 1.0:\n            raise ValueError(\"subsample must be in ]0; 1] but \"\n                             \"was %r\" % self.subsample)\n\n        if not 0.0 < self.learning_rate <= 1.0:\n            raise ValueError(\"learning_rate must be within ]0; 1] but \"\n                             \"was %r\" % self.learning_rate)\n\n        if not 0.0 <= self.dropout_rate < 1.0:\n            raise ValueError(\"dropout_rate must be within [0; 1[, but \"\n                             \"was %r\" % self.dropout_rate)\n\n        if self.loss not in LOSS_FUNCTIONS:\n            raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit(self, X, y, sample_weight=None):\n        X, event, time = check_arrays_survival(X, y)\n\n        n_samples, n_features = X.shape\n\n        if sample_weight is None:\n            sample_weight = numpy.ones(n_samples, dtype=numpy.float32)\n        else:\n            sample_weight = column_or_1d(sample_weight, warn=True)\n            check_consistent_length(X, sample_weight)\n\n        random_state = check_random_state(self.random_state)\n\n        self._check_params()\n\n        self.estimators_ = []\n        self.n_features_ = n_features\n        self.loss_ = LOSS_FUNCTIONS[self.loss](1)\n        if isinstance(self.loss_, (CensoredSquaredLoss, IPCWLeastSquaresError)):\n            time = numpy.log(time)\n\n        self.train_score_ = numpy.zeros((self.n_estimators,), dtype=numpy.float64)\n        # do oob?\n        if self.subsample < 1.0:\n            self.oob_improvement_ = numpy.zeros(self.n_estimators,\n                                                dtype=numpy.float64)\n\n        self._fit(X, event, time, sample_weight, random_state)\n\n        return self", "response": "Fit estimator.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data matrix\n\n        y : structured array, shape = (n_samples,)\n            A structured array containing the binary event indicator\n            as first field, and time of event or time of censoring as\n            second field.\n\n        sample_weight : array-like, shape = (n_samples,), optional\n            Weights given to each sample. If omitted, all samples have weight 1.\n\n        Returns\n        -------\n        self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npredict the risk score for a set of training data sets X.", "response": "def predict(self, X):\n        \"\"\"Predict risk scores.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Data matrix.\n\n        Returns\n        -------\n        risk_score : array, shape = (n_samples,)\n            Predicted risk scores.\n        \"\"\"\n        check_is_fitted(self, 'estimators_')\n\n        if X.shape[1] != self.n_features_:\n            raise ValueError('Dimensions of X are inconsistent with training data: '\n                             'expected %d features, but got %s' % (self.n_features_, X.shape[1]))\n\n        n_samples = X.shape[0]\n        Xi = numpy.column_stack((numpy.ones(n_samples), X))\n        pred = numpy.zeros(n_samples, dtype=float)\n\n        for estimator in self.estimators_:\n            pred += self.learning_rate * estimator.predict(Xi)\n\n        if isinstance(self.loss_, (CensoredSquaredLoss, IPCWLeastSquaresError)):\n            numpy.exp(pred, out=pred)\n\n        return pred"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef coef_(self):\n        coef = numpy.zeros(self.n_features_ + 1, dtype=float)\n\n        for estimator in self.estimators_:\n            coef[estimator.component] += self.learning_rate * estimator.coef_\n\n        return coef", "response": "Return the aggregated coefficients."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_params(self):\n        self.n_estimators = int(self.n_estimators)\n        if self.n_estimators <= 0:\n            raise ValueError(\"n_estimators must be greater than 0 but \"\n                             \"was %r\" % self.n_estimators)\n\n        if not 0.0 < self.learning_rate <= 1.0:\n            raise ValueError(\"learning_rate must be within ]0; 1] but \"\n                             \"was %r\" % self.learning_rate)\n\n        if not 0.0 < self.subsample <= 1.0:\n            raise ValueError(\"subsample must be in ]0; 1] but \"\n                             \"was %r\" % self.subsample)\n\n        if not 0.0 <= self.dropout_rate < 1.0:\n            raise ValueError(\"dropout_rate must be within [0; 1[, but \"\n                             \"was %r\" % self.dropout_rate)\n\n        max_features = self._check_max_features()\n\n        self.min_samples_split = int(self.min_samples_split)\n        self.min_samples_leaf = int(self.min_samples_leaf)\n        self.max_depth = int(self.max_depth)\n        if self.max_leaf_nodes:\n            self.max_leaf_nodes = int(self.max_leaf_nodes)\n\n        self.max_features_ = max_features\n\n        allowed_presort = ('auto', True, False)\n        if self.presort not in allowed_presort:\n            raise ValueError(\"'presort' should be in {}. Got {!r} instead.\"\n                             .format(allowed_presort, self.presort))\n\n        if self.loss not in LOSS_FUNCTIONS:\n            raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))", "response": "Check validity of parameters and raise ValueError if not valid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fit_stage(self, i, X, y, y_pred, sample_weight, sample_mask,\n                   random_state, scale, X_idx_sorted, X_csc=None, X_csr=None):\n        \"\"\"Fit another stage of ``n_classes_`` trees to the boosting model. \"\"\"\n\n        assert sample_mask.dtype == numpy.bool\n        loss = self.loss_\n\n        # whether to use dropout in next iteration\n        do_dropout = self.dropout_rate > 0. and 0 < i < len(scale) - 1\n\n        for k in range(loss.K):\n            residual = loss.negative_gradient(y, y_pred, k=k,\n                                              sample_weight=sample_weight)\n\n            # induce regression tree on residuals\n            tree = DecisionTreeRegressor(\n                criterion=self.criterion,\n                splitter='best',\n                max_depth=self.max_depth,\n                min_samples_split=self.min_samples_split,\n                min_samples_leaf=self.min_samples_leaf,\n                min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n                min_impurity_split=self.min_impurity_split,\n                min_impurity_decrease=self.min_impurity_decrease,\n                max_features=self.max_features,\n                max_leaf_nodes=self.max_leaf_nodes,\n                random_state=random_state,\n                presort=self.presort)\n\n            if self.subsample < 1.0:\n                # no inplace multiplication!\n                sample_weight = sample_weight * sample_mask.astype(numpy.float64)\n\n            X = X_csr if X_csr is not None else X\n            tree.fit(X, residual, sample_weight=sample_weight,\n                     check_input=False, X_idx_sorted=X_idx_sorted)\n\n            # add tree to ensemble\n            self.estimators_[i, k] = tree\n\n            # update tree leaves\n            if do_dropout:\n                # select base learners to be dropped for next iteration\n                drop_model, n_dropped = _sample_binomial_plus_one(self.dropout_rate, i + 1, random_state)\n\n                # adjust scaling factor of tree that is going to be trained in next iteration\n                scale[i + 1] = 1. / (n_dropped + 1.)\n\n                y_pred[:, k] = 0\n                for m in range(i + 1):\n                    if drop_model[m] == 1:\n                        # adjust scaling factor of dropped trees\n                        scale[m] *= n_dropped / (n_dropped + 1.)\n                    else:\n                        # pseudoresponse of next iteration (without contribution of dropped trees)\n                        y_pred[:, k] += self.learning_rate * scale[m] * self.estimators_[m, k].predict(X).ravel()\n            else:\n                # update tree leaves\n                loss.update_terminal_regions(tree.tree_, X, y, residual, y_pred,\n                                             sample_weight, sample_mask,\n                                             self.learning_rate, k=k)\n\n        return y_pred", "response": "Fit another stage of n_classes_ trees to the boosting model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fit_stages(self, X, y, y_pred, sample_weight, random_state,\n                    begin_at_stage=0, monitor=None, X_idx_sorted=None):\n        \"\"\"Iteratively fits the stages.\n\n        For each stage it computes the progress (OOB, train score)\n        and delegates to ``_fit_stage``.\n        Returns the number of stages fit; might differ from ``n_estimators``\n        due to early stopping.\n        \"\"\"\n        n_samples = X.shape[0]\n        do_oob = self.subsample < 1.0\n        sample_mask = numpy.ones((n_samples, ), dtype=numpy.bool)\n        n_inbag = max(1, int(self.subsample * n_samples))\n        loss_ = self.loss_\n\n        if self.verbose:\n            verbose_reporter = VerboseReporter(self.verbose)\n            verbose_reporter.init(self, begin_at_stage)\n\n        X_csc = csc_matrix(X) if issparse(X) else None\n        X_csr = csr_matrix(X) if issparse(X) else None\n\n        if self.dropout_rate > 0.:\n            scale = numpy.ones(self.n_estimators, dtype=float)\n        else:\n            scale = None\n\n        # perform boosting iterations\n        i = begin_at_stage\n        for i in range(begin_at_stage, self.n_estimators):\n\n            # subsampling\n            if do_oob:\n                sample_mask = _random_sample_mask(n_samples, n_inbag,\n                                                  random_state)\n                # OOB score before adding this stage\n                y_oob_sample = y[~sample_mask]\n                old_oob_score = loss_(y_oob_sample,\n                                      y_pred[~sample_mask],\n                                      sample_weight[~sample_mask])\n\n            # fit next stage of trees\n            y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n                                     sample_mask, random_state, scale, X_idx_sorted,\n                                     X_csc, X_csr)\n\n            # track deviance (= loss)\n            if do_oob:\n                self.train_score_[i] = loss_(y[sample_mask],\n                                             y_pred[sample_mask],\n                                             sample_weight[sample_mask])\n                self.oob_improvement_[i] = (old_oob_score - loss_(y_oob_sample, y_pred[~sample_mask],\n                                                                  sample_weight[~sample_mask]))\n            else:\n                # no need to fancy index w/ no subsampling\n                self.train_score_[i] = loss_(y, y_pred, sample_weight)\n\n            if self.verbose > 0:\n                verbose_reporter.update(i, self)\n\n            if monitor is not None:\n                early_stopping = monitor(i, self, locals())\n                if early_stopping:\n                    break\n\n        if self.dropout_rate > 0.:\n            self.scale_ = scale\n\n        return i + 1", "response": "Iteratively fits the trees and returns the number of trees and the final state of the trees."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit(self, X, y, sample_weight=None, monitor=None):\n        random_state = check_random_state(self.random_state)\n\n        X, event, time = check_arrays_survival(X, y, accept_sparse=['csr', 'csc', 'coo'], dtype=DTYPE)\n        n_samples, self.n_features_ = X.shape\n\n        X = X.astype(DTYPE)\n        if sample_weight is None:\n            sample_weight = numpy.ones(n_samples, dtype=numpy.float32)\n        else:\n            sample_weight = column_or_1d(sample_weight, warn=True)\n            check_consistent_length(X, sample_weight)\n\n        self._check_params()\n\n        self.loss_ = LOSS_FUNCTIONS[self.loss](1)\n        if isinstance(self.loss_, (CensoredSquaredLoss, IPCWLeastSquaresError)):\n            time = numpy.log(time)\n\n        self._init_state()\n        self.init_.fit(X, (event, time), sample_weight)\n        y_pred = self.init_.predict(X)\n        begin_at_stage = 0\n\n        if self.presort is True and issparse(X):\n            raise ValueError(\n                \"Presorting is not supported for sparse matrices.\")\n\n        presort = self.presort\n        # Allow presort to be 'auto', which means True if the dataset is dense,\n        # otherwise it will be False.\n        if presort == 'auto':\n            presort = not issparse(X)\n\n        X_idx_sorted = None\n        if presort:\n            X_idx_sorted = numpy.asfortranarray(numpy.argsort(X, axis=0),\n                                                dtype=numpy.int32)\n\n        # fit the boosting stages\n        y = numpy.fromiter(zip(event, time), dtype=[('event', numpy.bool), ('time', numpy.float64)])\n        n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n                                    begin_at_stage, monitor, X_idx_sorted)\n        # change shape of arrays after fit (early-stopping or additional tests)\n        if n_stages != self.estimators_.shape[0]:\n            self.estimators_ = self.estimators_[:n_stages]\n            self.train_score_ = self.train_score_[:n_stages]\n            if hasattr(self, 'oob_improvement_'):\n                self.oob_improvement_ = self.oob_improvement_[:n_stages]\n\n        self.n_estimators_ = n_stages\n        return self", "response": "Fit the gradient boosting model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict(self, X):\n        check_is_fitted(self, 'estimators_')\n\n        X = check_array(X, dtype=DTYPE, order=\"C\")\n        score = self._decision_function(X)\n        if score.shape[1] == 1:\n            score = score.ravel()\n\n        return score", "response": "Predict the risk score for a set of samples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npredicting hazard at each stage for X. This method allows monitoring error on testing set.", "response": "def staged_predict(self, X):\n        \"\"\"Predict hazard at each stage for X.\n\n        This method allows monitoring (i.e. determine error on testing set)\n        after each stage.\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        y : generator of array of shape = (n_samples,)\n            The predicted value of the input samples.\n        \"\"\"\n        check_is_fitted(self, 'estimators_')\n\n        # if dropout wasn't used during training, proceed as usual,\n        # otherwise consider scaling factor of individual trees\n        if not hasattr(self, \"scale_\"):\n            for y in self._staged_decision_function(X):\n                yield self._scale_prediction(y.ravel())\n        else:\n            for y in self._dropout_staged_decision_function(X):\n                yield self._scale_prediction(y.ravel())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit(self, X, y):\n        X, event, time = check_arrays_survival(X, y)\n        self._fit(X, event, time)\n\n        return self", "response": "Build a MINLIP survival model from training data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npredict risk score of experiencing an event.", "response": "def predict(self, X):\n        \"\"\"Predict risk score of experiencing an event.\n\n        Higher scores indicate shorter survival (high risk),\n        lower scores longer survival (low risk).\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        y : ndarray, shape = (n_samples,)\n            Predicted risk.\n        \"\"\"\n        K = self._get_kernel(X, self.X_fit_)\n        pred = -numpy.dot(self.coef_, K.T)\n        return pred.ravel()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsplitting data frame into features and labels.", "response": "def get_x_y(data_frame, attr_labels, pos_label=None, survival=True):\n    \"\"\"Split data frame into features and labels.\n\n    Parameters\n    ----------\n    data_frame : pandas.DataFrame, shape = (n_samples, n_columns)\n        A data frame.\n\n    attr_labels : sequence of str or None\n        A list of one or more columns that are considered the label.\n        If `survival` is `True`, then attr_labels has two elements:\n        1) the name of the column denoting the event indicator, and\n        2) the name of the column denoting the survival time.\n        If the sequence contains `None`, then labels are not retrieved\n        and only a data frame with features is returned.\n\n    pos_label : any, optional\n        Which value of the event indicator column denotes that a\n        patient experienced an event. This value is ignored if\n        `survival` is `False`.\n\n    survival : bool, optional, default: True\n        Whether to return `y` that can be used for survival analysis.\n\n    Returns\n    -------\n    X : pandas.DataFrame, shape = (n_samples, n_columns - len(attr_labels))\n        Data frame containing features.\n\n    y : None or pandas.DataFrame, shape = (n_samples, len(attr_labels))\n        Data frame containing columns with supervised information.\n        If `survival` was `True`, then the column denoting the event\n        indicator will be boolean and survival times will be float.\n        If `attr_labels` contains `None`, y is set to `None`.\n    \"\"\"\n    if survival:\n        if len(attr_labels) != 2:\n            raise ValueError(\"expected sequence of length two for attr_labels, but got %d\" % len(attr_labels))\n        if pos_label is None:\n            raise ValueError(\"pos_label needs to be specified if survival=True\")\n        return _get_x_y_survival(data_frame, attr_labels[0], attr_labels[1], pos_label)\n\n    return _get_x_y_other(data_frame, attr_labels)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_arff_files_standardized(path_training, attr_labels, pos_label=None, path_testing=None, survival=True,\n                                 standardize_numeric=True, to_numeric=True):\n    \"\"\"Load dataset in ARFF format.\n\n    Parameters\n    ----------\n    path_training : str\n        Path to ARFF file containing data.\n\n    attr_labels : sequence of str\n        Names of attributes denoting dependent variables.\n        If ``survival`` is set, it must be a sequence with two items:\n        the name of the event indicator and the name of the survival/censoring time.\n\n    pos_label : any type, optional\n        Value corresponding to an event in survival analysis.\n        Only considered if ``survival`` is ``True``.\n\n    path_testing : str, optional\n        Path to ARFF file containing hold-out data. Only columns that are available in both\n        training and testing are considered (excluding dependent variables).\n        If ``standardize_numeric`` is set, data is normalized by considering both training\n        and testing data.\n\n    survival : bool, optional, default: True\n        Whether the dependent variables denote event indicator and survival/censoring time.\n\n    standardize_numeric : bool, optional, default: True\n        Whether to standardize data to zero mean and unit variance.\n        See :func:`sksurv.column.standardize`.\n\n    to_numeric : boo, optional, default: True\n        Whether to convert categorical variables to numeric values.\n        See :func:`sksurv.column.categorical_to_numeric`.\n\n    Returns\n    -------\n    x_train : pandas.DataFrame, shape = (n_train, n_features)\n        Training data.\n\n    y_train : pandas.DataFrame, shape = (n_train, n_labels)\n        Dependent variables of training data.\n\n    x_test : None or pandas.DataFrame, shape = (n_train, n_features)\n        Testing data if `path_testing` was provided.\n\n    y_test : None or pandas.DataFrame, shape = (n_train, n_labels)\n        Dependent variables of testing data if `path_testing` was provided.\n    \"\"\"\n    dataset = loadarff(path_training)\n    if \"index\" in dataset.columns:\n        dataset.index = dataset[\"index\"].astype(object)\n        dataset.drop(\"index\", axis=1, inplace=True)\n\n    x_train, y_train = get_x_y(dataset, attr_labels, pos_label, survival)\n\n    if path_testing is not None:\n        x_test, y_test = _load_arff_testing(path_testing, attr_labels, pos_label, survival)\n\n        if len(x_train.columns.symmetric_difference(x_test.columns)) > 0:\n            warnings.warn(\"Restricting columns to intersection between training and testing data\",\n                          stacklevel=2)\n\n            cols = x_train.columns.intersection(x_test.columns)\n            if len(cols) == 0:\n                raise ValueError(\"columns of training and test data do not intersect\")\n\n            x_train = x_train.loc[:, cols]\n            x_test = x_test.loc[:, cols]\n\n        x = safe_concat((x_train, x_test), axis=0)\n        if standardize_numeric:\n            x = standardize(x)\n        if to_numeric:\n            x = categorical_to_numeric(x)\n\n        n_train = x_train.shape[0]\n        x_train = x.iloc[:n_train, :]\n        x_test = x.iloc[n_train:, :]\n    else:\n        if standardize_numeric:\n            x_train = standardize(x_train)\n        if to_numeric:\n            x_train = categorical_to_numeric(x_train)\n\n        x_test = None\n        y_test = None\n\n    return x_train, y_train, x_test, y_test", "response": "Load training and testing data in ARFF format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_aids(endpoint=\"aids\"):\n    labels_aids = ['censor', 'time']\n    labels_death = ['censor_d', 'time_d']\n    if endpoint == \"aids\":\n        attr_labels = labels_aids\n        drop_columns = labels_death\n    elif endpoint == \"death\":\n        attr_labels = labels_death\n        drop_columns = labels_aids\n    else:\n        raise ValueError(\"endpoint must be 'aids' or 'death'\")\n\n    fn = resource_filename(__name__, 'data/actg320.arff')\n    x, y = get_x_y(loadarff(fn), attr_labels=attr_labels, pos_label='1')\n    x.drop(drop_columns, axis=1, inplace=True)\n    return x, y", "response": "Load and return the AIDS Clinical Trial dataset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit_transform(self, X, y=None, **fit_params):\n        columns_to_encode = X.select_dtypes(include=[\"object\", \"category\"]).columns\n        x_dummy = self._encode(X, columns_to_encode)\n\n        self.feature_names_ = columns_to_encode\n        self.categories_ = {k: X[k].cat.categories for k in columns_to_encode}\n        self.encoded_columns_ = x_dummy.columns\n        return x_dummy", "response": "Convert categorical columns to numeric values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert categorical columns to numeric values.", "response": "def transform(self, X):\n        \"\"\"Convert categorical columns to numeric values.\n\n        Parameters\n        ----------\n        X : pandas.DataFrame\n            Data to encode.\n\n        Returns\n        -------\n        Xt : pandas.DataFrame\n            Encoded data.\n        \"\"\"\n        check_is_fitted(self, \"encoded_columns_\")\n        check_columns_exist(X.columns, self.feature_names_)\n\n        Xt = X.copy()\n        for col, cat in self.categories_.items():\n            Xt[col].cat.set_categories(cat, inplace=True)\n\n        new_data = self._encode(Xt, self.feature_names_)\n        return new_data.loc[:, self.encoded_columns_]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a player s full list of players and then returns a full row of player information if specified or the full row of player information if specified.", "response": "def get_player(first_name,\n               last_name=None,\n               season=constants.CURRENT_SEASON,\n               only_current=0,\n               just_id=True):\n    \"\"\"\n    Calls our PlayerList class to get a full list of players and then returns\n    just an id if specified or the full row of player information\n\n    Args:\n        :first_name: First name of the player\n        :last_name: Last name of the player\n        (this is None if the player only has first name [Nene])\n        :only_current: Only wants the current list of players\n        :just_id: Only wants the id of the player\n\n    Returns:\n        Either the ID or full row of information of the player inputted\n\n    Raises:\n        :PlayerNotFoundException::\n    \"\"\"\n    if last_name is None:\n        name = first_name.lower()\n    else:\n        name = '{}, {}'.format(last_name, first_name).lower()\n    pl = PlayerList(season=season, only_current=only_current).info()\n    hdr = 'DISPLAY_LAST_COMMA_FIRST'\n    if HAS_PANDAS:\n        item = pl[pl.DISPLAY_LAST_COMMA_FIRST.str.lower() == name]\n    else:\n        item = next(plyr for plyr in pl if str(plyr[hdr]).lower() == name)\n    if len(item) == 0:\n        raise PlayerNotFoundException\n    elif just_id:\n        return item['PERSON_ID']\n    else:\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef respond_to_ask(self, message):\n    valid_actions, hole_card, round_state = self.__parse_ask_message(message)\n    return self.declare_action(valid_actions, hole_card, round_state)", "response": "Called from Dealer when a message is received from RoundManager"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef receive_notification(self, message):\n    msg_type = message[\"message_type\"]\n\n    if msg_type == \"game_start_message\":\n      info = self.__parse_game_start_message(message)\n      self.receive_game_start_message(info)\n\n    elif msg_type == \"round_start_message\":\n      round_count, hole, seats = self.__parse_round_start_message(message)\n      self.receive_round_start_message(round_count, hole, seats)\n\n    elif msg_type == \"street_start_message\":\n      street, state = self.__parse_street_start_message(message)\n      self.receive_street_start_message(street, state)\n\n    elif msg_type == \"game_update_message\":\n      new_action, round_state = self.__parse_game_update_message(message)\n      self.receive_game_update_message(new_action, round_state)\n\n    elif msg_type == \"round_result_message\":\n      winners, hand_info, state = self.__parse_round_result_message(message)\n      self.receive_round_result_message(winners, hand_info, state)", "response": "Called from Dealer when a notification is received from the RoundManager"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def result_processor(tasks):\n    output = {}\n    for task in tasks:\n        num, res = await task\n        output[num] = res\n    return output", "response": "An async result aggregator that combines all the results\n      "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a decimal from the data stream.", "response": "def _read_decimal(data, size, writer_schema):\n    \"\"\"\n    based on https://github.com/apache/avro/pull/82/\n    \"\"\"\n    scale = writer_schema.get('scale', 0)\n    precision = writer_schema['precision']\n\n    datum_byte = str2ints(data)\n\n    unscaled_datum = 0\n    msb = fstint(data)\n    leftmost_bit = (msb >> 7) & 1\n    if leftmost_bit == 1:\n        modified_first_byte = datum_byte[0] ^ (1 << 7)\n        datum_byte = [modified_first_byte] + datum_byte[1:]\n        for offset in xrange(size):\n            unscaled_datum <<= 8\n            unscaled_datum += datum_byte[offset]\n        unscaled_datum += pow(-2, (size * 8) - 1)\n    else:\n        for offset in xrange(size):\n            unscaled_datum <<= 8\n            unscaled_datum += (datum_byte[offset])\n\n    with localcontext() as ctx:\n        ctx.prec = precision\n        scaled_datum = Decimal(unscaled_datum).scaleb(-scale)\n    return scaled_datum"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_long(fo, writer_schema=None, reader_schema=None):\n    c = fo.read(1)\n\n    # We do EOF checking only here, since most reader start here\n    if not c:\n        raise StopIteration\n\n    b = ord(c)\n    n = b & 0x7F\n    shift = 7\n\n    while (b & 0x80) != 0:\n        b = ord(fo.read(1))\n        n |= (b & 0x7F) << shift\n        shift += 7\n\n    return (n >> 1) ^ -(n & 1)", "response": "Reads a long integer from the file - like object fo."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_bytes(fo, writer_schema=None, reader_schema=None):\n    size = read_long(fo)\n    return fo.read(size)", "response": "Reads a byte string from the file - like object fo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading an enum from the file - like object fo.", "response": "def read_enum(fo, writer_schema, reader_schema=None):\n    \"\"\"An enum is encoded by a int, representing the zero-based position of the\n    symbol in the schema.\n    \"\"\"\n    index = read_long(fo)\n    symbol = writer_schema['symbols'][index]\n    if reader_schema and symbol not in reader_schema['symbols']:\n        default = reader_schema.get(\"default\")\n        if default:\n            return default\n        else:\n            symlist = reader_schema['symbols']\n            msg = '%s not found in reader symbol list %s' % (symbol, symlist)\n            raise SchemaResolutionError(msg)\n    return symbol"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_array(fo, writer_schema, reader_schema=None):\n    if reader_schema:\n        def item_reader(fo, w_schema, r_schema):\n            return read_data(fo, w_schema['items'], r_schema['items'])\n    else:\n        def item_reader(fo, w_schema, _):\n            return read_data(fo, w_schema['items'])\n\n    read_items = []\n\n    block_count = read_long(fo)\n\n    while block_count != 0:\n        if block_count < 0:\n            block_count = -block_count\n            # Read block size, unused\n            read_long(fo)\n\n        for i in xrange(block_count):\n            read_items.append(item_reader(fo, writer_schema, reader_schema))\n        block_count = read_long(fo)\n\n    return read_items", "response": "Reads an array of items from the file - like object fo."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a map from the file - like object fo.", "response": "def read_map(fo, writer_schema, reader_schema=None):\n    \"\"\"Maps are encoded as a series of blocks.\n\n    Each block consists of a long count value, followed by that many key/value\n    pairs.  A block with count zero indicates the end of the map.  Each item is\n    encoded per the map's value schema.\n\n    If a block's count is negative, then the count is followed immediately by a\n    long block size, indicating the number of bytes in the block.  The actual\n    count in this case is the absolute value of the count written.\n    \"\"\"\n    if reader_schema:\n        def item_reader(fo, w_schema, r_schema):\n            return read_data(fo, w_schema['values'], r_schema['values'])\n    else:\n        def item_reader(fo, w_schema, _):\n            return read_data(fo, w_schema['values'])\n\n    read_items = {}\n    block_count = read_long(fo)\n    while block_count != 0:\n        if block_count < 0:\n            block_count = -block_count\n            # Read block size, unused\n            read_long(fo)\n\n        for i in xrange(block_count):\n            key = read_utf8(fo)\n            read_items[key] = item_reader(fo, writer_schema, reader_schema)\n        block_count = read_long(fo)\n\n    return read_items"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a union of the content of a single element.", "response": "def read_union(fo, writer_schema, reader_schema=None):\n    \"\"\"A union is encoded by first writing a long value indicating the\n    zero-based position within the union of the schema of its value.\n\n    The value is then encoded per the indicated schema within the union.\n    \"\"\"\n    # schema resolution\n    index = read_long(fo)\n    if reader_schema:\n        # Handle case where the reader schema is just a single type (not union)\n        if not isinstance(reader_schema, list):\n            if match_types(writer_schema[index], reader_schema):\n                return read_data(fo, writer_schema[index], reader_schema)\n        else:\n            for schema in reader_schema:\n                if match_types(writer_schema[index], schema):\n                    return read_data(fo, writer_schema[index], schema)\n        msg = 'schema mismatch: %s not found in %s' % \\\n            (writer_schema, reader_schema)\n        raise SchemaResolutionError(msg)\n    else:\n        return read_data(fo, writer_schema[index])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_record(fo, writer_schema, reader_schema=None):\n    record = {}\n    if reader_schema is None:\n        for field in writer_schema['fields']:\n            record[field['name']] = read_data(fo, field['type'])\n    else:\n        readers_field_dict = {}\n        aliases_field_dict = {}\n        for f in reader_schema['fields']:\n            readers_field_dict[f['name']] = f\n            for alias in f.get('aliases', []):\n                aliases_field_dict[alias] = f\n\n        for field in writer_schema['fields']:\n            readers_field = readers_field_dict.get(\n                field['name'],\n                aliases_field_dict.get(field['name']),\n            )\n            if readers_field:\n                record[readers_field['name']] = read_data(\n                    fo,\n                    field['type'],\n                    readers_field['type'],\n                )\n            else:\n                # should implement skip\n                read_data(fo, field['type'], field['type'])\n\n        # fill in default values\n        if len(readers_field_dict) > len(record):\n            writer_fields = [f['name'] for f in writer_schema['fields']]\n            for f_name, field in iteritems(readers_field_dict):\n                if f_name not in writer_fields and f_name not in record:\n                    if 'default' in field:\n                        record[field['name']] = field['default']\n                    else:\n                        msg = 'No default value for %s' % field['name']\n                        raise SchemaResolutionError(msg)\n\n    return record", "response": "Reads a record from a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_data(fo, writer_schema, reader_schema=None):\n\n    record_type = extract_record_type(writer_schema)\n    logical_type = extract_logical_type(writer_schema)\n\n    if reader_schema and record_type in AVRO_TYPES:\n        # If the schemas are the same, set the reader schema to None so that no\n        # schema resolution is done for this call or future recursive calls\n        if writer_schema == reader_schema:\n            reader_schema = None\n        else:\n            match_schemas(writer_schema, reader_schema)\n\n    reader_fn = READERS.get(record_type)\n    if reader_fn:\n        try:\n            data = reader_fn(fo, writer_schema, reader_schema)\n        except StructError:\n            raise EOFError('cannot read %s from %s' % (record_type, fo))\n\n        if 'logicalType' in writer_schema:\n            fn = LOGICAL_READERS.get(logical_type)\n            if fn:\n                return fn(data, writer_schema, reader_schema)\n\n        if reader_schema is not None:\n            return maybe_promote(\n                data,\n                record_type,\n                extract_record_type(reader_schema)\n            )\n        else:\n            return data\n    else:\n        return read_data(\n            fo,\n            SCHEMA_DEFS[record_type],\n            SCHEMA_DEFS.get(reader_schema)\n        )", "response": "Read data from file object according to schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _iter_avro_records(fo, header, codec, writer_schema, reader_schema):\n    sync_marker = header['sync']\n\n    read_block = BLOCK_READERS.get(codec)\n    if not read_block:\n        raise ValueError('Unrecognized codec: %r' % codec)\n\n    block_count = 0\n    while True:\n        try:\n            block_count = read_long(fo)\n        except StopIteration:\n            return\n\n        block_fo = read_block(fo)\n\n        for i in xrange(block_count):\n            yield read_data(block_fo, writer_schema, reader_schema)\n\n        skip_sync(fo, sync_marker)", "response": "Return iterator over avro records."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn iterator over avro blocks.", "response": "def _iter_avro_blocks(fo, header, codec, writer_schema, reader_schema):\n    \"\"\"Return iterator over avro blocks.\"\"\"\n    sync_marker = header['sync']\n\n    read_block = BLOCK_READERS.get(codec)\n    if not read_block:\n        raise ValueError('Unrecognized codec: %r' % codec)\n\n    while True:\n        offset = fo.tell()\n        try:\n            num_block_records = read_long(fo)\n        except StopIteration:\n            return\n\n        block_bytes = read_block(fo)\n\n        skip_sync(fo, sync_marker)\n\n        size = fo.tell() - offset\n\n        yield Block(\n            block_bytes, num_block_records, codec, reader_schema,\n            writer_schema, offset, size\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef schemaless_reader(fo, writer_schema, reader_schema=None):\n    if writer_schema == reader_schema:\n        # No need for the reader schema if they are the same\n        reader_schema = None\n\n    writer_schema = parse_schema(writer_schema)\n\n    if reader_schema:\n        reader_schema = parse_schema(reader_schema)\n\n    return read_data(fo, writer_schema, reader_schema)", "response": "Reads a single record from a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if path points to an Avro file.", "response": "def is_avro(path_or_buffer):\n    \"\"\"Return True if path (or buffer) points to an Avro file.\n\n    Parameters\n    ----------\n    path_or_buffer: path to file or file-like object\n        Path to file\n    \"\"\"\n    if is_str(path_or_buffer):\n        fp = open(path_or_buffer, 'rb')\n        close = True\n    else:\n        fp = path_or_buffer\n        close = False\n\n    try:\n        header = fp.read(len(MAGIC))\n        return header == MAGIC\n    finally:\n        if close:\n            fp.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert datetime. datetime object to int timestamp with milliseconds", "response": "def prepare_timestamp_millis(data, schema):\n    \"\"\"Converts datetime.datetime object to int timestamp with milliseconds\n    \"\"\"\n    if isinstance(data, datetime.datetime):\n        if data.tzinfo is not None:\n            delta = (data - epoch)\n            return int(delta.total_seconds() * MLS_PER_SECOND)\n        t = int(time.mktime(data.timetuple())) * MLS_PER_SECOND + int(\n            data.microsecond / 1000)\n        return t\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts datetime. datetime to int timestamp with microseconds", "response": "def prepare_timestamp_micros(data, schema):\n    \"\"\"Converts datetime.datetime to int timestamp with microseconds\"\"\"\n    if isinstance(data, datetime.datetime):\n        if data.tzinfo is not None:\n            delta = (data - epoch)\n            return int(delta.total_seconds() * MCS_PER_SECOND)\n        t = int(time.mktime(data.timetuple())) * MCS_PER_SECOND + \\\n            data.microsecond\n        return t\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts datetime. date to int timestamp", "response": "def prepare_date(data, schema):\n    \"\"\"Converts datetime.date to int timestamp\"\"\"\n    if isinstance(data, datetime.date):\n        return data.toordinal() - DAYS_SHIFT\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepare_time_millis(data, schema):\n    if isinstance(data, datetime.time):\n        return int(\n            data.hour * MLS_PER_HOUR + data.minute * MLS_PER_MINUTE\n            + data.second * MLS_PER_SECOND + int(data.microsecond / 1000))\n    else:\n        return data", "response": "Convert datetime. time to int timestamp with milliseconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_time_micros(data, schema):\n    if isinstance(data, datetime.time):\n        return long(data.hour * MCS_PER_HOUR + data.minute * MCS_PER_MINUTE\n                    + data.second * MCS_PER_SECOND + data.microsecond)\n    else:\n        return data", "response": "Convert datetime. time to int timestamp with microseconds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting decimal. Decimal to bytes", "response": "def prepare_bytes_decimal(data, schema):\n    \"\"\"Convert decimal.Decimal to bytes\"\"\"\n    if not isinstance(data, decimal.Decimal):\n        return data\n    scale = schema.get('scale', 0)\n\n    # based on https://github.com/apache/avro/pull/82/\n\n    sign, digits, exp = data.as_tuple()\n\n    if -exp > scale:\n        raise ValueError(\n            'Scale provided in schema does not match the decimal')\n    delta = exp + scale\n    if delta > 0:\n        digits = digits + (0,) * delta\n\n    unscaled_datum = 0\n    for digit in digits:\n        unscaled_datum = (unscaled_datum * 10) + digit\n\n    bits_req = unscaled_datum.bit_length() + 1\n\n    if sign:\n        unscaled_datum = (1 << bits_req) - unscaled_datum\n\n    bytes_req = bits_req // 8\n    padding_bits = ~((1 << bits_req) - 1) if sign else 0\n    packed_bits = padding_bits | unscaled_datum\n\n    bytes_req += 1 if (bytes_req << 3) < bits_req else 0\n\n    tmp = MemoryIO()\n\n    for index in range(bytes_req - 1, -1, -1):\n        bits_to_write = packed_bits >> (8 * index)\n        tmp.write(mk_bits(bits_to_write & 0xff))\n\n    return tmp.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting decimal. Decimal to fixed length bytes array", "response": "def prepare_fixed_decimal(data, schema):\n    \"\"\"Converts decimal.Decimal to fixed length bytes array\"\"\"\n    if not isinstance(data, decimal.Decimal):\n        return data\n    scale = schema.get('scale', 0)\n    size = schema['size']\n\n    # based on https://github.com/apache/avro/pull/82/\n\n    sign, digits, exp = data.as_tuple()\n\n    if -exp > scale:\n        raise ValueError(\n            'Scale provided in schema does not match the decimal')\n    delta = exp + scale\n    if delta > 0:\n        digits = digits + (0,) * delta\n\n    unscaled_datum = 0\n    for digit in digits:\n        unscaled_datum = (unscaled_datum * 10) + digit\n\n    bits_req = unscaled_datum.bit_length() + 1\n\n    size_in_bits = size * 8\n    offset_bits = size_in_bits - bits_req\n\n    mask = 2 ** size_in_bits - 1\n    bit = 1\n    for i in range(bits_req):\n        mask ^= bit\n        bit <<= 1\n\n    if bits_req < 8:\n        bytes_req = 1\n    else:\n        bytes_req = bits_req // 8\n        if bits_req % 8 != 0:\n            bytes_req += 1\n\n    tmp = MemoryIO()\n\n    if sign:\n        unscaled_datum = (1 << bits_req) - unscaled_datum\n        unscaled_datum = mask | unscaled_datum\n        for index in range(size - 1, -1, -1):\n            bits_to_write = unscaled_datum >> (8 * index)\n            tmp.write(mk_bits(bits_to_write & 0xff))\n    else:\n        for i in range(offset_bits // 8):\n            tmp.write(mk_bits(0))\n        for index in range(bytes_req - 1, -1, -1):\n            bits_to_write = unscaled_datum >> (8 * index)\n            tmp.write(mk_bits(bits_to_write & 0xff))\n\n    return tmp.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_int(fo, datum, schema=None):\n    datum = (datum << 1) ^ (datum >> 63)\n    while (datum & ~0x7F) != 0:\n        fo.write(pack('B', (datum & 0x7f) | 0x80))\n        datum >>= 7\n    fo.write(pack('B', datum))", "response": "Writes an integer to the file - like object fo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_bytes(fo, datum, schema=None):\n    write_long(fo, len(datum))\n    fo.write(datum)", "response": "Writes a byte array to the file - like object fo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_crc32(fo, bytes):\n    data = crc32(bytes) & 0xFFFFFFFF\n    fo.write(pack('>I', data))", "response": "A 4 - byte big - endian CRC32 checksum"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_array(fo, datum, schema):\n\n    if len(datum) > 0:\n        write_long(fo, len(datum))\n        dtype = schema['items']\n        for item in datum:\n            write_data(fo, item, dtype)\n    write_long(fo, 0)", "response": "Writes the data in datum to the file - like object fo."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_map(fo, datum, schema):\n    if len(datum) > 0:\n        write_long(fo, len(datum))\n        vtype = schema['values']\n        for key, val in iteritems(datum):\n            write_utf8(fo, key)\n            write_data(fo, val, vtype)\n    write_long(fo, 0)", "response": "Writes a map to the file - like object fo."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_union(fo, datum, schema):\n\n    if isinstance(datum, tuple):\n        (name, datum) = datum\n        for index, candidate in enumerate(schema):\n            if extract_record_type(candidate) == 'record':\n                schema_name = candidate['name']\n            else:\n                schema_name = candidate\n            if name == schema_name:\n                break\n        else:\n            msg = 'provided union type name %s not found in schema %s' \\\n              % (name, schema)\n            raise ValueError(msg)\n    else:\n        pytype = type(datum)\n        best_match_index = -1\n        most_fields = -1\n        for index, candidate in enumerate(schema):\n            if validate(datum, candidate, raise_errors=False):\n                if extract_record_type(candidate) == 'record':\n                    fields = len(candidate['fields'])\n                    if fields > most_fields:\n                        best_match_index = index\n                        most_fields = fields\n                else:\n                    best_match_index = index\n                    break\n        if best_match_index < 0:\n            msg = '%r (type %s) do not match %s' % (datum, pytype, schema)\n            raise ValueError(msg)\n        index = best_match_index\n\n    # write data\n    write_long(fo, index)\n    write_data(fo, datum, schema[index])", "response": "Write a union of the data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_record(fo, datum, schema):\n    for field in schema['fields']:\n        name = field['name']\n        if name not in datum and 'default' not in field and \\\n                'null' not in field['type']:\n            raise ValueError('no value and no default for %s' % name)\n        write_data(fo, datum.get(\n            name, field.get('default')), field['type'])", "response": "Writes a record to the file - like object fo."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a datum of data to output stream.", "response": "def write_data(fo, datum, schema):\n    \"\"\"Write a datum of data to output stream.\n\n    Paramaters\n    ----------\n    fo: file-like\n        Output file\n    datum: object\n        Data to write\n    schema: dict\n        Schemda to use\n    \"\"\"\n\n    record_type = extract_record_type(schema)\n    logical_type = extract_logical_type(schema)\n\n    fn = WRITERS.get(record_type)\n    if fn:\n        if logical_type:\n            prepare = LOGICAL_WRITERS.get(logical_type)\n            if prepare:\n                datum = prepare(datum, schema)\n        return fn(fo, datum, schema)\n    else:\n        return write_data(fo, datum, SCHEMA_DEFS[record_type])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites block in null codec.", "response": "def null_write_block(fo, block_bytes):\n    \"\"\"Write block in \"null\" codec.\"\"\"\n    write_long(fo, len(block_bytes))\n    fo.write(block_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a block in deflate codec.", "response": "def deflate_write_block(fo, block_bytes):\n    \"\"\"Write block in \"deflate\" codec.\"\"\"\n    # The first two characters and last character are zlib\n    # wrappers around deflate data.\n    data = compress(block_bytes)[2:-1]\n\n    write_long(fo, len(data))\n    fo.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite records to fo according to schema.", "response": "def writer(fo,\n           schema,\n           records,\n           codec='null',\n           sync_interval=1000 * SYNC_SIZE,\n           metadata=None,\n           validator=None,\n           sync_marker=None):\n    \"\"\"Write records to fo (stream) according to schema\n\n    Parameters\n    ----------\n    fo: file-like\n        Output stream\n    records: iterable\n        Records to write. This is commonly a list of the dictionary\n        representation of the records, but it can be any iterable\n    codec: string, optional\n        Compression codec, can be 'null', 'deflate' or 'snappy' (if installed)\n    sync_interval: int, optional\n        Size of sync interval\n    metadata: dict, optional\n        Header metadata\n    validator: None, True or a function\n        Validator function. If None (the default) - no validation. If True then\n        then fastavro.validation.validate will be used. If it's a function, it\n        should have the same signature as fastavro.writer.validate and raise an\n        exeption on error.\n    sync_marker: bytes, optional\n        A byte string used as the avro sync marker. If not provided, a random\n        byte string will be used.\n\n\n    Example::\n\n        from fastavro import writer, parse_schema\n\n        schema = {\n            'doc': 'A weather reading.',\n            'name': 'Weather',\n            'namespace': 'test',\n            'type': 'record',\n            'fields': [\n                {'name': 'station', 'type': 'string'},\n                {'name': 'time', 'type': 'long'},\n                {'name': 'temp', 'type': 'int'},\n            ],\n        }\n        parsed_schema = parse_schema(schema)\n\n        records = [\n            {u'station': u'011990-99999', u'temp': 0, u'time': 1433269388},\n            {u'station': u'011990-99999', u'temp': 22, u'time': 1433270389},\n            {u'station': u'011990-99999', u'temp': -11, u'time': 1433273379},\n            {u'station': u'012650-99999', u'temp': 111, u'time': 1433275478},\n        ]\n\n        with open('weather.avro', 'wb') as out:\n            writer(out, parsed_schema, records)\n\n    Given an existing avro file, it's possible to append to it by re-opening\n    the file in `a+b` mode. If the file is only opened in `ab` mode, we aren't\n    able to read some of the existing header information and an error will be\n    raised. For example::\n\n        # Write initial records\n        with open('weather.avro', 'wb') as out:\n            writer(out, parsed_schema, records)\n\n        # Write some more records\n        with open('weather.avro', 'a+b') as out:\n            writer(out, parsed_schema, more_records)\n    \"\"\"\n    # Sanity check that records is not a single dictionary (as that is a common\n    # mistake and the exception that gets raised is not helpful)\n    if isinstance(records, dict):\n        raise ValueError('\"records\" argument should be an iterable, not dict')\n\n    output = Writer(\n        fo,\n        schema,\n        codec,\n        sync_interval,\n        metadata,\n        validator,\n        sync_marker,\n    )\n\n    for record in records:\n        output.write(record)\n    output.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a single record without the schema or header information.", "response": "def schemaless_writer(fo, schema, record):\n    \"\"\"Write a single record without the schema or header information\n\n    Parameters\n    ----------\n    fo: file-like\n        Output file\n    schema: dict\n        Schema\n    record: dict\n        Record to write\n\n\n    Example::\n\n        parsed_schema = fastavro.parse_schema(schema)\n        with open('file.avro', 'rb') as fp:\n            fastavro.schemaless_writer(fp, parsed_schema, record)\n\n    Note: The ``schemaless_writer`` can only write a single record.\n    \"\"\"\n    schema = parse_schema(schema)\n    write_data(fo, record, schema)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_int(datum, **kwargs):\n    return (\n            (isinstance(datum, (int, long, numbers.Integral))\n             and INT_MIN_VALUE <= datum <= INT_MAX_VALUE\n             and not isinstance(datum, bool))\n            or isinstance(\n                datum, (datetime.time, datetime.datetime, datetime.date)\n            )\n    )", "response": "Validate that the data value is a valid Int32."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating that the data value is a valid long64.", "response": "def validate_long(datum, **kwargs):\n    \"\"\"\n    Check that the data value is a non floating\n    point number with size less that long64.\n    * Also support for logicalType timestamp validation with datetime.\n\n    Int64 = -9223372036854775808 <= datum <= 9223372036854775807\n\n    conditional python types\n    (int, long, numbers.Integral,\n    datetime.time, datetime.datetime, datetime.date)\n\n    :Parameters\n    ----------\n    datum: Any\n        Data being validated\n    kwargs: Any\n        Unused kwargs\n    \"\"\"\n    return (\n            (isinstance(datum, (int, long, numbers.Integral))\n             and LONG_MIN_VALUE <= datum <= LONG_MAX_VALUE\n             and not isinstance(datum, bool))\n            or isinstance(\n                datum, (datetime.time, datetime.datetime, datetime.date)\n            )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that the data value is a floating point number or double precision.", "response": "def validate_float(datum, **kwargs):\n    \"\"\"\n    Check that the data value is a floating\n    point number or double precision.\n\n    conditional python types\n    (int, long, float, numbers.Real)\n\n    Parameters\n    ----------\n    datum: Any\n        Data being validated\n    kwargs: Any\n        Unused kwargs\n    \"\"\"\n    return (\n        isinstance(datum, (int, long, float, numbers.Real))\n        and not isinstance(datum, bool)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the data value is fixed width bytes and that the size of the datum is exactly equal to the size of the schema.", "response": "def validate_fixed(datum, schema, **kwargs):\n    \"\"\"\n    Check that the data value is fixed width bytes,\n    matching the schema['size'] exactly!\n\n    Parameters\n    ----------\n    datum: Any\n        Data being validated\n    schema: dict\n        Schema\n    kwargs: Any\n        Unused kwargs\n    \"\"\"\n    return (\n            (isinstance(datum, bytes) and len(datum) == schema['size'])\n            or (isinstance(datum, decimal.Decimal))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_array(datum, schema, parent_ns=None, raise_errors=True):\n    return (\n            isinstance(datum, Sequence) and\n            not is_str(datum) and\n            all(validate(datum=d, schema=schema['items'],\n                         field=parent_ns,\n                         raise_errors=raise_errors) for d in datum)\n    )", "response": "Validate that the data list values are all of the specified schema."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate that the data is a Map and that all of its values match the schema s values.", "response": "def validate_map(datum, schema, parent_ns=None, raise_errors=True):\n    \"\"\"\n    Check that the data is a Map(k,v)\n    matching values to schema['values'] type.\n\n    Parameters\n    ----------\n    datum: Any\n        Data being validated\n    schema: dict\n        Schema\n    parent_ns: str\n        parent namespace\n    raise_errors: bool\n        If true, raises ValidationError on invalid data\n    \"\"\"\n    return (\n            isinstance(datum, Mapping) and\n            all(is_str(k) for k in iterkeys(datum)) and\n            all(validate(datum=v, schema=schema['values'],\n                         field=parent_ns,\n                         raise_errors=raise_errors) for v in itervalues(datum))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_record(datum, schema, parent_ns=None, raise_errors=True):\n    _, namespace = schema_name(schema, parent_ns)\n    return (\n        isinstance(datum, Mapping) and\n        all(validate(datum=datum.get(f['name'], f.get('default', no_value)),\n                     schema=f['type'],\n                     field='{}.{}'.format(namespace, f['name']),\n                     raise_errors=raise_errors)\n            for f in schema['fields']\n            )\n    )", "response": "Validate that the data is a Mapping type with all schema defined fields\n    validated as True."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate that the data is a list of types with possible options to validate as True.", "response": "def validate_union(datum, schema, parent_ns=None, raise_errors=True):\n    \"\"\"\n    Check that the data is a list type with possible options to\n    validate as True.\n\n    Parameters\n    ----------\n    datum: Any\n        Data being validated\n    schema: dict\n        Schema\n    parent_ns: str\n        parent namespace\n    raise_errors: bool\n        If true, raises ValidationError on invalid data\n    \"\"\"\n    if isinstance(datum, tuple):\n        (name, datum) = datum\n        for candidate in schema:\n            if extract_record_type(candidate) == 'record':\n                if name == candidate[\"name\"]:\n                    return validate(datum, schema=candidate,\n                                    field=parent_ns,\n                                    raise_errors=raise_errors)\n        else:\n            return False\n\n    errors = []\n    for s in schema:\n        try:\n            ret = validate(datum, schema=s,\n                           field=parent_ns,\n                           raise_errors=raise_errors)\n            if ret:\n                # We exit on the first passing type in Unions\n                return True\n        except ValidationError as e:\n            errors.extend(e.errors)\n    if raise_errors:\n        raise ValidationError(*errors)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate(datum, schema, field=None, raise_errors=True):\n    record_type = extract_record_type(schema)\n    result = None\n\n    validator = VALIDATORS.get(record_type)\n    if validator:\n        result = validator(datum, schema=schema,\n                           parent_ns=field,\n                           raise_errors=raise_errors)\n    elif record_type in SCHEMA_DEFS:\n        result = validate(datum,\n                          schema=SCHEMA_DEFS[record_type],\n                          field=field,\n                          raise_errors=raise_errors)\n    else:\n        raise UnknownType(record_type)\n\n    if raise_errors and result is False:\n        raise ValidationError(ValidationErrorData(datum, schema, field))\n\n    return result", "response": "Validate a python datum against a schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_many(records, schema, raise_errors=True):\n    errors = []\n    results = []\n    for record in records:\n        try:\n            results.append(validate(record, schema, raise_errors=raise_errors))\n        except ValidationError as e:\n            errors.extend(e.errors)\n    if raise_errors and errors:\n        raise ValidationError(*errors)\n    return all(results)", "response": "Validate a list of data!"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a parsed avro schema", "response": "def parse_schema(schema, _write_hint=True, _force=False):\n    \"\"\"Returns a parsed avro schema\n\n    It is not necessary to call parse_schema but doing so and saving the parsed\n    schema for use later will make future operations faster as the schema will\n    not need to be reparsed.\n\n    Parameters\n    ----------\n    schema: dict\n        Input schema\n    _write_hint: bool\n        Internal API argument specifying whether or not the __fastavro_parsed\n        marker should be added to the schema\n    _force: bool\n        Internal API argument. If True, the schema will always be parsed even\n        if it has been parsed and has the __fastavro_parsed marker\n\n\n    Example::\n\n        from fastavro import parse_schema\n        from fastavro import writer\n\n        parsed_schema = parse_schema(original_schema)\n        with open('weather.avro', 'wb') as out:\n            writer(out, parsed_schema, records)\n    \"\"\"\n    if _force:\n        return _parse_schema(schema, \"\", _write_hint)\n    elif isinstance(schema, dict) and \"__fastavro_parsed\" in schema:\n        return schema\n    else:\n        return _parse_schema(schema, \"\", _write_hint)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a schema from a JSON file at schema_path.", "response": "def load_schema(schema_path):\n    '''\n    Returns a schema loaded from the file at `schema_path`.\n\n    Will recursively load referenced schemas assuming they can be found in\n    files in the same directory and named with the convention\n    `<type_name>.avsc`.\n    '''\n    with open(schema_path) as fd:\n        schema = json.load(fd)\n    schema_dir, schema_file = path.split(schema_path)\n    return _load_schema(schema, schema_dir)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays text in tooltip window", "response": "def showtip(self, text):\n        \"Display text in tooltip window\"\n        self.text = text\n        if self.tipwindow or not self.text:\n            return\n        x, y, cx, cy = self.widget.bbox(\"insert\")\n        x = x + self.widget.winfo_rootx() + 27\n        y = y + cy + self.widget.winfo_rooty() +27\n        self.tipwindow = tw = tk.Toplevel(self.widget)\n        tw.wm_overrideredirect(1)\n        tw.wm_geometry(\"+%d+%d\" % (x, y))\n        try:\n            # For Mac OS\n            tw.tk.call(\"::tk::unsupported::MacWindowStyle\",\n                       \"style\", tw._w,\n                       \"help\", \"noActivates\")\n        except tk.TclError:\n            pass\n        label = tk.Label(tw, text=self.text, justify=tk.LEFT,\n                      background=\"#ffffe0\", foreground=\"black\",\n                      relief=tk.SOLID, borderwidth=1,\n                      font=(\"tahoma\", \"8\", \"normal\"))\n        label.pack(ipadx=1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n\n        self.toplevel.protocol(\"WM_DELETE_WINDOW\", self.__on_window_close)\n        self.toplevel.mainloop()", "response": "Ejecute the main loop."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhiding and show scrollbar as needed. Code from Joe English (JE) at http://wiki.tcl.tk/950", "response": "def _autoscroll(sbar, first, last):\n    \"\"\"Hide and show scrollbar as needed.\n    Code from Joe English (JE) at http://wiki.tcl.tk/950\"\"\"\n    first, last = float(first), float(last)\n    if first <= 0 and last >= 1:\n        sbar.grid_remove()\n    else:\n        sbar.grid()\n    sbar.set(first, last)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a regular polygon", "response": "def create_regpoly(self, x0, y0, x1, y1, sides=0, start=90, extent=360, **kw):\n        \"\"\"Create a regular polygon\"\"\"\n        coords = self.__regpoly_coords(x0, y0, x1, y1, sides, start, extent)\n        return self.canvas.create_polygon(*coords, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __regpoly_coords(self, x0, y0, x1, y1, sides, start, extent):\n\n        coords = []\n        if extent == 0:\n            return coords\n\n        xm = (x0 + x1) / 2.\n        ym = (y0 + y1) / 2.\n        rx = xm - x0\n        ry = ym - y0\n\n        n = sides\n        if n == 0: # 0 sides => circle\n            n = round((rx + ry) * .5)\n            if n < 2:\n                n = 4\n\n        # Extent can be negative\n        dirv = 1 if extent > 0 else -1\n        if abs(extent) > 360:\n            extent = dirv * abs(extent) % 360\n\n        step = dirv * 360 / n\n        numsteps = 1 + extent / float(step)\n        numsteps_int = int(numsteps)\n\n        i = 0\n        while i < numsteps_int:\n            rad = (start - i * step) * DEG2RAD\n            x = rx * math.cos(rad)\n            y = ry * math.sin(rad)\n            coords.append((xm+x, ym-y))\n            i += 1\n\n        # Figure out where last segment should end\n        if numsteps != numsteps_int:\n            # Vecter V1 is last drawn vertext (x,y) from above\n            # Vector V2 is the edge of the polygon\n            rad2 = (start - numsteps_int * step) * DEG2RAD\n            x2 = rx * math.cos(rad2) - x\n            y2 = ry * math.sin(rad2) - y\n\n            # Vector V3 is unit vector in direction we end at\n            rad3 = (start - extent) * DEG2RAD\n            x3 = math.cos(rad3)\n            y3 = math.sin(rad3)\n\n            # Find where V3 crosses V1+V2 => find j s.t.  V1 + kV2 = jV3\n            j = (x*y2 - x2*y) / (x3*y2 - x2*y3)\n\n            coords.append((xm + j * x3, ym - j * y3))\n\n        return coords", "response": "Create the coordinates of the regular polygon specified"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_unused_grid_rc(self):\n\n        if 'columns' in self['layout']:\n            ckeys = tuple(self['layout']['columns'].keys())\n            for key in ckeys:\n                value = int(key)\n                if value > self.max_col:\n                    del self['layout']['columns'][key]\n        if 'rows' in self['layout']:\n            rkeys = tuple(self['layout']['rows'].keys())\n            for key in rkeys:\n                value = int(key)\n                if value > self.max_row:\n                    del self['layout']['rows'][key]", "response": "Deletes unused grid row or cols"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning tk image corresponding to name which is taken form path.", "response": "def get_image(self, path):\n        \"\"\"Return tk image corresponding to name which is taken form path.\"\"\"\n        image = ''\n        name = os.path.basename(path)\n        if not StockImage.is_registered(name):\n            ipath = self.__find_image(path)\n            if ipath is not None:\n                StockImage.register(name, ipath)\n            else:\n                msg = \"Image '{0}' not found in resource paths.\".format(name)\n                logger.warning(msg)\n        try:\n            image = StockImage.get(name)\n        except StockImageException:\n            # TODO: notify something here.\n            pass\n        return image"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_variable(self, varname, vtype=None):\n\n        var_types = ('string', 'int', 'boolean', 'double')\n        vname = varname\n        var = None\n        type_from_name = 'string'  # default type\n        if ':' in varname:\n            type_from_name, vname = varname.split(':')\n            #  Fix incorrect order bug #33\n            if type_from_name not in (var_types):\n                #  Swap order\n                type_from_name, vname = vname, type_from_name\n                if type_from_name not in (var_types):\n                    raise Exception('Undefined variable type in \"{0}\"'.format(varname))\n\n        if vname in self.tkvariables:\n            var = self.tkvariables[vname]\n        else:\n            if vtype is None:\n                # get type from name\n                if type_from_name == 'int':\n                    var = tkinter.IntVar()\n                elif type_from_name == 'boolean':\n                    var = tkinter.BooleanVar()\n                elif type_from_name == 'double':\n                    var = tkinter.DoubleVar()\n                else:\n                    var = tkinter.StringVar()\n            else:\n                var = vtype()\n\n            self.tkvariables[vname] = var\n        return var", "response": "Create a tk variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_from_file(self, fpath):\n        if self.tree is None:\n            base, name = os.path.split(fpath)\n            self.add_resource_path(base)\n            self.tree = tree = ET.parse(fpath)\n            self.root = tree.getroot()\n            self.objects = {}\n        else:\n            # TODO: append to current tree\n            pass", "response": "Load ui definition from file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_from_string(self, strdata):\n        if self.tree is None:\n            self.tree = tree = ET.ElementTree(ET.fromstring(strdata))\n            self.root = tree.getroot()\n            self.objects = {}\n        else:\n            # TODO: append to current tree\n            pass", "response": "Load ui definition from string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading ui definition from xml. etree. Element node.", "response": "def add_from_xmlnode(self, element):\n        \"\"\"Load ui definition from xml.etree.Element node.\"\"\"\n        if self.tree is None:\n            root = ET.Element('interface')\n            root.append(element)\n            self.tree = tree = ET.ElementTree(root)\n            self.root = tree.getroot()\n            self.objects = {}\n            # ET.dump(tree)\n        else:\n            # TODO: append to current tree\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind and create the widget named name. Use master as parent.", "response": "def get_object(self, name, master=None):\n        \"\"\"Find and create the widget named name.\n        Use master as parent. If widget was already created, return\n        that instance.\"\"\"\n        widget = None\n        if name in self.objects:\n            widget = self.objects[name].widget\n        else:\n            xpath = \".//object[@id='{0}']\".format(name)\n            node = self.tree.find(xpath)\n            if node is not None:\n                root = BuilderObject(self, dict())\n                root.widget = master\n                bobject = self._realize(root, node)\n                widget = bobject.widget\n        if widget is None:\n            msg = 'Widget \"{0}\" not defined.'.format(name)\n            raise Exception(msg)\n        return widget"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a widget from xml element using master as parent.", "response": "def _realize(self, master, element):\n        \"\"\"Builds a widget from xml element using master as parent.\"\"\"\n\n        data = data_xmlnode_to_dict(element, self.translator)\n        cname = data['class']\n        uniqueid = data['id']\n\n        if cname not in CLASS_MAP:\n            self._import_class(cname)\n\n        if cname in CLASS_MAP:\n            self._pre_process_data(data)\n            parent = CLASS_MAP[cname].builder.factory(self, data)\n            widget = parent.realize(master)\n\n            self.objects[uniqueid] = parent\n\n            xpath = \"./child\"\n            children = element.findall(xpath)\n            for child in children:\n                child_xml = child.find('./object')\n                child = self._realize(parent, child_xml)\n                parent.add_child(child)\n\n            parent.configure()\n            parent.layout()\n            return parent\n        else:\n            raise Exception('Class \"{0}\" not mapped'.format(cname))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect_callbacks(self, callbacks_bag):\n        notconnected = []\n        for wname, builderobj in self.objects.items():\n            missing = builderobj.connect_commands(callbacks_bag)\n            if missing is not None:\n                notconnected.extend(missing)\n            missing = builderobj.connect_bindings(callbacks_bag)\n            if missing is not None:\n                notconnected.extend(missing)\n        if notconnected:\n            notconnected = list(set(notconnected))\n            msg = 'Missing callbacks for commands: {}'.format(notconnected)\n            logger.warning(msg)\n            return notconnected\n        else:\n            return None", "response": "Connect callbacks specified in callbacks_bag with callbacks\n        defined in the ui definition. Return a list with the name of the callbacks not connected."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _start_selecting(self, event):\n        self._selecting = True\n        canvas = self._canvas\n        x = canvas.canvasx(event.x)\n        y = canvas.canvasy(event.y)\n        self._sstart = (x, y)\n        if not self._sobject:\n            self._sobject = canvas.create_rectangle(\n                self._sstart[0], self._sstart[1], x, y,\n                dash=(3,5), outline='#0000ff'\n            )\n        canvas.itemconfigure(self._sobject, state=tk.NORMAL)", "response": "Comienza con el proceso de seleccion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _finish_selecting(self, event):\n        self._selecting = False\n        canvas = self._canvas\n        x = canvas.canvasx(event.x)\n        y = canvas.canvasy(event.y)\n        \n        canvas.coords(self._sobject, -1, -1, -1, -1)\n        canvas.itemconfigure(self._sobject, state=tk.HIDDEN)\n\n        sel_region = self._sstart[0], self._sstart[1], x, y\n        canvas.region_selected = sel_region\n        canvas.event_generate('<<RegionSelected>>')", "response": "Finaliza la seleccion.\n        Marca como seleccionados todos los objetos que se encuentran\n        dentro del recuadro de seleccion."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_onmousewheel_cb(widget, orient, factor = 1):\n        _os = platform.system()\n        view_command = getattr(widget, orient+'view')\n        if _os in ('Linux', 'OpenBSD', 'FreeBSD'):\n            def on_mousewheel(event):\n                if event.num == 4:\n                    view_command('scroll', (-1)*factor, 'units')\n                elif event.num == 5:\n                    view_command('scroll', factor, 'units') \n        \n        elif _os == 'Windows':\n            def on_mousewheel(event):        \n                view_command('scroll', (-1)*int((event.delta/120)*factor), 'units') \n        \n        elif _os == 'Darwin':\n            def on_mousewheel(event):        \n                view_command('scroll', event.delta, 'units')\n        else:\n            # FIXME: unknown platform scroll method\n            def on_mousewheel(event):\n                pass\n        \n        return on_mousewheel", "response": "Create a callback to manage mousewheel events."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __obj2choices(self, values):\n        choices = values\n        # choices from string\n        if type(values) == type(''):\n            obj = None\n            # try json string\n            try:\n                obj = json.loads(values)\n            except ValueError:\n                obj = values\n            if type(obj) == type([]):\n                choices = obj\n            else:\n                choices = obj.split()\n        return choices", "response": "Convert a string to a list of key value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a list of key value pairs into a list of tkvalues", "response": "def __choices2tkvalues(self, choices):\n        \"\"\"choices: iterable of key, value pairs\"\"\"\n        values = []\n        for k, v in choices:\n            values.append(v)\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef matrix_coords(rows, cols, rowh, colw, ox=0, oy=0):\n    \"Generate coords for a matrix of rects\"\n    for i, f, c in rowmajor(rows, cols):\n        x = ox + c * colw\n        y = oy + f * rowh\n        x1 = x + colw\n        y1 = y + rowh\n        yield (i, x, y, x1, y1)", "response": "Generate coords for a matrix of rects"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mark_day(self, day, month=None, year=None):\n        self._remark_date(day, month, year, highlight=True)", "response": "Marks the specified month day with a visual marker."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary that represents the Tcl array", "response": "def get(self):\n        '''Return a dictionary that represents the Tcl array'''\n        value = {}\n        for (elementname, elementvar) in self._elementvars.items():\n            value[elementname] = elementvar.get()\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates inplace widgets position when doing vertical scroll", "response": "def yview(self, *args):\n        \"\"\"Update inplace widgets position when doing vertical scroll\"\"\"\n        self.after_idle(self.__updateWnds)\n        ttk.Treeview.yview(self, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xview(self, *args):\n        self.after_idle(self.__updateWnds)\n        ttk.Treeview.xview(self, *args)", "response": "Update inplace widgets position when doing horizontal scroll"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the focus has changed", "response": "def __check_focus(self, event):\n        \"\"\"Checks if the focus has changed\"\"\"\n        #print('Event:', event.type, event.x, event.y)\n        changed = False\n        if not self._curfocus:\n            changed = True\n        elif self._curfocus != self.focus():\n            self.__clear_inplace_widgets()\n            changed = True\n        newfocus = self.focus()\n        if changed:\n            if newfocus:\n                #print('Focus changed to:', newfocus)\n                self._curfocus= newfocus\n                self.__focus(newfocus)\n            self.__updateWnds()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __focus(self, item):\n        cols = self.__get_display_columns()\n        for col in cols:\n            self.__event_info =(col,item)\n            self.event_generate('<<TreeviewInplaceEdit>>')\n            if col in self._inplace_widgets:\n                w = self._inplace_widgets[col]\n                w.bind('<Key-Tab>',\n                    lambda e: w.tk_focusNext().focus_set())\n                w.bind('<Shift-Key-Tab>',\n                    lambda e: w.tk_focusPrev().focus_set())", "response": "Called when focus item has changed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove all inplace edit widgets.", "response": "def __clear_inplace_widgets(self):\n        \"\"\"Remove all inplace edit widgets.\"\"\"\n        cols = self.__get_display_columns()\n        #print('Clear:', cols)\n        for c in cols:\n            if c in self._inplace_widgets:\n                widget = self._inplace_widgets[c]\n                widget.place_forget()\n                self._inplace_widgets_show.pop(c, None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        install.run(self)\n\n        #\n        # Remove old pygubu.py from scripts path if exists\n        spath = os.path.join(self.install_scripts, 'pygubu')\n        for ext in ('.py', '.pyw'):\n            filename = spath + ext\n            if os.path.exists(filename):\n                os.remove(filename)\n        #\n        # Remove old pygubu-designer.bat\n        if platform.system() == 'Windows':\n            spath = os.path.join(self.install_scripts, 'pygubu-designer.bat')\n            if os.path.exists(spath):\n                os.remove(spath)", "response": "Run parent install and then save the install dir in the script."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npopulates a frame with a list of all editable properties", "response": "def _create_properties(self):\n        \"\"\"Populate a frame with a list of all editable properties\"\"\"\n        self._rcbag = {}  # bag for row/column prop editors\n        self._fgrid = f = ttk.Labelframe(self._sframe.innerframe,\n                                         text=_('Grid options:'), padding=5)\n        f.grid(sticky='nswe')\n        #  hack to resize correctly when properties are hidden\n        label = ttk.Label(f)\n        label.grid()\n\n        label_tpl = \"{0}:\"\n        row = 0\n        col = 0\n\n        groups = (\n            ('00', properties.GRID_PROPERTIES, properties.LAYOUT_OPTIONS),\n        )\n\n        for gcode, plist, propdescr in groups:\n            for name in plist:\n                kwdata = propdescr[name]\n                labeltext = label_tpl.format(name)\n                label = ttk.Label(self._fgrid, text=labeltext, anchor=tk.W)\n                label.grid(row=row, column=col, sticky=tk.EW, pady=2)\n                widget = self._create_editor(self._fgrid, name, kwdata)\n                widget.grid(row=row, column=col+1, sticky=tk.EW, pady=2)\n                row += 1\n                self._propbag[gcode+name] = (label, widget)\n\n        # Grid row/col properties\n        #labels\n        gcode = '01'\n        self._fgrc = fgrc = ttk.LabelFrame(self._sframe.innerframe,\n                                           text=_('Grid row/column options:'),\n                                           padding=5)\n        fgrc.grid(row=1, column=0, sticky=tk.NSEW, pady='10 0')\n\n        #hack to resize correctly when properties are hidden\n        label = ttk.Label(fgrc)\n        label.grid()\n\n        row = col = 0\n        icol = 1\n        headers = []\n        for pname in properties.GRID_RC_PROPERTIES:\n            label = ttk.Label(fgrc, text=pname)\n            label.grid(row=row, column=icol)\n            headers.append(label)\n            icol += 1\n        self._internal = {'grc_headers': headers}\n\n        #\n        name_format = '{}_{}_{}'  # {row/column}_{number}_{name}\n        MAX_RC = 50\n        #rowconfig\n        row += 1\n        trow_label = _('Row {0}:')\n        tcol_label = _('Column {0}:')\n        for index in range(0, MAX_RC):\n            labeltext = trow_label.format(index)\n            label = ttk.Label(fgrc, text=labeltext)\n            label.grid(row=row, column=0)\n\n            labeltext = tcol_label.format(index)\n            labelc = ttk.Label(fgrc, text=labeltext)\n            labelc.grid(row=row + MAX_RC, column=0, sticky=tk.E, pady=2)\n\n            icol = 1\n            for pname in properties.GRID_RC_PROPERTIES:\n                kwdata = properties.LAYOUT_OPTIONS[pname]\n\n                alias = name_format.format('row', index, pname)\n                widget = self._create_editor(fgrc, alias, kwdata)\n                widget.grid(row=row, column=icol, pady=2, sticky='ew')\n                self._rcbag[alias] = (label, widget)\n\n                alias = name_format.format('column', index, pname)\n                widget = self._create_editor(fgrc, alias, kwdata)\n                widget.grid(row=row + MAX_RC, column=icol, pady=2, sticky='ew')\n                self._rcbag[alias] = (labelc, widget)\n\n                icol += 1\n            row += 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_properties(self):\n        self._frame = f = ttk.Labelframe(self._sframe.innerframe,\n                                         text=_('Widget properties'))\n        f.grid(sticky='nswe')\n\n        label_tpl = \"{0}:\"\n        row = 0\n        col = 0\n\n        groups = (\n            ('00', _('Required'), properties.WIDGET_REQUIRED_OPTIONS,\n             properties.REQUIRED_OPTIONS),\n            ('01', _('Standard'), properties.WIDGET_STANDARD_OPTIONS,\n             properties.TK_WIDGET_OPTIONS),\n            ('02', _('Specific'), properties.WIDGET_SPECIFIC_OPTIONS,\n             properties.TK_WIDGET_OPTIONS),\n            ('03', _('Custom'), properties.WIDGET_CUSTOM_OPTIONS,\n             properties.CUSTOM_OPTIONS),\n        )\n\n        for gcode, gname, plist, propdescr in groups:\n            padding = '0 0 0 5' if row == 0 else '0 5 0 5'\n            label = ttk.Label(self._frame, text=gname,\n                              font='TkDefaultFont 10 bold', padding=padding,\n                              foreground='#000059')\n            label.grid(row=row, column=0, sticky='we', columnspan=2)\n            row += 1\n            for name in plist:\n                kwdata = propdescr[name]\n                labeltext = label_tpl.format(name)\n                label = ttk.Label(self._frame, text=labeltext, anchor=tk.W)\n                label.grid(row=row, column=col, sticky=tk.EW, pady=2)\n                widget = self._create_editor(self._frame, name, kwdata)\n                widget.grid(row=row, column=col+1, sticky=tk.EW, pady=2)\n                row += 1\n                self._propbag[gcode+name] = (label, widget)\n                logger.debug('Created property: {0}-{1}'.format(gname,name))", "response": "Populate a frame with a list of all editable properties"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhides all properties from property editor.", "response": "def hide_all(self):\n        \"\"\"Hide all properties from property editor.\"\"\"\n        self.current = None\n\n        for _v, (label, widget) in self._propbag.items():\n            label.grid_remove()\n            widget.grid_remove()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates dict with properties marked as readonly", "response": "def _get_init_args(self):\n        \"\"\"Creates dict with properties marked as readonly\"\"\"\n\n        args = {}\n        for rop in self.ro_properties:\n            if rop in self.properties:\n                args[rop] = self.properties[rop]\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _calculate_menu_wh(self):\n        w = iw = 50\n        h = ih = 0\n        # menu.index returns None if there are no choices\n        index = self._menu.index(tk.END)\n        index = index if index is not None else 0\n        count = index + 1\n\n        # First calculate using the font paramters of root menu:\n        font = self._menu.cget('font')\n        font = self._get_font(font)\n        for i in range(0, count):\n            mtype = self._menu.type(i)\n            if mtype == 'tearoff':\n                continue\n            label = 'default'\n            ifont = 'TkMenuFont'\n            if mtype != 'separator':\n                label = self._menu.entrycget(i, 'label')\n                ifont = self._menu.entrycget(i, 'font')\n            wpx = font.measure(label)\n            hpx = font.metrics('linespace')\n            w += wpx\n            if hpx > h:\n                h = hpx * 2\n            # Calculate using font configured for each subitem\n            ifont = self._get_font(ifont)\n            wpx = ifont.measure(label)\n            hpx = ifont.metrics('linespace')\n            iw += wpx\n            if hpx > ih:\n                ih = hpx * 2\n        # Then compare 2 sizes and use the greatest\n        w = max(w, iw, 100)\n        h = max(h, ih, 25)\n        self._cwidth = w + int(w * 0.25)\n        self._cheight = h + int(h * 0.25)", "response": "Calculate widht and height of the menu."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _over_resizer(self, x, y):\n        \"Returns True if mouse is over a resizer\"\n\n        over_resizer = False\n        c = self.canvas\n        ids = c.find_overlapping(x, y, x, y)\n        if ids:\n            o = ids[0]\n            tags = c.gettags(o)\n            if 'resizer' in tags:\n                over_resizer = True\n        return over_resizer", "response": "Returns True if mouse is over a resizer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resize_preview(self, dw, dh):\n        \"Resizes preview that is currently dragged\"\n\n        # identify preview\n        if self._objects_moving:\n            id_ = self._objects_moving[0]\n            tags = self.canvas.gettags(id_)\n            for tag in tags:\n                if tag.startswith('preview_'):\n                    _, ident = tag.split('preview_')\n                    preview = self.previews[ident]\n                    preview.resize_by(dw, dh)\n                    self.move_previews()\n                    break\n        self._update_cregion()", "response": "Resizes preview that is currently dragged"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving previews after a resize event", "response": "def move_previews(self):\n        \"Move previews after a resize event\"\n\n        # calculate new positions\n        min_y = self._calc_preview_ypos()\n        for idx, (key, p) in enumerate(self.previews.items()):\n            new_dy = min_y[idx] - p.y\n            self.previews[key].move_by(0, new_dy)\n        self._update_cregion()\n        self.show_selected(self._sel_id, self._sel_widget)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the previews positions on canvas", "response": "def _calc_preview_ypos(self):\n        \"Calculates the previews positions on canvas\"\n\n        y = 10\n        min_y = [y]\n        for k, p in self.previews.items():\n            y += p.height() + self.padding\n            min_y.append(y)\n        return min_y"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the next coordinates for a preview", "response": "def _get_slot(self):\n        \"Returns the next coordinates for a preview\"\n\n        x = y = 10\n        for k, p in self.previews.items():\n            y += p.height() + self.padding\n        return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing the cache of all the items in the cache.", "response": "def clear_cache(cls):\n        \"\"\"Call this before closing tk root\"\"\"\n        #Prevent tkinter errors on python 2 ??\n        for key in cls._cached:\n            cls._cached[key] = None\n        cls._cached = {}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(cls, key, filename):\n\n        if key in cls._stock:\n            logger.info('Warning, replacing resource ' + str(key))\n        cls._stock[key] = {'type': 'custom', 'filename': filename}\n        logger.info('%s registered as %s' % (filename, key))", "response": "Register a custom image file using key"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a new image data using key", "response": "def register_from_data(cls, key, format, data):\n        \"\"\"Register a image data using key\"\"\"\n\n        if key in cls._stock:\n            logger.info('Warning, replacing resource ' + str(key))\n        cls._stock[key] = {'type': 'data', 'data': data, 'format': format }\n        logger.info('%s registered as %s' % ('data', key))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_created(cls, key, image):\n\n        if key in cls._stock:\n            logger.info('Warning, replacing resource ' + str(key))\n        cls._stock[key] = {'type': 'created', 'image': image}\n        logger.info('%s registered as %s' % ('data', key))", "response": "Register an already created image using key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist files from dir_path and register them as keys", "response": "def register_from_dir(cls, dir_path, prefix=''):\n        \"\"\"List files from dir_path and register images with\n            filename as key (without extension)\n        Additionaly a prefix for the key can be provided,\n        so the resulting key will be prefix + filename\n        \"\"\"\n\n        for filename in os.listdir(dir_path):\n            name, file_ext = os.path.splitext(filename)\n            if file_ext in cls._formats:\n                fkey = '{0}{1}'.format(prefix, name)\n                cls.register(fkey, os.path.join(dir_path, filename))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_image(cls, rkey):\n\n        v = cls._stock[rkey]\n        img = None\n        itype = v['type']\n        if itype in ('stock', 'data'):\n            img = tk.PhotoImage(format=v['format'], data=v['data'])\n        elif itype == 'created':\n            img = v['image']\n        else:\n            img = tk.PhotoImage(file=v['filename'])\n        cls._cached[rkey] = img\n        logger.info('Loaded resource %s.' % rkey)\n        return img", "response": "Load image from file or return the cached instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets image with key rkey.", "response": "def get(cls, rkey):\n        \"\"\"Get image previously registered with key rkey.\n        If key not exist, raise StockImageException\n        \"\"\"\n\n        if rkey in cls._cached:\n            logger.info('Resource %s is in cache.' % rkey)\n            return cls._cached[rkey]\n        if rkey in cls._stock:\n            img = cls._load_image(rkey)\n            return img\n        else:\n            raise StockImageException('StockImage: %s not registered.' % rkey)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config_treeview(self):\n        tree = self.treeview\n        tree.bind('<Double-1>', self.on_treeview_double_click)\n        tree.bind('<<TreeviewSelect>>', self.on_treeview_select, add='+')", "response": "Sets treeview columns and other params"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_toplevel_parent(self, treeitem):\n        tv = self.treeview\n        toplevel_items = tv.get_children()\n\n        item = treeitem\n        while not (item in toplevel_items):\n            item = tv.parent(item)\n\n        return item", "response": "Returns the top level parent for treeitem."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a preview of the selected treeview item", "response": "def draw_widget(self, item):\n        \"\"\"Create a preview of the selected treeview item\"\"\"\n        if item:\n            self.filter_remove(remember=True)\n            selected_id = self.treedata[item]['id']\n            item = self.get_toplevel_parent(item)\n            widget_id = self.treedata[item]['id']\n            wclass = self.treedata[item]['class']\n            xmlnode = self.tree_node_to_xml('', item)\n            self.previewer.draw(item, widget_id, xmlnode, wclass)\n            self.previewer.show_selected(item, selected_id)\n            self.filter_restore()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove selected items from treeview", "response": "def on_treeview_delete_selection(self, event=None):\n        \"\"\"Removes selected items from treeview\"\"\"\n\n        tv = self.treeview\n        selection = tv.selection()\n\n        # Need to remove filter\n        self.filter_remove(remember=True)\n\n        toplevel_items = tv.get_children()\n        parents_to_redraw = set()\n        for item in selection:\n            try:\n                parent = ''\n                if item not in toplevel_items:\n                    parent = self.get_toplevel_parent(item)\n                else:\n                    self.previewer.delete(item)\n                del self.treedata[item]\n                tv.delete(item)\n                self.app.set_changed()\n                if parent:\n                    self._update_max_grid_rc(parent)\n                    parents_to_redraw.add(parent)\n                self.widget_editor.hide_all()\n            except tk.TclError:\n                # Selection of parent and child items ??\n                # TODO: notify something here\n                pass\n        # redraw widgets\n        for item in parents_to_redraw:\n            self.draw_widget(item)\n        # restore filter\n        self.filter_restore()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntraverse treeview and generates an ElementTree object", "response": "def tree_to_xml(self):\n        \"\"\"Traverses treeview and generates a ElementTree object\"\"\"\n\n        # Need to remove filter or hidden items will not be saved.\n        self.filter_remove(remember=True)\n\n        tree = self.treeview\n        root = ET.Element('interface')\n        items = tree.get_children()\n        for item in items:\n            node = self.tree_node_to_xml('', item)\n            root.append(node)\n\n        # restore filter\n        self.filter_restore()\n\n        return ET.ElementTree(root)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a treeview item and children to xml nodes", "response": "def tree_node_to_xml(self, parent, item):\n        \"\"\"Converts a treeview item and children to xml nodes\"\"\"\n\n        tree = self.treeview\n        data = self.treedata[item]\n        node = data.to_xml_node()\n\n        children = tree.get_children(item)\n        for child in children:\n            cnode = ET.Element('child')\n            cwidget = self.tree_node_to_xml(item, child)\n            cnode.append(cwidget)\n            node.append(cnode)\n\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting a new item on the treeview and fills columns from data", "response": "def _insert_item(self, root, data, from_file=False):\n        \"\"\"Insert a item on the treeview and fills columns from data\"\"\"\n\n        tree = self.treeview\n        treelabel = data.get_id()\n        row = col = ''\n        if root != '' and 'layout' in data:\n            row = data.get_layout_property('row')\n            col = data.get_layout_property('column')\n\n            # fix row position when using copy and paste\n            # If collision, increase by 1\n            row_count = self.get_max_row(root)\n            if not from_file and (row_count > int(row) and int(col) == 0):\n                row = str(row_count + 1)\n                data.set_layout_property('row', row)\n\n        image = ''\n        try:\n            image = StockImage.get('16x16-tk.default')\n        except StockImageException:\n            # TODO: notify something here\n            pass\n\n        try:\n            image = StockImage.get('16x16-{0}'.format(data.get_class()))\n        except StockImageException:\n            # TODO: notify something here\n            pass\n\n        values = (data.get_class(), row, col)\n        item = tree.insert(root, 'end', text=treelabel, values=values,\n                           image=image)\n        data.attach(self)\n        self.treedata[item] = data\n\n        # Update grid r/c data\n        self._update_max_grid_rc(root, from_file=True)\n        self.app.set_changed()\n\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_to_clipboard(self):\n        tree = self.treeview\n        # get the selected item:\n        selection = tree.selection()\n        if selection:\n            self.filter_remove(remember=True)\n            root = ET.Element('selection')\n            for item in selection:\n                node = self.tree_node_to_xml('', item)\n                root.append(node)\n            # python2 issue\n            try:\n                text = ET.tostring(root, encoding='unicode')\n            except LookupError:\n                text = ET.tostring(root, encoding='UTF-8')\n            tree.clipboard_clear()\n            tree.clipboard_append(text)\n            self.filter_restore()", "response": "Copies selected items to clipboard."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new item to the treeview.", "response": "def add_widget(self, wclass):\n        \"\"\"Adds a new item to the treeview.\"\"\"\n\n        tree = self.treeview\n        #  get the selected item:\n        selected_item = ''\n        tsel = tree.selection()\n        if tsel:\n            selected_item = tsel[0]\n\n        #  Need to remove filter if set\n        self.filter_remove()\n\n        root = selected_item\n        #  check if the widget can be added at selected point\n        if not self._validate_add(root, wclass, False):\n            #  if not try to add at item parent level\n            parent = tree.parent(root)\n            if parent != root:\n                if self._validate_add(parent, wclass):\n                    root = parent\n                else:\n                    return\n            else:\n                return\n\n        #  root item should be set at this point\n        #  setup properties\n        widget_id = self.get_unique_id(wclass)\n\n        data = WidgetDescr(wclass, widget_id)\n\n        # setup default values for properties\n        for pname in builder.CLASS_MAP[wclass].builder.properties:\n            pdescription = {}\n            if pname in properties.WIDGET_PROPERTIES:\n                pdescription = properties.WIDGET_PROPERTIES[pname]\n            if wclass in pdescription:\n                pdescription = dict(pdescription, **pdescription[wclass])\n            default_value = str(pdescription.get('default', ''))\n            data.set_property(pname, default_value)\n            # default text for widgets with text prop:\n            if pname in ('text', 'label'):\n                data.set_property(pname, widget_id)\n\n        #\n        #  default grid properties\n        #\n        # is_container = builder.CLASS_MAP[wclass].builder.container\n        for prop_name in properties.GRID_PROPERTIES:\n            pdescription = properties.LAYOUT_OPTIONS[prop_name]\n            if wclass in pdescription:\n                pdescription = dict(pdescription, **pdescription[wclass])\n            default_value = str(pdescription.get('default', ''))\n            data.set_layout_property(prop_name, default_value)\n\n        rownum = '0'\n        if root:\n            rownum = str(self.get_max_row(root)+1)\n        data.set_layout_property('row', rownum)\n        data.set_layout_property('column', '0')\n\n        item = self._insert_item(root, data)\n\n        # Do redraw\n        self.draw_widget(item)\n\n        # Select and show the item created\n        tree.after_idle(lambda: tree.selection_set(item))\n        tree.after_idle(lambda: tree.focus(item))\n        tree.after_idle(lambda: tree.see(item))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_file(self, filename):\n\n        self.counter.clear()\n        # python2 issues\n        try:\n            etree = ET.parse(filename)\n        except ET.ParseError:\n            parser = ET.XMLParser(encoding='UTF-8')\n            etree = ET.parse(filename, parser)\n        eroot = etree.getroot()\n\n        self.remove_all()\n        self.previewer.remove_all()\n        self.widget_editor.hide_all()\n\n        self.previewer.resource_paths.append(os.path.dirname(filename))\n        for element in eroot:\n            self.populate_tree('', eroot, element,from_file=True)\n        children = self.treeview.get_children('')\n        for child in children:\n            self.draw_widget(child)\n        self.previewer.show_selected(None, None)", "response": "Load file into treeview"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading xml nodes and populates tree item", "response": "def populate_tree(self, master, parent, element,from_file=False):\n        \"\"\"Reads xml nodes and populates tree item\"\"\"\n\n        data = WidgetDescr(None, None)\n        data.from_xml_node(element)\n        cname = data.get_class()\n        uniqueid = self.get_unique_id(cname, data.get_id())\n        data.set_property('id', uniqueid)\n\n        if cname in builder.CLASS_MAP:\n            pwidget = self._insert_item(master, data,from_file=from_file)\n            xpath = \"./child\"\n            children = element.findall(xpath)\n            for child in children:\n                child_object = child.find('./object')\n                cwidget = self.populate_tree(pwidget, child, child_object,from_file=from_file)\n\n            return pwidget\n        else:\n            raise Exception('Class \"{0}\" not mapped'.format(cname))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate tree colums when itemdata is changed.", "response": "def update_event(self, hint, obj):\n        \"\"\"Updates tree colums when itemdata is changed.\"\"\"\n\n        tree = self.treeview\n        data = obj\n        item = self.get_item_by_data(obj)\n        if item:\n            if data.get_id() != tree.item(item, 'text'):\n                tree.item(item, text=data.get_id())\n            # if tree.parent(item) != '' and 'layout' in data:\n            if tree.parent(item) != '':\n                row = data.get_layout_property('row')\n                col = data.get_layout_property('column')\n                values = tree.item(item, 'values')\n                if (row != values[1] or col != values[2]):\n                    values = (data.get_class(), row, col)\n                tree.item(item, values=values)\n            self.draw_widget(item)\n            self.app.set_changed()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_by(self, string):\n\n        self._reatach()\n        if string == '':\n            self.filter_remove()\n            return\n\n        self._expand_all()\n        self.treeview.selection_set('')\n\n        children = self.treeview.get_children('')\n        for item in children:\n            _, detached = self._detach(item)\n            if detached:\n                self._detached.extend(detached)\n        for i, p, idx in self._detached:\n            # txt = self.treeview.item(i, 'text')\n            self.treeview.detach(i)\n        self.filter_on = True", "response": "Filters treeview by a string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _reatach(self):\n        for item, p, idx in self._detached:\n            # The item may have been deleted.\n            if self.treeview.exists(item) and self.treeview.exists(p):\n                self.treeview.move(item, p, idx)\n        self._detached = []", "response": "Reinsert the hidden items."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _detach(self, item):\n        to_detach = []\n        children_det = []\n        children_match = False\n        match_found = False\n\n        value = self.filtervar.get()\n        txt = self.treeview.item(item, 'text').lower()\n        if value in txt:\n            match_found = True\n        else:\n            class_txt = self.treedata[item].get_class().lower()\n            if value in class_txt:\n                match_found = True\n\n        parent = self.treeview.parent(item)\n        idx = self.treeview.index(item)\n        children = self.treeview.get_children(item)\n        if children:\n            for child in children:\n                match, detach = self._detach(child)\n                children_match = children_match | match\n                if detach:\n                    children_det.extend(detach)\n\n        if match_found:\n            if children_det:\n                to_detach.extend(children_det)\n        else:\n            if children_match:\n                if children_det:\n                    to_detach.extend(children_det)\n            else:\n                to_detach.append((item, parent, idx))\n        match_found = match_found | children_match\n        return match_found, to_detach", "response": "Hide items from treeview that do not match the search string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates all gui widgets", "response": "def _create_ui(self):\n        \"\"\"Creates all gui widgets\"\"\"\n\n        self.preview = None\n        self.about_dialog = None\n        self.preferences = None\n        self.builder = pygubu.Builder(translator)\n        self.currentfile = None\n        self.is_changed = False\n\n        uifile = os.path.join(FILE_PATH, \"ui/pygubu-ui.ui\")\n        self.builder.add_from_file(uifile)\n        self.builder.add_resource_path(os.path.join(FILE_PATH, \"images\"))\n\n        #build main ui\n        self.builder.get_object('mainwindow', self.master)\n        toplevel = self.master.winfo_toplevel()\n        menu = self.builder.get_object('mainmenu', toplevel)\n        toplevel['menu'] = menu\n\n        #project name\n        self.project_name = self.builder.get_object('projectname_lbl')\n\n        #Class selector values\n        self.widgetlist_sf = self.builder.get_object(\"widgetlist_sf\")\n        self.widgetlist = self.builder.get_object(\"widgetlist\")\n        self.configure_widget_list()\n\n        #widget tree\n        self.treeview = self.builder.get_object('treeview1')\n        self.bindings_frame = self.builder.get_object('bindingsframe')\n        self.bindings_tree = self.builder.get_object('bindingstree')\n\n        #Preview\n        previewc = self.builder.get_object('preview_canvas')\n        self.previewer = PreviewHelper(previewc)\n        #tree editor\n        self.tree_editor = WidgetsTreeEditor(self)\n\n        self.builder.connect_callbacks(self)\n\n        #Status bar\n        self.statusbar = self.builder.get_object('statusbar')\n        handler = StatusBarHandler(self.statusbar)\n        handler.setLevel(logging.INFO)\n        logger.addHandler(handler)\n        pygubu.builder.logger.addHandler(handler)\n\n        #app grid\n        self.set_resizable()\n\n        #\n        #Application bindings\n        #\n        master = self.master\n        master.bind_all(\n            '<Control-KeyPress-n>',\n            lambda e: self.on_file_menuitem_clicked('file_new'))\n        master.bind_all(\n            '<Control-KeyPress-o>',\n            lambda e: self.on_file_menuitem_clicked('file_open'))\n        master.bind_all(\n            '<Control-KeyPress-s>',\n            lambda e: self.on_file_menuitem_clicked('file_save'))\n        master.bind_all(\n            '<Control-KeyPress-q>',\n            lambda e: self.on_file_menuitem_clicked('file_quit'))\n        master.bind_all(\n            '<Control-KeyPress-i>',\n            lambda e: self.on_edit_menuitem_clicked('edit_item_up'))\n        master.bind_all(\n            '<Control-KeyPress-k>',\n            lambda e: self.on_edit_menuitem_clicked('edit_item_down'))\n        master.bind_all(\n            '<F5>',\n            lambda e: self.tree_editor.preview_in_toplevel())\n        master.bind_all(\n            '<F6>',\n            lambda e: self.previewer.close_toplevel_previews())\n\n        #\n        # Widget bindings\n        #\n        self.tree_editor.treeview.bind(\n            '<Control-KeyPress-c>',\n            lambda e: self.tree_editor.copy_to_clipboard())\n        self.tree_editor.treeview.bind(\n            '<Control-KeyPress-v>',\n            lambda e: self.tree_editor.paste_from_clipboard())\n        self.tree_editor.treeview.bind(\n            '<Control-KeyPress-x>',\n            lambda e: self.tree_editor.cut_to_clipboard())\n        self.tree_editor.treeview.bind(\n            '<KeyPress-Delete>',\n            lambda e: self.on_edit_menuitem_clicked('edit_item_delete'))\n\n        def clear_key_pressed(event, newevent):\n            # when KeyPress, not Ctrl-KeyPress, generate event.\n            if event.keysym_num == ord(event.char):\n                self.tree_editor.treeview.event_generate(newevent)\n        self.tree_editor.treeview.bind('<i>',\n                lambda e: clear_key_pressed(e, '<Up>'))\n        self.tree_editor.treeview.bind('<k>',\n                lambda e: clear_key_pressed(e, '<Down>'))\n\n        #grid move bindings\n        self.tree_editor.treeview.bind(\n            '<Alt-KeyPress-i>',\n            lambda e: self.on_edit_menuitem_clicked('grid_up'))\n        self.tree_editor.treeview.bind(\n            '<Alt-KeyPress-k>',\n            lambda e: self.on_edit_menuitem_clicked('grid_down'))\n        self.tree_editor.treeview.bind(\n            '<Alt-KeyPress-j>',\n            lambda e: self.on_edit_menuitem_clicked('grid_left'))\n        self.tree_editor.treeview.bind(\n            '<Alt-KeyPress-l>',\n            lambda e: self.on_edit_menuitem_clicked('grid_right'))\n            \n        # On preferences save binding\n        self.master.bind('<<PygubuDesignerPreferencesSaved>>', self.on_preferences_saved)\n\n        #\n        # Setup tkk styles\n        #\n        self._setup_styles()\n\n        #\n        # Setup dynamic theme submenu\n        #\n        self._setup_theme_menu()\n\n        #app config\n        top = self.master.winfo_toplevel()\n        try:\n            top.wm_iconname('pygubu')\n            top.tk.call('wm', 'iconphoto', '.', StockImage.get('pygubu'))\n        except StockImageException as e:\n            pass\n\n        self.set_title(_('Pygubu a GUI builder for tkinter'))\n        self.set_size('640x480')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading xml into treeview", "response": "def load_file(self, filename):\n        \"\"\"Load xml into treeview\"\"\"\n\n        self.tree_editor.load_file(filename)\n        self.project_name.configure(text=filename)\n        self.currentfile = filename\n        self.is_changed = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlower the IR into a Gremlin - compatible form.", "response": "def lower_ir(ir_blocks, query_metadata_table, type_equivalence_hints=None):\n    \"\"\"Lower the IR into an IR form that can be represented in Gremlin queries.\n\n    Args:\n        ir_blocks: list of IR blocks to lower into Gremlin-compatible form\n        query_metadata_table: QueryMetadataTable object containing all metadata collected during\n                              query processing, including location metadata (e.g. which locations\n                              are folded or optional).\n        type_equivalence_hints: optional dict of GraphQL interface or type -> GraphQL union.\n                                Used as a workaround for GraphQL's lack of support for\n                                inheritance across \"types\" (i.e. non-interfaces), as well as a\n                                workaround for Gremlin's total lack of inheritance-awareness.\n                                The key-value pairs in the dict specify that the \"key\" type\n                                is equivalent to the \"value\" type, i.e. that the GraphQL type or\n                                interface in the key is the most-derived common supertype\n                                of every GraphQL type in the \"value\" GraphQL union.\n                                Recursive expansion of type equivalence hints is not performed,\n                                and only type-level correctness of this argument is enforced.\n                                See README.md for more details on everything this parameter does.\n                                *****\n                                Be very careful with this option, as bad input here will\n                                lead to incorrect output queries being generated.\n                                *****\n\n    Returns:\n        list of IR blocks suitable for outputting as Gremlin\n    \"\"\"\n    sanity_check_ir_blocks_from_frontend(ir_blocks, query_metadata_table)\n\n    ir_blocks = lower_context_field_existence(ir_blocks, query_metadata_table)\n    ir_blocks = optimize_boolean_expression_comparisons(ir_blocks)\n\n    if type_equivalence_hints:\n        ir_blocks = lower_coerce_type_block_type_data(ir_blocks, type_equivalence_hints)\n\n    ir_blocks = lower_coerce_type_blocks(ir_blocks)\n    ir_blocks = rewrite_filters_in_optional_blocks(ir_blocks)\n    ir_blocks = merge_consecutive_filter_clauses(ir_blocks)\n    ir_blocks = lower_folded_outputs(ir_blocks)\n\n    return ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lower_coerce_type_block_type_data(ir_blocks, type_equivalence_hints):\n    allowed_key_type_spec = (GraphQLInterfaceType, GraphQLObjectType)\n    allowed_value_type_spec = GraphQLUnionType\n\n    # Validate that the type_equivalence_hints parameter has correct types.\n    for key, value in six.iteritems(type_equivalence_hints):\n        if (not isinstance(key, allowed_key_type_spec) or\n                not isinstance(value, allowed_value_type_spec)):\n            msg = (u'Invalid type equivalence hints received! Hint {} ({}) -> {} ({}) '\n                   u'was unexpected, expected a hint in the form '\n                   u'GraphQLInterfaceType -> GraphQLUnionType or '\n                   u'GraphQLObjectType -> GraphQLUnionType'.format(key.name, str(type(key)),\n                                                                   value.name, str(type(value))))\n            raise GraphQLCompilationError(msg)\n\n    # CoerceType blocks only know the name of the type to which they coerce,\n    # and not its corresponding GraphQL type object. Convert the type equivalence hints into\n    # a dict of type name -> set of names of equivalent types, which can be used more readily.\n    equivalent_type_names = {\n        key.name: {x.name for x in value.types}\n        for key, value in six.iteritems(type_equivalence_hints)\n    }\n\n    new_ir_blocks = []\n    for block in ir_blocks:\n        new_block = block\n        if isinstance(block, CoerceType):\n            target_class = get_only_element_from_collection(block.target_class)\n            if target_class in equivalent_type_names:\n                new_block = CoerceType(equivalent_type_names[target_class])\n\n        new_ir_blocks.append(new_block)\n\n    return new_ir_blocks", "response": "Lower CoerceType blocks to explicitly state which types are allowed in the coercion."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlowers CoerceType blocks into Filter blocks with a type - check predicate.", "response": "def lower_coerce_type_blocks(ir_blocks):\n    \"\"\"Lower CoerceType blocks into Filter blocks with a type-check predicate.\"\"\"\n    new_ir_blocks = []\n\n    for block in ir_blocks:\n        new_block = block\n        if isinstance(block, CoerceType):\n            predicate = BinaryComposition(\n                u'contains', Literal(list(block.target_class)), LocalField('@class'))\n            new_block = Filter(predicate)\n\n        new_ir_blocks.append(new_block)\n\n    return new_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rewrite_filters_in_optional_blocks(ir_blocks):\n    new_ir_blocks = []\n    optional_context_depth = 0\n\n    for block in ir_blocks:\n        new_block = block\n        if isinstance(block, CoerceType):\n            raise AssertionError(u'Found a CoerceType block after all such blocks should have been '\n                                 u'lowered to Filter blocks: {}'.format(ir_blocks))\n        elif isinstance(block, Traverse) and block.optional:\n            optional_context_depth += 1\n        elif isinstance(block, Backtrack) and block.optional:\n            optional_context_depth -= 1\n            if optional_context_depth < 0:\n                raise AssertionError(u'Reached negative optional context depth for blocks: '\n                                     u'{}'.format(ir_blocks))\n        elif isinstance(block, Filter) and optional_context_depth > 0:\n            null_check = BinaryComposition(u'=', LocalField('@this'), NullLiteral)\n            new_block = Filter(BinaryComposition(u'||', null_check, block.predicate))\n        else:\n            pass\n\n        new_ir_blocks.append(new_block)\n\n    return new_ir_blocks", "response": "This function takes a list of IR blocks and replaces any CoerceType blocks with CoerceType blocks that are not allowed to exist in Gremlin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the list of IR blocks into Gremlin objects.", "response": "def _convert_folded_blocks(folded_ir_blocks):\n    \"\"\"Convert Filter/Traverse blocks and LocalField expressions within @fold to Gremlin objects.\"\"\"\n    new_folded_ir_blocks = []\n\n    def folded_context_visitor(expression):\n        \"\"\"Transform LocalField objects into their Gremlin-specific counterpart.\"\"\"\n        if not isinstance(expression, LocalField):\n            return expression\n\n        return GremlinFoldedLocalField(expression.field_name)\n\n    for block in folded_ir_blocks:\n        new_block = block\n\n        if isinstance(block, Filter):\n            new_predicate = block.predicate.visit_and_update(folded_context_visitor)\n            new_block = GremlinFoldedFilter(new_predicate)\n        elif isinstance(block, Traverse):\n            new_block = GremlinFoldedTraverse.from_traverse(block)\n        elif isinstance(block, (MarkLocation, Backtrack)):\n            # We remove MarkLocation and Backtrack blocks from the folded blocks output,\n            # since they do not produce any Gremlin output code inside folds.\n            continue\n        else:\n            raise AssertionError(u'Found an unexpected IR block in the folded IR blocks: '\n                                 u'{} {} {}'.format(type(block), block, folded_ir_blocks))\n\n        new_folded_ir_blocks.append(new_block)\n\n    return new_folded_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlowering standard folded output fields into GremlinFoldedContextField objects.", "response": "def lower_folded_outputs(ir_blocks):\n    \"\"\"Lower standard folded output fields into GremlinFoldedContextField objects.\"\"\"\n    folds, remaining_ir_blocks = extract_folds_from_ir_blocks(ir_blocks)\n\n    if not remaining_ir_blocks:\n        raise AssertionError(u'Expected at least one non-folded block to remain: {} {} '\n                             u'{}'.format(folds, remaining_ir_blocks, ir_blocks))\n    output_block = remaining_ir_blocks[-1]\n    if not isinstance(output_block, ConstructResult):\n        raise AssertionError(u'Expected the last non-folded block to be ConstructResult, '\n                             u'but instead was: {} {} '\n                             u'{}'.format(type(output_block), output_block, ir_blocks))\n\n    # Turn folded Filter blocks into GremlinFoldedFilter blocks.\n    converted_folds = {\n        base_fold_location.get_location_name()[0]: _convert_folded_blocks(folded_ir_blocks)\n        for base_fold_location, folded_ir_blocks in six.iteritems(folds)\n    }\n\n    new_output_fields = dict()\n    for output_name, output_expression in six.iteritems(output_block.fields):\n        new_output_expression = output_expression\n\n        # Turn FoldedContextField expressions into GremlinFoldedContextField ones.\n        if isinstance(output_expression, FoldedContextField):\n            # Get the matching folded IR blocks and put them in the new context field.\n            base_fold_location_name = output_expression.fold_scope_location.get_location_name()[0]\n            folded_ir_blocks = converted_folds[base_fold_location_name]\n            new_output_expression = GremlinFoldedContextField(\n                output_expression.fold_scope_location, folded_ir_blocks,\n                output_expression.field_type)\n\n        new_output_fields[output_name] = new_output_expression\n\n    new_ir_blocks = remaining_ir_blocks[:-1]\n    new_ir_blocks.append(ConstructResult(new_output_fields))\n    return new_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the GremlinFoldedContextField is correctly representable.", "response": "def validate(self):\n        \"\"\"Validate that the GremlinFoldedContextField is correctly representable.\"\"\"\n        if not isinstance(self.fold_scope_location, FoldScopeLocation):\n            raise TypeError(u'Expected FoldScopeLocation fold_scope_location, got: {} {}'.format(\n                type(self.fold_scope_location), self.fold_scope_location))\n\n        allowed_block_types = (GremlinFoldedFilter, GremlinFoldedTraverse, Backtrack)\n        for block in self.folded_ir_blocks:\n            if not isinstance(block, allowed_block_types):\n                raise AssertionError(\n                    u'Found invalid block of type {} in folded_ir_blocks: {} '\n                    u'Allowed types are {}.'\n                    .format(type(block), self.folded_ir_blocks, allowed_block_types))\n\n        if not isinstance(self.field_type, GraphQLList):\n            raise ValueError(u'Invalid value of \"field_type\", expected a list type but got: '\n                             u'{}'.format(self.field_type))\n\n        inner_type = strip_non_null_from_type(self.field_type.of_type)\n        if isinstance(inner_type, GraphQLList):\n            raise GraphQLCompilationError(\n                u'Outputting list-valued fields in a @fold context is currently '\n                u'not supported: {} {}'.format(self.fold_scope_location, self.field_type.of_type))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_gremlin(self):\n        self.validate()\n        edge_direction, edge_name = self.fold_scope_location.get_first_folded_edge()\n        validate_safe_string(edge_name)\n\n        inverse_direction_table = {\n            'out': 'in',\n            'in': 'out',\n        }\n        inverse_direction = inverse_direction_table[edge_direction]\n\n        base_location_name, _ = self.fold_scope_location.base_location.get_location_name()\n        validate_safe_string(base_location_name)\n\n        _, field_name = self.fold_scope_location.get_location_name()\n        validate_safe_string(field_name)\n\n        if not self.folded_ir_blocks:\n            # There is no filtering nor type coercions applied to this @fold scope.\n            #\n            # This template generates code like:\n            # (\n            #     (m.base.in_Animal_ParentOf == null) ?\n            #     [] : (\n            #         m.base.in_Animal_ParentOf.collect{entry -> entry.outV.next().uuid}\n            #     )\n            # )\n            template = (\n                u'((m.{base_location_name}.{direction}_{edge_name} == null) ? [] : ('\n                u'm.{base_location_name}.{direction}_{edge_name}.collect{{'\n                u'entry -> entry.{inverse_direction}V.next().{field_name}{maybe_format}'\n                u'}}'\n                u'))'\n            )\n            filter_and_traverse_data = ''\n        else:\n            # There is filtering or type coercions in this @fold scope.\n            #\n            # This template generates code like:\n            # (\n            #     (m.base.in_Animal_ParentOf == null) ?\n            #     [] : (\n            #         m.base.in_Animal_ParentOf\n            #          .collect{entry -> entry.outV.next()}\n            #          .findAll{it.alias.contains($wanted)}\n            #          .collect{it.uuid}\n            #     )\n            # )\n            template = (\n                u'((m.{base_location_name}.{direction}_{edge_name} == null) ? [] : ('\n                u'm.{base_location_name}.{direction}_{edge_name}.collect{{'\n                u'entry -> entry.{inverse_direction}V.next()'\n                u'}}'\n                u'.{filters_and_traverses}'\n                u'.collect{{entry -> entry.{field_name}{maybe_format}}}'\n                u'))'\n            )\n            filter_and_traverse_data = u'.'.join(block.to_gremlin()\n                                                 for block in self.folded_ir_blocks)\n\n        maybe_format = ''\n        inner_type = strip_non_null_from_type(self.field_type.of_type)\n        if GraphQLDate.is_same_type(inner_type):\n            maybe_format = '.format(\"' + STANDARD_DATE_FORMAT + '\")'\n        elif GraphQLDateTime.is_same_type(inner_type):\n            maybe_format = '.format(\"' + STANDARD_DATETIME_FORMAT + '\")'\n\n        template_data = {\n            'base_location_name': base_location_name,\n            'direction': edge_direction,\n            'edge_name': edge_name,\n            'field_name': field_name,\n            'inverse_direction': inverse_direction,\n            'maybe_format': maybe_format,\n            'filters_and_traverses': filter_and_traverse_data,\n        }\n        return template.format(**template_data)", "response": "Return a unicode object with the Gremlin representation of this expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_traverse(cls, traverse_block):\n        if isinstance(traverse_block, Traverse):\n            return cls(traverse_block.direction, traverse_block.edge_name)\n        else:\n            raise AssertionError(u'Tried to initialize an instance of GremlinFoldedTraverse '\n                                 u'with block of type {}'.format(type(traverse_block)))", "response": "Create a GremlinFoldedTraverse block as a copy of the given Traverse block."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_gremlin(self):\n        self.validate()\n        template_data = {\n            'direction': self.direction,\n            'edge_name': self.edge_name,\n            'inverse_direction': 'in' if self.direction == 'out' else 'out'\n        }\n        return (u'collectMany{{entry -> entry.{direction}_{edge_name}'\n                u'.collect{{edge -> edge.{inverse_direction}V.next()}}}}'\n                .format(**template_data))", "response": "Return a unicode object with the Gremlin representation of this block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_referenced_type_equivalences(graphql_types, type_equivalence_hints):\n    referenced_types = set()\n    for graphql_type in graphql_types.values():\n        if isinstance(graphql_type, (GraphQLObjectType, GraphQLInterfaceType)):\n            for _, field in graphql_type.fields.items():\n                if isinstance(field.type, GraphQLList):\n                    referenced_types.add(field.type.of_type.name)\n    return {\n        original: union\n        for original, union in type_equivalence_hints.items()\n        if union.name in referenced_types\n    }", "response": "Filter union types with no edges from the type equivalence hints dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary describing the field type overrides in subclasses.", "response": "def _get_inherited_field_types(class_to_field_type_overrides, schema_graph):\n    \"\"\"Return a dictionary describing the field type overrides in subclasses.\"\"\"\n    inherited_field_type_overrides = dict()\n    for superclass_name, field_type_overrides in class_to_field_type_overrides.items():\n        for subclass_name in schema_graph.get_subclass_set(superclass_name):\n            inherited_field_type_overrides.setdefault(subclass_name, dict())\n            inherited_field_type_overrides[subclass_name].update(field_type_overrides)\n    return inherited_field_type_overrides"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassert that the fields we want to override are not defined in superclasses.", "response": "def _validate_overriden_fields_are_not_defined_in_superclasses(class_to_field_type_overrides,\n                                                               schema_graph):\n    \"\"\"Assert that the fields we want to override are not defined in superclasses.\"\"\"\n    for class_name, field_type_overrides in six.iteritems(class_to_field_type_overrides):\n        for superclass_name in schema_graph.get_inheritance_set(class_name):\n            if superclass_name != class_name:\n                superclass = schema_graph.get_element_by_class_name(superclass_name)\n                for field_name in field_type_overrides:\n                    if field_name in superclass.properties:\n                        raise AssertionError(\n                            u'Attempting to override field \"{}\" from class \"{}\", but the field is '\n                            u'defined in superclass \"{}\"'\n                            .format(field_name, class_name, superclass_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _property_descriptor_to_graphql_type(property_obj):\n    property_type = property_obj.type_id\n    scalar_types = {\n        PROPERTY_TYPE_BOOLEAN_ID: GraphQLBoolean,\n        PROPERTY_TYPE_DATE_ID: GraphQLDate,\n        PROPERTY_TYPE_DATETIME_ID: GraphQLDateTime,\n        PROPERTY_TYPE_DECIMAL_ID: GraphQLDecimal,\n        PROPERTY_TYPE_DOUBLE_ID: GraphQLFloat,\n        PROPERTY_TYPE_FLOAT_ID: GraphQLFloat,\n        PROPERTY_TYPE_INTEGER_ID: GraphQLInt,\n        PROPERTY_TYPE_STRING_ID: GraphQLString,\n    }\n\n    result = scalar_types.get(property_type, None)\n    if result:\n        return result\n\n    mapping_types = {\n        PROPERTY_TYPE_EMBEDDED_SET_ID: GraphQLList,\n        PROPERTY_TYPE_EMBEDDED_LIST_ID: GraphQLList,\n    }\n    wrapping_type = mapping_types.get(property_type, None)\n    if wrapping_type:\n        linked_property_obj = property_obj.qualifier\n        # There are properties that are embedded collections of non-primitive types,\n        # for example, ProxyEventSet.scalar_parameters.\n        # The GraphQL compiler does not currently support these.\n        if linked_property_obj in scalar_types:\n            return wrapping_type(scalar_types[linked_property_obj])\n\n    # We weren't able to represent this property in GraphQL, so we'll hide it instead.\n    return None", "response": "Return the best GraphQL type representation for an OrientDB property descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_union_type_name(type_names_to_union):\n    if not type_names_to_union:\n        raise AssertionError(u'Expected a non-empty list of type names to union, received: '\n                             u'{}'.format(type_names_to_union))\n    return u'Union__' + u'__'.join(sorted(type_names_to_union))", "response": "Construct a unique union type name based on the type names being unioned."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_fields_for_class(schema_graph, graphql_types, field_type_overrides, hidden_classes,\n                          cls_name):\n    \"\"\"Return a dict from field name to GraphQL field type, for the specified graph class.\"\"\"\n    properties = schema_graph.get_element_by_class_name(cls_name).properties\n\n    # Add leaf GraphQL fields (class properties).\n    all_properties = {\n        property_name: _property_descriptor_to_graphql_type(property_obj)\n        for property_name, property_obj in six.iteritems(properties)\n    }\n    result = {\n        property_name: graphql_representation\n        for property_name, graphql_representation in six.iteritems(all_properties)\n        if graphql_representation is not None\n    }\n\n    # Add edge GraphQL fields (edges to other vertex classes).\n    schema_element = schema_graph.get_element_by_class_name(cls_name)\n    outbound_edges = (\n        ('out_{}'.format(out_edge_name),\n         schema_graph.get_element_by_class_name(out_edge_name).properties[\n             EDGE_DESTINATION_PROPERTY_NAME].qualifier)\n        for out_edge_name in schema_element.out_connections\n    )\n    inbound_edges = (\n        ('in_{}'.format(in_edge_name),\n         schema_graph.get_element_by_class_name(in_edge_name).properties[\n             EDGE_SOURCE_PROPERTY_NAME].qualifier)\n        for in_edge_name in schema_element.in_connections\n    )\n    for field_name, to_type_name in chain(outbound_edges, inbound_edges):\n        edge_endpoint_type_name = None\n        subclasses = schema_graph.get_subclass_set(to_type_name)\n\n        to_type_abstract = schema_graph.get_element_by_class_name(to_type_name).abstract\n        if not to_type_abstract and len(subclasses) > 1:\n            # If the edge endpoint type has no subclasses, it can't be coerced into any other type.\n            # If the edge endpoint type is abstract (an interface type), we can already\n            # coerce it to the proper type with a GraphQL fragment. However, if the endpoint type\n            # is non-abstract and has subclasses, we need to return its subclasses as an union type.\n            # This is because GraphQL fragments cannot be applied on concrete types, and\n            # GraphQL does not support inheritance of concrete types.\n            type_names_to_union = [\n                subclass\n                for subclass in subclasses\n                if subclass not in hidden_classes\n            ]\n            if type_names_to_union:\n                edge_endpoint_type_name = _get_union_type_name(type_names_to_union)\n        else:\n            if to_type_name not in hidden_classes:\n                edge_endpoint_type_name = to_type_name\n\n        if edge_endpoint_type_name is not None:\n            # If we decided to not hide this edge due to its endpoint type being non-representable,\n            # represent the edge field as the GraphQL type List(edge_endpoint_type_name).\n            result[field_name] = GraphQLList(graphql_types[edge_endpoint_type_name])\n\n    for field_name, field_type in six.iteritems(field_type_overrides):\n        if field_name not in result:\n            raise AssertionError(u'Attempting to override field \"{}\" from class \"{}\", but the '\n                                 u'class does not contain said field'.format(field_name, cls_name))\n        else:\n            result[field_name] = field_type\n\n    return result", "response": "Return a dict from field name to GraphQL field type for the specified graph class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_field_specification(schema_graph, graphql_types, field_type_overrides,\n                                hidden_classes, cls_name):\n    \"\"\"Return a function that specifies the fields present on the given type.\"\"\"\n    def field_maker_func():\n        \"\"\"Create and return the fields for the given GraphQL type.\"\"\"\n        result = EXTENDED_META_FIELD_DEFINITIONS.copy()\n        result.update(OrderedDict([\n            (name, GraphQLField(value))\n            for name, value in sorted(six.iteritems(_get_fields_for_class(\n                schema_graph, graphql_types, field_type_overrides, hidden_classes, cls_name)),\n                key=lambda x: x[0])\n        ]))\n        return result\n\n    return field_maker_func", "response": "Create a function that returns the fields present on the given GraphQL type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_interface_specification(schema_graph, graphql_types, hidden_classes, cls_name):\n    def interface_spec():\n        \"\"\"Return a list of GraphQL interface types implemented by the type named 'cls_name'.\"\"\"\n        abstract_inheritance_set = (\n            superclass_name\n            for superclass_name in sorted(list(schema_graph.get_inheritance_set(cls_name)))\n            if (superclass_name not in hidden_classes and\n                schema_graph.get_element_by_class_name(superclass_name).abstract)\n        )\n\n        return [\n            graphql_types[x]\n            for x in abstract_inheritance_set\n            if x not in hidden_classes\n        ]\n\n    return interface_spec", "response": "Create a function that returns the interfaces implemented by the given type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_union_types_specification(schema_graph, graphql_types, hidden_classes, base_name):\n    # When edges point to vertices of type base_name, and base_name is both non-abstract and\n    # has subclasses, we need to represent the edge endpoint type with a union type based on\n    # base_name and its subclasses. This function calculates what types that union should include.\n    def types_spec():\n        \"\"\"Return a list of GraphQL types that this class' corresponding union type includes.\"\"\"\n        return [\n            graphql_types[x]\n            for x in sorted(list(schema_graph.get_subclass_set(base_name)))\n            if x not in hidden_classes\n        ]\n\n    return types_spec", "response": "Create a function that returns the types that this class corresponds to union types."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_graphql_schema_from_schema_graph(schema_graph, class_to_field_type_overrides,\n                                         hidden_classes):\n    \"\"\"Return a GraphQL schema object corresponding to the schema of the given schema graph.\n\n    Args:\n        schema_graph: SchemaGraph\n        class_to_field_type_overrides: dict, class name -> {field name -> field type},\n                                       (string -> {string -> GraphQLType}). Used to override the\n                                       type of a field in the class where it's first defined and all\n                                       the class's subclasses.\n        hidden_classes: set of strings, classes to not include in the GraphQL schema.\n\n    Returns:\n        tuple of (GraphQL schema object, GraphQL type equivalence hints dict).\n        The tuple is of type (GraphQLSchema, {GraphQLObjectType -> GraphQLUnionType}).\n    \"\"\"\n    _validate_overriden_fields_are_not_defined_in_superclasses(class_to_field_type_overrides,\n                                                               schema_graph)\n\n    # The field types of subclasses must also be overridden.\n    # Remember that the result returned by get_subclass_set(class_name) includes class_name itself.\n    inherited_field_type_overrides = _get_inherited_field_types(class_to_field_type_overrides,\n                                                                schema_graph)\n\n    # We remove the base vertex class from the schema if it has no properties.\n    # If it has no properties, it's meaningless and makes the schema less syntactically sweet.\n    if not schema_graph.get_element_by_class_name(ORIENTDB_BASE_VERTEX_CLASS_NAME).properties:\n        hidden_classes.add(ORIENTDB_BASE_VERTEX_CLASS_NAME)\n\n    graphql_types = OrderedDict()\n    type_equivalence_hints = OrderedDict()\n\n    # For each vertex class, construct its analogous GraphQL type representation.\n    for vertex_cls_name in sorted(schema_graph.vertex_class_names):\n        vertex_cls = schema_graph.get_element_by_class_name(vertex_cls_name)\n        if vertex_cls_name in hidden_classes:\n            continue\n\n        inherited_field_type_overrides.setdefault(vertex_cls_name, dict())\n        field_type_overrides = inherited_field_type_overrides[vertex_cls_name]\n\n        # We have to use delayed type binding here, because some of the type references\n        # are circular: if an edge connects vertices of types A and B, then\n        # GraphQL type A has a List[B] field, and type B has a List[A] field.\n        # To avoid the circular dependency, GraphQL allows us to initialize the types\n        # initially without their field information, and fill in their field information\n        # later using a lambda function as the second argument to GraphQLObjectType.\n        # This lambda function will be called on each type after all types are created\n        # in their initial blank state.\n        #\n        # However, 'cls_name' is a variable that would not be correctly bound\n        # if we naively tried to construct a lambda in-place, because Python lambdas\n        # are not closures. Instead, call a function with 'cls_name' as an argument,\n        # and have that function construct and return the required lambda.\n        field_specification_lambda = _create_field_specification(\n            schema_graph, graphql_types, field_type_overrides, hidden_classes, vertex_cls_name)\n\n        # Abstract classes are interfaces, concrete classes are object types.\n        current_graphql_type = None\n        if vertex_cls.abstract:\n            # \"fields\" is a kwarg in the interface constructor, even though\n            # it's a positional arg in the object type constructor.\n            current_graphql_type = GraphQLInterfaceType(vertex_cls_name,\n                                                        fields=field_specification_lambda)\n        else:\n            # For similar reasons as the field_specification_lambda,\n            # we need to create an interface specification lambda function that\n            # specifies the interfaces implemented by this type.\n            interface_specification_lambda = _create_interface_specification(\n                schema_graph, graphql_types, hidden_classes, vertex_cls_name)\n\n            # N.B.: Ignore the \"is_type_of\" argument below, it is simply a circumvention of\n            #       a sanity check inside the GraphQL library. The library assumes that we'll use\n            #       its execution system, so it complains that we don't provide a means to\n            #       differentiate between different implementations of the same interface.\n            #       We don't care, because we compile the GraphQL query to a database query.\n            current_graphql_type = GraphQLObjectType(vertex_cls_name,\n                                                     field_specification_lambda,\n                                                     interfaces=interface_specification_lambda,\n                                                     is_type_of=lambda: None)\n\n        graphql_types[vertex_cls_name] = current_graphql_type\n\n    # For each vertex class, construct all union types representations.\n    for vertex_cls_name in sorted(schema_graph.vertex_class_names):\n        vertex_cls = schema_graph.get_element_by_class_name(vertex_cls_name)\n        if vertex_cls_name in hidden_classes:\n            continue\n\n        vertex_cls_subclasses = schema_graph.get_subclass_set(vertex_cls_name)\n        if not vertex_cls.abstract and len(vertex_cls_subclasses) > 1:\n            # In addition to creating this class' corresponding GraphQL type, we'll need a\n            # union type to represent it when it appears as the endpoint of an edge.\n            union_type_name = _get_union_type_name(vertex_cls_subclasses)\n\n            # For similar reasons as the field_specification_lambda,\n            # we need to create a union type specification lambda function that specifies\n            # the types that this union type is composed of.\n            type_specification_lambda = _create_union_types_specification(\n                schema_graph, graphql_types, hidden_classes, vertex_cls_name)\n\n            union_type = GraphQLUnionType(union_type_name, types=type_specification_lambda)\n            graphql_types[union_type_name] = union_type\n            type_equivalence_hints[graphql_types[vertex_cls_name]] = union_type\n\n    # Include all abstract non-vertex classes whose only non-abstract subclasses are vertices.\n    for non_graph_cls_name in sorted(schema_graph.non_graph_class_names):\n        if non_graph_cls_name in hidden_classes:\n            continue\n        if not schema_graph.get_element_by_class_name(non_graph_cls_name).abstract:\n            continue\n\n        cls_subclasses = schema_graph.get_subclass_set(non_graph_cls_name)\n        # No need to add the possible abstract class if it doesn't have subclasses besides itself.\n        if len(cls_subclasses) > 1:\n            all_non_abstract_subclasses_are_vertices = True\n\n            # Check all non-abstract subclasses are vertices.\n            for subclass_name in cls_subclasses:\n                subclass = schema_graph.get_element_by_class_name(subclass_name)\n                if subclass_name != non_graph_cls_name:\n                    if not subclass.abstract and not subclass.is_vertex:\n                        all_non_abstract_subclasses_are_vertices = False\n                        break\n\n            if all_non_abstract_subclasses_are_vertices:\n                # Add abstract class as an interface.\n                inherited_field_type_overrides.setdefault(non_graph_cls_name, dict())\n                field_type_overrides = inherited_field_type_overrides[non_graph_cls_name]\n                field_specification_lambda = _create_field_specification(\n                    schema_graph, graphql_types, field_type_overrides, hidden_classes,\n                    non_graph_cls_name)\n                graphql_type = GraphQLInterfaceType(non_graph_cls_name,\n                                                    fields=field_specification_lambda)\n                graphql_types[non_graph_cls_name] = graphql_type\n\n    if not graphql_types:\n        raise EmptySchemaError(u'After evaluating all subclasses of V, we were not able to find '\n                               u'visible schema data to import into the GraphQL schema object')\n\n    # Create the root query GraphQL type. Consists of all non-union classes, i.e.\n    # all non-abstract classes (as GraphQL types) and all abstract classes (as GraphQL interfaces).\n    RootSchemaQuery = GraphQLObjectType('RootSchemaQuery', OrderedDict([\n        (name, GraphQLField(value))\n        for name, value in sorted(six.iteritems(graphql_types), key=lambda x: x[0])\n        if not isinstance(value, GraphQLUnionType)\n    ]))\n\n    schema = GraphQLSchema(RootSchemaQuery, directives=DIRECTIVES)\n\n    # Note that the GraphQLSchema reconstructs the set of types in the schema by recursively\n    # searching through the fields of the RootSchemaQuery. Since union types can only appear in the\n    # fields of other types as edges, union types with no in or out edges will not appear in the\n    # schema. Therefore, we remove these unions and their keys from the type equivalence hints.\n    return schema, _get_referenced_type_equivalences(graphql_types,\n                                                     type_equivalence_hints)", "response": "Returns a GraphQL schema object corresponding to the given schema graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract locations from TernaryConditionals and rewrite their Filter blocks as necessary.", "response": "def workaround_lowering_pass(ir_blocks, query_metadata_table):\n    \"\"\"Extract locations from TernaryConditionals and rewrite their Filter blocks as necessary.\"\"\"\n    new_ir_blocks = []\n\n    for block in ir_blocks:\n        if isinstance(block, Filter):\n            new_block = _process_filter_block(query_metadata_table, block)\n        else:\n            new_block = block\n        new_ir_blocks.append(new_block)\n\n    return new_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_filter_block(query_metadata_table, block):\n    # For a given Filter block with BinaryComposition predicate expression X,\n    # let L be the set of all Locations referenced in any TernaryConditional\n    # predicate expression enclosed in X.\n    # For each location l in L, we construct a tautological expression that looks like:\n    #     ((l IS NULL) OR (l IS NOT NULL))\n    # and then join the original BinaryComposition X with all such expressions with ANDs.\n    # We set this new BinaryComposition expression as the predicate of the Filter block.\n    base_predicate = block.predicate\n\n    # These variables are used by the visitor functions below.\n    ternary_conditionals = []\n    # \"problematic_locations\" is a list and not a set,\n    # to preserve ordering and generate a deterministic order of added clauses.\n    # We expect the maximum size of this list to be a small constant number,\n    # so the linear \"in\" operator is really not a concern.\n    problematic_locations = []\n\n    def find_ternary_conditionals(expression):\n        \"\"\"Visitor function that extracts all enclosed TernaryConditional expressions.\"\"\"\n        if isinstance(expression, TernaryConditional):\n            ternary_conditionals.append(expression)\n        return expression\n\n    def extract_locations_visitor(expression):\n        \"\"\"Visitor function that extracts all the problematic locations.\"\"\"\n        if isinstance(expression, (ContextField, ContextFieldExistence)):\n            # We get the location at the vertex, ignoring property fields.\n            # The vertex-level location is sufficient to work around the OrientDB bug,\n            # and we want as few location as possible overall.\n            location_at_vertex = expression.location.at_vertex()\n            if location_at_vertex not in problematic_locations:\n                problematic_locations.append(location_at_vertex)\n\n        return expression\n\n    # We aren't modifying the base predicate itself, just traversing it.\n    # The returned \"updated\" value must be the exact same as the original.\n    return_value = base_predicate.visit_and_update(find_ternary_conditionals)\n    if return_value is not base_predicate:\n        raise AssertionError(u'Read-only visitor function \"find_ternary_conditionals\" '\n                             u'caused state to change: '\n                             u'{} {}'.format(base_predicate, return_value))\n\n    for ternary in ternary_conditionals:\n        # We aren't modifying the ternary itself, just traversing it.\n        # The returned \"updated\" value must be the exact same as the original.\n        return_value = ternary.visit_and_update(extract_locations_visitor)\n        if return_value is not ternary:\n            raise AssertionError(u'Read-only visitor function \"extract_locations_visitor\" '\n                                 u'caused state to change: '\n                                 u'{} {}'.format(ternary, return_value))\n\n    tautologies = [\n        _create_tautological_expression_for_location(query_metadata_table, location)\n        for location in problematic_locations\n    ]\n\n    if not tautologies:\n        return block\n\n    final_predicate = base_predicate\n    for tautology in tautologies:\n        final_predicate = BinaryComposition(u'&&', final_predicate, tautology)\n    return Filter(final_predicate)", "response": "Process a Filter block."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a Tautological Expression for a given location.", "response": "def _create_tautological_expression_for_location(query_metadata_table, location):\n    \"\"\"For a given location, create a BinaryComposition that always evaluates to 'true'.\"\"\"\n    location_type = query_metadata_table.get_location_info(location).type\n\n    location_exists = BinaryComposition(\n        u'!=', ContextField(location, location_type), NullLiteral)\n    location_does_not_exist = BinaryComposition(\n        u'=', ContextField(location, location_type), NullLiteral)\n    return BinaryComposition(u'||', location_exists, location_does_not_exist)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_only_element_from_collection(one_element_collection):\n    if len(one_element_collection) != 1:\n        raise AssertionError(u'Expected a collection with exactly one element, but got: {}'\n                             .format(one_element_collection))\n    return funcy.first(one_element_collection)", "response": "Assert that the collection has exactly one element then return that element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_ast_field_name(ast):\n    replacements = {\n        # We always rewrite the following field names into their proper underlying counterparts.\n        TYPENAME_META_FIELD_NAME: '@class'\n    }\n    base_field_name = ast.name.value\n    normalized_name = replacements.get(base_field_name, base_field_name)\n    return normalized_name", "response": "Return the normalized field name for the given AST node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_field_type_from_schema(schema_type, field_name):\n    if field_name == '@class':\n        return GraphQLString\n    else:\n        if field_name not in schema_type.fields:\n            raise AssertionError(u'Field {} passed validation but was not present on type '\n                                 u'{}'.format(field_name, schema_type))\n\n        # Validation guarantees that the field must exist in the schema.\n        return schema_type.fields[field_name].type", "response": "Return the type of the field in the given type accounting for field name normalization."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the type of the vertex within the specified vertex field name of the given type.", "response": "def get_vertex_field_type(current_schema_type, vertex_field_name):\n    \"\"\"Return the type of the vertex within the specified vertex field name of the given type.\"\"\"\n    # According to the schema, the vertex field itself is of type GraphQLList, and this is\n    # what get_field_type_from_schema returns. We care about what the type *inside* the list is,\n    # i.e., the type on the other side of the edge (hence .of_type).\n    # Validation guarantees that the field must exist in the schema.\n    if not is_vertex_field_name(vertex_field_name):\n        raise AssertionError(u'Trying to load the vertex field type of a non-vertex field: '\n                             u'{} {}'.format(current_schema_type, vertex_field_name))\n\n    raw_field_type = get_field_type_from_schema(current_schema_type, vertex_field_name)\n    if not isinstance(strip_non_null_from_type(raw_field_type), GraphQLList):\n        raise AssertionError(u'Found an edge whose schema type was not GraphQLList: '\n                             u'{} {} {}'.format(current_schema_type, vertex_field_name,\n                                                raw_field_type))\n    return raw_field_type.of_type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the edge direction and name from a non - root vertex field name.", "response": "def get_edge_direction_and_name(vertex_field_name):\n    \"\"\"Get the edge direction and name from a non-root vertex field name.\"\"\"\n    edge_direction = None\n    edge_name = None\n    if vertex_field_name.startswith(OUTBOUND_EDGE_FIELD_PREFIX):\n        edge_direction = OUTBOUND_EDGE_DIRECTION\n        edge_name = vertex_field_name[len(OUTBOUND_EDGE_FIELD_PREFIX):]\n    elif vertex_field_name.startswith(INBOUND_EDGE_FIELD_PREFIX):\n        edge_direction = INBOUND_EDGE_DIRECTION\n        edge_name = vertex_field_name[len(INBOUND_EDGE_FIELD_PREFIX):]\n    else:\n        raise AssertionError(u'Unreachable condition reached:', vertex_field_name)\n\n    validate_safe_string(edge_name)\n\n    return edge_direction, edge_name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_vertex_field_type(graphql_type):\n    # This will need to change if we ever support complex embedded types or edge field types.\n    underlying_type = strip_non_null_from_type(graphql_type)\n    return isinstance(underlying_type, (GraphQLInterfaceType, GraphQLObjectType, GraphQLUnionType))", "response": "Return True if the argument is a vertex field type and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure the value is a string and return it as unicode.", "response": "def ensure_unicode_string(value):\n    \"\"\"Ensure the value is a string, and return it as unicode.\"\"\"\n    if not isinstance(value, six.string_types):\n        raise TypeError(u'Expected string value, got: {}'.format(value))\n    return six.text_type(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict of name - > object pairs from a list of objects with unique names.", "response": "def get_uniquely_named_objects_by_name(object_list):\n    \"\"\"Return dict of name -> object pairs from a list of objects with unique names.\n\n    Args:\n        object_list: list of objects, each X of which has a unique name accessible as X.name.value\n\n    Returns:\n        dict, { X.name.value: X for x in object_list }\n        If the list is empty or None, returns an empty dict.\n    \"\"\"\n    if not object_list:\n        return dict()\n\n    result = dict()\n    for obj in object_list:\n        name = obj.name.value\n        if name in result:\n            raise GraphQLCompilationError(u'Found duplicate object key: '\n                                          u'{} {}'.format(name, object_list))\n        result[name] = obj\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure the provided string does not contain illegal characters.", "response": "def validate_safe_string(value):\n    \"\"\"Ensure the provided string does not have illegal characters.\"\"\"\n    # The following strings are explicitly allowed, despite having otherwise-illegal chars.\n    legal_strings_with_special_chars = frozenset({'@rid', '@class', '@this', '%'})\n\n    if not isinstance(value, six.string_types):\n        raise TypeError(u'Expected string value, got: {} {}'.format(\n            type(value).__name__, value))\n\n    if not value:\n        raise GraphQLCompilationError(u'Empty strings are not allowed!')\n\n    if value[0] in string.digits:\n        raise GraphQLCompilationError(u'String values cannot start with a digit: {}'.format(value))\n\n    if not set(value).issubset(VARIABLE_ALLOWED_CHARS) and \\\n            value not in legal_strings_with_special_chars:\n        raise GraphQLCompilationError(u'Encountered illegal characters in string: {}'.format(value))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_edge_direction(edge_direction):\n    if not isinstance(edge_direction, six.string_types):\n        raise TypeError(u'Expected string edge_direction, got: {} {}'.format(\n                        type(edge_direction), edge_direction))\n\n    if edge_direction not in ALLOWED_EDGE_DIRECTIONS:\n        raise ValueError(u'Unrecognized edge direction: {}'.format(edge_direction))", "response": "Ensure the provided edge direction is either in or out."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_marked_location(location):\n    if not isinstance(location, (Location, FoldScopeLocation)):\n        raise TypeError(u'Expected Location or FoldScopeLocation location, got: {} {}'.format(\n            type(location).__name__, location))\n\n    if location.field is not None:\n        raise GraphQLCompilationError(u'Cannot mark location at a field: {}'.format(location))", "response": "Validate that a Location object is safe for marking and not at a field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvert a dict. A dict is invertible if values are unique and hashable.", "response": "def invert_dict(invertible_dict):\n    \"\"\"Invert a dict. A dict is invertible if values are unique and hashable.\"\"\"\n    inverted = {}\n    for k, v in six.iteritems(invertible_dict):\n        if not isinstance(v, Hashable):\n            raise TypeError(u'Expected an invertible dict, but value at key {} has type {}'.format(\n                k, type(v).__name__))\n        if v in inverted:\n            raise TypeError(u'Expected an invertible dict, but keys '\n                            u'{} and {} map to the same value'.format(\n                                inverted[v], k))\n        inverted[v] = k\n    return inverted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading package file as text to get name and version", "response": "def read_file(filename):\n    \"\"\"Read package file as text to get name and version\"\"\"\n    # intentionally *not* adding an encoding option to open\n    # see here:\n    # https://github.com/pypa/virtualenv/issues/201#issuecomment-3145690\n    here = os.path.abspath(os.path.dirname(__file__))\n    with codecs.open(os.path.join(here, 'graphql_compiler', filename), 'r') as f:\n        return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlower CoerceType blocks into Filter blocks within Recurse steps.", "response": "def workaround_type_coercions_in_recursions(match_query):\n    \"\"\"Lower CoerceType blocks into Filter blocks within Recurse steps.\"\"\"\n    # This step is required to work around an OrientDB bug that causes queries with both\n    # \"while:\" and \"class:\" in the same query location to fail to parse correctly.\n    #\n    # This bug is reported upstream: https://github.com/orientechnologies/orientdb/issues/8129\n    #\n    # Instead of \"class:\", we use \"INSTANCEOF\" in the \"where:\" clause to get correct behavior.\n    # However, we don't want to switch all coercions to this format, since the \"class:\" clause\n    # provides valuable info to the MATCH query scheduler about how to schedule efficiently.\n    new_match_traversals = []\n\n    for current_traversal in match_query.match_traversals:\n        new_traversal = []\n\n        for match_step in current_traversal:\n            new_match_step = match_step\n\n            has_coerce_type = match_step.coerce_type_block is not None\n            has_recurse_root = isinstance(match_step.root_block, Recurse)\n\n            if has_coerce_type and has_recurse_root:\n                new_where_block = convert_coerce_type_and_add_to_where_block(\n                    match_step.coerce_type_block, match_step.where_block)\n                new_match_step = match_step._replace(coerce_type_block=None,\n                                                     where_block=new_where_block)\n\n            new_traversal.append(new_match_step)\n\n        new_match_traversals.append(new_traversal)\n\n    return match_query._replace(match_traversals=new_match_traversals)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    query = ' '.join(sys.stdin.readlines())\n\n    sys.stdout.write(pretty_print_graphql(query))", "response": "Read a GraphQL query from standard input and output it pretty - printed to standard output."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsanitize and represent a string argument in Gremlin.", "response": "def _safe_gremlin_string(value):\n    \"\"\"Sanitize and represent a string argument in Gremlin.\"\"\"\n    if not isinstance(value, six.string_types):\n        if isinstance(value, bytes):  # should only happen in py3\n            value = value.decode('utf-8')\n        else:\n            raise GraphQLInvalidArgumentError(u'Attempting to convert a non-string into a string: '\n                                              u'{}'.format(value))\n\n    # Using JSON encoding means that all unicode literals and special chars\n    # (e.g. newlines and backslashes) are replaced by appropriate escape sequences.\n    # However, the quoted result is wrapped in double quotes, and $ signs are not escaped,\n    # so that would allow arbitrary code execution in Gremlin.\n    # We will therefore turn the double-quoted string into a single-quoted one to avoid this risk.\n    escaped_and_quoted = json.dumps(value)\n\n    # Double-quoted string literals in Gremlin/Groovy allow\n    # arbitrary code execution via string interpolation and closures.\n    # To avoid this, we perform the following steps:\n    #   - we strip the wrapping double quotes;\n    #   - we un-escape any double-quotes in the string, by replacing \\\" with \";\n    #   - we escape any single-quotes in the string, by replacing ' with \\';\n    #   - finally, we wrap the string in single quotes.\n    # http://www.groovy-lang.org/syntax.html#_double_quoted_string\n    if not escaped_and_quoted[0] == escaped_and_quoted[-1] == '\"':\n        raise AssertionError(u'Unreachable state reached: {} {}'.format(value, escaped_and_quoted))\n    no_quotes = escaped_and_quoted[1:-1]\n    re_escaped = no_quotes.replace('\\\\\"', '\"').replace('\\'', '\\\\\\'')\n\n    final_escaped_value = '\\'' + re_escaped + '\\''\n    return final_escaped_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _safe_gremlin_list(inner_type, argument_value):\n    if not isinstance(argument_value, list):\n        raise GraphQLInvalidArgumentError(u'Attempting to represent a non-list as a list: '\n                                          u'{}'.format(argument_value))\n\n    stripped_type = strip_non_null_from_type(inner_type)\n    components = (\n        _safe_gremlin_argument(stripped_type, x)\n        for x in argument_value\n    )\n    return u'[' + u','.join(components) + u']'", "response": "Represent the list of inner_type objects in Gremlin form."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a Gremlin string representing the given argument value.", "response": "def _safe_gremlin_argument(expected_type, argument_value):\n    \"\"\"Return a Gremlin string representing the given argument value.\"\"\"\n    if GraphQLString.is_same_type(expected_type):\n        return _safe_gremlin_string(argument_value)\n    elif GraphQLID.is_same_type(expected_type):\n        # IDs can be strings or numbers, but the GraphQL library coerces them to strings.\n        # We will follow suit and treat them as strings.\n        if not isinstance(argument_value, six.string_types):\n            if isinstance(argument_value, bytes):  # should only happen in py3\n                argument_value = argument_value.decode('utf-8')\n            else:\n                argument_value = six.text_type(argument_value)\n        return _safe_gremlin_string(argument_value)\n    elif GraphQLFloat.is_same_type(expected_type):\n        return represent_float_as_str(argument_value)\n    elif GraphQLInt.is_same_type(expected_type):\n        # Special case: in Python, isinstance(True, int) returns True.\n        # Safeguard against this with an explicit check against bool type.\n        if isinstance(argument_value, bool):\n            raise GraphQLInvalidArgumentError(u'Attempting to represent a non-int as an int: '\n                                              u'{}'.format(argument_value))\n\n        return type_check_and_str(int, argument_value)\n    elif GraphQLBoolean.is_same_type(expected_type):\n        return type_check_and_str(bool, argument_value)\n    elif GraphQLDecimal.is_same_type(expected_type):\n        return _safe_gremlin_decimal(argument_value)\n    elif GraphQLDate.is_same_type(expected_type):\n        return _safe_gremlin_date_and_datetime(expected_type, (datetime.date,), argument_value)\n    elif GraphQLDateTime.is_same_type(expected_type):\n        return _safe_gremlin_date_and_datetime(expected_type,\n                                               (datetime.datetime, arrow.Arrow), argument_value)\n    elif isinstance(expected_type, GraphQLList):\n        return _safe_gremlin_list(expected_type.of_type, argument_value)\n    else:\n        raise AssertionError(u'Could not safely represent the requested GraphQL type: '\n                             u'{} {}'.format(expected_type, argument_value))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_arguments_into_gremlin_query(compilation_result, arguments):\n    if compilation_result.language != GREMLIN_LANGUAGE:\n        raise AssertionError(u'Unexpected query output language: {}'.format(compilation_result))\n\n    base_query = compilation_result.query\n    argument_types = compilation_result.input_metadata\n\n    # The arguments are assumed to have already been validated against the query.\n    sanitized_arguments = {\n        key: _safe_gremlin_argument(argument_types[key], value)\n        for key, value in six.iteritems(arguments)\n    }\n\n    return Template(base_query).substitute(sanitized_arguments)", "response": "Insert the arguments into the Gremlin query."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_vertex_location_name(location):\n    mark_name, field_name = location.get_location_name()\n    if field_name is not None:\n        raise AssertionError(u'Location unexpectedly pointed to a field: {}'.format(location))\n\n    return mark_name", "response": "Get the location name from a location that is expected to point to a vertex."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _first_step_to_match(match_step):\n    parts = []\n\n    if match_step.root_block is not None:\n        if not isinstance(match_step.root_block, QueryRoot):\n            raise AssertionError(u'Expected None or QueryRoot root block, received: '\n                                 u'{} {}'.format(match_step.root_block, match_step))\n\n        match_step.root_block.validate()\n\n        start_class = get_only_element_from_collection(match_step.root_block.start_class)\n        parts.append(u'class: %s' % (start_class,))\n\n    # MATCH steps with a QueryRoot root block shouldn't have a 'coerce_type_block'.\n    if match_step.coerce_type_block is not None:\n        raise AssertionError(u'Invalid MATCH step: {}'.format(match_step))\n\n    if match_step.where_block:\n        match_step.where_block.validate()\n        parts.append(u'where: (%s)' % (match_step.where_block.predicate.to_match(),))\n\n    if match_step.as_block is None:\n        raise AssertionError(u'Found a MATCH step without a corresponding Location. '\n                             u'This should never happen: {}'.format(match_step))\n    else:\n        match_step.as_block.validate()\n        parts.append(u'as: %s' % (_get_vertex_location_name(match_step.as_block.location),))\n\n    return u'{{ %s }}' % (u', '.join(parts),)", "response": "Transform the very first MATCH step into a MATCH query string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _subsequent_step_to_match(match_step):\n    if not isinstance(match_step.root_block, (Traverse, Recurse)):\n        raise AssertionError(u'Expected Traverse root block, received: '\n                             u'{} {}'.format(match_step.root_block, match_step))\n\n    is_recursing = isinstance(match_step.root_block, Recurse)\n\n    match_step.root_block.validate()\n\n    traversal_command = u'.%s(\\'%s\\')' % (match_step.root_block.direction,\n                                          match_step.root_block.edge_name)\n\n    parts = []\n    if match_step.coerce_type_block:\n        coerce_type_set = match_step.coerce_type_block.target_class\n        if len(coerce_type_set) != 1:\n            raise AssertionError(u'Found MATCH type coercion block with more than one target class:'\n                                 u' {} {}'.format(coerce_type_set, match_step))\n        coerce_type_target = list(coerce_type_set)[0]\n        parts.append(u'class: %s' % (coerce_type_target,))\n\n    if is_recursing:\n        # In MATCH, \"$depth < 1\" means \"include the source vertex and its immediate neighbors.\"\n        # Yes, the \"<\" is intentional -- it's not supposed to be a \"<=\".\n        parts.append(u'while: ($depth < %d)' % (match_step.root_block.depth,))\n\n    if match_step.where_block:\n        match_step.where_block.validate()\n        parts.append(u'where: (%s)' % (match_step.where_block.predicate.to_match(),))\n\n    if not is_recursing and match_step.root_block.optional:\n        parts.append(u'optional: true')\n\n    if match_step.as_block:\n        match_step.as_block.validate()\n        parts.append(u'as: %s' % (_get_vertex_location_name(match_step.as_block.location),))\n\n    return u'%s {{ %s }}' % (traversal_command, u', '.join(parts))", "response": "Transform any subsequent MATCH step into a MATCH query string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _represent_match_traversal(match_traversal):\n    output = []\n\n    output.append(_first_step_to_match(match_traversal[0]))\n    for step in match_traversal[1:]:\n        output.append(_subsequent_step_to_match(step))\n\n    return u''.join(output)", "response": "Emit MATCH query code for an entire MATCH traversal sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a LET clause corresponding to the IR blocks in a fold scope.", "response": "def _represent_fold(fold_location, fold_ir_blocks):\n    \"\"\"Emit a LET clause corresponding to the IR blocks for a @fold scope.\"\"\"\n    start_let_template = u'$%(mark_name)s = %(base_location)s'\n    traverse_edge_template = u'.%(direction)s(\"%(edge_name)s\")'\n    base_template = start_let_template + traverse_edge_template\n    edge_direction, edge_name = fold_location.get_first_folded_edge()\n    mark_name, _ = fold_location.get_location_name()\n    base_location_name, _ = fold_location.base_location.get_location_name()\n\n    validate_safe_string(mark_name)\n    validate_safe_string(base_location_name)\n    validate_safe_string(edge_direction)\n    validate_safe_string(edge_name)\n\n    template_data = {\n        'mark_name': mark_name,\n        'base_location': base_location_name,\n        'direction': edge_direction,\n        'edge_name': edge_name,\n    }\n    final_string = base_template % template_data\n\n    for block in fold_ir_blocks:\n        if isinstance(block, Filter):\n            final_string += u'[' + block.predicate.to_match() + u']'\n        elif isinstance(block, Traverse):\n            template_data = {\n                'direction': block.direction,\n                'edge_name': block.edge_name,\n            }\n            final_string += traverse_edge_template % template_data\n        elif isinstance(block, MarkLocation):\n            # MarkLocation blocks inside a fold do not result in any MATCH output.\n            pass\n        else:\n            raise AssertionError(u'Found an unexpected IR block in the folded IR blocks: '\n                                 u'{} {} {}'.format(type(block), block, fold_ir_blocks))\n\n    # Workaround for OrientDB's inconsistent return type when filtering a list.\n    # https://github.com/orientechnologies/orientdb/issues/7811\n    final_string += '.asList()'\n\n    return final_string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _construct_output_to_match(output_block):\n    output_block.validate()\n\n    selections = (\n        u'%s AS `%s`' % (output_block.fields[key].to_match(), key)\n        for key in sorted(output_block.fields.keys())  # Sort keys for deterministic output order.\n    )\n\n    return u'SELECT %s FROM' % (u', '.join(selections),)", "response": "Transform a ConstructResult block into a MATCH query string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming a Filter block into a MATCH query string.", "response": "def _construct_where_to_match(where_block):\n    \"\"\"Transform a Filter block into a MATCH query string.\"\"\"\n    if where_block.predicate == TrueLiteral:\n        raise AssertionError(u'Received WHERE block with TrueLiteral predicate: {}'\n                             .format(where_block))\n    return u'WHERE ' + where_block.predicate.to_match()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a MATCH query string from a single MATCH query.", "response": "def emit_code_from_single_match_query(match_query):\n    \"\"\"Return a MATCH query string from a list of IR blocks.\"\"\"\n    query_data = deque([u'MATCH '])\n\n    if not match_query.match_traversals:\n        raise AssertionError(u'Unexpected falsy value for match_query.match_traversals received: '\n                             u'{} {}'.format(match_query.match_traversals, match_query))\n\n    # Represent and add the MATCH traversal steps.\n    match_traversal_data = [\n        _represent_match_traversal(x)\n        for x in match_query.match_traversals\n    ]\n    query_data.append(match_traversal_data[0])\n    for traversal_data in match_traversal_data[1:]:\n        query_data.append(u', ')\n        query_data.append(traversal_data)\n\n    query_data.appendleft(u' (')            # Prepare to wrap the MATCH in a SELECT.\n    query_data.append(u'RETURN $matches)')  # Finish the MATCH query and the wrapping ().\n\n    # Represent and add the LET clauses for any @fold scopes that might be part of the query.\n    # Sort for deterministic order of clauses.\n    fold_data = sorted([\n        _represent_fold(fold_location, fold_ir_blocks)\n        for fold_location, fold_ir_blocks in six.iteritems(match_query.folds)\n    ])\n    if fold_data:\n        query_data.append(u' LET ')\n        query_data.append(fold_data[0])\n        for fold_clause in fold_data[1:]:\n            query_data.append(u', ')\n            query_data.append(fold_clause)\n\n    # Represent and add the SELECT clauses with the proper output data.\n    query_data.appendleft(_construct_output_to_match(match_query.output_block))\n\n    # Represent and add the WHERE clause with the proper filters.\n    if match_query.where_block is not None:\n        query_data.append(_construct_where_to_match(match_query.where_block))\n\n    return u' '.join(query_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef emit_code_from_multiple_match_queries(match_queries):\n    optional_variable_base_name = '$optional__'\n    union_variable_name = '$result'\n    query_data = deque([u'SELECT EXPAND(', union_variable_name, u')', u' LET '])\n\n    optional_variables = []\n    sub_queries = [emit_code_from_single_match_query(match_query)\n                   for match_query in match_queries]\n    for (i, sub_query) in enumerate(sub_queries):\n        variable_name = optional_variable_base_name + str(i)\n        variable_assignment = variable_name + u' = ('\n        sub_query_end = u'),'\n        query_data.append(variable_assignment)\n        query_data.append(sub_query)\n        query_data.append(sub_query_end)\n        optional_variables.append(variable_name)\n\n    query_data.append(union_variable_name)\n    query_data.append(u' = UNIONALL(')\n    query_data.append(u', '.join(optional_variables))\n    query_data.append(u')')\n\n    return u' '.join(query_data)", "response": "Return a MATCH query string from a list of MatchQuery namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a MATCH query string from a CompoundMatchQuery.", "response": "def emit_code_from_ir(compound_match_query, compiler_metadata):\n    \"\"\"Return a MATCH query string from a CompoundMatchQuery.\"\"\"\n    # If the compound match query contains only one match query,\n    # just call `emit_code_from_single_match_query`\n    # If there are multiple match queries, construct the query string for each\n    # individual query and combine them as follows.\n    #\n    # SELECT EXPAND($result)\n    # LET\n    #    $optional__0 = (\n    #        <query_string_0>\n    #    ),\n    #    $optional__1 = (\n    #        <query_string_1>\n    #    ),\n    #    $optional__2 = (\n    #        <query_string_2>\n    #    ),\n    #\n    #    . . .\n    #\n    #    $result = UNIONALL($optional__0, $optional__1, . . . )\n\n    match_queries = compound_match_query.match_queries\n    if len(match_queries) == 1:\n        query_string = emit_code_from_single_match_query(match_queries[0])\n    elif len(match_queries) > 1:\n        query_string = emit_code_from_multiple_match_queries(match_queries)\n    else:\n        raise AssertionError(u'Received CompoundMatchQuery with an empty list of MatchQueries: '\n                             u'{}'.format(match_queries))\n\n    return query_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _serialize_date(value):\n    if not isinstance(value, date):\n        raise ValueError(u'The received object was not a date: '\n                         u'{} {}'.format(type(value), value))\n    return value.isoformat()", "response": "Serialize a Date object to its proper ISO - 8601 representation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _serialize_datetime(value):\n    if not isinstance(value, (datetime, arrow.Arrow)):\n        raise ValueError(u'The received object was not a datetime: '\n                         u'{} {}'.format(type(value), value))\n    return value.isoformat()", "response": "Serialize a DateTime object to its proper ISO - 8601 representation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert_meta_fields_into_existing_schema(graphql_schema):\n    root_type_name = graphql_schema.get_query_type().name\n\n    for type_name, type_obj in six.iteritems(graphql_schema.get_type_map()):\n        if type_name.startswith('__') or type_name == root_type_name:\n            # Ignore the types that are built into GraphQL itself, as well as the root query type.\n            continue\n\n        if not isinstance(type_obj, (GraphQLObjectType, GraphQLInterfaceType)):\n            # Ignore definitions that are not interfaces or types.\n            continue\n\n        for meta_field_name, meta_field in six.iteritems(EXTENDED_META_FIELD_DEFINITIONS):\n            if meta_field_name in type_obj.fields:\n                raise AssertionError(u'Unexpectedly encountered an existing field named {} while '\n                                     u'attempting to add a meta-field of the same name. Make sure '\n                                     u'you are not attempting to add meta-fields twice.'\n                                     .format(meta_field_name))\n\n            type_obj.fields[meta_field_name] = meta_field", "response": "Insert compiler - specific meta - fields into all interfaces and types of the specified schema."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_context_for_visiting_vertex_field(parent_location, vertex_field_name, context):\n    if is_in_fold_innermost_scope(context):\n        raise GraphQLCompilationError(\n            u'Traversing inside a @fold block after filtering on {} or outputting fields '\n            u'is not supported! Parent location: {}, vertex field name: {}'\n            .format(COUNT_META_FIELD_NAME, parent_location, vertex_field_name))", "response": "Ensure that the current context allows for visiting a vertex field."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a GraphQL query and pretty print it and return it.", "response": "def pretty_print_graphql(query, use_four_spaces=True):\n    \"\"\"Take a GraphQL query, pretty print it, and return it.\"\"\"\n    # Use our custom visitor, which fixes directive argument order\n    # to get the canonical representation\n    output = visit(parse(query), CustomPrintingVisitor())\n\n    # Using four spaces for indentation makes it easier to edit in\n    # Python source files.\n    if use_four_spaces:\n        return fix_indentation_depth(output)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes indentation use 4 spaces rather than the 2 spaces GraphQL normally uses.", "response": "def fix_indentation_depth(query):\n    \"\"\"Make indentation use 4 spaces, rather than the 2 spaces GraphQL normally uses.\"\"\"\n    lines = query.split('\\n')\n    final_lines = []\n\n    for line in lines:\n        consecutive_spaces = 0\n        for char in line:\n            if char == ' ':\n                consecutive_spaces += 1\n            else:\n                break\n\n        if consecutive_spaces % 2 != 0:\n            raise AssertionError(u'Indentation was not a multiple of two: '\n                                 u'{}'.format(consecutive_spaces))\n\n        final_lines.append(('  ' * consecutive_spaces) + line[consecutive_spaces:])\n\n    return '\\n'.join(final_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef leave_Directive(self, node, *args):\n        name_to_arg_value = {\n            # Taking [0] is ok here because the GraphQL parser checks for the\n            # existence of ':' in directive arguments.\n            arg.split(':', 1)[0]: arg\n            for arg in node.arguments\n        }\n\n        ordered_args = node.arguments\n        directive = DIRECTIVES_BY_NAME.get(node.name)\n        if directive:\n            sorted_args = []\n            encountered_argument_names = set()\n\n            # Iterate through all defined arguments in the directive schema.\n            for defined_arg_name in six.iterkeys(directive.args):\n                if defined_arg_name in name_to_arg_value:\n                    # The argument was present in the query, print it in the correct order.\n                    encountered_argument_names.add(defined_arg_name)\n                    sorted_args.append(name_to_arg_value[defined_arg_name])\n\n            # Get all the arguments that weren't defined in the directive schema.\n            # They will be printed after all the arguments that were in the schema.\n            unsorted_args = [\n                value\n                for name, value in six.iteritems(name_to_arg_value)\n                if name not in encountered_argument_names\n            ]\n\n            ordered_args = sorted_args + unsorted_args\n\n        return '@' + node.name + wrap('(', join(ordered_args, ', '), ')')", "response": "Call when exiting a directive node in the ast."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lower_ir(ir_blocks, query_metadata_table, type_equivalence_hints=None):\n    sanity_check_ir_blocks_from_frontend(ir_blocks, query_metadata_table)\n\n    # Construct the mapping of each location to its corresponding GraphQL type.\n    location_types = {\n        location: location_info.type\n        for location, location_info in query_metadata_table.registered_locations\n    }\n\n    # Compute the set of all locations that have associated type coercions.\n    coerced_locations = {\n        location\n        for location, location_info in query_metadata_table.registered_locations\n        if location_info.coerced_from_type is not None\n    }\n\n    # Extract information for both simple and complex @optional traverses\n    location_to_optional_results = extract_optional_location_root_info(ir_blocks)\n    complex_optional_roots, location_to_optional_roots = location_to_optional_results\n    simple_optional_root_info = extract_simple_optional_location_info(\n        ir_blocks, complex_optional_roots, location_to_optional_roots)\n    ir_blocks = remove_end_optionals(ir_blocks)\n\n    # Append global operation block(s) to filter out incorrect results\n    # from simple optional match traverses (using a WHERE statement)\n    if len(simple_optional_root_info) > 0:\n        where_filter_predicate = construct_where_filter_predicate(\n            query_metadata_table, simple_optional_root_info)\n        ir_blocks.insert(-1, GlobalOperationsStart())\n        ir_blocks.insert(-1, Filter(where_filter_predicate))\n\n    # These lowering / optimization passes work on IR blocks.\n    ir_blocks = lower_context_field_existence(ir_blocks, query_metadata_table)\n    ir_blocks = optimize_boolean_expression_comparisons(ir_blocks)\n    ir_blocks = rewrite_binary_composition_inside_ternary_conditional(ir_blocks)\n    ir_blocks = merge_consecutive_filter_clauses(ir_blocks)\n    ir_blocks = lower_has_substring_binary_compositions(ir_blocks)\n    ir_blocks = orientdb_eval_scheduling.workaround_lowering_pass(ir_blocks, query_metadata_table)\n\n    # Here, we lower from raw IR blocks into a MatchQuery object.\n    # From this point on, the lowering / optimization passes work on the MatchQuery representation.\n    match_query = convert_to_match_query(ir_blocks)\n\n    match_query = lower_comparisons_to_between(match_query)\n\n    match_query = lower_backtrack_blocks(match_query, location_types)\n    match_query = truncate_repeated_single_step_traversals(match_query)\n    match_query = orientdb_class_with_while.workaround_type_coercions_in_recursions(match_query)\n\n    # Optimize and lower the IR blocks inside @fold scopes.\n    new_folds = {\n        key: merge_consecutive_filter_clauses(\n            remove_backtrack_blocks_from_fold(\n                lower_folded_coerce_types_into_filter_blocks(folded_ir_blocks)\n            )\n        )\n        for key, folded_ir_blocks in six.iteritems(match_query.folds)\n    }\n    match_query = match_query._replace(folds=new_folds)\n\n    compound_match_query = convert_optional_traversals_to_compound_match_query(\n        match_query, complex_optional_roots, location_to_optional_roots)\n    compound_match_query = prune_non_existent_outputs(compound_match_query)\n    compound_match_query = collect_filters_to_first_location_occurrence(compound_match_query)\n    compound_match_query = lower_context_field_expressions(compound_match_query)\n\n    compound_match_query = truncate_repeated_single_step_traversals_in_sub_queries(\n        compound_match_query)\n    compound_match_query = orientdb_query_execution.expose_ideal_query_execution_start_points(\n        compound_match_query, location_types, coerced_locations)\n\n    return compound_match_query", "response": "Lower the IR into an IR form that can be represented in MATCH queries."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef toposort_classes(classes):\n    def get_class_topolist(class_name, name_to_class, processed_classes, current_trace):\n        \"\"\"Return a topologically sorted list of this class's dependencies and class itself\n\n        Args:\n            class_name: string, name of the class to process\n            name_to_class: dict, class_name -> descriptor\n            processed_classes: set of strings, a set of classes that have already been processed\n            current_trace: list of strings, list of classes traversed during the recursion\n\n        Returns:\n            list of dicts, list of classes sorted in topological order\n        \"\"\"\n        # Check if this class has already been handled\n        if class_name in processed_classes:\n            return []\n\n        if class_name in current_trace:\n            raise AssertionError(\n                'Encountered self-reference in dependency chain of {}'.format(class_name))\n\n        cls = name_to_class[class_name]\n        # Collect the dependency classes\n        # These are bases and classes from linked properties\n        dependencies = _list_superclasses(cls)\n        # Recursively process linked edges\n        properties = cls['properties'] if 'properties' in cls else []\n        for prop in properties:\n            if 'linkedClass' in prop:\n                dependencies.append(prop['linkedClass'])\n\n        class_list = []\n        # Recursively process superclasses\n        current_trace.add(class_name)\n        for dependency in dependencies:\n            class_list.extend(get_class_topolist(\n                dependency, name_to_class, processed_classes, current_trace))\n        current_trace.remove(class_name)\n        # Do the bookkeeping\n        class_list.append(name_to_class[class_name])\n        processed_classes.add(class_name)\n\n        return class_list\n\n    # Map names to classes\n    class_map = {c['name']: c for c in classes}\n    seen_classes = set()\n\n    toposorted = []\n    for name in class_map.keys():\n        toposorted.extend(get_class_topolist(name, class_map, seen_classes, set()))\n    return toposorted", "response": "Sort the list of classes in the topological order of the given classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _list_superclasses(class_def):\n    superclasses = class_def.get('superClasses', [])\n    if superclasses:\n        # Make sure to duplicate the list\n        return list(superclasses)\n\n    sup = class_def.get('superClass', None)\n    if sup:\n        return [sup]\n    else:\n        return []", "response": "Return a list of the superclasses of the given class"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a LocationStackEntry namedtuple with the specified parameters.", "response": "def _construct_location_stack_entry(location, num_traverses):\n    \"\"\"Return a LocationStackEntry namedtuple with the specified parameters.\"\"\"\n    if not isinstance(num_traverses, int) or num_traverses < 0:\n        raise AssertionError(u'Attempted to create a LocationStackEntry namedtuple with an invalid '\n                             u'value for \"num_traverses\" {}. This is not allowed.'\n                             .format(num_traverses))\n    if not isinstance(location, Location):\n        raise AssertionError(u'Attempted to create a LocationStackEntry namedtuple with an invalid '\n                             u'value for \"location\" {}. This is not allowed.'\n                             .format(location))\n    return LocationStackEntry(location=location, num_traverses=num_traverses)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of vertex fields and a list of property fields for the given GraphQL AST node.", "response": "def _get_fields(ast):\n    \"\"\"Return a list of vertex fields, and a list of property fields, for the given AST node.\n\n    Also verifies that all property fields for the AST node appear before all vertex fields,\n    raising GraphQLCompilationError if that is not the case.\n\n    Args:\n        ast: GraphQL AST node, obtained from the graphql library\n\n    Returns:\n        tuple of two lists\n            - the first list contains ASTs for vertex fields\n            - the second list contains ASTs for property fields\n    \"\"\"\n    if not ast.selection_set:\n        # There are no child fields.\n        return [], []\n\n    property_fields = []\n    vertex_fields = []\n    seen_field_names = set()\n    switched_to_vertices = False  # Ensures that all property fields are before all vertex fields.\n    for field_ast in ast.selection_set.selections:\n        if not isinstance(field_ast, Field):\n            # We are getting Fields only, ignore everything else.\n            continue\n\n        name = get_ast_field_name(field_ast)\n        if name in seen_field_names:\n            # If we ever allow repeated field names,\n            # then we have to change the Location naming scheme to reflect the repetitions\n            # and disambiguate between Recurse and Traverse visits to a Location.\n            raise GraphQLCompilationError(u'Encountered repeated field name: {}'.format(name))\n        seen_field_names.add(name)\n\n        # Vertex fields start with 'out_' or 'in_', denoting the edge direction to that vertex.\n        if is_vertex_field_name(name):\n            switched_to_vertices = True\n            vertex_fields.append(field_ast)\n        else:\n            if switched_to_vertices:\n                raise GraphQLCompilationError(u'Encountered property field {} '\n                                              u'after vertex fields!'.format(name))\n            property_fields.append(field_ast)\n\n    return vertex_fields, property_fields"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the inline fragment at the current AST node or None if no inline fragment exists.", "response": "def _get_inline_fragment(ast):\n    \"\"\"Return the inline fragment at the current AST node, or None if no fragment exists.\"\"\"\n    if not ast.selection_set:\n        # There is nothing selected here, so no fragment.\n        return None\n\n    fragments = [\n        ast_node\n        for ast_node in ast.selection_set.selections\n        if isinstance(ast_node, InlineFragment)\n    ]\n\n    if not fragments:\n        return None\n\n    if len(fragments) > 1:\n        raise GraphQLCompilationError(u'Cannot compile GraphQL with more than one fragment in '\n                                      u'a given selection set.')\n\n    return fragments[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _process_output_source_directive(schema, current_schema_type, ast,\n                                     location, context, local_unique_directives):\n    \"\"\"Process the output_source directive, modifying the context as appropriate.\n\n    Args:\n        schema: GraphQL schema object, obtained from the graphql library\n        current_schema_type: GraphQLType, the schema type at the current location\n        ast: GraphQL AST node, obtained from the graphql library\n        location: Location object representing the current location in the query\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n        local_unique_directives: dict, directive name string -> directive object, containing\n                                 unique directives present on the current AST node *only*\n\n    Returns:\n        an OutputSource block, if one should be emitted, or None otherwise\n    \"\"\"\n    # The 'ast' variable is only for function signature uniformity, and is currently not used.\n    output_source_directive = local_unique_directives.get('output_source', None)\n    if output_source_directive:\n        if has_encountered_output_source(context):\n            raise GraphQLCompilationError(u'Cannot have more than one output source!')\n        if is_in_optional_scope(context):\n            raise GraphQLCompilationError(u'Cannot have the output source in an optional block!')\n        set_output_source_data(context, location)\n        return blocks.OutputSource()\n    else:\n        return None", "response": "Processes the output_source directive and returns a block that can be emitted if one should be emitted or None if there is no such block."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompile the property AST node at this location.", "response": "def _compile_property_ast(schema, current_schema_type, ast, location,\n                          context, unique_local_directives):\n    \"\"\"Process property directives at this AST node, updating the query context as appropriate.\n\n    Args:\n        schema: GraphQL schema object, obtained from the graphql library\n        current_schema_type: GraphQLType, the schema type at the current location\n        ast: GraphQL AST node, obtained from the graphql library. Only for function signature\n             uniformity at the moment -- it is currently not used.\n        location: Location object representing the current location in the query\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n        unique_local_directives: dict, directive name string -> directive object, containing\n                                 unique directives present on the current AST node *only*\n    \"\"\"\n    validate_property_directives(unique_local_directives)\n\n    if location.field == COUNT_META_FIELD_NAME:\n        # Verify that uses of this field are within a @fold scope.\n        if not is_in_fold_scope(context):\n            raise GraphQLCompilationError(u'Cannot use the \"{}\" meta field when not within a @fold '\n                                          u'vertex field, as counting elements only makes sense '\n                                          u'in a fold. Location: {}'\n                                          .format(COUNT_META_FIELD_NAME, location))\n\n    # step P-2: process property-only directives\n    tag_directive = unique_local_directives.get('tag', None)\n    if tag_directive:\n        if is_in_fold_scope(context):\n            raise GraphQLCompilationError(u'Tagging values within a @fold vertex field is '\n                                          u'not allowed! Location: {}'.format(location))\n\n        if location.field == COUNT_META_FIELD_NAME:\n            raise AssertionError(u'Tags are prohibited within @fold, but unexpectedly found use of '\n                                 u'a tag on the {} meta field that is only allowed within a @fold!'\n                                 u'Location: {}'\n                                 .format(COUNT_META_FIELD_NAME, location))\n\n        # Schema validation has ensured that the fields below exist.\n        tag_name = tag_directive.arguments[0].value.value\n        if tag_name in context['tags']:\n            raise GraphQLCompilationError(u'Cannot reuse tag name: {}'.format(tag_name))\n        validate_safe_string(tag_name)\n        context['tags'][tag_name] = {\n            'location': location,\n            'optional': is_in_optional_scope(context),\n            'type': strip_non_null_from_type(current_schema_type),\n        }\n        context['metadata'].record_tag_info(tag_name, TagInfo(location=location))\n\n    output_directive = unique_local_directives.get('output', None)\n    if output_directive:\n        # Schema validation has ensured that the fields below exist.\n        output_name = output_directive.arguments[0].value.value\n        if output_name in context['outputs']:\n            raise GraphQLCompilationError(u'Cannot reuse output name: '\n                                          u'{}, {}'.format(output_name, context))\n        validate_safe_string(output_name)\n        validate_output_name(output_name)\n\n        graphql_type = strip_non_null_from_type(current_schema_type)\n        if is_in_fold_scope(context):\n            # Fold outputs are only allowed at the last level of traversal.\n            set_fold_innermost_scope(context)\n\n            if location.field != COUNT_META_FIELD_NAME:\n                graphql_type = GraphQLList(graphql_type)\n\n        context['outputs'][output_name] = {\n            'location': location,\n            'optional': is_in_optional_scope(context),\n            'type': graphql_type,\n            'fold': context.get('fold', None),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate and return the depth parameter of the recurse directive.", "response": "def _get_recurse_directive_depth(field_name, field_directives):\n    \"\"\"Validate and return the depth parameter of the recurse directive.\"\"\"\n    recurse_directive = field_directives['recurse']\n    optional_directive = field_directives.get('optional', None)\n\n    if optional_directive:\n        raise GraphQLCompilationError(u'Found both @optional and @recurse on '\n                                      u'the same vertex field: {}'.format(field_name))\n\n    recurse_args = get_uniquely_named_objects_by_name(recurse_directive.arguments)\n    recurse_depth = int(recurse_args['depth'].value.value)\n    if recurse_depth < 1:\n        raise GraphQLCompilationError(u'Found recurse directive with disallowed depth: '\n                                      u'{}'.format(recurse_depth))\n\n    return recurse_depth"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform type checks on the enclosing type and the recursed type.", "response": "def _validate_recurse_directive_types(current_schema_type, field_schema_type, context):\n    \"\"\"Perform type checks on the enclosing type and the recursed type for a recurse directive.\n\n    Args:\n        current_schema_type: GraphQLType, the schema type at the current location\n        field_schema_type: GraphQLType, the schema type at the inner scope\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n    \"\"\"\n    # Get the set of all allowed types in the current scope.\n    type_hints = context['type_equivalence_hints'].get(field_schema_type)\n    type_hints_inverse = context['type_equivalence_hints_inverse'].get(field_schema_type)\n    allowed_current_types = {field_schema_type}\n\n    if type_hints and isinstance(type_hints, GraphQLUnionType):\n        allowed_current_types.update(type_hints.types)\n\n    if type_hints_inverse and isinstance(type_hints_inverse, GraphQLUnionType):\n        allowed_current_types.update(type_hints_inverse.types)\n\n    # The current scope must be of the same type as the field scope, or an acceptable subtype.\n    current_scope_is_allowed = current_schema_type in allowed_current_types\n\n    is_implemented_interface = (\n        isinstance(field_schema_type, GraphQLInterfaceType) and\n        isinstance(current_schema_type, GraphQLObjectType) and\n        field_schema_type in current_schema_type.interfaces\n    )\n\n    if not any((current_scope_is_allowed, is_implemented_interface)):\n        raise GraphQLCompilationError(u'Edges expanded with a @recurse directive must either '\n                                      u'be of the same type as their enclosing scope, a supertype '\n                                      u'of the enclosing scope, or be of an interface type that is '\n                                      u'implemented by the type of their enclosing scope. '\n                                      u'Enclosing scope type: {}, edge type: '\n                                      u'{}'.format(current_schema_type, field_schema_type))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _compile_vertex_ast(schema, current_schema_type, ast,\n                        location, context, unique_local_directives, fields):\n    \"\"\"Return a list of basic blocks corresponding to the vertex AST node.\n\n    Args:\n        schema: GraphQL schema object, obtained from the graphql library\n        current_schema_type: GraphQLType, the schema type at the current location\n        ast: GraphQL AST node, obtained from the graphql library\n        location: Location object representing the current location in the query\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n        unique_local_directives: dict, directive name string -> directive object, containing\n                                 unique directives present on the current AST node *only*\n        fields: tuple of lists (property_fields, vertex_fields), with lists of field objects\n                present on the current vertex AST node\n\n    Returns:\n        list of basic blocks, the compiled output of the vertex AST node\n    \"\"\"\n    basic_blocks = []\n    query_metadata_table = context['metadata']\n    current_location_info = query_metadata_table.get_location_info(location)\n\n    vertex_fields, property_fields = fields\n\n    validate_vertex_directives(unique_local_directives)\n\n    # step V-2: step into property fields\n    for field_ast in property_fields:\n        field_name = get_ast_field_name(field_ast)\n        property_schema_type = get_field_type_from_schema(current_schema_type, field_name)\n\n        inner_location = location.navigate_to_field(field_name)\n        inner_basic_blocks = _compile_ast_node_to_ir(schema, property_schema_type, field_ast,\n                                                     inner_location, context)\n        basic_blocks.extend(inner_basic_blocks)\n\n    # step V-3: mark the graph position, and process output_source directive\n    basic_blocks.append(_mark_location(location))\n\n    output_source = _process_output_source_directive(schema, current_schema_type, ast,\n                                                     location, context, unique_local_directives)\n    if output_source:\n        basic_blocks.append(output_source)\n\n    # step V-4: step into vertex fields\n    for field_ast in vertex_fields:\n        field_name = get_ast_field_name(field_ast)\n        validate_context_for_visiting_vertex_field(location, field_name, context)\n\n        field_schema_type = get_vertex_field_type(current_schema_type, field_name)\n        hinted_base = context['type_equivalence_hints_inverse'].get(field_schema_type, None)\n        if hinted_base:\n            field_schema_type = hinted_base\n\n        inner_unique_directives = get_unique_directives(field_ast)\n        validate_vertex_field_directive_interactions(location, field_name, inner_unique_directives)\n        validate_vertex_field_directive_in_context(\n            location, field_name, inner_unique_directives, context)\n\n        recurse_directive = inner_unique_directives.get('recurse', None)\n        optional_directive = inner_unique_directives.get('optional', None)\n        fold_directive = inner_unique_directives.get('fold', None)\n        in_topmost_optional_block = False\n\n        edge_traversal_is_optional = optional_directive is not None\n        edge_traversal_is_folded = fold_directive is not None\n        edge_traversal_is_recursive = recurse_directive is not None\n\n        # This is true for any vertex expanded within an @optional scope.\n        within_optional_scope = is_in_optional_scope(context)\n\n        if edge_traversal_is_optional:\n            # Invariant: There must always be a marked location corresponding to the query position\n            # immediately before any optional Traverse.\n            #\n            # This invariant is verified in the IR sanity checks module (ir_sanity_checks.py),\n            # in the function named _sanity_check_mark_location_preceding_optional_traverse().\n            #\n            # This marked location is the one that the @optional directive's corresponding\n            # optional Backtrack will jump back to. If such a marked location isn't present,\n            # the backtrack could rewind to an old marked location and might ignore\n            # entire stretches of applied filtering.\n            #\n            # Assumption: The only way there might not be a marked location here is\n            # if the current location already traversed into child locations, not including folds.\n            non_fold_child_locations = {\n                child_location\n                for child_location in query_metadata_table.get_child_locations(location)\n                if not isinstance(child_location, FoldScopeLocation)\n            }\n            if non_fold_child_locations:\n                location = query_metadata_table.revisit_location(location)\n                basic_blocks.append(_mark_location(location))\n\n        if fold_directive:\n            inner_location = location.navigate_to_fold(field_name)\n        else:\n            inner_location = location.navigate_to_subpath(field_name)\n\n        inner_location_info = LocationInfo(\n            parent_location=location,\n            type=strip_non_null_from_type(field_schema_type),\n            coerced_from_type=None,\n            optional_scopes_depth=(\n                current_location_info.optional_scopes_depth + edge_traversal_is_optional),\n            recursive_scopes_depth=(\n                current_location_info.recursive_scopes_depth + edge_traversal_is_recursive),\n            is_within_fold=(current_location_info.is_within_fold or edge_traversal_is_folded),\n        )\n        query_metadata_table.register_location(inner_location, inner_location_info)\n\n        if edge_traversal_is_optional:\n            # Remember where the topmost optional context started.\n            topmost_optional = get_optional_scope_or_none(context)\n            if topmost_optional is None:\n                set_optional_scope_data(context, inner_location)\n                in_topmost_optional_block = True\n\n        edge_direction, edge_name = get_edge_direction_and_name(field_name)\n\n        if fold_directive:\n            fold_block = blocks.Fold(inner_location)\n            basic_blocks.append(fold_block)\n            set_fold_scope_data(context, inner_location)\n        elif recurse_directive:\n            _validate_recurse_directive_types(current_schema_type, field_schema_type, context)\n            recurse_depth = _get_recurse_directive_depth(field_name, inner_unique_directives)\n            basic_blocks.append(blocks.Recurse(edge_direction,\n                                               edge_name,\n                                               recurse_depth,\n                                               within_optional_scope=within_optional_scope))\n            query_metadata_table.record_recurse_info(location,\n                                                     RecurseInfo(edge_direction=edge_direction,\n                                                                 edge_name=edge_name,\n                                                                 depth=recurse_depth))\n        else:\n            basic_blocks.append(blocks.Traverse(edge_direction, edge_name,\n                                                optional=edge_traversal_is_optional,\n                                                within_optional_scope=within_optional_scope))\n\n        inner_basic_blocks = _compile_ast_node_to_ir(schema, field_schema_type, field_ast,\n                                                     inner_location, context)\n        basic_blocks.extend(inner_basic_blocks)\n\n        if edge_traversal_is_folded:\n            has_count_filter = has_fold_count_filter(context)\n            _validate_fold_has_outputs_or_count_filter(\n                get_context_fold_info(context), has_count_filter, context['outputs'])\n            basic_blocks.append(blocks.Unfold())\n            unmark_context_fold_scope(context)\n            if has_count_filter:\n                unmark_fold_count_filter(context)\n            if is_in_fold_innermost_scope(context):\n                unmark_fold_innermost_scope(context)\n\n        if in_topmost_optional_block:\n            unmark_optional_scope(context)\n\n        # If we are currently evaluating a @fold vertex,\n        # we didn't Traverse into it, so we don't need to backtrack out either.\n        # We also don't backtrack if we've reached an @output_source.\n        backtracking_required = (\n            (not fold_directive) and\n            (not has_encountered_output_source(context))\n        )\n        if backtracking_required:\n            if edge_traversal_is_optional:\n                basic_blocks.append(blocks.EndOptional())\n                basic_blocks.append(blocks.Backtrack(location, optional=True))\n\n                # Exiting optional block!\n                # Revisit the location so that there is a marked location right after the optional,\n                # so that future Backtrack blocks return after the optional set of blocks, and\n                # don't accidentally return to a prior location instead.\n                location = query_metadata_table.revisit_location(location)\n\n                basic_blocks.append(_mark_location(location))\n            else:\n                basic_blocks.append(blocks.Backtrack(location))\n\n    return basic_blocks", "response": "Compile the vertex AST node into a list of basic blocks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_fold_has_outputs_or_count_filter(fold_scope_location, fold_has_count_filter, outputs):\n    # This function makes sure that the @fold scope has an effect.\n    # Folds either output data, or filter the data enclosing the fold based on the size of the fold.\n    if fold_has_count_filter:\n        # This fold has a filter on the \"_x_count\" property, so it is legal and has an effect.\n        return True\n\n    # At least one output in the outputs list must point to the fold_scope_location,\n    # or the scope corresponding to fold_scope_location had no @outputs and is illegal.\n    for output in six.itervalues(outputs):\n        if output['fold'] == fold_scope_location:\n            return True\n\n    raise GraphQLCompilationError(u'Found a @fold scope that has no effect on the query. '\n                                  u'Each @fold scope must either perform filtering, or contain at '\n                                  u'least one field marked for output. Fold location: {}'\n                                  .format(fold_scope_location))", "response": "Ensure the fold scope has at least one output or count filter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _compile_fragment_ast(schema, current_schema_type, ast, location, context):\n    query_metadata_table = context['metadata']\n\n    # step F-2. Emit a type coercion block if appropriate,\n    #           then recurse into the fragment's selection.\n    coerces_to_type_name = ast.type_condition.name.value\n    coerces_to_type_obj = schema.get_type(coerces_to_type_name)\n\n    basic_blocks = []\n\n    # Check if the coercion is necessary.\n    # No coercion is necessary if coercing to the current type of the scope,\n    # or if the scope is of union type, to the base type of the union as defined by\n    # the type_equivalence_hints compilation parameter.\n    is_same_type_as_scope = current_schema_type.is_same_type(coerces_to_type_obj)\n    equivalent_union_type = context['type_equivalence_hints'].get(coerces_to_type_obj, None)\n    is_base_type_of_union = (\n        isinstance(current_schema_type, GraphQLUnionType) and\n        current_schema_type.is_same_type(equivalent_union_type)\n    )\n\n    if not (is_same_type_as_scope or is_base_type_of_union):\n        # Coercion is required.\n        query_metadata_table.record_coercion_at_location(location, coerces_to_type_obj)\n        basic_blocks.append(blocks.CoerceType({coerces_to_type_name}))\n\n    inner_basic_blocks = _compile_ast_node_to_ir(\n        schema, coerces_to_type_obj, ast, location, context)\n    basic_blocks.extend(inner_basic_blocks)\n\n    return basic_blocks", "response": "Compile the inline fragment at this AST node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _compile_ast_node_to_ir(schema, current_schema_type, ast, location, context):\n    basic_blocks = []\n\n    # step 0: preprocessing\n    local_unique_directives = get_unique_directives(ast)\n    fields = _get_fields(ast)\n    vertex_fields, property_fields = fields\n    fragment = _get_inline_fragment(ast)\n    filter_operations = get_local_filter_directives(\n        ast, current_schema_type, vertex_fields)\n\n    # We don't support type coercion while at the same time selecting fields.\n    # Either there are no fields, or there is no fragment, otherwise we raise a compilation error.\n    fragment_exists = fragment is not None\n    fields_exist = vertex_fields or property_fields\n    if fragment_exists and fields_exist:\n        raise GraphQLCompilationError(u'Cannot compile GraphQL that has inline fragment and '\n                                      u'selected fields in the same selection. Please move the '\n                                      u'selected fields inside the inline fragment.')\n\n    if location.field is not None:  # we're at a property field\n        # sanity-check: cannot have an inline fragment at a property field\n        if fragment_exists:\n            raise AssertionError(u'Found inline fragment at a property field: '\n                                 u'{} {}'.format(location, fragment))\n\n        # sanity-check: locations at properties don't have their own property locations\n        if len(property_fields) > 0:\n            raise AssertionError(u'Found property fields on a property field: '\n                                 u'{} {}'.format(location, property_fields))\n\n    # step 1: apply local filter, if any\n    for filter_operation_info in filter_operations:\n        filter_block = process_filter_directive(filter_operation_info, location, context)\n        if isinstance(location, FoldScopeLocation) and location.field == COUNT_META_FIELD_NAME:\n            # Filtering on the fold count field is only allowed at the innermost scope of a fold.\n            set_fold_innermost_scope(context)\n\n            # This Filter is going in the global operations section of the query, so it cannot\n            # use LocalField expressions since there is no \"local\" location to use.\n            # Rewrite it so that all references of data at a location instead use ContextFields.\n            expected_field = expressions.LocalField(COUNT_META_FIELD_NAME)\n            replacement_field = expressions.FoldedContextField(location, GraphQLInt)\n\n            visitor_fn = expressions.make_replacement_visitor(expected_field, replacement_field)\n            filter_block = filter_block.visit_and_update_expressions(visitor_fn)\n\n            visitor_fn = expressions.make_type_replacement_visitor(\n                expressions.ContextField,\n                lambda context_field: expressions.GlobalContextField(\n                    context_field.location, context_field.field_type))\n            filter_block = filter_block.visit_and_update_expressions(visitor_fn)\n\n            set_fold_count_filter(context)\n            context['global_filters'].append(filter_block)\n        else:\n            basic_blocks.append(filter_block)\n\n    if location.field is not None:\n        # The location is at a property, compile the property data following P-steps.\n        _compile_property_ast(schema, current_schema_type, ast,\n                              location, context, local_unique_directives)\n    else:\n        # The location is at a vertex.\n        if fragment_exists:\n            # Compile the fragment data following F-steps.\n            # N.B.: Note that the \"fragment\" variable is the fragment's AST. Since we've asserted\n            #       that the fragment is the only part of the selection set at the current AST node,\n            #       we pass the \"fragment\" in the AST parameter of the _compile_fragment_ast()\n            #       function, rather than the current AST node as in the other compilation steps.\n            basic_blocks.extend(\n                _compile_fragment_ast(schema, current_schema_type, fragment, location, context))\n        else:\n            # Compile the vertex data following V-steps.\n            basic_blocks.extend(\n                _compile_vertex_ast(schema, current_schema_type, ast,\n                                    location, context, local_unique_directives, fields))\n\n    return basic_blocks", "response": "Compile the given GraphQL AST node into a list of basic blocks corresponding to the current schema type and location."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nensure all tags are used in some filter.", "response": "def _validate_all_tags_are_used(metadata):\n    \"\"\"Ensure all tags are used in some filter.\"\"\"\n    tag_names = set([tag_name for tag_name, _ in metadata.tags])\n    filter_arg_names = set()\n    for location, _ in metadata.registered_locations:\n        for filter_info in metadata.get_filter_infos(location):\n            for filter_arg in filter_info.args:\n                if is_tag_argument(filter_arg):\n                    filter_arg_names.add(get_directive_argument_name(filter_arg))\n\n    unused_tags = tag_names - filter_arg_names\n    if unused_tags:\n        raise GraphQLCompilationError(u'This GraphQL query contains @tag directives whose values '\n                                      u'are not used: {}. This is not allowed. Please either use '\n                                      u'them in a filter or remove them entirely.'\n                                      .format(unused_tags))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compile_root_ast_to_ir(schema, ast, type_equivalence_hints=None):\n    if len(ast.selection_set.selections) != 1:\n        raise GraphQLCompilationError(u'Cannot process AST with more than one root selection!')\n\n    base_ast = ast.selection_set.selections[0]\n    base_start_type = get_ast_field_name(base_ast)  # This is the type at which querying starts.\n\n    # Validation passed, so the base_start_type must exist as a field of the root query.\n    current_schema_type = get_field_type_from_schema(schema.get_query_type(), base_start_type)\n\n    # Construct the start location of the query and its associated metadata.\n    location = Location((base_start_type,))\n    base_location_info = LocationInfo(\n        parent_location=None,\n        type=current_schema_type,\n        coerced_from_type=None,\n        optional_scopes_depth=0,\n        recursive_scopes_depth=0,\n        is_within_fold=False,\n    )\n    query_metadata_table = QueryMetadataTable(location, base_location_info)\n\n    # Default argument value is empty dict\n    if not type_equivalence_hints:\n        type_equivalence_hints = dict()\n\n    # Construct the starting context object.\n    context = {\n        # 'metadata' is the QueryMetadataTable describing all the metadata collected during query\n        # processing, including location metadata (e.g. which locations are folded or optional).\n        'metadata': query_metadata_table,\n        # 'tags' is a dict containing\n        #  - location: Location where the tag was defined\n        #  - optional: boolean representing whether the tag was defined within an @optional scope\n        #  - type: GraphQLType of the tagged value\n        'tags': dict(),\n        # 'global_filters' is a list that may contain Filter blocks that are generated during\n        # query processing, but apply to the global query scope and should be appended to the\n        # IR blocks only after the GlobalOperationsStart block has been emitted.\n        'global_filters': [],\n        # 'outputs' is a dict mapping each output name to another dict which contains\n        #  - location: Location where to output from\n        #  - optional: boolean representing whether the output was defined within an @optional scope\n        #  - type: GraphQLType of the output\n        #  - fold: FoldScopeLocation object if the current output was defined within a fold scope,\n        #          and None otherwise\n        'outputs': dict(),\n        # 'inputs' is a dict mapping input parameter names to their respective expected GraphQL\n        # types, as automatically inferred by inspecting the query structure\n        'inputs': dict(),\n        # 'type_equivalence_hints' is a dict mapping GraphQL types to equivalent GraphQL unions\n        'type_equivalence_hints': type_equivalence_hints,\n        # 'type_equivalence_hints_inverse' is the inverse of type_equivalence_hints,\n        # which is always invertible.\n        'type_equivalence_hints_inverse': invert_dict(type_equivalence_hints),\n    }\n\n    # Add the query root basic block to the output.\n    basic_blocks = [\n        blocks.QueryRoot({base_start_type})\n    ]\n\n    # Ensure the GraphQL query root doesn't immediately have a fragment (type coercion).\n    # Instead of starting at one type and coercing to another,\n    # users should simply start at the type to which they are coercing.\n    immediate_fragment = _get_inline_fragment(base_ast)\n    if immediate_fragment is not None:\n        msg_args = {\n            'coerce_to': immediate_fragment.type_condition.name.value,\n            'type_from': base_start_type,\n        }\n        raise GraphQLCompilationError(u'Found inline fragment coercing to type {coerce_to}, '\n                                      u'immediately inside query root asking for type {type_from}. '\n                                      u'This is a contrived pattern -- you should simply start '\n                                      u'your query at {coerce_to}.'.format(**msg_args))\n\n    # Ensure the GraphQL query root doesn't have any vertex directives\n    # that are disallowed on the root node.\n    validate_root_vertex_directives(base_ast)\n\n    # Compile and add the basic blocks for the query's base AST vertex.\n    new_basic_blocks = _compile_ast_node_to_ir(\n        schema, current_schema_type, base_ast, location, context)\n    basic_blocks.extend(new_basic_blocks)\n\n    _validate_all_tags_are_used(context['metadata'])\n\n    # All operations after this point affect the global query scope, and are not related to\n    # the \"current\" location in the query produced by the sequence of Traverse/Backtrack blocks.\n    basic_blocks.append(blocks.GlobalOperationsStart())\n\n    # Add any filters that apply to the global query scope.\n    basic_blocks.extend(context['global_filters'])\n\n    # Based on the outputs context data, add an output step and construct the output metadata.\n    outputs_context = context['outputs']\n    basic_blocks.append(_compile_output_step(outputs_context))\n    output_metadata = {\n        name: OutputMetadata(type=value['type'], optional=value['optional'])\n        for name, value in six.iteritems(outputs_context)\n    }\n\n    return IrAndMetadata(\n        ir_blocks=basic_blocks,\n        input_metadata=context['inputs'],\n        output_metadata=output_metadata,\n        query_metadata_table=context['metadata'])", "response": "Compile a full GraphQL abstract syntax tree to intermediate representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncompiling the output step for the base class.", "response": "def _compile_output_step(outputs):\n    \"\"\"Construct the final ConstructResult basic block that defines the output format of the query.\n\n    Args:\n        outputs: dict, output name (string) -> output data dict, specifying the location\n                 from where to get the data, and whether the data is optional (and therefore\n                 may be missing); missing optional data is replaced with 'null'\n\n    Returns:\n        a ConstructResult basic block that constructs appropriate outputs for the query\n    \"\"\"\n    if not outputs:\n        raise GraphQLCompilationError(u'No fields were selected for output! Please mark at least '\n                                      u'one field with the @output directive.')\n\n    output_fields = {}\n    for output_name, output_context in six.iteritems(outputs):\n        location = output_context['location']\n        optional = output_context['optional']\n        graphql_type = output_context['type']\n\n        expression = None\n        existence_check = None\n        # pylint: disable=redefined-variable-type\n        if isinstance(location, FoldScopeLocation):\n            if optional:\n                raise AssertionError(u'Unreachable state reached, optional in fold: '\n                                     u'{}'.format(output_context))\n\n            if location.field == COUNT_META_FIELD_NAME:\n                expression = expressions.FoldCountContextField(location)\n            else:\n                expression = expressions.FoldedContextField(location, graphql_type)\n        else:\n            expression = expressions.OutputContextField(location, graphql_type)\n\n            if optional:\n                existence_check = expressions.ContextFieldExistence(location.at_vertex())\n\n        if existence_check:\n            expression = expressions.TernaryConditional(\n                existence_check, expression, expressions.NullLiteral)\n        # pylint: enable=redefined-variable-type\n\n        output_fields[output_name] = expression\n\n    return blocks.ConstructResult(output_fields)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_schema_and_ast(schema, ast):\n    core_graphql_errors = validate(schema, ast)\n\n    # The following directives appear in the core-graphql library, but are not supported by the\n    # graphql compiler.\n    unsupported_default_directives = frozenset([\n        frozenset([\n            'include',\n            frozenset(['FIELD', 'FRAGMENT_SPREAD', 'INLINE_FRAGMENT']),\n            frozenset(['if'])\n        ]),\n        frozenset([\n            'skip',\n            frozenset(['FIELD', 'FRAGMENT_SPREAD', 'INLINE_FRAGMENT']),\n            frozenset(['if'])\n        ]),\n        frozenset([\n            'deprecated',\n            frozenset(['ENUM_VALUE', 'FIELD_DEFINITION']),\n            frozenset(['reason'])\n        ])\n    ])\n\n    # Directives expected by the graphql compiler.\n    expected_directives = {\n        frozenset([\n            directive.name,\n            frozenset(directive.locations),\n            frozenset(six.viewkeys(directive.args))\n        ])\n        for directive in DIRECTIVES\n    }\n\n    # Directives provided in the parsed graphql schema.\n    actual_directives = {\n        frozenset([\n            directive.name,\n            frozenset(directive.locations),\n            frozenset(six.viewkeys(directive.args))\n        ])\n        for directive in schema.get_directives()\n    }\n\n    # Directives missing from the actual directives provided.\n    missing_directives = expected_directives - actual_directives\n    if missing_directives:\n        missing_message = (u'The following directives were missing from the '\n                           u'provided schema: {}'.format(missing_directives))\n        core_graphql_errors.append(missing_message)\n\n    # Directives that are not specified by the core graphql library. Note that Graphql-core\n    # automatically injects default directives into the schema, regardless of whether\n    # the schema supports said directives. Hence, while the directives contained in\n    # unsupported_default_directives are incompatible with the graphql-compiler, we allow them to\n    # be present in the parsed schema string.\n    extra_directives = actual_directives - expected_directives - unsupported_default_directives\n    if extra_directives:\n        extra_message = (u'The following directives were supplied in the given schema, but are not '\n                         u'not supported by the GraphQL compiler: {}'.format(extra_directives))\n        core_graphql_errors.append(extra_message)\n\n    return core_graphql_errors", "response": "Validate the supplied graphql schema and ast."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the given GraphQL string into compiler IR.", "response": "def graphql_to_ir(schema, graphql_string, type_equivalence_hints=None):\n    \"\"\"Convert the given GraphQL string into compiler IR, using the given schema object.\n\n    Args:\n        schema: GraphQL schema object, created using the GraphQL library\n        graphql_string: string containing the GraphQL to compile to compiler IR\n        type_equivalence_hints: optional dict of GraphQL interface or type -> GraphQL union.\n                                Used as a workaround for GraphQL's lack of support for\n                                inheritance across \"types\" (i.e. non-interfaces), as well as a\n                                workaround for Gremlin's total lack of inheritance-awareness.\n                                The key-value pairs in the dict specify that the \"key\" type\n                                is equivalent to the \"value\" type, i.e. that the GraphQL type or\n                                interface in the key is the most-derived common supertype\n                                of every GraphQL type in the \"value\" GraphQL union.\n                                Recursive expansion of type equivalence hints is not performed,\n                                and only type-level correctness of this argument is enforced.\n                                See README.md for more details on everything this parameter does.\n                                *****\n                                Be very careful with this option, as bad input here will\n                                lead to incorrect output queries being generated.\n                                *****\n\n    Returns:\n        IrAndMetadata named tuple, containing fields:\n        - ir_blocks: a list of IR basic block objects\n        - input_metadata: a dict of expected input parameters (string) -> inferred GraphQL type\n        - output_metadata: a dict of output name (string) -> OutputMetadata object\n        - query_metadata_table: a QueryMetadataTable object containing location metadata\n\n    Raises flavors of GraphQLError in the following cases:\n        - if the query is invalid GraphQL (GraphQLParsingError);\n        - if the query doesn't match the schema (GraphQLValidationError);\n        - if the query has more than one definition block (GraphQLValidationError);\n        - if the query has more than one selection in the root object (GraphQLCompilationError);\n        - if the query does not obey directive usage rules (GraphQLCompilationError);\n        - if the query provides invalid / disallowed / wrong number of arguments\n          for a directive (GraphQLCompilationError).\n\n    In the case of implementation bugs, could also raise ValueError, TypeError, or AssertionError.\n    \"\"\"\n    graphql_string = _preprocess_graphql_string(graphql_string)\n    try:\n        ast = parse(graphql_string)\n    except GraphQLSyntaxError as e:\n        raise GraphQLParsingError(e)\n\n    validation_errors = _validate_schema_and_ast(schema, ast)\n\n    if validation_errors:\n        raise GraphQLValidationError(u'String does not validate: {}'.format(validation_errors))\n\n    if len(ast.definitions) != 1:\n        raise AssertionError(u'Unsupported graphql string with multiple definitions, should have '\n                             u'been caught in validation: \\n{}\\n{}'.format(graphql_string, ast))\n    base_ast = ast.definitions[0]\n\n    return _compile_root_ast_to_ir(schema, base_ast, type_equivalence_hints=type_equivalence_hints)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a human - readable representation of a gremlin command string.", "response": "def pretty_print_gremlin(gremlin):\n    \"\"\"Return a human-readable representation of a gremlin command string.\"\"\"\n    gremlin = remove_custom_formatting(gremlin)\n    too_many_parts = re.split(r'([)}]|scatter)[ ]?\\.', gremlin)\n\n    # Put the ) and } back on.\n    parts = [\n        too_many_parts[i] + too_many_parts[i + 1]\n        for i in six.moves.xrange(0, len(too_many_parts) - 1, 2)\n    ]\n    parts.append(too_many_parts[-1])\n\n    # Put the . back on.\n    for i in six.moves.xrange(1, len(parts)):\n        parts[i] = '.' + parts[i]\n\n    indentation = 0\n    indentation_increment = 4\n    output = []\n    for current_part in parts:\n        if any([current_part.startswith('.out'),\n                current_part.startswith('.in'),\n                current_part.startswith('.ifThenElse')]):\n            indentation += indentation_increment\n        elif current_part.startswith('.back') or current_part.startswith('.optional'):\n            indentation -= indentation_increment\n            if indentation < 0:\n                raise AssertionError(u'Indentation became negative: {}'.format(indentation))\n\n        output.append((' ' * indentation) + current_part)\n\n    return '\\n'.join(output).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a human - readable representation of a parameterized MATCH query string.", "response": "def pretty_print_match(match, parameterized=True):\n    \"\"\"Return a human-readable representation of a parameterized MATCH query string.\"\"\"\n    left_curly = '{{' if parameterized else '{'\n    right_curly = '}}' if parameterized else '}'\n    match = remove_custom_formatting(match)\n    parts = re.split('({}|{})'.format(left_curly, right_curly), match)\n\n    inside_braces = False\n    indent_size = 4\n    indent = ' ' * indent_size\n\n    output = [parts[0]]\n    for current_index, current_part in enumerate(parts[1:]):\n        if current_part == left_curly:\n            if inside_braces:\n                raise AssertionError(u'Found open-braces pair while already inside braces: '\n                                     u'{} {} {}'.format(current_index, parts, match))\n            inside_braces = True\n            output.append(current_part + '\\n')\n        elif current_part == right_curly:\n            if not inside_braces:\n                raise AssertionError(u'Found close-braces pair while not inside braces: '\n                                     u'{} {} {}'.format(current_index, parts, match))\n            inside_braces = False\n            output.append(current_part)\n        else:\n            if not inside_braces:\n                stripped_part = current_part.lstrip()\n                if stripped_part.startswith('.'):\n                    # Strip whitespace before traversal steps.\n                    output.append(stripped_part)\n                else:\n                    # Do not strip whitespace before e.g. the RETURN keyword.\n                    output.append(current_part)\n            else:\n                # Split out the keywords, initially getting rid of commas.\n                separate_keywords = re.split(', ([a-z]+:)', current_part)\n\n                # The first item in the separated list is the full first \"keyword: value\" pair.\n                # For every subsequent item, the keyword and value are separated; join them\n                # back together, outputting the comma, newline and indentation before them.\n                output.append(indent + separate_keywords[0].lstrip())\n                for i in six.moves.xrange(1, len(separate_keywords) - 1, 2):\n                    output.append(',\\n{indent}{keyword} {value}'.format(\n                        keyword=separate_keywords[i].strip(),\n                        value=separate_keywords[i + 1].strip(),\n                        indent=indent))\n                output.append('\\n')\n\n    return ''.join(output).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrepresenting a float as a string without losing precision.", "response": "def represent_float_as_str(value):\n    \"\"\"Represent a float as a string without losing precision.\"\"\"\n    # In Python 2, calling str() on a float object loses precision:\n    #\n    # In [1]: 1.23456789012345678\n    # Out[1]: 1.2345678901234567\n    #\n    # In [2]: 1.2345678901234567\n    # Out[2]: 1.2345678901234567\n    #\n    # In [3]: str(1.2345678901234567)\n    # Out[3]: '1.23456789012'\n    #\n    # The best way to ensure precision is not lost is to convert to string via Decimal:\n    # https://github.com/mogui/pyorient/pull/226/files\n    if not isinstance(value, float):\n        raise GraphQLInvalidArgumentError(u'Attempting to represent a non-float as a float: '\n                                          u'{}'.format(value))\n\n    with decimal.localcontext() as ctx:\n        ctx.prec = 20  # floats are max 80-bits wide = 20 significant digits\n        return u'{:f}'.format(decimal.Decimal(value))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntypes - check the value and then just return str ( value ).", "response": "def type_check_and_str(python_type, value):\n    \"\"\"Type-check the value, and then just return str(value).\"\"\"\n    if not isinstance(value, python_type):\n        raise GraphQLInvalidArgumentError(u'Attempting to represent a non-{type} as a {type}: '\n                                          u'{value}'.format(type=python_type, value=value))\n\n    return str(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattempts to coerce the value to a Decimal.", "response": "def coerce_to_decimal(value):\n    \"\"\"Attempt to coerce the value to a Decimal, or raise an error if unable to do so.\"\"\"\n    if isinstance(value, decimal.Decimal):\n        return value\n    else:\n        try:\n            return decimal.Decimal(value)\n        except decimal.InvalidOperation as e:\n            raise GraphQLInvalidArgumentError(e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_replacement_visitor(find_expression, replace_expression):\n    def visitor_fn(expression):\n        \"\"\"Return the replacement if this expression matches the expression we're looking for.\"\"\"\n        if expression == find_expression:\n            return replace_expression\n        else:\n            return expression\n\n    return visitor_fn", "response": "Return a visitor function that replaces every instance of one expression with another one."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a visitor function that replaces expressions of a given type with new expressions.", "response": "def make_type_replacement_visitor(find_types, replacement_func):\n    \"\"\"Return a visitor function that replaces expressions of a given type with new expressions.\"\"\"\n    def visitor_fn(expression):\n        \"\"\"Return a replacement expression if the original expression is of the correct type.\"\"\"\n        if isinstance(expression, find_types):\n            return replacement_func(expression)\n        else:\n            return expression\n\n    return visitor_fn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_operator_name(operator, supported_operators):\n    if not isinstance(operator, six.text_type):\n        raise TypeError(u'Expected operator as unicode string, got: {} {}'.format(\n            type(operator).__name__, operator))\n\n    if operator not in supported_operators:\n        raise GraphQLCompilationError(u'Unrecognized operator: {}'.format(operator))", "response": "Ensure the named operator is valid and supported."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(self):\n        # Literals representing boolean values or None are correctly representable and supported.\n        if self.value is None or self.value is True or self.value is False:\n            return\n\n        # Literal safe strings are correctly representable and supported.\n        if isinstance(self.value, six.string_types):\n            validate_safe_string(self.value)\n            return\n\n        # Literal ints are correctly representable and supported.\n        if isinstance(self.value, int):\n            return\n\n        # Literal empty lists, and non-empty lists of safe strings, are\n        # correctly representable and supported.\n        if isinstance(self.value, list):\n            if len(self.value) > 0:\n                for x in self.value:\n                    validate_safe_string(x)\n            return\n\n        raise GraphQLCompilationError(u'Cannot represent literal: {}'.format(self.value))", "response": "Validate that the Literal is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a unicode object with the Gremlin representation of this Literal.", "response": "def _to_output_code(self):\n        \"\"\"Return a unicode object with the Gremlin/MATCH representation of this Literal.\"\"\"\n        # All supported Literal objects serialize to identical strings both in Gremlin and MATCH.\n        self.validate()\n        if self.value is None:\n            return u'null'\n        elif self.value is True:\n            return u'true'\n        elif self.value is False:\n            return u'false'\n        elif isinstance(self.value, six.string_types):\n            return safe_quoted_string(self.value)\n        elif isinstance(self.value, int):\n            return six.text_type(self.value)\n        elif isinstance(self.value, list):\n            if len(self.value) == 0:\n                return '[]'\n            elif all(isinstance(x, six.string_types) for x in self.value):\n                list_contents = ', '.join(safe_quoted_string(x) for x in sorted(self.value))\n                return '[' + list_contents + ']'\n        else:\n            pass  # Fall through to assertion error below.\n        raise AssertionError(u'Unreachable state reached: {}'.format(self))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self):\n        # Get the first letter, or empty string if it doesn't exist.\n        if not self.variable_name.startswith(u'$'):\n            raise GraphQLCompilationError(u'Expected variable name to start with $, but was: '\n                                          u'{}'.format(self.variable_name))\n\n        if self.variable_name in RESERVED_MATCH_KEYWORDS:\n            raise GraphQLCompilationError(u'Cannot use reserved MATCH keyword {} as variable '\n                                          u'name!'.format(self.variable_name))\n\n        validate_safe_string(self.variable_name[1:])\n\n        if not is_graphql_type(self.inferred_type):\n            raise ValueError(u'Invalid value of \"inferred_type\": {}'.format(self.inferred_type))\n\n        if isinstance(self.inferred_type, GraphQLNonNull):\n            raise ValueError(u'GraphQL non-null types are not supported as \"inferred_type\": '\n                             u'{}'.format(self.inferred_type))\n\n        if isinstance(self.inferred_type, GraphQLList):\n            inner_type = strip_non_null_from_type(self.inferred_type.of_type)\n            if GraphQLDate.is_same_type(inner_type) or GraphQLDateTime.is_same_type(inner_type):\n                # This is a compilation error rather than a ValueError as\n                # it can be caused by an invalid GraphQL query on an otherwise valid schema.\n                # In other words, it's an error in writing the GraphQL query, rather than\n                # a programming error within the library.\n                raise GraphQLCompilationError(\n                    u'Lists of Date or DateTime cannot currently be represented as '\n                    u'Variable objects: {}'.format(self.inferred_type))", "response": "Validate that the Variable is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a unicode object with the MATCH representation of this Variable.", "response": "def to_match(self):\n        \"\"\"Return a unicode object with the MATCH representation of this Variable.\"\"\"\n        self.validate()\n\n        # We don't want the dollar sign as part of the variable name.\n        variable_with_no_dollar_sign = self.variable_name[1:]\n\n        match_variable_name = '{%s}' % (six.text_type(variable_with_no_dollar_sign),)\n\n        # We can't directly pass a Date or DateTime object, so we have to pass it as a string\n        # and then parse it inline. For date format parameter meanings, see:\n        # http://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html\n        # For the semantics of the date() OrientDB SQL function, see:\n        # http://orientdb.com/docs/last/SQL-Functions.html#date\n        if GraphQLDate.is_same_type(self.inferred_type):\n            return u'date(%s, \"%s\")' % (match_variable_name, STANDARD_DATE_FORMAT)\n        elif GraphQLDateTime.is_same_type(self.inferred_type):\n            return u'date(%s, \"%s\")' % (match_variable_name, STANDARD_DATETIME_FORMAT)\n        else:\n            return match_variable_name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a unicode object with the Gremlin representation of this expression.", "response": "def to_gremlin(self):\n        \"\"\"Return a unicode object with the Gremlin representation of this expression.\"\"\"\n        # We can't directly pass a Date or a DateTime object, so we have to pass it as a string\n        # and then parse it inline. For date format parameter meanings, see:\n        # http://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html\n        if GraphQLDate.is_same_type(self.inferred_type):\n            return u'Date.parse(\"{}\", {})'.format(STANDARD_DATE_FORMAT, self.variable_name)\n        elif GraphQLDateTime.is_same_type(self.inferred_type):\n            return u'Date.parse(\"{}\", {})'.format(STANDARD_DATETIME_FORMAT, self.variable_name)\n        else:\n            return six.text_type(self.variable_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a unicode object with the Gremlin representation of this expression.", "response": "def to_gremlin(self):\n        \"\"\"Return a unicode object with the Gremlin representation of this expression.\"\"\"\n        self.validate()\n\n        local_object_name = self.get_local_object_gremlin_name()\n\n        if self.field_name == '@this':\n            return local_object_name\n\n        if '@' in self.field_name:\n            return u'{}[\\'{}\\']'.format(local_object_name, self.field_name)\n        else:\n            return u'{}.{}'.format(local_object_name, self.field_name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self):\n        if not isinstance(self.location, Location):\n            raise TypeError(u'Expected Location location, got: {} {}'\n                            .format(type(self.location).__name__, self.location))\n\n        if self.location.field is None:\n            raise AssertionError(u'Received Location without a field: {}'\n                                 .format(self.location))\n\n        if not is_graphql_type(self.field_type):\n            raise ValueError(u'Invalid value of \"field_type\": {}'.format(self.field_type))", "response": "Validate that the GlobalContextField is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a unicode object with the MATCH representation of this GlobalContextField.", "response": "def to_match(self):\n        \"\"\"Return a unicode object with the MATCH representation of this GlobalContextField.\"\"\"\n        self.validate()\n\n        mark_name, field_name = self.location.get_location_name()\n        validate_safe_string(mark_name)\n        validate_safe_string(field_name)\n\n        return u'%s.%s' % (mark_name, field_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_match(self):\n        self.validate()\n\n        mark_name, field_name = self.location.get_location_name()\n        validate_safe_string(mark_name)\n\n        if field_name is None:\n            return u'$matched.%s' % (mark_name,)\n        else:\n            validate_safe_string(field_name)\n            return u'$matched.%s.%s' % (mark_name, field_name)", "response": "Return a unicode object with the MATCH representation of this ContextField."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_gremlin(self):\n        self.validate()\n\n        mark_name, field_name = self.location.get_location_name()\n\n        if field_name is not None:\n            validate_safe_string(field_name)\n            if '@' in field_name:\n                template = u'm.{mark_name}[\\'{field_name}\\']'\n            else:\n                template = u'm.{mark_name}.{field_name}'\n        else:\n            template = u'm.{mark_name}'\n\n        validate_safe_string(mark_name)\n\n        return template.format(mark_name=mark_name, field_name=field_name)", "response": "Return a unicode object with the Gremlin representation of this expression."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that the OutputContextField is correctly representable.", "response": "def validate(self):\n        \"\"\"Validate that the OutputContextField is correctly representable.\"\"\"\n        if not isinstance(self.location, Location):\n            raise TypeError(u'Expected Location location, got: {} {}'.format(\n                type(self.location).__name__, self.location))\n\n        if not self.location.field:\n            raise ValueError(u'Expected Location object that points to a field, got: '\n                             u'{}'.format(self.location))\n\n        if not is_graphql_type(self.field_type):\n            raise ValueError(u'Invalid value of \"field_type\": {}'.format(self.field_type))\n\n        stripped_field_type = strip_non_null_from_type(self.field_type)\n        if isinstance(stripped_field_type, GraphQLList):\n            inner_type = strip_non_null_from_type(stripped_field_type.of_type)\n            if GraphQLDate.is_same_type(inner_type) or GraphQLDateTime.is_same_type(inner_type):\n                # This is a compilation error rather than a ValueError as\n                # it can be caused by an invalid GraphQL query on an otherwise valid schema.\n                # In other words, it's an error in writing the GraphQL query, rather than\n                # a programming error within the library.\n                raise GraphQLCompilationError(\n                    u'Lists of Date or DateTime cannot currently be represented as '\n                    u'OutputContextField objects: {}'.format(self.field_type))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a unicode object with the MATCH representation of this expression.", "response": "def to_match(self):\n        \"\"\"Return a unicode object with the MATCH representation of this expression.\"\"\"\n        self.validate()\n\n        mark_name, field_name = self.location.get_location_name()\n        validate_safe_string(mark_name)\n        validate_safe_string(field_name)\n\n        stripped_field_type = strip_non_null_from_type(self.field_type)\n        if GraphQLDate.is_same_type(stripped_field_type):\n            return u'%s.%s.format(\"%s\")' % (mark_name, field_name, STANDARD_DATE_FORMAT)\n        elif GraphQLDateTime.is_same_type(stripped_field_type):\n            return u'%s.%s.format(\"%s\")' % (mark_name, field_name, STANDARD_DATETIME_FORMAT)\n        else:\n            return u'%s.%s' % (mark_name, field_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a unicode object with the Gremlin representation of this expression.", "response": "def to_gremlin(self):\n        \"\"\"Return a unicode object with the Gremlin representation of this expression.\"\"\"\n        self.validate()\n\n        mark_name, field_name = self.location.get_location_name()\n        validate_safe_string(mark_name)\n        validate_safe_string(field_name)\n\n        if '@' in field_name:\n            template = u'm.{mark_name}[\\'{field_name}\\']'\n        else:\n            template = u'm.{mark_name}.{field_name}'\n\n        format_value = None\n        stripped_field_type = strip_non_null_from_type(self.field_type)\n        if GraphQLDate.is_same_type(stripped_field_type):\n            template += '.format(\"{format}\")'\n            format_value = STANDARD_DATE_FORMAT\n        elif GraphQLDateTime.is_same_type(stripped_field_type):\n            template += '.format(\"{format}\")'\n            format_value = STANDARD_DATETIME_FORMAT\n\n        return template.format(mark_name=mark_name, field_name=field_name,\n                               format=format_value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(self):\n        if not isinstance(self.fold_scope_location, FoldScopeLocation):\n            raise TypeError(u'Expected FoldScopeLocation fold_scope_location, got: {} {}'.format(\n                type(self.fold_scope_location), self.fold_scope_location))\n\n        if self.fold_scope_location.field is None:\n            raise ValueError(u'Expected FoldScopeLocation at a field, but got: {}'\n                             .format(self.fold_scope_location))\n\n        if self.fold_scope_location.field == COUNT_META_FIELD_NAME:\n            if not GraphQLInt.is_same_type(self.field_type):\n                raise TypeError(u'Expected the _x_count meta-field to be of GraphQLInt type, but '\n                                u'encountered type {} instead: {}'\n                                .format(self.field_type, self.fold_scope_location))\n        else:\n            if not isinstance(self.field_type, GraphQLList):\n                raise ValueError(u'Invalid value of \"field_type\" for a field that is not '\n                                 u'a meta-field, expected a list type but got: {} {}'\n                                 .format(self.field_type, self.fold_scope_location))\n\n            inner_type = strip_non_null_from_type(self.field_type.of_type)\n            if isinstance(inner_type, GraphQLList):\n                raise GraphQLCompilationError(\n                    u'Outputting list-valued fields in a @fold context is currently not supported: '\n                    u'{} {}'.format(self.fold_scope_location, self.field_type.of_type))", "response": "Validate that the FoldedContextField is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_match(self):\n        self.validate()\n\n        mark_name, field_name = self.fold_scope_location.get_location_name()\n        validate_safe_string(mark_name)\n\n        template = u'$%(mark_name)s.%(field_name)s'\n        template_data = {\n            'mark_name': mark_name,\n        }\n\n        if field_name == COUNT_META_FIELD_NAME:\n            template_data['field_name'] = 'size()'\n        else:\n            inner_type = strip_non_null_from_type(self.field_type.of_type)\n            if GraphQLDate.is_same_type(inner_type):\n                # Known OrientDB bug may cause trouble here, and incorrect data may be returned:\n                # https://github.com/orientechnologies/orientdb/issues/7289\n                template += '.format(\"' + STANDARD_DATE_FORMAT + '\")'\n            elif GraphQLDateTime.is_same_type(inner_type):\n                # Known OrientDB bug may cause trouble here, and incorrect data may be returned:\n                # https://github.com/orientechnologies/orientdb/issues/7289\n                template += '.format(\"' + STANDARD_DATETIME_FORMAT + '\")'\n\n            template_data['field_name'] = field_name\n\n        return template % template_data", "response": "Return a unicode object with the MATCH representation of this expression."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate that the FoldCountContextField is correctly representable.", "response": "def validate(self):\n        \"\"\"Validate that the FoldCountContextField is correctly representable.\"\"\"\n        if not isinstance(self.fold_scope_location, FoldScopeLocation):\n            raise TypeError(u'Expected FoldScopeLocation fold_scope_location, got: {} {}'.format(\n                type(self.fold_scope_location), self.fold_scope_location))\n\n        if self.fold_scope_location.field != COUNT_META_FIELD_NAME:\n            raise AssertionError(u'Unexpected field in the FoldScopeLocation of this '\n                                 u'FoldCountContextField object: {} {}'\n                                 .format(self.fold_scope_location, self))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a unicode object with the MATCH representation of this expression.", "response": "def to_match(self):\n        \"\"\"Return a unicode object with the MATCH representation of this expression.\"\"\"\n        self.validate()\n\n        mark_name, _ = self.fold_scope_location.get_location_name()\n        validate_safe_string(mark_name)\n\n        template = u'$%(mark_name)s.size()'\n        template_data = {\n            'mark_name': mark_name,\n        }\n        return template % template_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self):\n        if not isinstance(self.location, Location):\n            raise TypeError(u'Expected Location location, got: {} {}'.format(\n                type(self.location).__name__, self.location))\n\n        if self.location.field:\n            raise ValueError(u'Expected location to point to a vertex, '\n                             u'but found a field: {}'.format(self.location))", "response": "Validate that the ContextFieldExistence is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self):\n        _validate_operator_name(self.operator, UnaryTransformation.SUPPORTED_OPERATORS)\n\n        if not isinstance(self.inner_expression, Expression):\n            raise TypeError(u'Expected Expression inner_expression, got {} {}'.format(\n                type(self.inner_expression).__name__, self.inner_expression))", "response": "Validate that the UnaryTransformation is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_and_update(self, visitor_fn):\n        new_inner = self.inner_expression.visit_and_update(visitor_fn)\n\n        if new_inner is not self.inner_expression:\n            return visitor_fn(UnaryTransformation(self.operator, new_inner))\n        else:\n            return visitor_fn(self)", "response": "Create an updated version of the UnaryTransformation via the visitor pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_match(self):\n        self.validate()\n\n        translation_table = {\n            u'size': u'size()',\n        }\n        match_operator = translation_table.get(self.operator)\n        if not match_operator:\n            raise AssertionError(u'Unrecognized operator used: '\n                                 u'{} {}'.format(self.operator, self))\n\n        template = u'%(inner)s.%(operator)s'\n        args = {\n            'inner': self.inner_expression.to_match(),\n            'operator': match_operator,\n        }\n        return template % args", "response": "Return a unicode object with the MATCH representation of this UnaryTransformation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_gremlin(self):\n        translation_table = {\n            u'size': u'count()',\n        }\n        gremlin_operator = translation_table.get(self.operator)\n        if not gremlin_operator:\n            raise AssertionError(u'Unrecognized operator used: '\n                                 u'{} {}'.format(self.operator, self))\n\n        template = u'{inner}.{operator}'\n        args = {\n            'inner': self.inner_expression.to_gremlin(),\n            'operator': gremlin_operator,\n        }\n        return template.format(**args)", "response": "Return a unicode object with the Gremlin representation of this expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(self):\n        _validate_operator_name(self.operator, BinaryComposition.SUPPORTED_OPERATORS)\n\n        if not isinstance(self.left, Expression):\n            raise TypeError(u'Expected Expression left, got: {} {} {}'.format(\n                type(self.left).__name__, self.left, self))\n\n        if not isinstance(self.right, Expression):\n            raise TypeError(u'Expected Expression right, got: {} {}'.format(\n                type(self.right).__name__, self.right))", "response": "Validate that the BinaryComposition is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_and_update(self, visitor_fn):\n        new_left = self.left.visit_and_update(visitor_fn)\n        new_right = self.right.visit_and_update(visitor_fn)\n\n        if new_left is not self.left or new_right is not self.right:\n            return visitor_fn(BinaryComposition(self.operator, new_left, new_right))\n        else:\n            return visitor_fn(self)", "response": "Create an updated version of the binary comparision via the visitor pattern."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_match(self):\n        self.validate()\n\n        # The MATCH versions of some operators require an inverted order of arguments.\n        # pylint: disable=unused-variable\n        regular_operator_format = '(%(left)s %(operator)s %(right)s)'\n        inverted_operator_format = '(%(right)s %(operator)s %(left)s)'  # noqa\n        intersects_operator_format = '(%(operator)s(%(left)s, %(right)s).asList().size() > 0)'\n        # pylint: enable=unused-variable\n\n        # Null literals use 'is/is not' as (in)equality operators, while other values use '=/<>'.\n        if any((isinstance(self.left, Literal) and self.left.value is None,\n                isinstance(self.right, Literal) and self.right.value is None)):\n            translation_table = {\n                u'=': (u'IS', regular_operator_format),\n                u'!=': (u'IS NOT', regular_operator_format),\n            }\n        else:\n            translation_table = {\n                u'=': (u'=', regular_operator_format),\n                u'!=': (u'<>', regular_operator_format),\n                u'>=': (u'>=', regular_operator_format),\n                u'<=': (u'<=', regular_operator_format),\n                u'>': (u'>', regular_operator_format),\n                u'<': (u'<', regular_operator_format),\n                u'+': (u'+', regular_operator_format),\n                u'||': (u'OR', regular_operator_format),\n                u'&&': (u'AND', regular_operator_format),\n                u'contains': (u'CONTAINS', regular_operator_format),\n                u'intersects': (u'intersect', intersects_operator_format),\n                u'has_substring': (None, None),  # must be lowered into compatible form using LIKE\n\n                # MATCH-specific operators\n                u'LIKE': (u'LIKE', regular_operator_format),\n                u'INSTANCEOF': (u'INSTANCEOF', regular_operator_format),\n            }\n\n        match_operator, format_spec = translation_table.get(self.operator, (None, None))\n        if not match_operator:\n            raise AssertionError(u'Unrecognized operator used: '\n                                 u'{} {}'.format(self.operator, self))\n\n        return format_spec % dict(operator=match_operator,\n                                  left=self.left.to_match(),\n                                  right=self.right.to_match())", "response": "Return a unicode object with the MATCH representation of this BinaryComposition."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_gremlin(self):\n        self.validate()\n\n        immediate_operator_format = u'({left} {operator} {right})'\n        dotted_operator_format = u'{left}.{operator}({right})'\n        intersects_operator_format = u'(!{left}.{operator}({right}).empty)'\n\n        translation_table = {\n            u'=': (u'==', immediate_operator_format),\n            u'!=': (u'!=', immediate_operator_format),\n            u'>=': (u'>=', immediate_operator_format),\n            u'<=': (u'<=', immediate_operator_format),\n            u'>': (u'>', immediate_operator_format),\n            u'<': (u'<', immediate_operator_format),\n            u'+': (u'+', immediate_operator_format),\n            u'||': (u'||', immediate_operator_format),\n            u'&&': (u'&&', immediate_operator_format),\n            u'contains': (u'contains', dotted_operator_format),\n            u'intersects': (u'intersect', intersects_operator_format),\n            u'has_substring': (u'contains', dotted_operator_format),\n        }\n\n        gremlin_operator, format_spec = translation_table.get(self.operator, (None, None))\n        if not gremlin_operator:\n            raise AssertionError(u'Unrecognized operator used: '\n                                 u'{} {}'.format(self.operator, self))\n\n        return format_spec.format(operator=gremlin_operator,\n                                  left=self.left.to_gremlin(),\n                                  right=self.right.to_gremlin())", "response": "Return a unicode object with the Gremlin representation of this expression."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self):\n        if not isinstance(self.predicate, Expression):\n            raise TypeError(u'Expected Expression predicate, got: {} {}'.format(\n                type(self.predicate).__name__, self.predicate))\n        if not isinstance(self.if_true, Expression):\n            raise TypeError(u'Expected Expression if_true, got: {} {}'.format(\n                type(self.if_true).__name__, self.if_true))\n        if not isinstance(self.if_false, Expression):\n            raise TypeError(u'Expected Expression if_false, got: {} {}'.format(\n                type(self.if_false).__name__, self.if_false))", "response": "Validate that the TernaryConditional is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_and_update(self, visitor_fn):\n        new_predicate = self.predicate.visit_and_update(visitor_fn)\n        new_if_true = self.if_true.visit_and_update(visitor_fn)\n        new_if_false = self.if_false.visit_and_update(visitor_fn)\n\n        if any((new_predicate is not self.predicate,\n                new_if_true is not self.if_true,\n                new_if_false is not self.if_false)):\n            return visitor_fn(TernaryConditional(new_predicate, new_if_true, new_if_false))\n        else:\n            return visitor_fn(self)", "response": "Create an updated version of TernaryConditional via the visitor pattern."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_match(self):\n        self.validate()\n\n        # For MATCH, an additional validation step is needed -- we currently do not support\n        # emitting MATCH code for TernaryConditional that contains another TernaryConditional\n        # anywhere within the predicate expression. This is because the predicate expression\n        # must be surrounded in quotes, and it is unclear whether nested/escaped quotes would work.\n        def visitor_fn(expression):\n            \"\"\"Visitor function that ensures the predicate does not contain TernaryConditionals.\"\"\"\n            if isinstance(expression, TernaryConditional):\n                raise ValueError(u'Cannot emit MATCH code for TernaryConditional that contains '\n                                 u'in its predicate another TernaryConditional: '\n                                 u'{} {}'.format(expression, self))\n            return expression\n\n        self.predicate.visit_and_update(visitor_fn)\n\n        format_spec = u'if(eval(\"%(predicate)s\"), %(if_true)s, %(if_false)s)'\n        predicate_string = self.predicate.to_match()\n        if u'\"' in predicate_string:\n            raise AssertionError(u'Found a double-quote within the predicate string, this would '\n                                 u'have terminated the if(eval()) early and should be fixed: '\n                                 u'{} {}'.format(predicate_string, self))\n\n        return format_spec % dict(predicate=predicate_string,\n                                  if_true=self.if_true.to_match(),\n                                  if_false=self.if_false.to_match())", "response": "Return a unicode object with the MATCH representation of this TernaryConditional."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_gremlin(self):\n        self.validate()\n        return u'({predicate} ? {if_true} : {if_false})'.format(\n            predicate=self.predicate.to_gremlin(),\n            if_true=self.if_true.to_gremlin(),\n            if_false=self.if_false.to_gremlin())", "response": "Return a unicode object with the Gremlin representation of this expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nasserts that IR blocks originating from the frontend do not have nonsensical structure.", "response": "def sanity_check_ir_blocks_from_frontend(ir_blocks, query_metadata_table):\n    \"\"\"Assert that IR blocks originating from the frontend do not have nonsensical structure.\n\n    Args:\n        ir_blocks: list of BasicBlocks representing the IR to sanity-check\n\n    Raises:\n        AssertionError, if the IR has unexpected structure. If the IR produced by the front-end\n        cannot be successfully and correctly used to generate MATCH or Gremlin due to a bug,\n        this is the method that should catch the problem.\n    \"\"\"\n    if not ir_blocks:\n        raise AssertionError(u'Received no ir_blocks: {}'.format(ir_blocks))\n\n    _sanity_check_fold_scope_locations_are_unique(ir_blocks)\n    _sanity_check_no_nested_folds(ir_blocks)\n    _sanity_check_query_root_block(ir_blocks)\n    _sanity_check_output_source_follower_blocks(ir_blocks)\n    _sanity_check_block_pairwise_constraints(ir_blocks)\n    _sanity_check_mark_location_preceding_optional_traverse(ir_blocks)\n    _sanity_check_every_location_is_marked(ir_blocks)\n    _sanity_check_coerce_type_outside_of_fold(ir_blocks)\n    _sanity_check_all_marked_locations_are_registered(ir_blocks, query_metadata_table)\n    _sanity_check_registered_locations_parent_locations(query_metadata_table)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _sanity_check_registered_locations_parent_locations(query_metadata_table):\n    for location, location_info in query_metadata_table.registered_locations:\n        if (location != query_metadata_table.root_location and\n                not query_metadata_table.root_location.is_revisited_at(location)):\n            # If the location is not the root location and is not a revisit of the root,\n            # then it must have a parent location.\n            if location_info.parent_location is None:\n                raise AssertionError(u'Found a location that is not the root location of the query '\n                                     u'or a revisit of the root, but does not have a parent: '\n                                     u'{} {}'.format(location, location_info))\n\n        if location_info.parent_location is not None:\n            # Make sure the parent_location is also registered.\n            # If the location is not registered, the following line will raise an error.\n            query_metadata_table.get_location_info(location_info.parent_location)", "response": "Assert that all registered locations parent locations are also registered."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nasserting that all locations in MarkLocation blocks have registered and valid metadata.", "response": "def _sanity_check_all_marked_locations_are_registered(ir_blocks, query_metadata_table):\n    \"\"\"Assert that all locations in MarkLocation blocks have registered and valid metadata.\"\"\"\n    # Grab all the registered locations, then make sure that:\n    # - Any location that appears in a MarkLocation block is also registered.\n    # - There are no registered locations that do not appear in a MarkLocation block.\n    registered_locations = {\n        location\n        for location, _ in query_metadata_table.registered_locations\n    }\n\n    ir_encountered_locations = {\n        block.location\n        for block in ir_blocks\n        if isinstance(block, MarkLocation)\n    }\n\n    unregistered_locations = ir_encountered_locations - registered_locations\n    unencountered_locations = registered_locations - ir_encountered_locations\n    if unregistered_locations:\n        raise AssertionError(u'IR blocks unexpectedly contain locations not registered in the '\n                             u'QueryMetadataTable: {}'.format(unregistered_locations))\n    if unencountered_locations:\n        raise AssertionError(u'QueryMetadataTable unexpectedly contains registered locations that '\n                             u'never appear in the IR blocks: {}'.format(unencountered_locations))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sanity_check_fold_scope_locations_are_unique(ir_blocks):\n    observed_locations = dict()\n    for block in ir_blocks:\n        if isinstance(block, Fold):\n            alternate = observed_locations.get(block.fold_scope_location, None)\n            if alternate is not None:\n                raise AssertionError(u'Found two Fold blocks with identical FoldScopeLocations: '\n                                     u'{} {} {}'.format(alternate, block, ir_blocks))\n            observed_locations[block.fold_scope_location] = block", "response": "Assert that every FoldScopeLocation that exists on a Fold block is unique."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nasserting that there are no nested Folds.", "response": "def _sanity_check_no_nested_folds(ir_blocks):\n    \"\"\"Assert that there are no nested Fold contexts, and that every Fold has a matching Unfold.\"\"\"\n    fold_seen = False\n    for block in ir_blocks:\n        if isinstance(block, Fold):\n            if fold_seen:\n                raise AssertionError(u'Found a nested Fold contexts: {}'.format(ir_blocks))\n            else:\n                fold_seen = True\n        elif isinstance(block, Unfold):\n            if not fold_seen:\n                raise AssertionError(u'Found an Unfold block without a matching Fold: '\n                                     u'{}'.format(ir_blocks))\n            else:\n                fold_seen = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nasserting that QueryRoot is always the first block and only the first block.", "response": "def _sanity_check_query_root_block(ir_blocks):\n    \"\"\"Assert that QueryRoot is always the first block, and only the first block.\"\"\"\n    if not isinstance(ir_blocks[0], QueryRoot):\n        raise AssertionError(u'The first block was not QueryRoot: {}'.format(ir_blocks))\n    for block in ir_blocks[1:]:\n        if isinstance(block, QueryRoot):\n            raise AssertionError(u'Found QueryRoot after the first block: {}'.format(ir_blocks))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nasserting that ConstructResult is always the last block and only the last block.", "response": "def _sanity_check_construct_result_block(ir_blocks):\n    \"\"\"Assert that ConstructResult is always the last block, and only the last block.\"\"\"\n    if not isinstance(ir_blocks[-1], ConstructResult):\n        raise AssertionError(u'The last block was not ConstructResult: {}'.format(ir_blocks))\n    for block in ir_blocks[:-1]:\n        if isinstance(block, ConstructResult):\n            raise AssertionError(u'Found ConstructResult before the last block: '\n                                 u'{}'.format(ir_blocks))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that there are no Traverse Backtrack or Recurse blocks after an OutputSource block.", "response": "def _sanity_check_output_source_follower_blocks(ir_blocks):\n    \"\"\"Ensure there are no Traverse / Backtrack / Recurse blocks after an OutputSource block.\"\"\"\n    seen_output_source = False\n    for block in ir_blocks:\n        if isinstance(block, OutputSource):\n            seen_output_source = True\n        elif seen_output_source:\n            if isinstance(block, (Backtrack, Traverse, Recurse)):\n                raise AssertionError(u'Found Backtrack / Traverse / Recurse '\n                                     u'after OutputSource block: '\n                                     u'{}'.format(ir_blocks))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nassert that adjacent blocks obey all invariants.", "response": "def _sanity_check_block_pairwise_constraints(ir_blocks):\n    \"\"\"Assert that adjacent blocks obey all invariants.\"\"\"\n    for first_block, second_block in pairwise(ir_blocks):\n        # Always Filter before MarkLocation, never after.\n        if isinstance(first_block, MarkLocation) and isinstance(second_block, Filter):\n            raise AssertionError(u'Found Filter after MarkLocation block: {}'.format(ir_blocks))\n\n        # There's no point in marking the same location twice in a row.\n        if isinstance(first_block, MarkLocation) and isinstance(second_block, MarkLocation):\n            raise AssertionError(u'Found consecutive MarkLocation blocks: {}'.format(ir_blocks))\n\n        # Traverse blocks with optional=True are immediately followed\n        # by a MarkLocation, CoerceType or Filter block.\n        if isinstance(first_block, Traverse) and first_block.optional:\n            if not isinstance(second_block, (MarkLocation, CoerceType, Filter)):\n                raise AssertionError(u'Expected MarkLocation, CoerceType or Filter after Traverse '\n                                     u'with optional=True. Found: {}'.format(ir_blocks))\n\n        # Backtrack blocks with optional=True are immediately followed by a MarkLocation block.\n        if isinstance(first_block, Backtrack) and first_block.optional:\n            if not isinstance(second_block, MarkLocation):\n                raise AssertionError(u'Expected MarkLocation after Backtrack with optional=True, '\n                                     u'but none was found: {}'.format(ir_blocks))\n\n        # Recurse blocks are immediately preceded by a MarkLocation or Backtrack block.\n        if isinstance(second_block, Recurse):\n            if not (isinstance(first_block, MarkLocation) or isinstance(first_block, Backtrack)):\n                raise AssertionError(u'Expected MarkLocation or Backtrack before Recurse, but none '\n                                     u'was found: {}'.format(ir_blocks))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nasserting that optional Traverse blocks are preceded by a MarkLocation.", "response": "def _sanity_check_mark_location_preceding_optional_traverse(ir_blocks):\n    \"\"\"Assert that optional Traverse blocks are preceded by a MarkLocation.\"\"\"\n    # Once all fold blocks are removed, each optional Traverse must have\n    # a MarkLocation block immediately before it.\n    _, new_ir_blocks = extract_folds_from_ir_blocks(ir_blocks)\n    for first_block, second_block in pairwise(new_ir_blocks):\n        # Traverse blocks with optional=True are immediately preceded by a MarkLocation block.\n        if isinstance(second_block, Traverse) and second_block.optional:\n            if not isinstance(first_block, MarkLocation):\n                raise AssertionError(u'Expected MarkLocation before Traverse with optional=True, '\n                                     u'but none was found: {}'.format(ir_blocks))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures that every new location is marked with a MarkLocation block.", "response": "def _sanity_check_every_location_is_marked(ir_blocks):\n    \"\"\"Ensure that every new location is marked with a MarkLocation block.\"\"\"\n    # Exactly one MarkLocation block is found between any block that starts an interval of blocks\n    # that all affect the same query position, and the first subsequent block that affects a\n    # different position in the query. Such intervals include the following examples:\n    # - from Fold to Unfold\n    # - from QueryRoot to Traverse/Recurse\n    # - from one Traverse to the next Traverse\n    # - from Traverse to Backtrack\n    found_start_block = False\n    mark_location_blocks_count = 0\n\n    start_interval_types = (QueryRoot, Traverse, Recurse, Fold)\n    end_interval_types = (Backtrack, ConstructResult, Recurse, Traverse, Unfold)\n\n    for block in ir_blocks:\n        # Terminate started intervals before opening new ones.\n        if isinstance(block, end_interval_types) and found_start_block:\n            found_start_block = False\n            if mark_location_blocks_count != 1:\n                raise AssertionError(u'Expected 1 MarkLocation block between traversals, found: '\n                                     u'{} {}'.format(mark_location_blocks_count, ir_blocks))\n\n        # Now consider opening new intervals or processing MarkLocation blocks.\n        if isinstance(block, MarkLocation):\n            mark_location_blocks_count += 1\n        elif isinstance(block, start_interval_types):\n            found_start_block = True\n            mark_location_blocks_count = 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring that CoerceType not in a Fold block is followed by a MarkLocation or Filter block.", "response": "def _sanity_check_coerce_type_outside_of_fold(ir_blocks):\n    \"\"\"Ensure that CoerceType not in a @fold are followed by a MarkLocation or Filter block.\"\"\"\n    is_in_fold = False\n    for first_block, second_block in pairwise(ir_blocks):\n        if isinstance(first_block, Fold):\n            is_in_fold = True\n\n        if not is_in_fold and isinstance(first_block, CoerceType):\n            if not isinstance(second_block, (MarkLocation, Filter)):\n                raise AssertionError(u'Expected MarkLocation or Filter after CoerceType, '\n                                     u'but none was found: {}'.format(ir_blocks))\n\n        if isinstance(second_block, Unfold):\n            is_in_fold = False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_supported_property_type_id(property_name, property_type_id):\n    if property_type_id not in PROPERTY_TYPE_ID_TO_NAME:\n        raise AssertionError(u'Property \"{}\" has unsupported property type id: '\n                             u'{}'.format(property_name, property_type_id))", "response": "Ensure that the given property type_id is supported by the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing and return the default value for a boolean property.", "response": "def _parse_bool_default_value(property_name, default_value_string):\n    \"\"\"Parse and return the default value for a boolean property.\"\"\"\n    lowercased_value_string = default_value_string.lower()\n    if lowercased_value_string in {'0', 'false'}:\n        return False\n    elif lowercased_value_string in {'1', 'true'}:\n        return True\n    else:\n        raise AssertionError(u'Unsupported default value for boolean property \"{}\": '\n                             u'{}'.format(property_name, default_value_string))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_datetime_default_value(property_name, default_value_string):\n    # OrientDB doesn't use ISO-8601 datetime format, so we have to parse it manually\n    # and then turn it into a python datetime object. strptime() will raise an exception\n    # if the provided value cannot be parsed correctly.\n    parsed_value = time.strptime(default_value_string, ORIENTDB_DATETIME_FORMAT)\n    return datetime.datetime(\n        parsed_value.tm_year, parsed_value.tm_mon, parsed_value.tm_mday,\n        parsed_value.tm_hour, parsed_value.tm_min, parsed_value.tm_sec, 0, None)", "response": "Parse and return the default value for a datetime property."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses and return the default value for a date property.", "response": "def _parse_date_default_value(property_name, default_value_string):\n    \"\"\"Parse and return the default value for a date property.\"\"\"\n    # OrientDB doesn't use ISO-8601 datetime format, so we have to parse it manually\n    # and then turn it into a python datetime object. strptime() will raise an exception\n    # if the provided value cannot be parsed correctly.\n    parsed_value = time.strptime(default_value_string, ORIENTDB_DATE_FORMAT)\n    return datetime.date(parsed_value.tm_year, parsed_value.tm_mon, parsed_value.tm_mday)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the default value string into its proper form given the property type ID.", "response": "def parse_default_property_value(property_name, property_type_id, default_value_string):\n    \"\"\"Parse the default value string into its proper form given the property type ID.\n\n    Args:\n        property_name: string, the name of the property whose default value is being parsed.\n                       Used primarily to construct meaningful error messages, should the default\n                       value prove invalid.\n        property_type_id: int, one of the property type ID constants defined in this file that\n                          OrientDB uses to designate the native type of a given property.\n        default_value_string: string, the textual representation of the default value for\n                              for the property, as returned by OrientDB's schema introspection code.\n\n    Returns:\n        an object of type matching the property that can be used as the property's default value.\n        For example, if the property is of string type, the return type will be a string, and if\n        the property is of list type, the return type will be a list.\n\n    Raises:\n        AssertionError, if the default value is not supported or does not match the\n        property's declared type (e.g. if a default of \"[]\" is set on an integer property).\n    \"\"\"\n    if property_type_id == PROPERTY_TYPE_EMBEDDED_SET_ID and default_value_string == '{}':\n        return set()\n    elif property_type_id == PROPERTY_TYPE_EMBEDDED_LIST_ID and default_value_string == '[]':\n        return list()\n    elif (property_type_id == PROPERTY_TYPE_STRING_ID and\n          isinstance(default_value_string, six.string_types)):\n        return default_value_string\n    elif property_type_id == PROPERTY_TYPE_BOOLEAN_ID:\n        return _parse_bool_default_value(property_name, default_value_string)\n    elif property_type_id == PROPERTY_TYPE_DATETIME_ID:\n        return _parse_datetime_default_value(property_name, default_value_string)\n    elif property_type_id == PROPERTY_TYPE_DATE_ID:\n        return _parse_date_default_value(property_name, default_value_string)\n    else:\n        raise AssertionError(u'Unsupported default value for property \"{}\" with type id {}: '\n                             u'{}'.format(property_name, property_type_id, default_value_string))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompiles the GraphQL query into a MATCH query and associated metadata.", "response": "def compile_graphql_to_match(schema, graphql_string, type_equivalence_hints=None):\n    \"\"\"Compile the GraphQL input using the schema into a MATCH query and associated metadata.\n\n    Args:\n        schema: GraphQL schema object describing the schema of the graph to be queried\n        graphql_string: the GraphQL query to compile to MATCH, as a string\n        type_equivalence_hints: optional dict of GraphQL interface or type -> GraphQL union.\n                                Used as a workaround for GraphQL's lack of support for\n                                inheritance across \"types\" (i.e. non-interfaces), as well as a\n                                workaround for Gremlin's total lack of inheritance-awareness.\n                                The key-value pairs in the dict specify that the \"key\" type\n                                is equivalent to the \"value\" type, i.e. that the GraphQL type or\n                                interface in the key is the most-derived common supertype\n                                of every GraphQL type in the \"value\" GraphQL union.\n                                Recursive expansion of type equivalence hints is not performed,\n                                and only type-level correctness of this argument is enforced.\n                                See README.md for more details on everything this parameter does.\n                                *****\n                                Be very careful with this option, as bad input here will\n                                lead to incorrect output queries being generated.\n                                *****\n\n    Returns:\n        a CompilationResult object\n    \"\"\"\n    lowering_func = ir_lowering_match.lower_ir\n    query_emitter_func = emit_match.emit_code_from_ir\n\n    return _compile_graphql_generic(\n        MATCH_LANGUAGE, lowering_func, query_emitter_func,\n        schema, graphql_string, type_equivalence_hints, None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_graphql_to_gremlin(schema, graphql_string, type_equivalence_hints=None):\n    lowering_func = ir_lowering_gremlin.lower_ir\n    query_emitter_func = emit_gremlin.emit_code_from_ir\n\n    return _compile_graphql_generic(\n        GREMLIN_LANGUAGE, lowering_func, query_emitter_func,\n        schema, graphql_string, type_equivalence_hints, None)", "response": "Compile the GraphQL query into Gremlin query and associated metadata."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_graphql_to_sql(schema, graphql_string, compiler_metadata, type_equivalence_hints=None):\n    lowering_func = ir_lowering_sql.lower_ir\n    query_emitter_func = emit_sql.emit_code_from_ir\n    return _compile_graphql_generic(\n        SQL_LANGUAGE, lowering_func, query_emitter_func,\n        schema, graphql_string, type_equivalence_hints, compiler_metadata)", "response": "Compile the GraphQL query into a SQL query and associated metadata."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _compile_graphql_generic(language, lowering_func, query_emitter_func,\n                             schema, graphql_string, type_equivalence_hints, compiler_metadata):\n    \"\"\"Compile the GraphQL input, lowering and emitting the query using the given functions.\n\n    Args:\n        language: string indicating the target language to compile to.\n        lowering_func: Function to lower the compiler IR into a compatible form for the target\n                       language backend.\n        query_emitter_func: Function that emits a query in the target language from the lowered IR.\n        schema: GraphQL schema object describing the schema of the graph to be queried.\n        graphql_string: the GraphQL query to compile to the target language, as a string.\n        type_equivalence_hints: optional dict of GraphQL interface or type -> GraphQL union.\n        compiler_metadata: optional target specific metadata for usage by the query_emitter_func.\n\n    Returns:\n        a CompilationResult object\n    \"\"\"\n    ir_and_metadata = graphql_to_ir(\n        schema, graphql_string, type_equivalence_hints=type_equivalence_hints)\n\n    lowered_ir_blocks = lowering_func(\n        ir_and_metadata.ir_blocks, ir_and_metadata.query_metadata_table,\n        type_equivalence_hints=type_equivalence_hints)\n\n    query = query_emitter_func(lowered_ir_blocks, compiler_metadata)\n\n    return CompilationResult(\n        query=query,\n        language=language,\n        output_metadata=ir_and_metadata.output_metadata,\n        input_metadata=ir_and_metadata.input_metadata)", "response": "Compile the GraphQL input lowering and emitting the query using the given functions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scalar_leaf_only(operator):\n    def decorator(f):\n        \"\"\"Decorate the supplied function with the \"scalar_leaf_only\" logic.\"\"\"\n        @wraps(f)\n        def wrapper(filter_operation_info, context, parameters, *args, **kwargs):\n            \"\"\"Check that the type on which the operator operates is a scalar leaf type.\"\"\"\n            if 'operator' in kwargs:\n                current_operator = kwargs['operator']\n            else:\n                # Because \"operator\" is from an enclosing scope, it is immutable in Python 2.x.\n                current_operator = operator\n\n            if not is_leaf_type(filter_operation_info.field_type):\n                raise GraphQLCompilationError(u'Cannot apply \"{}\" filter to non-leaf type'\n                                              u'{}'.format(current_operator, filter_operation_info))\n            return f(filter_operation_info, context, parameters, *args, **kwargs)\n\n        return wrapper\n\n    return decorator", "response": "Decorator to ensure the filter function is only applied to scalar leaf types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nensure the filter function is only applied to vertex field types.", "response": "def vertex_field_only(operator):\n    \"\"\"Ensure the filter function is only applied to vertex field types.\"\"\"\n    def decorator(f):\n        \"\"\"Decorate the supplied function with the \"vertex_field_only\" logic.\"\"\"\n        @wraps(f)\n        def wrapper(filter_operation_info, context, parameters, *args, **kwargs):\n            \"\"\"Check that the type on which the operator operates is a vertex field type.\"\"\"\n            if 'operator' in kwargs:\n                current_operator = kwargs['operator']\n            else:\n                # Because \"operator\" is from an enclosing scope, it is immutable in Python 2.x.\n                current_operator = operator\n\n            if not is_vertex_field_type(filter_operation_info.field_type):\n                raise GraphQLCompilationError(\n                    u'Cannot apply \"{}\" filter to non-vertex field: '\n                    u'{}'.format(current_operator, filter_operation_info.field_name))\n            return f(filter_operation_info, context, parameters, *args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef takes_parameters(count):\n    def decorator(f):\n        \"\"\"Decorate the supplied function with the \"takes_parameters\" logic.\"\"\"\n        @wraps(f)\n        def wrapper(filter_operation_info, location, context, parameters, *args, **kwargs):\n            \"\"\"Check that the supplied number of parameters equals the expected number.\"\"\"\n            if len(parameters) != count:\n                raise GraphQLCompilationError(u'Incorrect number of parameters, expected {} got '\n                                              u'{}: {}'.format(count, len(parameters), parameters))\n\n            return f(filter_operation_info, location, context, parameters, *args, **kwargs)\n\n        return wrapper\n\n    return decorator", "response": "Decorator to ensure the filter function has count parameters specified."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _represent_argument(directive_location, context, argument, inferred_type):\n    # Regardless of what kind of variable we are dealing with,\n    # we want to ensure its name is valid.\n    argument_name = argument[1:]\n    validate_safe_string(argument_name)\n\n    if is_variable_argument(argument):\n        existing_type = context['inputs'].get(argument_name, inferred_type)\n        if not inferred_type.is_same_type(existing_type):\n            raise GraphQLCompilationError(u'Incompatible types inferred for argument {}. '\n                                          u'The argument cannot simultaneously be '\n                                          u'{} and {}.'.format(argument, existing_type,\n                                                               inferred_type))\n        context['inputs'][argument_name] = inferred_type\n\n        return (expressions.Variable(argument, inferred_type), None)\n    elif is_tag_argument(argument):\n        argument_context = context['tags'].get(argument_name, None)\n        if argument_context is None:\n            raise GraphQLCompilationError(u'Undeclared argument used: {}'.format(argument))\n\n        location = argument_context['location']\n        optional = argument_context['optional']\n        tag_inferred_type = argument_context['type']\n\n        if location is None:\n            raise AssertionError(u'Argument declared without location: {}'.format(argument_name))\n\n        if location.field is None:\n            raise AssertionError(u'Argument location is not a property field: {}'.format(location))\n\n        if not inferred_type.is_same_type(tag_inferred_type):\n            raise GraphQLCompilationError(u'The inferred type of the matching @tag directive does '\n                                          u'not match the inferred required type for this filter: '\n                                          u'{} vs {}'.format(tag_inferred_type, inferred_type))\n\n        # Check whether the argument is a field on the vertex on which the directive is applied.\n        field_is_local = directive_location.at_vertex() == location.at_vertex()\n\n        non_existence_expression = None\n        if optional:\n            if field_is_local:\n                non_existence_expression = expressions.FalseLiteral\n            else:\n                non_existence_expression = expressions.BinaryComposition(\n                    u'=',\n                    expressions.ContextFieldExistence(location.at_vertex()),\n                    expressions.FalseLiteral)\n\n        if field_is_local:\n            representation = expressions.LocalField(argument_name)\n        else:\n            representation = expressions.ContextField(location, tag_inferred_type)\n\n        return (representation, non_existence_expression)\n    else:\n        # If we want to support literal arguments, add them here.\n        raise GraphQLCompilationError(u'Non-argument type found: {}'.format(argument))", "response": "Return a two - element tuple that represents the argument to the current block."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_comparison_filter_directive(filter_operation_info, location,\n                                         context, parameters, operator=None):\n    \"\"\"Return a Filter basic block that performs the given comparison against the property field.\n\n    Args:\n        filter_operation_info: FilterOperationInfo object, containing the directive and field info\n                               of the field where the filter is to be applied.\n        location: Location where this filter is used.\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n        parameters: list of 1 element, containing the value to perform the comparison against;\n                    if the parameter is optional and missing, the check will return True\n        operator: unicode, a comparison operator, like '=', '!=', '>=' etc.\n                  This is a kwarg only to preserve the same positional arguments in the\n                  function signature, to ease validation.\n\n    Returns:\n        a Filter basic block that performs the requested comparison\n    \"\"\"\n    comparison_operators = {u'=', u'!=', u'>', u'<', u'>=', u'<='}\n    if operator not in comparison_operators:\n        raise AssertionError(u'Expected a valid comparison operator ({}), but got '\n                             u'{}'.format(comparison_operators, operator))\n\n    filtered_field_type = filter_operation_info.field_type\n    filtered_field_name = filter_operation_info.field_name\n\n    argument_inferred_type = strip_non_null_from_type(filtered_field_type)\n    argument_expression, non_existence_expression = _represent_argument(\n        location, context, parameters[0], argument_inferred_type)\n\n    comparison_expression = expressions.BinaryComposition(\n        operator, expressions.LocalField(filtered_field_name), argument_expression)\n\n    final_expression = None\n    if non_existence_expression is not None:\n        # The argument comes from an optional block and might not exist,\n        # in which case the filter expression should evaluate to True.\n        final_expression = expressions.BinaryComposition(\n            u'||', non_existence_expression, comparison_expression)\n    else:\n        final_expression = comparison_expression\n\n    return blocks.Filter(final_expression)", "response": "Returns a Filter basic block that performs the given comparison against the property field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_has_edge_degree_filter_directive(filter_operation_info, location, context, parameters):\n    if isinstance(filter_operation_info.field_ast, InlineFragment):\n        raise AssertionError(u'Received InlineFragment AST node in \"has_edge_degree\" filter '\n                             u'handler. This should have been caught earlier: '\n                             u'{}'.format(filter_operation_info.field_ast))\n\n    filtered_field_name = filter_operation_info.field_name\n    if filtered_field_name is None or not is_vertex_field_name(filtered_field_name):\n        raise AssertionError(u'Invalid value for \"filtered_field_name\" in \"has_edge_degree\" '\n                             u'filter: {}'.format(filtered_field_name))\n\n    if not is_vertex_field_type(filter_operation_info.field_type):\n        raise AssertionError(u'Invalid value for \"filter_operation_info.field_type\" in '\n                             u'\"has_edge_degree\" filter: {}'.format(filter_operation_info))\n\n    argument = parameters[0]\n    if not is_variable_argument(argument):\n        raise GraphQLCompilationError(u'The \"has_edge_degree\" filter only supports runtime '\n                                      u'variable arguments. Tagged values are not supported.'\n                                      u'Argument name: {}'.format(argument))\n\n    argument_inferred_type = GraphQLInt\n    argument_expression, non_existence_expression = _represent_argument(\n        location, context, argument, argument_inferred_type)\n\n    if non_existence_expression is not None:\n        raise AssertionError(u'Since we do not support tagged values, non_existence_expression '\n                             u'should have been None. However, it was: '\n                             u'{}'.format(non_existence_expression))\n\n    # If no edges to the vertex field exist, the edges' field in the database may be \"null\".\n    # We also don't know ahead of time whether the supplied argument is zero or not.\n    # We have to accommodate these facts in our generated comparison code.\n    # We construct the following expression to check if the edge degree is zero:\n    #   ({argument} == 0) && (edge_field == null)\n    argument_is_zero = expressions.BinaryComposition(\n        u'=', argument_expression, expressions.ZeroLiteral)\n    edge_field_is_null = expressions.BinaryComposition(\n        u'=', expressions.LocalField(filtered_field_name), expressions.NullLiteral)\n    edge_degree_is_zero = expressions.BinaryComposition(\n        u'&&', argument_is_zero, edge_field_is_null)\n\n    # The following expression will check for a non-zero edge degree equal to the argument.\n    #  (edge_field != null) && (edge_field.size() == {argument})\n    edge_field_is_not_null = expressions.BinaryComposition(\n        u'!=', expressions.LocalField(filtered_field_name), expressions.NullLiteral)\n    edge_degree = expressions.UnaryTransformation(\n        u'size', expressions.LocalField(filtered_field_name))\n    edge_degree_matches_argument = expressions.BinaryComposition(\n        u'=', edge_degree, argument_expression)\n    edge_degree_is_non_zero = expressions.BinaryComposition(\n        u'&&', edge_field_is_not_null, edge_degree_matches_argument)\n\n    # We combine the two cases with a logical-or to handle both situations:\n    filter_predicate = expressions.BinaryComposition(\n        u'||', edge_degree_is_zero, edge_degree_is_non_zero)\n    return blocks.Filter(filter_predicate)", "response": "Process a has edge degree filter directive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing a name or alias filter directive.", "response": "def _process_name_or_alias_filter_directive(filter_operation_info, location, context, parameters):\n    \"\"\"Return a Filter basic block that checks for a match against an Entity's name or alias.\n\n    Args:\n        filter_operation_info: FilterOperationInfo object, containing the directive and field info\n                               of the field where the filter is to be applied.\n        location: Location where this filter is used.\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n        parameters: list of 1 element, containing the value to check the name or alias against;\n                    if the parameter is optional and missing, the check will return True\n\n    Returns:\n        a Filter basic block that performs the check against the name or alias\n    \"\"\"\n    filtered_field_type = filter_operation_info.field_type\n    if isinstance(filtered_field_type, GraphQLUnionType):\n        raise GraphQLCompilationError(u'Cannot apply \"name_or_alias\" to union type '\n                                      u'{}'.format(filtered_field_type))\n\n    current_type_fields = filtered_field_type.fields\n    name_field = current_type_fields.get('name', None)\n    alias_field = current_type_fields.get('alias', None)\n    if not name_field or not alias_field:\n        raise GraphQLCompilationError(u'Cannot apply \"name_or_alias\" to type {} because it lacks a '\n                                      u'\"name\" or \"alias\" field.'.format(filtered_field_type))\n\n    name_field_type = strip_non_null_from_type(name_field.type)\n    alias_field_type = strip_non_null_from_type(alias_field.type)\n\n    if not isinstance(name_field_type, GraphQLScalarType):\n        raise GraphQLCompilationError(u'Cannot apply \"name_or_alias\" to type {} because its \"name\" '\n                                      u'field is not a scalar.'.format(filtered_field_type))\n    if not isinstance(alias_field_type, GraphQLList):\n        raise GraphQLCompilationError(u'Cannot apply \"name_or_alias\" to type {} because its '\n                                      u'\"alias\" field is not a list.'.format(filtered_field_type))\n\n    alias_field_inner_type = strip_non_null_from_type(alias_field_type.of_type)\n    if alias_field_inner_type != name_field_type:\n        raise GraphQLCompilationError(u'Cannot apply \"name_or_alias\" to type {} because the '\n                                      u'\"name\" field and the inner type of the \"alias\" field '\n                                      u'do not match: {} vs {}'.format(filtered_field_type,\n                                                                       name_field_type,\n                                                                       alias_field_inner_type))\n\n    argument_inferred_type = name_field_type\n    argument_expression, non_existence_expression = _represent_argument(\n        location, context, parameters[0], argument_inferred_type)\n\n    check_against_name = expressions.BinaryComposition(\n        u'=', expressions.LocalField('name'), argument_expression)\n    check_against_alias = expressions.BinaryComposition(\n        u'contains', expressions.LocalField('alias'), argument_expression)\n    filter_predicate = expressions.BinaryComposition(\n        u'||', check_against_name, check_against_alias)\n\n    if non_existence_expression is not None:\n        # The argument comes from an optional block and might not exist,\n        # in which case the filter expression should evaluate to True.\n        filter_predicate = expressions.BinaryComposition(\n            u'||', non_existence_expression, filter_predicate)\n\n    return blocks.Filter(filter_predicate)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a Filter basic block that checks that a field is between two values inclusive.", "response": "def _process_between_filter_directive(filter_operation_info, location, context, parameters):\n    \"\"\"Return a Filter basic block that checks that a field is between two values, inclusive.\n\n    Args:\n        filter_operation_info: FilterOperationInfo object, containing the directive and field info\n                               of the field where the filter is to be applied.\n        location: Location where this filter is used.\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n        parameters: list of 2 elements, specifying the time range in which the data must lie;\n                    if either of the elements is optional and missing,\n                    their side of the check is assumed to be True\n\n    Returns:\n        a Filter basic block that performs the range check\n    \"\"\"\n    filtered_field_type = filter_operation_info.field_type\n    filtered_field_name = filter_operation_info.field_name\n\n    argument_inferred_type = strip_non_null_from_type(filtered_field_type)\n    arg1_expression, arg1_non_existence = _represent_argument(\n        location, context, parameters[0], argument_inferred_type)\n    arg2_expression, arg2_non_existence = _represent_argument(\n        location, context, parameters[1], argument_inferred_type)\n\n    lower_bound_clause = expressions.BinaryComposition(\n        u'>=', expressions.LocalField(filtered_field_name), arg1_expression)\n    if arg1_non_existence is not None:\n        # The argument is optional, and if it doesn't exist, this side of the check should pass.\n        lower_bound_clause = expressions.BinaryComposition(\n            u'||', arg1_non_existence, lower_bound_clause)\n\n    upper_bound_clause = expressions.BinaryComposition(\n        u'<=', expressions.LocalField(filtered_field_name), arg2_expression)\n    if arg2_non_existence is not None:\n        # The argument is optional, and if it doesn't exist, this side of the check should pass.\n        upper_bound_clause = expressions.BinaryComposition(\n            u'||', arg2_non_existence, upper_bound_clause)\n\n    filter_predicate = expressions.BinaryComposition(\n        u'&&', lower_bound_clause, upper_bound_clause)\n    return blocks.Filter(filter_predicate)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_in_collection_filter_directive(filter_operation_info, location, context, parameters):\n    filtered_field_type = filter_operation_info.field_type\n    filtered_field_name = filter_operation_info.field_name\n\n    argument_inferred_type = GraphQLList(strip_non_null_from_type(filtered_field_type))\n    argument_expression, non_existence_expression = _represent_argument(\n        location, context, parameters[0], argument_inferred_type)\n\n    filter_predicate = expressions.BinaryComposition(\n        u'contains', argument_expression, expressions.LocalField(filtered_field_name))\n    if non_existence_expression is not None:\n        # The argument comes from an optional block and might not exist,\n        # in which case the filter expression should evaluate to True.\n        filter_predicate = expressions.BinaryComposition(\n            u'||', non_existence_expression, filter_predicate)\n\n    return blocks.Filter(filter_predicate)", "response": "Processes a filter directive that checks for a value s existence in a collection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing a has substring filter directive.", "response": "def _process_has_substring_filter_directive(filter_operation_info, location, context, parameters):\n    \"\"\"Return a Filter basic block that checks if the directive arg is a substring of the field.\n\n    Args:\n        filter_operation_info: FilterOperationInfo object, containing the directive and field info\n                               of the field where the filter is to be applied.\n        location: Location where this filter is used.\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n        parameters: list of 1 element, specifying the collection in which the value must exist;\n                    if the collection is optional and missing, the check will return True\n\n    Returns:\n        a Filter basic block that performs the substring check\n    \"\"\"\n    filtered_field_type = filter_operation_info.field_type\n    filtered_field_name = filter_operation_info.field_name\n\n    if not strip_non_null_from_type(filtered_field_type).is_same_type(GraphQLString):\n        raise GraphQLCompilationError(u'Cannot apply \"has_substring\" to non-string '\n                                      u'type {}'.format(filtered_field_type))\n    argument_inferred_type = GraphQLString\n\n    argument_expression, non_existence_expression = _represent_argument(\n        location, context, parameters[0], argument_inferred_type)\n\n    filter_predicate = expressions.BinaryComposition(\n        u'has_substring', expressions.LocalField(filtered_field_name), argument_expression)\n    if non_existence_expression is not None:\n        # The argument comes from an optional block and might not exist,\n        # in which case the filter expression should evaluate to True.\n        filter_predicate = expressions.BinaryComposition(\n            u'||', non_existence_expression, filter_predicate)\n\n    return blocks.Filter(filter_predicate)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Filter basic block that checks if the directive arg is contained in the field.", "response": "def _process_contains_filter_directive(filter_operation_info, location, context, parameters):\n    \"\"\"Return a Filter basic block that checks if the directive arg is contained in the field.\n\n    Args:\n        filter_operation_info: FilterOperationInfo object, containing the directive and field info\n                               of the field where the filter is to be applied.\n        location: Location where this filter is used.\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n        parameters: list of 1 element, specifying the collection in which the value must exist;\n                    if the collection is optional and missing, the check will return True\n\n    Returns:\n        a Filter basic block that performs the contains check\n    \"\"\"\n    filtered_field_type = filter_operation_info.field_type\n    filtered_field_name = filter_operation_info.field_name\n\n    base_field_type = strip_non_null_from_type(filtered_field_type)\n    if not isinstance(base_field_type, GraphQLList):\n        raise GraphQLCompilationError(u'Cannot apply \"contains\" to non-list '\n                                      u'type {}'.format(filtered_field_type))\n\n    argument_inferred_type = strip_non_null_from_type(base_field_type.of_type)\n    argument_expression, non_existence_expression = _represent_argument(\n        location, context, parameters[0], argument_inferred_type)\n\n    filter_predicate = expressions.BinaryComposition(\n        u'contains', expressions.LocalField(filtered_field_name), argument_expression)\n    if non_existence_expression is not None:\n        # The argument comes from an optional block and might not exist,\n        # in which case the filter expression should evaluate to True.\n        filter_predicate = expressions.BinaryComposition(\n            u'||', non_existence_expression, filter_predicate)\n\n    return blocks.Filter(filter_predicate)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_intersects_filter_directive(filter_operation_info, location, context, parameters):\n    filtered_field_type = filter_operation_info.field_type\n    filtered_field_name = filter_operation_info.field_name\n\n    argument_inferred_type = strip_non_null_from_type(filtered_field_type)\n    if not isinstance(argument_inferred_type, GraphQLList):\n        raise GraphQLCompilationError(u'Cannot apply \"intersects\" to non-list '\n                                      u'type {}'.format(filtered_field_type))\n\n    argument_expression, non_existence_expression = _represent_argument(\n        location, context, parameters[0], argument_inferred_type)\n\n    filter_predicate = expressions.BinaryComposition(\n        u'intersects', expressions.LocalField(filtered_field_name), argument_expression)\n    if non_existence_expression is not None:\n        # The argument comes from an optional block and might not exist,\n        # in which case the filter expression should evaluate to True.\n        filter_predicate = expressions.BinaryComposition(\n            u'||', non_existence_expression, filter_predicate)\n\n    return blocks.Filter(filter_predicate)", "response": "Returns a Filter basic block that checks if the directive arg and the field intersect."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_filter_op_name_and_values(directive):\n    args = get_uniquely_named_objects_by_name(directive.arguments)\n    if 'op_name' not in args:\n        raise AssertionError(u'op_name not found in filter directive arguments!'\n                             u'Validation should have caught this: {}'.format(directive))\n\n    # HACK(predrag): Workaround for graphql-core validation issue\n    #                https://github.com/graphql-python/graphql-core/issues/97\n    if not isinstance(args['value'].value, ListValue):\n        raise GraphQLValidationError(u'Filter directive value was not a list: {}'.format(directive))\n\n    op_name = args['op_name'].value.value\n    operator_params = [x.value for x in args['value'].value.values]\n\n    return (op_name, operator_params)", "response": "Extract the op_name operator_params tuple from a filter directive object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_filter_with_outer_scope_vertex_field_operator(directive):\n    if directive.name.value != 'filter':\n        return False\n\n    op_name, _ = _get_filter_op_name_and_values(directive)\n    return op_name in OUTER_SCOPE_VERTEX_FIELD_OPERATORS", "response": "Return True if we have a filter directive whose operator applies to the outer scope."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Filter basic block that applies the filter operation in the filter operation in the directive.", "response": "def process_filter_directive(filter_operation_info, location, context):\n    \"\"\"Return a Filter basic block that corresponds to the filter operation in the directive.\n\n    Args:\n        filter_operation_info: FilterOperationInfo object, containing the directive and field info\n                               of the field where the filter is to be applied.\n        location: Location where this filter is used.\n        context: dict, various per-compilation data (e.g. declared tags, whether the current block\n                 is optional, etc.). May be mutated in-place in this function!\n\n    Returns:\n        a Filter basic block that performs the requested filtering operation\n    \"\"\"\n    op_name, operator_params = _get_filter_op_name_and_values(filter_operation_info.directive)\n\n    non_comparison_filters = {\n        u'name_or_alias': _process_name_or_alias_filter_directive,\n        u'between': _process_between_filter_directive,\n        u'in_collection': _process_in_collection_filter_directive,\n        u'has_substring': _process_has_substring_filter_directive,\n        u'contains': _process_contains_filter_directive,\n        u'intersects': _process_intersects_filter_directive,\n        u'has_edge_degree': _process_has_edge_degree_filter_directive,\n    }\n    all_recognized_filters = frozenset(non_comparison_filters.keys()) | COMPARISON_OPERATORS\n    if all_recognized_filters != ALL_OPERATORS:\n        unrecognized_filters = ALL_OPERATORS - all_recognized_filters\n        raise AssertionError(u'Some filtering operators are defined but do not have an associated '\n                             u'processing function. This is a bug: {}'.format(unrecognized_filters))\n\n    if op_name in COMPARISON_OPERATORS:\n        process_func = partial(_process_comparison_filter_directive, operator=op_name)\n    else:\n        process_func = non_comparison_filters.get(op_name, None)\n\n    if process_func is None:\n        raise GraphQLCompilationError(u'Unknown op_name for filter directive: {}'.format(op_name))\n\n    # Operators that do not affect the inner scope require a field name to which they apply.\n    # There is no field name on InlineFragment ASTs, which is why only operators that affect\n    # the inner scope make semantic sense when applied to InlineFragments.\n    # Here, we ensure that we either have a field name to which the filter applies,\n    # or that the operator affects the inner scope.\n    if (filter_operation_info.field_name is None and\n            op_name not in INNER_SCOPE_VERTEX_FIELD_OPERATORS):\n        raise GraphQLCompilationError(u'The filter with op_name \"{}\" must be applied on a field. '\n                                      u'It may not be applied on a type coercion.'.format(op_name))\n\n    fields = ((filter_operation_info.field_name,) if op_name != 'name_or_alias'\n              else ('name', 'alias'))\n\n    context['metadata'].record_filter_info(\n        location,\n        FilterInfo(fields=fields, op_name=op_name, args=tuple(operator_params))\n    )\n\n    return process_func(filter_operation_info, location, context, operator_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the GraphQL type name of a node.", "response": "def get_schema_type_name(node, context):\n    \"\"\"Return the GraphQL type name of a node.\"\"\"\n    query_path = node.query_path\n    if query_path not in context.query_path_to_location_info:\n        raise AssertionError(\n            u'Unable to find type name for query path {} with context {}.'.format(\n                query_path, context))\n    location_info = context.query_path_to_location_info[query_path]\n    return location_info.type.name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the Selectable Union [ Table CTE ] associated with the node.", "response": "def get_node_selectable(node, context):\n    \"\"\"Return the Selectable Union[Table, CTE] associated with the node.\"\"\"\n    query_path = node.query_path\n    if query_path not in context.query_path_to_selectable:\n        raise AssertionError(\n            u'Unable to find selectable for query path {} with context {}.'.format(\n                query_path, context))\n    selectable = context.query_path_to_selectable[query_path]\n    return selectable"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_node_at_path(query_path, context):\n    if query_path not in context.query_path_to_node:\n        raise AssertionError(\n            u'Unable to find SqlNode for query path {} with context {}.'.format(\n                query_path, context))\n    node = context.query_path_to_node[query_path]\n    return node", "response": "Return the SqlNode associated with the query path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef try_get_column(column_name, node, context):\n    selectable = get_node_selectable(node, context)\n    if not hasattr(selectable, 'c'):\n        raise AssertionError(\n            u'Selectable \"{}\" does not have a column collection. Context is {}.'.format(\n                selectable, context))\n    return selectable.c.get(column_name, None)", "response": "Attempt to get a column by name from the selectable."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a column by name from the selectable.", "response": "def get_column(column_name, node, context):\n    \"\"\"Get a column by name from the selectable.\n\n    Args:\n        column_name: str, name of the column to retrieve.\n        node: SqlNode, the node the column is being retrieved for.\n        context: CompilationContext, compilation specific metadata.\n\n    Returns:\n        column, the SQLAlchemy column if found. Raises an AssertionError otherwise.\n    \"\"\"\n    column = try_get_column(column_name, node, context)\n    if column is None:\n        selectable = get_node_selectable(node, context)\n        raise AssertionError(\n            u'Column \"{}\" not found in selectable \"{}\". Columns present are {}. '\n            u'Context is {}.'.format(column_name, selectable.original,\n                                     [col.name for col in selectable.c], context))\n    return column"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dict of directive name to directive object for the given GraphQL AST node.", "response": "def get_unique_directives(ast):\n    \"\"\"Return a dict of directive name to directive object for the given AST node.\n\n    Any directives that are allowed to exist more than once on any AST node are ignored.\n    For any directives that can only exist up to once, we verify that they are not duplicated\n    raising GraphQLCompilationError in case we find them more than once on the AST node.\n\n    Args:\n        ast: GraphQL AST node, obtained from the graphql library\n\n    Returns:\n        dict of string to directive object\n    \"\"\"\n    if not ast.directives:\n        return dict()\n\n    result = dict()\n    for directive_obj in ast.directives:\n        directive_name = directive_obj.name.value\n        if directive_name in ALLOWED_DUPLICATED_DIRECTIVES:\n            pass  # We don't return these.\n        elif directive_name in result:\n            raise GraphQLCompilationError(u'Directive was unexpectedly applied twice in the same '\n                                          u'location: {} {}'.format(directive_name, ast.directives))\n        else:\n            result[directive_name] = directive_obj\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of filter directives that apply to the current field.", "response": "def get_local_filter_directives(ast, current_schema_type, inner_vertex_fields):\n    \"\"\"Get all filter directives that apply to the current field.\n\n    This helper abstracts away the fact that some vertex field filtering operators apply on the\n    inner scope (the scope of the inner vertex field on which they are applied), whereas some apply\n    on the outer scope (the scope that contains the inner vertex field).\n    See filters.py for more information.\n\n    Args:\n        ast: a GraphQL AST object for which to load local filters, from the graphql library\n        current_schema_type: GraphQLType, the schema type at the current AST location\n        inner_vertex_fields: a list of inner AST objects representing vertex fields that are within\n                             the current field. If currently processing a property field (i.e.\n                             there are no inner vertex fields), this argument may be set to None.\n\n    Returns:\n        list of FilterOperationInfo objects.\n        If the field_ast field is of type InlineFragment, the field_name field is set to None.\n    \"\"\"\n    result = []\n    if ast.directives:  # it'll be None if the AST has no directives at that node\n        for directive_obj in ast.directives:\n            # Of all filters that appear *on the field itself*, only the ones that apply\n            # to the outer scope are not considered \"local\" and are not to be returned.\n            if directive_obj.name.value == 'filter':\n                filtered_field_name = get_ast_field_name_or_none(ast)\n                if is_filter_with_outer_scope_vertex_field_operator(directive_obj):\n                    # We found a filter that affects the outer scope vertex. Let's make sure\n                    # we are at a vertex field. If we are actually at a property field,\n                    # that is a compilation error.\n                    if not is_vertex_field_type(current_schema_type):\n                        raise GraphQLCompilationError(\n                            u'Found disallowed filter on a property field: {} {} '\n                            u'{}'.format(directive_obj, current_schema_type, filtered_field_name))\n                    elif isinstance(ast, InlineFragment):\n                        raise GraphQLCompilationError(\n                            u'Found disallowed filter on a type coercion: {} '\n                            u'{}'.format(directive_obj, current_schema_type))\n                    else:\n                        # The filter is valid and non-local, since it is applied at this AST node\n                        # but affects the outer scope vertex field. Skip over it.\n                        pass\n                else:\n                    operation = FilterOperationInfo(\n                        directive=directive_obj, field_name=filtered_field_name,\n                        field_type=current_schema_type, field_ast=ast)\n                    result.append(operation)\n\n    if inner_vertex_fields:  # allow the argument to be None\n        for inner_ast in inner_vertex_fields:\n            for directive_obj in inner_ast.directives:\n                # Of all filters that appear on an inner vertex field, only the ones that apply\n                # to the outer scope are \"local\" to the outer field and therefore to be returned.\n                if is_filter_with_outer_scope_vertex_field_operator(directive_obj):\n                    # The inner AST must not be an InlineFragment, so it must have a field name.\n                    filtered_field_name = get_ast_field_name(inner_ast)\n                    filtered_field_type = get_vertex_field_type(\n                        current_schema_type, filtered_field_name)\n\n                    operation = FilterOperationInfo(\n                        directive=directive_obj, field_name=filtered_field_name,\n                        field_type=filtered_field_type, field_ast=inner_ast)\n                    result.append(operation)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_property_directives(directives):\n    for directive_name in six.iterkeys(directives):\n        if directive_name in VERTEX_ONLY_DIRECTIVES:\n            raise GraphQLCompilationError(\n                u'Found vertex-only directive {} set on property.'.format(directive_name))", "response": "Validate the directives that appear at a property field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the directives that appear at a vertex field.", "response": "def validate_vertex_directives(directives):\n    \"\"\"Validate the directives that appear at a vertex field.\"\"\"\n    for directive_name in six.iterkeys(directives):\n        if directive_name in PROPERTY_ONLY_DIRECTIVES:\n            raise GraphQLCompilationError(\n                u'Found property-only directive {} set on vertex.'.format(directive_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_root_vertex_directives(root_ast):\n    directives_present_at_root = set()\n    for directive_obj in root_ast.directives:\n        directive_name = directive_obj.name.value\n\n        if is_filter_with_outer_scope_vertex_field_operator(directive_obj):\n            raise GraphQLCompilationError(u'Found a filter directive with an operator that is not'\n                                          u'allowed on the root vertex: {}'.format(directive_obj))\n\n        directives_present_at_root.add(directive_name)\n\n    disallowed_directives = directives_present_at_root & VERTEX_DIRECTIVES_PROHIBITED_ON_ROOT\n    if disallowed_directives:\n        raise GraphQLCompilationError(u'Found prohibited directives on root vertex: '\n                                      u'{}'.format(disallowed_directives))", "response": "Validate the directives that appear at the root vertex field."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_vertex_field_directive_interactions(parent_location, vertex_field_name, directives):\n    fold_directive = directives.get('fold', None)\n    optional_directive = directives.get('optional', None)\n    output_source_directive = directives.get('output_source', None)\n    recurse_directive = directives.get('recurse', None)\n\n    if fold_directive and optional_directive:\n        raise GraphQLCompilationError(u'@fold and @optional may not appear at the same '\n                                      u'vertex field! Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n\n    if fold_directive and output_source_directive:\n        raise GraphQLCompilationError(u'@fold and @output_source may not appear at the same '\n                                      u'vertex field! Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n\n    if fold_directive and recurse_directive:\n        raise GraphQLCompilationError(u'@fold and @recurse may not appear at the same '\n                                      u'vertex field! Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n\n    if optional_directive and output_source_directive:\n        raise GraphQLCompilationError(u'@optional and @output_source may not appear at the same '\n                                      u'vertex field! Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n\n    if optional_directive and recurse_directive:\n        raise GraphQLCompilationError(u'@optional and @recurse may not appear at the same '\n                                      u'vertex field! Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))", "response": "Ensure that the specified vertex field directives are not mutually disallowed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_vertex_field_directive_in_context(parent_location, vertex_field_name,\n                                               directives, context):\n    \"\"\"Ensure that the specified vertex field directives are allowed in the current context.\"\"\"\n    fold_directive = directives.get('fold', None)\n    optional_directive = directives.get('optional', None)\n    recurse_directive = directives.get('recurse', None)\n    output_source_directive = directives.get('output_source', None)\n\n    fold_context = 'fold' in context\n    optional_context = 'optional' in context\n    output_source_context = 'output_source' in context\n\n    if fold_directive and fold_context:\n        raise GraphQLCompilationError(u'@fold is not allowed within a @fold traversal! '\n                                      u'Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n    if optional_directive and fold_context:\n        raise GraphQLCompilationError(u'@optional is not allowed within a @fold traversal! '\n                                      u'Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n    if output_source_directive and fold_context:\n        raise GraphQLCompilationError(u'@output_source is not allowed within a @fold traversal! '\n                                      u'Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n    if recurse_directive and fold_context:\n        raise GraphQLCompilationError(u'@recurse is not allowed within a @fold traversal! '\n                                      u'Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n\n    if output_source_context and not fold_directive:\n        raise GraphQLCompilationError(u'Found non-fold vertex field after the vertex marked '\n                                      u'output source! Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n    if optional_context and fold_directive:\n        raise GraphQLCompilationError(u'@fold is not allowed within a @optional traversal! '\n                                      u'Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))\n    if optional_context and output_source_directive:\n        raise GraphQLCompilationError(u'@output_source is not allowed within a @optional '\n                                      u'traversal! Parent location: {}, vertex field name: {}'\n                                      .format(parent_location, vertex_field_name))", "response": "Ensure that the specified vertex field directives are allowed in the current context."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _safe_match_string(value):\n    if not isinstance(value, six.string_types):\n        if isinstance(value, bytes):  # should only happen in py3\n            value = value.decode('utf-8')\n        else:\n            raise GraphQLInvalidArgumentError(u'Attempting to convert a non-string into a string: '\n                                              u'{}'.format(value))\n\n    # Using JSON encoding means that all unicode literals and special chars\n    # (e.g. newlines and backslashes) are replaced by appropriate escape sequences.\n    # JSON has the same escaping rules as MATCH / SQL, so no further escaping is necessary.\n    return json.dumps(value)", "response": "Sanitize and represent a string argument in MATCH."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _safe_match_date_and_datetime(graphql_type, expected_python_types, value):\n    # Python datetime.datetime is a subclass of datetime.date,\n    # but in this case, the two are not interchangeable.\n    # Rather than using isinstance, we will therefore check for exact type equality.\n    value_type = type(value)\n    if not any(value_type == x for x in expected_python_types):\n        raise GraphQLInvalidArgumentError(u'Expected value to be exactly one of '\n                                          u'python types {}, but was {}: '\n                                          u'{}'.format(expected_python_types, value_type, value))\n\n    # The serialize() method of GraphQLDate and GraphQLDateTime produces the correct\n    # ISO-8601 format that MATCH expects. We then simply represent it as a regular string.\n    try:\n        serialized_value = graphql_type.serialize(value)\n    except ValueError as e:\n        raise GraphQLInvalidArgumentError(e)\n\n    return _safe_match_string(serialized_value)", "response": "Represent date and datetime objects as MATCH strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrepresents the list of inner_type objects in MATCH form.", "response": "def _safe_match_list(inner_type, argument_value):\n    \"\"\"Represent the list of \"inner_type\" objects in MATCH form.\"\"\"\n    stripped_type = strip_non_null_from_type(inner_type)\n    if isinstance(stripped_type, GraphQLList):\n        raise GraphQLInvalidArgumentError(u'MATCH does not currently support nested lists, '\n                                          u'but inner type was {}: '\n                                          u'{}'.format(inner_type, argument_value))\n\n    if not isinstance(argument_value, list):\n        raise GraphQLInvalidArgumentError(u'Attempting to represent a non-list as a list: '\n                                          u'{}'.format(argument_value))\n\n    components = (\n        _safe_match_argument(stripped_type, x)\n        for x in argument_value\n    )\n    return u'[' + u','.join(components) + u']'"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a MATCH string representing the given argument value.", "response": "def _safe_match_argument(expected_type, argument_value):\n    \"\"\"Return a MATCH (SQL) string representing the given argument value.\"\"\"\n    if GraphQLString.is_same_type(expected_type):\n        return _safe_match_string(argument_value)\n    elif GraphQLID.is_same_type(expected_type):\n        # IDs can be strings or numbers, but the GraphQL library coerces them to strings.\n        # We will follow suit and treat them as strings.\n        if not isinstance(argument_value, six.string_types):\n            if isinstance(argument_value, bytes):  # should only happen in py3\n                argument_value = argument_value.decode('utf-8')\n            else:\n                argument_value = six.text_type(argument_value)\n        return _safe_match_string(argument_value)\n    elif GraphQLFloat.is_same_type(expected_type):\n        return represent_float_as_str(argument_value)\n    elif GraphQLInt.is_same_type(expected_type):\n        # Special case: in Python, isinstance(True, int) returns True.\n        # Safeguard against this with an explicit check against bool type.\n        if isinstance(argument_value, bool):\n            raise GraphQLInvalidArgumentError(u'Attempting to represent a non-int as an int: '\n                                              u'{}'.format(argument_value))\n        return type_check_and_str(int, argument_value)\n    elif GraphQLBoolean.is_same_type(expected_type):\n        return type_check_and_str(bool, argument_value)\n    elif GraphQLDecimal.is_same_type(expected_type):\n        return _safe_match_decimal(argument_value)\n    elif GraphQLDate.is_same_type(expected_type):\n        return _safe_match_date_and_datetime(expected_type, (datetime.date,), argument_value)\n    elif GraphQLDateTime.is_same_type(expected_type):\n        return _safe_match_date_and_datetime(expected_type,\n                                             (datetime.datetime, arrow.Arrow), argument_value)\n    elif isinstance(expected_type, GraphQLList):\n        return _safe_match_list(expected_type.of_type, argument_value)\n    else:\n        raise AssertionError(u'Could not safely represent the requested GraphQL type: '\n                             u'{} {}'.format(expected_type, argument_value))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert the arguments into the MATCH query.", "response": "def insert_arguments_into_match_query(compilation_result, arguments):\n    \"\"\"Insert the arguments into the compiled MATCH query to form a complete query.\n\n    Args:\n        compilation_result: a CompilationResult object derived from the GraphQL compiler\n        arguments: dict, mapping argument name to its value, for every parameter the query expects.\n\n    Returns:\n        string, a MATCH query with inserted argument data\n    \"\"\"\n    if compilation_result.language != MATCH_LANGUAGE:\n        raise AssertionError(u'Unexpected query output language: {}'.format(compilation_result))\n\n    base_query = compilation_result.query\n    argument_types = compilation_result.input_metadata\n\n    # The arguments are assumed to have already been validated against the query.\n    sanitized_arguments = {\n        key: _safe_match_argument(argument_types[key], value)\n        for key, value in six.iteritems(arguments)\n    }\n\n    return base_query.format(**sanitized_arguments)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a SQLAlchemy table based on the supplied GraphQL schema type name.", "response": "def get_table(self, schema_type):\n        \"\"\"Retrieve a SQLAlchemy table based on the supplied GraphQL schema type name.\"\"\"\n        table_name = schema_type.lower()\n        if not self.has_table(table_name):\n            raise exceptions.GraphQLCompilationError(\n                'No Table found in SQLAlchemy metadata for table name \"{}\"'.format(table_name)\n            )\n        return self.table_name_to_table[table_name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _per_location_tuple_to_step(ir_tuple):\n    root_block = ir_tuple[0]\n    if not isinstance(root_block, root_block_types):\n        raise AssertionError(u'Unexpected root block type for MatchStep: '\n                             u'{} {}'.format(root_block, ir_tuple))\n\n    coerce_type_block = None\n    where_block = None\n    as_block = None\n    for block in ir_tuple[1:]:\n        if isinstance(block, CoerceType):\n            if coerce_type_block is not None:\n                raise AssertionError(u'Unexpectedly found two blocks eligible for \"class\" clause: '\n                                     u'{} {} {}'.format(block, coerce_type_block, ir_tuple))\n            coerce_type_block = block\n        elif isinstance(block, MarkLocation):\n            if as_block is not None:\n                raise AssertionError(u'Unexpectedly found two blocks eligible for \"as\" clause: '\n                                     u'{} {} {}'.format(block, as_block, ir_tuple))\n            as_block = block\n        elif isinstance(block, Filter):\n            if where_block is not None:\n                raise AssertionError(u'Unexpectedly found two blocks eligible for \"where\" clause: '\n                                     u'{} {} {}'.format(block, as_block, ir_tuple))\n\n            # Filter always comes before MarkLocation in a given MatchStep.\n            if as_block is not None:\n                raise AssertionError(u'Unexpectedly found MarkLocation before Filter in '\n                                     u'MatchStep: {} {} {}'.format(block, where_block, ir_tuple))\n\n            where_block = block\n        else:\n            raise AssertionError(u'Unexpected block encountered: {} {}'.format(block, ir_tuple))\n\n    step = MatchStep(root_block=root_block,\n                     coerce_type_block=coerce_type_block,\n                     where_block=where_block,\n                     as_block=as_block)\n\n    # MatchSteps with Backtrack as the root block should only contain MarkLocation,\n    # and not do filtering or type coercion.\n    if isinstance(root_block, Backtrack):\n        if where_block is not None or coerce_type_block is not None:\n            raise AssertionError(u'Unexpected blocks in Backtrack-based MatchStep: {}'.format(step))\n\n    return step", "response": "Construct a MatchStep from a tuple of constituent blocks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit a list of IR blocks into a list of MatchStep namedtuples each of which contains all basic blocks that correspond to a single MATCH step.", "response": "def _split_ir_into_match_steps(pruned_ir_blocks):\n    \"\"\"Split a list of IR blocks into per-location MATCH steps.\n\n    Args:\n        pruned_ir_blocks: list of IR basic block objects that have gone through a lowering step.\n\n    Returns:\n        list of MatchStep namedtuples, each of which contains all basic blocks that correspond\n        to a single MATCH step.\n    \"\"\"\n    output = []\n    current_tuple = None\n    for block in pruned_ir_blocks:\n        if isinstance(block, OutputSource):\n            # OutputSource blocks do not require any MATCH code, and only serve to help\n            # optimizations and debugging. Simply omit them at this stage.\n            continue\n        elif isinstance(block, root_block_types):\n            if current_tuple is not None:\n                output.append(current_tuple)\n            current_tuple = (block,)\n        elif isinstance(block, (CoerceType, Filter, MarkLocation)):\n            current_tuple += (block,)\n        else:\n            raise AssertionError(u'Unexpected block type when converting to MATCH query: '\n                                 u'{} {}'.format(block, pruned_ir_blocks))\n\n    if current_tuple is None:\n        raise AssertionError(u'current_tuple was unexpectedly None: {}'.format(pruned_ir_blocks))\n    output.append(current_tuple)\n\n    return [_per_location_tuple_to_step(x) for x in output]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _split_match_steps_into_match_traversals(match_steps):\n    output = []\n    current_list = None\n    for step in match_steps:\n        if isinstance(step.root_block, QueryRoot):\n            if current_list is not None:\n                output.append(current_list)\n            current_list = [step]\n        else:\n            current_list.append(step)\n\n    if current_list is None:\n        raise AssertionError(u'current_list was unexpectedly None: {}'.format(match_steps))\n    output.append(current_list)\n\n    return output", "response": "Split a list of MatchSteps into multiple lists each denoting a single MATCH traversal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting all global operations from a list of IR blocks except GlobalOperationsStart blocks.", "response": "def _extract_global_operations(ir_blocks_except_output_and_folds):\n    \"\"\"Extract all global operation blocks (all blocks following GlobalOperationsStart).\n\n    Args:\n        ir_blocks_except_output_and_folds: list of IR blocks (excluding ConstructResult and all\n                                           fold blocks), to extract global operations from\n\n    Returns:\n        tuple (global_operation_blocks, remaining_ir_blocks):\n        - global_operation_blocks: list of IR blocks following a GlobalOperationsStart block if it\n                                   exists, and an empty list otherwise\n        - remaining_ir_blocks: list of IR blocks excluding GlobalOperationsStart and all global\n                               operation blocks\n    \"\"\"\n    global_operation_blocks = []\n    remaining_ir_blocks = []\n    in_global_operations_scope = False\n\n    for block in ir_blocks_except_output_and_folds:\n        if isinstance(block, (ConstructResult, Fold, Unfold)):\n            raise AssertionError(u'Received unexpected block of type {}. No ConstructResult or '\n                                 u'Fold/Unfold blocks should be present: {}'\n                                 .format(type(block).__name__, ir_blocks_except_output_and_folds))\n        elif isinstance(block, GlobalOperationsStart):\n            in_global_operations_scope = True\n        elif in_global_operations_scope:\n            global_operation_blocks.append(block)\n        else:\n            remaining_ir_blocks.append(block)\n\n    return global_operation_blocks, remaining_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_to_match_query(ir_blocks):\n    output_block = ir_blocks[-1]\n    if not isinstance(output_block, ConstructResult):\n        raise AssertionError(u'Expected last IR block to be ConstructResult, found: '\n                             u'{} {}'.format(output_block, ir_blocks))\n    ir_except_output = ir_blocks[:-1]\n\n    folds, ir_except_output_and_folds = extract_folds_from_ir_blocks(ir_except_output)\n\n    # Extract WHERE Filter\n    global_operation_ir_blocks_tuple = _extract_global_operations(ir_except_output_and_folds)\n    global_operation_blocks, pruned_ir_blocks = global_operation_ir_blocks_tuple\n    if len(global_operation_blocks) > 1:\n        raise AssertionError(u'Received IR blocks with multiple global operation blocks. Only one '\n                             u'is allowed: {} {}'.format(global_operation_blocks, ir_blocks))\n    if len(global_operation_blocks) == 1:\n        if not isinstance(global_operation_blocks[0], Filter):\n            raise AssertionError(u'Received non-Filter global operation block. {}'\n                                 .format(global_operation_blocks[0]))\n        where_block = global_operation_blocks[0]\n    else:\n        where_block = None\n\n    match_steps = _split_ir_into_match_steps(pruned_ir_blocks)\n\n    match_traversals = _split_match_steps_into_match_traversals(match_steps)\n\n    return MatchQuery(\n        match_traversals=match_traversals,\n        folds=folds,\n        output_block=output_block,\n        where_block=where_block,\n    )", "response": "Convert the list of IR blocks into a MatchQuery object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert the arguments into the compiled SQL query.", "response": "def insert_arguments_into_sql_query(compilation_result, arguments):\n    \"\"\"Insert the arguments into the compiled SQL query to form a complete query.\n\n    Args:\n        compilation_result: CompilationResult, compilation result from the GraphQL compiler.\n        arguments: Dict[str, Any], parameter name -> value, for every parameter the query expects.\n\n    Returns:\n        SQLAlchemy Selectable, a executable SQL query with parameters bound.\n    \"\"\"\n    if compilation_result.language != SQL_LANGUAGE:\n        raise AssertionError(u'Unexpected query output language: {}'.format(compilation_result))\n    base_query = compilation_result.query\n    return base_query.params(**arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_coerce_type_to_instanceof_filter(coerce_type_block):\n    coerce_type_target = get_only_element_from_collection(coerce_type_block.target_class)\n\n    # INSTANCEOF requires the target class to be passed in as a string,\n    # so we make the target class a string literal.\n    new_predicate = BinaryComposition(\n        u'INSTANCEOF', LocalField('@this'), Literal(coerce_type_target))\n\n    return Filter(new_predicate)", "response": "Convert a CoerceType block to an INSTANCEOF Filter block."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a CoerceType to an InstanceOf Filter and add it to an existing Filter if any.", "response": "def convert_coerce_type_and_add_to_where_block(coerce_type_block, where_block):\n    \"\"\"Create an \"INSTANCEOF\" Filter from a CoerceType, adding to an existing Filter if any.\"\"\"\n    instanceof_filter = convert_coerce_type_to_instanceof_filter(coerce_type_block)\n\n    if where_block:\n        # There was already a Filter block -- we'll merge the two predicates together.\n        return Filter(BinaryComposition(u'&&', instanceof_filter.predicate, where_block.predicate))\n    else:\n        return instanceof_filter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expression_list_to_conjunction(expression_list):\n    if not isinstance(expression_list, list):\n        raise AssertionError(u'Expected `list`, Received {}.'.format(expression_list))\n\n    if len(expression_list) == 0:\n        return TrueLiteral\n\n    if not isinstance(expression_list[0], Expression):\n        raise AssertionError(u'Non-Expression object {} found in expression_list'\n                             .format(expression_list[0]))\n    if len(expression_list) == 1:\n        return expression_list[0]\n    else:\n        return BinaryComposition(u'&&',\n                                 expression_list_to_conjunction(expression_list[1:]),\n                                 expression_list[0])", "response": "Convert a list of expressions to an Expression that is the conjunction of all of them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_edge_field_non_existence(edge_expression):\n    # When an edge does not exist at a given vertex, OrientDB represents that in one of two ways:\n    #   - the edge's field does not exist (is null) on the vertex document, or\n    #   - the edge's field does exist, but is an empty list.\n    # We check both of these possibilities.\n    if not isinstance(edge_expression, (LocalField, GlobalContextField)):\n        raise AssertionError(u'Received invalid edge_expression {} of type {}.'\n                             u'Expected LocalField or GlobalContextField.'\n                             .format(edge_expression, type(edge_expression).__name__))\n    if isinstance(edge_expression, LocalField):\n        if not is_vertex_field_name(edge_expression.field_name):\n            raise AssertionError(u'Received LocalField edge_expression {} with non-edge field_name '\n                                 u'{}.'.format(edge_expression, edge_expression.field_name))\n\n    field_null_check = BinaryComposition(u'=', edge_expression, NullLiteral)\n\n    local_field_size = UnaryTransformation(u'size', edge_expression)\n    field_size_check = BinaryComposition(u'=', local_field_size, ZeroLiteral)\n\n    return BinaryComposition(u'||', field_null_check, field_size_check)", "response": "Return an Expression that is True iff the specified edge does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters the optional edge field that does not follow the OrientDB simple optional specification.", "response": "def _filter_orientdb_simple_optional_edge(\n        query_metadata_table, optional_edge_location, inner_location_name):\n    \"\"\"Return an Expression that is False for rows that don't follow the @optional specification.\n\n    OrientDB does not filter correctly within optionals. Namely, a result where the optional edge\n    DOES EXIST will be returned regardless of whether the inner filter is satisfed.\n    To mitigate this, we add a final filter to reject such results.\n    A valid result must satisfy either of the following:\n    - The location within the optional exists (the filter will have been applied in this case)\n    - The optional edge field does not exist at the root location of the optional traverse\n    So, if the inner location within the optional was never visited, it must be the case that\n    the corresponding edge field does not exist at all.\n\n    Example:\n        A MATCH traversal which starts at location `Animal___1`, and follows the optional edge\n        `out_Animal_ParentOf` to the location `Animal__out_Animal_ParentOf___1`\n        results in the following filtering Expression:\n        (\n            (\n                (Animal___1.out_Animal_ParentOf IS null)\n                OR\n                (Animal___1.out_Animal_ParentOf.size() = 0)\n            )\n            OR\n            (Animal__out_Animal_ParentOf___1 IS NOT null)\n        )\n        Here, the `optional_edge_location` is `Animal___1.out_Animal_ParentOf`.\n\n    Args:\n        query_metadata_table: QueryMetadataTable object containing all metadata collected during\n                              query processing, including location metadata (e.g. which locations\n                              are folded or optional).\n        optional_edge_location: Location object representing the optional edge field\n        inner_location_name: string representing location within the corresponding optional traverse\n\n    Returns:\n        Expression that evaluates to False for rows that do not follow the @optional specification\n    \"\"\"\n    inner_local_field = LocalField(inner_location_name)\n    inner_location_existence = BinaryComposition(u'!=', inner_local_field, NullLiteral)\n\n    # The optional_edge_location here is actually referring to the edge field itself.\n    # This is definitely non-standard, but required to get the proper semantics.\n    # To get its type, we construct the location of the vertex field on the other side of the edge.\n    vertex_location = (\n        optional_edge_location.at_vertex().navigate_to_subpath(optional_edge_location.field)\n    )\n    location_type = query_metadata_table.get_location_info(vertex_location).type\n\n    edge_context_field = GlobalContextField(optional_edge_location, location_type)\n    edge_field_non_existence = filter_edge_field_non_existence(edge_context_field)\n\n    return BinaryComposition(u'||', edge_field_non_existence, inner_location_existence)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a filter predicate that evaluates to True if and only if each simple optional filter is True.", "response": "def construct_where_filter_predicate(query_metadata_table, simple_optional_root_info):\n    \"\"\"Return an Expression that is True if and only if each simple optional filter is True.\n\n    Construct filters for each simple optional, that are True if and only if `edge_field` does\n    not exist in the `simple_optional_root_location` OR the `inner_location` is not defined.\n    Return an Expression that evaluates to True if and only if *all* of the aforementioned filters\n    evaluate to True (conjunction).\n\n    Args:\n        query_metadata_table: QueryMetadataTable object containing all metadata collected during\n                              query processing, including location metadata (e.g. which locations\n                              are folded or optional).\n        simple_optional_root_info: dict mapping from simple_optional_root_location -> dict\n                                   containing keys\n                                   - 'inner_location_name': Location object correspoding to the\n                                                            unique MarkLocation present within a\n                                                            simple @optional (one that does not\n                                                            expands vertex fields) scope\n                                   - 'edge_field': string representing the optional edge being\n                                                   traversed\n                                   where simple_optional_root_to_inner_location is the location\n                                   preceding the @optional scope\n    Returns:\n        a new Expression object\n    \"\"\"\n    inner_location_name_to_where_filter = {}\n    for root_location, root_info_dict in six.iteritems(simple_optional_root_info):\n        inner_location_name = root_info_dict['inner_location_name']\n        edge_field = root_info_dict['edge_field']\n\n        optional_edge_location = root_location.navigate_to_field(edge_field)\n        optional_edge_where_filter = _filter_orientdb_simple_optional_edge(\n            query_metadata_table, optional_edge_location, inner_location_name)\n        inner_location_name_to_where_filter[inner_location_name] = optional_edge_where_filter\n\n    # Sort expressions by inner_location_name to obtain deterministic order\n    where_filter_expressions = [\n        inner_location_name_to_where_filter[key]\n        for key in sorted(inner_location_name_to_where_filter.keys())\n    ]\n\n    return expression_list_to_conjunction(where_filter_expressions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct_optional_traversal_tree(complex_optional_roots, location_to_optional_roots):\n    tree = OptionalTraversalTree(complex_optional_roots)\n    for optional_root_locations_stack in six.itervalues(location_to_optional_roots):\n        tree.insert(list(optional_root_locations_stack))\n\n    return tree", "response": "Construct a tree of complex optional root locations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(self):\n        if not isinstance(self.field, LocalField):\n            raise TypeError(u'Expected LocalField field, got: {} {}'.format(\n                type(self.field).__name__, self.field))\n\n        if not isinstance(self.lower_bound, Expression):\n            raise TypeError(u'Expected Expression lower_bound, got: {} {}'.format(\n                type(self.lower_bound).__name__, self.lower_bound))\n\n        if not isinstance(self.upper_bound, Expression):\n            raise TypeError(u'Expected Expression upper_bound, got: {} {}'.format(\n                type(self.upper_bound).__name__, self.upper_bound))", "response": "Validate that the Between Expression is correctly representable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an updated version of the BetweenClause via the visitor pattern.", "response": "def visit_and_update(self, visitor_fn):\n        \"\"\"Create an updated version (if needed) of BetweenClause via the visitor pattern.\"\"\"\n        new_lower_bound = self.lower_bound.visit_and_update(visitor_fn)\n        new_upper_bound = self.upper_bound.visit_and_update(visitor_fn)\n\n        if new_lower_bound is not self.lower_bound or new_upper_bound is not self.upper_bound:\n            return visitor_fn(BetweenClause(self.field, new_lower_bound, new_upper_bound))\n        else:\n            return visitor_fn(self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a unicode object with the MATCH representation of this BetweenClause.", "response": "def to_match(self):\n        \"\"\"Return a unicode object with the MATCH representation of this BetweenClause.\"\"\"\n        template = u'({field_name} BETWEEN {lower_bound} AND {upper_bound})'\n        return template.format(\n            field_name=self.field.to_match(),\n            lower_bound=self.lower_bound.to_match(),\n            upper_bound=self.upper_bound.to_match())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert a path of optional Locations into the tree.", "response": "def insert(self, optional_root_locations_path):\n        \"\"\"Insert a path of optional Locations into the tree.\n\n        Each OptionalTraversalTree object contains child Location objects as keys mapping to\n        other OptionalTraversalTree objects.\n\n        Args:\n            optional_root_locations_path: list of optional root Locations all except the last\n                                          of which must be present in complex_optional_roots\n        \"\"\"\n        encountered_simple_optional = False\n        parent_location = self._root_location\n        for optional_root_location in optional_root_locations_path:\n            if encountered_simple_optional:\n                raise AssertionError(u'Encountered simple optional root location {} in path, but'\n                                     u'further locations are present. This should not happen: {}'\n                                     .format(optional_root_location, optional_root_locations_path))\n\n            if optional_root_location not in self._location_to_children:\n                # Simple optionals are ignored.\n                # There should be no complex optionals after a simple optional.\n                encountered_simple_optional = True\n            else:\n                self._location_to_children[parent_location].add(optional_root_location)\n                parent_location = optional_root_location"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all rooted subtrees of the current node.", "response": "def get_all_rooted_subtrees_as_lists(self, start_location=None):\n        \"\"\"Return a list of all rooted subtrees (each as a list of Location objects).\"\"\"\n        if start_location is not None and start_location not in self._location_to_children:\n            raise AssertionError(u'Received invalid start_location {} that was not present '\n                                 u'in the tree. Present root locations of complex @optional '\n                                 u'queries (ones that expand vertex fields within) are: {}'\n                                 .format(start_location, self._location_to_children.keys()))\n\n        if start_location is None:\n            start_location = self._root_location\n\n        if len(self._location_to_children[start_location]) == 0:\n            # Node with no children only returns a singleton list containing the null set.\n            return [[]]\n\n        current_children = sorted(self._location_to_children[start_location])\n\n        # Recursively find all rooted subtrees of each of the children of the current node.\n        location_to_list_of_subtrees = {\n            location: list(self.get_all_rooted_subtrees_as_lists(location))\n            for location in current_children\n        }\n\n        # All subsets of direct child Location objects\n        all_location_subsets = [\n            list(subset)\n            for subset in itertools.chain(*[\n                itertools.combinations(current_children, x)\n                for x in range(0, len(current_children) + 1)\n            ])\n        ]\n\n        # For every possible subset of the children, and every combination of the chosen\n        # subtrees within, create a list of subtree Location lists.\n        new_subtrees_as_lists = []\n        for location_subset in all_location_subsets:\n            all_child_subtree_possibilities = [\n                location_to_list_of_subtrees[location]\n                for location in location_subset\n            ]\n            all_child_subtree_combinations = itertools.product(*all_child_subtree_possibilities)\n\n            for child_subtree_combination in all_child_subtree_combinations:\n                merged_child_subtree_combination = list(itertools.chain(*child_subtree_combination))\n                new_subtree_as_list = location_subset + merged_child_subtree_combination\n                new_subtrees_as_lists.append(new_subtree_as_list)\n\n        return new_subtrees_as_lists"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emit_code_from_ir(sql_query_tree, compiler_metadata):\n    context = CompilationContext(\n        query_path_to_selectable=dict(),\n        query_path_to_location_info=sql_query_tree.query_path_to_location_info,\n        query_path_to_output_fields=sql_query_tree.query_path_to_output_fields,\n        query_path_to_filters=sql_query_tree.query_path_to_filters,\n        query_path_to_node=sql_query_tree.query_path_to_node,\n        compiler_metadata=compiler_metadata,\n    )\n\n    return _query_tree_to_query(sql_query_tree.root, context)", "response": "Return a SQLAlchemy Query from a passed SqlQueryTree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_table_and_update_context(node, context):\n    schema_type_name = sql_context_helpers.get_schema_type_name(node, context)\n    table = context.compiler_metadata.get_table(schema_type_name).alias()\n    context.query_path_to_selectable[node.query_path] = table\n    return table", "response": "Create an aliased table for a SqlNode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_query(node, context):\n    visited_nodes = [node]\n    output_columns = _get_output_columns(visited_nodes, context)\n    filters = _get_filters(visited_nodes, context)\n    selectable = sql_context_helpers.get_node_selectable(node, context)\n    query = select(output_columns).select_from(selectable).where(and_(*filters))\n    return query", "response": "Create a query from a SqlNode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the output columns for a list of SqlNodes.", "response": "def _get_output_columns(nodes, context):\n    \"\"\"Get the output columns for a list of SqlNodes.\n\n    Args:\n        nodes: List[SqlNode], the nodes to get output columns from.\n        context: CompilationContext, global compilation state and metadata.\n\n    Returns:\n        List[Column], list of SqlAlchemy Columns to output for this query.\n    \"\"\"\n    columns = []\n    for node in nodes:\n        for sql_output in sql_context_helpers.get_outputs(node, context):\n            field_name = sql_output.field_name\n            column = sql_context_helpers.get_column(field_name, node, context)\n            column = column.label(sql_output.output_name)\n            columns.append(column)\n    return columns"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_filters(nodes, context):\n    filters = []\n    for node in nodes:\n        for filter_block in sql_context_helpers.get_filters(node, context):\n            filter_sql_expression = _transform_filter_to_sql(filter_block, node, context)\n            filters.append(filter_sql_expression)\n    return filters", "response": "Get filters to apply to a list of SqlNodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform a Filter block to its corresponding SQLAlchemy expression.", "response": "def _transform_filter_to_sql(filter_block, node, context):\n    \"\"\"Transform a Filter block to its corresponding SQLAlchemy expression.\n\n    Args:\n        filter_block: Filter, the Filter block to transform.\n        node: SqlNode, the node Filter block applies to.\n        context: CompilationContext, global compilation state and metadata.\n\n    Returns:\n        Expression, SQLAlchemy expression equivalent to the Filter.predicate expression.\n    \"\"\"\n    expression = filter_block.predicate\n    return _expression_to_sql(expression, node, context)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming a BinaryComposition compiler expression into a SQLAlchemy expression.", "response": "def _transform_binary_composition_to_expression(expression, node, context):\n    \"\"\"Transform a BinaryComposition compiler expression into a SQLAlchemy expression.\n\n    Recursively calls _expression_to_sql to convert its left and right sub-expressions.\n\n    Args:\n        expression: expression, BinaryComposition compiler expression.\n        node: SqlNode, the SqlNode the expression applies to.\n        context: CompilationContext, global compilation state and metadata.\n\n    Returns:\n        Expression, SQLAlchemy expression.\n    \"\"\"\n    if expression.operator not in constants.SUPPORTED_OPERATORS:\n        raise NotImplementedError(\n            u'Filter operation \"{}\" is not supported by the SQL backend.'.format(\n                expression.operator))\n    sql_operator = constants.SUPPORTED_OPERATORS[expression.operator]\n    left = _expression_to_sql(expression.left, node, context)\n    right = _expression_to_sql(expression.right, node, context)\n    if sql_operator.cardinality == constants.CARDINALITY_UNARY:\n        left, right = _get_column_and_bindparam(left, right, sql_operator)\n        clause = getattr(left, sql_operator.name)(right)\n        return clause\n    elif sql_operator.cardinality == constants.CARDINALITY_BINARY:\n        clause = getattr(sql_expressions, sql_operator.name)(left, right)\n        return clause\n    elif sql_operator.cardinality == constants.CARDINALITY_LIST_VALUED:\n        left, right = _get_column_and_bindparam(left, right, sql_operator)\n        # ensure that SQLAlchemy treats the right bind parameter as list valued\n        right.expanding = True\n        clause = getattr(left, sql_operator.name)(right)\n        return clause\n    raise AssertionError(u'Unreachable, operator cardinality {} for compiler expression {} is '\n                         u'unknown'.format(sql_operator.cardinality, expression))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_column_and_bindparam(left, right, operator):\n    if not isinstance(left, Column):\n        left, right = right, left\n    if not isinstance(left, Column):\n        raise AssertionError(\n            u'SQLAlchemy operator {} expects Column as left side the of expression, got {} '\n            u'of type {} instead.'.format(operator, left, type(left)))\n    if not isinstance(right, BindParameter):\n        raise AssertionError(\n            u'SQLAlchemy operator {} expects BindParameter as the right side of the expression, '\n            u'got {} of type {} instead.'.format(operator, right, type(right)))\n    return left, right", "response": "Return left and right expressions in ( Column BindParameter order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform a Variable compiler expression into its SQLAlchemy expression representation.", "response": "def _transform_variable_to_expression(expression, node, context):\n    \"\"\"Transform a Variable compiler expression into its SQLAlchemy expression representation.\n\n    Args:\n        expression: expression, Variable compiler expression.\n        node: SqlNode, the SqlNode the expression applies to.\n        context: CompilationContext, global compilation state and metadata.\n\n    Returns:\n        Expression, SQLAlchemy expression.\n    \"\"\"\n    variable_name = expression.variable_name\n    if not variable_name.startswith(u'$'):\n        raise AssertionError(u'Unexpectedly received variable name {} that is not '\n                             u'prefixed with \"$\"'.format(variable_name))\n    return bindparam(variable_name[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _transform_local_field_to_expression(expression, node, context):\n    column_name = expression.field_name\n    column = sql_context_helpers.get_column(column_name, node, context)\n    return column", "response": "Transform a LocalField compiler expression into its SQLAlchemy expression representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_consecutive_filter_clauses(ir_blocks):\n    if not ir_blocks:\n        return ir_blocks\n\n    new_ir_blocks = [ir_blocks[0]]\n\n    for block in ir_blocks[1:]:\n        last_block = new_ir_blocks[-1]\n        if isinstance(last_block, Filter) and isinstance(block, Filter):\n            new_ir_blocks[-1] = Filter(\n                BinaryComposition(u'&&', last_block.predicate, block.predicate))\n        else:\n            new_ir_blocks.append(block)\n\n    return new_ir_blocks", "response": "Merge consecutive Filter clauses into one."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lower_context_field_existence(ir_blocks, query_metadata_table):\n    def regular_visitor_fn(expression):\n        \"\"\"Expression visitor function that rewrites ContextFieldExistence expressions.\"\"\"\n        if not isinstance(expression, ContextFieldExistence):\n            return expression\n\n        location_type = query_metadata_table.get_location_info(expression.location).type\n\n        # Since this function is only used in blocks that aren't ConstructResult,\n        # the location check is performed using a regular ContextField expression.\n        return BinaryComposition(\n            u'!=',\n            ContextField(expression.location, location_type),\n            NullLiteral)\n\n    def construct_result_visitor_fn(expression):\n        \"\"\"Expression visitor function that rewrites ContextFieldExistence expressions.\"\"\"\n        if not isinstance(expression, ContextFieldExistence):\n            return expression\n\n        location_type = query_metadata_table.get_location_info(expression.location).type\n\n        # Since this function is only used in ConstructResult blocks,\n        # the location check is performed using the special OutputContextVertex expression.\n        return BinaryComposition(\n            u'!=',\n            OutputContextVertex(expression.location, location_type),\n            NullLiteral)\n\n    new_ir_blocks = []\n    for block in ir_blocks:\n        new_block = None\n        if isinstance(block, ConstructResult):\n            new_block = block.visit_and_update_expressions(construct_result_visitor_fn)\n        else:\n            new_block = block.visit_and_update_expressions(regular_visitor_fn)\n        new_ir_blocks.append(new_block)\n\n    return new_ir_blocks", "response": "Lower ContextFieldExistence expressions into lower - level expressions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noptimizing comparisons of a boolean binary comparison expression against a boolean literal.", "response": "def optimize_boolean_expression_comparisons(ir_blocks):\n    \"\"\"Optimize comparisons of a boolean binary comparison expression against a boolean literal.\n\n    Rewriting example:\n        BinaryComposition(\n            '=',\n            BinaryComposition('!=', something, NullLiteral)\n            False)\n\n    The above is rewritten into:\n        BinaryComposition('=', something, NullLiteral)\n\n    Args:\n        ir_blocks: list of basic block objects\n\n    Returns:\n        a new list of basic block objects, with the optimization applied\n    \"\"\"\n    operator_inverses = {\n        u'=': u'!=',\n        u'!=': u'=',\n    }\n\n    def visitor_fn(expression):\n        \"\"\"Expression visitor function that performs the above rewriting.\"\"\"\n        if not isinstance(expression, BinaryComposition):\n            return expression\n\n        left_is_binary_composition = isinstance(expression.left, BinaryComposition)\n        right_is_binary_composition = isinstance(expression.right, BinaryComposition)\n\n        if not left_is_binary_composition and not right_is_binary_composition:\n            # Nothing to rewrite, return the expression as-is.\n            return expression\n\n        identity_literal = None  # The boolean literal for which we just use the inner expression.\n        inverse_literal = None  # The boolean literal for which we negate the inner expression.\n        if expression.operator == u'=':\n            identity_literal = TrueLiteral\n            inverse_literal = FalseLiteral\n        elif expression.operator == u'!=':\n            identity_literal = FalseLiteral\n            inverse_literal = TrueLiteral\n        else:\n            return expression\n\n        expression_to_rewrite = None\n        if expression.left == identity_literal and right_is_binary_composition:\n            return expression.right\n        elif expression.right == identity_literal and left_is_binary_composition:\n            return expression.left\n        elif expression.left == inverse_literal and right_is_binary_composition:\n            expression_to_rewrite = expression.right\n        elif expression.right == inverse_literal and left_is_binary_composition:\n            expression_to_rewrite = expression.left\n\n        if expression_to_rewrite is None:\n            # We couldn't find anything to rewrite, return the expression as-is.\n            return expression\n        elif expression_to_rewrite.operator not in operator_inverses:\n            # We can't rewrite the inner expression since we don't know its inverse operator.\n            return expression\n        else:\n            return BinaryComposition(\n                operator_inverses[expression_to_rewrite.operator],\n                expression_to_rewrite.left,\n                expression_to_rewrite.right)\n\n    new_ir_blocks = []\n    for block in ir_blocks:\n        new_block = block.visit_and_update_expressions(visitor_fn)\n        new_ir_blocks.append(new_block)\n\n    return new_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_folds_from_ir_blocks(ir_blocks):\n    folds = dict()\n    remaining_ir_blocks = []\n    current_folded_blocks = []\n    in_fold_location = None\n\n    for block in ir_blocks:\n        if isinstance(block, Fold):\n            if in_fold_location is not None:\n                raise AssertionError(u'in_fold_location was not None at a Fold block: {} {} '\n                                     u'{}'.format(current_folded_blocks, remaining_ir_blocks,\n                                                  ir_blocks))\n\n            in_fold_location = block.fold_scope_location\n        elif isinstance(block, Unfold):\n            if in_fold_location is None:\n                raise AssertionError(u'in_fold_location was None at an Unfold block: {} {} '\n                                     u'{}'.format(current_folded_blocks, remaining_ir_blocks,\n                                                  ir_blocks))\n\n            folds[in_fold_location] = current_folded_blocks\n            current_folded_blocks = []\n            in_fold_location = None\n        else:\n            if in_fold_location is not None:\n                current_folded_blocks.append(block)\n            else:\n                remaining_ir_blocks.append(block)\n\n    return folds, remaining_ir_blocks", "response": "Extract all Fold - Unfold data from the IR blocks and cut the folded IR blocks out of the IR."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting optional locations from a list of IR blocks.", "response": "def extract_optional_location_root_info(ir_blocks):\n    \"\"\"Construct a mapping from locations within @optional to their correspoding optional Traverse.\n\n    Args:\n        ir_blocks: list of IR blocks to extract optional data from\n\n    Returns:\n        tuple (complex_optional_roots, location_to_optional_roots):\n        complex_optional_roots: list of @optional locations (location immmediately preceding\n                                an @optional Traverse) that expand vertex fields\n        location_to_optional_roots: dict mapping from location -> optional_roots where location is\n                                    within some number of @optionals and optional_roots is a list\n                                    of optional root locations preceding the successive @optional\n                                    scopes within which the location resides\n    \"\"\"\n    complex_optional_roots = []\n    location_to_optional_roots = dict()\n\n    # These are both stacks that perform depth-first search on the tree of @optional edges.\n    # At any given location they contain\n    # - in_optional_root_locations: all the optional root locations\n    # - encountered_traverse_within_optional: whether the optional is complex or not\n    # in order that they appear on the path from the root to that location.\n    in_optional_root_locations = []\n    encountered_traverse_within_optional = []\n\n    # Blocks within folded scopes should not be taken into account in this function.\n    _, non_folded_ir_blocks = extract_folds_from_ir_blocks(ir_blocks)\n\n    preceding_location = None\n    for current_block in non_folded_ir_blocks:\n        if len(in_optional_root_locations) > 0 and isinstance(current_block, (Traverse, Recurse)):\n            encountered_traverse_within_optional[-1] = True\n\n        if isinstance(current_block, Traverse) and current_block.optional:\n            if preceding_location is None:\n                raise AssertionError(u'No MarkLocation found before an optional Traverse: {} {}'\n                                     .format(current_block, non_folded_ir_blocks))\n\n            in_optional_root_locations.append(preceding_location)\n            encountered_traverse_within_optional.append(False)\n        elif isinstance(current_block, EndOptional):\n            if len(in_optional_root_locations) == 0:\n                raise AssertionError(u'in_optional_root_locations was empty at an EndOptional '\n                                     u'block: {}'.format(ir_blocks))\n\n            if encountered_traverse_within_optional[-1]:\n                complex_optional_roots.append(in_optional_root_locations[-1])\n\n            in_optional_root_locations.pop()\n            encountered_traverse_within_optional.pop()\n        elif isinstance(current_block, MarkLocation):\n            preceding_location = current_block.location\n            if len(in_optional_root_locations) != 0:\n                # in_optional_root_locations will not be empty if and only if we are within an\n                # @optional scope. In this case, we add the current location to the dictionary\n                # mapping it to the sequence of optionals locations leading up to it.\n                optional_root_locations_stack = tuple(in_optional_root_locations)\n                location_to_optional_roots[current_block.location] = optional_root_locations_stack\n        else:\n            # No locations need to be marked, and no optional scopes begin or end here.\n            pass\n\n    return complex_optional_roots, location_to_optional_roots"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_simple_optional_location_info(\n        ir_blocks, complex_optional_roots, location_to_optional_roots):\n    \"\"\"Construct a map from simple optional locations to their inner location and traversed edge.\n\n    Args:\n        ir_blocks: list of IR blocks to extract optional data from\n        complex_optional_roots: list of @optional locations (location immmediately preceding\n                                an @optional traverse) that expand vertex fields\n        location_to_optional_roots: dict mapping from location -> optional_roots where location is\n                                    within some number of @optionals and optional_roots is a list\n                                    of optional root locations preceding the successive @optional\n                                    scopes within which the location resides\n\n    Returns:\n        dict mapping from simple_optional_root_location -> dict containing keys\n         - 'inner_location_name': Location object correspoding to the unique MarkLocation present\n                                  within a simple optional (one that does not expand vertex fields)\n                                  scope\n         - 'edge_field': string representing the optional edge being traversed\n        where simple_optional_root_to_inner_location is the location preceding the @optional scope\n    \"\"\"\n    # Simple optional roots are a subset of location_to_optional_roots.values() (all optional roots)\n    # We filter out the ones that are also present in complex_optional_roots.\n    location_to_preceding_optional_root_iteritems = six.iteritems({\n        location: optional_root_locations_stack[-1]\n        for location, optional_root_locations_stack in six.iteritems(location_to_optional_roots)\n    })\n    simple_optional_root_to_inner_location = {\n        optional_root_location: inner_location\n        for inner_location, optional_root_location in location_to_preceding_optional_root_iteritems\n        if optional_root_location not in complex_optional_roots\n    }\n    simple_optional_root_locations = set(simple_optional_root_to_inner_location.keys())\n\n    # Blocks within folded scopes should not be taken into account in this function.\n    _, non_folded_ir_blocks = extract_folds_from_ir_blocks(ir_blocks)\n\n    simple_optional_root_info = {}\n    preceding_location = None\n    for current_block in non_folded_ir_blocks:\n        if isinstance(current_block, MarkLocation):\n            preceding_location = current_block.location\n        elif isinstance(current_block, Traverse) and current_block.optional:\n            if preceding_location in simple_optional_root_locations:\n                # The current optional Traverse is \"simple\"\n                # i.e. it does not contain any Traverses within.\n                inner_location = simple_optional_root_to_inner_location[preceding_location]\n                inner_location_name, _ = inner_location.get_location_name()\n                simple_optional_info_dict = {\n                    'inner_location_name': inner_location_name,\n                    'edge_field': current_block.get_field_name(),\n                }\n                simple_optional_root_info[preceding_location] = simple_optional_info_dict\n\n    return simple_optional_root_info", "response": "This function extracts simple optional locations from a list of IR blocks and a list of complex optional roots and a list of optional roots."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of IR blocks as a copy of the original with EndOptional blocks removed.", "response": "def remove_end_optionals(ir_blocks):\n    \"\"\"Return a list of IR blocks as a copy of the original, with EndOptional blocks removed.\"\"\"\n    new_ir_blocks = []\n    for block in ir_blocks:\n        if not isinstance(block, EndOptional):\n            new_ir_blocks.append(block)\n    return new_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that the OutputContextVertex is correctly representable.", "response": "def validate(self):\n        \"\"\"Validate that the OutputContextVertex is correctly representable.\"\"\"\n        super(OutputContextVertex, self).validate()\n\n        if self.location.field is not None:\n            raise ValueError(u'Expected location at a vertex, but got: {}'.format(self.location))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_match(self):\n        self.validate()\n\n        mark_name, field_name = self.location.get_location_name()\n        validate_safe_string(mark_name)\n\n        if field_name is not None:\n            raise AssertionError(u'Vertex location has non-None field_name: '\n                                 u'{} {}'.format(field_name, self.location))\n\n        return mark_name", "response": "Return a unicode object with the MATCH representation of this expression."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrewriting the expression that is a TernaryConditional inside a TernaryConditionals.", "response": "def rewrite_binary_composition_inside_ternary_conditional(ir_blocks):\n    \"\"\"Rewrite BinaryConditional expressions in the true/false values of TernaryConditionals.\"\"\"\n    def visitor_fn(expression):\n        \"\"\"Expression visitor function.\"\"\"\n        # MATCH queries do not allow BinaryComposition inside a TernaryConditional's true/false\n        # value blocks, since OrientDB cannot produce boolean values for comparisons inside them.\n        # We transform any structures that resemble the following:\n        #    TernaryConditional(predicate, X, Y), with X or Y of type BinaryComposition\n        # into the following:\n        # - if X is of type BinaryComposition, and Y is not,\n        #    BinaryComposition(\n        #        u'=',\n        #        TernaryConditional(\n        #            predicate,\n        #            TernaryConditional(X, true, false),\n        #            Y\n        #        ),\n        #        true\n        #    )\n        # - if Y is of type BinaryComposition, and X is not,\n        #    BinaryComposition(\n        #        u'=',\n        #        TernaryConditional(\n        #            predicate,\n        #            X,\n        #            TernaryConditional(Y, true, false),\n        #        ),\n        #        true\n        #    )\n        # - if both X and Y are of type BinaryComposition,\n        #    BinaryComposition(\n        #        u'=',\n        #        TernaryConditional(\n        #            predicate,\n        #            TernaryConditional(X, true, false),\n        #            TernaryConditional(Y, true, false)\n        #        ),\n        #        true\n        #    )\n        if not isinstance(expression, TernaryConditional):\n            return expression\n\n        if_true = expression.if_true\n        if_false = expression.if_false\n\n        true_branch_rewriting_necessary = isinstance(if_true, BinaryComposition)\n        false_branch_rewriting_necessary = isinstance(if_false, BinaryComposition)\n\n        if not (true_branch_rewriting_necessary or false_branch_rewriting_necessary):\n            # No rewriting is necessary.\n            return expression\n\n        if true_branch_rewriting_necessary:\n            if_true = TernaryConditional(if_true, TrueLiteral, FalseLiteral)\n\n        if false_branch_rewriting_necessary:\n            if_false = TernaryConditional(if_false, TrueLiteral, FalseLiteral)\n\n        ternary = TernaryConditional(expression.predicate, if_true, if_false)\n        return BinaryComposition(u'=', ternary, TrueLiteral)\n\n    new_ir_blocks = [\n        block.visit_and_update_expressions(visitor_fn)\n        for block in ir_blocks\n    ]\n\n    return new_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlower Filter blocks that use the has_substring operation into MATCH - representable form.", "response": "def lower_has_substring_binary_compositions(ir_blocks):\n    \"\"\"Lower Filter blocks that use the \"has_substring\" operation into MATCH-representable form.\"\"\"\n    def visitor_fn(expression):\n        \"\"\"Rewrite BinaryComposition expressions with \"has_substring\" into representable form.\"\"\"\n        # The implementation of \"has_substring\" must use the LIKE operator in MATCH, and must\n        # prepend and append \"%\" symbols to the substring being matched.\n        # We transform any structures that resemble the following:\n        #    BinaryComposition(u'has_substring', X, Y)\n        # into the following:\n        #    BinaryComposition(\n        #        u'LIKE',\n        #        X,\n        #        BinaryComposition(\n        #            u'+',\n        #            Literal(\"%\"),\n        #            BinaryComposition(\n        #                 u'+',\n        #                 Y,\n        #                 Literal(\"%\")\n        #            )\n        #        )\n        #    )\n        if not isinstance(expression, BinaryComposition) or expression.operator != u'has_substring':\n            return expression\n\n        return BinaryComposition(\n            u'LIKE',\n            expression.left,\n            BinaryComposition(\n                u'+',\n                Literal('%'),\n                BinaryComposition(\n                    u'+',\n                    expression.right,\n                    Literal('%')\n                )\n            )\n        )\n\n    new_ir_blocks = [\n        block.visit_and_update_expressions(visitor_fn)\n        for block in ir_blocks\n    ]\n\n    return new_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntruncate one - step traversals that overlap a previous traversal location.", "response": "def truncate_repeated_single_step_traversals(match_query):\n    \"\"\"Truncate one-step traversals that overlap a previous traversal location.\"\"\"\n    # Such traversals frequently happen as side-effects of the lowering process\n    # of Backtrack blocks, and needlessly complicate the executed queries.\n    new_match_traversals = []\n    visited_locations = set()\n\n    for current_match_traversal in match_query.match_traversals:\n        ignore_traversal = False\n        if len(current_match_traversal) == 1:\n            # Single-step traversal detected. If its location was visited already, ignore it.\n            single_step = current_match_traversal[0]\n            if single_step.as_block is None:\n                raise AssertionError(u'Unexpectedly found a single-step traversal with no as_block:'\n                                     u' {} {}'.format(current_match_traversal, match_query))\n\n            if single_step.as_block.location in visited_locations:\n                # This location was visited before, omit the traversal.\n                ignore_traversal = True\n\n        if not ignore_traversal:\n            # For each step in this traversal, mark its location as visited.\n            for step in current_match_traversal:\n                if step.as_block is not None:\n                    visited_locations.add(step.as_block.location)\n\n            new_match_traversals.append(current_match_traversal)\n\n    return match_query._replace(match_traversals=new_match_traversals)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlowering Backtrack blocks into ( QueryRoot MarkLocation ) pairs of blocks.", "response": "def lower_backtrack_blocks(match_query, location_types):\n    \"\"\"Lower Backtrack blocks into (QueryRoot, MarkLocation) pairs of blocks.\"\"\"\n    # The lowering works as follows:\n    #   1. Upon seeing a Backtrack block, end the current traversal (if non-empty).\n    #   2. Start new traversal from the type and location to which the Backtrack pointed.\n    #   3. If the Backtrack block had an associated MarkLocation, mark that location\n    #      as equivalent to the location where the Backtrack pointed.\n    new_match_traversals = []\n\n    location_translations = dict()\n\n    for current_match_traversal in match_query.match_traversals:\n        new_traversal = []\n        for step in current_match_traversal:\n            if not isinstance(step.root_block, Backtrack):\n                new_traversal.append(step)\n            else:\n                # 1. Upon seeing a Backtrack block, end the current traversal (if non-empty).\n                if new_traversal:\n                    new_match_traversals.append(new_traversal)\n                    new_traversal = []\n\n                backtrack_location = step.root_block.location\n                backtrack_location_type = location_types[backtrack_location]\n\n                # 2. Start new traversal from the type and location to which the Backtrack pointed.\n                new_root_block = QueryRoot({backtrack_location_type.name})\n                new_as_block = MarkLocation(backtrack_location)\n\n                # 3. If the Backtrack block had an associated MarkLocation, mark that location\n                #    as equivalent to the location where the Backtrack pointed.\n                if step.as_block is not None:\n                    location_translations[step.as_block.location] = backtrack_location\n\n                if step.coerce_type_block is not None:\n                    raise AssertionError(u'Encountered type coercion in a MatchStep with '\n                                         u'a Backtrack root block, this is unexpected: {} {}'\n                                         .format(step, match_query))\n\n                new_step = step._replace(root_block=new_root_block, as_block=new_as_block)\n                new_traversal.append(new_step)\n\n        new_match_traversals.append(new_traversal)\n\n    _flatten_location_translations(location_translations)\n    new_match_query = match_query._replace(match_traversals=new_match_traversals)\n\n    return _translate_equivalent_locations(new_match_query, location_translations)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _flatten_location_translations(location_translations):\n    sources_to_process = set(six.iterkeys(location_translations))\n\n    def _update_translation(source):\n        \"\"\"Return the proper (fully-flattened) translation for the given location.\"\"\"\n        destination = location_translations[source]\n        if destination not in location_translations:\n            # \"destination\" cannot be translated, no further flattening required.\n            return destination\n        else:\n            # \"destination\" can itself be translated -- do so,\n            # and then flatten \"source\" to the final translation as well.\n            sources_to_process.discard(destination)\n            final_destination = _update_translation(destination)\n            location_translations[source] = final_destination\n            return final_destination\n\n    while sources_to_process:\n        _update_translation(sources_to_process.pop())", "response": "Flatten the location translations into a single tree structure."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _translate_equivalent_locations(match_query, location_translations):\n    new_match_traversals = []\n\n    def visitor_fn(expression):\n        \"\"\"Expression visitor function used to rewrite expressions with updated Location data.\"\"\"\n        if isinstance(expression, (ContextField, GlobalContextField)):\n            old_location = expression.location.at_vertex()\n            new_location = location_translations.get(old_location, old_location)\n            if expression.location.field is not None:\n                new_location = new_location.navigate_to_field(expression.location.field)\n\n            # The Expression could be one of many types, including:\n            #   - ContextField\n            #   - GlobalContextField\n            # We determine its exact class to make sure we return an object of the same class\n            # as the expression being replaced.\n            expression_cls = type(expression)\n            return expression_cls(new_location, expression.field_type)\n        elif isinstance(expression, ContextFieldExistence):\n            old_location = expression.location\n            new_location = location_translations.get(old_location, old_location)\n\n            return ContextFieldExistence(new_location)\n        elif isinstance(expression, FoldedContextField):\n            # Update the Location within FoldedContextField\n            old_location = expression.fold_scope_location.base_location\n            new_location = location_translations.get(old_location, old_location)\n\n            fold_path = expression.fold_scope_location.fold_path\n            fold_field = expression.fold_scope_location.field\n            new_fold_scope_location = FoldScopeLocation(new_location, fold_path, field=fold_field)\n            field_type = expression.field_type\n\n            return FoldedContextField(new_fold_scope_location, field_type)\n        else:\n            return expression\n\n    # Rewrite the Locations in the steps of each MATCH traversal.\n    for current_match_traversal in match_query.match_traversals:\n        new_traversal = []\n        for step in current_match_traversal:\n            new_step = step\n\n            # If the root_block is a Backtrack, translate its Location if necessary.\n            if isinstance(new_step.root_block, Backtrack):\n                old_location = new_step.root_block.location\n                if old_location in location_translations:\n                    new_location = location_translations[old_location]\n                    new_step = new_step._replace(root_block=Backtrack(new_location))\n\n            # If the as_block exists, translate its Location if necessary.\n            if new_step.as_block is not None:\n                old_location = new_step.as_block.location\n                if old_location in location_translations:\n                    new_location = location_translations[old_location]\n                    new_step = new_step._replace(as_block=MarkLocation(new_location))\n\n            # If the where_block exists, update any Location objects in its predicate.\n            if new_step.where_block is not None:\n                new_where_block = new_step.where_block.visit_and_update_expressions(visitor_fn)\n                new_step = new_step._replace(where_block=new_where_block)\n\n            new_traversal.append(new_step)\n\n        new_match_traversals.append(new_traversal)\n\n    new_folds = {}\n    # Update the Location within each FoldScopeLocation\n    for fold_scope_location, fold_ir_blocks in six.iteritems(match_query.folds):\n        fold_path = fold_scope_location.fold_path\n        fold_field = fold_scope_location.field\n        old_location = fold_scope_location.base_location\n        new_location = location_translations.get(old_location, old_location)\n        new_fold_scope_location = FoldScopeLocation(new_location, fold_path, field=fold_field)\n\n        new_folds[new_fold_scope_location] = fold_ir_blocks\n\n    # Rewrite the Locations in the ConstructResult output block.\n    new_output_block = match_query.output_block.visit_and_update_expressions(visitor_fn)\n\n    # Rewrite the Locations in the global where block.\n    new_where_block = None\n    if match_query.where_block is not None:\n        new_where_block = match_query.where_block.visit_and_update_expressions(visitor_fn)\n\n    return match_query._replace(match_traversals=new_match_traversals, folds=new_folds,\n                                output_block=new_output_block, where_block=new_where_block)", "response": "Translate Location objects into their equivalent locations based on the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lower_folded_coerce_types_into_filter_blocks(folded_ir_blocks):\n    new_folded_ir_blocks = []\n    for block in folded_ir_blocks:\n        if isinstance(block, CoerceType):\n            new_block = convert_coerce_type_to_instanceof_filter(block)\n        else:\n            new_block = block\n\n        new_folded_ir_blocks.append(new_block)\n\n    return new_folded_ir_blocks", "response": "Lower CoerceType blocks into INSTANCEOF Filter blocks. Indended for folded IR blocks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of IR blocks with all Backtrack blocks removed.", "response": "def remove_backtrack_blocks_from_fold(folded_ir_blocks):\n    \"\"\"Return a list of IR blocks with all Backtrack blocks removed.\"\"\"\n    new_folded_ir_blocks = []\n    for block in folded_ir_blocks:\n        if not isinstance(block, Backtrack):\n            new_folded_ir_blocks.append(block)\n    return new_folded_ir_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef truncate_repeated_single_step_traversals_in_sub_queries(compound_match_query):\n    lowered_match_queries = []\n    for match_query in compound_match_query.match_queries:\n        new_match_query = truncate_repeated_single_step_traversals(match_query)\n        lowered_match_queries.append(new_match_query)\n\n    return compound_match_query._replace(match_queries=lowered_match_queries)", "response": "Removes repeated single - step traversals in a compound match query."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a list of complex_optional_roots and a dictionary mapping from locations to locations in omitted_locations returns a new match traversal that includes all optional locations that are not present in the given locations.", "response": "def _prune_traverse_using_omitted_locations(match_traversal, omitted_locations,\n                                            complex_optional_roots, location_to_optional_roots):\n    \"\"\"Return a prefix of the given traverse, excluding any blocks after an omitted optional.\n\n    Given a subset (omitted_locations) of complex_optional_roots, return a new match traversal\n    removing all MatchStep objects that are within any omitted location.\n\n    Args:\n        match_traversal: list of MatchStep objects to be pruned\n        omitted_locations: subset of complex_optional_roots to be omitted\n        complex_optional_roots: list of all @optional locations (location immmediately preceding\n                                an @optional traverse) that expand vertex fields\n        location_to_optional_roots: dict mapping from location -> optional_roots where location is\n                                    within some number of @optionals and optional_roots is a list\n                                    of optional root locations preceding the successive @optional\n                                    scopes within which the location resides\n\n    Returns:\n        list of MatchStep objects as a copy of the given match traversal\n        with all steps within any omitted location removed.\n    \"\"\"\n    new_match_traversal = []\n    for step in match_traversal:\n        new_step = step\n        if isinstance(step.root_block, Traverse) and step.root_block.optional:\n            current_location = step.as_block.location\n            optional_root_locations_stack = location_to_optional_roots.get(current_location, None)\n            optional_root_location = optional_root_locations_stack[-1]\n\n            if optional_root_location is None:\n                raise AssertionError(u'Found optional Traverse location {} that was not present '\n                                     u'in location_to_optional_roots dict: {}'\n                                     .format(current_location, location_to_optional_roots))\n            elif optional_root_location in omitted_locations:\n                # Add filter to indicate that the omitted edge(s) shoud not exist\n                field_name = step.root_block.get_field_name()\n                new_predicate = filter_edge_field_non_existence(LocalField(field_name))\n                old_filter = new_match_traversal[-1].where_block\n                if old_filter is not None:\n                    new_predicate = BinaryComposition(u'&&', old_filter.predicate, new_predicate)\n                new_match_step = new_match_traversal[-1]._replace(\n                    where_block=Filter(new_predicate))\n                new_match_traversal[-1] = new_match_step\n\n                # Discard all steps following the omitted @optional traverse\n                new_step = None\n            elif optional_root_location in complex_optional_roots:\n                # Any non-omitted @optional traverse (that expands vertex fields)\n                # becomes a normal mandatory traverse (discard the optional flag).\n                new_root_block = Traverse(step.root_block.direction, step.root_block.edge_name)\n                new_step = step._replace(root_block=new_root_block)\n            else:\n                # The current optional traverse is a \"simple optional\" (one that does not\n                # expand vertex fields). No further action is required since MATCH supports it.\n                pass\n\n        # If new_step was set to None,\n        # we have encountered a Traverse that is within an omitted location.\n        # We discard the remainder of the match traversal (everything following is also omitted).\n        if new_step is None:\n            break\n        else:\n            new_match_traversal.append(new_step)\n\n    return new_match_traversal"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_optional_traversals_to_compound_match_query(\n        match_query, complex_optional_roots, location_to_optional_roots):\n    \"\"\"Return 2^n distinct MatchQuery objects in a CompoundMatchQuery.\n\n    Given a MatchQuery containing `n` optional traverses that expand vertex fields,\n    construct `2^n` different MatchQuery objects:\n    one for each possible subset of optional edges that can be followed.\n    For each edge `e` in a subset of optional edges chosen to be omitted,\n    discard all traversals following `e`, and add filters specifying that `e` *does not exist*.\n\n    Args:\n        match_query: MatchQuery object containing n `@optional` scopes which expand vertex fields\n        complex_optional_roots: list of @optional locations (location preceding an @optional\n                                traverse) that expand vertex fields within\n        location_to_optional_roots: dict mapping from location -> optional_roots where location is\n                                    within some number of @optionals and optional_roots is a list\n                                    of optional root locations preceding the successive @optional\n                                    scopes within which the location resides\n\n    Returns:\n        CompoundMatchQuery object containing 2^n MatchQuery objects,\n        one for each possible subset of the n optional edges being followed\n    \"\"\"\n    tree = construct_optional_traversal_tree(\n        complex_optional_roots, location_to_optional_roots)\n    rooted_optional_root_location_subsets = tree.get_all_rooted_subtrees_as_lists()\n\n    omitted_location_subsets = [\n        set(complex_optional_roots) - set(subset)\n        for subset in rooted_optional_root_location_subsets\n    ]\n    sorted_omitted_location_subsets = sorted(omitted_location_subsets)\n\n    compound_match_traversals = []\n    for omitted_locations in reversed(sorted_omitted_location_subsets):\n        new_match_traversals = []\n        for match_traversal in match_query.match_traversals:\n            location = match_traversal[0].as_block.location\n            optional_root_locations_stack = location_to_optional_roots.get(location, None)\n            if optional_root_locations_stack is not None:\n                optional_root_location = optional_root_locations_stack[-1]\n            else:\n                optional_root_location = None\n\n            if optional_root_location is None or optional_root_location not in omitted_locations:\n                new_match_traversal = _prune_traverse_using_omitted_locations(\n                    match_traversal, set(omitted_locations),\n                    complex_optional_roots, location_to_optional_roots)\n                new_match_traversals.append(new_match_traversal)\n            else:\n                # The root_block is within an omitted scope.\n                # Discard the entire match traversal (do not append to new_match_traversals)\n                pass\n\n        compound_match_traversals.append(new_match_traversals)\n\n    match_queries = [\n        MatchQuery(\n            match_traversals=match_traversals,\n            folds=match_query.folds,\n            output_block=match_query.output_block,\n            where_block=match_query.where_block,\n        )\n        for match_traversals in compound_match_traversals\n    ]\n\n    return CompoundMatchQuery(match_queries=match_queries)", "response": "Convert optional traverses that expand vertex fields within a complex_optional_roots list to a CompoundMatchQuery."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_present_locations(match_traversals):\n    present_locations = set()\n    present_non_optional_locations = set()\n\n    for match_traversal in match_traversals:\n        for step in match_traversal:\n            if step.as_block is not None:\n                location_name, _ = step.as_block.location.get_location_name()\n                present_locations.add(location_name)\n                if isinstance(step.root_block, Traverse) and not step.root_block.optional:\n                    present_non_optional_locations.add(location_name)\n\n    if not present_non_optional_locations.issubset(present_locations):\n        raise AssertionError(u'present_non_optional_locations {} was not a subset of '\n                             u'present_locations {}. THis hould never happen.'\n                             .format(present_non_optional_locations, present_locations))\n\n    return present_locations, present_non_optional_locations", "response": "Return the set of locations and non - optional locations present in the given match traversals."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves non - existent outputs from each MatchQuery in the given CompoundMatchQuery.", "response": "def prune_non_existent_outputs(compound_match_query):\n    \"\"\"Remove non-existent outputs from each MatchQuery in the given CompoundMatchQuery.\n\n    Each of the 2^n MatchQuery objects (except one) has been pruned to exclude some Traverse blocks,\n    For each of these, remove the outputs (that have been implicitly pruned away) from each\n    corresponding ConstructResult block.\n\n    Args:\n        compound_match_query: CompoundMatchQuery object containing 2^n pruned MatchQuery objects\n                              (see convert_optional_traversals_to_compound_match_query)\n\n    Returns:\n        CompoundMatchQuery with pruned ConstructResult blocks for each of the 2^n MatchQuery objects\n    \"\"\"\n    if len(compound_match_query.match_queries) == 1:\n        return compound_match_query\n    elif len(compound_match_query.match_queries) == 0:\n        raise AssertionError(u'Received CompoundMatchQuery with '\n                             u'an empty list of MatchQuery objects.')\n    else:\n        match_queries = []\n        for match_query in compound_match_query.match_queries:\n            match_traversals = match_query.match_traversals\n            output_block = match_query.output_block\n\n            present_locations_tuple = _get_present_locations(match_traversals)\n            present_locations, present_non_optional_locations = present_locations_tuple\n\n            new_output_fields = {}\n            for output_name, expression in six.iteritems(output_block.fields):\n                if isinstance(expression, OutputContextField):\n                    # An OutputContextField as an output Expression indicates that we are not\n                    # within an @optional scope. Therefore, the location this output uses must\n                    # be in present_locations, and the output is never pruned.\n                    location_name, _ = expression.location.get_location_name()\n                    if location_name not in present_locations:\n                        raise AssertionError(u'Non-optional output location {} was not found in '\n                                             u'present_locations: {}'\n                                             .format(expression.location, present_locations))\n                    new_output_fields[output_name] = expression\n                elif isinstance(expression, FoldedContextField):\n                    # A FoldedContextField as an output Expression indicates that we are not\n                    # within an @optional scope. Therefore, the location this output uses must\n                    # be in present_locations, and the output is never pruned.\n                    base_location = expression.fold_scope_location.base_location\n                    location_name, _ = base_location.get_location_name()\n                    if location_name not in present_locations:\n                        raise AssertionError(u'Folded output location {} was found in '\n                                             u'present_locations: {}'\n                                             .format(base_location, present_locations))\n                    new_output_fields[output_name] = expression\n                elif isinstance(expression, TernaryConditional):\n                    # A TernaryConditional indicates that this output is within some optional scope.\n                    # This may be pruned away based on the contents of present_locations.\n                    location_name, _ = expression.if_true.location.get_location_name()\n                    if location_name in present_locations:\n                        if location_name in present_non_optional_locations:\n                            new_output_fields[output_name] = expression.if_true\n                        else:\n                            new_output_fields[output_name] = expression\n                else:\n                    raise AssertionError(u'Invalid expression of type {} in output block: '\n                                         u'{}'.format(type(expression).__name__, output_block))\n\n            match_queries.append(\n                MatchQuery(\n                    match_traversals=match_traversals,\n                    folds=match_query.folds,\n                    output_block=ConstructResult(new_output_fields),\n                    where_block=match_query.where_block,\n                )\n            )\n\n        return CompoundMatchQuery(match_queries=match_queries)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _construct_location_to_filter_list(match_query):\n    # For each location, all filters for that location should be applied at the first instance.\n    # This function collects a list of all filters corresponding to each location\n    # present in the given MatchQuery.\n    location_to_filters = {}\n    for match_traversal in match_query.match_traversals:\n        for match_step in match_traversal:\n            current_filter = match_step.where_block\n            if current_filter is not None:\n                current_location = match_step.as_block.location\n                location_to_filters.setdefault(current_location, []).append(\n                    current_filter)\n\n    return location_to_filters", "response": "Construct a dict mapping each location to a list of filters applied at that location."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _filter_list_to_conjunction_expression(filter_list):\n    if not isinstance(filter_list, list):\n        raise AssertionError(u'Expected `list`, Received: {}.'.format(filter_list))\n    if any((not isinstance(filter_block, Filter) for filter_block in filter_list)):\n        raise AssertionError(u'Expected list of Filter objects. Received: {}'.format(filter_list))\n\n    expression_list = [filter_block.predicate for filter_block in filter_list]\n    return expression_list_to_conjunction(expression_list)", "response": "Convert a list of filters to an Expression that is the conjunction of all of them."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _apply_filters_to_first_location_occurrence(match_traversal, location_to_filters,\n                                                already_filtered_locations):\n    \"\"\"Apply all filters for a specific location into its first occurrence in a given traversal.\n\n    For each location in the given match traversal,\n    construct a conjunction of all filters applied to that location,\n    and apply the resulting Filter to the first instance of the location.\n\n    Args:\n        match_traversal: list of MatchStep objects to be lowered\n        location_to_filters: dict mapping each location in the MatchQuery which contains\n                             the given match traversal to a list of filters applied at that location\n        already_filtered_locations: set of locations that have already had their filters applied\n\n    Returns:\n        new list of MatchStep objects with all filters for any given location composed into\n        a single filter which is applied to the first instance of that location\n    \"\"\"\n    new_match_traversal = []\n    newly_filtered_locations = set()\n    for match_step in match_traversal:\n        # Apply all filters for a location to the first occurence of that location\n        current_location = match_step.as_block.location\n\n        if current_location in newly_filtered_locations:\n            raise AssertionError(u'The same location {} was encountered twice in a single '\n                                 u'match traversal: {}. This should never happen.'\n                                 .format(current_location, match_traversal))\n\n        if all((current_location in location_to_filters,\n                current_location not in already_filtered_locations)):\n            where_block = Filter(\n                _filter_list_to_conjunction_expression(\n                    location_to_filters[current_location]\n                )\n            )\n            # No further filters needed for this location. If the same location is found in\n            # another call to this function, no filters will be added.\n            newly_filtered_locations.add(current_location)\n        else:\n            where_block = None\n\n        new_match_step = MatchStep(\n            root_block=match_step.root_block,\n            coerce_type_block=match_step.coerce_type_block,\n            where_block=where_block,\n            as_block=match_step.as_block\n        )\n        new_match_traversal.append(new_match_step)\n\n    return new_match_traversal, newly_filtered_locations", "response": "Returns a list of MatchStep objects that are applied to the first occurrence of a specific location."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collect_filters_to_first_location_occurrence(compound_match_query):\n    new_match_queries = []\n    # Each MatchQuery has a different set of locations, and associated Filters.\n    # Hence, each of them is processed independently.\n    for match_query in compound_match_query.match_queries:\n        # Construct mapping from location -> list of filter predicates applied at that location\n        location_to_filters = _construct_location_to_filter_list(match_query)\n        already_filtered_locations = set()\n\n        new_match_traversals = []\n        for match_traversal in match_query.match_traversals:\n            result = _apply_filters_to_first_location_occurrence(\n                match_traversal, location_to_filters, already_filtered_locations)\n            new_match_traversal, newly_filtered_locations = result\n\n            new_match_traversals.append(new_match_traversal)\n            already_filtered_locations.update(newly_filtered_locations)\n\n        new_match_queries.append(\n            MatchQuery(\n                match_traversals=new_match_traversals,\n                folds=match_query.folds,\n                output_block=match_query.output_block,\n                where_block=match_query.where_block,\n            )\n        )\n\n    return CompoundMatchQuery(match_queries=new_match_queries)", "response": "Collect all filters for a particular location to the first occurrence of that location."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_context_field_binary_composition(present_locations, expression):\n    if not any((isinstance(expression.left, ContextField),\n                isinstance(expression.right, ContextField))):\n        raise AssertionError(u'Received a BinaryComposition {} without any ContextField '\n                             u'operands. This should never happen.'.format(expression))\n\n    if isinstance(expression.left, ContextField):\n        context_field = expression.left\n        location_name, _ = context_field.location.get_location_name()\n        if location_name not in present_locations:\n            return TrueLiteral\n\n    if isinstance(expression.right, ContextField):\n        context_field = expression.right\n        location_name, _ = context_field.location.get_location_name()\n        if location_name not in present_locations:\n            return TrueLiteral\n\n    return expression", "response": "Lower BinaryCompositions involving non - existent ContextFields to True."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a simplified BinaryComposition if either operand is a TrueLiteral and the original expression otherwise.", "response": "def _simplify_non_context_field_binary_composition(expression):\n    \"\"\"Return a simplified BinaryComposition if either operand is a TrueLiteral.\n\n    Args:\n        expression: BinaryComposition without any ContextField operand(s)\n\n    Returns:\n        simplified expression if the given expression is a disjunction/conjunction\n        and one of it's operands is a TrueLiteral,\n        and the original expression otherwise\n    \"\"\"\n    if any((isinstance(expression.left, ContextField),\n            isinstance(expression.right, ContextField))):\n        raise AssertionError(u'Received a BinaryComposition {} with a ContextField '\n                             u'operand. This should never happen.'.format(expression))\n\n    if expression.operator == u'||':\n        if expression.left == TrueLiteral or expression.right == TrueLiteral:\n            return TrueLiteral\n        else:\n            return expression\n    elif expression.operator == u'&&':\n        if expression.left == TrueLiteral:\n            return expression.right\n        if expression.right == TrueLiteral:\n            return expression.left\n        else:\n            return expression\n    else:\n        return expression"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_context_field_expression(present_locations, expression):\n    no_op_blocks = (ContextField, Literal, LocalField, UnaryTransformation, Variable)\n    if isinstance(expression, BinaryComposition):\n        if isinstance(expression.left, ContextField) or isinstance(expression.right, ContextField):\n            return _update_context_field_binary_composition(present_locations, expression)\n        else:\n            return _simplify_non_context_field_binary_composition(expression)\n    elif isinstance(expression, TernaryConditional):\n        return _simplify_ternary_conditional(expression)\n    elif isinstance(expression, BetweenClause):\n        lower_bound = expression.lower_bound\n        upper_bound = expression.upper_bound\n        if isinstance(lower_bound, ContextField) or isinstance(upper_bound, ContextField):\n            raise AssertionError(u'Found BetweenClause with ContextFields as lower/upper bounds. '\n                                 u'This should never happen: {}'.format(expression))\n        return expression\n    elif isinstance(expression, (OutputContextField, FoldedContextField)):\n        raise AssertionError(u'Found unexpected expression of type {}. This should never happen: '\n                             u'{}'.format(type(expression).__name__, expression))\n    elif isinstance(expression, no_op_blocks):\n        return expression\n\n    raise AssertionError(u'Found unhandled expression of type {}. This should never happen: '\n                         u'{}'.format(type(expression).__name__, expression))", "response": "Lower Expressions involving non - existent ContextFields to TrueLiteral and simplify result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _lower_non_existent_context_field_filters(match_traversals, visitor_fn):\n    new_match_traversals = []\n    for match_traversal in match_traversals:\n        new_match_traversal = []\n        for step in match_traversal:\n            if step.where_block is not None:\n                new_filter = step.where_block.visit_and_update_expressions(visitor_fn)\n                if new_filter.predicate == TrueLiteral:\n                    new_filter = None\n\n                new_step = step._replace(where_block=new_filter)\n            else:\n                new_step = step\n\n            new_match_traversal.append(new_step)\n        new_match_traversals.append(new_match_traversal)\n\n    return new_match_traversals", "response": "Lower the non - existent ContextFields in a list of match traversals."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lower_context_field_expressions(compound_match_query):\n    if len(compound_match_query.match_queries) == 0:\n        raise AssertionError(u'Received CompoundMatchQuery {} with no MatchQuery objects.'\n                             .format(compound_match_query))\n    elif len(compound_match_query.match_queries) == 1:\n        # All ContextFields exist if there is only one MatchQuery\n        # becuase none of the traverses were omitted, and all locations exist (are defined).\n        return compound_match_query\n    else:\n        new_match_queries = []\n        for match_query in compound_match_query.match_queries:\n            match_traversals = match_query.match_traversals\n            present_locations, _ = _get_present_locations(match_traversals)\n            current_visitor_fn = partial(_update_context_field_expression, present_locations)\n\n            new_match_traversals = _lower_non_existent_context_field_filters(\n                match_traversals, current_visitor_fn)\n            new_match_queries.append(\n                MatchQuery(\n                    match_traversals=new_match_traversals,\n                    folds=match_query.folds,\n                    output_block=match_query.output_block,\n                    where_block=match_query.where_block,\n                )\n            )\n\n    return CompoundMatchQuery(match_queries=new_match_queries)", "response": "Lower Expressons involving non - existent ContextFields."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that the edge properties dict has defined in or out link types.", "response": "def _validate_non_abstract_edge_has_defined_endpoint_types(class_name, properties):\n    \"\"\"Validate that the non-abstract edge properties dict has defined in/out link properties.\"\"\"\n    edge_source = properties.get(EDGE_SOURCE_PROPERTY_NAME, None)\n    edge_destination = properties.get(EDGE_DESTINATION_PROPERTY_NAME, None)\n    has_defined_endpoint_types = all((\n        edge_source is not None and edge_source.type_id == PROPERTY_TYPE_LINK_ID,\n        edge_destination is not None and edge_destination.type_id == PROPERTY_TYPE_LINK_ID,\n    ))\n    if not has_defined_endpoint_types:\n        raise IllegalSchemaStateError(u'Found a non-abstract edge class with undefined or illegal '\n                                      u'in/out properties: {} {}'.format(class_name, properties))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_non_edges_do_not_have_edge_like_properties(class_name, properties):\n    has_source = EDGE_SOURCE_PROPERTY_NAME in properties\n    has_destination = EDGE_DESTINATION_PROPERTY_NAME in properties\n\n    if has_source or has_destination:\n        raise IllegalSchemaStateError(u'Found a non-edge class that defines edge-like \"in\" or '\n                                      u'\"out\" properties: {} {}'.format(class_name, properties))\n\n    for property_name, property_descriptor in six.iteritems(properties):\n        if property_descriptor.type_id == PROPERTY_TYPE_LINK_ID:\n            raise IllegalSchemaStateError(u'Non-edge class \"{}\" has a property of type Link, this '\n                                          u'is not allowed: {}'.format(class_name, property_name))", "response": "Validate that the non - edges do not have edge - like properties defined."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_edges_do_not_have_extra_links(class_name, properties):\n    for property_name, property_descriptor in six.iteritems(properties):\n        if property_name in {EDGE_SOURCE_PROPERTY_NAME, EDGE_DESTINATION_PROPERTY_NAME}:\n            continue\n\n        if property_descriptor.type_id == PROPERTY_TYPE_LINK_ID:\n            raise IllegalSchemaStateError(u'Edge class \"{}\" has a property of type Link that is '\n                                          u'not an edge endpoint, this is not allowed: '\n                                          u'{}'.format(class_name, property_name))", "response": "Validate that edges do not have extra links."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that properties do not have a name that may cause problems in the GraphQL schema.", "response": "def _validate_property_names(class_name, properties):\n    \"\"\"Validate that properties do not have names that may cause problems in the GraphQL schema.\"\"\"\n    for property_name in properties:\n        if not property_name or property_name.startswith(ILLEGAL_PROPERTY_NAME_PREFIXES):\n            raise IllegalSchemaStateError(u'Class \"{}\" has a property with an illegal name: '\n                                          u'{}'.format(class_name, property_name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate that the property is of collection type and has a default value.", "response": "def _validate_collections_have_default_values(class_name, property_name, property_descriptor):\n    \"\"\"Validate that if the property is of collection type, it has a specified default value.\"\"\"\n    # We don't want properties of collection type having \"null\" values, since that may cause\n    # unexpected errors during GraphQL query execution and other operations.\n    if property_descriptor.type_id in COLLECTION_PROPERTY_TYPES:\n        if property_descriptor.default is None:\n            raise IllegalSchemaStateError(u'Class \"{}\" has a property \"{}\" of collection type with '\n                                          u'no default value.'.format(class_name, property_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_superclasses_from_class_definition(class_definition):\n    # New-style superclasses definition, supporting multiple-inheritance.\n    superclasses = class_definition.get('superClasses', None)\n\n    if superclasses:\n        return list(superclasses)\n\n    # Old-style superclass definition, single inheritance only.\n    superclass = class_definition.get('superClass', None)\n    if superclass:\n        return [superclass]\n\n    # No superclasses are present.\n    return []", "response": "Extract a list of all superclass names from a class definition dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake the SchemaElement s connections immutable.", "response": "def freeze(self):\n        \"\"\"Make the SchemaElement's connections immutable.\"\"\"\n        self.in_connections = frozenset(self.in_connections)\n        self.out_connections = frozenset(self.out_connections)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dict with default values for all properties declared on this class.", "response": "def get_default_property_values(self, classname):\n        \"\"\"Return a dict with default values for all properties declared on this class.\"\"\"\n        schema_element = self.get_element_by_class_name(classname)\n\n        result = {\n            property_name: property_descriptor.default\n            for property_name, property_descriptor in six.iteritems(schema_element.properties)\n        }\n\n        if schema_element.is_edge:\n            # Remove the source/destination properties for edges, if they exist.\n            result.pop(EDGE_SOURCE_PROPERTY_NAME, None)\n            result.pop(EDGE_DESTINATION_PROPERTY_NAME, None)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the property values for the class with default values applied where needed.", "response": "def _get_property_values_with_defaults(self, classname, property_values):\n        \"\"\"Return the property values for the class, with default values applied where needed.\"\"\"\n        # To uphold OrientDB semantics, make a new dict with all property values set\n        # to their default values, which are None if no default was set.\n        # Then, overwrite its data with the supplied property values.\n        final_values = self.get_default_property_values(classname)\n        final_values.update(property_values)\n        return final_values"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the SchemaElement for the specified class name or raise an InvalidClassError.", "response": "def get_element_by_class_name_or_raise(self, class_name):\n        \"\"\"Return the SchemaElement for the specified class name, asserting that it exists.\"\"\"\n        if class_name not in self._elements:\n            raise InvalidClassError(u'Class does not exist: {}'.format(class_name))\n\n        return self._elements[class_name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_vertex_schema_element_or_raise(self, vertex_classname):\n        schema_element = self.get_element_by_class_name_or_raise(vertex_classname)\n\n        if not schema_element.is_vertex:\n            raise InvalidClassError(u'Non-vertex class provided: {}'.format(vertex_classname))\n\n        return schema_element", "response": "Return the schema element with the given name asserting that it s of vertex type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the schema element with the given name asserting that it s of edge type.", "response": "def get_edge_schema_element_or_raise(self, edge_classname):\n        \"\"\"Return the schema element with the given name, asserting that it's of edge type.\"\"\"\n        schema_element = self.get_element_by_class_name_or_raise(edge_classname)\n\n        if not schema_element.is_edge:\n            raise InvalidClassError(u'Non-edge class provided: {}'.format(edge_classname))\n\n        return schema_element"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_is_non_abstract_vertex_type(self, vertex_classname):\n        element = self.get_vertex_schema_element_or_raise(vertex_classname)\n\n        if element.abstract:\n            raise InvalidClassError(u'Expected a non-abstract vertex class, but {} is abstract'\n                                    .format(vertex_classname))", "response": "Validate that a vertex classname corresponds to a non - abstract vertex class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_is_non_abstract_edge_type(self, edge_classname):\n        element = self.get_edge_schema_element_or_raise(edge_classname)\n\n        if element.abstract:\n            raise InvalidClassError(u'Expected a non-abstract vertex class, but {} is abstract'\n                                    .format(edge_classname))", "response": "Validate that a edge classname corresponds to a non - abstract edge class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that the specified property names are indeed defined on the given class.", "response": "def validate_properties_exist(self, classname, property_names):\n        \"\"\"Validate that the specified property names are indeed defined on the given class.\"\"\"\n        schema_element = self.get_element_by_class_name(classname)\n\n        requested_properties = set(property_names)\n        available_properties = set(schema_element.properties.keys())\n        non_existent_properties = requested_properties - available_properties\n        if non_existent_properties:\n            raise InvalidPropertyError(\n                u'Class \"{}\" does not have definitions for properties \"{}\": '\n                u'{}'.format(classname, non_existent_properties, property_names))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_up_inheritance_and_subclass_sets(self, schema_data):\n        # For each class name, construct its inheritance set:\n        # itself + the set of class names from which it inherits.\n        for class_definition in schema_data:\n            class_name = class_definition['name']\n            immediate_superclass_names = get_superclasses_from_class_definition(\n                class_definition)\n\n            inheritance_set = set(immediate_superclass_names)\n            inheritance_set.add(class_name)\n\n            # Since the input data must be in topological order, the superclasses of\n            # the current class should have already been processed.\n            # A KeyError on the following line would mean that the input\n            # was not topologically sorted.\n            inheritance_set.update(chain.from_iterable(\n                self._inheritance_sets[superclass_name]\n                for superclass_name in immediate_superclass_names\n            ))\n\n            # Freeze the inheritance set so it can't ever be modified again.\n            self._inheritance_sets[class_name] = frozenset(inheritance_set)\n\n        # For each class name, construct its subclass set:\n        # itself + the set of class names that inherit from it.\n        for subclass_name, superclass_names in six.iteritems(self._inheritance_sets):\n            for superclass_name in superclass_names:\n                self._subclass_sets.setdefault(\n                    superclass_name, set()).add(subclass_name)\n\n        # Freeze all subclass sets so they can never be modified again,\n        # making a list of all keys before modifying any of their values.\n        # It's bad practice to mutate a dict while iterating over it.\n        for class_name in list(six.iterkeys(self._subclass_sets)):\n            self._subclass_sets[class_name] = frozenset(self._subclass_sets[class_name])", "response": "Load all inheritance data from the OrientDB schema. Used as part of __init__."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassigns each class to the vertex edge or non - graph type sets based on its kind.", "response": "def _split_classes_by_kind(self, class_name_to_definition):\n        \"\"\"Assign each class to the vertex, edge or non-graph type sets based on its kind.\"\"\"\n        for class_name in class_name_to_definition:\n            inheritance_set = self._inheritance_sets[class_name]\n\n            is_vertex = ORIENTDB_BASE_VERTEX_CLASS_NAME in inheritance_set\n            is_edge = ORIENTDB_BASE_EDGE_CLASS_NAME in inheritance_set\n\n            if is_vertex and is_edge:\n                raise AssertionError(u'Class {} appears to be both a vertex and an edge class: '\n                                     u'{}'.format(class_name, inheritance_set))\n            elif is_vertex:\n                self._vertex_class_names.add(class_name)\n            elif is_edge:\n                self._edge_class_names.add(class_name)\n            else:\n                self._non_graph_class_names.add(class_name)\n\n        # Freeze the classname sets so they cannot be modified again.\n        self._vertex_class_names = frozenset(self._vertex_class_names)\n        self._edge_class_names = frozenset(self._edge_class_names)\n        self._non_graph_class_names = frozenset(self._non_graph_class_names)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_up_schema_elements_of_kind(self, class_name_to_definition, kind, class_names):\n        allowed_duplicated_edge_property_names = frozenset({\n            EDGE_DESTINATION_PROPERTY_NAME, EDGE_SOURCE_PROPERTY_NAME\n        })\n        orientdb_base_classes = frozenset({\n            ORIENTDB_BASE_VERTEX_CLASS_NAME,\n            ORIENTDB_BASE_EDGE_CLASS_NAME,\n        })\n\n        for class_name in class_names:\n            class_definition = class_name_to_definition[class_name]\n\n            class_fields = class_definition.get('customFields')\n            if class_fields is None:\n                # OrientDB likes to make empty collections be None instead.\n                # We convert this field back to an empty dict, for our general sanity.\n                class_fields = dict()\n\n            abstract = class_definition['abstract']\n            if class_name in orientdb_base_classes:\n                # Special-case the V and E base classes:\n                # OrientDB won't let us make them abstract, but we don't want to create\n                # any vertices or edges with those types either.\n                # Pretend they are marked abstract in OrientDB's schema.\n                abstract = True\n\n            property_name_to_descriptor = {}\n            all_property_lists = (\n                class_name_to_definition[inherited_class_name]['properties']\n                for inherited_class_name in self._inheritance_sets[class_name]\n            )\n            links = {EDGE_DESTINATION_PROPERTY_NAME: [], EDGE_SOURCE_PROPERTY_NAME: []}\n            for property_definition in chain.from_iterable(all_property_lists):\n                property_name = property_definition['name']\n\n                # The only properties we allow to be redefined are the in/out properties\n                # of edge classes. All other properties may only be defined once\n                # in the entire inheritance hierarchy of any schema class, of any kind.\n                duplication_allowed = all((\n                    property_name in allowed_duplicated_edge_property_names,\n                    kind == SchemaElement.ELEMENT_KIND_EDGE\n                ))\n\n                if not duplication_allowed and property_name in property_name_to_descriptor:\n                    raise AssertionError(u'The property \"{}\" on class \"{}\" is defined '\n                                         u'more than once, this is not allowed!'\n                                         .format(property_name, class_name))\n\n                property_descriptor = self._create_descriptor_from_property_definition(\n                    class_name, property_definition, class_name_to_definition)\n\n                if property_name in allowed_duplicated_edge_property_names:\n                    links[property_name].append(property_descriptor)\n                else:\n                    property_name_to_descriptor[property_name] = property_descriptor\n\n            for property_name in allowed_duplicated_edge_property_names:\n                elements = {\n                    property_descriptor.qualifier\n                    for property_descriptor in links[property_name]\n                }\n                # If there are multiple in/out properties, we choose to include the one that\n                # is a subclass of all the elements present in the in/out properties.\n                for property_descriptor in links[property_name]:\n                    subclass_set = self._subclass_sets[property_descriptor.qualifier]\n                    if len(elements.intersection(subclass_set)) == 1:\n                        current_descriptor = property_name_to_descriptor.get(property_name, None)\n                        if current_descriptor and current_descriptor != property_descriptor:\n                            raise AssertionError(u'There already exists property \"{}\" in addition '\n                                                 u'to property \"{}\" which is a subclass of all '\n                                                 u'in/out properties for class \"{}\".'\n                                                 .format(current_descriptor,\n                                                         property_descriptor, class_name))\n                        property_name_to_descriptor[property_name] = property_descriptor\n\n                if (property_name not in property_name_to_descriptor and not abstract and\n                        kind == SchemaElement.ELEMENT_KIND_EDGE):\n                    raise AssertionError(u'For property \"{}\" of non-abstract edge class \"{}\", '\n                                         u'no such subclass-of-all-elements exists.'\n                                         .format(property_name, class_name))\n\n            self._elements[class_name] = SchemaElement(class_name, kind, abstract,\n                                                       property_name_to_descriptor, class_fields)", "response": "Load all schema classes of the given kind. Used as part of __init__."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a PropertyDescriptor from the given property definition.", "response": "def _create_descriptor_from_property_definition(self, class_name, property_definition,\n                                                    class_name_to_definition):\n        \"\"\"Return a PropertyDescriptor corresponding to the given OrientDB property definition.\"\"\"\n        name = property_definition['name']\n        type_id = property_definition['type']\n        linked_class = property_definition.get('linkedClass', None)\n        linked_type = property_definition.get('linkedType', None)\n        qualifier = None\n\n        validate_supported_property_type_id(name, type_id)\n\n        if type_id == PROPERTY_TYPE_LINK_ID:\n            if class_name not in self._edge_class_names:\n                raise AssertionError(u'Found a property of type Link on a non-edge class: '\n                                     u'{} {}'.format(name, class_name))\n\n            if name not in {EDGE_SOURCE_PROPERTY_NAME, EDGE_DESTINATION_PROPERTY_NAME}:\n                raise AssertionError(u'Found a property of type Link with an unexpected name: '\n                                     u'{} {}'.format(name, class_name))\n\n            if linked_class is None:\n                raise AssertionError(u'Property \"{}\" is declared with type Link but has no '\n                                     u'linked class: {}'.format(name, property_definition))\n\n            if linked_class not in self._vertex_class_names:\n                is_linked_class_abstract = class_name_to_definition[linked_class]['abstract']\n                all_subclasses_are_vertices = True\n                for subclass in self._subclass_sets[linked_class]:\n                    if subclass != linked_class and subclass not in self.vertex_class_names:\n                        all_subclasses_are_vertices = False\n                        break\n                if not (is_linked_class_abstract and all_subclasses_are_vertices):\n                    raise AssertionError(u'Property \"{}\" is declared as a Link to class {}, but '\n                                         u'that class is neither a vertex nor is it an '\n                                         u'abstract class whose subclasses are all vertices!'\n                                         .format(name, linked_class))\n\n            qualifier = linked_class\n        elif type_id in COLLECTION_PROPERTY_TYPES:\n            if linked_class is not None and linked_type is not None:\n                raise AssertionError(u'Property \"{}\" unexpectedly has both a linked class and '\n                                     u'a linked type: {}'.format(name, property_definition))\n            elif linked_type is not None and linked_class is None:\n                # No linked class, must be a linked native OrientDB type.\n                validate_supported_property_type_id(name + ' inner type', linked_type)\n\n                qualifier = linked_type\n            elif linked_class is not None and linked_type is None:\n                # No linked type, must be a linked non-graph user-defined type.\n                if linked_class not in self._non_graph_class_names:\n                    raise AssertionError(u'Property \"{}\" is declared as the inner type of '\n                                         u'an embedded collection, but is not a non-graph class: '\n                                         u'{}'.format(name, linked_class))\n\n                qualifier = linked_class\n            else:\n                raise AssertionError(u'Property \"{}\" is an embedded collection but has '\n                                     u'neither a linked class nor a linked type: '\n                                     u'{}'.format(name, property_definition))\n\n        default_value = None\n        default_value_string = property_definition.get('defaultValue', None)\n        if default_value_string is not None:\n            default_value = parse_default_property_value(name, type_id, default_value_string)\n\n        descriptor = PropertyDescriptor(type_id=type_id, qualifier=qualifier, default=default_value)\n        # Sanity-check the descriptor before returning it.\n        _validate_collections_have_default_values(class_name, name, descriptor)\n        return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _link_vertex_and_edge_types(self):\n        for edge_class_name in self._edge_class_names:\n            edge_element = self._elements[edge_class_name]\n\n            if (EDGE_SOURCE_PROPERTY_NAME not in edge_element.properties or\n                    EDGE_DESTINATION_PROPERTY_NAME not in edge_element.properties):\n                if edge_element.abstract:\n                    continue\n                else:\n                    raise AssertionError(u'Found a non-abstract edge class with undefined '\n                                         u'endpoint types: {}'.format(edge_element))\n\n            from_class_name = edge_element.properties[EDGE_SOURCE_PROPERTY_NAME].qualifier\n            to_class_name = edge_element.properties[EDGE_DESTINATION_PROPERTY_NAME].qualifier\n\n            edge_schema_element = self._elements[edge_class_name]\n\n            # Link from_class_name with edge_class_name\n            for from_class in self._subclass_sets[from_class_name]:\n                from_schema_element = self._elements[from_class]\n                from_schema_element.out_connections.add(edge_class_name)\n                edge_schema_element.in_connections.add(from_class)\n\n            # Link edge_class_name with to_class_name\n            for to_class in self._subclass_sets[to_class_name]:\n                to_schema_element = self._elements[to_class]\n                edge_schema_element.out_connections.add(to_class)\n                to_schema_element.in_connections.add(edge_class_name)", "response": "For each edge link it to the vertex types it connects to each other."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_local_filter(filter_block):\n    # We need the \"result\" value of this function to be mutated within the \"visitor_fn\".\n    # Since we support both Python 2 and Python 3, we can't use the \"nonlocal\" keyword here:\n    # https://www.python.org/dev/peps/pep-3104/\n    # Instead, we use a dict to store the value we need mutated, since the \"visitor_fn\"\n    # can mutate state in the parent scope, but not rebind variables in it without \"nonlocal\".\n    # TODO(predrag): Revisit this if we drop support for Python 2.\n    result = {\n        'is_local_filter': True\n    }\n    filter_predicate = filter_block.predicate\n\n    def visitor_fn(expression):\n        \"\"\"Expression visitor function that looks for uses of non-local fields.\"\"\"\n        non_local_expression_types = (ContextField, ContextFieldExistence)\n\n        if isinstance(expression, non_local_expression_types):\n            result['is_local_filter'] = False\n\n        # Don't change the expression.\n        return expression\n\n    filter_predicate.visit_and_update(visitor_fn)\n\n    return result['is_local_filter']", "response": "Return True if the Filter block references no non - local fields and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _classify_query_locations(match_query):\n    preferred_locations = set()\n    eligible_locations = set()\n    ineligible_locations = set()\n\n    # Any query must have at least one traversal with at least one step.\n    # The first step in this traversal must be a QueryRoot.\n    first_match_step = match_query.match_traversals[0][0]\n    if not isinstance(first_match_step.root_block, QueryRoot):\n        raise AssertionError(u'First step of first traversal unexpectedly was not QueryRoot: '\n                             u'{} {}'.format(first_match_step, match_query))\n\n    # The first step in the first traversal cannot possibly be inside an optional, recursion,\n    # or fold. Its location is always an eligible start location for a query.\n    # We need to determine whether it is merely eligible, or actually a preferred location.\n    if first_match_step.where_block is not None:\n        if _is_local_filter(first_match_step.where_block):\n            preferred_locations.add(first_match_step.as_block.location)\n        else:\n            # TODO(predrag): Fix once we have a proper fix for tag-and-filter in the same scope.\n            #                Either the locally-scoped tag will have to generate a LocalField\n            #                instead of a ContextField, or we'll have to rework the local filter\n            #                detection code in this module.\n            raise AssertionError(u'The first step of the first traversal somehow had a non-local '\n                                 u'filter. This should not be possible, since there is nowhere '\n                                 u'for the tagged value to have come from. Values: {} {}'\n                                 .format(first_match_step, match_query))\n    else:\n        eligible_locations.add(first_match_step.as_block.location)\n\n    # This loop will repeat the analysis of the first step of the first traversal.\n    # QueryRoots other than the first are required to always be at a location whose status\n    # (preferred / eligible / ineligible) is already known. Since we already processed\n    # the first QueryRoot above, the rest of the loop can assume all QueryRoots are like that.\n    for current_traversal in match_query.match_traversals:\n        for match_step in current_traversal:\n            current_step_location = match_step.as_block.location\n\n            if isinstance(match_step.root_block, QueryRoot):\n                already_encountered_location = any((\n                    current_step_location in preferred_locations,\n                    current_step_location in eligible_locations,\n                    current_step_location in ineligible_locations,\n                ))\n\n                if not already_encountered_location:\n                    raise AssertionError(u'Unexpectedly encountered a location in QueryRoot whose '\n                                         u'status has not been determined: {} {} {}'\n                                         .format(current_step_location, match_step, match_query))\n\n                at_eligible_or_preferred_location = (\n                    current_step_location in preferred_locations or\n                    current_step_location in eligible_locations)\n\n                # This location has already been encountered and processed.\n                # Other than setting the \"at_eligible_or_preferred_location\" state for the sake of\n                # the following MATCH steps, there is nothing further to be done.\n                continue\n            elif isinstance(match_step.root_block, Recurse):\n                # All Recurse blocks cause locations within to be ineligible.\n                at_eligible_or_preferred_location = False\n            elif isinstance(match_step.root_block, Traverse):\n                # Optional Traverse blocks cause locations within to be ineligible.\n                # Non-optional Traverse blocks do not change the eligibility of locations within:\n                # if the pre-Traverse location was eligible, so will the location within,\n                # and if it was not eligible, neither will the location within.\n                if match_step.root_block.optional:\n                    at_eligible_or_preferred_location = False\n            else:\n                raise AssertionError(u'Unreachable condition reached: {} {} {}'\n                                     .format(match_step.root_block, match_step, match_query))\n\n            if not at_eligible_or_preferred_location:\n                ineligible_locations.add(current_step_location)\n            elif match_step.where_block is not None:\n                if _is_local_filter(match_step.where_block):\n                    # This location has a local filter, and is not otherwise ineligible (it's not\n                    # in a recursion etc.). Therefore, it's a preferred query start location.\n                    preferred_locations.add(current_step_location)\n                else:\n                    # Locations with non-local filters are never eligible locations, since they\n                    # depend on another location being executed before them.\n                    ineligible_locations.add(current_step_location)\n            else:\n                # No local filtering (i.e. not preferred), but also not ineligible. Eligible it is.\n                eligible_locations.add(current_step_location)\n\n    return preferred_locations, eligible_locations, ineligible_locations", "response": "Classify query locations into three groups preferred eligible and ineligible."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _calculate_type_bound_at_step(match_step):\n    current_type_bounds = []\n\n    if isinstance(match_step.root_block, QueryRoot):\n        # The QueryRoot start class is a type bound.\n        current_type_bounds.extend(match_step.root_block.start_class)\n\n    if match_step.coerce_type_block is not None:\n        # The CoerceType target class is also a type bound.\n        current_type_bounds.extend(match_step.coerce_type_block.target_class)\n\n    if current_type_bounds:\n        # A type bound exists. Assert that there is exactly one bound, defined in precisely one way.\n        return get_only_element_from_collection(current_type_bounds)\n    else:\n        # No type bound exists at this MATCH step.\n        return None", "response": "Calculate the type bound at the given MATCH step."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _assert_type_bounds_are_not_conflicting(current_type_bound, previous_type_bound,\n                                            location, match_query):\n    \"\"\"Ensure that the two bounds either are an exact match, or one of them is None.\"\"\"\n    if all((current_type_bound is not None,\n            previous_type_bound is not None,\n            current_type_bound != previous_type_bound)):\n        raise AssertionError(\n            u'Conflicting type bounds calculated at location {}: {} vs {} '\n            u'for query {}'.format(location, previous_type_bound, current_type_bound, match_query))", "response": "Assert that two type bounds are not conflicting."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a MATCH query where only preferred locations are valid as query start locations.", "response": "def _expose_only_preferred_locations(match_query, location_types, coerced_locations,\n                                     preferred_locations, eligible_locations):\n    \"\"\"Return a MATCH query where only preferred locations are valid as query start locations.\"\"\"\n    preferred_location_types = dict()\n    eligible_location_types = dict()\n\n    new_match_traversals = []\n    for current_traversal in match_query.match_traversals:\n        new_traversal = []\n        for match_step in current_traversal:\n            new_step = match_step\n            current_step_location = match_step.as_block.location\n\n            if current_step_location in preferred_locations:\n                # This location is preferred. We have to make sure that at least one occurrence\n                # of this location in the MATCH query has an associated \"class:\" clause,\n                # which would be generated by a type bound at the corresponding MATCH step.\n                current_type_bound = _calculate_type_bound_at_step(match_step)\n                previous_type_bound = preferred_location_types.get(current_step_location, None)\n\n                if previous_type_bound is not None:\n                    # The location is already valid. If so, make sure that this step either does\n                    # not have any type bounds (e.g. via QueryRoot or CoerceType blocks),\n                    # or has type bounds that match the previously-decided type bound.\n                    _assert_type_bounds_are_not_conflicting(\n                        current_type_bound, previous_type_bound, current_step_location, match_query)\n                else:\n                    # The location is not yet known to be valid. If it does not have\n                    # a type bound in this MATCH step, add a type coercion to the type\n                    # registered in \"location_types\".\n                    if current_type_bound is None:\n                        current_type_bound = location_types[current_step_location].name\n                        new_step = match_step._replace(\n                            coerce_type_block=CoerceType({current_type_bound}))\n\n                    preferred_location_types[current_step_location] = current_type_bound\n            elif current_step_location in eligible_locations:\n                # This location is eligible, but not preferred. We have not make sure\n                # none of the MATCH steps with this location have type bounds, and therefore\n                # will not produce a corresponding \"class:\" clause in the resulting MATCH query.\n                current_type_bound = _calculate_type_bound_at_step(match_step)\n                previous_type_bound = eligible_location_types.get(current_step_location, None)\n                if current_type_bound is not None:\n                    # There is a type bound here that we need to neutralize.\n                    _assert_type_bounds_are_not_conflicting(\n                        current_type_bound, previous_type_bound, current_step_location, match_query)\n\n                    # Record the deduced type bound, so that if we encounter this location again,\n                    # we ensure that we again infer the same type bound.\n                    eligible_location_types[current_step_location] = current_type_bound\n\n                    if (current_step_location not in coerced_locations or\n                            previous_type_bound is not None):\n                        # The type bound here is already implied by the GraphQL query structure,\n                        # or has already been applied at a previous occurrence of this location.\n                        # We can simply delete the QueryRoot / CoerceType blocks that impart it.\n                        if isinstance(match_step.root_block, QueryRoot):\n                            new_root_block = None\n                        else:\n                            new_root_block = match_step.root_block\n\n                        new_step = match_step._replace(\n                            root_block=new_root_block, coerce_type_block=None)\n                    else:\n                        # The type bound here is not already implied by the GraphQL query structure.\n                        # This should only be possible via a CoerceType block. Lower this CoerceType\n                        # block into a Filter with INSTANCEOF to ensure the resulting query has the\n                        # same semantics, while making the location invalid as a query start point.\n                        if (isinstance(match_step.root_block, QueryRoot) or\n                                match_step.coerce_type_block is None):\n                            raise AssertionError(u'Unexpected MATCH step applying a type bound not '\n                                                 u'already implied by the GraphQL query structure: '\n                                                 u'{} {}'.format(match_step, match_query))\n\n                        new_where_block = convert_coerce_type_and_add_to_where_block(\n                            match_step.coerce_type_block, match_step.where_block)\n                        new_step = match_step._replace(\n                            coerce_type_block=None, where_block=new_where_block)\n                else:\n                    # There is no type bound that OrientDB can find defined at this location.\n                    # No action is necessary.\n                    pass\n            else:\n                # This location is neither preferred nor eligible.\n                # No action is necessary at this location.\n                pass\n\n            new_traversal.append(new_step)\n        new_match_traversals.append(new_traversal)\n    return match_query._replace(match_traversals=new_match_traversals)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a MATCH query where all eligible locations are valid as query start locations.", "response": "def _expose_all_eligible_locations(match_query, location_types, eligible_locations):\n    \"\"\"Return a MATCH query where all eligible locations are valid as query start locations.\"\"\"\n    eligible_location_types = dict()\n\n    new_match_traversals = []\n    for current_traversal in match_query.match_traversals:\n        new_traversal = []\n        for match_step in current_traversal:\n            new_step = match_step\n            current_step_location = match_step.as_block.location\n\n            if current_step_location in eligible_locations:\n                # This location is eligible. We need to make sure it has an associated type bound,\n                # so that it produces a \"class:\" clause that will make it a valid query start\n                # location. It either already has such a type bound, or we can use the type\n                # implied by the GraphQL query structure to add one.\n                current_type_bound = _calculate_type_bound_at_step(match_step)\n                previous_type_bound = eligible_location_types.get(current_step_location, None)\n                if current_type_bound is None:\n                    current_type_bound = location_types[current_step_location].name\n                    new_coerce_type_block = CoerceType({current_type_bound})\n                    new_step = match_step._replace(coerce_type_block=new_coerce_type_block)\n                else:\n                    # There is a type bound here. We simply ensure that the bound is not conflicting\n                    # with any other type bound at a different MATCH step with the same location.\n                    _assert_type_bounds_are_not_conflicting(\n                        current_type_bound, previous_type_bound, current_step_location, match_query)\n\n                # Record the deduced type bound, so that if we encounter this location again,\n                # we ensure that we again infer the same type bound.\n                eligible_location_types[current_step_location] = current_type_bound\n            else:\n                # This function may only be called if there are no preferred locations. Since this\n                # location cannot be preferred, and is not eligible, it must be ineligible.\n                # No action is necessary in this case.\n                pass\n\n            new_traversal.append(new_step)\n        new_match_traversals.append(new_traversal)\n    return match_query._replace(match_traversals=new_match_traversals)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expose_ideal_query_execution_start_points(compound_match_query, location_types,\n                                              coerced_locations):\n    \"\"\"Ensure that OrientDB only considers desirable query start points in query planning.\"\"\"\n    new_queries = []\n\n    for match_query in compound_match_query.match_queries:\n        location_classification = _classify_query_locations(match_query)\n        preferred_locations, eligible_locations, _ = location_classification\n\n        if preferred_locations:\n            # Convert all eligible locations into non-eligible ones, by removing\n            # their \"class:\" clause. The \"class:\" clause is provided either by having\n            # a QueryRoot block or a CoerceType block in the MatchStep corresponding\n            # to the location. We remove it by converting the class check into\n            # an \"INSTANCEOF\" Filter block, which OrientDB is unable to optimize away.\n            new_query = _expose_only_preferred_locations(\n                match_query, location_types, coerced_locations,\n                preferred_locations, eligible_locations)\n        elif eligible_locations:\n            # Make sure that all eligible locations have a \"class:\" clause by adding\n            # a CoerceType block that is a no-op as guaranteed by the schema. This merely\n            # ensures that OrientDB is able to use each of these locations as a query start point,\n            # and will choose the one whose class is of lowest cardinality.\n            new_query = _expose_all_eligible_locations(\n                match_query, location_types, eligible_locations)\n        else:\n            raise AssertionError(u'This query has no preferred or eligible query start locations. '\n                                 u'This is almost certainly a bug: {}'.format(match_query))\n\n        new_queries.append(new_query)\n\n    return compound_match_query._replace(match_queries=new_queries)", "response": "Expose query start points in query planning."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _expression_list_to_conjunction(expression_list):\n    if not isinstance(expression_list, list):\n        raise AssertionError(u'Expected list. Received {}: '\n                             u'{}'.format(type(expression_list).__name__, expression_list))\n    if len(expression_list) == 0:\n        raise AssertionError(u'Received empty expression_list '\n                             u'(function should never be called with empty list): '\n                             u'{}'.format(expression_list))\n    elif len(expression_list) == 1:\n        return expression_list[0]\n    else:\n        remaining_conjunction = _expression_list_to_conjunction(expression_list[1:])\n        return BinaryComposition(u'&&', expression_list[0], remaining_conjunction)", "response": "Return an Expression that is the && of all the expressions in the given list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _extract_conjuction_elements_from_expression(expression):\n    if isinstance(expression, BinaryComposition) and expression.operator == u'&&':\n        for element in _extract_conjuction_elements_from_expression(expression.left):\n            yield element\n        for element in _extract_conjuction_elements_from_expression(expression.right):\n            yield element\n    else:\n        yield expression", "response": "Return a generator for expressions that are connected by && s in the given expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _construct_field_operator_expression_dict(expression_list):\n    between_operators = (u'<=', u'>=')\n    inverse_operator = {u'>=': u'<=', u'<=': u'>='}\n    local_field_to_expressions = {}\n    remaining_expression_list = deque([])\n    for expression in expression_list:\n        if all((\n            isinstance(expression, BinaryComposition),\n            expression.operator in between_operators,\n            isinstance(expression.left, LocalField) or isinstance(expression.right, LocalField)\n        )):\n            if isinstance(expression.right, LocalField):\n                new_operator = inverse_operator[expression.operator]\n                new_expression = BinaryComposition(new_operator, expression.right, expression.left)\n            else:\n                new_expression = expression\n            field_name = new_expression.left.field_name\n            expressions_dict = local_field_to_expressions.setdefault(field_name, {})\n            expressions_dict.setdefault(new_expression.operator, []).append(new_expression)\n        else:\n            remaining_expression_list.append(expression)\n    return local_field_to_expressions, remaining_expression_list", "response": "Construct a mapping from local field names to specified operators and corresponding expressions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new expression with any eligible comparisons lowered to between clauses.", "response": "def _lower_expressions_to_between(base_expression):\n    \"\"\"Return a new expression, with any eligible comparisons lowered to `between` clauses.\"\"\"\n    expression_list = list(_extract_conjuction_elements_from_expression(base_expression))\n    if len(expression_list) == 0:\n        raise AssertionError(u'Received empty expression_list {} from base_expression: '\n                             u'{}'.format(expression_list, base_expression))\n    elif len(expression_list) == 1:\n        return base_expression\n    else:\n        between_operators = (u'<=', u'>=')\n        local_field_to_expressions, new_expression_list = _construct_field_operator_expression_dict(\n            expression_list)\n\n        lowering_occurred = False\n        for field_name in local_field_to_expressions:\n            expressions_dict = local_field_to_expressions[field_name]\n            if all(operator in expressions_dict and len(expressions_dict[operator]) == 1\n                   for operator in between_operators):\n                field = LocalField(field_name)\n                lower_bound = expressions_dict[u'>='][0].right\n                upper_bound = expressions_dict[u'<='][0].right\n                new_expression_list.appendleft(BetweenClause(field, lower_bound, upper_bound))\n                lowering_occurred = True\n            else:\n                for expression in expressions_dict.values():\n                    new_expression_list.extend(expression)\n\n        if lowering_occurred:\n            return _expression_list_to_conjunction(list(new_expression_list))\n        else:\n            return base_expression"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new MatchQuery with all eligible comparison filters lowered to between clauses.", "response": "def lower_comparisons_to_between(match_query):\n    \"\"\"Return a new MatchQuery, with all eligible comparison filters lowered to between clauses.\"\"\"\n    new_match_traversals = []\n\n    for current_match_traversal in match_query.match_traversals:\n        new_traversal = []\n        for step in current_match_traversal:\n            if step.where_block:\n                expression = step.where_block.predicate\n                new_where_block = Filter(_lower_expressions_to_between(expression))\n                new_traversal.append(step._replace(where_block=new_where_block))\n            else:\n                new_traversal.append(step)\n\n        new_match_traversals.append(new_traversal)\n\n    return match_query._replace(match_traversals=new_match_traversals)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ensure_arguments_are_provided(expected_types, arguments):\n    # This function only checks that the arguments were specified,\n    # and does not check types. Type checking is done as part of the actual formatting step.\n    expected_arg_names = set(six.iterkeys(expected_types))\n    provided_arg_names = set(six.iterkeys(arguments))\n\n    if expected_arg_names != provided_arg_names:\n        missing_args = expected_arg_names - provided_arg_names\n        unexpected_args = provided_arg_names - expected_arg_names\n        raise GraphQLInvalidArgumentError(u'Missing or unexpected arguments found: '\n                                          u'missing {}, unexpected '\n                                          u'{}'.format(missing_args, unexpected_args))", "response": "Ensure that all arguments expected by the query were actually provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert_arguments_into_query(compilation_result, arguments):\n    _ensure_arguments_are_provided(compilation_result.input_metadata, arguments)\n\n    if compilation_result.language == MATCH_LANGUAGE:\n        return insert_arguments_into_match_query(compilation_result, arguments)\n    elif compilation_result.language == GREMLIN_LANGUAGE:\n        return insert_arguments_into_gremlin_query(compilation_result, arguments)\n    elif compilation_result.language == SQL_LANGUAGE:\n        return insert_arguments_into_sql_query(compilation_result, arguments)\n    else:\n        raise AssertionError(u'Unrecognized language in compilation result: '\n                             u'{}'.format(compilation_result))", "response": "Insert the arguments into the compiled GraphQL query to form a complete query."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures that the QueryRoot block is valid.", "response": "def validate(self):\n        \"\"\"Ensure that the QueryRoot block is valid.\"\"\"\n        if not (isinstance(self.start_class, set) and\n                all(isinstance(x, six.string_types) for x in self.start_class)):\n            raise TypeError(u'Expected set of string start_class, got: {} {}'.format(\n                type(self.start_class).__name__, self.start_class))\n\n        for cls in self.start_class:\n            validate_safe_string(cls)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a unicode object with the Gremlin representation of this block.", "response": "def to_gremlin(self):\n        \"\"\"Return a unicode object with the Gremlin representation of this block.\"\"\"\n        self.validate()\n        if len(self.start_class) == 1:\n            # The official Gremlin documentation claims that this approach\n            # is generally faster than the one below, since it makes using indexes easier.\n            # http://gremlindocs.spmallette.documentup.com/#filter/has\n            start_class = list(self.start_class)[0]\n            return u'g.V({}, {})'.format('\\'@class\\'', safe_quoted_string(start_class))\n        else:\n            start_classes_list = ','.join(safe_quoted_string(x) for x in self.start_class)\n            return u'g.V.has(\\'@class\\', T.in, [{}])'.format(start_classes_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self):\n        if not (isinstance(self.target_class, set) and\n                all(isinstance(x, six.string_types) for x in self.target_class)):\n            raise TypeError(u'Expected set of string target_class, got: {} {}'.format(\n                type(self.target_class).__name__, self.target_class))\n\n        for cls in self.target_class:\n            validate_safe_string(cls)", "response": "Ensure that the CoerceType block is valid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self):\n        if not isinstance(self.fields, dict):\n            raise TypeError(u'Expected dict fields, got: {} {}'.format(\n                type(self.fields).__name__, self.fields))\n\n        for key, value in six.iteritems(self.fields):\n            validate_safe_string(key)\n            if not isinstance(value, Expression):\n                raise TypeError(\n                    u'Expected Expression values in the fields dict, got: '\n                    u'{} -> {}'.format(key, value))", "response": "Ensure that the ConstructResult block is valid."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an updated version of the ConstructResult via the visitor pattern.", "response": "def visit_and_update_expressions(self, visitor_fn):\n        \"\"\"Create an updated version (if needed) of the ConstructResult via the visitor pattern.\"\"\"\n        new_fields = {}\n\n        for key, value in six.iteritems(self.fields):\n            new_value = value.visit_and_update(visitor_fn)\n            if new_value is not value:\n                new_fields[key] = new_value\n\n        if new_fields:\n            return ConstructResult(dict(self.fields, **new_fields))\n        else:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a unicode object with the Gremlin representation of this block.", "response": "def to_gremlin(self):\n        \"\"\"Return a unicode object with the Gremlin representation of this block.\"\"\"\n        self.validate()\n\n        template = (\n            u'transform{{'\n            u'it, m -> new com.orientechnologies.orient.core.record.impl.ODocument([ {} ])'\n            u'}}')\n\n        field_representations = (\n            u'{name}: {expr}'.format(name=key, expr=self.fields[key].to_gremlin())\n            for key in sorted(self.fields.keys())  # Sort the keys for deterministic output order.\n        )\n        return template.format(u', '.join(field_representations))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures that the Filter block is valid.", "response": "def validate(self):\n        \"\"\"Ensure that the Filter block is valid.\"\"\"\n        if not isinstance(self.predicate, Expression):\n            raise TypeError(u'Expected Expression predicate, got: {} {}'.format(\n                type(self.predicate).__name__, self.predicate))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an updated version of the Filter via the visitor pattern.", "response": "def visit_and_update_expressions(self, visitor_fn):\n        \"\"\"Create an updated version (if needed) of the Filter via the visitor pattern.\"\"\"\n        new_predicate = self.predicate.visit_and_update(visitor_fn)\n        if new_predicate is not self.predicate:\n            return Filter(new_predicate)\n        else:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_gremlin(self):\n        self.validate()\n        mark_name, _ = self.location.get_location_name()\n        return u'as({})'.format(safe_quoted_string(mark_name))", "response": "Return a unicode object with the Gremlin representation of this block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self):\n        if not isinstance(self.direction, six.string_types):\n            raise TypeError(u'Expected string direction, got: {} {}'.format(\n                type(self.direction).__name__, self.direction))\n\n        validate_edge_direction(self.direction)\n        validate_safe_string(self.edge_name)\n\n        if not isinstance(self.optional, bool):\n            raise TypeError(u'Expected bool optional, got: {} {}'.format(\n                type(self.optional).__name__, self.optional))\n\n        if not isinstance(self.within_optional_scope, bool):\n            raise TypeError(u'Expected bool within_optional_scope, got: {} '\n                            u'{}'.format(type(self.within_optional_scope).__name__,\n                                         self.within_optional_scope))", "response": "Ensure that the Traverse block is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a unicode object with the Gremlin representation of this block.", "response": "def to_gremlin(self):\n        \"\"\"Return a unicode object with the Gremlin representation of this block.\"\"\"\n        self.validate()\n        if self.optional:\n            # Optional edges have to be handled differently than non-optionals, since the compiler\n            # provides the guarantee that properties read from an optional, non-existing location\n            # always resolve to a \"null\" value. This guarantee is not upheld by default by Gremlin;\n            # in fact, Gremlin .as('foo').out().as('bar').optional('foo') does not provide\n            # ANY guarantees as to what the value at any \"bar.*\" is -- it could be \"null\",\n            # it could be a previous pipeline element's location at \"bar.*\" or anything else.\n            # The .ifThenElse block ensures that the edge traversal happens only if the edge exists,\n            # and that otherwise the result in the pipeline is replaced with \"null\".\n            #\n            # The code below makes the assumption that links to outward/inward edges are stored\n            # as vertex properties named \"<direction>_<edge_name>\" where direction is \"in\" or \"out\".\n            # For example, the links to outward edges named \"Person_SpeechBy\" from Person\n            # are assumed to be stored as \"out_Person_SpeechBy\" on the Person node.\n            return (u'ifThenElse{{it.{direction}_{edge_name} == null}}'\n                    u'{{null}}{{it.{direction}({edge_quoted})}}'.format(\n                        direction=self.direction,\n                        edge_name=self.edge_name,\n                        edge_quoted=safe_quoted_string(self.edge_name)))\n        elif self.within_optional_scope:\n            # During a traversal, the pipeline element may be null.\n            # The following code returns null when the current pipeline entity is null\n            # (an optional edge did not exist at some earlier traverse).\n            # Otherwise it performs a normal traversal (previous optional edge did exist).\n            return (u'ifThenElse{{it == null}}'\n                    u'{{null}}{{it.{direction}({edge_quoted})}}'.format(\n                        direction=self.direction,\n                        edge_quoted=safe_quoted_string(self.edge_name)))\n        else:\n            return u'{direction}({edge})'.format(\n                direction=self.direction,\n                edge=safe_quoted_string(self.edge_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nensures that the Traverse block is valid.", "response": "def validate(self):\n        \"\"\"Ensure that the Traverse block is valid.\"\"\"\n        validate_edge_direction(self.direction)\n        validate_safe_string(self.edge_name)\n\n        if not isinstance(self.within_optional_scope, bool):\n            raise TypeError(u'Expected bool within_optional_scope, got: {} '\n                            u'{}'.format(type(self.within_optional_scope).__name__,\n                                         self.within_optional_scope))\n\n        if not isinstance(self.depth, int):\n            raise TypeError(u'Expected int depth, got: {} {}'.format(\n                type(self.depth).__name__, self.depth))\n\n        if not (self.depth >= 1):\n            raise ValueError(u'depth ({}) >= 1 does not hold!'.format(self.depth))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_gremlin(self):\n        self.validate()\n        template = 'copySplit({recurse}).exhaustMerge'\n        recurse_base = '_()'\n        recurse_traversal = '.{direction}(\\'{edge_name}\\')'.format(\n            direction=self.direction, edge_name=self.edge_name)\n\n        recurse_steps = [\n            recurse_base + (recurse_traversal * i)\n            for i in six.moves.xrange(self.depth + 1)\n        ]\n        recursion_string = template.format(recurse=','.join(recurse_steps))\n        if self.within_optional_scope:\n            # During a traversal, the pipeline element may be null.\n            # The following code returns null when the current pipeline entity is null\n            # (an optional edge did not exist at some earlier traverse).\n            # Otherwise it performs a normal recursion (previous optional edge did exist).\n            recurse_template = u'ifThenElse{{it == null}}{{null}}{{it.{recursion_string}}}'\n            return recurse_template.format(recursion_string=recursion_string)\n        else:\n            return recursion_string", "response": "Return a unicode object with the Gremlin representation of this block."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure that the Backtrack block is valid.", "response": "def validate(self):\n        \"\"\"Ensure that the Backtrack block is valid.\"\"\"\n        validate_marked_location(self.location)\n        if not isinstance(self.optional, bool):\n            raise TypeError(u'Expected bool optional, got: {} {}'.format(\n                type(self.optional).__name__, self.optional))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a unicode object with the Gremlin representation of this BasicBlock.", "response": "def to_gremlin(self):\n        \"\"\"Return a unicode object with the Gremlin representation of this BasicBlock.\"\"\"\n        self.validate()\n        if self.optional:\n            operation = u'optional'\n        else:\n            operation = u'back'\n\n        mark_name, _ = self.location.get_location_name()\n\n        return u'{operation}({mark_name})'.format(\n            operation=operation,\n            mark_name=safe_quoted_string(mark_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures the Fold block is valid.", "response": "def validate(self):\n        \"\"\"Ensure the Fold block is valid.\"\"\"\n        if not isinstance(self.fold_scope_location, FoldScopeLocation):\n            raise TypeError(u'Expected a FoldScopeLocation for fold_scope_location, got: {} '\n                            u'{}'.format(type(self.fold_scope_location), self.fold_scope_location))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lower_ir(ir_blocks, query_metadata_table, type_equivalence_hints=None):\n    _validate_all_blocks_supported(ir_blocks, query_metadata_table)\n    construct_result = _get_construct_result(ir_blocks)\n    query_path_to_location_info = _map_query_path_to_location_info(query_metadata_table)\n    query_path_to_output_fields = _map_query_path_to_outputs(\n        construct_result, query_path_to_location_info)\n    block_index_to_location = _map_block_index_to_location(ir_blocks)\n\n    # perform lowering steps\n    ir_blocks = lower_unary_transformations(ir_blocks)\n    ir_blocks = lower_unsupported_metafield_expressions(ir_blocks)\n\n    # iteratively construct SqlTree\n    query_path_to_node = {}\n    query_path_to_filters = {}\n    tree_root = None\n    for index, block in enumerate(ir_blocks):\n        if isinstance(block, constants.SKIPPABLE_BLOCK_TYPES):\n            continue\n        location = block_index_to_location[index]\n        if isinstance(block, (blocks.QueryRoot,)):\n            query_path = location.query_path\n            if tree_root is not None:\n                raise AssertionError(\n                    u'Encountered QueryRoot {} but tree root is already set to {} during '\n                    u'construction of SQL query tree for IR blocks {} with query '\n                    u'metadata table {}'.format(\n                        block, tree_root, ir_blocks, query_metadata_table))\n            tree_root = SqlNode(block=block, query_path=query_path)\n            query_path_to_node[query_path] = tree_root\n        elif isinstance(block, blocks.Filter):\n            query_path_to_filters.setdefault(query_path, []).append(block)\n        else:\n            raise AssertionError(\n                u'Unsupported block {} unexpectedly passed validation for IR blocks '\n                u'{} with query metadata table {} .'.format(block, ir_blocks, query_metadata_table))\n\n    return SqlQueryTree(tree_root, query_path_to_location_info, query_path_to_output_fields,\n                        query_path_to_filters, query_path_to_node)", "response": "Lower the list of IR blocks into a SQL - compatible form."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_all_blocks_supported(ir_blocks, query_metadata_table):\n    if len(ir_blocks) < 3:\n        raise AssertionError(\n            u'Unexpectedly attempting to validate IR blocks with fewer than 3 blocks. A minimal '\n            u'query is expected to have at least a QueryRoot, GlobalOperationsStart, and '\n            u'ConstructResult block. The query metadata table is {}.'.format(query_metadata_table))\n    construct_result = _get_construct_result(ir_blocks)\n    unsupported_blocks = []\n    unsupported_fields = []\n    for block in ir_blocks[:-1]:\n        if isinstance(block, constants.SUPPORTED_BLOCK_TYPES):\n            continue\n        if isinstance(block, constants.SKIPPABLE_BLOCK_TYPES):\n            continue\n        unsupported_blocks.append(block)\n\n    for field_name, field in six.iteritems(construct_result.fields):\n        if not isinstance(field, constants.SUPPORTED_OUTPUT_EXPRESSION_TYPES):\n            unsupported_fields.append((field_name, field))\n        elif field.location.field in constants.UNSUPPORTED_META_FIELDS:\n            unsupported_fields.append((field_name, field))\n\n    if len(unsupported_blocks) > 0 or len(unsupported_fields) > 0:\n        raise NotImplementedError(\n            u'Encountered unsupported blocks {} and unsupported fields {} during construction of '\n            u'SQL query tree for IR blocks {} with query metadata table {}.'.format(\n                unsupported_blocks, unsupported_fields, ir_blocks, query_metadata_table))", "response": "Validate that all IR blocks and ConstructResult fields passed to the backend are supported."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the ConstructResult block from a list of IR blocks.", "response": "def _get_construct_result(ir_blocks):\n    \"\"\"Return the ConstructResult block from a list of IR blocks.\"\"\"\n    last_block = ir_blocks[-1]\n    if not isinstance(last_block, blocks.ConstructResult):\n        raise AssertionError(\n            u'The last IR block {} for IR blocks {} was unexpectedly not '\n            u'a ConstructResult block.'.format(last_block, ir_blocks))\n    return last_block"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _map_query_path_to_location_info(query_metadata_table):\n    query_path_to_location_info = {}\n    for location, location_info in query_metadata_table.registered_locations:\n        if not isinstance(location, Location):\n            continue\n        if location.query_path in query_path_to_location_info:\n            # make sure the stored location information equals the new location information\n            # for the fields the SQL backend requires.\n            equivalent_location_info = query_path_to_location_info[location.query_path]\n            if not _location_infos_equal(location_info, equivalent_location_info):\n                raise AssertionError(\n                    u'Differing LocationInfos at query_path {} between {} and {}. Expected '\n                    u'parent_location.query_path, optional_scopes_depth, recursive_scopes_depth '\n                    u'and types to be equal for LocationInfos sharing the same query path.'.format(\n                        location.query_path, location_info, equivalent_location_info))\n\n        query_path_to_location_info[location.query_path] = location_info\n    return query_path_to_location_info", "response": "Create a map from each query path to a LocationInfo at that path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the LocationInfo objects are considered equal for the SQL backend False otherwise.", "response": "def _location_infos_equal(left, right):\n    \"\"\"Return True if LocationInfo objects are equivalent for the SQL backend, False otherwise.\n\n    LocationInfo objects are considered equal for the SQL backend iff the optional scopes depth,\n    recursive scopes depth, types and parent query paths are equal.\n\n    Args:\n        left: LocationInfo, left location info object to compare.\n        right: LocationInfo, right location info object to compare.\n\n    Returns:\n        bool, True if LocationInfo objects equivalent, False otherwise.\n    \"\"\"\n    if not isinstance(left, LocationInfo) or not isinstance(right, LocationInfo):\n        raise AssertionError(\n            u'Unsupported LocationInfo comparison between types {} and {} '\n            u'with values {}, {}'.format(type(left), type(right), left, right))\n    optional_scopes_depth_equal = (left.optional_scopes_depth == right.optional_scopes_depth)\n\n    parent_query_paths_equal = (\n        (left.parent_location is None and right.parent_location is None) or\n        (left.parent_location.query_path == right.parent_location.query_path))\n\n    recursive_scopes_depths_equal = (left.recursive_scopes_depth == right.recursive_scopes_depth)\n\n    types_equal = left.type == right.type\n\n    return all([\n        optional_scopes_depth_equal,\n        parent_query_paths_equal,\n        recursive_scopes_depths_equal,\n        types_equal,\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning the output fields of a ConstructResult block to their respective query_path.", "response": "def _map_query_path_to_outputs(construct_result, query_path_to_location_info):\n    \"\"\"Assign the output fields of a ConstructResult block to their respective query_path.\"\"\"\n    query_path_to_output_fields = {}\n    for output_name, field in six.iteritems(construct_result.fields):\n        field_name = field.location.field\n        output_query_path = field.location.query_path\n        output_field_info = constants.SqlOutput(\n            field_name=field_name,\n            output_name=output_name,\n            graphql_type=query_path_to_location_info[output_query_path].type)\n        output_field_mapping = query_path_to_output_fields.setdefault(output_query_path, [])\n        output_field_mapping.append(output_field_info)\n    return query_path_to_output_fields"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps each IR block with its corresponding location by index.", "response": "def _map_block_index_to_location(ir_blocks):\n    \"\"\"Associate each IR block with its corresponding location, by index.\"\"\"\n    block_index_to_location = {}\n    # MarkLocation blocks occur after the blocks related to that location.\n    # The core approach here is to buffer blocks until their MarkLocation is encountered\n    # after which all buffered blocks can be associated with the encountered MarkLocation.location.\n    current_block_ixs = []\n    for num, ir_block in enumerate(ir_blocks):\n        if isinstance(ir_block, blocks.GlobalOperationsStart):\n            if len(current_block_ixs) > 0:\n                unassociated_blocks = [ir_blocks[ix] for ix in current_block_ixs]\n                raise AssertionError(\n                    u'Unexpectedly encountered global operations before mapping blocks '\n                    u'{} to their respective locations.'.format(unassociated_blocks))\n            break\n        current_block_ixs.append(num)\n        if isinstance(ir_block, blocks.MarkLocation):\n            for ix in current_block_ixs:\n                block_index_to_location[ix] = ir_block.location\n            current_block_ixs = []\n    return block_index_to_location"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lower_unary_transformations(ir_blocks):\n    def visitor_fn(expression):\n        \"\"\"Raise error if current expression is a UnaryTransformation.\"\"\"\n        if not isinstance(expression, expressions.UnaryTransformation):\n            return expression\n        raise NotImplementedError(\n            u'UnaryTransformation expression \"{}\" encountered with IR blocks {} is unsupported by '\n            u'the SQL backend.'.format(expression, ir_blocks)\n        )\n\n    new_ir_blocks = [\n        block.visit_and_update_expressions(visitor_fn)\n        for block in ir_blocks\n    ]\n    return new_ir_blocks", "response": "Lower unary transformations in the list of IR blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lower_unsupported_metafield_expressions(ir_blocks):\n    def visitor_fn(expression):\n        \"\"\"Visitor function raising exception for any unsupported metafield.\"\"\"\n        if not isinstance(expression, expressions.LocalField):\n            return expression\n        if expression.field_name not in constants.UNSUPPORTED_META_FIELDS:\n            return expression\n        raise NotImplementedError(\n            u'Encountered unsupported metafield {} in LocalField {} during construction of '\n            u'SQL query tree for IR blocks {}.'.format(\n                constants.UNSUPPORTED_META_FIELDS[expression.field_name], expression, ir_blocks))\n\n    new_ir_blocks = [\n        block.visit_and_update_expressions(visitor_fn)\n        for block in ir_blocks\n    ]\n    return new_ir_blocks", "response": "Lower unsupported metafield expressions in the list of IR blocks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncompiling the GraphQL input using the schema into a MATCH query and associated metadata.", "response": "def graphql_to_match(schema, graphql_query, parameters, type_equivalence_hints=None):\n    \"\"\"Compile the GraphQL input using the schema into a MATCH query and associated metadata.\n\n    Args:\n        schema: GraphQL schema object describing the schema of the graph to be queried\n        graphql_query: the GraphQL query to compile to MATCH, as a string\n        parameters: dict, mapping argument name to its value, for every parameter the query expects.\n        type_equivalence_hints: optional dict of GraphQL interface or type -> GraphQL union.\n                                Used as a workaround for GraphQL's lack of support for\n                                inheritance across \"types\" (i.e. non-interfaces), as well as a\n                                workaround for Gremlin's total lack of inheritance-awareness.\n                                The key-value pairs in the dict specify that the \"key\" type\n                                is equivalent to the \"value\" type, i.e. that the GraphQL type or\n                                interface in the key is the most-derived common supertype\n                                of every GraphQL type in the \"value\" GraphQL union.\n                                Recursive expansion of type equivalence hints is not performed,\n                                and only type-level correctness of this argument is enforced.\n                                See README.md for more details on everything this parameter does.\n                                *****\n                                Be very careful with this option, as bad input here will\n                                lead to incorrect output queries being generated.\n                                *****\n\n    Returns:\n        a CompilationResult object, containing:\n            - query: string, the resulting compiled and parameterized query string\n            - language: string, specifying the language to which the query was compiled\n            - output_metadata: dict, output name -> OutputMetadata namedtuple object\n            - input_metadata: dict, name of input variables -> inferred GraphQL type, based on use\n    \"\"\"\n    compilation_result = compile_graphql_to_match(\n        schema, graphql_query, type_equivalence_hints=type_equivalence_hints)\n    return compilation_result._replace(\n        query=insert_arguments_into_query(compilation_result, parameters))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef graphql_to_sql(schema, graphql_query, parameters, compiler_metadata,\n                   type_equivalence_hints=None):\n    \"\"\"Compile the GraphQL input using the schema into a SQL query and associated metadata.\n\n    Args:\n        schema: GraphQL schema object describing the schema of the graph to be queried\n        graphql_query: the GraphQL query to compile to SQL, as a string\n        parameters: dict, mapping argument name to its value, for every parameter the query expects.\n        compiler_metadata: SqlMetadata object, provides SQLAlchemy specific backend\n                           information\n        type_equivalence_hints: optional dict of GraphQL interface or type -> GraphQL union.\n                                Used as a workaround for GraphQL's lack of support for\n                                inheritance across \"types\" (i.e. non-interfaces), as well as a\n                                workaround for Gremlin's total lack of inheritance-awareness.\n                                The key-value pairs in the dict specify that the \"key\" type\n                                is equivalent to the \"value\" type, i.e. that the GraphQL type or\n                                interface in the key is the most-derived common supertype\n                                of every GraphQL type in the \"value\" GraphQL union.\n                                Recursive expansion of type equivalence hints is not performed,\n                                and only type-level correctness of this argument is enforced.\n                                See README.md for more details on everything this parameter does.\n                                *****\n                                Be very careful with this option, as bad input here will\n                                lead to incorrect output queries being generated.\n                                *****\n\n    Returns:\n        a CompilationResult object, containing:\n            - query: string, the resulting compiled and parameterized query string\n            - language: string, specifying the language to which the query was compiled\n            - output_metadata: dict, output name -> OutputMetadata namedtuple object\n            - input_metadata: dict, name of input variables -> inferred GraphQL type, based on use\n    \"\"\"\n    compilation_result = compile_graphql_to_sql(\n        schema, graphql_query, compiler_metadata, type_equivalence_hints=type_equivalence_hints)\n    return compilation_result._replace(\n        query=insert_arguments_into_query(compilation_result, parameters))", "response": "Compile the GraphQL query into a SQL query and associated metadata."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef graphql_to_gremlin(schema, graphql_query, parameters, type_equivalence_hints=None):\n    compilation_result = compile_graphql_to_gremlin(\n        schema, graphql_query, type_equivalence_hints=type_equivalence_hints)\n    return compilation_result._replace(\n        query=insert_arguments_into_query(compilation_result, parameters))", "response": "Compile the GraphQL input using the schema into Gremlin query and associated metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstructs a GraphQL schema from a list of data structures.", "response": "def get_graphql_schema_from_orientdb_schema_data(schema_data, class_to_field_type_overrides=None,\n                                                 hidden_classes=None):\n    \"\"\"Construct a GraphQL schema from an OrientDB schema.\n\n    Args:\n        schema_data: list of dicts describing the classes in the OrientDB schema. The following\n                     format is the way the data is structured in OrientDB 2. See\n                     the README.md file for an example of how to query this data.\n                     Each dict has the following string fields:\n                        - name: string, the name of the class.\n                        - superClasses (optional): list of strings, the name of the class's\n                                                   superclasses.\n                        - superClass (optional): string, the name of the class's superclass. May be\n                                                 used instead of superClasses if there is only one\n                                                 superClass. Used for backwards compatibility with\n                                                 OrientDB.\n                        - customFields (optional): dict, string -> string, data defined on the class\n                                                   instead of instances of the class.\n                        - abstract: bool, true if the class is abstract.\n                        - properties: list of dicts, describing the class's properties.\n                                      Each property dictionary has the following string fields:\n                                         - name: string, the name of the property.\n                                         - type: int, builtin OrientDB type ID of the property.\n                                                 See schema_properties.py for the mapping.\n                                         - linkedType (optional): int, if the property is a\n                                                                  collection of builtin OrientDB\n                                                                  objects, then it indicates their\n                                                                  type ID.\n                                         - linkedClass (optional): string, if the property is a\n                                                                   collection of class instances,\n                                                                   then it indicates the name of\n                                                                   the class. If class is an edge\n                                                                   class, and the field name is\n                                                                   either 'in' or 'out', then it\n                                                                   describes the name of an\n                                                                   endpoint of the edge.\n                                         - defaultValue: string, the textual representation of the\n                                                         default value for the property, as\n                                                         returned by OrientDB's schema\n                                                         introspection code, e.g., '{}' for\n                                                         the embedded set type. Note that if the\n                                                         property is a collection type, it must\n                                                         have a default value.\n        class_to_field_type_overrides: optional dict, class name -> {field name -> field type},\n                                       (string -> {string -> GraphQLType}). Used to override the\n                                       type of a field in the class where it's first defined and all\n                                       the class's subclasses.\n        hidden_classes: optional set of strings, classes to not include in the GraphQL schema.\n\n    Returns:\n        tuple of (GraphQL schema object, GraphQL type equivalence hints dict).\n        The tuple is of type (GraphQLSchema, {GraphQLObjectType -> GraphQLUnionType}).\n    \"\"\"\n    if class_to_field_type_overrides is None:\n        class_to_field_type_overrides = dict()\n    if hidden_classes is None:\n        hidden_classes = set()\n\n    schema_graph = SchemaGraph(schema_data)\n    return get_graphql_schema_from_schema_graph(schema_graph, class_to_field_type_overrides,\n                                                hidden_classes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a MATCH query string from a list of IR blocks.", "response": "def emit_code_from_ir(ir_blocks, compiler_metadata):\n    \"\"\"Return a MATCH query string from a list of IR blocks.\"\"\"\n    gremlin_steps = (\n        block.to_gremlin()\n        for block in ir_blocks\n    )\n\n    # OutputSource blocks translate to empty steps.\n    # Discard such empty steps so we don't end up with an incorrect concatenation.\n    non_empty_steps = (\n        step\n        for step in gremlin_steps\n        if step\n    )\n\n    return u'.'.join(non_empty_steps)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the built in webserver", "response": "def start(self, host='127.0.0.1', port=None, debug=False, **kwargs):\n        \"\"\"\n        Start the built in webserver, bound to the host and port you'd like.\n        Default host is `127.0.0.1` and port 8080.\n\n        :param host: The host you want to bind the build in webserver to\n        :param port: The port number you want the webserver to run on\n        :param debug: Set to `True` to enable debug level logging\n        :param kwargs: Additional arguments you'd like to pass to Flask\n        \"\"\"\n        self.server.run(host=host, port=port, debug=debug, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef login(request):\n    '''\n    Logs in the user via given login and password.\n    '''\n    serializer_class = registration_settings.LOGIN_SERIALIZER_CLASS\n    serializer = serializer_class(data=request.data)\n    serializer.is_valid(raise_exception=True)\n    user = serializer.get_authenticated_user()\n\n    if not user:\n        raise BadRequest('Login or password invalid.')\n\n    extra_data = perform_login(request, user)\n\n    return get_ok_response('Login successful', extra_data=extra_data)", "response": "Logs in the user via given login and password."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef logout(request):\n    '''\n    Logs out the user. returns an error if the user is not\n    authenticated.\n    '''\n    user = request.user\n    serializer = LogoutSerializer(data=request.data)\n    serializer.is_valid(raise_exception=True)\n    data = serializer.validated_data\n\n    if should_authenticate_session():\n        auth.logout(request)\n    if should_retrieve_token() and data['revoke_token']:\n        try:\n            user.auth_token.delete()\n        except Token.DoesNotExist:\n            raise BadRequest('Cannot remove non-existent token')\n\n    return get_ok_response('Logout successful')", "response": "Logs out the user. Returns an error if the user is not authenticated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_object_or_404(queryset, *filter_args, **filter_kwargs):\n    try:\n        return _get_object_or_404(queryset, *filter_args, **filter_kwargs)\n    except (TypeError, ValueError, ValidationError):\n        raise Http404", "response": "Same as get_object_or_404 but also raise 404 if the filter_kwargs don t match the required types."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef profile(request):\n    '''\n    Get or set user profile.\n    '''\n    serializer_class = registration_settings.PROFILE_SERIALIZER_CLASS\n    if request.method in ['POST', 'PUT', 'PATCH']:\n        partial = request.method == 'PATCH'\n        serializer = serializer_class(\n            instance=request.user,\n            data=request.data,\n            partial=partial,\n        )\n        serializer.is_valid(raise_exception=True)\n        serializer.save()\n    else:  # request.method == 'GET':\n        serializer = serializer_class(instance=request.user)\n\n    return Response(serializer.data)", "response": "Get or set user profile."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies registration via signature.", "response": "def verify_registration(request):\n    \"\"\"\n    Verify registration via signature.\n    \"\"\"\n    user = process_verify_registration_data(request.data)\n    extra_data = None\n    if registration_settings.REGISTER_VERIFICATION_AUTO_LOGIN:\n        extra_data = perform_login(request, user)\n    return get_ok_response('User verified successfully', extra_data=extra_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_requirements(requirements_filepath):\n    '''\n    Return list of this package requirements via local filepath.\n    '''\n    requirements = []\n    with open(os.path.join(ROOT_DIR, requirements_filepath), 'rt') as f:\n        for line in f:\n            if line.startswith('#'):\n                continue\n            line = line.rstrip()\n            if not line:\n                continue\n            requirements.append(line)\n    return requirements", "response": "Return list of this package requirements via local filepath."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef change_password(request):\n    '''\n    Change the user password.\n    '''\n    serializer = ChangePasswordSerializer(data=request.data,\n                                          context={'request': request})\n    serializer.is_valid(raise_exception=True)\n\n    user = request.user\n    user.set_password(serializer.validated_data['password'])\n    user.save()\n    return get_ok_response('Password changed successfully')", "response": "Change the user s password."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the template configuration data into a single node.", "response": "def parse_template_config(template_config_data):\n    \"\"\"\n    >>> from tests import doctest_utils\n    >>> convert_html_to_text = registration_settings.VERIFICATION_EMAIL_HTML_TO_TEXT_CONVERTER  # noqa: E501\n    >>> parse_template_config({})  # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n    ...\n    ImproperlyConfigured\n    >>> parse_template_config({\n    ...     'subject': 'blah',\n    ... })  # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n    ...\n    ImproperlyConfigured\n    >>> parse_template_config({\n    ...     'subject': 'blah',\n    ...     'body': 'blah',\n    ... })  # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n    ...\n    ImproperlyConfigured\n    >>> doctest_utils.equals(\n    ...     parse_template_config({\n    ...         'subject': 'rest_registration/register/subject.txt',\n    ...         'html_body': 'rest_registration/register/body.html',\n    ...         'text_body': 'rest_registration/register/body.txt',\n    ...     }),\n    ...     EmailTemplateConfig(\n    ...         'rest_registration/register/subject.txt',\n    ...         'rest_registration/register/body.txt',\n    ...         'rest_registration/register/body.html',\n    ...         identity))\n    OK\n    >>> doctest_utils.equals(\n    ...     parse_template_config({\n    ...         'subject': 'rest_registration/register/subject.txt',\n    ...         'html_body': 'rest_registration/register/body.html',\n    ...     }),\n    ...     EmailTemplateConfig(\n    ...         'rest_registration/register/subject.txt',\n    ...         'rest_registration/register/body.html',\n    ...         'rest_registration/register/body.html',\n    ...         convert_html_to_text))\n    OK\n    >>> doctest_utils.equals(\n    ...     parse_template_config({\n    ...         'subject': 'rest_registration/register/subject.txt',\n    ...         'text_body': 'rest_registration/register/body.txt',\n    ...     }),\n    ...     EmailTemplateConfig(\n    ...         'rest_registration/register/subject.txt',\n    ...         'rest_registration/register/body.txt', None,\n    ...         identity))\n    OK\n    >>> doctest_utils.equals(\n    ...     parse_template_config({\n    ...         'subject': 'rest_registration/register/subject.txt',\n    ...         'body': 'rest_registration/register/body.txt',\n    ...     }),\n    ...     EmailTemplateConfig(\n    ...         'rest_registration/register/subject.txt',\n    ...         'rest_registration/register/body.txt', None,\n    ...         identity))\n    OK\n    >>> doctest_utils.equals(\n    ...     parse_template_config({\n    ...         'subject': 'rest_registration/register/subject.txt',\n    ...         'body': 'rest_registration/register/body.html',\n    ...         'is_html': True,\n    ...     }),\n    ...     EmailTemplateConfig(\n    ...         'rest_registration/register/subject.txt',\n    ...         'rest_registration/register/body.html',\n    ...         'rest_registration/register/body.html',\n    ...         convert_html_to_text))\n    OK\n    \"\"\"\n    try:\n        subject_template_name = template_config_data['subject']\n    except KeyError:\n        raise ImproperlyConfigured(\"No 'subject' key found\")\n    body_template_name = template_config_data.get('body')\n    text_body_template_name = template_config_data.get('text_body')\n    html_body_template_name = template_config_data.get('html_body')\n    is_html_body = template_config_data.get('is_html')\n    convert_html_to_text = registration_settings.VERIFICATION_EMAIL_HTML_TO_TEXT_CONVERTER  # noqa: E501\n\n    if html_body_template_name and text_body_template_name:\n        config = EmailTemplateConfig(\n            subject_template_name=subject_template_name,\n            text_body_template_name=text_body_template_name,\n            html_body_template_name=html_body_template_name,\n            text_body_processor=identity,\n        )\n    elif html_body_template_name:\n        config = EmailTemplateConfig(\n            subject_template_name=subject_template_name,\n            text_body_template_name=html_body_template_name,\n            html_body_template_name=html_body_template_name,\n            text_body_processor=convert_html_to_text,\n        )\n    elif text_body_template_name:\n        config = EmailTemplateConfig(\n            subject_template_name=subject_template_name,\n            text_body_template_name=text_body_template_name,\n            html_body_template_name=None,\n            text_body_processor=identity,\n        )\n    elif body_template_name:\n        if is_html_body:\n            config = EmailTemplateConfig(\n                subject_template_name=subject_template_name,\n                text_body_template_name=body_template_name,\n                html_body_template_name=body_template_name,\n                text_body_processor=convert_html_to_text,\n            )\n        else:\n            config = EmailTemplateConfig(\n                subject_template_name=subject_template_name,\n                text_body_template_name=body_template_name,\n                html_body_template_name=None,\n                text_body_processor=identity,\n            )\n    else:\n        raise ImproperlyConfigured(\n            'Could not parse template config data: {template_config_data}'.format(  # noqa: E501\n                template_config_data=template_config_data))\n\n    _validate_template_name_existence(config.subject_template_name)\n    _validate_template_name_existence(config.text_body_template_name)\n\n    if config.html_body_template_name:\n        _validate_template_name_existence(config.html_body_template_name)\n\n    assert callable(config.text_body_processor)\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend email with reset password link.", "response": "def send_reset_password_link(request):\n    '''\n    Send email with reset password link.\n    '''\n    if not registration_settings.RESET_PASSWORD_VERIFICATION_ENABLED:\n        raise Http404()\n    serializer = SendResetPasswordLinkSerializer(data=request.data)\n    serializer.is_valid(raise_exception=True)\n    login = serializer.validated_data['login']\n\n    user = None\n    for login_field in get_login_fields():\n        user = get_user_by_lookup_dict(\n            {login_field: login}, default=None, require_verified=False)\n        if user:\n            break\n\n    if not user:\n        raise UserNotFound()\n\n    signer = ResetPasswordSigner({\n        'user_id': user.pk,\n    }, request=request)\n\n    template_config = (\n        registration_settings.RESET_PASSWORD_VERIFICATION_EMAIL_TEMPLATES)\n    send_verification_notification(user, signer, template_config)\n\n    return get_ok_response('Reset link sent')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_html_to_text(value, preserve_urls=False):\n    s = MLStripper(preserve_urls=preserve_urls)\n    s.feed(value)\n    s.close()\n    return s.get_data()", "response": "r Converts a single HTML element to text."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a {'x','y' and returns the necessary axis options for the given configuration.", "response": "def _get_ticks(data, xy, ticks, ticklabels):\n    \"\"\"Gets a {'x','y'}, a number of ticks and ticks labels, and returns the\n    necessary axis options for the given configuration.\n    \"\"\"\n    axis_options = []\n    pgfplots_ticks = []\n    pgfplots_ticklabels = []\n    is_label_required = False\n    for tick, ticklabel in zip(ticks, ticklabels):\n        pgfplots_ticks.append(tick)\n        # store the label anyway\n        label = ticklabel.get_text()\n        if ticklabel.get_visible():\n            label = mpl_backend_pgf.common_texification(label)\n            pgfplots_ticklabels.append(label)\n        else:\n            is_label_required = True\n        # Check if the label is necessary. If one of the labels is, then all of them\n        # must appear in the TikZ plot.\n        if label:\n            try:\n                label_float = float(label.replace(u\"\\N{MINUS SIGN}\", \"-\"))\n                is_label_required = is_label_required or (label and label_float != tick)\n            except ValueError:\n                is_label_required = True\n\n    # Leave the ticks to PGFPlots if not in STRICT mode and if there are no explicit\n    # labels.\n    if data[\"strict\"] or is_label_required:\n        if pgfplots_ticks:\n            ff = data[\"float format\"]\n            axis_options.append(\n                \"{}tick={{{}}}\".format(\n                    xy, \",\".join([ff.format(el) for el in pgfplots_ticks])\n                )\n            )\n        else:\n            val = \"{}\" if \"minor\" in xy else \"\\\\empty\"\n            axis_options.append(\"{}tick={}\".format(xy, val))\n\n        if is_label_required:\n            axis_options.append(\n                \"{}ticklabels={{{}}}\".format(xy, \",\".join(pgfplots_ticklabels))\n            )\n    return axis_options"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the object is a colorbar.", "response": "def _is_colorbar_heuristic(obj):\n    \"\"\"Find out if the object is in fact a color bar.\n    \"\"\"\n    # TODO come up with something more accurate here\n    # Might help:\n    # TODO Are the colorbars exactly the l.collections.PolyCollection's?\n    try:\n        aspect = float(obj.get_aspect())\n    except ValueError:\n        # e.g., aspect == 'equal'\n        return False\n\n    # Assume that something is a colorbar if and only if the ratio is above 5.0\n    # and there are no ticks on the corresponding axis. This isn't always true,\n    # though: The ratio of a color can be freely adjusted by the aspect\n    # keyword, e.g.,\n    #\n    #    plt.colorbar(im, aspect=5)\n    #\n    limit_ratio = 5.0\n\n    return (aspect >= limit_ratio and len(obj.get_xticks()) == 0) or (\n        aspect <= 1.0 / limit_ratio and len(obj.get_yticks()) == 0\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _mpl_cmap2pgf_cmap(cmap, data):\n    if isinstance(cmap, mpl.colors.LinearSegmentedColormap):\n        return _handle_linear_segmented_color_map(cmap, data)\n\n    assert isinstance(\n        cmap, mpl.colors.ListedColormap\n    ), \"Only LinearSegmentedColormap and ListedColormap are supported\"\n    return _handle_listed_color_map(cmap, data)", "response": "Converts a color map as given in matplotlib to a color map as represented in PGFPlots."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nscales the array X such that it contains only integers.", "response": "def _scale_to_int(X, max_val=None):\n    \"\"\"\n    Scales the array X such that it contains only integers.\n    \"\"\"\n\n    if max_val is None:\n        X = X / _gcd_array(X)\n    else:\n        X = X / max(1 / max_val, _gcd_array(X))\n    return [int(entry) for entry in X]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _gcd_array(X):\n    greatest_common_divisor = 0.0\n    for x in X:\n        greatest_common_divisor = _gcd(greatest_common_divisor, x)\n\n    return greatest_common_divisor", "response": "Return the greatest common divisor of all elements in X."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving two data points [X,Y], linearly interpolate those at x.", "response": "def _linear_interpolation(x, X, Y):\n    \"\"\"Given two data points [X,Y], linearly interpolate those at x.\n    \"\"\"\n    return (Y[1] * (x - X[0]) + Y[0] * (X[1] - x)) / (X[1] - X[0])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the colorbar associated with an axis.", "response": "def _find_associated_colorbar(obj):\n    \"\"\"A rather poor way of telling whether an axis has a colorbar associated:\n    Check the next axis environment, and see if it is de facto a color bar;\n    if yes, return the color bar object.\n    \"\"\"\n    for child in obj.get_children():\n        try:\n            cbar = child.colorbar\n        except AttributeError:\n            continue\n        if cbar is not None:  # really necessary?\n            # if fetch was successful, cbar contains\n            # (reference to colorbar,\n            #   reference to axis containing colorbar)\n            return cbar\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a filename and relative path to the next available file in the next available file.", "response": "def new_filename(data, file_kind, ext):\n    \"\"\"Returns an available filename.\n\n    :param file_kind: Name under which numbering is recorded, such as 'img' or\n                      'table'.\n    :type file_kind: str\n\n    :param ext: Filename extension.\n    :type ext: str\n\n    :returns: (filename, rel_filepath) where filename is a path in the\n              filesystem and rel_filepath is the path to be used in the tex\n              code.\n    \"\"\"\n\n    nb_key = file_kind + \"number\"\n    if nb_key not in data.keys():\n        data[nb_key] = -1\n\n    if not data[\"override externals\"]:\n        # Make sure not to overwrite anything.\n        file_exists = True\n        while file_exists:\n            data[nb_key] = data[nb_key] + 1\n            filename, name = _gen_filename(data, nb_key, ext)\n            file_exists = os.path.isfile(filename)\n    else:\n        data[nb_key] = data[nb_key] + 1\n        filename, name = _gen_filename(data, nb_key, ext)\n\n    if data[\"rel data path\"]:\n        rel_filepath = posixpath.join(data[\"rel data path\"], name)\n    else:\n        rel_filepath = name\n\n    return filename, rel_filepath"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_path(data, path, draw_options=None, simplify=None):\n    # For some reasons, matplotlib sometimes adds void paths which consist of\n    # only one point and have 0 fill opacity. To not let those clutter the\n    # output TeX file, bail out here.\n    if (\n        len(path.vertices) == 2\n        and all(path.vertices[0] == path.vertices[1])\n        and \"fill opacity=0\" in draw_options\n    ):\n        return data, \"\", None, False\n\n    nodes = []\n    ff = data[\"float format\"]\n    prev = None\n    for vert, code in path.iter_segments(simplify=simplify):\n        # nschloe, Oct 2, 2015:\n        #   The transform call yields warnings and it is unclear why. Perhaps\n        #   the input data is not suitable? Anyhow, this should not happen.\n        #   Comment out for now.\n        # vert = numpy.asarray(\n        #         _transform_to_data_coordinates(obj, [vert[0]], [vert[1]])\n        #         )\n        # For path codes see: http://matplotlib.org/api/path_api.html\n        #\n        # if code == mpl.path.Path.STOP: pass\n        is_area = False\n        if code == mpl.path.Path.MOVETO:\n            nodes.append((\"(axis cs:\" + ff + \",\" + ff + \")\").format(*vert))\n        elif code == mpl.path.Path.LINETO:\n            nodes.append((\"--(axis cs:\" + ff + \",\" + ff + \")\").format(*vert))\n        elif code == mpl.path.Path.CURVE3:\n            # Quadratic Bezier curves aren't natively supported in TikZ, but\n            # can be emulated as cubic Beziers.\n            # From\n            # http://www.latex-community.org/forum/viewtopic.php?t=4424&f=45:\n            # If you really need a quadratic B\u00e9zier curve on the points P0, P1\n            # and P2, then a process called 'degree elevation' yields the cubic\n            # control points (Q0, Q1, Q2 and Q3) as follows:\n            #   CODE: SELECT ALL\n            #   Q0 = P0\n            #   Q1 = 1/3 P0 + 2/3 P1\n            #   Q2 = 2/3 P1 + 1/3 P2\n            #   Q3 = P2\n            #\n            # P0 is the point of the previous step which is needed to compute\n            # Q1.\n            #\n            # Cannot draw quadratic Bezier curves as the beginning of of a path\n            assert prev is not None\n            Q1 = 1.0 / 3.0 * prev + 2.0 / 3.0 * vert[0:2]\n            Q2 = 2.0 / 3.0 * vert[0:2] + 1.0 / 3.0 * vert[2:4]\n            Q3 = vert[2:4]\n            nodes.append(\n                (\n                    \".. controls (axis cs:\"\n                    + ff\n                    + \",\"\n                    + ff\n                    + \") \"\n                    + \"and (axis cs:\"\n                    + ff\n                    + \",\"\n                    + ff\n                    + \") \"\n                    + \".. (axis cs:\"\n                    + ff\n                    + \",\"\n                    + ff\n                    + \")\"\n                ).format(Q1[0], Q1[1], Q2[0], Q2[1], Q3[0], Q3[1])\n            )\n        elif code == mpl.path.Path.CURVE4:\n            # Cubic Bezier curves.\n            nodes.append(\n                (\n                    \".. controls (axis cs:\"\n                    + ff\n                    + \",\"\n                    + ff\n                    + \") \"\n                    + \"and (axis cs:\"\n                    + ff\n                    + \",\"\n                    + ff\n                    + \") \"\n                    + \".. (axis cs:\"\n                    + ff\n                    + \",\"\n                    + ff\n                    + \")\"\n                ).format(*vert)\n            )\n        else:\n            assert code == mpl.path.Path.CLOSEPOLY\n            nodes.append(\"--cycle\")\n            is_area = True\n\n        # Store the previous point for quadratic Beziers.\n        prev = vert[0:2]\n\n    do = \"[{}]\".format(\", \".join(draw_options)) if draw_options else \"\"\n    path_command = \"\\\\path {}\\n{};\\n\".format(do, \"\\n\".join(nodes))\n\n    return data, path_command, draw_options, is_area", "response": "Draw a path from a path object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw_pathcollection(data, obj):\n    content = []\n    # gather data\n    assert obj.get_offsets() is not None\n    labels = [\"x\" + 21 * \" \", \"y\" + 21 * \" \"]\n    dd = obj.get_offsets()\n\n    draw_options = [\"only marks\"]\n    table_options = []\n\n    if obj.get_array() is not None:\n        draw_options.append(\"scatter\")\n        dd = numpy.column_stack([dd, obj.get_array()])\n        labels.append(\"colordata\" + 13 * \" \")\n        draw_options.append(\"scatter src=explicit\")\n        table_options.extend([\"x=x\", \"y=y\", \"meta=colordata\"])\n        ec = None\n        fc = None\n        ls = None\n    else:\n        # gather the draw options\n        try:\n            ec = obj.get_edgecolors()[0]\n        except (TypeError, IndexError):\n            ec = None\n\n        try:\n            fc = obj.get_facecolors()[0]\n        except (TypeError, IndexError):\n            fc = None\n\n        try:\n            ls = obj.get_linestyle()[0]\n        except (TypeError, IndexError):\n            ls = None\n\n    is_contour = len(dd) == 1\n    if is_contour:\n        draw_options = [\"draw=none\"]\n\n    # `only mark` plots don't need linewidth\n    data, extra_draw_options = get_draw_options(data, obj, ec, fc, ls, None)\n    draw_options.extend(extra_draw_options)\n\n    if obj.get_cmap():\n        mycolormap, is_custom_cmap = _mpl_cmap2pgf_cmap(obj.get_cmap(), data)\n        draw_options.append(\"colormap\" + (\"=\" if is_custom_cmap else \"/\") + mycolormap)\n\n    legend_text = get_legend_text(obj)\n    if legend_text is None and has_legend(obj.axes):\n        draw_options.append(\"forget plot\")\n\n    for path in obj.get_paths():\n        if is_contour:\n            dd = path.vertices\n\n        if len(obj.get_sizes()) == len(dd):\n            # See Pgfplots manual, chapter 4.25.\n            # In Pgfplots, \\mark size specifies raddi, in matplotlib circle areas.\n            radii = numpy.sqrt(obj.get_sizes() / numpy.pi)\n            dd = numpy.column_stack([dd, radii])\n            labels.append(\"sizedata\" + 14 * \" \")\n            draw_options.extend(\n                [\n                    \"visualization depends on=\"\n                    \"{\\\\thisrow{sizedata} \\\\as\\\\perpointmarksize}\",\n                    \"scatter/@pre marker code/.append style=\"\n                    \"{/tikz/mark size=\\\\perpointmarksize}\",\n                ]\n            )\n\n        do = \" [{}]\".format(\", \".join(draw_options)) if draw_options else \"\"\n        content.append(\"\\\\addplot{}\\n\".format(do))\n\n        to = \" [{}]\".format(\", \".join(table_options)) if table_options else \"\"\n        content.append(\"table{}{{%\\n\".format(to))\n\n        content.append((\" \".join(labels)).strip() + \"\\n\")\n        ff = data[\"float format\"]\n        fmt = (\" \".join(dd.shape[1] * [ff])) + \"\\n\"\n        for d in dd:\n            content.append(fmt.format(*tuple(d)))\n        content.append(\"};\\n\")\n\n    if legend_text is not None:\n        content.append(\"\\\\addlegendentry{{{}}}\\n\".format(legend_text))\n\n    return data, content", "response": "Returns a PGFPlots code for a number of patch objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_draw_options(data, obj, ec, fc, style, width):\n    draw_options = []\n\n    if ec is not None:\n        data, col, ec_rgba = color.mpl_color2xcolor(data, ec)\n        if ec_rgba[3] != 0.0:\n            # Don't draw if it's invisible anyways.\n            draw_options.append(\"draw={}\".format(col))\n\n    if fc is not None:\n        data, col, fc_rgba = color.mpl_color2xcolor(data, fc)\n        if fc_rgba[3] != 0.0:\n            # Don't draw if it's invisible anyways.\n            draw_options.append(\"fill={}\".format(col))\n\n    # handle transparency\n    ff = data[\"float format\"]\n    if (\n        ec is not None\n        and fc is not None\n        and ec_rgba[3] != 1.0\n        and ec_rgba[3] == fc_rgba[3]\n    ):\n        draw_options.append((\"opacity=\" + ff).format(ec[3]))\n    else:\n        if ec is not None and ec_rgba[3] != 1.0:\n            draw_options.append((\"draw opacity=\" + ff).format(ec_rgba[3]))\n        if fc is not None and fc_rgba[3] != 1.0:\n            draw_options.append((\"fill opacity=\" + ff).format(fc_rgba[3]))\n\n    if width is not None:\n        w = mpl_linewidth2pgfp_linewidth(data, width)\n        if w:\n            draw_options.append(w)\n\n    if style is not None:\n        ls = mpl_linestyle2pgfplots_linestyle(style)\n        if ls is not None and ls != \"solid\":\n            draw_options.append(ls)\n\n    return data, draw_options", "response": "Get the draw options for a given object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mpl_linestyle2pgfplots_linestyle(line_style, line=None):\n    # linestyle is a string or dash tuple. Legal string values are\n    # solid|dashed|dashdot|dotted.  The dash tuple is (offset, onoffseq) where onoffseq\n    # is an even length tuple of on and off ink in points.\n    #\n    # solid: [(None, None), (None, None), ..., (None, None)]\n    # dashed: (0, (6.0, 6.0))\n    # dotted: (0, (1.0, 3.0))\n    # dashdot: (0, (3.0, 5.0, 1.0, 5.0))\n    if isinstance(line_style, tuple):\n        if line_style[0] is None:\n            return None\n\n        if len(line_style[1]) == 2:\n            return \"dash pattern=on {}pt off {}pt\".format(*line_style[1])\n\n        assert len(line_style[1]) == 4\n        return \"dash pattern=on {}pt off {}pt on {}pt off {}pt\".format(*line_style[1])\n\n    if isinstance(line, mpl.lines.Line2D) and line.is_dashed():\n        # see matplotlib.lines.Line2D.set_dashes\n\n        # get defaults\n        default_dashOffset, default_dashSeq = mpl.lines._get_dash_pattern(line_style)\n\n        # get dash format of line under test\n        dashSeq = line._us_dashSeq\n        dashOffset = line._us_dashOffset\n\n        lst = list()\n        if dashSeq != default_dashSeq:\n            # generate own dash sequence\n            format_string = \" \".join(len(dashSeq) // 2 * [\"on {}pt off {}pt\"])\n            lst.append(\"dash pattern=\" + format_string.format(*dashSeq))\n\n        if dashOffset != default_dashOffset:\n            lst.append(\"dash phase={}pt\".format(dashOffset))\n\n        if len(lst) > 0:\n            return \", \".join(lst)\n\n    return {\n        \"\": None,\n        \"None\": None,\n        \"none\": None,  # happens when using plt.boxplot()\n        \"-\": \"solid\",\n        \"solid\": \"solid\",\n        \":\": \"dotted\",\n        \"--\": \"dashed\",\n        \"-.\": \"dash pattern=on 1pt off 3pt on 3pt off 3pt\",\n    }[line_style]", "response": "Translates a line style of matplotlib to PGFPlots line style in PGFPlots."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the code for an analytical a rendering of the object.", "response": "def draw_quadmesh(data, obj):\n    \"\"\"Returns the PGFPlots code for an graphics environment holding a\n       rendering of the object.\n    \"\"\"\n    content = []\n\n    # Generate file name for current object\n    filename, rel_filepath = files.new_filename(data, \"img\", \".png\")\n\n    # Get the dpi for rendering and store the original dpi of the figure\n    dpi = data[\"dpi\"]\n    fig_dpi = obj.figure.get_dpi()\n    obj.figure.set_dpi(dpi)\n\n    # Render the object and save as png file\n    from matplotlib.backends.backend_agg import RendererAgg\n\n    cbox = obj.get_clip_box()\n    width = int(round(cbox.extents[2]))\n    height = int(round(cbox.extents[3]))\n    ren = RendererAgg(width, height, dpi)\n    obj.draw(ren)\n\n    # Generate a image from the render buffer\n    image = Image.frombuffer(\n        \"RGBA\", ren.get_canvas_width_height(), ren.buffer_rgba(), \"raw\", \"RGBA\", 0, 1\n    )\n    # Crop the image to the actual content (removing the the regions otherwise\n    # used for axes, etc.)\n    # 'image.crop' expects the crop box to specify the left, upper, right, and\n    # lower pixel. 'cbox.extents' gives the left, lower, right, and upper\n    # pixel.\n    box = (\n        int(round(cbox.extents[0])),\n        0,\n        int(round(cbox.extents[2])),\n        int(round(cbox.extents[3] - cbox.extents[1])),\n    )\n    cropped = image.crop(box)\n    cropped.save(filename)\n\n    # Restore the original dpi of the figure\n    obj.figure.set_dpi(fig_dpi)\n\n    # write the corresponding information to the TikZ file\n    extent = obj.axes.get_xlim() + obj.axes.get_ylim()\n\n    # Explicitly use \\pgfimage as includegrapics command, as the default\n    # \\includegraphics fails unexpectedly in some cases\n    ff = data[\"float format\"]\n    content.append(\n        (\n            \"\\\\addplot graphics [includegraphics cmd=\\\\pgfimage,\"\n            \"xmin=\" + ff + \", xmax=\" + ff + \", \"\n            \"ymin=\" + ff + \", ymax=\" + ff + \"] {{{}}};\\n\"\n        ).format(*(extent + (rel_filepath,)))\n    )\n\n    return data, content"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mpl_color2xcolor(data, matplotlib_color):\n    # Convert it to RGBA.\n    my_col = numpy.array(mpl.colors.ColorConverter().to_rgba(matplotlib_color))\n\n    # If the alpha channel is exactly 0, then the color is really 'none'\n    # regardless of the RGB channels.\n    if my_col[-1] == 0.0:\n        return data, \"none\", my_col\n\n    xcol = None\n    # RGB values (as taken from xcolor.dtx):\n    available_colors = {\n        # List white first such that for gray values, the combination\n        # white!<x>!black is preferred over, e.g., gray!<y>!black. Note that\n        # the order of the dictionary is respected from Python 3.6 on.\n        \"white\": numpy.array([1, 1, 1]),\n        \"lightgray\": numpy.array([0.75, 0.75, 0.75]),\n        \"gray\": numpy.array([0.5, 0.5, 0.5]),\n        \"darkgray\": numpy.array([0.25, 0.25, 0.25]),\n        \"black\": numpy.array([0, 0, 0]),\n        #\n        \"red\": numpy.array([1, 0, 0]),\n        \"green\": numpy.array([0, 1, 0]),\n        \"blue\": numpy.array([0, 0, 1]),\n        \"brown\": numpy.array([0.75, 0.5, 0.25]),\n        \"lime\": numpy.array([0.75, 1, 0]),\n        \"orange\": numpy.array([1, 0.5, 0]),\n        \"pink\": numpy.array([1, 0.75, 0.75]),\n        \"purple\": numpy.array([0.75, 0, 0.25]),\n        \"teal\": numpy.array([0, 0.5, 0.5]),\n        \"violet\": numpy.array([0.5, 0, 0.5]),\n        # The colors cyan, magenta, yellow, and olive are also\n        # predefined by xcolor, but their RGB approximation of the\n        # native CMYK values is not very good. Don't use them here.\n    }\n\n    available_colors.update(data[\"custom colors\"])\n\n    # Check if it exactly matches any of the colors already available.\n    # This case is actually treated below (alpha==1), but that loop\n    # may pick up combinations with black before finding the exact\n    # match. Hence, first check all colors.\n    for name, rgb in available_colors.items():\n        if all(my_col[:3] == rgb):\n            xcol = name\n            return data, xcol, my_col\n\n    # Check if my_col is a multiple of a predefined color and 'black'.\n    for name, rgb in available_colors.items():\n        if name == \"black\":\n            continue\n\n        if rgb[0] != 0.0:\n            alpha = my_col[0] / rgb[0]\n        elif rgb[1] != 0.0:\n            alpha = my_col[1] / rgb[1]\n        else:\n            assert rgb[2] != 0.0\n            alpha = my_col[2] / rgb[2]\n\n        # The cases 0.0 (my_col == black) and 1.0 (my_col == rgb) are\n        # already accounted for by checking in available_colors above.\n        if all(my_col[:3] == alpha * rgb) and 0.0 < alpha < 1.0:\n            xcol = name + (\"!{}!black\".format(alpha * 100))\n            return data, xcol, my_col\n\n    # Lookup failed, add it to the custom list.\n    xcol = \"color\" + str(len(data[\"custom colors\"]))\n    data[\"custom colors\"][xcol] = my_col[:3]\n\n    return data, xcol, my_col", "response": "Translates a matplotlib color specification into a proper LaTeX xcolor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw_patch(data, obj):\n    # Gather the draw options.\n    data, draw_options = mypath.get_draw_options(\n        data,\n        obj,\n        obj.get_edgecolor(),\n        obj.get_facecolor(),\n        obj.get_linestyle(),\n        obj.get_linewidth(),\n    )\n\n    if isinstance(obj, mpl.patches.Rectangle):\n        # rectangle specialization\n        return _draw_rectangle(data, obj, draw_options)\n    elif isinstance(obj, mpl.patches.Ellipse):\n        # ellipse specialization\n        return _draw_ellipse(data, obj, draw_options)\n\n    # regular patch\n    data, path_command, _, _ = mypath.draw_path(\n        data, obj.get_path(), draw_options=draw_options\n    )\n    return data, path_command", "response": "Draw a single patch from the data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of PGFPlots code for a number of patch objects.", "response": "def draw_patchcollection(data, obj):\n    \"\"\"Returns PGFPlots code for a number of patch objects.\n    \"\"\"\n    content = []\n    # Gather the draw options.\n    try:\n        ec = obj.get_edgecolor()[0]\n    except IndexError:\n        ec = None\n\n    try:\n        fc = obj.get_facecolor()[0]\n    except IndexError:\n        fc = None\n\n    try:\n        ls = obj.get_linestyle()[0]\n    except IndexError:\n        ls = None\n\n    try:\n        w = obj.get_linewidth()[0]\n    except IndexError:\n        w = None\n\n    data, draw_options = mypath.get_draw_options(data, obj, ec, fc, ls, w)\n\n    paths = obj.get_paths()\n    for path in paths:\n        data, cont, draw_options, is_area = mypath.draw_path(\n            data, path, draw_options=draw_options\n        )\n        content.append(cont)\n\n    if _is_in_legend(obj):\n        # Unfortunately, patch legend entries need \\addlegendimage in Pgfplots.\n        tpe = \"area legend\" if is_area else \"line legend\"\n        do = \", \".join([tpe] + draw_options) if draw_options else \"\"\n        content += [\n            \"\\\\addlegendimage{{{}}}\\n\".format(do),\n            \"\\\\addlegendentry{{{}}}\\n\\n\".format(obj.get_label()),\n        ]\n    else:\n        content.append(\"\\n\")\n\n    return data, content"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _draw_rectangle(data, obj, draw_options):\n    # Objects with labels are plot objects (from bar charts, etc).  Even those without\n    # labels explicitly set have a label of \"_nolegend_\".  Everything else should be\n    # skipped because they likely correspong to axis/legend objects which are handled by\n    # PGFPlots\n    label = obj.get_label()\n    if label == \"\":\n        return data, []\n\n    # Get actual label, bar charts by default only give rectangles labels of\n    # \"_nolegend_\". See <https://stackoverflow.com/q/35881290/353337>.\n    handles, labels = obj.axes.get_legend_handles_labels()\n    labelsFound = [\n        label for h, label in zip(handles, labels) if obj in h.get_children()\n    ]\n    if len(labelsFound) == 1:\n        label = labelsFound[0]\n\n    left_lower_x = obj.get_x()\n    left_lower_y = obj.get_y()\n    ff = data[\"float format\"]\n    cont = (\n        \"\\\\draw[{}] (axis cs:\" + ff + \",\" + ff + \") \"\n        \"rectangle (axis cs:\" + ff + \",\" + ff + \");\\n\"\n    ).format(\n        \",\".join(draw_options),\n        left_lower_x,\n        left_lower_y,\n        left_lower_x + obj.get_width(),\n        left_lower_y + obj.get_height(),\n    )\n\n    if label != \"_nolegend_\" and label not in data[\"rectangle_legends\"]:\n        data[\"rectangle_legends\"].add(label)\n        cont += \"\\\\addlegendimage{{ybar,ybar legend,{}}};\\n\".format(\n            \",\".join(draw_options)\n        )\n        cont += \"\\\\addlegendentry{{{}}}\\n\\n\".format(label)\n    return data, cont", "response": "Return the PGFPlots code for rectangles."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the PGFPlots code for the ellipses.", "response": "def _draw_ellipse(data, obj, draw_options):\n    \"\"\"Return the PGFPlots code for ellipses.\n    \"\"\"\n    if isinstance(obj, mpl.patches.Circle):\n        # circle specialization\n        return _draw_circle(data, obj, draw_options)\n    x, y = obj.center\n    ff = data[\"float format\"]\n\n    if obj.angle != 0:\n        fmt = \"rotate around={{\" + ff + \":(axis cs:\" + ff + \",\" + ff + \")}}\"\n        draw_options.append(fmt.format(obj.angle, x, y))\n\n    cont = (\n        \"\\\\draw[{}] (axis cs:\"\n        + ff\n        + \",\"\n        + ff\n        + \") ellipse (\"\n        + ff\n        + \" and \"\n        + ff\n        + \");\\n\"\n    ).format(\",\".join(draw_options), x, y, 0.5 * obj.width, 0.5 * obj.height)\n    return data, cont"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _draw_circle(data, obj, draw_options):\n    x, y = obj.center\n    ff = data[\"float format\"]\n    cont = (\"\\\\draw[{}] (axis cs:\" + ff + \",\" + ff + \") circle (\" + ff + \");\\n\").format(\n        \",\".join(draw_options), x, y, obj.get_radius()\n    )\n    return data, cont", "response": "Return the PGFPlots code for circles."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef draw_image(data, obj):\n    content = []\n\n    filename, rel_filepath = files.new_filename(data, \"img\", \".png\")\n\n    # store the image as in a file\n    img_array = obj.get_array()\n\n    dims = img_array.shape\n    if len(dims) == 2:  # the values are given as one real number: look at cmap\n        clims = obj.get_clim()\n        mpl.pyplot.imsave(\n            fname=filename,\n            arr=img_array,\n            cmap=obj.get_cmap(),\n            vmin=clims[0],\n            vmax=clims[1],\n            origin=obj.origin,\n        )\n    else:\n        # RGB (+alpha) information at each point\n        assert len(dims) == 3 and dims[2] in [3, 4]\n        # convert to PIL image\n        if obj.origin == \"lower\":\n            img_array = numpy.flipud(img_array)\n\n        # Convert mpl image to PIL\n        image = PIL.Image.fromarray(numpy.uint8(img_array * 255))\n\n        # If the input image is PIL:\n        # image = PIL.Image.fromarray(img_array)\n\n        image.save(filename, origin=obj.origin)\n\n    # write the corresponding information to the TikZ file\n    extent = obj.get_extent()\n\n    # the format specification will only accept tuples\n    if not isinstance(extent, tuple):\n        extent = tuple(extent)\n\n    # Explicitly use \\pgfimage as includegrapics command, as the default\n    # \\includegraphics fails unexpectedly in some cases\n    ff = data[\"float format\"]\n    content.append(\n        (\n            \"\\\\addplot graphics [includegraphics cmd=\\\\pgfimage,\"\n            \"xmin=\" + ff + \", xmax=\" + ff + \", \"\n            \"ymin=\" + ff + \", ymax=\" + ff + \"] {{{}}};\\n\"\n        ).format(*(extent + (rel_filepath,)))\n    )\n\n    return data, content", "response": "Returns the PGFPlots code for an image environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if line is in legend.", "response": "def get_legend_text(obj):\n    \"\"\"Check if line is in legend.\n    \"\"\"\n    leg = obj.axes.get_legend()\n    if leg is None:\n        return None\n\n    keys = [l.get_label() for l in leg.legendHandles if l is not None]\n    values = [l.get_text() for l in leg.texts]\n\n    label = obj.get_label()\n    d = dict(zip(keys, values))\n    if label in d:\n        return d[label]\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform_to_data_coordinates(obj, xdata, ydata):\n    if obj.axes is not None and obj.get_transform() != obj.axes.transData:\n        points = numpy.array([xdata, ydata]).T\n        transform = matplotlib.transforms.composite_transform_factory(\n            obj.get_transform(), obj.axes.transData.inverted()\n        )\n        return transform.transform(points).T\n    return xdata, ydata", "response": "Transform the data coordinates to the data coordinates of the axes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_tikz_code(\n    figure=\"gcf\",\n    filepath=None,\n    figurewidth=None,\n    figureheight=None,\n    textsize=10.0,\n    tex_relative_path_to_data=None,\n    externalize_tables=False,\n    override_externals=False,\n    strict=False,\n    wrap=True,\n    add_axis_environment=True,\n    extra_axis_parameters=None,\n    extra_tikzpicture_parameters=None,\n    dpi=None,\n    show_info=False,\n    include_disclaimer=True,\n    standalone=False,\n    float_format=\"{:.15g}\",\n    table_row_sep=\"\\n\",\n):\n    \"\"\"Main function. Here, the recursion into the image starts and the\n    contents are picked up. The actual file gets written in this routine.\n\n    :param figure: either a Figure object or 'gcf' (default).\n\n    :param figurewidth: If not ``None``, this will be used as figure width\n                        within the TikZ/PGFPlots output. If ``figureheight``\n                        is not given, ``matplotlib2tikz`` will try to preserve\n                        the original width/height ratio.\n                        Note that ``figurewidth`` can be a string literal,\n                        such as ``'\\\\figurewidth'``.\n    :type figurewidth: str\n\n    :param figureheight: If not ``None``, this will be used as figure height\n                         within the TikZ/PGFPlots output. If ``figurewidth`` is\n                         not given, ``matplotlib2tikz`` will try to preserve\n                         the original width/height ratio.  Note that\n                         ``figurewidth`` can be a string literal, such as\n                         ``'\\\\figureheight'``.\n    :type figureheight: str\n\n    :param textsize: The text size (in pt) that the target latex document is\n                     using.  Default is 10.0.\n    :type textsize: float\n\n    :param tex_relative_path_to_data: In some cases, the TikZ file will have to\n                                      refer to another file, e.g., a PNG for\n                                      image plots. When ``\\\\input`` into a\n                                      regular LaTeX document, the additional\n                                      file is looked for in a folder relative\n                                      to the LaTeX file, not the TikZ file.\n                                      This arguments optionally sets the\n                                      relative path from the LaTeX file to the\n                                      data.\n    :type tex_relative_path_to_data: str\n\n    :param externalize_tables: Whether or not to externalize plot data tables\n                               into tsv files.\n    :type externalize_tables: bool\n\n    :param override_externals: Whether or not to override existing external\n                               files (such as tsv or images) with conflicting\n                               names (the alternative is to choose other\n                               names).\n    :type override_externals: bool\n\n    :param strict: Whether or not to strictly stick to matplotlib's appearance.\n                   This influences, for example, whether tick marks are set\n                   exactly as in the matplotlib plot, or if TikZ/PGFPlots\n                   can decide where to put the ticks.\n    :type strict: bool\n\n    :param wrap: Whether ``'\\\\begin{tikzpicture}'`` and\n                 ``'\\\\end{tikzpicture}'`` will be written. One might need to\n                 provide custom arguments to the environment (eg. scale= etc.).\n                 Default is ``True``.\n    :type wrap: bool\n\n    :param add_axis_environment: Whether ``'\\\\begin{axis}[...]'`` and\n                                 ``'\\\\end{axis}'`` will be written. One needs to\n                                 set the environment in the document. If ``False``\n                                 additionally sets ``wrap=False``. Default is ``True``.\n    :type add_axis_environment: bool\n\n    :param extra_axis_parameters: Extra axis options to be passed (as a list or set)\n                                  to pgfplots. Default is ``None``.\n    :type extra_axis_parameters: a list or set of strings for the pfgplots axes.\n\n    :param extra_tikzpicture_parameters: Extra tikzpicture options to be passed\n                                         (as a set) to pgfplots.\n\n    :type extra_tikzpicture_parameters: a set of strings for the pfgplots\n                                        tikzpicture.\n\n    :param dpi: The resolution in dots per inch of the rendered image in case\n                of QuadMesh plots. If ``None`` it will default to the value\n                ``savefig.dpi`` from matplotlib.rcParams. Default is ``None``.\n    :type dpi: int\n\n    :param show_info: Show extra info on the command line. Default is ``False``.\n    :type show_info: bool\n\n    :param include_disclaimer: Include matplotlib2tikz disclaimer in the output.\n                               Set ``False`` to make tests reproducible.\n                               Default is ``True``.\n    :type include_disclaimer: bool\n\n    :param standalone: Include wrapper code for a standalone LaTeX file.\n    :type standalone: bool\n\n    :param float_format: Format for float entities. Default is ```\"{:.15g}\"```.\n    :type float_format: str\n\n    :param table_row_sep: Row separator for table data. Default is ```\"\\\\n\"```.\n    :type table_row_sep: str\n\n    :returns: None\n\n    The following optional attributes of matplotlib's objects are recognized\n    and handled:\n\n     - axes.Axes._matplotlib2tikz_anchors\n       This attribute can be set to a list of ((x,y), anchor_name) tuples.\n       Invisible nodes at the respective location will be created which  can be\n       referenced from outside the axis environment.\n    \"\"\"\n    # not as default value because gcf() would be evaluated at import time\n    if figure == \"gcf\":\n        figure = plt.gcf()\n    data = {}\n    data[\"fwidth\"] = figurewidth\n    data[\"fheight\"] = figureheight\n    data[\"rel data path\"] = tex_relative_path_to_data\n    data[\"externalize tables\"] = externalize_tables\n    data[\"override externals\"] = override_externals\n\n    if filepath:\n        data[\"output dir\"] = os.path.dirname(filepath)\n    else:\n        directory = tempfile.mkdtemp()\n        data[\"output dir\"] = directory\n\n    data[\"base name\"] = (\n        os.path.splitext(os.path.basename(filepath))[0] if filepath else \"tmp\"\n    )\n    data[\"strict\"] = strict\n    data[\"tikz libs\"] = set()\n    data[\"pgfplots libs\"] = set()\n    data[\"font size\"] = textsize\n    data[\"custom colors\"] = {}\n    data[\"legend colors\"] = []\n    data[\"extra tikzpicture parameters\"] = extra_tikzpicture_parameters\n    data[\"add axis environment\"] = add_axis_environment\n    data[\"show_info\"] = show_info\n    # rectangle_legends is used to keep track of which rectangles have already\n    # had \\addlegendimage added. There should be only one \\addlegenimage per\n    # bar chart data series.\n    data[\"rectangle_legends\"] = set()\n    if extra_axis_parameters:\n        data[\"extra axis options [base]\"] = set(extra_axis_parameters).copy()\n    else:\n        data[\"extra axis options [base]\"] = set()\n\n    if dpi:\n        data[\"dpi\"] = dpi\n    else:\n        savefig_dpi = mpl.rcParams[\"savefig.dpi\"]\n        data[\"dpi\"] = (\n            savefig_dpi if isinstance(savefig_dpi, int) else mpl.rcParams[\"figure.dpi\"]\n        )\n\n    data[\"float format\"] = float_format\n    data[\"table_row_sep\"] = table_row_sep\n\n    # print message about necessary pgfplot libs to command line\n    if show_info:\n        _print_pgfplot_libs_message(data)\n\n    # gather the file content\n    data, content = _recurse(data, figure)\n\n    # Check if there is still an open groupplot environment. This occurs if not\n    # all of the group plot slots are used.\n    if \"is_in_groupplot_env\" in data and data[\"is_in_groupplot_env\"]:\n        content.extend(\"\\\\end{groupplot}\\n\\n\")\n\n    # write disclaimer to the file header\n    code = \"\"\"\"\"\"\n\n    if include_disclaimer:\n        disclaimer = \"This file was created by matplotlib2tikz v{}.\".format(__version__)\n        code += _tex_comment(disclaimer)\n\n    # write the contents\n    if wrap and add_axis_environment:\n        code += \"\\\\begin{tikzpicture}\\n\\n\"\n        if extra_tikzpicture_parameters:\n            code += \",\\n\".join(data[\"extra tikzpicture parameters\"])\n            code += \"\\n\"\n\n    coldefs = _get_color_definitions(data)\n    if coldefs:\n        code += \"\\n\".join(coldefs)\n        code += \"\\n\\n\"\n\n    code += \"\".join(content)\n\n    if wrap and add_axis_environment:\n        code += \"\\\\end{tikzpicture}\"\n\n    if standalone:\n        # create a latex wrapper for the tikz\n        # <https://tex.stackexchange.com/a/361070/13262>\n        code = \"\"\"\\\\documentclass{{standalone}}\n\\\\usepackage[utf8]{{inputenc}}\n\\\\usepackage{{pgfplots}}\n\\\\usepgfplotslibrary{{groupplots}}\n\\\\usepgfplotslibrary{{dateplot}}\n\\\\pgfplotsset{{compat=newest}}\n\\\\DeclareUnicodeCharacter{{2212}}{{\u2212}}\n\\\\begin{{document}}\n{}\n\\\\end{{document}}\"\"\".format(\n            code\n        )\n\n    return code", "response": "This function is used to get the TikZ code from a TikZ file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(filepath, *args, encoding=None, **kwargs):\n    code = get_tikz_code(*args, filepath=filepath, **kwargs)\n    file_handle = codecs.open(filepath, \"w\", encoding)\n    try:\n        file_handle.write(code)\n    except UnicodeEncodeError:\n        # We're probably using Python 2, so treat unicode explicitly\n        file_handle.write(six.text_type(code).encode(\"utf-8\"))\n    file_handle.close()\n    return", "response": "Same as get_tikz_code but actually saves the code to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the list of custom color definitions for the TikZ file.", "response": "def _get_color_definitions(data):\n    \"\"\"Returns the list of custom color definitions for the TikZ file.\n    \"\"\"\n    definitions = []\n    fmt = \"\\\\definecolor{{{}}}{{rgb}}{{\" + \",\".join(3 * [data[\"float format\"]]) + \"}}\"\n    for name, rgb in data[\"custom colors\"].items():\n        definitions.append(fmt.format(name, rgb[0], rgb[1], rgb[2]))\n    return definitions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint message to screen indicating the use of PGFPlots and its libraries.", "response": "def _print_pgfplot_libs_message(data):\n    \"\"\"Prints message to screen indicating the use of PGFPlots and its\n    libraries.\"\"\"\n    pgfplotslibs = \",\".join(list(data[\"pgfplots libs\"]))\n    tikzlibs = \",\".join(list(data[\"tikz libs\"]))\n\n    print(70 * \"=\")\n    print(\"Please add the following lines to your LaTeX preamble:\\n\")\n    print(\"\\\\usepackage[utf8]{inputenc}\")\n    print(\"\\\\usepackage{fontspec}  % This line only for XeLaTeX and LuaLaTeX\")\n    print(\"\\\\usepackage{pgfplots}\")\n    if tikzlibs:\n        print(\"\\\\usetikzlibrary{\" + tikzlibs + \"}\")\n    if pgfplotslibs:\n        print(\"\\\\usepgfplotslibrary{\" + pgfplotslibs + \"}\")\n    print(70 * \"=\")\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _recurse(data, obj):\n    content = _ContentManager()\n    for child in obj.get_children():\n        # Some patches are Spines, too; skip those entirely.\n        # See <https://github.com/nschloe/matplotlib2tikz/issues/277>.\n        if isinstance(child, mpl.spines.Spine):\n            continue\n\n        if isinstance(child, mpl.axes.Axes):\n            ax = axes.Axes(data, child)\n\n            if ax.is_colorbar:\n                continue\n\n            # add extra axis options\n            if data[\"extra axis options [base]\"]:\n                ax.axis_options.extend(data[\"extra axis options [base]\"])\n\n            data[\"current mpl axes obj\"] = child\n            data[\"current axes\"] = ax\n\n            # Run through the child objects, gather the content.\n            data, children_content = _recurse(data, child)\n\n            # populate content and add axis environment if desired\n            if data[\"add axis environment\"]:\n                content.extend(\n                    ax.get_begin_code() + children_content + [ax.get_end_code(data)], 0\n                )\n            else:\n                content.extend(children_content, 0)\n                # print axis environment options, if told to show infos\n                if data[\"show_info\"]:\n                    print(\"=========================================================\")\n                    print(\"These would have been the properties of the environment:\")\n                    print(\"\".join(ax.get_begin_code()[1:]))\n                    print(\"=========================================================\")\n        elif isinstance(child, mpl.lines.Line2D):\n            data, cont = line2d.draw_line2d(data, child)\n            content.extend(cont, child.get_zorder())\n        elif isinstance(child, mpl.image.AxesImage):\n            data, cont = img.draw_image(data, child)\n            content.extend(cont, child.get_zorder())\n        elif isinstance(child, mpl.patches.Patch):\n            data, cont = patch.draw_patch(data, child)\n            content.extend(cont, child.get_zorder())\n        elif isinstance(\n            child, (mpl.collections.PatchCollection, mpl.collections.PolyCollection)\n        ):\n            data, cont = patch.draw_patchcollection(data, child)\n            content.extend(cont, child.get_zorder())\n        elif isinstance(child, mpl.collections.PathCollection):\n            data, cont = path.draw_pathcollection(data, child)\n            content.extend(cont, child.get_zorder())\n        elif isinstance(child, mpl.collections.LineCollection):\n            data, cont = line2d.draw_linecollection(data, child)\n            content.extend(cont, child.get_zorder())\n        elif isinstance(child, mpl.collections.QuadMesh):\n            data, cont = qmsh.draw_quadmesh(data, child)\n            content.extend(cont, child.get_zorder())\n        elif isinstance(child, mpl.legend.Legend):\n            data = legend.draw_legend(data, child)\n            if data[\"legend colors\"]:\n                content.extend(data[\"legend colors\"], 0)\n        elif isinstance(child, (mpl.text.Text, mpl.text.Annotation)):\n            data, cont = text.draw_text(data, child)\n            content.extend(cont, child.get_zorder())\n        elif isinstance(child, (mpl.axis.XAxis, mpl.axis.YAxis)):\n            pass\n        else:\n            warnings.warn(\n                \"matplotlib2tikz: Don't know how to handle object {}.\".format(\n                    type(child)\n                )\n            )\n    return data, content.flatten()", "response": "Recursively gathers the contents of all children of the current object and returns those."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extend(self, content, zorder):\n        if zorder not in self._content:\n            self._content[zorder] = []\n        self._content[zorder].extend(content)", "response": "Extends with a list and a z - order"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef draw_line2d(data, obj):\n    content = []\n    addplot_options = []\n\n    # If line is of length 0, do nothing.  Otherwise, an empty \\addplot table will be\n    # created, which will be interpreted as an external data source in either the file\n    # '' or '.tex'.  Instead, render nothing.\n    if len(obj.get_xdata()) == 0:\n        return data, []\n\n    # get the linewidth (in pt)\n    line_width = mypath.mpl_linewidth2pgfp_linewidth(data, obj.get_linewidth())\n    if line_width:\n        addplot_options.append(line_width)\n\n    # get line color\n    color = obj.get_color()\n    data, line_xcolor, _ = mycol.mpl_color2xcolor(data, color)\n    addplot_options.append(line_xcolor)\n\n    alpha = obj.get_alpha()\n    if alpha is not None:\n        addplot_options.append(\"opacity={}\".format(alpha))\n\n    linestyle = mypath.mpl_linestyle2pgfplots_linestyle(obj.get_linestyle(), line=obj)\n    if linestyle is not None and linestyle != \"solid\":\n        addplot_options.append(linestyle)\n\n    marker_face_color = obj.get_markerfacecolor()\n    marker_edge_color = obj.get_markeredgecolor()\n    data, marker, extra_mark_options = _mpl_marker2pgfp_marker(\n        data, obj.get_marker(), marker_face_color\n    )\n    if marker:\n        _marker(\n            obj,\n            data,\n            marker,\n            addplot_options,\n            extra_mark_options,\n            marker_face_color,\n            marker_edge_color,\n            line_xcolor,\n        )\n\n    if marker and linestyle is None:\n        addplot_options.append(\"only marks\")\n\n    # Check if a line is in a legend and forget it if not.\n    # Fixes <https://github.com/nschloe/matplotlib2tikz/issues/167>.\n    legend_text = get_legend_text(obj)\n    if legend_text is None and has_legend(obj.axes):\n        addplot_options.append(\"forget plot\")\n\n    # process options\n    content.append(\"\\\\addplot \")\n    if addplot_options:\n        content.append(\"[{}]\\n\".format(\", \".join(addplot_options)))\n\n    c, axis_options = _table(obj, data)\n    content += c\n\n    if legend_text is not None:\n        content.append(\"\\\\addlegendentry{{{}}}\\n\".format(legend_text))\n\n    return data, content", "response": "Returns the PGFPlots code for a Line2D environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn Pgfplots code for a number of patch objects.", "response": "def draw_linecollection(data, obj):\n    \"\"\"Returns Pgfplots code for a number of patch objects.\n    \"\"\"\n    content = []\n\n    edgecolors = obj.get_edgecolors()\n    linestyles = obj.get_linestyles()\n    linewidths = obj.get_linewidths()\n    paths = obj.get_paths()\n\n    for i, path in enumerate(paths):\n        color = edgecolors[i] if i < len(edgecolors) else edgecolors[0]\n        style = linestyles[i] if i < len(linestyles) else linestyles[0]\n        width = linewidths[i] if i < len(linewidths) else linewidths[0]\n\n        data, options = mypath.get_draw_options(data, obj, color, None, style, width)\n\n        # TODO what about masks?\n        data, cont, _, _ = mypath.draw_path(\n            data, path, draw_options=options, simplify=False\n        )\n        content.append(cont + \"\\n\")\n\n    return data, content"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntranslates a marker style of matplotlib to the corresponding style in PGFPlots.", "response": "def _mpl_marker2pgfp_marker(data, mpl_marker, marker_face_color):\n    \"\"\"Translates a marker style of matplotlib to the corresponding style\n    in PGFPlots.\n    \"\"\"\n    # try default list\n    try:\n        pgfplots_marker = _MP_MARKER2PGF_MARKER[mpl_marker]\n    except KeyError:\n        pass\n    else:\n        if (marker_face_color is not None) and pgfplots_marker == \"o\":\n            pgfplots_marker = \"*\"\n            data[\"tikz libs\"].add(\"plotmarks\")\n        marker_options = None\n        return (data, pgfplots_marker, marker_options)\n\n    # try plotmarks list\n    try:\n        data[\"tikz libs\"].add(\"plotmarks\")\n        pgfplots_marker, marker_options = _MP_MARKER2PLOTMARKS[mpl_marker]\n    except KeyError:\n        # There's no equivalent for the pixel marker (,) in Pgfplots.\n        pass\n    else:\n        if (\n            marker_face_color is not None\n            and (\n                not isinstance(marker_face_color, str)\n                or marker_face_color.lower() != \"none\"\n            )\n            and pgfplots_marker not in [\"|\", \"-\", \"asterisk\", \"star\"]\n        ):\n            pgfplots_marker += \"*\"\n        return (data, pgfplots_marker, marker_options)\n\n    return data, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npainting text on the graph.", "response": "def draw_text(data, obj):\n    \"\"\"Paints text on the graph.\n    \"\"\"\n    content = []\n    properties = []\n    style = []\n    if isinstance(obj, mpl.text.Annotation):\n        _annotation(obj, data, content)\n\n    # 1: coordinates\n    # 2: properties (shapes, rotation, etc)\n    # 3: text style\n    # 4: the text\n    #                   -------1--------2---3--4--\n    pos = obj.get_position()\n\n    # from .util import transform_to_data_coordinates\n    # pos = transform_to_data_coordinates(obj, *pos)\n\n    text = obj.get_text()\n\n    if text in [\"\", data[\"current axis title\"]]:\n        # Text nodes which are direct children of Axes are typically titles.  They are\n        # already captured by the `title` property of pgfplots axes, so skip them here.\n        return data, content\n\n    size = obj.get_size()\n    bbox = obj.get_bbox_patch()\n    converter = mpl.colors.ColorConverter()\n    # without the factor 0.5, the fonts are too big most of the time.\n    # TODO fix this\n    scaling = 0.5 * size / data[\"font size\"]\n    ff = data[\"float format\"]\n    if scaling != 1.0:\n        properties.append((\"scale=\" + ff).format(scaling))\n\n    if bbox is not None:\n        _bbox(bbox, data, properties, scaling)\n\n    ha = obj.get_ha()\n    va = obj.get_va()\n    anchor = _transform_positioning(ha, va)\n    if anchor is not None:\n        properties.append(anchor)\n    data, col, _ = color.mpl_color2xcolor(data, converter.to_rgb(obj.get_color()))\n    properties.append(\"text={}\".format(col))\n    properties.append(\"rotate={:.1f}\".format(obj.get_rotation()))\n\n    if obj.get_style() == \"italic\":\n        style.append(\"\\\\itshape\")\n    else:\n        assert obj.get_style() == \"normal\"\n\n    # From matplotlib/font_manager.py:\n    # weight_dict = {\n    #     'ultralight' : 100,\n    #     'light'      : 200,\n    #     'normal'     : 400,\n    #     'regular'    : 400,\n    #     'book'       : 400,\n    #     'medium'     : 500,\n    #     'roman'      : 500,\n    #     'semibold'   : 600,\n    #     'demibold'   : 600,\n    #     'demi'       : 600,\n    #     'bold'       : 700,\n    #     'heavy'      : 800,\n    #     'extra bold' : 800,\n    #     'black'      : 900}\n    #\n    # get_weights returns a numeric value in the range 0-1000 or one of\n    # \u2018light\u2019, \u2018normal\u2019, \u2018regular\u2019, \u2018book\u2019, \u2018medium\u2019, \u2018roman\u2019, \u2018semibold\u2019,\n    # \u2018demibold\u2019, \u2018demi\u2019, \u2018bold\u2019, \u2018heavy\u2019, \u2018extra bold\u2019, \u2018black\u2019\n    weight = obj.get_weight()\n    if weight in [\n        \"semibold\",\n        \"demibold\",\n        \"demi\",\n        \"bold\",\n        \"heavy\",\n        \"extra bold\",\n        \"black\",\n    ] or (isinstance(weight, int) and weight > 550):\n        style.append(\"\\\\bfseries\")\n\n    # \\lfseries isn't that common yet\n    # elif weight == 'light' or (isinstance(weight, int) and weight < 300):\n    #     style.append('\\\\lfseries')\n\n    if obj.axes:\n        # If the coordinates are relative to an axis, use `axis cs`.\n        tikz_pos = (\"(axis cs:\" + ff + \",\" + ff + \")\").format(*pos)\n    else:\n        # relative to the entire figure, it's a getting a littler harder. See\n        # <http://tex.stackexchange.com/a/274902/13262> for a solution to the\n        # problem:\n        tikz_pos = (\n            \"({{$(current bounding box.south west)!\" + ff + \"!\"\n            \"(current bounding box.south east)$}}\"\n            \"|-\"\n            \"{{$(current bounding box.south west)!\" + ff + \"!\"\n            \"(current bounding box.north west)$}})\"\n        ).format(*pos)\n\n    if \"\\n\" in text:\n        # http://tex.stackexchange.com/a/124114/13262\n        properties.append(\"align={}\".format(ha))\n        # Manipulating the text here is actually against mpl2tikz's policy not\n        # to do that. On the other hand, newlines should translate into\n        # newlines.\n        # We might want to remove this here in the future.\n        text = text.replace(\"\\n \", \"\\\\\\\\\")\n\n    content.append(\n        \"\\\\node at {}[\\n  {}\\n]{{{}}};\\n\".format(\n            tikz_pos, \",\\n  \".join(properties), \" \".join(style + [text])\n        )\n    )\n    return data, content"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _transform_positioning(ha, va):\n    if ha == \"center\" and va == \"center\":\n        return None\n\n    ha_mpl_to_tikz = {\"right\": \"east\", \"left\": \"west\", \"center\": \"\"}\n    va_mpl_to_tikz = {\n        \"top\": \"north\",\n        \"bottom\": \"south\",\n        \"center\": \"\",\n        \"baseline\": \"base\",\n    }\n    return \"anchor={} {}\".format(va_mpl_to_tikz[va], ha_mpl_to_tikz[ha]).strip()", "response": "Converts matplotlib positioning to pgf node positioning."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports a JSON file or file - like object into a rows. Table.", "response": "def import_from_json(filename_or_fobj, encoding=\"utf-8\", *args, **kwargs):\n    \"\"\"Import a JSON file or file-like object into a `rows.Table`.\n\n    If a file-like object is provided it MUST be open in text (non-binary) mode\n    on Python 3 and could be open in both binary or text mode on Python 2.\n    \"\"\"\n\n    source = Source.from_file(filename_or_fobj, mode=\"rb\", plugin_name=\"json\", encoding=encoding)\n\n    json_obj = json.load(source.fobj, encoding=source.encoding)\n    field_names = list(json_obj[0].keys())\n    table_rows = [[item[key] for key in field_names] for item in json_obj]\n\n    meta = {\"imported_from\": \"json\", \"source\": source}\n    return create_table([field_names] + table_rows, meta=meta, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexport a rows. Table to a JSON file or file - like object.", "response": "def export_to_json(\n    table, filename_or_fobj=None, encoding=\"utf-8\", indent=None, *args, **kwargs\n):\n    \"\"\"Export a `rows.Table` to a JSON file or file-like object.\n\n    If a file-like object is provided it MUST be open in binary mode (like in\n    `open('myfile.json', mode='wb')`).\n    \"\"\"\n    # TODO: will work only if table.fields is OrderedDict\n\n    fields = table.fields\n    prepared_table = prepare_to_export(table, *args, **kwargs)\n    field_names = next(prepared_table)\n    data = [\n        {\n            field_name: _convert(value, fields[field_name], *args, **kwargs)\n            for field_name, value in zip(field_names, row)\n        }\n        for row in prepared_table\n    ]\n\n    result = json.dumps(data, indent=indent)\n    if type(result) is six.text_type:  # Python 3\n        result = result.encode(encoding)\n\n    if indent is not None:\n        # clean up empty spaces at the end of lines\n        result = b\"\\n\".join(line.rstrip() for line in result.splitlines())\n\n    return export_data(filename_or_fobj, result, mode=\"wb\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plugin_name_by_uri(uri):\n    \"Return the plugin name based on the URI\"\n\n    # TODO: parse URIs like 'sqlite://' also\n    parsed = urlparse(uri)\n    basename = os.path.basename(parsed.path)\n\n    if not basename.strip():\n        raise RuntimeError(\"Could not identify file format.\")\n\n    plugin_name = basename.split(\".\")[-1].lower()\n    if plugin_name in FILE_EXTENSIONS:\n        plugin_name = MIME_TYPE_TO_PLUGIN_NAME[FILE_EXTENSIONS[plugin_name]]\n\n    return plugin_name", "response": "Return the plugin name based on the URI"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extension_by_source(source, mime_type):\n    \"Return the file extension used by this plugin\"\n\n    # TODO: should get this information from the plugin\n    extension = source.plugin_name\n    if extension:\n        return extension\n\n    if mime_type:\n        return mime_type.split(\"/\")[-1]", "response": "Return the file extension used by this plugin"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the plugin name based on the MIME type", "response": "def plugin_name_by_mime_type(mime_type, mime_name, file_extension):\n    \"Return the plugin name based on the MIME type\"\n\n    return MIME_TYPE_TO_PLUGIN_NAME.get(\n        normalize_mime_type(mime_type, mime_name, file_extension), None\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_source(uri, verify_ssl, progress, timeout=5):\n\n    # TODO: should also supporte other schemes, like file://, sqlite:// etc.\n\n    if uri.lower().startswith(\"http://\") or uri.lower().startswith(\"https://\"):\n        return download_file(\n            uri, verify_ssl=verify_ssl, timeout=timeout, progress=progress, detect=True\n        )\n\n    elif uri.startswith(\"postgres://\"):\n        return Source(\n            should_delete=False,\n            encoding=None,\n            plugin_name=\"postgresql\",\n            uri=uri,\n            is_file=False,\n            local=None,\n        )\n    else:\n        return local_file(uri)", "response": "Return a rows. Source with information for a given URI."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_from_source(source, default_encoding, *args, **kwargs):\n    \"Import data described in a `rows.Source` into a `rows.Table`\"\n\n    # TODO: test open_compressed\n    plugin_name = source.plugin_name\n    kwargs[\"encoding\"] = (\n        kwargs.get(\"encoding\", None) or source.encoding or default_encoding\n    )\n\n    try:\n        import_function = getattr(rows, \"import_from_{}\".format(plugin_name))\n    except AttributeError:\n        raise ValueError('Plugin (import) \"{}\" not found'.format(plugin_name))\n\n    table = import_function(source.uri, *args, **kwargs)\n\n    return table", "response": "Import data described in a rows. Source into a rows. Table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving an URI detects plugin and encoding and imports into a rows. Table", "response": "def import_from_uri(\n    uri, default_encoding=\"utf-8\", verify_ssl=True, progress=False, *args, **kwargs\n):\n    \"Given an URI, detects plugin and encoding and imports into a `rows.Table`\"\n\n    # TODO: support '-' also\n    # TODO: (optimization) if `kwargs.get('encoding', None) is not None` we can\n    #       skip encoding detection.\n    source = detect_source(uri, verify_ssl=verify_ssl, progress=progress)\n    return import_from_source(source, default_encoding, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a rows. Table and an URI detects plugin ( from URI and exports", "response": "def export_to_uri(table, uri, *args, **kwargs):\n    \"Given a `rows.Table` and an URI, detects plugin (from URI) and exports\"\n\n    # TODO: support '-' also\n    plugin_name = plugin_name_by_uri(uri)\n\n    try:\n        export_function = getattr(rows, \"export_to_{}\".format(plugin_name))\n    except AttributeError:\n        raise ValueError('Plugin (export) \"{}\" not found'.format(plugin_name))\n\n    return export_function(table, uri, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_compressed(filename, mode=\"r\", encoding=None):\n    \"Return a text-based file object from a filename, even if compressed\"\n\n    # TODO: integrate this function in the library itself, using\n    # get_filename_and_fobj\n    binary_mode = \"b\" in mode\n    extension = str(filename).split(\".\")[-1].lower()\n    if binary_mode and encoding:\n        raise ValueError(\"encoding should not be specified in binary mode\")\n\n    if extension == \"xz\":\n        if lzma is None:\n            raise RuntimeError(\"lzma support is not installed\")\n\n        fobj = lzma.open(filename, mode=mode)\n        if binary_mode:\n            return fobj\n        else:\n            return io.TextIOWrapper(fobj, encoding=encoding)\n\n    elif extension == \"gz\":\n        fobj = gzip.GzipFile(filename, mode=mode)\n        if binary_mode:\n            return fobj\n        else:\n            return io.TextIOWrapper(fobj, encoding=encoding)\n\n    elif extension == \"bz2\":\n        if bz2 is None:\n            raise RuntimeError(\"bzip2 support is not installed\")\n\n        if binary_mode:  # ignore encoding\n            return bz2.open(filename, mode=mode)\n        else:\n            if \"t\" not in mode:\n                # For some reason, passing only mode='r' to bzip2 is equivalent\n                # to 'rb', not 'rt', so we force it here.\n                mode += \"t\"\n            return bz2.open(filename, mode=mode, encoding=encoding)\n\n    else:\n        if binary_mode:\n            return open(filename, mode=mode)\n        else:\n            return open(filename, mode=mode, encoding=encoding)", "response": "Return a text - based file object from a filename even if compressed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexport a CSV file to SQLite based on field type detection from samples", "response": "def csv_to_sqlite(\n    input_filename,\n    output_filename,\n    samples=None,\n    dialect=None,\n    batch_size=10000,\n    encoding=\"utf-8\",\n    callback=None,\n    force_types=None,\n    chunk_size=8388608,\n    table_name=\"table1\",\n    schema=None,\n):\n    \"Export a CSV file to SQLite, based on field type detection from samples\"\n\n    # TODO: automatically detect encoding if encoding == `None`\n    # TODO: should be able to specify fields\n    # TODO: if table_name is \"2019\" the final name will be \"field_2019\" - must\n    #       be \"table_2019\"\n    # TODO: if schema is provided and the names are in uppercase, this function\n    #       will fail\n\n    if dialect is None:  # Get a sample to detect dialect\n        fobj = open_compressed(input_filename, mode=\"rb\")\n        sample = fobj.read(chunk_size)\n        dialect = rows.plugins.csv.discover_dialect(sample, encoding=encoding)\n    elif isinstance(dialect, six.text_type):\n        dialect = csv.get_dialect(dialect)\n\n    if schema is None:  # Identify data types\n        fobj = open_compressed(input_filename, encoding=encoding)\n        data = list(islice(csv.DictReader(fobj, dialect=dialect), samples))\n        schema = rows.import_from_dicts(data).fields\n        if force_types is not None:\n            schema.update(force_types)\n\n    # Create lazy table object to be converted\n    # TODO: this lazyness feature will be incorported into the library soon so\n    #       we can call here `rows.import_from_csv` instead of `csv.reader`.\n    reader = csv.reader(\n        open_compressed(input_filename, encoding=encoding), dialect=dialect\n    )\n    header = make_header(next(reader))  # skip header\n    table = rows.Table(fields=OrderedDict([(field, schema[field]) for field in header]))\n    table._rows = reader\n\n    # Export to SQLite\n    return rows.export_to_sqlite(\n        table,\n        output_filename,\n        table_name=table_name,\n        batch_size=batch_size,\n        callback=callback,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport a table inside a SQLite database to CSV", "response": "def sqlite_to_csv(\n    input_filename,\n    table_name,\n    output_filename,\n    dialect=csv.excel,\n    batch_size=10000,\n    encoding=\"utf-8\",\n    callback=None,\n    query=None,\n):\n    \"\"\"Export a table inside a SQLite database to CSV\"\"\"\n\n    # TODO: should be able to specify fields\n    # TODO: should be able to specify custom query\n\n    if isinstance(dialect, six.text_type):\n        dialect = csv.get_dialect(dialect)\n\n    if query is None:\n        query = \"SELECT * FROM {}\".format(table_name)\n    connection = sqlite3.Connection(input_filename)\n    cursor = connection.cursor()\n    result = cursor.execute(query)\n    header = [item[0] for item in cursor.description]\n    fobj = open_compressed(output_filename, mode=\"w\", encoding=encoding)\n    writer = csv.writer(fobj, dialect=dialect)\n    writer.writerow(header)\n    total_written = 0\n    for batch in rows.plugins.utils.ipartition(result, batch_size):\n        writer.writerows(batch)\n        written = len(batch)\n        total_written += written\n        if callback:\n            callback(written, total_written)\n    fobj.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a command and return its output", "response": "def execute_command(command):\n    \"\"\"Execute a command and return its output\"\"\"\n\n    command = shlex.split(command)\n    try:\n        process = subprocess.Popen(\n            command,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n    except FileNotFoundError:\n        raise RuntimeError(\"Command not found: {}\".format(repr(command)))\n    process.wait()\n    # TODO: may use another codec to decode\n    if process.returncode > 0:\n        stderr = process.stderr.read().decode(\"utf-8\")\n        raise ValueError(\"Error executing command: {}\".format(repr(stderr)))\n    return process.stdout.read().decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the uncompressed size for a file by executing commands", "response": "def uncompressed_size(filename):\n    \"\"\"Return the uncompressed size for a file by executing commands\n\n    Note: due to a limitation in gzip format, uncompressed files greather than\n    4GiB will have a wrong value.\n    \"\"\"\n\n    quoted_filename = shlex.quote(filename)\n\n    # TODO: get filetype from file-magic, if available\n    if str(filename).lower().endswith(\".xz\"):\n        output = execute_command('xz --list \"{}\"'.format(quoted_filename))\n        compressed, uncompressed = regexp_sizes.findall(output)\n        value, unit = uncompressed.split()\n        value = float(value.replace(\",\", \"\"))\n        return int(value * MULTIPLIERS[unit])\n\n    elif str(filename).lower().endswith(\".gz\"):\n        # XXX: gzip only uses 32 bits to store uncompressed size, so if the\n        # uncompressed size is greater than 4GiB, the value returned will be\n        # incorrect.\n        output = execute_command('gzip --list \"{}\"'.format(quoted_filename))\n        lines = [line.split() for line in output.splitlines()]\n        header, data = lines[0], lines[1]\n        gzip_data = dict(zip(header, data))\n        return int(gzip_data[\"uncompressed\"])\n\n    else:\n        raise ValueError('Unrecognized file type for \"{}\".'.format(filename))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimports data from CSV into PostgreSQL using the fastest method", "response": "def pgimport(\n    filename,\n    database_uri,\n    table_name,\n    encoding=\"utf-8\",\n    dialect=None,\n    create_table=True,\n    schema=None,\n    callback=None,\n    timeout=0.1,\n    chunk_size=8388608,\n    max_samples=10000,\n):\n    \"\"\"Import data from CSV into PostgreSQL using the fastest method\n\n    Required: psql command\n    \"\"\"\n\n    fobj = open_compressed(filename, mode=\"r\", encoding=encoding)\n    sample = fobj.read(chunk_size)\n\n    if dialect is None:  # Detect dialect\n        dialect = rows.plugins.csv.discover_dialect(\n            sample.encode(encoding), encoding=encoding\n        )\n    elif isinstance(dialect, six.text_type):\n        dialect = csv.get_dialect(dialect)\n\n    if schema is None:\n        # Detect field names\n        reader = csv.reader(io.StringIO(sample), dialect=dialect)\n        field_names = [slug(field_name) for field_name in next(reader)]\n\n    else:\n        field_names = list(schema.keys())\n\n    if create_table:\n        if schema is None:\n            data = [\n                dict(zip(field_names, row))\n                for row in itertools.islice(reader, max_samples)\n            ]\n            table = rows.import_from_dicts(data)\n            field_types = [table.fields[field_name] for field_name in field_names]\n        else:\n            field_types = list(schema.values())\n\n        columns = [\n            \"{} {}\".format(name, POSTGRESQL_TYPES.get(type_, DEFAULT_POSTGRESQL_TYPE))\n            for name, type_ in zip(field_names, field_types)\n        ]\n        create_table = SQL_CREATE_TABLE.format(\n            table_name=table_name, field_types=\", \".join(columns)\n        )\n        execute_command(get_psql_command(create_table, database_uri=database_uri))\n\n    # Prepare the `psql` command to be executed based on collected metadata\n    command = get_psql_copy_command(\n        database_uri=database_uri,\n        dialect=dialect,\n        direction=\"FROM\",\n        encoding=encoding,\n        header=field_names,\n        table_name=table_name,\n    )\n    rows_imported, error = 0, None\n    fobj = open_compressed(filename, mode=\"rb\")\n    try:\n        process = subprocess.Popen(\n            shlex.split(command),\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n        data = fobj.read(chunk_size)\n        total_written = 0\n        while data != b\"\":\n            written = process.stdin.write(data)\n            total_written += written\n            if callback:\n                callback(written, total_written)\n            data = fobj.read(chunk_size)\n        stdout, stderr = process.communicate()\n        if stderr != b\"\":\n            raise RuntimeError(stderr.decode(\"utf-8\"))\n        rows_imported = int(stdout.replace(b\"COPY \", b\"\").strip())\n\n    except FileNotFoundError:\n        raise RuntimeError(\"Command `psql` not found\")\n\n    except BrokenPipeError:\n        raise RuntimeError(process.stderr.read().decode(\"utf-8\"))\n\n    return {\"bytes_written\": total_written, \"rows_imported\": rows_imported}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pgexport(\n    database_uri,\n    table_name,\n    filename,\n    encoding=\"utf-8\",\n    dialect=csv.excel,\n    callback=None,\n    timeout=0.1,\n    chunk_size=8388608,\n):\n    \"\"\"Export data from PostgreSQL into a CSV file using the fastest method\n\n    Required: psql command\n    \"\"\"\n\n    if isinstance(dialect, six.text_type):\n        dialect = csv.get_dialect(dialect)\n\n    # Prepare the `psql` command to be executed to export data\n    command = get_psql_copy_command(\n        database_uri=database_uri,\n        direction=\"TO\",\n        encoding=encoding,\n        header=None,  # Needed when direction = 'TO'\n        table_name=table_name,\n        dialect=dialect,\n    )\n    fobj = open_compressed(filename, mode=\"wb\")\n    try:\n        process = subprocess.Popen(\n            shlex.split(command),\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n        total_written = 0\n        data = process.stdout.read(chunk_size)\n        while data != b\"\":\n            written = fobj.write(data)\n            total_written += written\n            if callback:\n                callback(written, total_written)\n            data = process.stdout.read(chunk_size)\n        stdout, stderr = process.communicate()\n        if stderr != b\"\":\n            raise RuntimeError(stderr.decode(\"utf-8\"))\n\n    except FileNotFoundError:\n        raise RuntimeError(\"Command `psql` not found\")\n\n    except BrokenPipeError:\n        raise RuntimeError(process.stderr.read().decode(\"utf-8\"))\n\n    return {\"bytes_written\": total_written}", "response": "Export data from PostgreSQL into a CSV file using the fastest method."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the schema for a specific output format and write it to a file.", "response": "def generate_schema(table, export_fields, output_format, output_fobj):\n    \"\"\"Generate table schema for a specific output format and write\n\n    Current supported output formats: 'txt', 'sql' and 'django'.\n    The table name and all fields names pass for a slugifying process (table\n    name is taken from file name).\n    \"\"\"\n\n    if output_format in (\"csv\", \"txt\"):\n        from rows import plugins\n\n        data = [\n            {\n                \"field_name\": fieldname,\n                \"field_type\": fieldtype.__name__.replace(\"Field\", \"\").lower(),\n            }\n            for fieldname, fieldtype in table.fields.items()\n            if fieldname in export_fields\n        ]\n        table = plugins.dicts.import_from_dicts(\n            data, import_fields=[\"field_name\", \"field_type\"]\n        )\n        if output_format == \"txt\":\n            plugins.txt.export_to_txt(table, output_fobj)\n        elif output_format == \"csv\":\n            plugins.csv.export_to_csv(table, output_fobj)\n\n    elif output_format == \"sql\":\n        # TODO: may use dict from rows.plugins.sqlite or postgresql\n        sql_fields = {\n            rows.fields.BinaryField: \"BLOB\",\n            rows.fields.BoolField: \"BOOL\",\n            rows.fields.IntegerField: \"INT\",\n            rows.fields.FloatField: \"FLOAT\",\n            rows.fields.PercentField: \"FLOAT\",\n            rows.fields.DateField: \"DATE\",\n            rows.fields.DatetimeField: \"DATETIME\",\n            rows.fields.TextField: \"TEXT\",\n            rows.fields.DecimalField: \"FLOAT\",\n            rows.fields.EmailField: \"TEXT\",\n            rows.fields.JSONField: \"TEXT\",\n        }\n        fields = [\n            \"    {} {}\".format(field_name, sql_fields[field_type])\n            for field_name, field_type in table.fields.items()\n            if field_name in export_fields\n        ]\n        sql = (\n            dedent(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS {name} (\n                {fields}\n                );\n                \"\"\"\n            )\n            .strip()\n            .format(name=table.name, fields=\",\\n\".join(fields))\n            + \"\\n\"\n        )\n        output_fobj.write(sql)\n\n    elif output_format == \"django\":\n        django_fields = {\n            rows.fields.BinaryField: \"BinaryField\",\n            rows.fields.BoolField: \"BooleanField\",\n            rows.fields.IntegerField: \"IntegerField\",\n            rows.fields.FloatField: \"FloatField\",\n            rows.fields.PercentField: \"DecimalField\",\n            rows.fields.DateField: \"DateField\",\n            rows.fields.DatetimeField: \"DateTimeField\",\n            rows.fields.TextField: \"TextField\",\n            rows.fields.DecimalField: \"DecimalField\",\n            rows.fields.EmailField: \"EmailField\",\n            rows.fields.JSONField: \"JSONField\",\n        }\n        table_name = \"\".join(word.capitalize() for word in table.name.split(\"_\"))\n\n        lines = [\"from django.db import models\"]\n        if rows.fields.JSONField in [\n            table.fields[field_name] for field_name in export_fields\n        ]:\n            lines.append(\"from django.contrib.postgres.fields import JSONField\")\n        lines.append(\"\")\n\n        lines.append(\"class {}(models.Model):\".format(table_name))\n        for field_name, field_type in table.fields.items():\n            if field_name not in export_fields:\n                continue\n\n            if field_type is not rows.fields.JSONField:\n                django_type = \"models.{}()\".format(django_fields[field_type])\n            else:\n                django_type = \"JSONField()\"\n            lines.append(\"    {} = {}\".format(field_name, django_type))\n\n        result = \"\\n\".join(lines) + \"\\n\"\n        output_fobj.write(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload schema from file in any of the supported formats", "response": "def load_schema(filename, context=None):\n    \"\"\"Load schema from file in any of the supported formats\n\n    The table must have at least the fields `field_name` and `field_type`.\n    `context` is a `dict` with field_type as key pointing to field class, like:\n        {\"text\": rows.fields.TextField, \"value\": MyCustomField}\n    \"\"\"\n    table = import_from_uri(filename)\n    field_names = table.field_names\n    assert \"field_name\" in field_names\n    assert \"field_type\" in field_names\n\n    context = context or {\n        key.replace(\"Field\", \"\").lower(): getattr(rows.fields, key)\n        for key in dir(rows.fields)\n        if \"Field\" in key and key != \"Field\"\n    }\n    return OrderedDict(\n        [\n            (row.field_name, context[row.field_type])\n            for row in table\n        ]\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_items(*indexes):\n    return lambda obj: tuple(\n        obj[index] if len(obj) > index else None for index in indexes\n    )", "response": "Returns a callable that fetches the given indexes of an object\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a slug for the text.", "response": "def slug(text, separator=\"_\", permitted_chars=SLUG_CHARS):\n    \"\"\"Generate a slug for the `text`.\n\n    >>> slug(' \u00c1LVARO  justen% ')\n    'alvaro_justen'\n    >>> slug(' \u00c1LVARO  justen% ', separator='-')\n    'alvaro-justen'\n    \"\"\"\n\n    text = six.text_type(text or \"\")\n\n    # Strip non-ASCII characters\n    # Example: u' \u00c1LVARO  justen% ' -> ' ALVARO  justen% '\n    text = normalize(\"NFKD\", text.strip()).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n\n    # Replace word boundaries with separator\n    text = REGEXP_WORD_BOUNDARY.sub(\"\\\\1\" + re.escape(separator), text)\n\n    # Remove non-permitted characters and put everything to lowercase\n    # Example: u'_ALVARO__justen%_' -> u'_alvaro__justen_'\n    allowed_chars = list(permitted_chars) + [separator]\n    text = \"\".join(char for char in text if char in allowed_chars).lower()\n\n    # Remove double occurrencies of separator\n    # Example: u'_alvaro__justen_' -> u'_alvaro_justen_'\n    text = (\n        REGEXP_SEPARATOR\n        if separator == \"_\"\n        else re.compile(\"(\" + re.escape(separator) + \"+)\")\n    ).sub(separator, text)\n\n    # Strip separators\n    # Example: u'_alvaro_justen_' -> u'alvaro_justen'\n    return text.strip(separator)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a unique name based on name_format and name.", "response": "def make_unique_name(name, existing_names, name_format=\"{name}_{index}\", start=2):\n    \"\"\"Return a unique name based on `name_format` and `name`.\"\"\"\n    index = start\n    new_name = name\n    while new_name in existing_names:\n        new_name = name_format.format(name=name, index=index)\n        index += 1\n\n    return new_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn unique and slugged field names.", "response": "def make_header(field_names, permit_not=False):\n    \"\"\"Return unique and slugged field names.\"\"\"\n    slug_chars = SLUG_CHARS if not permit_not else SLUG_CHARS + \"^\"\n\n    header = [\n        slug(field_name, permitted_chars=slug_chars) for field_name in field_names\n    ]\n    result = []\n    for index, field_name in enumerate(header):\n        if not field_name:\n            field_name = \"field_{}\".format(index)\n        elif field_name[0].isdigit():\n            field_name = \"field_{}\".format(field_name)\n\n        if field_name in result:\n            field_name = make_unique_name(\n                name=field_name, existing_names=result, start=2\n            )\n        result.append(field_name)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detect_types(\n    field_names,\n    field_values,\n    field_types=DEFAULT_TYPES,\n    skip_indexes=None,\n    type_detector=TypeDetector,\n    fallback_type=TextField,\n    *args,\n    **kwargs\n):\n    \"\"\"Detect column types (or \"where the magic happens\")\"\"\"\n\n    # TODO: look strategy of csv.Sniffer.has_header\n    # TODO: may receive 'type hints'\n    detector = type_detector(\n        field_names,\n        field_types=field_types,\n        fallback_type=fallback_type,\n        skip_indexes=skip_indexes,\n    )\n    detector.feed(field_values)\n    return detector.fields", "response": "Detect column types (or \"where the magic happens\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter out objects outside table boundaries", "response": "def selected_objects(self):\n        \"\"\"Filter out objects outside table boundaries\"\"\"\n\n        return [\n            obj\n            for obj in self.text_objects\n            if contains_or_overlap(self.table_bbox, obj.bbox)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform(row, table):\n    'Extract links from \"project\" field and remove HTML from all'\n\n    data = row._asdict()\n    data[\"links\"] = \" \".join(extract_links(row.project))\n    for key, value in data.items():\n        if isinstance(value, six.text_type):\n            data[key] = extract_text(value)\n    return data", "response": "Extract links from project field and remove HTML from all"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(row, table):\n    'Transform row \"link\" into full URL and add \"state\" based on \"name\"'\n\n    data = row._asdict()\n    data[\"link\"] = urljoin(\"https://pt.wikipedia.org\", data[\"link\"])\n    data[\"name\"], data[\"state\"] = regexp_city_state.findall(data[\"name\"])[0]\n    return data", "response": "Transform row link into full URL and add state based on name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting data from a Parquet file and return with rows. Table.", "response": "def import_from_parquet(filename_or_fobj, *args, **kwargs):\n    \"\"\"Import data from a Parquet file and return with rows.Table.\"\"\"\n    source = Source.from_file(filename_or_fobj, plugin_name=\"parquet\", mode=\"rb\")\n\n    # TODO: should look into `schema.converted_type` also\n    types = OrderedDict(\n        [\n            (schema.name, PARQUET_TO_ROWS[schema.type])\n            for schema in parquet._read_footer(source.fobj).schema\n            if schema.type is not None\n        ]\n    )\n    header = list(types.keys())\n    table_rows = list(parquet.reader(source.fobj))  # TODO: be lazy\n\n    meta = {\"imported_from\": \"parquet\", \"source\": source}\n    return create_table(\n        [header] + table_rows, meta=meta, force_types=types, *args, **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_from_dicts(data, samples=None, *args, **kwargs):\n\n    data = iter(data)\n\n    cached_rows, headers = [], []\n    for index, row in enumerate(data, start=1):\n        cached_rows.append(row)\n\n        for key in row.keys():\n            if key not in headers:\n                headers.append(key)\n\n        if samples and index == samples:\n            break\n\n    data_rows = (\n        [row.get(header, None) for header in headers]\n        for row in chain(cached_rows, data)\n    )\n\n    kwargs[\"samples\"] = samples\n    meta = {\"imported_from\": \"dicts\"}\n    return create_table(chain([headers], data_rows), meta=meta, *args, **kwargs)", "response": "Imports data from a iterable of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export_to_dicts(table, *args, **kwargs):\n    field_names = table.field_names\n    return [{key: getattr(row, key) for key in field_names} for row in table]", "response": "Export a rows. Table to a list of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract the set of intervals from a string.", "response": "def extract_intervals(text, repeat=False, sort=True):\n    \"\"\"\n    >>> extract_intervals(\"1,2,3\")\n    [1, 2, 3]\n    >>> extract_intervals(\"1,2,5-10\")\n    [1, 2, 5, 6, 7, 8, 9, 10]\n    >>> extract_intervals(\"1,2,5-10,3\")\n    [1, 2, 3, 5, 6, 7, 8, 9, 10]\n    >>> extract_intervals(\"1,2,5-10,6,7\")\n    [1, 2, 5, 6, 7, 8, 9, 10]\n    \"\"\"\n\n    result = []\n    for value in text.split(\",\"):\n        value = value.strip()\n        if \"-\" in value:\n            start_value, end_value = value.split(\"-\")\n            start_value = int(start_value.strip())\n            end_value = int(end_value.strip())\n            result.extend(range(start_value, end_value + 1))\n        else:\n            result.append(int(value.strip()))\n\n    if not repeat:\n        result = list(set(result))\n    if sort:\n        result.sort()\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value of the table passed by argument based in row and column.", "response": "def cell_value(sheet, row, col):\n    \"\"\"Return the cell value of the table passed by argument, based in row and column.\"\"\"\n    cell = sheet.cell(row, col)\n    field_type = CELL_TYPES[cell.ctype]\n\n    # TODO: this approach will not work if using locale\n    value = cell.value\n\n    if field_type is None:\n        return None\n\n    elif field_type is fields.TextField:\n        if cell.ctype != xlrd.XL_CELL_BLANK:\n            return value\n        else:\n            return \"\"\n\n    elif field_type is fields.DatetimeField:\n        if value == 0.0:\n            return None\n\n        try:\n            time_tuple = xlrd.xldate_as_tuple(value, sheet.book.datemode)\n        except xlrd.xldate.XLDateTooLarge:\n            return None\n        value = field_type.serialize(datetime.datetime(*time_tuple))\n        return value.split(\"T00:00:00\")[0]\n\n    elif field_type is fields.BoolField:\n        if value == 0:\n            return False\n        elif value == 1:\n            return True\n\n    elif cell.xf_index is None:\n        return value  # TODO: test\n\n    else:\n        book = sheet.book\n        xf = book.xf_list[cell.xf_index]\n        fmt = book.format_map[xf.format_key]\n\n        if fmt.format_str.endswith(\"%\"):\n            # TODO: we may optimize this approach: we're converting to string\n            # and the library is detecting the type when we could just say to\n            # the library this value is PercentField\n\n            if value is not None:\n                try:\n                    decimal_places = len(fmt.format_str[:-1].split(\".\")[-1])\n                except IndexError:\n                    decimal_places = 2\n                return \"{}%\".format(str(round(value * 100, decimal_places)))\n            else:\n                return None\n\n        elif type(value) == float and int(value) == value:\n            return int(value)\n\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport a rows. Table from an XLS file.", "response": "def import_from_xls(\n    filename_or_fobj,\n    sheet_name=None,\n    sheet_index=0,\n    start_row=None,\n    start_column=None,\n    end_row=None,\n    end_column=None,\n    *args,\n    **kwargs\n):\n    \"\"\"Return a rows.Table created from imported XLS file.\"\"\"\n\n    source = Source.from_file(filename_or_fobj, mode=\"rb\", plugin_name=\"xls\")\n    source.fobj.close()\n    book = xlrd.open_workbook(\n        source.uri, formatting_info=True, logfile=open(os.devnull, mode=\"w\")\n    )\n\n    if sheet_name is not None:\n        sheet = book.sheet_by_name(sheet_name)\n    else:\n        sheet = book.sheet_by_index(sheet_index)\n    # TODO: may re-use Excel data types\n\n    # Get header and rows\n    # xlrd library reads rows and columns starting from 0 and ending on\n    # sheet.nrows/ncols - 1. rows accepts the same pattern\n    # The xlrd library reads rows and columns starting from 0 and ending on\n    # sheet.nrows/ncols - 1. rows also uses 0-based indexes, so no\n    # transformation is needed\n    min_row, min_column = get_table_start(sheet)\n    max_row, max_column = sheet.nrows - 1, sheet.ncols - 1\n    # TODO: consider adding a parameter `ignore_padding=True` and when it's\n    # True, consider `start_row` starting from `min_row` and `start_column`\n    # starting from `min_col`.\n    start_row = max(start_row if start_row is not None else min_row, min_row)\n    end_row = min(end_row if end_row is not None else max_row, max_row)\n    start_column = max(\n        start_column if start_column is not None else min_column, min_column\n    )\n    end_column = min(end_column if end_column is not None else max_column, max_column)\n\n    table_rows = [\n        [\n            cell_value(sheet, row_index, column_index)\n            for column_index in range(start_column, end_column + 1)\n        ]\n        for row_index in range(start_row, end_row + 1)\n    ]\n\n    meta = {\"imported_from\": \"xls\", \"source\": source, \"name\": sheet.name}\n    return create_table(table_rows, meta=meta, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export_to_xls(table, filename_or_fobj=None, sheet_name=\"Sheet1\", *args, **kwargs):\n\n    workbook = xlwt.Workbook()\n    sheet = workbook.add_sheet(sheet_name)\n\n    prepared_table = prepare_to_export(table, *args, **kwargs)\n\n    field_names = next(prepared_table)\n    for column_index, field_name in enumerate(field_names):\n        sheet.write(0, column_index, field_name)\n\n    _convert_row = _python_to_xls([table.fields.get(field) for field in field_names])\n    for row_index, row in enumerate(prepared_table, start=1):\n        for column_index, (value, data) in enumerate(_convert_row(row)):\n            sheet.write(row_index, column_index, value, **data)\n\n    return_result = False\n    if filename_or_fobj is None:\n        filename_or_fobj = BytesIO()\n        return_result = True\n\n    source = Source.from_file(filename_or_fobj, mode=\"wb\", plugin_name=\"xls\")\n    workbook.save(source.fobj)\n    source.fobj.flush()\n\n    if return_result:\n        source.fobj.seek(0)\n        result = source.fobj.read()\n    else:\n        result = source.fobj\n\n    if source.should_close:\n        source.fobj.close()\n\n    return result", "response": "Export the rows. Table to XLS file and return the saved file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify if a given table name is valid for rows", "response": "def _valid_table_name(name):\n    \"\"\"Verify if a given table name is valid for `rows`\n\n    Rules:\n    - Should start with a letter or '_'\n    - Letters can be capitalized or not\n    - Accepts letters, numbers and _\n    \"\"\"\n\n    if name[0] not in \"_\" + string.ascii_letters or not set(name).issubset(\n        \"_\" + string.ascii_letters + string.digits\n    ):\n        return False\n\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_col_positions(frame_style, header_line):\n\n    separator = re.escape(FRAMES[frame_style.lower()][\"VERTICAL\"])\n\n    if frame_style == \"None\":\n        separator = r\"[\\s]{2}[^\\s]\"\n        # Matches two whitespaces followed by a non-whitespace.\n        # Our column headers are serated by 3 spaces by default.\n\n    col_positions = []\n    # Abuse regexp engine to anotate vertical-separator positions:\n    re.sub(separator, lambda group: col_positions.append(group.start()), header_line)\n    if frame_style == \"None\":\n        col_positions.append(len(header_line) - 1)\n    return col_positions", "response": "Find the positions of each column separator in the given line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting a single TXT file into a new table.", "response": "def import_from_txt(\n    filename_or_fobj, encoding=\"utf-8\", frame_style=FRAME_SENTINEL, *args, **kwargs\n):\n    \"\"\"Return a rows.Table created from imported TXT file.\"\"\"\n\n    # TODO: (maybe)\n    # enable parsing of non-fixed-width-columns\n    # with old algorithm - that would just split columns\n    # at the vertical separator character for the frame.\n    # (if doing so, include an optional parameter)\n    # Also, this fixes an outstanding unreported issue:\n    # trying to parse tables which fields values\n    # included a Pipe char - \"|\" - would silently\n    # yield bad results.\n\n    source = Source.from_file(filename_or_fobj, mode=\"rb\", plugin_name=\"txt\", encoding=encoding)\n    raw_contents = source.fobj.read().decode(encoding).rstrip(\"\\n\")\n\n    if frame_style is FRAME_SENTINEL:\n        frame_style = _guess_frame_style(raw_contents)\n    else:\n        frame_style = _parse_frame_style(frame_style)\n\n    contents = raw_contents.splitlines()\n    del raw_contents\n\n    if frame_style != \"None\":\n        contents = contents[1:-1]\n        del contents[1]\n    else:\n        # the table is possibly generated from other source.\n        # check if the line we reserve as a separator is realy empty.\n        if not contents[1].strip():\n            del contents[1]\n    col_positions = _parse_col_positions(frame_style, contents[0])\n\n    table_rows = [\n        [\n            row[start + 1 : end].strip()\n            for start, end in zip(col_positions, col_positions[1:])\n        ]\n        for row in contents\n    ]\n\n    meta = {\n        \"imported_from\": \"txt\",\n        \"source\": source,\n        \"frame_style\": frame_style,\n    }\n    return create_table(table_rows, meta=meta, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexports a rows. Table to text.", "response": "def export_to_txt(\n    table,\n    filename_or_fobj=None,\n    encoding=None,\n    frame_style=\"ASCII\",\n    safe_none_frame=True,\n    *args,\n    **kwargs\n):\n    \"\"\"Export a `rows.Table` to text.\n\n    This function can return the result as a string or save into a file (via\n    filename or file-like object).\n\n    `encoding` could be `None` if no filename/file-like object is specified,\n    then the return type will be `six.text_type`.\n    `frame_style`: will select the frame style to be printed around data.\n    Valid values are: ('None', 'ASCII', 'single', 'double') - ASCII is default.\n    Warning: no checks are made to check the desired encoding allows the\n    characters needed by single and double frame styles.\n\n    `safe_none_frame`: bool, defaults to True. Affects only output with\n    frame_style == \"None\":\n    column titles are left-aligned and have\n    whitespace replaced for \"_\".  This enables\n    the output to be parseable. Otherwise, the generated table will look\n    prettier but can not be imported back.\n    \"\"\"\n    # TODO: will work only if table.fields is OrderedDict\n\n    frame_style = _parse_frame_style(frame_style)\n    frame = FRAMES[frame_style.lower()]\n\n    serialized_table = serialize(table, *args, **kwargs)\n    field_names = next(serialized_table)\n    table_rows = list(serialized_table)\n    max_sizes = _max_column_sizes(field_names, table_rows)\n\n    dashes = [frame[\"HORIZONTAL\"] * (max_sizes[field] + 2) for field in field_names]\n\n    if frame_style != \"None\" or not safe_none_frame:\n        header = [field.center(max_sizes[field]) for field in field_names]\n    else:\n        header = [\n            field.replace(\" \", \"_\").ljust(max_sizes[field]) for field in field_names\n        ]\n    header = \"{0} {1} {0}\".format(\n        frame[\"VERTICAL\"], \" {} \".format(frame[\"VERTICAL\"]).join(header)\n    )\n    top_split_line = (\n        frame[\"DOWN AND RIGHT\"]\n        + frame[\"DOWN AND HORIZONTAL\"].join(dashes)\n        + frame[\"DOWN AND LEFT\"]\n    )\n\n    body_split_line = (\n        frame[\"VERTICAL AND RIGHT\"]\n        + frame[\"VERTICAL AND HORIZONTAL\"].join(dashes)\n        + frame[\"VERTICAL AND LEFT\"]\n    )\n\n    botton_split_line = (\n        frame[\"UP AND RIGHT\"]\n        + frame[\"UP AND HORIZONTAL\"].join(dashes)\n        + frame[\"UP AND LEFT\"]\n    )\n\n    result = []\n    if frame_style != \"None\":\n        result += [top_split_line]\n    result += [header, body_split_line]\n\n    for row in table_rows:\n        values = [\n            value.rjust(max_sizes[field_name])\n            for field_name, value in zip(field_names, row)\n        ]\n        row_data = \" {} \".format(frame[\"VERTICAL\"]).join(values)\n        result.append(\"{0} {1} {0}\".format(frame[\"VERTICAL\"], row_data))\n\n    if frame_style != \"None\":\n        result.append(botton_split_line)\n    result.append(\"\")\n    data = \"\\n\".join(result)\n\n    if encoding is not None:\n        data = data.encode(encoding)\n\n    return export_data(filename_or_fobj, data, mode=\"wb\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a rows. Table with data from SQLite database.", "response": "def import_from_sqlite(\n    filename_or_connection,\n    table_name=\"table1\",\n    query=None,\n    query_args=None,\n    *args,\n    **kwargs\n):\n    \"\"\"Return a rows.Table with data from SQLite database.\"\"\"\n    source = get_source(filename_or_connection)\n    connection = source.fobj\n    cursor = connection.cursor()\n\n    if query is None:\n        if not _valid_table_name(table_name):\n            raise ValueError(\"Invalid table name: {}\".format(table_name))\n\n        query = SQL_SELECT_ALL.format(table_name=table_name)\n\n    if query_args is None:\n        query_args = tuple()\n\n    table_rows = list(cursor.execute(query, query_args))  # TODO: may be lazy\n    header = [six.text_type(info[0]) for info in cursor.description]\n    cursor.close()\n    # TODO: should close connection also?\n\n    meta = {\"imported_from\": \"sqlite\", \"source\": source}\n    return create_table([header] + table_rows, meta=meta, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a PyOpenXL s Cell object to the corresponding Python object.", "response": "def _cell_to_python(cell):\n    \"\"\"Convert a PyOpenXL's `Cell` object to the corresponding Python object.\"\"\"\n    data_type, value = cell.data_type, cell.value\n\n    if type(cell) is EmptyCell:\n        return None\n    elif data_type == \"f\" and value == \"=TRUE()\":\n        return True\n    elif data_type == \"f\" and value == \"=FALSE()\":\n        return False\n\n    elif cell.number_format.lower() == \"yyyy-mm-dd\":\n        return str(value).split(\" 00:00:00\")[0]\n    elif cell.number_format.lower() == \"yyyy-mm-dd hh:mm:ss\":\n        return str(value).split(\".\")[0]\n\n    elif cell.number_format.endswith(\"%\") and isinstance(value, Number):\n        value = Decimal(str(value))\n        return \"{:%}\".format(value)\n\n    elif value is None:\n        return \"\"\n    else:\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_from_xlsx(\n    filename_or_fobj,\n    sheet_name=None,\n    sheet_index=0,\n    start_row=None,\n    start_column=None,\n    end_row=None,\n    end_column=None,\n    workbook_kwargs=None,\n    *args,\n    **kwargs\n):\n    \"\"\"Return a rows.Table created from imported XLSX file.\n\n    workbook_kwargs will be passed to openpyxl.load_workbook\n    \"\"\"\n\n    workbook_kwargs = workbook_kwargs or {}\n    if \"read_only\" not in workbook_kwargs:\n        workbook_kwargs[\"read_only\"] = True\n\n    workbook = load_workbook(filename_or_fobj, **workbook_kwargs)\n    if sheet_name is None:\n        sheet_name = workbook.sheetnames[sheet_index]\n    sheet = workbook[sheet_name]\n\n    # The openpyxl library reads rows and columns starting from 1 and ending on\n    # sheet.max_row/max_col. rows uses 0-based indexes (from 0 to N - 1), so we\n    # need to adjust the ranges accordingly.\n    min_row, min_column = sheet.min_row - 1, sheet.min_column - 1\n    max_row, max_column = sheet.max_row - 1, sheet.max_column - 1\n    # TODO: consider adding a parameter `ignore_padding=True` and when it's\n    # True, consider `start_row` starting from `sheet.min_row` and\n    # `start_column` starting from `sheet.min_col`.\n    start_row = start_row if start_row is not None else min_row\n    end_row = end_row if end_row is not None else max_row\n    start_column = start_column if start_column is not None else min_column\n    end_column = end_column if end_column is not None else max_column\n    table_rows = []\n    is_empty = lambda row: all(cell is None for cell in row)\n    selected_rows = sheet.iter_rows(\n        min_row=start_row + 1,\n        max_row=end_row + 1,\n        min_col=start_column + 1,\n        max_col=end_column + 1,\n    )\n    for row in selected_rows:\n        row = [_cell_to_python(cell) for cell in row]\n        if not is_empty(row):\n            table_rows.append(row)\n\n    source = Source.from_file(filename_or_fobj, plugin_name=\"xlsx\")\n    source.fobj.close()\n    # TODO: pass a parameter to Source.from_file so it won't open the file\n    metadata = {\"imported_from\": \"xlsx\", \"source\": source, \"name\": sheet_name}\n    return create_table(table_rows, meta=metadata, *args, **kwargs)", "response": "Imports a single row or column from an XLSX file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport the rows. Table to XLSX file and return the saved file.", "response": "def export_to_xlsx(table, filename_or_fobj=None, sheet_name=\"Sheet1\", *args, **kwargs):\n    \"\"\"Export the rows.Table to XLSX file and return the saved file.\"\"\"\n\n    workbook = Workbook()\n    sheet = workbook.active\n    sheet.title = sheet_name\n    prepared_table = prepare_to_export(table, *args, **kwargs)\n\n    # Write header\n    field_names = next(prepared_table)\n    for col_index, field_name in enumerate(field_names):\n        cell = sheet.cell(row=1, column=col_index + 1)\n        cell.value = field_name\n\n    # Write sheet rows\n    _convert_row = _python_to_cell(list(map(table.fields.get, field_names)))\n    for row_index, row in enumerate(prepared_table, start=1):\n        for col_index, (value, number_format) in enumerate(_convert_row(row)):\n            cell = sheet.cell(row=row_index + 1, column=col_index + 1)\n            cell.value = value\n            if number_format is not None:\n                cell.number_format = number_format\n\n    return_result = False\n    if filename_or_fobj is None:\n        filename_or_fobj = BytesIO()\n        return_result = True\n\n    source = Source.from_file(filename_or_fobj, mode=\"wb\", plugin_name=\"xlsx\")\n    workbook.save(source.fobj)\n    source.fobj.flush()\n\n    if return_result:\n        source.fobj.seek(0)\n        result = source.fobj.read()\n    else:\n        result = source.fobj\n\n    if source.should_close:\n        source.fobj.close()\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download_organizations():\n    \"Download organizations JSON and extract its properties\"\n\n    response = requests.get(URL)\n    data = response.json()\n    organizations = [organization[\"properties\"] for organization in data[\"features\"]]\n    return rows.import_from_dicts(organizations)", "response": "Download organizations JSON and extract its properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefines table name based on its metadata", "response": "def name(self):\n        \"\"\"Define table name based on its metadata (filename used on import)\n\n        If `filename` is not available, return `table1`.\n        \"\"\"\n\n        from rows.plugins.utils import slug\n\n        name = self.meta.get(\"name\", None)\n        if name is not None:\n            return slug(name)\n\n        source = self.meta.get(\"source\", None)\n        if source and source.uri:\n            return slug(os.path.splitext(Path(source.uri).name)[0])\n\n        return \"table1\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning rows. Table from HTML file.", "response": "def import_from_html(\n    filename_or_fobj,\n    encoding=\"utf-8\",\n    index=0,\n    ignore_colspan=True,\n    preserve_html=False,\n    properties=False,\n    table_tag=\"table\",\n    row_tag=\"tr\",\n    column_tag=\"td|th\",\n    *args,\n    **kwargs\n):\n    \"\"\"Return rows.Table from HTML file.\"\"\"\n\n    source = Source.from_file(\n        filename_or_fobj, plugin_name=\"html\", mode=\"rb\", encoding=encoding\n    )\n\n    html = source.fobj.read().decode(source.encoding)\n    html_tree = document_fromstring(html)\n    tables = html_tree.xpath(\"//{}\".format(table_tag))\n    table = tables[index]\n    # TODO: set meta's \"name\" from @id or @name (if available)\n\n    strip_tags(table, \"thead\")\n    strip_tags(table, \"tbody\")\n    row_elements = table.xpath(row_tag)\n\n    table_rows = [\n        _get_row(\n            row,\n            column_tag=column_tag,\n            preserve_html=preserve_html,\n            properties=properties,\n        )\n        for row in row_elements\n    ]\n\n    if properties:\n        table_rows[0][-1] = \"properties\"\n\n    if preserve_html and kwargs.get(\"fields\", None) is None:\n        # The field names will be the first table row, so we need to strip HTML\n        # from it even if `preserve_html` is `True` (it's `True` only for rows,\n        # not for the header).\n        table_rows[0] = list(map(_extract_node_text, row_elements[0]))\n\n    if ignore_colspan:\n        max_columns = max(map(len, table_rows))\n        table_rows = [row for row in table_rows if len(row) == max_columns]\n\n    meta = {\"imported_from\": \"html\", \"source\": source}\n    return create_table(table_rows, meta=meta, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexporting and return rows. Table data to HTML file.", "response": "def export_to_html(\n    table, filename_or_fobj=None, encoding=\"utf-8\", caption=False, *args, **kwargs\n):\n    \"\"\"Export and return rows.Table data to HTML file.\"\"\"\n\n    serialized_table = serialize(table, *args, **kwargs)\n    fields = next(serialized_table)\n    result = [\"<table>\\n\\n\"]\n    if caption and table.name:\n        result.extend([\"  <caption>\", table.name, \"</caption>\\n\\n\"])\n    result.extend([\"  <thead>\\n\", \"    <tr>\\n\"])\n    # TODO: set @name/@id if self.meta[\"name\"] is set\n    header = [\"      <th> {} </th>\\n\".format(field) for field in fields]\n    result.extend(header)\n    result.extend([\"    </tr>\\n\", \"  </thead>\\n\", \"\\n\", \"  <tbody>\\n\", \"\\n\"])\n    for index, row in enumerate(serialized_table, start=1):\n        css_class = \"odd\" if index % 2 == 1 else \"even\"\n        result.append('    <tr class=\"{}\">\\n'.format(css_class))\n        for value in row:\n            result.extend([\"      <td> \", escape(value), \" </td>\\n\"])\n        result.append(\"    </tr>\\n\\n\")\n    result.append(\"  </tbody>\\n\\n</table>\\n\")\n    html = \"\".join(result).encode(encoding)\n\n    return export_data(filename_or_fobj, html, mode=\"wb\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _extract_node_text(node):\n\n    texts = map(\n        six.text_type.strip, map(six.text_type, map(unescape, node.xpath(\".//text()\")))\n    )\n    return \" \".join(text for text in texts if text)", "response": "Extract text from a given lxml node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef count_tables(filename_or_fobj, encoding=\"utf-8\", table_tag=\"table\"):\n\n    source = Source.from_file(\n        filename_or_fobj, plugin_name=\"html\", mode=\"rb\", encoding=encoding\n    )\n    html = source.fobj.read().decode(source.encoding)\n    html_tree = document_fromstring(html)\n    tables = html_tree.xpath(\"//{}\".format(table_tag))\n    result = len(tables)\n\n    if source.should_close:\n        source.fobj.close()\n\n    return result", "response": "Read a file passed by arg and return your table HTML tag count."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting tag s attributes into a dict.", "response": "def tag_to_dict(html):\n    \"\"\"Extract tag's attributes into a `dict`.\"\"\"\n\n    element = document_fromstring(html).xpath(\"//html/body/child::*\")[0]\n    attributes = dict(element.attrib)\n    attributes[\"text\"] = element.text_content()\n    return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a rows. Table object based on data rows and some configurations.", "response": "def create_table(\n    data,\n    meta=None,\n    fields=None,\n    skip_header=True,\n    import_fields=None,\n    samples=None,\n    force_types=None,\n    max_rows=None,\n    *args,\n    **kwargs\n):\n    \"\"\"Create a rows.Table object based on data rows and some configurations\n\n    - `skip_header` is only used if `fields` is set\n    - `samples` is only used if `fields` is `None`. If samples=None, all data\n      is filled in memory - use with caution.\n    - `force_types` is only used if `fields` is `None`\n    - `import_fields` can be used either if `fields` is set or not, the\n      resulting fields will seek its order\n    - `fields` must always be in the same order as the data\n    \"\"\"\n\n    table_rows = iter(data)\n    force_types = force_types or {}\n    if import_fields is not None:\n        import_fields = make_header(import_fields)\n\n    # TODO: test max_rows\n    if fields is None:  # autodetect field types\n        # TODO: may add `type_hints` parameter so autodetection can be easier\n        #       (plugins may specify some possible field types).\n        header = make_header(next(table_rows))\n\n        if samples is not None:\n            sample_rows = list(islice(table_rows, 0, samples))\n            table_rows = chain(sample_rows, table_rows)\n        else:\n            if max_rows is not None and max_rows > 0:\n                sample_rows = table_rows = list(islice(table_rows, max_rows))\n            else:\n                sample_rows = table_rows = list(table_rows)\n\n        # Detect field types using only the desired columns\n        detected_fields = detect_types(\n            header,\n            sample_rows,\n            skip_indexes=[\n                index\n                for index, field in enumerate(header)\n                if field in force_types or field not in (import_fields or header)\n            ],\n            *args,\n            **kwargs\n        )\n        # Check if any field was added during detecting process\n        new_fields = [\n            field_name\n            for field_name in detected_fields.keys()\n            if field_name not in header\n        ]\n        # Finally create the `fields` with both header and new field names,\n        # based on detected fields `and force_types`\n        fields = OrderedDict(\n            [\n                (field_name, detected_fields.get(field_name, TextField))\n                for field_name in header + new_fields\n            ]\n        )\n        fields.update(force_types)\n\n        # Update `header` and `import_fields` based on new `fields`\n        header = list(fields.keys())\n        if import_fields is None:\n            import_fields = header\n\n    else:  # using provided field types\n        if not isinstance(fields, OrderedDict):\n            raise ValueError(\"`fields` must be an `OrderedDict`\")\n\n        if skip_header:\n            # If we're skipping the header probably this row is not trustable\n            # (can be data or garbage).\n            next(table_rows)\n\n        header = make_header(list(fields.keys()))\n        if import_fields is None:\n            import_fields = header\n\n        fields = OrderedDict(\n            [(field_name, fields[key]) for field_name, key in zip(header, fields)]\n        )\n\n    diff = set(import_fields) - set(header)\n    if diff:\n        field_names = \", \".join('\"{}\"'.format(field) for field in diff)\n        raise ValueError(\"Invalid field names: {}\".format(field_names))\n    fields = OrderedDict(\n        [(field_name, fields[field_name]) for field_name in import_fields]\n    )\n\n    get_row = get_items(*map(header.index, import_fields))\n    table = Table(fields=fields, meta=meta)\n    if max_rows is not None and max_rows > 0:\n        table_rows = islice(table_rows, max_rows)\n    table.extend(dict(zip(import_fields, get_row(row))) for row in table_rows)\n\n    source = table.meta.get(\"source\", None)\n    if source is not None:\n        if source.should_close:\n            source.fobj.close()\n        if source.should_delete and Path(source.uri).exists():\n            unlink(source.uri)\n\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export_data(filename_or_fobj, data, mode=\"w\"):\n\n    if filename_or_fobj is None:\n        return data\n\n    _, fobj = get_filename_and_fobj(filename_or_fobj, mode=mode)\n    source = Source.from_file(filename_or_fobj, mode=mode, plugin_name=None)\n    source.fobj.write(data)\n    source.fobj.flush()\n    return source.fobj", "response": "Export data to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a sample from fobj and return the cursor to where it was.", "response": "def read_sample(fobj, sample):\n    \"\"\"Read `sample` bytes from `fobj` and return the cursor to where it was.\"\"\"\n    cursor = fobj.tell()\n    data = fobj.read(sample)\n    fobj.seek(cursor)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports data from a CSV file.", "response": "def import_from_csv(\n    filename_or_fobj,\n    encoding=\"utf-8\",\n    dialect=None,\n    sample_size=262144,\n    *args,\n    **kwargs\n):\n    \"\"\"Import data from a CSV file (automatically detects dialect).\n\n    If a file-like object is provided it MUST be in binary mode, like in\n    `open(filename, mode='rb')`.\n    \"\"\"\n    source = Source.from_file(\n        filename_or_fobj, plugin_name=\"csv\", mode=\"rb\", encoding=encoding\n    )\n\n    if dialect is None:\n        dialect = discover_dialect(\n            sample=read_sample(source.fobj, sample_size), encoding=source.encoding\n        )\n\n    reader = unicodecsv.reader(source.fobj, encoding=encoding, dialect=dialect)\n\n    meta = {\"imported_from\": \"csv\", \"source\": source}\n    return create_table(reader, meta=meta, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef export_to_csv(\n    table,\n    filename_or_fobj=None,\n    encoding=\"utf-8\",\n    dialect=unicodecsv.excel,\n    batch_size=100,\n    callback=None,\n    *args,\n    **kwargs\n):\n    \"\"\"Export a `rows.Table` to a CSV file.\n\n\n    If a file-like object is provided it MUST be in binary mode, like in\n    `open(filename, mode='wb')`.\n    If not filename/fobj is provided, the function returns a string with CSV\n    contents.\n    \"\"\"\n    # TODO: will work only if table.fields is OrderedDict\n    # TODO: should use fobj? What about creating a method like json.dumps?\n\n    return_data, should_close = False, None\n    if filename_or_fobj is None:\n        filename_or_fobj = BytesIO()\n        return_data = should_close = True\n\n    source = Source.from_file(\n        filename_or_fobj,\n        plugin_name=\"csv\",\n        mode=\"wb\",\n        encoding=encoding,\n        should_close=should_close,\n    )\n\n    # TODO: may use `io.BufferedWriter` instead of `ipartition` so user can\n    # choose the real size (in Bytes) when to flush to the file system, instead\n    # number of rows\n    writer = unicodecsv.writer(source.fobj, encoding=encoding, dialect=dialect)\n\n    if callback is None:\n        for batch in ipartition(serialize(table, *args, **kwargs), batch_size):\n            writer.writerows(batch)\n\n    else:\n        serialized = serialize(table, *args, **kwargs)\n        writer.writerow(next(serialized))  # First, write the header\n        total = 0\n        for batch in ipartition(serialized, batch_size):\n            writer.writerows(batch)\n            total += len(batch)\n            callback(total)\n\n    if return_data:\n        source.fobj.seek(0)\n        result = source.fobj.read()\n    else:\n        source.fobj.flush()\n        result = source.fobj\n\n    if source.should_close:\n        source.fobj.close()\n\n    return result", "response": "Export a rows. Table to a CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging a list of Table objects using keys to group rows", "response": "def join(keys, tables):\n    \"\"\"Merge a list of `Table` objects using `keys` to group rows\"\"\"\n\n    # Make new (merged) Table fields\n    fields = OrderedDict()\n    for table in tables:\n        fields.update(table.fields)\n    # TODO: may raise an error if a same field is different in some tables\n\n    # Check if all keys are inside merged Table's fields\n    fields_keys = set(fields.keys())\n    for key in keys:\n        if key not in fields_keys:\n            raise ValueError('Invalid key: \"{}\"'.format(key))\n\n    # Group rows by key, without missing ordering\n    none_fields = lambda: OrderedDict({field: None for field in fields.keys()})\n    data = OrderedDict()\n    for table in tables:\n        for row in table:\n            row_key = tuple([getattr(row, key) for key in keys])\n            if row_key not in data:\n                data[row_key] = none_fields()\n            data[row_key].update(row._asdict())\n\n    merged = Table(fields=fields)\n    merged.extend(data.values())\n    return merged"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new table based on other tables and a transformation function", "response": "def transform(fields, function, *tables):\n    \"Return a new table based on other tables and a transformation function\"\n\n    new_table = Table(fields=fields)\n\n    for table in tables:\n        for row in filter(bool, map(lambda row: function(row, table), table)):\n            new_table.append(row)\n\n    return new_table"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initiate_sniff(self, initial=False):\n        if self.sniffing_task and self.sniffing_task.done():\n            try:\n                if self.sniffing_task is not None:\n                    self.sniffing_task.result()\n            except:\n                if self.raise_on_sniff_error:\n                    raise\n            finally:\n                self.sniffing_task = None\n\n        if self.sniffing_task is None:\n            self.sniffing_task = ensure_future(self.sniff_hosts(initial), loop=self.loop)", "response": "Initiate a sniffing task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of nodes from the cluster and create a new connection pool.", "response": "def sniff_hosts(self, initial=False):\n        \"\"\"\n        Obtain a list of nodes from the cluster and create a new connection\n        pool using the information retrieved.\n\n        To extract the node connection parameters use the ``nodes_to_host_callback``.\n\n        :arg initial: flag indicating if this is during startup\n            (``sniff_on_start``), ignore the ``sniff_timeout`` if ``True``\n        \"\"\"\n        node_info = yield from self._get_sniff_data(initial)\n\n        hosts = list(filter(None, (self._get_host_info(n) for n in node_info)))\n\n        # we weren't able to get any nodes, maybe using an incompatible\n        # transport_schema or host_info_callback blocked all - raise error.\n        if not hosts:\n            raise TransportError(\"N/A\", \"Unable to sniff hosts - no viable hosts found.\")\n\n        # remember current live connections\n        orig_connections = self.connection_pool.connections[:]\n        self.set_connections(hosts)\n        # close those connections that are not in use any more\n        for c in orig_connections:\n            if c not in self.connection_pool.connections:\n                yield from c.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a k8s pod specification for running a user notebook.", "response": "def make_pod(\n    name,\n    cmd,\n    port,\n    image,\n    image_pull_policy,\n    image_pull_secret=None,\n    node_selector=None,\n    run_as_uid=None,\n    run_as_gid=None,\n    fs_gid=None,\n    supplemental_gids=None,\n    run_privileged=False,\n    env=None,\n    working_dir=None,\n    volumes=None,\n    volume_mounts=None,\n    labels=None,\n    annotations=None,\n    cpu_limit=None,\n    cpu_guarantee=None,\n    mem_limit=None,\n    mem_guarantee=None,\n    extra_resource_limits=None,\n    extra_resource_guarantees=None,\n    lifecycle_hooks=None,\n    init_containers=None,\n    service_account=None,\n    extra_container_config=None,\n    extra_pod_config=None,\n    extra_containers=None,\n    scheduler_name=None,\n    tolerations=None,\n    node_affinity_preferred=None,\n    node_affinity_required=None,\n    pod_affinity_preferred=None,\n    pod_affinity_required=None,\n    pod_anti_affinity_preferred=None,\n    pod_anti_affinity_required=None,\n    priority_class_name=None,\n    logger=None,\n):\n    \"\"\"\n    Make a k8s pod specification for running a user notebook.\n\n    Parameters\n    ----------\n    name:\n        Name of pod. Must be unique within the namespace the object is\n        going to be created in. Must be a valid DNS label.\n    image:\n        Image specification - usually a image name and tag in the form\n        of image_name:tag. Same thing you would use with docker commandline\n        arguments\n    image_pull_policy:\n        Image pull policy - one of 'Always', 'IfNotPresent' or 'Never'. Decides\n        when kubernetes will check for a newer version of image and pull it when\n        running a pod.\n    image_pull_secret:\n        Image pull secret - Default is None -- set to your secret name to pull\n        from private docker registry.\n    port:\n        Port the notebook server is going to be listening on\n    cmd:\n        The command used to execute the singleuser server.\n    node_selector:\n        Dictionary Selector to match nodes where to launch the Pods\n    run_as_uid:\n        The UID used to run single-user pods. The default is to run as the user\n        specified in the Dockerfile, if this is set to None.\n    run_as_gid:\n        The GID used to run single-user pods. The default is to run as the primary\n        group of the user specified in the Dockerfile, if this is set to None.\n        Setting this parameter requires that *feature-gate* **RunAsGroup** be enabled,\n        otherwise the effective GID of the pod will be 0 (root).  In addition, not\n        setting `run_as_gid` once feature-gate RunAsGroup is enabled will also\n        result in an effective GID of 0 (root).\n    fs_gid\n        The gid that will own any fresh volumes mounted into this pod, if using\n        volume types that support this (such as GCE). This should be a group that\n        the uid the process is running as should be a member of, so that it can\n        read / write to the volumes mounted.\n    supplemental_gids:\n        A list of GIDs that should be set as additional supplemental groups to\n        the user that the container runs as. You may have to set this if you are\n        deploying to an environment with RBAC/SCC enforced and pods run with a\n        'restricted' SCC which results in the image being run as an assigned\n        user ID. The supplemental group IDs would need to include the\n        corresponding group ID of the user ID the image normally would run as.\n        The image must setup all directories/files any application needs access\n        to, as group writable.\n    run_privileged:\n        Whether the container should be run in privileged mode.\n    env:\n        Dictionary of environment variables.\n    volumes:\n        List of dictionaries containing the volumes of various types this pod\n        will be using. See k8s documentation about volumes on how to specify\n        these\n    volume_mounts:\n        List of dictionaries mapping paths in the container and the volume(\n        specified in volumes) that should be mounted on them. See the k8s\n        documentaiton for more details\n    working_dir:\n        String specifying the working directory for the notebook container\n    labels:\n        Labels to add to the spawned pod.\n    annotations:\n        Annotations to add to the spawned pod.\n    cpu_limit:\n        Float specifying the max number of CPU cores the user's pod is\n        allowed to use.\n    cpu_guarentee:\n        Float specifying the max number of CPU cores the user's pod is\n        guaranteed to have access to, by the scheduler.\n    mem_limit:\n        String specifying the max amount of RAM the user's pod is allowed\n        to use. String instead of float/int since common suffixes are allowed\n    mem_guarantee:\n        String specifying the max amount of RAM the user's pod is guaranteed\n        to have access to. String ins loat/int since common suffixes\n        are allowed\n    lifecycle_hooks:\n        Dictionary of lifecycle hooks\n    init_containers:\n        List of initialization containers belonging to the pod.\n    service_account:\n        Service account to mount on the pod. None disables mounting\n    extra_container_config:\n        Extra configuration (e.g. envFrom) for notebook container which is not covered by parameters above.\n    extra_pod_config:\n        Extra configuration (e.g. tolerations) for pod which is not covered by parameters above.\n    extra_containers:\n        Extra containers besides notebook container. Used for some housekeeping jobs (e.g. crontab).\n    scheduler_name:\n        The pod's scheduler explicitly named.\n    tolerations:\n        Tolerations can allow a pod to schedule or execute on a tainted node. To\n        learn more about pod tolerations, see\n        https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/.\n\n        Pass this field an array of \"Toleration\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#nodeselectorterm-v1-core\n    node_affinity_preferred:\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PreferredSchedulingTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#preferredschedulingterm-v1-core\n    node_affinity_required:\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"NodeSelectorTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#nodeselectorterm-v1-core\n    pod_affinity_preferred:\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"WeightedPodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#weightedpodaffinityterm-v1-core\n    pod_affinity_required:\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#podaffinityterm-v1-core\n    pod_anti_affinity_preferred:\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"WeightedPodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#weightedpodaffinityterm-v1-core\n    pod_anti_affinity_required:\n        Affinities describe where pods prefer or require to be scheduled, they\n        may prefer or require a node to have a certain label or be in proximity\n        / remoteness to another pod. To learn more visit\n        https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n\n        Pass this field an array of \"PodAffinityTerm\" objects.*\n        * https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#podaffinityterm-v1-core\n    priority_class_name:\n        The name of the PriorityClass to be assigned the pod. This feature is Beta available in K8s 1.11.\n    \"\"\"\n\n    pod = V1Pod()\n    pod.kind = \"Pod\"\n    pod.api_version = \"v1\"\n\n    pod.metadata = V1ObjectMeta(\n        name=name,\n        labels=(labels or {}).copy(),\n        annotations=(annotations or {}).copy()\n    )\n\n    pod.spec = V1PodSpec(containers=[])\n    pod.spec.restart_policy = 'OnFailure'\n\n    security_context = V1PodSecurityContext()\n    if fs_gid is not None:\n        security_context.fs_group = int(fs_gid)\n    if supplemental_gids is not None and supplemental_gids:\n        security_context.supplemental_groups = [int(gid) for gid in supplemental_gids]\n    if run_as_uid is not None:\n        security_context.run_as_user = int(run_as_uid)\n    if run_as_gid is not None:\n        security_context.run_as_group = int(run_as_gid)\n    pod.spec.security_context = security_context\n\n    if image_pull_secret is not None:\n        pod.spec.image_pull_secrets = []\n        image_secret = V1LocalObjectReference()\n        image_secret.name = image_pull_secret\n        pod.spec.image_pull_secrets.append(image_secret)\n\n    if node_selector:\n        pod.spec.node_selector = node_selector\n\n    if lifecycle_hooks:\n        lifecycle_hooks = get_k8s_model(V1Lifecycle, lifecycle_hooks)\n    notebook_container = V1Container(\n        name='notebook',\n        image=image,\n        working_dir=working_dir,\n        ports=[V1ContainerPort(name='notebook-port', container_port=port)],\n        env=[V1EnvVar(k, v) for k, v in (env or {}).items()],\n        args=cmd,\n        image_pull_policy=image_pull_policy,\n        lifecycle=lifecycle_hooks,\n        resources=V1ResourceRequirements(),\n        volume_mounts=[get_k8s_model(V1VolumeMount, obj) for obj in (volume_mounts or [])],\n    )\n\n    if service_account is None:\n        # This makes sure that we don't accidentally give access to the whole\n        # kubernetes API to the users in the spawned pods.\n        pod.spec.automount_service_account_token = False\n    else:\n        pod.spec.service_account_name = service_account\n\n    if run_privileged:\n        notebook_container.security_context = V1SecurityContext(privileged=True)\n\n    notebook_container.resources.requests = {}\n    if cpu_guarantee:\n        notebook_container.resources.requests['cpu'] = cpu_guarantee\n    if mem_guarantee:\n        notebook_container.resources.requests['memory'] = mem_guarantee\n    if extra_resource_guarantees:\n        notebook_container.resources.requests.update(extra_resource_guarantees)\n\n    notebook_container.resources.limits = {}\n    if cpu_limit:\n        notebook_container.resources.limits['cpu'] = cpu_limit\n    if mem_limit:\n        notebook_container.resources.limits['memory'] = mem_limit\n    if extra_resource_limits:\n        notebook_container.resources.limits.update(extra_resource_limits)\n\n    if extra_container_config:\n        notebook_container = update_k8s_model(\n            target=notebook_container,\n            changes=extra_container_config,\n            logger=logger,\n            target_name=\"notebook_container\",\n            changes_name=\"extra_container_config\",\n        )\n\n    pod.spec.containers.append(notebook_container)\n\n    if extra_containers:\n        pod.spec.containers.extend([get_k8s_model(V1Container, obj) for obj in extra_containers])\n    if tolerations:\n        pod.spec.tolerations = [get_k8s_model(V1Toleration, obj) for obj in tolerations]\n    if init_containers:\n        pod.spec.init_containers = [get_k8s_model(V1Container, obj) for obj in init_containers]\n    if volumes:\n        pod.spec.volumes = [get_k8s_model(V1Volume, obj) for obj in volumes]\n    else:\n        # Keep behaving exactly like before by not cleaning up generated pod\n        # spec by setting the volumes field even though it is an empty list.\n        pod.spec.volumes = []\n    if scheduler_name:\n        pod.spec.scheduler_name = scheduler_name\n\n    node_affinity = None\n    if node_affinity_preferred or node_affinity_required:\n        node_selector = None\n        if node_affinity_required:\n            node_selector = V1NodeSelector(\n                node_selector_terms=[get_k8s_model(V1NodeSelectorTerm, obj) for obj in node_affinity_required],\n            )\n\n        preferred_scheduling_terms = None\n        if node_affinity_preferred:\n            preferred_scheduling_terms = [get_k8s_model(V1PreferredSchedulingTerm, obj) for obj in node_affinity_preferred]\n\n        node_affinity = V1NodeAffinity(\n            preferred_during_scheduling_ignored_during_execution=preferred_scheduling_terms,\n            required_during_scheduling_ignored_during_execution=node_selector,\n        )\n\n    pod_affinity = None\n    if pod_affinity_preferred or pod_affinity_required:\n        weighted_pod_affinity_terms = None\n        if pod_affinity_preferred:\n            weighted_pod_affinity_terms = [get_k8s_model(V1WeightedPodAffinityTerm, obj) for obj in pod_affinity_preferred]\n\n        pod_affinity_terms = None\n        if pod_affinity_required:\n            pod_affinity_terms = [get_k8s_model(V1PodAffinityTerm, obj) for obj in pod_affinity_required]\n\n        pod_affinity = V1PodAffinity(\n            preferred_during_scheduling_ignored_during_execution=weighted_pod_affinity_terms,\n            required_during_scheduling_ignored_during_execution=pod_affinity_terms,\n        )\n\n    pod_anti_affinity = None\n    if pod_anti_affinity_preferred or pod_anti_affinity_required:\n        weighted_pod_affinity_terms = None\n        if pod_anti_affinity_preferred:\n            weighted_pod_affinity_terms = [get_k8s_model(V1WeightedPodAffinityTerm, obj) for obj in pod_anti_affinity_preferred]\n\n        pod_affinity_terms = None\n        if pod_anti_affinity_required:\n            pod_affinity_terms = [get_k8s_model(V1PodAffinityTerm, obj) for obj in pod_anti_affinity_required]\n\n        pod_anti_affinity = V1PodAffinity(\n            preferred_during_scheduling_ignored_during_execution=weighted_pod_affinity_terms,\n            required_during_scheduling_ignored_during_execution=pod_affinity_terms,\n        )\n\n    affinity = None\n    if (node_affinity or pod_affinity or pod_anti_affinity):\n        affinity = V1Affinity(\n            node_affinity=node_affinity,\n            pod_affinity=pod_affinity,\n            pod_anti_affinity=pod_anti_affinity,\n        )\n\n    if affinity:\n        pod.spec.affinity = affinity\n\n    if priority_class_name:\n        pod.spec.priority_class_name = priority_class_name\n\n    if extra_pod_config:\n        pod.spec = update_k8s_model(\n            target=pod.spec,\n            changes=extra_pod_config,\n            logger=logger,\n            target_name=\"pod.spec\",\n            changes_name=\"extra_pod_config\",\n        )\n\n    return pod"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a k8s persistent volume claim.", "response": "def make_pvc(\n    name,\n    storage_class,\n    access_modes,\n    storage,\n    labels=None,\n    annotations=None,\n):\n    \"\"\"\n    Make a k8s pvc specification for running a user notebook.\n\n    Parameters\n    ----------\n    name:\n        Name of persistent volume claim. Must be unique within the namespace the object is\n        going to be created in. Must be a valid DNS label.\n    storage_class:\n        String of the name of the k8s Storage Class to use.\n    access_modes:\n        A list of specifying what access mode the pod should have towards the pvc\n    storage:\n        The ammount of storage needed for the pvc\n\n    \"\"\"\n    pvc = V1PersistentVolumeClaim()\n    pvc.kind = \"PersistentVolumeClaim\"\n    pvc.api_version = \"v1\"\n    pvc.metadata = V1ObjectMeta()\n    pvc.metadata.name = name\n    pvc.metadata.annotations = (annotations or {}).copy()\n    pvc.metadata.labels = (labels or {}).copy()\n    pvc.spec = V1PersistentVolumeClaimSpec()\n    pvc.spec.access_modes = access_modes\n    pvc.spec.resources = V1ResourceRequirements()\n    pvc.spec.resources.requests = {\"storage\": storage}\n\n    if storage_class:\n        pvc.metadata.annotations.update({\"volume.beta.kubernetes.io/storage-class\": storage_class})\n        pvc.spec.storage_class_name = storage_class\n\n    return pvc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_ingress(\n        name,\n        routespec,\n        target,\n        data\n):\n    \"\"\"\n    Returns an ingress, service, endpoint object that'll work for this service\n    \"\"\"\n\n    # move beta imports here,\n    # which are more sensitive to kubernetes version\n    # and will change when they move out of beta\n    from kubernetes.client.models import (\n        V1beta1Ingress, V1beta1IngressSpec, V1beta1IngressRule,\n        V1beta1HTTPIngressRuleValue, V1beta1HTTPIngressPath,\n        V1beta1IngressBackend,\n    )\n\n    meta = V1ObjectMeta(\n        name=name,\n        annotations={\n            'hub.jupyter.org/proxy-data': json.dumps(data),\n            'hub.jupyter.org/proxy-routespec': routespec,\n            'hub.jupyter.org/proxy-target': target\n        },\n        labels={\n            'heritage': 'jupyterhub',\n            'component': 'singleuser-server',\n            'hub.jupyter.org/proxy-route': 'true'\n        }\n    )\n\n    if routespec.startswith('/'):\n        host = None\n        path = routespec\n    else:\n        host, path = routespec.split('/', 1)\n\n    target_parts = urlparse(target)\n\n    target_ip = target_parts.hostname\n    target_port = target_parts.port\n\n    target_is_ip = re.match('^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$', target_ip) is not None\n\n    # Make endpoint object\n    if target_is_ip:\n        endpoint = V1Endpoints(\n            kind='Endpoints',\n            metadata=meta,\n            subsets=[\n                V1EndpointSubset(\n                    addresses=[V1EndpointAddress(ip=target_ip)],\n                    ports=[V1EndpointPort(port=target_port)]\n                )\n            ]\n        )\n    else:\n        endpoint = None\n\n    # Make service object\n    if target_is_ip:\n        service = V1Service(\n            kind='Service',\n            metadata=meta,\n            spec=V1ServiceSpec(\n                type='ClusterIP',\n                external_name='',\n                ports=[V1ServicePort(port=target_port, target_port=target_port)]\n            )\n        )\n    else:\n        service = V1Service(\n            kind='Service',\n            metadata=meta,\n            spec=V1ServiceSpec(\n                type='ExternalName',\n                external_name=target_ip,\n                cluster_ip='',\n                ports=[V1ServicePort(port=target_port, target_port=target_port)],\n            ),\n        )\n\n    # Make Ingress object\n    ingress = V1beta1Ingress(\n        kind='Ingress',\n        metadata=meta,\n        spec=V1beta1IngressSpec(\n            rules=[V1beta1IngressRule(\n                host=host,\n                http=V1beta1HTTPIngressRuleValue(\n                    paths=[\n                        V1beta1HTTPIngressPath(\n                            path=path,\n                            backend=V1beta1IngressBackend(\n                                service_name=name,\n                                service_port=target_port\n                            )\n                        )\n                    ]\n                )\n            )]\n        )\n    )\n\n    return endpoint, service, ingress", "response": "Creates an ingress service endpoint object that will work for this service"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a single shared kubernetes client instance", "response": "def shared_client(ClientType, *args, **kwargs):\n    \"\"\"Return a single shared kubernetes client instance\n\n    A weak reference to the instance is cached,\n    so that concurrent calls to shared_client\n    will all return the same instance until\n    all references to the client are cleared.\n    \"\"\"\n    kwarg_key = tuple((key, kwargs[key]) for key in sorted(kwargs))\n    cache_key = (ClientType, args, kwarg_key)\n    client = None\n    if cache_key in _client_cache:\n        # resolve cached weakref\n        # client can still be None after this!\n        client = _client_cache[cache_key]()\n\n    if client is None:\n        Client = getattr(kubernetes.client, ClientType)\n        client = Client(*args, **kwargs)\n        # cache weakref so that clients can be garbage collected\n        _client_cache[cache_key] = weakref.ref(client)\n    return client"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_hashed_slug(slug, limit=63, hash_length=6):\n    if len(slug) < (limit - hash_length):\n        return slug\n\n    slug_hash = hashlib.sha256(slug.encode('utf-8')).hexdigest()\n\n    return '{prefix}-{hash}'.format(\n        prefix=slug[:limit - hash_length - 1],\n        hash=slug_hash[:hash_length],\n    ).lower()", "response": "Generate a hashed version of a slug."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the K8S model with the changes dict.", "response": "def update_k8s_model(target, changes, logger=None, target_name=None, changes_name=None):\n    \"\"\"\n    Takes a model instance such as V1PodSpec() and updates it with another\n    model, which is allowed to be a dict or another model instance of the same\n    type. The logger is used to warn if any truthy value in the target is is\n    overridden. The target_name parameter can for example be \"pod.spec\", and\n    changes_name parameter could be \"extra_pod_config\". These parameters allows\n    the logger to write out something more meaningful to the user whenever\n    something is about to become overridden.\n    \"\"\"\n    model_type = type(target)\n    if not hasattr(target, 'attribute_map'):\n        raise AttributeError(\"Attribute 'target' ({}) must be an object (such as 'V1PodSpec') with an attribute 'attribute_map'.\".format(model_type.__name__))\n    if not isinstance(changes, model_type) and not isinstance(changes, dict):\n        raise AttributeError(\"Attribute 'changes' ({}) must be an object of the same type as 'target' ({}) or a 'dict'.\".format(type(changes).__name__, model_type.__name__))\n\n    changes_dict = _get_k8s_model_dict(model_type, changes)\n    for key, value in changes_dict.items():\n        if key not in target.attribute_map:\n            raise ValueError(\"The attribute 'changes' ({}) contained '{}' not modeled by '{}'.\".format(type(changes).__name__, key, model_type.__name__))\n        \n\n        # If changes are passed as a dict, they will only have a few keys/value\n        # pairs representing the specific changes. If the changes parameter is a\n        # model instance on the other hand, the changes parameter will have a\n        # lot of default values as well. These default values, which are also\n        # falsy, should not use to override the target's values.\n        if isinstance(changes, dict) or value:\n            if getattr(target, key):\n                if logger and changes_name:\n                    warning = \"'{}.{}' current value: '{}' is overridden with '{}', which is the value of '{}.{}'.\".format(\n                        target_name,\n                        key,\n                        getattr(target, key),\n                        value,\n                        changes_name,\n                        key\n                    )\n                    logger.warning(warning)\n            setattr(target, key, value)\n\n    return target"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_k8s_model(model_type, model_dict):\n    model_dict = copy.deepcopy(model_dict)\n\n    if isinstance(model_dict, model_type):\n        return model_dict\n    elif isinstance(model_dict, dict):\n        # convert the dictionaries camelCase keys to snake_case keys\n        model_dict = _map_dict_keys_to_model_attributes(model_type, model_dict)\n        # use the dictionary keys to initialize a model of given type\n        return model_type(**model_dict)\n    else:\n        raise AttributeError(\"Expected object of type 'dict' (or '{}') but got '{}'.\".format(model_type.__name__, type(model_dict).__name__))", "response": "Returns an instance of type specified model_type from an object dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary representation of a provided model type", "response": "def _get_k8s_model_dict(model_type, model):\n    \"\"\"\n    Returns a dictionary representation of a provided model type\n    \"\"\"\n    model = copy.deepcopy(model)\n\n    if isinstance(model, model_type):\n        return model.to_dict()\n    elif isinstance(model, dict):\n        return _map_dict_keys_to_model_attributes(model_type, model)\n    else:\n        raise AttributeError(\"Expected object of type '{}' (or 'dict') but got '{}'.\".format(model_type.__name__, type(model).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _map_dict_keys_to_model_attributes(model_type, model_dict):\n\n    new_dict = {}\n    for key, value in model_dict.items():\n        new_dict[_get_k8s_model_attribute(model_type, key)] = value\n\n    return new_dict", "response": "Maps a dict s keys to the provided models attributes using its attribute_map\n    attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a related Kubernetes API resource attribute name for a given model type and field name.", "response": "def _get_k8s_model_attribute(model_type, field_name):\n    \"\"\"\n    Takes a model type and a Kubernetes API resource field name (such as\n    \"serviceAccount\") and returns a related attribute name (such as\n    \"service_account\") to be used with  kubernetes.client.models objects. It is\n    impossible to prove a negative but it seems like it is always a question of\n    making camelCase to snake_case but by using the provided 'attribute_map' we\n    also ensure that the fields actually exist.\n\n    Example of V1PodSpec's attribute_map:\n    {\n        'active_deadline_seconds': 'activeDeadlineSeconds',\n        'affinity': 'affinity',\n        'automount_service_account_token': 'automountServiceAccountToken',\n        'containers': 'containers',\n        'dns_policy': 'dnsPolicy',\n        'host_aliases': 'hostAliases',\n        'host_ipc': 'hostIPC',\n        'host_network': 'hostNetwork',\n        'host_pid': 'hostPID',\n        'hostname': 'hostname',\n        'image_pull_secrets': 'imagePullSecrets',\n        'init_containers': 'initContainers',\n        'node_name': 'nodeName',\n        'node_selector': 'nodeSelector',\n        'priority': 'priority',\n        'priority_class_name': 'priorityClassName',\n        'restart_policy': 'restartPolicy',\n        'scheduler_name': 'schedulerName',\n        'security_context': 'securityContext',\n        'service_account': 'serviceAccount',\n        'service_account_name': 'serviceAccountName',\n        'subdomain': 'subdomain',\n        'termination_grace_period_seconds': 'terminationGracePeriodSeconds',\n        'tolerations': 'tolerations',\n        'volumes': 'volumes'\n    }\n    \"\"\"\n    # if we get \"service_account\", return\n    if field_name in model_type.attribute_map:\n        return field_name\n\n    # if we get \"serviceAccount\", then return \"service_account\"\n    for key, value in model_type.attribute_map.items():\n        if value == field_name:\n            return key\n    else:\n        raise ValueError(\"'{}' did not have an attribute matching '{}'\".format(model_type.__name__, field_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _list_and_update(self):\n        initial_resources = getattr(self.api, self.list_method_name)(\n            self.namespace,\n            label_selector=self.label_selector,\n            field_selector=self.field_selector,\n            _request_timeout=self.request_timeout,\n        )\n        # This is an atomic operation on the dictionary!\n        self.resources = {p.metadata.name: p for p in initial_resources.items}\n        # return the resource version so we can hook up a watch\n        return initial_resources.metadata.resource_version", "response": "List all current resource info and update self. resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwatches for changes to the current list of resources and updates the local store.", "response": "def _watch_and_update(self):\n        \"\"\"\n        Keeps the current list of resources up-to-date\n\n        This method is to be run not on the main thread!\n\n        We first fetch the list of current resources, and store that. Then we\n        register to be notified of changes to those resources, and keep our\n        local store up-to-date based on these notifications.\n\n        We also perform exponential backoff, giving up after we hit 32s\n        wait time. This should protect against network connections dropping\n        and intermittent unavailability of the api-server. Every time we\n        recover from an exception we also do a full fetch, to pick up\n        changes that might've been missed in the time we were not doing\n        a watch.\n\n        Note that we're playing a bit with fire here, by updating a dictionary\n        in this thread while it is probably being read in another thread\n        without using locks! However, dictionary access itself is atomic,\n        and as long as we don't try to mutate them (do a 'fetch / modify /\n        update' cycle on them), we should be ok!\n        \"\"\"\n        selectors = []\n        log_name = \"\"\n        if self.label_selector:\n            selectors.append(\"label selector=%r\" % self.label_selector)\n        if self.field_selector:\n            selectors.append(\"field selector=%r\" % self.field_selector)\n        log_selector = ', '.join(selectors)\n\n        cur_delay = 0.1\n\n        self.log.info(\n            \"watching for %s with %s in namespace %s\",\n            self.kind, log_selector, self.namespace,\n        )\n        while True:\n            self.log.debug(\"Connecting %s watcher\", self.kind)\n            start = time.monotonic()\n            w = watch.Watch()\n            try:\n                resource_version = self._list_and_update()\n                if not self.first_load_future.done():\n                    # signal that we've loaded our initial data\n                    self.first_load_future.set_result(None)\n                watch_args = {\n                    'namespace': self.namespace,\n                    'label_selector': self.label_selector,\n                    'field_selector': self.field_selector,\n                    'resource_version': resource_version,\n                }\n                if self.request_timeout:\n                    # set network receive timeout\n                    watch_args['_request_timeout'] = self.request_timeout\n                if self.timeout_seconds:\n                    # set watch timeout\n                    watch_args['timeout_seconds'] = self.timeout_seconds\n                # in case of timeout_seconds, the w.stream just exits (no exception thrown)\n                # -> we stop the watcher and start a new one\n                for ev in w.stream(\n                        getattr(self.api, self.list_method_name),\n                        **watch_args\n                ):\n                    cur_delay = 0.1\n                    resource = ev['object']\n                    if ev['type'] == 'DELETED':\n                        # This is an atomic delete operation on the dictionary!\n                        self.resources.pop(resource.metadata.name, None)\n                    else:\n                        # This is an atomic operation on the dictionary!\n                        self.resources[resource.metadata.name] = resource\n                    if self._stop_event.is_set():\n                        self.log.info(\"%s watcher stopped\", self.kind)\n                        break\n                    watch_duration = time.monotonic() - start\n                    if watch_duration >= self.restart_seconds:\n                        self.log.debug(\n                            \"Restarting %s watcher after %i seconds\",\n                            self.kind, watch_duration,\n                        )\n                        break\n            except ReadTimeoutError:\n                # network read time out, just continue and restart the watch\n                # this could be due to a network problem or just low activity\n                self.log.warning(\"Read timeout watching %s, reconnecting\", self.kind)\n                continue\n            except Exception:\n                cur_delay = cur_delay * 2\n                if cur_delay > 30:\n                    self.log.exception(\"Watching resources never recovered, giving up\")\n                    if self.on_failure:\n                        self.on_failure()\n                    return\n                self.log.exception(\"Error when watching resources, retrying in %ss\", cur_delay)\n                time.sleep(cur_delay)\n                continue\n            else:\n                # no events on watch, reconnect\n                self.log.debug(\"%s watcher timeout\", self.kind)\n            finally:\n                w.stop()\n                if self._stop_event.is_set():\n                    self.log.info(\"%s watcher stopped\", self.kind)\n                    break\n        self.log.warning(\"%s watcher finished\", self.kind)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n        if hasattr(self, 'watch_thread'):\n            raise ValueError('Thread watching for resources is already running')\n\n        self._list_and_update()\n        self.watch_thread = threading.Thread(target=self._watch_and_update)\n        # If the watch_thread is only thread left alive, exit app\n        self.watch_thread.daemon = True\n        self.watch_thread.start()", "response": "Start the reflection process for the pod s internal cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a pod manifest that will spawn current user s notebook pod.", "response": "def get_pod_manifest(self):\n        \"\"\"\n        Make a pod manifest that will spawn current user's notebook pod.\n        \"\"\"\n        if callable(self.uid):\n            uid = yield gen.maybe_future(self.uid(self))\n        else:\n            uid = self.uid\n\n        if callable(self.gid):\n            gid = yield gen.maybe_future(self.gid(self))\n        else:\n            gid = self.gid\n\n        if callable(self.fs_gid):\n            fs_gid = yield gen.maybe_future(self.fs_gid(self))\n        else:\n            fs_gid = self.fs_gid\n\n        if callable(self.supplemental_gids):\n            supplemental_gids = yield gen.maybe_future(self.supplemental_gids(self))\n        else:\n            supplemental_gids = self.supplemental_gids\n\n        if self.cmd:\n            real_cmd = self.cmd + self.get_args()\n        else:\n            real_cmd = None\n\n        labels = self._build_pod_labels(self._expand_all(self.extra_labels))\n        annotations = self._build_common_annotations(self._expand_all(self.extra_annotations))\n\n        return make_pod(\n            name=self.pod_name,\n            cmd=real_cmd,\n            port=self.port,\n            image=self.image,\n            image_pull_policy=self.image_pull_policy,\n            image_pull_secret=self.image_pull_secrets,\n            node_selector=self.node_selector,\n            run_as_uid=uid,\n            run_as_gid=gid,\n            fs_gid=fs_gid,\n            supplemental_gids=supplemental_gids,\n            run_privileged=self.privileged,\n            env=self.get_env(),\n            volumes=self._expand_all(self.volumes),\n            volume_mounts=self._expand_all(self.volume_mounts),\n            working_dir=self.working_dir,\n            labels=labels,\n            annotations=annotations,\n            cpu_limit=self.cpu_limit,\n            cpu_guarantee=self.cpu_guarantee,\n            mem_limit=self.mem_limit,\n            mem_guarantee=self.mem_guarantee,\n            extra_resource_limits=self.extra_resource_limits,\n            extra_resource_guarantees=self.extra_resource_guarantees,\n            lifecycle_hooks=self.lifecycle_hooks,\n            init_containers=self._expand_all(self.init_containers),\n            service_account=self.service_account,\n            extra_container_config=self.extra_container_config,\n            extra_pod_config=self.extra_pod_config,\n            extra_containers=self._expand_all(self.extra_containers),\n            scheduler_name=self.scheduler_name,\n            tolerations=self.tolerations,\n            node_affinity_preferred=self.node_affinity_preferred,\n            node_affinity_required=self.node_affinity_required,\n            pod_affinity_preferred=self.pod_affinity_preferred,\n            pod_affinity_required=self.pod_affinity_required,\n            pod_anti_affinity_preferred=self.pod_anti_affinity_preferred,\n            pod_anti_affinity_required=self.pod_anti_affinity_required,\n            priority_class_name=self.priority_class_name,\n            logger=self.log,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_pvc_manifest(self):\n        labels = self._build_common_labels(self._expand_all(self.storage_extra_labels))\n        labels.update({\n            'component': 'singleuser-storage'\n        })\n\n        annotations = self._build_common_annotations({})\n\n        return make_pvc(\n            name=self.pvc_name,\n            storage_class=self.storage_class,\n            access_modes=self.storage_access_modes,\n            storage=self.storage_capacity,\n            labels=labels,\n            annotations=annotations\n        )", "response": "Returns a pvc manifest that will spawn current user s pvc."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the given pod is running.", "response": "def is_pod_running(self, pod):\n        \"\"\"\n        Check if the given pod is running\n\n        pod must be a dictionary representing a Pod kubernetes API object.\n        \"\"\"\n        # FIXME: Validate if this is really the best way\n        is_running = (\n            pod is not None and\n            pod.status.phase == 'Running' and\n            pod.status.pod_ip is not None and\n            pod.metadata.deletion_timestamp is None and\n            all([cs.ready for cs in pod.status.container_statuses])\n        )\n        return is_running"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the environment dict to use for the Spawner.", "response": "def get_env(self):\n        \"\"\"Return the environment dict to use for the Spawner.\n\n        See also: jupyterhub.Spawner.get_env\n        \"\"\"\n\n        env = super(KubeSpawner, self).get_env()\n        # deprecate image\n        env['JUPYTER_IMAGE_SPEC'] = self.image\n        env['JUPYTER_IMAGE'] = self.image\n\n        return env"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef poll(self):\n        # have to wait for first load of data before we have a valid answer\n        if not self.pod_reflector.first_load_future.done():\n            yield self.pod_reflector.first_load_future\n        data = self.pod_reflector.pods.get(self.pod_name, None)\n        if data is not None:\n            if data.status.phase == 'Pending':\n                return None\n            ctr_stat = data.status.container_statuses\n            if ctr_stat is None:  # No status, no container (we hope)\n                # This seems to happen when a pod is idle-culled.\n                return 1\n            for c in ctr_stat:\n                # return exit code if notebook container has terminated\n                if c.name == 'notebook':\n                    if c.state.terminated:\n                        # call self.stop to delete the pod\n                        if self.delete_stopped_pods:\n                            yield self.stop(now=True)\n                        return c.state.terminated.exit_code\n                    break\n            # None means pod is running or starting up\n            return None\n        # pod doesn't exist or has been deleted\n        return 1", "response": "Poll the pod for a specific entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef events(self):\n        if not self.event_reflector:\n            return []\n\n        events = []\n        for event in self.event_reflector.events:\n            if event.involved_object.name != self.pod_name:\n                # only consider events for my pod name\n                continue\n\n            if self._last_event and event.metadata.uid == self._last_event:\n                # saw last_event marker, ignore any previous events\n                # and only consider future events\n                # only include events *after* our _last_event marker\n                events = []\n            else:\n                events.append(event)\n        return events", "response": "Filter event - reflector to just our events\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a shared reflector on the KubeSpawner class.", "response": "def _start_reflector(self, key, ReflectorClass, replace=False, **kwargs):\n        \"\"\"Start a shared reflector on the KubeSpawner class\n\n\n        key: key for the reflector (e.g. 'pod' or 'events')\n        Reflector: Reflector class to be instantiated\n        kwargs: extra keyword-args to be relayed to ReflectorClass\n\n        If replace=False and the pod reflector is already running,\n        do nothing.\n\n        If replace=True, a running pod reflector will be stopped\n        and a new one started (for recovering from possible errors).\n        \"\"\"\n        main_loop = IOLoop.current()\n        def on_reflector_failure():\n            self.log.critical(\n                \"%s reflector failed, halting Hub.\",\n                key.title(),\n            )\n            sys.exit(1)\n\n        previous_reflector = self.__class__.reflectors.get(key)\n\n        if replace or not previous_reflector:\n            self.__class__.reflectors[key] = ReflectorClass(\n                parent=self,\n                namespace=self.namespace,\n                on_failure=on_reflector_failure,\n                **kwargs,\n            )\n\n        if replace and previous_reflector:\n            # we replaced the reflector, stop the old one\n            previous_reflector.stop()\n\n        # return the current reflector\n        return self.__class__.reflectors[key]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _start_watching_events(self, replace=False):\n        return self._start_reflector(\n            \"events\",\n            EventReflector,\n            fields={\"involvedObject.kind\": \"Pod\"},\n            replace=replace,\n        )", "response": "Start the events reflector"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the user s pod.", "response": "def _start(self):\n        \"\"\"Start the user's pod\"\"\"\n\n        # load user options (including profile)\n        yield self.load_user_options()\n\n        # record latest event so we don't include old\n        # events from previous pods in self.events\n        # track by order and name instead of uid\n        # so we get events like deletion of a previously stale\n        # pod if it's part of this spawn process\n        events = self.events\n        if events:\n            self._last_event = events[-1].metadata.uid\n\n        if self.storage_pvc_ensure:\n            # Try and create the pvc. If it succeeds we are good. If\n            # returns a 409 indicating it already exists we are good. If\n            # it returns a 403, indicating potential quota issue we need\n            # to see if pvc already exists before we decide to raise the\n            # error for quota being exceeded. This is because quota is\n            # checked before determining if the PVC needed to be\n            # created.\n\n            pvc = self.get_pvc_manifest()\n\n            try:\n                yield self.asynchronize(\n                    self.api.create_namespaced_persistent_volume_claim,\n                    namespace=self.namespace,\n                    body=pvc\n                )\n            except ApiException as e:\n                if e.status == 409:\n                    self.log.info(\"PVC \" + self.pvc_name + \" already exists, so did not create new pvc.\")\n\n                elif e.status == 403:\n                    t, v, tb = sys.exc_info()\n\n                    try:\n                        yield self.asynchronize(\n                            self.api.read_namespaced_persistent_volume_claim,\n                            name=self.pvc_name,\n                            namespace=self.namespace)\n\n                    except ApiException as e:\n                        raise v.with_traceback(tb)\n\n                    self.log.info(\"PVC \" + self.pvc_name + \" already exists, possibly have reached quota though.\")\n\n                else:\n                    raise\n\n        # If we run into a 409 Conflict error, it means a pod with the\n        # same name already exists. We stop it, wait for it to stop, and\n        # try again. We try 4 times, and if it still fails we give up.\n        # FIXME: Have better / cleaner retry logic!\n        retry_times = 4\n        pod = yield self.get_pod_manifest()\n        if self.modify_pod_hook:\n            pod = yield gen.maybe_future(self.modify_pod_hook(self, pod))\n        for i in range(retry_times):\n            try:\n                yield self.asynchronize(\n                    self.api.create_namespaced_pod,\n                    self.namespace,\n                    pod,\n                )\n                break\n            except ApiException as e:\n                if e.status != 409:\n                    # We only want to handle 409 conflict errors\n                    self.log.exception(\"Failed for %s\", pod.to_str())\n                    raise\n                self.log.info('Found existing pod %s, attempting to kill', self.pod_name)\n                # TODO: this should show up in events\n                yield self.stop(True)\n\n                self.log.info('Killed pod %s, will try starting singleuser pod again', self.pod_name)\n        else:\n            raise Exception(\n                'Can not create user pod %s already exists & could not be deleted' % self.pod_name)\n\n        # we need a timeout here even though start itself has a timeout\n        # in order for this coroutine to finish at some point.\n        # using the same start_timeout here\n        # essentially ensures that this timeout should never propagate up\n        # because the handler will have stopped waiting after\n        # start_timeout, starting from a slightly earlier point.\n        try:\n            yield exponential_backoff(\n                lambda: self.is_pod_running(self.pod_reflector.pods.get(self.pod_name, None)),\n                'pod/%s did not start in %s seconds!' % (self.pod_name, self.start_timeout),\n                timeout=self.start_timeout,\n            )\n        except TimeoutError:\n            if self.pod_name not in self.pod_reflector.pods:\n                # if pod never showed up at all,\n                # restart the pod reflector which may have become disconnected.\n                self.log.error(\n                    \"Pod %s never showed up in reflector, restarting pod reflector\",\n                    self.pod_name,\n                )\n                self._start_watching_pods(replace=True)\n            raise\n\n        pod = self.pod_reflector.pods[self.pod_name]\n        self.pod_id = pod.metadata.uid\n        if self.event_reflector:\n            self.log.debug(\n                'pod %s events before launch: %s',\n                self.pod_name,\n                \"\\n\".join(\n                    [\n                        \"%s [%s] %s\" % (event.last_timestamp, event.type, event.message)\n                        for event in self.events\n                    ]\n                ),\n            )\n        return (pod.status.pod_ip, self.port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _options_form_default(self):\n        '''\n        Build the form template according to the `profile_list` setting.\n\n        Returns:\n            '' when no `profile_list` has been defined\n            The rendered template (using jinja2) when `profile_list` is defined.\n        '''\n        if not self.profile_list:\n            return ''\n        if callable(self.profile_list):\n            return self._render_options_form_dynamically\n        else:\n            return self._render_options_form(self.profile_list)", "response": "Build the options form template according to the profile_list setting."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the user options from the form", "response": "def options_from_form(self, formdata):\n        \"\"\"get the option selected by the user on the form\n\n        This only constructs the user_options dict,\n        it should not actually load any options.\n        That is done later in `.load_user_options()`\n\n        Args:\n            formdata: user selection returned by the form\n\n        To access to the value, you can use the `get` accessor and the name of the html element,\n        for example::\n\n            formdata.get('profile',[0])\n\n        to get the value of the form named \"profile\", as defined in `form_template`::\n\n            <select class=\"form-control\" name=\"profile\"...>\n            </select>\n\n        Returns:\n            user_options (dict): the selected profile in the user_options form,\n                e.g. ``{\"profile\": \"8 CPUs\"}``\n        \"\"\"\n        if not self.profile_list or self._profile_list is None:\n            return formdata\n        # Default to first profile if somehow none is provided\n        try:\n            selected_profile = int(formdata.get('profile', [0])[0])\n            options = self._profile_list[selected_profile]\n        except (TypeError, IndexError, ValueError):\n            raise web.HTTPError(400, \"No such profile: %i\", formdata.get('profile', None))\n        return {\n            'profile': options['display_name']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_profile(self, profile_name):\n\n        # find the profile\n        default_profile = self._profile_list[0]\n        for profile in self._profile_list:\n            if profile.get('default', False):\n                # explicit default, not the first\n                default_profile = profile\n\n            if profile['display_name'] == profile_name:\n                break\n        else:\n            if profile_name:\n                # name specified, but not found\n                raise ValueError(\"No such profile: %s. Options include: %s\" % (\n                    profile_name, ', '.join(p['display_name'] for p in self._profile_list)\n                ))\n            else:\n                # no name specified, use the default\n                profile = default_profile\n\n        self.log.debug(\"Applying KubeSpawner override for profile '%s'\", profile['display_name'])\n        kubespawner_override = profile.get('kubespawner_override', {})\n        for k, v in kubespawner_override.items():\n            if callable(v):\n                v = v(self)\n                self.log.debug(\".. overriding KubeSpawner value %s=%s (callable result)\", k, v)\n            else:\n                self.log.debug(\".. overriding KubeSpawner value %s=%s\", k, v)\n            setattr(self, k, v)", "response": "Load a profile by name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload user options from self. user_options dict.", "response": "def load_user_options(self):\n        \"\"\"Load user options from self.user_options dict\n\n        This can be set via POST to the API or via options_from_form\n\n        Only supported argument by default is 'profile'.\n        Override in subclasses to support other options.\n        \"\"\"\n        if self._profile_list is None:\n            if callable(self.profile_list):\n                self._profile_list = yield gen.maybe_future(self.profile_list(self))\n            else:\n                self._profile_list = self.profile_list\n        if self._profile_list:\n            yield self._load_profile(self.user_options.get('profile', None))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_object_members(self, want_all):\n        check, members = super().get_object_members(want_all)\n        get_traits = self.object.class_own_traits if self.options.inherited_members \\\n                     else self.object.class_traits\n        trait_members = []\n        for name, trait in sorted(get_traits(config=True).items()):\n            # put help in __doc__ where autodoc will look for it\n            trait.__doc__ = trait.help\n            trait_members.append((name, trait))\n        return check, trait_members + members", "response": "Add traits with. tag to members list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the native speed measurement required to achieve desired rotations - per - second.", "response": "def to_native_units(self, motor):\n        \"\"\"\n        Return the native speed measurement required to achieve desired rotations-per-second\n        \"\"\"\n        assert abs(self.rotations_per_second) <= motor.max_rps,\\\n            \"invalid rotations-per-second: {} max RPS is {}, {} was requested\".format(\n            motor, motor.max_rps, self.rotations_per_second)\n        return self.rotations_per_second/motor.max_rps * motor.max_speed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the native speed measurement required to achieve desired rotations - per - minute.", "response": "def to_native_units(self, motor):\n        \"\"\"\n        Return the native speed measurement required to achieve desired rotations-per-minute\n        \"\"\"\n        assert abs(self.rotations_per_minute) <= motor.max_rpm,\\\n            \"invalid rotations-per-minute: {} max RPM is {}, {} was requested\".format(\n            motor, motor.max_rpm, self.rotations_per_minute)\n        return self.rotations_per_minute/motor.max_rpm * motor.max_speed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_native_units(self, motor):\n        assert abs(self.degrees_per_second) <= motor.max_dps,\\\n            \"invalid degrees-per-second: {} max DPS is {}, {} was requested\".format(\n            motor, motor.max_dps, self.degrees_per_second)\n        return self.degrees_per_second/motor.max_dps * motor.max_speed", "response": "Return the native speed measurement required to achieve desired degrees - per - second."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the native speed measurement required to achieve desired degrees - per - minute.", "response": "def to_native_units(self, motor):\n        \"\"\"\n        Return the native speed measurement required to achieve desired degrees-per-minute\n        \"\"\"\n        assert abs(self.degrees_per_minute) <= motor.max_dpm,\\\n            \"invalid degrees-per-minute: {} max DPM is {}, {} was requested\".format(\n            motor, motor.max_dpm, self.degrees_per_minute)\n        return self.degrees_per_minute/motor.max_dpm * motor.max_speed"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the name of the port that this motor is connected to.", "response": "def address(self):\n        \"\"\"\n        Returns the name of the port that this motor is connected to.\n        \"\"\"\n        self._address, value = self.get_attr_string(self._address, 'address')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of commands that are supported by the motor controller. Possible values are run - forever run - to - abs - pos run - to - rel - pos stop - to - direct stop and reset.", "response": "def commands(self):\n        \"\"\"\n        Returns a list of commands that are supported by the motor\n        controller. Possible values are `run-forever`, `run-to-abs-pos`, `run-to-rel-pos`,\n        `run-timed`, `run-direct`, `stop` and `reset`. Not all commands may be supported.\n\n        - `run-forever` will cause the motor to run until another command is sent.\n        - `run-to-abs-pos` will run to an absolute position specified by `position_sp`\n          and then stop using the action specified in `stop_action`.\n        - `run-to-rel-pos` will run to a position relative to the current `position` value.\n          The new position will be current `position` + `position_sp`. When the new\n          position is reached, the motor will stop using the action specified by `stop_action`.\n        - `run-timed` will run the motor for the amount of time specified in `time_sp`\n          and then stop the motor using the action specified by `stop_action`.\n        - `run-direct` will run the motor at the duty cycle specified by `duty_cycle_sp`.\n          Unlike other run commands, changing `duty_cycle_sp` while running *will*\n          take effect immediately.\n        - `stop` will stop any of the run commands before they are complete using the\n          action specified by `stop_action`.\n        - `reset` will reset all of the motor parameter attributes to their default value.\n          This will also have the effect of stopping the motor.\n        \"\"\"\n        (self._commands, value) = self.get_cached_attr_set(self._commands, 'commands')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count_per_rot(self):\n        (self._count_per_rot, value) = self.get_cached_attr_int(self._count_per_rot, 'count_per_rot')\n        return value", "response": "Returns the number of tacho counts in one rotation of the motor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef count_per_m(self):\n        (self._count_per_m, value) = self.get_cached_attr_int(self._count_per_m, 'count_per_m')\n        return value", "response": "Returns the number of tacho counts in one meter of travel of the motor."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the name of the driver that provides this tacho motor device.", "response": "def driver_name(self):\n        \"\"\"\n        Returns the name of the driver that provides this tacho motor device.\n        \"\"\"\n        (self._driver_name, value) = self.get_cached_attr_string(self._driver_name, 'driver_name')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads and returns the current duty cycle setpoint.", "response": "def duty_cycle_sp(self):\n        \"\"\"\n        Writing sets the duty cycle setpoint. Reading returns the current value.\n        Units are in percent. Valid values are -100 to 100. A negative value causes\n        the motor to rotate in reverse.\n        \"\"\"\n        self._duty_cycle_sp, value = self.get_attr_int(self._duty_cycle_sp, 'duty_cycle_sp')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the number of tacho counts in the full travel of the motor.", "response": "def full_travel_count(self):\n        \"\"\"\n        Returns the number of tacho counts in the full travel of the motor. When\n        combined with the `count_per_m` atribute, you can use this value to\n        calculate the maximum travel distance of the motor. (linear motors only)\n        \"\"\"\n        (self._full_travel_count, value) = self.get_cached_attr_int(self._full_travel_count, 'full_travel_count')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the polarity of the log entry.", "response": "def polarity(self):\n        \"\"\"\n        Sets the polarity of the motor. With `normal` polarity, a positive duty\n        cycle will cause the motor to rotate clockwise. With `inversed` polarity,\n        a positive duty cycle will cause the motor to rotate counter-clockwise.\n        Valid values are `normal` and `inversed`.\n        \"\"\"\n        self._polarity, value = self.get_attr_string(self._polarity, 'polarity')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef position(self):\n        self._position, value = self.get_attr_int(self._position, 'position')\n        return value", "response": "Returns the current position of the rotary Arc Arc."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef position_p(self):\n        self._position_p, value = self.get_attr_int(self._position_p, 'hold_pid/Kp')\n        return value", "response": "Returns the proportional constant for the position PID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef position_i(self):\n        self._position_i, value = self.get_attr_int(self._position_i, 'hold_pid/Ki')\n        return value", "response": "Returns the integer constant for the position PID."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the derivative constant for the position PID.", "response": "def position_d(self):\n        \"\"\"\n        The derivative constant for the position PID.\n        \"\"\"\n        self._position_d, value = self.get_attr_int(self._position_d, 'hold_pid/Kd')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the current value of the position_sp attribute.", "response": "def position_sp(self):\n        \"\"\"\n        Writing specifies the target position for the `run-to-abs-pos` and `run-to-rel-pos`\n        commands. Reading returns the current value. Units are in tacho counts. You\n        can use the value returned by `count_per_rot` to convert tacho counts to/from\n        rotations or degrees.\n        \"\"\"\n        self._position_sp, value = self.get_attr_int(self._position_sp, 'position_sp')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef max_speed(self):\n        (self._max_speed, value) = self.get_cached_attr_int(self._max_speed, 'max_speed')\n        return value", "response": "Returns the maximum speed that can be used by the speed_sp attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef speed(self):\n        self._speed, value = self.get_attr_int(self._speed, 'speed')\n        return value", "response": "Returns the current motor speed in tacho counts per second."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef speed_sp(self):\n        self._speed_sp, value = self.get_attr_int(self._speed_sp, 'speed_sp')\n        return value", "response": "Reads the current value of speed_sp and sets it to the value used for all run - direct and run - to - * commands except run - direct."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ramp_up_sp(self):\n        self._ramp_up_sp, value = self.get_attr_int(self._ramp_up_sp, 'ramp_up_sp')\n        return value", "response": "Reads sets the ramp up setpoint. Reading returns the current value. Units\n        are in milliseconds."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread sets the ramp down setpoint. Reading returns the current value.", "response": "def ramp_down_sp(self):\n        \"\"\"\n        Writing sets the ramp down setpoint. Reading returns the current value. Units\n        are in milliseconds and must be positive. When set to a non-zero value, the\n        motor speed will decrease from 0 to 100% of `max_speed` over the span of this\n        setpoint. The actual ramp time is the ratio of the difference between the\n        `speed_sp` and the current `speed` and max_speed multiplied by `ramp_down_sp`.\n        \"\"\"\n        self._ramp_down_sp, value = self.get_attr_int(self._ramp_down_sp, 'ramp_down_sp')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef speed_p(self):\n        self._speed_p, value = self.get_attr_int(self._speed_p, 'speed_pid/Kp')\n        return value", "response": "Returns the proportional constant for the speed regulation PID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef speed_i(self):\n        self._speed_i, value = self.get_attr_int(self._speed_i, 'speed_pid/Ki')\n        return value", "response": "Returns the integer constant for the speed regulation PID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the derivative constant for the speed regulation PID.", "response": "def speed_d(self):\n        \"\"\"\n        The derivative constant for the speed regulation PID.\n        \"\"\"\n        self._speed_d, value = self.get_attr_int(self._speed_d, 'speed_pid/Kd')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of state flags. Possible flags are running ramping holding overloaded and stalled.", "response": "def state(self):\n        \"\"\"\n        Reading returns a list of state flags. Possible flags are\n        `running`, `ramping`, `holding`, `overloaded` and `stalled`.\n        \"\"\"\n        self._state, value = self.get_attr_set(self._state, 'state')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread returns the current stop action. Writing sets the stop action.", "response": "def stop_action(self):\n        \"\"\"\n        Reading returns the current stop action. Writing sets the stop action.\n        The value determines the motors behavior when `command` is set to `stop`.\n        Also, it determines the motors behavior when a run command completes. See\n        `stop_actions` for a list of possible values.\n        \"\"\"\n        self._stop_action, value = self.get_attr_string(self._stop_action, 'stop_action')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_actions(self):\n        (self._stop_actions, value) = self.get_cached_attr_set(self._stop_actions, 'stop_actions')\n        return value", "response": "Returns a list of stop actions supported by the motor controller."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef time_sp(self):\n        self._time_sp, value = self.get_attr_int(self._time_sp, 'time_sp')\n        return value", "response": "Returns the amount of time the motor will run when using the\n        run - timed command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_forever(self, **kwargs):\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_RUN_FOREVER", "response": "Run the motor until another command is sent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_to_abs_pos(self, **kwargs):\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_RUN_TO_ABS_POS", "response": "This method is used to set the command to run to an absolute position specified by position_sp and then\n            stop using the action specified by stop_action."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_to_rel_pos(self, **kwargs):\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_RUN_TO_REL_POS", "response": "Run to a position relative to the current position value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_timed(self, **kwargs):\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_RUN_TIMED", "response": "Runs the motor for the amount of time specified in time_sp and then stops the motor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the motor at the duty cycle specified by `duty_cycle_sp`. Unlike other run commands, changing `duty_cycle_sp` while running *will* take effect immediately.", "response": "def run_direct(self, **kwargs):\n        \"\"\"\n        Run the motor at the duty cycle specified by `duty_cycle_sp`.\n        Unlike other run commands, changing `duty_cycle_sp` while running *will*\n        take effect immediately.\n        \"\"\"\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_RUN_DIRECT"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop(self, **kwargs):\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_STOP", "response": "Stop any of the run commands before they are complete using the stop_action action specified by stop_action."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets all of the motor parameter attributes to their default value.", "response": "def reset(self, **kwargs):\n        \"\"\"\n        Reset all of the motor parameter attributes to their default value.\n        This will also have the effect of stopping the motor.\n        \"\"\"\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_RESET"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nblocks until condition is met.", "response": "def wait(self, cond, timeout=None):\n        \"\"\"\n        Blocks until ``cond(self.state)`` is ``True``.  The condition is\n        checked when there is an I/O event related to the ``state`` attribute.\n        Exits early when ``timeout`` (in milliseconds) is reached.\n\n        Returns ``True`` if the condition is met, and ``False`` if the timeout\n        is reached.\n        \"\"\"\n\n        tic = time.time()\n\n        if self._poll is None:\n            if self._state is None:\n                self._state = self._attribute_file_open('state')\n            self._poll = select.poll()\n            self._poll.register(self._state, select.POLLPRI)\n\n        # Set poll timeout to something small. For more details, see\n        # https://github.com/ev3dev/ev3dev-lang-python/issues/583\n        if timeout:\n            poll_tm = min(timeout, 100)\n        else:\n            poll_tm = 100\n\n        while True:\n            # This check is now done every poll_tm even if poll has nothing to report:\n            if cond(self.state):\n                return True\n\n            self._poll.poll(poll_tm)\n\n            if timeout is not None and time.time() >= tic + timeout / 1000:\n                # Final check when user timeout is reached\n                return cond(self.state)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nblocking until the I/O event is not migrated.", "response": "def wait_until_not_moving(self, timeout=None):\n        \"\"\"\n        Blocks until ``running`` is not in ``self.state`` or ``stalled`` is in\n        ``self.state``.  The condition is checked when there is an I/O event\n        related to the ``state`` attribute.  Exits early when ``timeout``\n        (in milliseconds) is reached.\n\n        Returns ``True`` if the condition is met, and ``False`` if the timeout\n        is reached.\n\n        Example::\n\n            m.wait_until_not_moving()\n        \"\"\"\n        return self.wait(lambda state: self.STATE_RUNNING not in state or self.STATE_STALLED in state, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait_until(self, s, timeout=None):\n        return self.wait(lambda state: s in state, timeout)", "response": "Blocks until s is in self. state. Returns True if the condition is met False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nblocks until s is in state and is not in state.", "response": "def wait_while(self, s, timeout=None):\n        \"\"\"\n        Blocks until ``s`` is not in ``self.state``.  The condition is checked\n        when there is an I/O event related to the ``state`` attribute.  Exits\n        early when ``timeout`` (in milliseconds) is reached.\n\n        Returns ``True`` if the condition is met, and ``False`` if the timeout\n        is reached.\n\n        Example::\n\n            m.wait_while('running')\n        \"\"\"\n        return self.wait(lambda state: s not in state, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_for_rotations(self, speed, rotations, brake=True, block=True):\n        speed_sp = self._speed_native_units(speed)\n        self._set_rel_position_degrees_and_speed_sp(rotations * 360, speed_sp)\n        self._set_brake(brake)\n        self.run_to_rel_pos()\n\n        if block:\n            self.wait_until('running', timeout=WAIT_RUNNING_TIMEOUT)\n            self.wait_until_not_moving()", "response": "Rotate the motors at speed for rotations."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_for_degrees(self, speed, degrees, brake=True, block=True):\n        speed_sp = self._speed_native_units(speed)\n        self._set_rel_position_degrees_and_speed_sp(degrees, speed_sp)\n        self._set_brake(brake)\n        self.run_to_rel_pos()\n\n        if block:\n            self.wait_until('running', timeout=WAIT_RUNNING_TIMEOUT)\n            self.wait_until_not_moving()", "response": "Rotate the motors at speed for degrees."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrotate the motors at speed to position.", "response": "def on_to_position(self, speed, position, brake=True, block=True):\n        \"\"\"\n        Rotate the motor at ``speed`` to ``position``\n\n        ``speed`` can be a percentage or a :class:`ev3dev2.motor.SpeedValue`\n        object, enabling use of other units.\n        \"\"\"\n        speed = self._speed_native_units(speed)\n        self.speed_sp = int(round(speed))\n        self.position_sp = position\n        self._set_brake(brake)\n        self.run_to_abs_pos()\n\n        if block:\n            self.wait_until('running', timeout=WAIT_RUNNING_TIMEOUT)\n            self.wait_until_not_moving()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrotate the motors at speed for seconds.", "response": "def on_for_seconds(self, speed, seconds, brake=True, block=True):\n        \"\"\"\n        Rotate the motor at ``speed`` for ``seconds``\n\n        ``speed`` can be a percentage or a :class:`ev3dev2.motor.SpeedValue`\n        object, enabling use of other units.\n        \"\"\"\n\n        if seconds < 0:\n            raise ValueError(\"seconds is negative ({})\".format(seconds))\n\n        speed = self._speed_native_units(speed)\n        self.speed_sp = int(round(speed))\n        self.time_sp = int(seconds * 1000)\n        self._set_brake(brake)\n        self.run_timed()\n\n        if block:\n            self.wait_until('running', timeout=WAIT_RUNNING_TIMEOUT)\n            self.wait_until_not_moving()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on(self, speed, brake=True, block=False):\n        speed = self._speed_native_units(speed)\n        self.speed_sp = int(round(speed))\n        self._set_brake(brake)\n        self.run_forever()\n\n        if block:\n            self.wait_until('running', timeout=WAIT_RUNNING_TIMEOUT)\n            self.wait_until_not_moving()", "response": "Rotate the motors at speed for forever."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commands(self):\n        self._commands, value = self.get_attr_set(self._commands, 'commands')\n        return value", "response": "Returns a list of commands supported by the motor\n        controller."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef driver_name(self):\n        self._driver_name, value = self.get_attr_string(self._driver_name, 'driver_name')\n        return value", "response": "Returns the name of the motor driver that loaded this device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop_actions(self):\n        self._stop_actions, value = self.get_attr_set(self._stop_actions, 'stop_actions')\n        return value", "response": "Gets a list of stop actions. Valid values are coast and brake."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the pulse size in milliseconds for the current time series of the current log entry.", "response": "def max_pulse_sp(self):\n        \"\"\"\n        Used to set the pulse size in milliseconds for the signal that tells the\n        servo to drive to the maximum (clockwise) position_sp. Default value is 2400.\n        Valid values are 2300 to 2700. You must write to the position_sp attribute for\n        changes to this attribute to take effect.\n        \"\"\"\n        self._max_pulse_sp, value = self.get_attr_int(self._max_pulse_sp, 'max_pulse_sp')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mid_pulse_sp(self):\n        self._mid_pulse_sp, value = self.get_attr_int(self._mid_pulse_sp, 'mid_pulse_sp')\n        return value", "response": "Sets the pulse size in milliseconds for the current time series of the mid position_sp."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the pulse size in milliseconds for the current time interval for the current time interval.", "response": "def min_pulse_sp(self):\n        \"\"\"\n        Used to set the pulse size in milliseconds for the signal that tells the\n        servo to drive to the miniumum (counter-clockwise) position_sp. Default value\n        is 600. Valid values are 300 to 700. You must write to the position_sp\n        attribute for changes to this attribute to take effect.\n        \"\"\"\n        self._min_pulse_sp, value = self.get_attr_int(self._min_pulse_sp, 'min_pulse_sp')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rate_sp(self):\n        self._rate_sp, value = self.get_attr_int(self._rate_sp, 'rate_sp')\n        return value", "response": "Sets the rate_sp of the servo to the desired value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, **kwargs):\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_RUN", "response": "This method is called by the base class to set the command to run."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef float(self, **kwargs):\n        for key in kwargs:\n            setattr(self, key, kwargs[key])\n        self.command = self.COMMAND_FLOAT", "response": "Set the motor to send a float command"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef off(self, motors=None, brake=True):\n        motors = motors if motors is not None else self.motors.values()\n\n        for motor in motors:\n            motor._set_brake(brake)\n\n        for motor in motors:\n            motor.stop()", "response": "Stop motors immediately. Configure motors to brake if ``brake`` is set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrotating the motors at left_speed & right_speed for degrees.", "response": "def on_for_degrees(self, left_speed, right_speed, degrees, brake=True, block=True):\n        \"\"\"\n        Rotate the motors at 'left_speed & right_speed' for 'degrees'. Speeds\n        can be percentages or any SpeedValue implementation.\n\n        If the left speed is not equal to the right speed (i.e., the robot will\n        turn), the motor on the outside of the turn will rotate for the full\n        ``degrees`` while the motor on the inside will have its requested\n        distance calculated according to the expected turn.\n        \"\"\"\n        (left_speed_native_units, right_speed_native_units) = self._unpack_speeds_to_native_units(left_speed, right_speed)\n\n        # proof of the following distance calculation: consider the circle formed by each wheel's path\n        # v_l = d_l/t, v_r = d_r/t\n        # therefore, t = d_l/v_l = d_r/v_r\n\n        if degrees == 0 or (left_speed_native_units == 0 and right_speed_native_units == 0):\n            left_degrees = degrees\n            right_degrees = degrees\n\n        # larger speed by magnitude is the \"outer\" wheel, and rotates the full \"degrees\"\n        elif abs(left_speed_native_units) > abs(right_speed_native_units):\n            left_degrees = degrees\n            right_degrees = abs(right_speed_native_units / left_speed_native_units) * degrees\n\n        else:\n            left_degrees = abs(left_speed_native_units / right_speed_native_units) * degrees\n            right_degrees = degrees\n\n        # Set all parameters\n        self.left_motor._set_rel_position_degrees_and_speed_sp(left_degrees, left_speed_native_units)\n        self.left_motor._set_brake(brake)\n        self.right_motor._set_rel_position_degrees_and_speed_sp(right_degrees, right_speed_native_units)\n        self.right_motor._set_brake(brake)\n\n        log.debug(\"{}: on_for_degrees {}\".format(self, degrees))\n\n        # These debugs involve disk I/O to pull position and position_sp so only uncomment\n        # if you need to troubleshoot in more detail.\n        # log.debug(\"{}: left_speed {}, left_speed_native_units {}, left_degrees {}, left-position {}->{}\".format(\n        #     self, left_speed, left_speed_native_units, left_degrees,\n        #     self.left_motor.position, self.left_motor.position_sp))\n        # log.debug(\"{}: right_speed {}, right_speed_native_units {}, right_degrees {}, right-position {}->{}\".format(\n        #     self, right_speed, right_speed_native_units, right_degrees,\n        #     self.right_motor.position, self.right_motor.position_sp))\n\n        # Start the motors\n        self.left_motor.run_to_rel_pos()\n        self.right_motor.run_to_rel_pos()\n\n        if block:\n            self._block()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_for_rotations(self, left_speed, right_speed, rotations, brake=True, block=True):\n        MoveTank.on_for_degrees(self, left_speed, right_speed, rotations * 360, brake, block)", "response": "Rotate the motors at left_speed & right_speed for rotations degrees."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrotates the motors at left_speed & right_speed for seconds.", "response": "def on_for_seconds(self, left_speed, right_speed, seconds, brake=True, block=True):\n        \"\"\"\n        Rotate the motors at 'left_speed & right_speed' for 'seconds'. Speeds\n        can be percentages or any SpeedValue implementation.\n        \"\"\"\n\n        if seconds < 0:\n            raise ValueError(\"seconds is negative ({})\".format(seconds))\n\n        (left_speed_native_units, right_speed_native_units) = self._unpack_speeds_to_native_units(left_speed, right_speed)\n\n        # Set all parameters\n        self.left_motor.speed_sp = int(round(left_speed_native_units))\n        self.left_motor.time_sp = int(seconds * 1000)\n        self.left_motor._set_brake(brake)\n        self.right_motor.speed_sp = int(round(right_speed_native_units))\n        self.right_motor.time_sp = int(seconds * 1000)\n        self.right_motor._set_brake(brake)\n\n        log.debug(\"%s: on_for_seconds %ss at left-speed %s, right-speed %s\" %\n            (self, seconds, left_speed, right_speed))\n\n        # Start the motors\n        self.left_motor.run_timed()\n        self.right_motor.run_timed()\n\n        if block:\n            self._block()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on(self, left_speed, right_speed):\n        (left_speed_native_units, right_speed_native_units) = self._unpack_speeds_to_native_units(left_speed, right_speed)\n\n        # Set all parameters\n        self.left_motor.speed_sp = int(round(left_speed_native_units))\n        self.right_motor.speed_sp = int(round(right_speed_native_units))\n\n        # This debug involves disk I/O to pull speed_sp so only uncomment\n        # if you need to troubleshoot in more detail.\n        # log.debug(\"%s: on at left-speed %s, right-speed %s\" %\n        #     (self, self.left_motor.speed_sp, self.right_motor.speed_sp))\n\n        # Start the motors\n        self.left_motor.run_forever()\n        self.right_motor.run_forever()", "response": "Start rotating the motors according to left_speed and right_speed forever."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_for_rotations(self, steering, speed, rotations, brake=True, block=True):\n        (left_speed, right_speed) = self.get_speed_steering(steering, speed)\n        MoveTank.on_for_rotations(self, SpeedNativeUnits(left_speed), SpeedNativeUnits(right_speed), rotations, brake, block)", "response": "Rotate the motors according to the provided steering and speed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrotating the motors according to the provided steering and speed for the given degrees.", "response": "def on_for_degrees(self, steering, speed, degrees, brake=True, block=True):\n        \"\"\"\n        Rotate the motors according to the provided ``steering``.\n\n        The distance each motor will travel follows the rules of :meth:`MoveTank.on_for_degrees`.\n        \"\"\"\n        (left_speed, right_speed) = self.get_speed_steering(steering, speed)\n        MoveTank.on_for_degrees(self, SpeedNativeUnits(left_speed), SpeedNativeUnits(right_speed), degrees, brake, block)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_for_seconds(self, steering, speed, seconds, brake=True, block=True):\n        (left_speed, right_speed) = self.get_speed_steering(steering, speed)\n        MoveTank.on_for_seconds(self, SpeedNativeUnits(left_speed), SpeedNativeUnits(right_speed), seconds, brake, block)", "response": "Rotate motors according to the provided steering for the given speed for the given number of seconds."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart rotating motors according to the provided steering and speed forever.", "response": "def on(self, steering, speed):\n        \"\"\"\n        Start rotating the motors according to the provided ``steering`` and\n        ``speed`` forever.\n        \"\"\"\n        (left_speed, right_speed) = self.get_speed_steering(steering, speed)\n        MoveTank.on(self, SpeedNativeUnits(left_speed), SpeedNativeUnits(right_speed))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_speed_steering(self, steering, speed):\n\n        assert steering >= -100 and steering <= 100,\\\n            \"{} is an invalid steering, must be between -100 and 100 (inclusive)\".format(steering)\n\n        # We don't have a good way to make this generic for the pair... so we\n        # assume that the left motor's speed stats are the same as the right\n        # motor's.\n        speed = self.left_motor._speed_native_units(speed)\n        left_speed = speed\n        right_speed = speed\n        speed_factor = (50 - abs(float(steering))) / 50\n\n        if steering >= 0:\n            right_speed *= speed_factor\n        else:\n            left_speed *= speed_factor\n\n        return (left_speed, right_speed)", "response": "Calculate the speed_sp for each motor in a pair to achieve the specified steering."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_for_distance(self, speed, distance_mm, brake=True, block=True):\n        rotations = distance_mm / self.wheel.circumference_mm\n        log.debug(\"%s: on_for_rotations distance_mm %s, rotations %s, speed %s\" % (self, distance_mm, rotations, speed))\n\n        MoveTank.on_for_rotations(self, speed, speed, rotations, brake, block)", "response": "Move the tank at speed for a given distance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndriving in a circle with 'radius' for 'distance'", "response": "def _on_arc(self, speed, radius_mm, distance_mm, brake, block, arc_right):\n        \"\"\"\n        Drive in a circle with 'radius' for 'distance'\n        \"\"\"\n\n        if radius_mm < self.min_circle_radius_mm:\n            raise ValueError(\"{}: radius_mm {} is less than min_circle_radius_mm {}\" .format(\n                    self, radius_mm, self.min_circle_radius_mm))\n\n        # The circle formed at the halfway point between the two wheels is the\n        # circle that must have a radius of radius_mm\n        circle_outer_mm = 2 * math.pi * (radius_mm + (self.wheel_distance_mm / 2))\n        circle_middle_mm = 2 * math.pi * radius_mm\n        circle_inner_mm = 2 * math.pi * (radius_mm - (self.wheel_distance_mm / 2))\n\n        if arc_right:\n            # The left wheel is making the larger circle and will move at 'speed'\n            # The right wheel is making a smaller circle so its speed will be a fraction of the left motor's speed\n            left_speed = speed\n            right_speed = float(circle_inner_mm/circle_outer_mm) * left_speed\n\n        else:\n            # The right wheel is making the larger circle and will move at 'speed'\n            # The left wheel is making a smaller circle so its speed will be a fraction of the right motor's speed\n            right_speed = speed\n            left_speed = float(circle_inner_mm/circle_outer_mm) * right_speed\n\n        log.debug(\"%s: arc %s, radius %s, distance %s, left-speed %s, right-speed %s, circle_outer_mm %s, circle_middle_mm %s, circle_inner_mm %s\" %\n            (self, \"right\" if arc_right else \"left\",\n             radius_mm, distance_mm, left_speed, right_speed,\n             circle_outer_mm, circle_middle_mm, circle_inner_mm\n            )\n        )\n\n        # We know we want the middle circle to be of length distance_mm so\n        # calculate the percentage of circle_middle_mm we must travel for the\n        # middle of the robot to travel distance_mm.\n        circle_middle_percentage = float(distance_mm / circle_middle_mm)\n\n        # Now multiple that percentage by circle_outer_mm to calculate how\n        # many mm the outer wheel should travel.\n        circle_outer_final_mm = circle_middle_percentage * circle_outer_mm\n\n        outer_wheel_rotations = float(circle_outer_final_mm / self.wheel.circumference_mm)\n        outer_wheel_degrees = outer_wheel_rotations * 360\n\n        log.debug(\"%s: arc %s, circle_middle_percentage %s, circle_outer_final_mm %s, outer_wheel_rotations %s, outer_wheel_degrees %s\" %\n            (self, \"right\" if arc_right else \"left\",\n             circle_middle_percentage, circle_outer_final_mm,\n             outer_wheel_rotations, outer_wheel_degrees\n            )\n        )\n\n        MoveTank.on_for_degrees(self, left_speed, right_speed, outer_wheel_degrees, brake, block)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndrives clockwise in a circle with radius_mm for distance_mm", "response": "def on_arc_right(self, speed, radius_mm, distance_mm, brake=True, block=True):\n        \"\"\"\n        Drive clockwise in a circle with 'radius_mm' for 'distance_mm'\n        \"\"\"\n        self._on_arc(speed, radius_mm, distance_mm, brake, block, True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndriving counter - clockwise in a circle with radius_mm for distance_mm", "response": "def on_arc_left(self, speed, radius_mm, distance_mm, brake=True, block=True):\n        \"\"\"\n        Drive counter-clockwise in a circle with 'radius_mm' for 'distance_mm'\n        \"\"\"\n        self._on_arc(speed, radius_mm, distance_mm, brake, block, False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _turn(self, speed, degrees, brake=True, block=True):\n\n        # The distance each wheel needs to travel\n        distance_mm = (abs(degrees) / 360) * self.circumference_mm\n\n        # The number of rotations to move distance_mm\n        rotations = distance_mm/self.wheel.circumference_mm\n\n        log.debug(\"%s: turn() degrees %s, distance_mm %s, rotations %s, degrees %s\" %\n            (self, degrees, distance_mm, rotations, degrees))\n\n        # If degrees is positive rotate clockwise\n        if degrees > 0:\n            MoveTank.on_for_rotations(self, speed, speed * -1, rotations, brake, block)\n\n        # If degrees is negative rotate counter-clockwise\n        else:\n            rotations = distance_mm / self.wheel.circumference_mm\n            MoveTank.on_for_rotations(self, speed * -1, speed, rotations, brake, block)", "response": "Rotate in place degrees."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrotating clockwise degrees in place", "response": "def turn_right(self, speed, degrees, brake=True, block=True):\n        \"\"\"\n        Rotate clockwise 'degrees' in place\n        \"\"\"\n        self._turn(speed, abs(degrees), brake, block)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the odometry thread.", "response": "def odometry_start(self, theta_degrees_start=90.0,\n            x_pos_start=0.0, y_pos_start=0.0,\n            SLEEP_TIME=0.005):  # 5ms\n        \"\"\"\n        Ported from:\n        http://seattlerobotics.org/encoder/200610/Article3/IMU%20Odometry,%20by%20David%20Anderson.htm\n\n        A thread is started that will run until the user calls odometry_stop()\n        which will set odometry_thread_run to False\n        \"\"\"\n\n        def _odometry_monitor():\n            left_previous = 0\n            right_previous = 0\n            self.theta = math.radians(theta_degrees_start)  # robot heading\n            self.x_pos_mm = x_pos_start  # robot X position in mm\n            self.y_pos_mm = y_pos_start  # robot Y position in mm\n            TWO_PI = 2 * math.pi\n\n            while self.odometry_thread_run:\n\n                # sample the left and right encoder counts as close together\n                # in time as possible\n                left_current = self.left_motor.position\n                right_current = self.right_motor.position\n\n                # determine how many ticks since our last sampling\n                left_ticks = left_current - left_previous\n                right_ticks = right_current - right_previous\n\n                # Have we moved?\n                if not left_ticks and not right_ticks:\n                    if SLEEP_TIME:\n                        time.sleep(SLEEP_TIME)\n                    continue\n\n                # log.debug(\"%s: left_ticks %s (from %s to %s)\" %\n                #     (self, left_ticks, left_previous, left_current))\n                # log.debug(\"%s: right_ticks %s (from %s to %s)\" %\n                #     (self, right_ticks, right_previous, right_current))\n\n                # update _previous for next time\n                left_previous = left_current\n                right_previous = right_current\n\n                # rotations = distance_mm/self.wheel.circumference_mm\n                left_rotations = float(left_ticks / self.left_motor.count_per_rot)\n                right_rotations = float(right_ticks / self.right_motor.count_per_rot)\n\n                # convert longs to floats and ticks to mm\n                left_mm = float(left_rotations * self.wheel.circumference_mm)\n                right_mm = float(right_rotations * self.wheel.circumference_mm)\n\n                # calculate distance we have traveled since last sampling\n                mm = (left_mm + right_mm) / 2.0\n\n                # accumulate total rotation around our center\n                self.theta += (right_mm - left_mm) / self.wheel_distance_mm\n\n                # and clip the rotation to plus or minus 360 degrees\n                self.theta -= float(int(self.theta/TWO_PI) * TWO_PI)\n\n                # now calculate and accumulate our position in mm\n                self.x_pos_mm += mm * math.cos(self.theta)\n                self.y_pos_mm += mm * math.sin(self.theta)\n\n                if SLEEP_TIME:\n                    time.sleep(SLEEP_TIME)\n\n            self.odometry_thread_id = None\n\n        self.odometry_thread_run = True\n        self.odometry_thread_id = _thread.start_new_thread(_odometry_monitor, ())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef turn_to_angle(self, speed, angle_target_degrees, brake=True, block=True):\n        assert self.odometry_thread_id, \"odometry_start() must be called to track robot coordinates\"\n\n        # Make both target and current angles positive numbers between 0 and 360\n        if angle_target_degrees < 0:\n            angle_target_degrees += 360\n\n        angle_current_degrees = math.degrees(self.theta)\n\n        if angle_current_degrees < 0:\n            angle_current_degrees += 360\n\n        # Is it shorter to rotate to the right or left\n        # to reach angle_target_degrees?\n        if angle_current_degrees > angle_target_degrees:\n            turn_right = True\n            angle_delta = angle_current_degrees - angle_target_degrees\n        else:\n            turn_right = False\n            angle_delta = angle_target_degrees - angle_current_degrees\n\n        if angle_delta > 180:\n            angle_delta = 360 - angle_delta\n            turn_right = not turn_right\n\n        log.debug(\"%s: turn_to_angle %s, current angle %s, delta %s, turn_right %s\" %\n            (self, angle_target_degrees, angle_current_degrees, angle_delta, turn_right))\n        self.odometry_coordinates_log()\n\n        if turn_right:\n            self.turn_right(speed, angle_delta, brake, block)\n        else:\n            self.turn_left(speed, angle_delta, brake, block)\n\n        self.odometry_coordinates_log()", "response": "Rotate in place to angle_target_degrees at speed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndriving to the target coordinates at speed", "response": "def on_to_coordinates(self, speed, x_target_mm, y_target_mm, brake=True, block=True):\n        \"\"\"\n        Drive to (`x_target_mm`, `y_target_mm`) coordinates at `speed`\n        \"\"\"\n        assert self.odometry_thread_id, \"odometry_start() must be called to track robot coordinates\"\n\n        # stop moving\n        self.off(brake='hold')\n\n        # rotate in place so we are pointed straight at our target\n        x_delta = x_target_mm - self.x_pos_mm\n        y_delta = y_target_mm - self.y_pos_mm\n        angle_target_radians = math.atan2(y_delta, x_delta)\n        angle_target_degrees = math.degrees(angle_target_radians)\n        self.turn_to_angle(speed, angle_target_degrees, brake=True, block=True)\n\n        # drive in a straight line to the target coordinates\n        distance_mm = math.sqrt(pow(self.x_pos_mm - x_target_mm, 2) + pow(self.y_pos_mm - y_target_mm, 2))\n        self.on_for_distance(speed, distance_mm, brake, block)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert x,y joystick coordinates to left/right motor speed percentages and move the motors. This will use a classic \"arcade drive\" algorithm: a full-forward joystick goes straight forward and likewise for full-backward. Pushing the joystick all the way to one side will make it turn on the spot in that direction. Positions in the middle will control how fast the vehicle moves and how sharply it turns. \"x\", \"y\": The X and Y coordinates of the joystick's position, with (0,0) representing the center position. X is horizontal and Y is vertical. radius (default 100): The radius of the joystick, controlling the range of the input (x, y) values. e.g. if \"x\" and \"y\" can be between -1 and 1, radius should be set to \"1\".", "response": "def on(self, x, y, radius=100.0):\n        \"\"\"\n        Convert x,y joystick coordinates to left/right motor speed percentages\n        and move the motors.\n\n        This will use a classic \"arcade drive\" algorithm: a full-forward joystick\n        goes straight forward and likewise for full-backward. Pushing the joystick\n        all the way to one side will make it turn on the spot in that direction.\n        Positions in the middle will control how fast the vehicle moves and how\n        sharply it turns.\n\n        \"x\", \"y\":\n            The X and Y coordinates of the joystick's position, with\n            (0,0) representing the center position. X is horizontal and Y is vertical.\n\n        radius (default 100):\n            The radius of the joystick, controlling the range of the input (x, y) values.\n            e.g. if \"x\" and \"y\" can be between -1 and 1, radius should be set to \"1\".\n        \"\"\"\n\n        # If joystick is in the middle stop the tank\n        if not x and not y:\n            self.off()\n            return\n\n        vector_length = math.sqrt((x * x) + (y * y))\n        angle = math.degrees(math.atan2(y, x))\n\n        if angle < 0:\n            angle += 360\n\n        # Should not happen but can happen (just by a hair) due to floating point math\n        if vector_length > radius:\n            vector_length = radius\n\n        (init_left_speed_percentage, init_right_speed_percentage) = MoveJoystick.angle_to_speed_percentage(angle)\n\n        # scale the speed percentages based on vector_length vs. radius\n        left_speed_percentage = (init_left_speed_percentage * vector_length) / radius\n        right_speed_percentage = (init_right_speed_percentage * vector_length) / radius\n\n    #     log.debug(\"\"\"\n    # x, y                         : %s, %s\n    # radius                       : %s\n    # angle                        : %s\n    # vector length                : %s\n    # init left_speed_percentage   : %s\n    # init right_speed_percentage  : %s\n    # final left_speed_percentage  : %s\n    # final right_speed_percentage : %s\n    # \"\"\" % (x, y, radius, angle, vector_length,\n    #         init_left_speed_percentage, init_right_speed_percentage,\n    #         left_speed_percentage, right_speed_percentage))\n\n        MoveTank.on(self,\n            SpeedPercent(left_speed_percentage),\n            SpeedPercent(right_speed_percentage))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a datetime. timedelta object return the delta in milliseconds", "response": "def datetime_delta_to_ms(delta):\n    \"\"\"\n    Given a datetime.timedelta object, return the delta in milliseconds\n    \"\"\"\n    delta_ms = delta.days * 24 * 60 * 60 * 1000\n    delta_ms += delta.seconds * 1000\n    delta_ms += delta.microseconds / 1000\n    delta_ms = int(delta_ms)\n    return delta_ms"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef duration_expired(start_time, duration_seconds):\n\n    if duration_seconds is not None:\n        delta_seconds = datetime_delta_to_seconds(dt.datetime.now() - start_time)\n\n        if delta_seconds >= duration_seconds:\n            return True\n\n    return False", "response": "Return True if duration_seconds have expired since start_time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef max_brightness(self):\n        self._max_brightness, value = self.get_cached_attr_int(self._max_brightness, 'max_brightness')\n        return value", "response": "Returns the maximum allowable brightness value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef brightness(self):\n        self._brightness, value = self.get_attr_int(self._brightness, 'brightness')\n        return value", "response": "Sets the brightness level. Possible values are 0 to max_brightness."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef triggers(self):\n        self._triggers, value = self.get_attr_set(self._triggers, 'trigger')\n        return value", "response": "Returns a list of available trigger names."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the LED trigger for this entry.", "response": "def trigger(self):\n        \"\"\"\n        Sets the LED trigger. A trigger is a kernel based source of LED events.\n        Triggers can either be simple or complex. A simple trigger isn't\n        configurable and is designed to slot into existing subsystems with\n        minimal additional code. Examples are the `ide-disk` and `nand-disk`\n        triggers.\n\n        Complex triggers whilst available to all LEDs have LED specific\n        parameters and work on a per LED basis. The `timer` trigger is an example.\n        The `timer` trigger will periodically change the LED brightness between\n        0 and the current brightness setting. The `on` and `off` time can\n        be specified via `delay_{on,off}` attributes in milliseconds.\n        You can change the brightness value of a LED independently of the timer\n        trigger. However, if you set the brightness value to 0 it will\n        also disable the `timer` trigger.\n        \"\"\"\n        self._trigger, value = self.get_attr_from_set(self._trigger, 'trigger')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delay_on(self):\n\n        # Workaround for ev3dev/ev3dev#225.\n        # 'delay_on' and 'delay_off' attributes are created when trigger is set\n        # to 'timer', and destroyed when it is set to anything else.\n        # This means the file cache may become outdated, and we may have to\n        # reopen the file.\n        for retry in (True, False):\n            try:\n                self._delay_on, value = self.get_attr_int(self._delay_on, 'delay_on')\n                return value\n            except OSError:\n                if retry:\n                    self._delay_on = None\n                else:\n                    raise", "response": "This method is used to set the LED on time for the current LED."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the brightness of LEDs in the given group to the values specified in the color tuple.", "response": "def set_color(self, group, color, pct=1):\n        \"\"\"\n        Sets brightness of LEDs in the given group to the values specified in\n        color tuple. When percentage is specified, brightness of each LED is\n        reduced proportionally.\n\n        Example::\n\n            my_leds = Leds()\n            my_leds.set_color('LEFT', 'AMBER')\n\n        With a custom color::\n\n            my_leds = Leds()\n            my_leds.set_color('LEFT', (0.5, 0.3))\n        \"\"\"\n        # If this is a platform without LEDs there is nothing to do\n        if not self.leds:\n            return\n\n        color_tuple = color\n        if isinstance(color, str):\n            assert color in self.led_colors, \\\n                \"%s is an invalid LED color, valid choices are %s\" % \\\n                (color, ', '.join(self.led_colors.keys()))\n            color_tuple = self.led_colors[color]\n\n        assert group in self.led_groups, \\\n            \"%s is an invalid LED group, valid choices are %s\" % \\\n            (group, ', '.join(self.led_groups.keys()))\n\n        for led, value in zip(self.led_groups[group], color_tuple):\n            led.brightness_pct = value * pct"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets attributes for each LED in group.", "response": "def set(self, group, **kwargs):\n        \"\"\"\n        Set attributes for each LED in group.\n\n        Example::\n\n            my_leds = Leds()\n            my_leds.set_color('LEFT', brightness_pct=0.5, trigger='timer')\n        \"\"\"\n\n        # If this is a platform without LEDs there is nothing to do\n        if not self.leds:\n            return\n\n        assert group in self.led_groups, \\\n            \"%s is an invalid LED group, valid choices are %s\" % \\\n            (group, ', '.join(self.led_groups.keys()))\n\n        for led in self.led_groups[group]:\n            for k in kwargs:\n                setattr(led, k, kwargs[k])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns all LEDs off", "response": "def all_off(self):\n        \"\"\"\n        Turn all LEDs off\n        \"\"\"\n\n        # If this is a platform without LEDs there is nothing to do\n        if not self.leds:\n            return\n\n        for led in self.leds.values():\n            led.brightness = 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset(self):\n\n        if not self.leds:\n            return\n\n        self.animate_stop()\n\n        for group in self.led_groups:\n            self.set_color(group, LED_DEFAULT_COLOR)", "response": "Reset all LEDs to default color"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef animate_police_lights(self, color1, color2, group1='LEFT', group2='RIGHT', sleeptime=0.5, duration=5, block=True):\n\n        def _animate_police_lights():\n            self.all_off()\n            even = True\n            start_time = dt.datetime.now()\n\n            while True:\n                if even:\n                    self.set_color(group1, color1)\n                    self.set_color(group2, color2)\n                else:\n                    self.set_color(group1, color2)\n                    self.set_color(group2, color1)\n\n                if self.animate_thread_stop or duration_expired(start_time, duration):\n                    break\n\n                even = not even\n                sleep(sleeptime)\n\n            self.animate_thread_stop = False\n            self.animate_thread_id = None\n\n        self.animate_stop()\n\n        if block:\n            _animate_police_lights()\n        else:\n            self.animate_thread_id = _thread.start_new_thread(_animate_police_lights, ())", "response": "Animate the police lights between color1 and color2."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nanimates all LEDs in groups off and on every sleeptime seconds.", "response": "def animate_flash(self, color, groups=('LEFT', 'RIGHT'), sleeptime=0.5, duration=5, block=True):\n        \"\"\"\n        Turn all LEDs in ``groups`` off/on to ``color`` every ``sleeptime`` seconds\n\n        Animate for ``duration`` seconds.  If ``duration`` is None animate for forever.\n\n        Example:\n\n        .. code-block:: python\n\n            from ev3dev2.led import Leds\n            leds = Leds()\n            leds.animate_flash('AMBER', sleeptime=0.75, duration=10)\n        \"\"\"\n\n        def _animate_flash():\n            even = True\n            start_time = dt.datetime.now()\n\n            while True:\n                if even:\n                    for group in groups:\n                        self.set_color(group, color)\n                else:\n                    self.all_off()\n\n                if self.animate_thread_stop or duration_expired(start_time, duration):\n                    break\n\n                even = not even\n                sleep(sleeptime)\n\n            self.animate_thread_stop = False\n            self.animate_thread_id = None\n\n        self.animate_stop()\n\n        if block:\n            _animate_flash()\n        else:\n            self.animate_thread_id = _thread.start_new_thread(_animate_flash, ())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncycle the LEDs through colors.", "response": "def animate_cycle(self, colors, groups=('LEFT', 'RIGHT'), sleeptime=0.5, duration=5, block=True):\n        \"\"\"\n        Cycle ``groups`` LEDs through ``colors``. Do this in a loop where\n        we display each color for ``sleeptime`` seconds.\n\n        Animate for ``duration`` seconds.  If ``duration`` is None animate for forever.\n\n        Example:\n\n        .. code-block:: python\n\n            from ev3dev2.led import Leds\n            leds = Leds()\n            leds.animate_cyle(('RED', 'GREEN', 'AMBER'))\n        \"\"\"\n        def _animate_cycle():\n            index = 0\n            max_index = len(colors)\n            start_time = dt.datetime.now()\n\n            while True:\n                for group in groups:\n                    self.set_color(group, colors[index])\n\n                index += 1\n\n                if index == max_index:\n                    index = 0\n\n                if self.animate_thread_stop or duration_expired(start_time, duration):\n                    break\n\n                sleep(sleeptime)\n\n            self.animate_thread_stop = False\n            self.animate_thread_id = None\n\n        self.animate_stop()\n\n        if block:\n            _animate_cycle()\n        else:\n            self.animate_thread_id = _thread.start_new_thread(_animate_cycle, ())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_GET(self):\n\n        if self.path == \"/\":\n            self.path = \"/index.html\"\n\n        # Serve a file (image, css, html, etc)\n        if '.' in self.path:\n            extension = self.path.split('.')[-1]\n            mt = self.mimetype.get(extension)\n\n            if mt:\n                filename = os.curdir + os.sep + self.path\n\n                # Open the static file requested and send it\n                if os.path.exists(filename):\n                    self.send_response(200)\n                    self.send_header('Content-type', mt)\n                    self.end_headers()\n\n                    if extension in ('gif', 'ico', 'jpg', 'png'):\n                        # Open in binary mode, do not encode\n                        with open(filename, mode='rb') as fh:\n                            self.wfile.write(fh.read())\n                    else:\n                        # Open as plain text and encode\n                        with open(filename, mode='r') as fh:\n                            self.wfile.write(fh.read().encode())\n                else:\n                    log.error(\"404: %s not found\" % self.path)\n                    self.send_error(404, 'File Not Found: %s' % self.path)\n                return True\n\n        return False", "response": "If the request is for a known file type serve the file (or send a 404) and return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_GET(self):\n\n        if RobotWebHandler.do_GET(self):\n            return True\n\n        global motor_max_speed\n        global medium_motor_max_speed\n        global max_move_xy_seq\n        global joystick_engaged\n\n        if medium_motor_max_speed is None:\n            motor_max_speed = self.robot.left_motor.max_speed\n\n            if hasattr(self.robot, 'medium_motor'):\n                medium_motor_max_speed = self.robot.medium_motor.max_speed\n            else:\n                medium_motor_max_speed = 0\n\n        '''\n        Sometimes we get AJAX requests out of order like this:\n        2016-09-06 02:29:35,846 DEBUG: seq 65: (x, y): 0, 44 -> speed 462 462\n        2016-09-06 02:29:35,910 DEBUG: seq 66: (x, y): 0, 45 -> speed 473 473\n        2016-09-06 02:29:35,979 DEBUG: seq 67: (x, y): 0, 46 -> speed 483 483\n        2016-09-06 02:29:36,033 DEBUG: seq 69: (x, y): -1, 48 -> speed 491 504\n        2016-09-06 02:29:36,086 DEBUG: seq 68: (x, y): -1, 47 -> speed 480 494\n        2016-09-06 02:29:36,137 DEBUG: seq 70: (x, y): -1, 49 -> speed 501 515\n        2016-09-06 02:29:36,192 DEBUG: seq 73: (x, y): -2, 51 -> speed 509 536\n        2016-09-06 02:29:36,564 DEBUG: seq 74: (x, y): -3, 51 -> speed 496 536\n        2016-09-06 02:29:36,649  INFO: seq 75: CLIENT LOG: touchend\n        2016-09-06 02:29:36,701 DEBUG: seq 71: (x, y): -1, 50 -> speed 512 525\n        2016-09-06 02:29:36,760 DEBUG: seq 76: move stop\n        2016-09-06 02:29:36,814 DEBUG: seq 72: (x, y): -1, 51 -> speed 522 536\n\n        This can be bad because the last command sequentially was #76 which was \"move stop\"\n        but we RXed seq #72 after that so we started moving again and never stopped\n\n        A quick fix is to have the client send us an AJAX request to let us know\n        when the joystick has been engaged so that we can ignore any move-xy events\n        that we get out of order and show up after \"move stop\" but before the\n        next \"joystick-engaged\"\n\n        We can also ignore any move-xy requests that show up late by tracking the\n        max seq for any move-xy we service.\n        '''\n        path = self.path.split('/')\n        seq = int(path[1])\n        action = path[2]\n\n        # desktop interface\n        if action == 'move-start':\n            direction = path[3]\n            speed_percentage = path[4]\n            log.debug(\"seq %d: move %s\" % (seq, direction))\n\n            left_speed = int(int(speed_percentage) * motor_max_speed)/100.0\n            right_speed = int(int(speed_percentage) * motor_max_speed)/100.0\n\n            if direction == 'forward':\n                self.robot.left_motor.run_forever(speed_sp=left_speed)\n                self.robot.right_motor.run_forever(speed_sp=right_speed)\n\n            elif direction == 'backward':\n                self.robot.left_motor.run_forever(speed_sp=left_speed * -1)\n                self.robot.right_motor.run_forever(speed_sp=right_speed * -1)\n\n            elif direction == 'left':\n                self.robot.left_motor.run_forever(speed_sp=left_speed * -1)\n                self.robot.right_motor.run_forever(speed_sp=right_speed)\n\n            elif direction == 'right':\n                self.robot.left_motor.run_forever(speed_sp=left_speed)\n                self.robot.right_motor.run_forever(speed_sp=right_speed * -1)\n\n        # desktop & mobile interface\n        elif action == 'move-stop':\n            log.debug(\"seq %d: move stop\" % seq)\n            self.robot.left_motor.stop()\n            self.robot.right_motor.stop()\n            joystick_engaged = False\n\n        # medium motor\n        elif action == 'motor-stop':\n            motor = path[3]\n            log.debug(\"seq %d: motor-stop %s\" % (seq, motor))\n\n            if motor == 'medium':\n                if hasattr(self.robot, 'medium_motor'):\n                    self.robot.medium_motor.stop()\n            else:\n                raise Exception(\"motor %s not supported yet\" % motor)\n\n        elif action == 'motor-start':\n            motor = path[3]\n            direction = path[4]\n            speed_percentage = path[5]\n            log.debug(\"seq %d: start motor %s, direction %s, speed_percentage %s\" % (seq, motor, direction, speed_percentage))\n\n            if motor == 'medium':\n                if hasattr(self.robot, 'medium_motor'):\n                    if direction == 'clockwise':\n                        medium_speed = int(int(speed_percentage) * medium_motor_max_speed)/100.0\n                        self.robot.medium_motor.run_forever(speed_sp=medium_speed)\n\n                    elif direction == 'counter-clockwise':\n                        medium_speed = int(int(speed_percentage) * medium_motor_max_speed)/100.0\n                        self.robot.medium_motor.run_forever(speed_sp=medium_speed * -1)\n                else:\n                    log.info(\"we do not have a medium_motor\")\n            else:\n                raise Exception(\"motor %s not supported yet\" % motor)\n\n        # mobile interface\n        elif action == 'move-xy':\n            x = int(path[3])\n            y = int(path[4])\n\n            if joystick_engaged:\n                if seq > max_move_xy_seq:\n                    self.robot.on(x, y)\n                    max_move_xy_seq = seq\n                    log.debug(\"seq %d: (x, y) (%4d, %4d)\" % (seq, x, y))\n                else:\n                    log.debug(\"seq %d: (x, y) %4d, %4d (ignore, max seq %d)\" %\n                              (seq, x, y, max_move_xy_seq))\n            else:\n                log.debug(\"seq %d: (x, y) %4d, %4d (ignore, joystick idle)\" %\n                          (seq, x, y))\n\n        elif action == 'joystick-engaged':\n            joystick_engaged = True\n\n        elif action == 'log':\n            msg = ''.join(path[3:])\n            re_msg = re.search('^(.*)\\?', msg)\n\n            if re_msg:\n                msg = re_msg.group(1)\n\n            log.debug(\"seq %d: CLIENT LOG: %s\" % (seq, msg))\n\n        else:\n            log.warning(\"Unsupported URL %s\" % self.path)\n\n        # It is good practice to send this but if we are getting move-xy we\n        # tend to get a lot of them and we need to be as fast as possible so\n        # be bad and don't send a reply. This takes ~20ms.\n        if action != 'move-xy':\n            self.send_response(204)\n\n        return True", "response": "Returns True if the requested URL is supported by the current robot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the raw components of the color sensor as a tuple.", "response": "def raw(self):\n        \"\"\"\n        Red, green, and blue components of the detected color, as a tuple.\n        \n        Officially in the range 0-1020 but the values returned will never be\n        that high. We do not yet know why the values returned are low, but\n        pointing the color sensor at a well lit sheet of white paper will return\n        values in the 250-400 range.\n\n        If this is an issue, check out the rgb() and calibrate_white() methods.\n        \"\"\"\n        self._ensure_mode(self.MODE_RGB_RAW)\n        return self.value(0), self.value(1), self.value(2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calibrate_white(self):\n        (self.red_max, self.green_max, self.blue_max) = self.raw", "response": "Calibration for the color sensor to white object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the RGB color of the current color cache entry.", "response": "def rgb(self):\n        \"\"\"\n        Same as raw() but RGB values are scaled to 0-255\n        \"\"\"\n        (red, green, blue) = self.raw\n\n        return (min(int((red * 255) / self.red_max), 255),\n                min(int((green * 255) / self.green_max), 255),\n                min(int((blue * 255) / self.blue_max), 255))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns colors in Lab color space", "response": "def lab(self):\n        \"\"\"\n        Return colors in Lab color space\n        \"\"\"\n        RGB = [0, 0, 0]\n        XYZ = [0, 0, 0]\n\n        for (num, value) in enumerate(self.rgb):\n            if value > 0.04045:\n                value = pow(((value + 0.055) / 1.055), 2.4)\n            else:\n                value = value / 12.92\n\n            RGB[num] = value * 100.0\n\n        # http://www.brucelindbloom.com/index.html?Eqn_RGB_XYZ_Matrix.html\n        # sRGB\n        # 0.4124564  0.3575761  0.1804375\n        # 0.2126729  0.7151522  0.0721750\n        # 0.0193339  0.1191920  0.9503041\n        X = (RGB[0] * 0.4124564) + (RGB[1] * 0.3575761) + (RGB[2] * 0.1804375)\n        Y = (RGB[0] * 0.2126729) + (RGB[1] * 0.7151522) + (RGB[2] * 0.0721750)\n        Z = (RGB[0] * 0.0193339) + (RGB[1] * 0.1191920) + (RGB[2] * 0.9503041)\n\n        XYZ[0] = X / 95.047   # ref_X =  95.047\n        XYZ[1] = Y / 100.0    # ref_Y = 100.000\n        XYZ[2] = Z / 108.883  # ref_Z = 108.883\n\n        for (num, value) in enumerate(XYZ):\n            if value > 0.008856:\n                value = pow(value, (1.0 / 3.0))\n            else:\n                value = (7.787 * value) + (16 / 116.0)\n\n            XYZ[num] = value\n\n        L = (116.0 * XYZ[1]) - 16\n        a = 500.0 * (XYZ[0] - XYZ[1])\n        b = 200.0 * (XYZ[1] - XYZ[2])\n\n        L = round(L, 4)\n        a = round(a, 4)\n        b = round(b, 4)\n\n        return (L, a, b)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hsv(self):\n        (r, g, b) = self.rgb\n        maxc = max(r, g, b)\n        minc = min(r, g, b)\n        v = maxc\n\n        if minc == maxc:\n            return 0.0, 0.0, v\n\n        s = (maxc-minc) / maxc\n        rc = (maxc-r) / (maxc-minc)\n        gc = (maxc-g) / (maxc-minc)\n        bc = (maxc-b) / (maxc-minc)\n\n        if r == maxc:\n            h = bc-gc\n        elif g == maxc:\n            h = 2.0+rc-bc\n        else:\n            h = 4.0+gc-rc\n\n        h = (h/6.0) % 1.0\n\n        return (h, s, v)", "response": "HSV Saturation Value\n HSV HHS SHS VHS HSV SHS VHS HSV SHS VHS HSV SHS VHS HSV SHS VHS HSV SHS VHS HSV SHS VHS HSV SHS VHS HSV SHS VHS HSV SHS VHS HSV SHS HSV SHS VHS HSV SHS HSV S V HSV S V HSV S V HSV S V HSV S V HSV S V HSV S V HSV S V HSV S V HSV V HSV V HSV V HSV V HSV V HSV V HSV V HSV V HSV H"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the distance of the sensor in centimeters.", "response": "def distance_centimeters_continuous(self):\n        \"\"\"\n        Measurement of the distance detected by the sensor,\n        in centimeters.\n\n        The sensor will continue to take measurements so\n        they are available for future reads.\n\n        Prefer using the equivalent :meth:`UltrasonicSensor.distance_centimeters` property.\n        \"\"\"\n        self._ensure_mode(self.MODE_US_DIST_CM)\n        return self.value(0) * self._scale('US_DIST_CM')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npinging the sensor for the distance detected by the sensor.", "response": "def distance_centimeters_ping(self):\n        \"\"\"\n        Measurement of the distance detected by the sensor,\n        in centimeters.\n\n        The sensor will take a single measurement then stop\n        broadcasting.\n\n        If you use this property too frequently (e.g. every\n        100msec), the sensor will sometimes lock up and writing\n        to the mode attribute will return an error. A delay of\n        250msec between each usage seems sufficient to keep the\n        sensor from locking up.\n        \"\"\"\n        # This mode is special; setting the mode causes the sensor to send out\n        # a \"ping\", but the mode isn't actually changed.\n        self.mode = self.MODE_US_SI_CM\n        return self.value(0) * self._scale('US_DIST_CM')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the distance detected by the sensor in inches.", "response": "def distance_inches_continuous(self):\n        \"\"\"\n        Measurement of the distance detected by the sensor,\n        in inches.\n\n        The sensor will continue to take measurements so\n        they are available for future reads.\n\n        Prefer using the equivalent :meth:`UltrasonicSensor.distance_inches` property.\n        \"\"\"\n        self._ensure_mode(self.MODE_US_DIST_IN)\n        return self.value(0) * self._scale('US_DIST_IN')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef distance_inches_ping(self):\n        # This mode is special; setting the mode causes the sensor to send out\n        # a \"ping\", but the mode isn't actually changed.\n        self.mode = self.MODE_US_SI_IN\n        return self.value(0) * self._scale('US_DIST_IN')", "response": "The distance detected by the sensor in inches ping the sensor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the angle and rate of the current time.", "response": "def angle_and_rate(self):\n        \"\"\"\n        Angle (degrees) and Rotational Speed (degrees/second).\n        \"\"\"\n        self._ensure_mode(self.MODE_GYRO_G_A)\n        return self.value(0), self.value(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting until angle has changed by specified amount.", "response": "def wait_until_angle_changed_by(self, delta, direction_sensitive=False):\n        \"\"\"\n        Wait until angle has changed by specified amount.\n\n        If ``direction_sensitive`` is True we will wait until angle has changed\n        by ``delta`` and with the correct sign.\n\n        If ``direction_sensitive`` is False (default) we will wait until angle has changed\n        by ``delta`` in either direction.\n        \"\"\"\n        assert self.mode in (self.MODE_GYRO_G_A, self.MODE_GYRO_ANG,\n                             self.MODE_TILT_ANG),\\\n            'Gyro mode should be MODE_GYRO_ANG, MODE_GYRO_G_A or MODE_TILT_ANG'\n        start_angle = self.value(0)\n\n        if direction_sensitive:\n            if delta > 0:\n                while (self.value(0) - start_angle) < delta:\n                    time.sleep(0.01)\n            else:\n                delta *= -1\n                while (start_angle - self.value(0)) < delta:\n                    time.sleep(0.01)\n        else:\n            while abs(start_angle - self.value(0)) < delta:\n                time.sleep(0.01)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the heading to the beacon on the given channel.", "response": "def heading(self, channel=1):\n        \"\"\"\n        Returns heading (-25, 25) to the beacon on the given channel.\n        \"\"\"\n        self._ensure_mode(self.MODE_IR_SEEK)\n        channel = self._normalize_channel(channel)\n        return self.value(channel * 2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef distance(self, channel=1):\n        self._ensure_mode(self.MODE_IR_SEEK)\n        channel = self._normalize_channel(channel)\n        ret_value = self.value((channel * 2) + 1)\n\n        # The value will be -128 if no beacon is found, return None instead\n        return None if ret_value == -128 else ret_value", "response": "Returns the distance between the beacon and the given channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of currently pressed buttons.", "response": "def buttons_pressed(self, channel=1):\n        \"\"\"\n        Returns list of currently pressed buttons.\n\n        Note that the sensor can only identify up to two buttons pressed at once.\n        \"\"\"\n        self._ensure_mode(self.MODE_IR_REMOTE)\n        channel = self._normalize_channel(channel)\n        return self._BUTTON_VALUES.get(self.value(channel), [])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process(self):\n        new_state = []\n        state_diff = []\n\n        for channel in range(1,5):\n\n            for button in self.buttons_pressed(channel):\n                new_state.append((button, channel))\n\n                # Key was not pressed before but now is pressed\n                if (button, channel) not in self._state:\n                    state_diff.append((button, channel))\n\n            # Key was pressed but is no longer pressed\n            for button in self._BUTTONS:\n                if (button, channel) not in new_state and (button, channel) in self._state:\n                    state_diff.append((button, channel))\n\n        old_state = self._state\n        self._state = new_state\n\n        for (button, channel) in state_diff:\n            handler = getattr(self, 'on_channel' + str(channel) + '_' + button )\n\n            if handler is not None:\n                handler((button, channel) in new_state)\n\n        if self.on_change is not None and state_diff:\n            self.on_change([(button, channel, button in new_state) for (button, channel) in state_diff])", "response": "Process the currenly pressed buttons."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sound_pressure_low(self):\n        self._ensure_mode(self.MODE_DBA)\n        return self.value(0) * self._scale('DBA')", "response": "A measurement of the measured sound pressure level as a\n        percent. Uses A - weighting which focuses on levels up to 55 dB."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reflected_light_intensity(self):\n        self._ensure_mode(self.MODE_REFLECT)\n        return self.value(0) * self._scale('REFLECT')", "response": "A measurement of the reflected light intensity as a percentage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the ambient light intensity of the log entry as a percentage.", "response": "def ambient_light_intensity(self):\n        \"\"\"\n        A measurement of the ambient light intensity, as a percentage.\n        \"\"\"\n        self._ensure_mode(self.MODE_AMBIENT)\n        return self.value(0) * self._scale('AMBIENT')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef measured_current(self):\n        self._measured_current, value = self.get_attr_int(self._measured_current, 'current_now')\n        return value", "response": "Returns the current of the battery supplying the battery."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the measured voltage of the battery", "response": "def measured_voltage(self):\n        \"\"\"\n        The measured voltage that the battery is supplying (in microvolts)\n        \"\"\"\n        self._measured_voltage, value = self.get_attr_int(self._measured_voltage, 'voltage_now')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn list of available font names.", "response": "def available():\n    \"\"\"\n    Returns list of available font names.\n    \"\"\"\n    font_dir = os.path.dirname(__file__)\n    names = [os.path.basename(os.path.splitext(f)[0])\n            for f in glob(os.path.join(font_dir, '*.pil'))]\n    return sorted(names)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the specified name and returns it as an instance of PIL. ImageFont <http://pillow.readthedocs. io / en / latest / reference / ImageFont. html > _ class.", "response": "def load(name):\n    \"\"\"\n    Loads the font specified by name and returns it as an instance of\n    `PIL.ImageFont <http://pillow.readthedocs.io/en/latest/reference/ImageFont.html>`_\n    class.\n    \"\"\"\n    try:\n        font_dir = os.path.dirname(__file__)\n        pil_file = os.path.join(font_dir, '{}.pil'.format(name))\n        pbm_file = os.path.join(font_dir, '{}.pbm'.format(name))\n        return ImageFont.load(pil_file)\n    except FileNotFoundError:\n        raise Exception('Failed to load font \"{}\". '.format(name) +\n        'Check ev3dev.fonts.available() for the list of available fonts')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef modes(self):\n        (self._modes, value) = self.get_cached_attr_set(self._modes, 'modes')\n        return value", "response": "Returns a list of the available modes of the port."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the currently selected mode.", "response": "def mode(self):\n        \"\"\"\n        Reading returns the currently selected mode. Writing sets the mode.\n        Generally speaking when the mode changes any sensor or motor devices\n        associated with the port will be removed new ones loaded, however this\n        this will depend on the individual driver implementing this class.\n        \"\"\"\n        self._mode, value = self.get_attr_string(self._mode, 'mode')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status(self):\n        self._status, value = self.get_attr_string(self._status, 'status')\n        return value", "response": "Returns the status of the entry in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_sensors(name_pattern=Sensor.SYSTEM_DEVICE_NAME_CONVENTION, **kwargs):\n    class_path = abspath(Device.DEVICE_ROOT_PATH + '/' + Sensor.SYSTEM_CLASS_NAME)\n    return (Sensor(name_pattern=name, name_exact=True)\n            for name in list_device_names(class_path, name_pattern, **kwargs))", "response": "This function returns a generator function that enumerates all sensors that match the provided arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _scale(self, mode):\n        if mode in self._mode_scale:\n            scale = self._mode_scale[mode]\n        else:\n            scale = 10**(-self.decimals)\n            self._mode_scale[mode] = scale\n\n        return scale", "response": "Returns the value scaling coefficient for the given mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decimals(self):\n        self._decimals, value = self.get_attr_int(self._decimals, 'decimals')\n        return value", "response": "Returns the number of decimal places for the values in the current mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of values that will return a valid value for the current mode.", "response": "def num_values(self):\n        \"\"\"\n        Returns the number of `value<N>` attributes that will return a valid value\n        for the current mode.\n        \"\"\"\n        self._num_values, value = self.get_attr_int(self._num_values, 'num_values')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the units of the current mode. May return empty string", "response": "def units(self):\n        \"\"\"\n        Returns the units of the measured value for the current mode. May return\n        empty string\n        \"\"\"\n        self._units, value = self.get_attr_string(self._units, 'units')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef value(self, n=0):\n        n = int(n)\n\n        self._value[n], value = self.get_attr_int(self._value[n], 'value'+str(n))\n        return value", "response": "Returns the value or values measured by the sensor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bin_data_format(self):\n        self._bin_data_format, value = self.get_attr_string(self._bin_data_format, 'bin_data_format')\n        return value", "response": "Returns the format of the bin_data for the current mode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the unscaled raw values in the value<N attributes as raw byte array.", "response": "def bin_data(self, fmt=None):\n        \"\"\"\n        Returns the unscaled raw values in the `value<N>` attributes as raw byte\n        array. Use `bin_data_format`, `num_values` and the individual sensor\n        documentation to determine how to interpret the data.\n\n        Use `fmt` to unpack the raw bytes into a struct.\n\n        Example::\n\n            >>> from ev3dev2.sensor.lego import InfraredSensor\n            >>> ir = InfraredSensor()\n            >>> ir.value()\n            28\n            >>> ir.bin_data('<b')\n            (28,)\n        \"\"\"\n\n        if self._bin_data_size == None:\n            self._bin_data_size = {\n                    \"u8\":     1,\n                    \"s8\":     1,\n                    \"u16\":    2,\n                    \"s16\":    2,\n                    \"s16_be\": 2,\n                    \"s32\":    4,\n                    \"float\":  4\n                }.get(self.bin_data_format, 1) * self.num_values\n\n        if None == self._bin_data:\n            self._bin_data = self._attribute_file_open( 'bin_data' )\n\n        self._bin_data.seek(0)\n        raw = bytearray(self._bin_data.read(self._bin_data_size))\n\n        if fmt is None: return raw\n\n        return unpack(fmt, raw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fw_version(self):\n        (self._fw_version, value) = self.get_cached_attr_string(self._fw_version, 'fw_version')\n        return value", "response": "Returns the firmware version of the sensor if available. Currently only\n        I2C and NXT sensors support this."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the polling period of the I2C or NXT sensors in milliseconds.", "response": "def poll_ms(self):\n        \"\"\"\n        Returns the polling period of the sensor in milliseconds. Writing sets the\n        polling period. Setting to 0 disables polling. Minimum value is hard\n        coded as 50 msec. Returns -EOPNOTSUPP if changing polling is not supported.\n        Currently only I2C/NXT sensors support changing the polling period.\n        \"\"\"\n        self._poll_ms, value = self.get_attr_int(self._poll_ms, 'poll_ms')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _open_fbdev(fbdev=None):\n        dev = fbdev or os.getenv('FRAMEBUFFER', '/dev/fb0')\n        fbfid = os.open(dev, os.O_RDWR)\n        return fbfid", "response": "Open the framebuffer file descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the fix screen info from the framebuffer file descriptor.", "response": "def _get_fix_info(fbfid):\n        \"\"\"Return the fix screen info from the framebuffer file descriptor.\"\"\"\n        fix_info = FbMem.FixScreenInfo()\n        fcntl.ioctl(fbfid, FbMem.FBIOGET_FSCREENINFO, fix_info)\n        return fix_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_var_info(fbfid):\n        var_info = FbMem.VarScreenInfo()\n        fcntl.ioctl(fbfid, FbMem.FBIOGET_VSCREENINFO, var_info)\n        return var_info", "response": "Return the var screen info from the framebuffer file descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmapping the framebuffer memory.", "response": "def _map_fb_memory(fbfid, fix_info):\n        \"\"\"Map the framebuffer memory.\"\"\"\n        return mmap.mmap(\n            fbfid,\n            fix_info.smem_len,\n            mmap.MAP_SHARED,\n            mmap.PROT_READ | mmap.PROT_WRITE,\n            offset=0\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the internal map with the current image.", "response": "def update(self):\n        \"\"\"\n        Applies pending changes to the screen.\n        Nothing will be drawn on the screen until this function is called.\n        \"\"\"\n        if self.var_info.bits_per_pixel == 1:\n            b = self._img.tobytes(\"raw\", \"1;R\")\n            self.mmap[:len(b)] = b\n\n        elif self.var_info.bits_per_pixel == 16:\n            self.mmap[:] = self._img_to_rgb565_bytes()\n\n        elif self.var_info.bits_per_pixel == 32:\n            self.mmap[:] = self._img.convert(\"RGB\").tobytes(\"raw\", \"XRGB\")\n\n        else:\n            raise Exception(\"Not supported - platform %s with bits_per_pixel %s\" %\n                (self.platform, self.var_info.bits_per_pixel))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef line(self, clear_screen=True, x1=10, y1=10, x2=50, y2=50, line_color='black', width=1):\n\n        if clear_screen:\n            self.clear()\n\n        return self.draw.line((x1, y1, x2, y2), fill=line_color, width=width)", "response": "Draw a line from x1 y1 to x2 y2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw a circle centered at x y with radius radius", "response": "def circle(self, clear_screen=True, x=50, y=50, radius=40, fill_color='black', outline_color='black'):\n        \"\"\"\n        Draw a circle of 'radius' centered at (x, y)\n        \"\"\"\n\n        if clear_screen:\n            self.clear()\n\n        x1 = x - radius\n        y1 = y - radius\n        x2 = x + radius\n        y2 = y + radius\n\n        return self.draw.ellipse((x1, y1, x2, y2), fill=fill_color, outline=outline_color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws a rectangle where the top left corner is at x1 y1 and the bottom right corner is at x2 y2.", "response": "def rectangle(self, clear_screen=True, x1=10, y1=10, x2=80, y2=40, fill_color='black', outline_color='black'):\n        \"\"\"\n        Draw a rectangle where the top left corner is at (x1, y1) and the\n        bottom right corner is at (x2, y2)\n        \"\"\"\n\n        if clear_screen:\n            self.clear()\n\n        return self.draw.rectangle((x1, y1, x2, y2), fill=fill_color, outline=outline_color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws a single pixel at x y.", "response": "def point(self, clear_screen=True, x=10, y=10, point_color='black'):\n        \"\"\"\n        Draw a single pixel at (x, y)\n        \"\"\"\n\n        if clear_screen:\n            self.clear()\n\n        return self.draw.point((x, y), fill=point_color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef text_pixels(self, text, clear_screen=True, x=0, y=0, text_color='black', font=None):\n\n        if clear_screen:\n            self.clear()\n\n        if font is not None:\n            if isinstance(font, str):\n                assert font in fonts.available(), \"%s is an invalid font\" % font\n                font = fonts.load(font)\n            return self.draw.text((x, y), text, fill=text_color, font=font)\n        else:\n            return self.draw.text((x, y), text, fill=text_color)", "response": "Display text in pixels."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef text_grid(self, text, clear_screen=True, x=0, y=0, text_color='black', font=None):\n\n        assert 0 <= x < Display.GRID_COLUMNS,\\\n            \"grid columns must be between 0 and %d, %d was requested\" %\\\n            ((Display.GRID_COLUMNS - 1, x))\n\n        assert 0 <= y < Display.GRID_ROWS,\\\n            \"grid rows must be between 0 and %d, %d was requested\" %\\\n            ((Display.GRID_ROWS - 1), y)\n\n        return self.text_pixels(text, clear_screen,\n                                x * Display.GRID_COLUMN_PIXELS,\n                                y * Display.GRID_ROW_PIXELS,\n                                text_color, font)", "response": "Display a text grid of the EV3 display."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_scales(notes):\n    res = dict()\n    for note, freq in notes:\n        freq = round(freq)\n        for n in note.split('/'):\n            res[n] = freq\n    return res", "response": "Utility function used by Sound class to build the note frequencies table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef beep(self, args='', play_type=PLAY_WAIT_FOR_COMPLETE):\n        with open(os.devnull, 'w') as n:\n            subprocess = Popen(shlex.split('/usr/bin/beep %s' % args), stdout=n)\n            if play_type == Sound.PLAY_WAIT_FOR_COMPLETE:\n                subprocess.wait()\n                return None\n            else:\n                return subprocess", "response": "Call the beep command with the provided arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tone(self, *args, play_type=PLAY_WAIT_FOR_COMPLETE):\n        def play_tone_sequence(tone_sequence):\n            def beep_args(frequency=None, duration=None, delay=None):\n                args = ''\n                if frequency is not None:\n                    args += '-f %s ' % frequency\n                if duration  is not None:\n                    args += '-l %s ' % duration\n                if delay     is not None:\n                    args += '-D %s ' % delay\n\n                return args\n\n            return self.beep(' -n '.join([beep_args(*t) for t in tone_sequence]), play_type=play_type)\n\n        if len(args) == 1:\n            return play_tone_sequence(args[0])\n        elif len(args) == 2:\n            return play_tone_sequence([(args[0], args[1])])\n        else:\n            raise Exception(\"Unsupported number of parameters in Sound.tone(): expected 1 or 2, got \" + str(len(args)))", "response": ".. rubric:: tone(tone_sequence)\n\n        Play tone sequence.\n\n        Here is a cheerful example::\n\n            my_sound = Sound()\n            my_sound.tone([\n                (392, 350, 100), (392, 350, 100), (392, 350, 100), (311.1, 250, 100),\n                (466.2, 25, 100), (392, 350, 100), (311.1, 250, 100), (466.2, 25, 100),\n                (392, 700, 100), (587.32, 350, 100), (587.32, 350, 100),\n                (587.32, 350, 100), (622.26, 250, 100), (466.2, 25, 100),\n                (369.99, 350, 100), (311.1, 250, 100), (466.2, 25, 100), (392, 700, 100),\n                (784, 350, 100), (392, 250, 100), (392, 25, 100), (784, 350, 100),\n                (739.98, 250, 100), (698.46, 25, 100), (659.26, 25, 100),\n                (622.26, 25, 100), (659.26, 50, 400), (415.3, 25, 200), (554.36, 350, 100),\n                (523.25, 250, 100), (493.88, 25, 100), (466.16, 25, 100), (440, 25, 100),\n                (466.16, 50, 400), (311.13, 25, 200), (369.99, 350, 100),\n                (311.13, 250, 100), (392, 25, 100), (466.16, 350, 100), (392, 250, 100),\n                (466.16, 25, 100), (587.32, 700, 100), (784, 350, 100), (392, 250, 100),\n                (392, 25, 100), (784, 350, 100), (739.98, 250, 100), (698.46, 25, 100),\n                (659.26, 25, 100), (622.26, 25, 100), (659.26, 50, 400), (415.3, 25, 200),\n                (554.36, 350, 100), (523.25, 250, 100), (493.88, 25, 100),\n                (466.16, 25, 100), (440, 25, 100), (466.16, 50, 400), (311.13, 25, 200),\n                (392, 350, 100), (311.13, 250, 100), (466.16, 25, 100),\n                (392.00, 300, 150), (311.13, 250, 100), (466.16, 25, 100), (392, 700)\n                ])\n\n        Have also a look at :py:meth:`play_song` for a more musician-friendly way of doing, which uses\n        the conventional notation for notes and durations.\n\n        :param list[tuple(float,float,float)] tone_sequence: The sequence of tones to play. The first number of each tuple is frequency in Hz, the second is duration in milliseconds, and the third is delay in milliseconds between this and the next tone in the sequence.\n\n        :param play_type: The behavior of ``tone`` once playback has been initiated\n        :type play_type: ``Sound.PLAY_WAIT_FOR_COMPLETE`` or ``Sound.PLAY_NO_WAIT_FOR_COMPLETE``\n\n        :return: When ``Sound.PLAY_NO_WAIT_FOR_COMPLETE`` is specified, returns the returns the spawn subprocess from ``subprocess.Popen``; ``None`` otherwise\n\n        .. rubric:: tone(frequency, duration)\n\n        Play single tone of given frequency and duration.\n\n        :param float frequency: The frequency of the tone in Hz\n        :param float duration: The duration of the tone in milliseconds\n\n        :param play_type: The behavior of ``tone`` once playback has been initiated\n        :type play_type: ``Sound.PLAY_WAIT_FOR_COMPLETE`` or ``Sound.PLAY_NO_WAIT_FOR_COMPLETE``\n\n        :return: When ``Sound.PLAY_NO_WAIT_FOR_COMPLETE`` is specified, returns the returns the spawn subprocess from ``subprocess.Popen``; ``None`` otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplay a single tone.", "response": "def play_tone(self, frequency, duration, delay=0.0, volume=100,\n                  play_type=PLAY_WAIT_FOR_COMPLETE):\n        \"\"\" Play a single tone, specified by its frequency, duration, volume and final delay.\n\n        :param int frequency: the tone frequency, in Hertz\n        :param float duration: Tone duration, in seconds\n        :param float delay: Delay after tone, in seconds (can be useful when chaining calls to ``play_tone``)\n        :param int volume: The play volume, in percent of maximum volume\n\n        :param play_type: The behavior of ``play_tone`` once playback has been initiated\n        :type play_type: ``Sound.PLAY_WAIT_FOR_COMPLETE``, ``Sound.PLAY_NO_WAIT_FOR_COMPLETE`` or ``Sound.PLAY_LOOP``\n\n        :return: When ``Sound.PLAY_NO_WAIT_FOR_COMPLETE`` is specified, returns the PID of the underlying beep command; ``None`` otherwise\n\n        :raises ValueError: if invalid parameter\n        \"\"\"\n        self._validate_play_type(play_type)\n\n        if duration <= 0:\n            raise ValueError('invalid duration (%s)' % duration)\n        if delay < 0:\n            raise ValueError('invalid delay (%s)' % delay)\n        if not 0 < volume <= 100:\n            raise ValueError('invalid volume (%s)' % volume)\n\n        self.set_volume(volume)\n\n        duration_ms = int(duration * 1000)\n        delay_ms = int(delay * 1000)\n\n        self.tone([(frequency, duration_ms, delay_ms)], play_type=play_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef play_note(self, note, duration, volume=100, play_type=PLAY_WAIT_FOR_COMPLETE):\n        self._validate_play_type(play_type)\n        try:\n            freq = self._NOTE_FREQUENCIES.get(note.upper(), self._NOTE_FREQUENCIES[note])\n        except KeyError:\n            raise ValueError('invalid note (%s)' % note)\n\n        if duration <= 0:\n            raise ValueError('invalid duration (%s)' % duration)\n        if not 0 < volume <= 100:\n            raise ValueError('invalid volume (%s)' % volume)\n\n        return self.play_tone(freq, duration=duration, volume=volume, play_type=play_type)", "response": "Plays a note given by its name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef play_file(self, wav_file, volume=100, play_type=PLAY_WAIT_FOR_COMPLETE):\n        if not 0 < volume <= 100:\n            raise ValueError('invalid volume (%s)' % volume)\n\n        if not wav_file.endswith(\".wav\"):\n            raise ValueError('invalid sound file (%s), only .wav files are supported' % wav_file)\n\n        if not os.path.isfile(wav_file):\n            raise ValueError(\"%s does not exist\" % wav_file)\n\n        self.set_volume(volume)\n        self._validate_play_type(play_type)\n\n        with open(os.devnull, 'w') as n:\n\n            if play_type == Sound.PLAY_WAIT_FOR_COMPLETE:\n                pid = Popen(shlex.split('/usr/bin/aplay -q \"%s\"' % wav_file), stdout=n)\n                pid.wait()\n\n            # Do not wait, run in the background\n            elif play_type == Sound.PLAY_NO_WAIT_FOR_COMPLETE:\n                return Popen(shlex.split('/usr/bin/aplay -q \"%s\"' % wav_file), stdout=n)\n\n            elif play_type == Sound.PLAY_LOOP:\n                while True:\n                    pid = Popen(shlex.split('/usr/bin/aplay -q \"%s\"' % wav_file), stdout=n)\n                    pid.wait()", "response": "Play a sound file at a given volume."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nspeaking the given text using the espeak command.", "response": "def speak(self, text, espeak_opts='-a 200 -s 130', volume=100, play_type=PLAY_WAIT_FOR_COMPLETE):\n        \"\"\" Speak the given text aloud.\n\n        Uses the ``espeak`` external command.\n\n        :param string text: The text to speak\n        :param string espeak_opts: ``espeak`` command options (advanced usage)\n        :param int volume: The play volume, in percent of maximum volume\n\n        :param play_type: The behavior of ``speak`` once playback has been initiated\n        :type play_type: ``Sound.PLAY_WAIT_FOR_COMPLETE``, ``Sound.PLAY_NO_WAIT_FOR_COMPLETE`` or ``Sound.PLAY_LOOP``\n\n        :returns: When ``Sound.PLAY_NO_WAIT_FOR_COMPLETE`` is specified, returns the spawn subprocess from ``subprocess.Popen``; ``None`` otherwise\n        \"\"\"\n        self._validate_play_type(play_type)\n        self.set_volume(volume)\n\n        with open(os.devnull, 'w') as n:\n            cmd_line = ['/usr/bin/espeak', '--stdout'] + shlex.split(espeak_opts) + [shlex.quote(text)]\n            aplay_cmd_line = shlex.split('/usr/bin/aplay -q')\n\n            if play_type == Sound.PLAY_WAIT_FOR_COMPLETE:\n                espeak = Popen(cmd_line, stdout=PIPE)\n                play = Popen(aplay_cmd_line, stdin=espeak.stdout, stdout=n)\n                play.wait()\n\n            elif play_type == Sound.PLAY_NO_WAIT_FOR_COMPLETE:\n                espeak = Popen(cmd_line, stdout=PIPE)\n                return Popen(aplay_cmd_line, stdin=espeak.stdout, stdout=n)\n\n            elif play_type == Sound.PLAY_LOOP:\n                while True:\n                    espeak = Popen(cmd_line, stdout=PIPE)\n                    play = Popen(aplay_cmd_line, stdin=espeak.stdout, stdout=n)\n                    play.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_channel(self):\n        if self.channel is None:\n            # Get default channel as the first one that pops up in\n            # 'amixer scontrols' output, which contains strings in the\n            # following format:\n            #\n            #     Simple mixer control 'Master',0\n            #     Simple mixer control 'Capture',0\n            out = check_output(['amixer', 'scontrols']).decode()\n            m = re.search(r\"'(?P<channel>[^']+)'\", out)\n            if m:\n                self.channel = m.group('channel')\n            else:\n                self.channel = 'Playback'\n\n        return self.channel", "response": "Returns the detected sound channel for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_volume(self, pct, channel=None):\n\n        if channel is None:\n            channel = self._get_channel()\n\n        cmd_line = '/usr/bin/amixer -q set {0} {1:d}%'.format(channel, pct)\n        Popen(shlex.split(cmd_line)).wait()", "response": "Sets the sound volume to the given percentage."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_volume(self, channel=None):\n\n        if channel is None:\n            channel = self._get_channel()\n\n        out = check_output(['amixer', 'get', channel]).decode()\n        m = re.search(r'\\[(?P<volume>\\d+)%\\]', out)\n        if m:\n            return int(m.group('volume'))\n        else:\n            raise Exception('Failed to parse output of `amixer get {}`'.format(channel))", "response": "Gets the current sound volume by parsing the output of amixer get."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplays a song into the specified tempo and delay seconds.", "response": "def play_song(self, song, tempo=120, delay=0.05):\n        \"\"\" Plays a song provided as a list of tuples containing the note name and its\n        value using music conventional notation instead of numerical values for frequency\n        and duration.\n\n        It supports symbolic notes (e.g. ``A4``, ``D#3``, ``Gb5``) and durations (e.g. ``q``, ``h``).\n\n        For an exhaustive list of accepted note symbols and values, have a look at the ``_NOTE_FREQUENCIES``\n        and ``_NOTE_VALUES`` private dictionaries in the source code.\n\n        The value can be suffixed by modifiers:\n\n        - a *divider* introduced by a ``/`` to obtain triplets for instance\n          (e.g. ``q/3`` for a triplet of eight note)\n        - a *multiplier* introduced by ``*`` (e.g. ``*1.5`` is a dotted note).\n\n        Shortcuts exist for common modifiers:\n\n        - ``3`` produces a triplet member note. For instance `e3` gives a triplet of eight notes,\n          i.e. 3 eight notes in the duration of a single quarter. You must ensure that 3 triplets\n          notes are defined in sequence to match the count, otherwise the result will not be the\n          expected one.\n        - ``.`` produces a dotted note, i.e. which duration is one and a half the base one. Double dots\n          are not currently supported.\n\n        Example::\n\n            >>> # A long time ago in a galaxy far,\n            >>> # far away...\n            >>> Sound.play_song((\n            >>>     ('D4', 'e3'),      # intro anacrouse\n            >>>     ('D4', 'e3'),\n            >>>     ('D4', 'e3'),\n            >>>     ('G4', 'h'),       # meas 1\n            >>>     ('D5', 'h'),\n            >>>     ('C5', 'e3'),      # meas 2\n            >>>     ('B4', 'e3'),\n            >>>     ('A4', 'e3'),\n            >>>     ('G5', 'h'),\n            >>>     ('D5', 'q'),\n            >>>     ('C5', 'e3'),      # meas 3\n            >>>     ('B4', 'e3'),\n            >>>     ('A4', 'e3'),\n            >>>     ('G5', 'h'),\n            >>>     ('D5', 'q'),\n            >>>     ('C5', 'e3'),      # meas 4\n            >>>     ('B4', 'e3'),\n            >>>     ('C5', 'e3'),\n            >>>     ('A4', 'h.'),\n            >>> ))\n\n        .. important::\n\n            Only 4/4 signature songs are supported with respect to note durations.\n\n        :param iterable[tuple(string, string)] song: the song\n        :param int tempo: the song tempo, given in quarters per minute\n        :param float delay: delay between notes (in seconds)\n\n        :return: the spawn subprocess from ``subprocess.Popen``\n\n        :raises ValueError: if invalid note in song or invalid play parameters\n        \"\"\"\n        if tempo <= 0:\n            raise ValueError('invalid tempo (%s)' % tempo)\n        if delay < 0:\n            raise ValueError('invalid delay (%s)' % delay)\n\n        delay_ms = int(delay * 1000)\n        meas_duration_ms = 60000 / tempo * 4       # we only support 4/4 bars, hence \"* 4\"\n\n        def beep_args(note, value):\n            \"\"\" Builds the arguments string for producing a beep matching\n            the requested note and value.\n\n            Args:\n                note (str): the note note and octave\n                value (str): the note value expression\n            Returns:\n                str: the arguments to be passed to the beep command\n            \"\"\"\n            freq = self._NOTE_FREQUENCIES.get(note.upper(), self._NOTE_FREQUENCIES[note])\n\n            if '/' in value:\n                base, factor = value.split('/')\n                duration_ms = meas_duration_ms * self._NOTE_VALUES[base] / float(factor)\n            elif '*' in value:\n                base, factor = value.split('*')\n                duration_ms = meas_duration_ms * self._NOTE_VALUES[base] * float(factor)\n            elif value.endswith('.'):\n                base = value[:-1]\n                duration_ms = meas_duration_ms * self._NOTE_VALUES[base] * 1.5\n            elif value.endswith('3'):\n                base = value[:-1]\n                duration_ms = meas_duration_ms * self._NOTE_VALUES[base] * 2 / 3\n            else:\n                duration_ms = meas_duration_ms * self._NOTE_VALUES[value]\n\n            return '-f %d -l %d -D %d' % (freq, duration_ms, delay_ms)\n\n        try:\n            return self.beep(' -n '.join(\n                [beep_args(note, value) for (note, value) in song]\n            ))\n        except KeyError as e:\n            raise ValueError('invalid note (%s)' % e)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current platform type of the current board.", "response": "def get_current_platform():\n    \"\"\"\n    Look in /sys/class/board-info/ to determine the platform type.\n\n    This can return 'ev3', 'evb', 'pistorms', 'brickpi', 'brickpi3' or 'fake'.\n    \"\"\"\n    board_info_dir = '/sys/class/board-info/'\n\n    if not os.path.exists(board_info_dir) or os.environ.get(\"FAKE_SYS\"):\n        return 'fake'\n\n    for board in os.listdir(board_info_dir):\n        uevent_filename = os.path.join(board_info_dir, board, 'uevent')\n\n        if os.path.exists(uevent_filename):\n            with open(uevent_filename, 'r') as fh:\n                for line in fh.readlines():\n                    (key, value) = line.strip().split('=')\n\n                    if key == 'BOARD_INFO_MODEL':\n\n                        if value == 'LEGO MINDSTORMS EV3':\n                            return 'ev3'\n\n                        elif value in ('FatcatLab EVB', 'QuestCape'):\n                            return 'evb'\n\n                        elif value == 'PiStorms':\n                            return 'pistorms'\n\n                        # This is the same for both BrickPi and BrickPi+.\n                        # There is not a way to tell the difference.\n                        elif value == 'Dexter Industries BrickPi':\n                            return 'brickpi'\n\n                        elif value == 'Dexter Industries BrickPi3':\n                            return 'brickpi3'\n\n                        elif value == 'FAKE-SYS':\n                            return 'fake'\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_device_names(class_path, name_pattern, **kwargs):\n\n    if not os.path.isdir(class_path):\n        return\n\n    def matches(attribute, pattern):\n        try:\n            with io.FileIO(attribute) as f:\n                value = f.read().strip().decode()\n        except:\n            return False\n\n        if isinstance(pattern, list):\n            return any([value.find(p) >= 0 for p in pattern])\n        else:\n            return value.find(pattern) >= 0\n\n    for f in os.listdir(class_path):\n        if fnmatch.fnmatch(f, name_pattern):\n            path = class_path + '/' + f\n            if all([matches(path + '/' + k, kwargs[k]) for k in kwargs]):\n                yield f", "response": "This function returns a generator function that lists all the names of all devices matching the given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_devices(class_name, name_pattern, **kwargs):\n    classpath = abspath(Device.DEVICE_ROOT_PATH + '/' + class_name)\n\n    return (Device(class_name, name, name_exact=True)\n            for name in list_device_names(classpath, name_pattern, **kwargs))", "response": "This function returns a generator function that returns all devices present in the system that match the provided name pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_attribute(self, attribute, name):\n        try:\n            if attribute is None:\n                attribute = self._attribute_file_open( name )\n            else:\n                attribute.seek(0)\n            return attribute, attribute.read().strip().decode()\n        except Exception as ex:\n            self._raise_friendly_access_error(ex, name)", "response": "Get the attribute of a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclose all file handles and stop all motors.", "response": "def shutdown(self):\n        \"\"\"Close all file handles and stop all motors.\"\"\"\n        self.stop_balance.set()  # Stop balance thread\n        self.motor_left.stop()\n        self.motor_right.stop()\n        self.gyro_file.close()\n        self.touch_file.close()\n        self.encoder_left_file.close()\n        self.encoder_right_file.close()\n        self.dc_left_file.close()\n        self.dc_right_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fast_read(self, infile):\n        infile.seek(0)\n        return(int(infile.read().decode().strip()))", "response": "Function for fast reading from sensor files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning for fast writing to motor files.", "response": "def _fast_write(self, outfile, value):\n        \"\"\"Function for fast writing to motor files.\"\"\"\n        outfile.truncate(0)\n        outfile.write(str(int(value)))\n        outfile.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to set the duty cycle of the motors.", "response": "def _set_duty(self, motor_duty_file, duty, friction_offset,\n                  voltage_comp):\n        \"\"\"Function to set the duty cycle of the motors.\"\"\"\n        # Compensate for nominal voltage and round the input\n        duty_int = int(round(duty*voltage_comp))\n\n        # Add or subtract offset and clamp the value between -100 and 100\n        if duty_int > 0:\n            duty_int = min(100, duty_int + friction_offset)\n        elif duty_int < 0:\n            duty_int = max(-100, duty_int - friction_offset)\n\n        # Apply the signal to the motor\n        self._fast_write(motor_duty_file, duty_int)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef balance(self):\n        balance_thread = threading.Thread(target=self._balance)\n        balance_thread.start()", "response": "Run the _balance method as a thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking the robot balance.", "response": "def _balance(self):\n        \"\"\"Make the robot balance.\"\"\"\n        while True and not self.stop_balance.is_set():\n\n            # Reset the motors\n            self.motor_left.reset()  # Reset the encoder\n            self.motor_right.reset()\n            self.motor_left.run_direct()  # Set to run direct mode\n            self.motor_right.run_direct()\n\n            # Initialize variables representing physical signals\n            # (more info on these in the docs)\n\n            # The angle of \"the motor\", measured in raw units,\n            # degrees for the EV3).\n            # We will take the average of both motor positions as\n            # \"the motor\" angle, which is essentially how far the middle\n            # of the robot has travelled.\n            motor_angle_raw = 0\n\n            # The angle of the motor, converted to RAD (2*pi RAD\n            # equals 360 degrees).\n            motor_angle = 0\n\n            # The reference angle of the motor. The robot will attempt to\n            # drive forward or backward, such that its measured position\n            motor_angle_ref = 0\n            # equals this reference (or close enough).\n\n            # The error: the deviation of the measured motor angle from the\n            # reference. The robot attempts to make this zero, by driving\n            # toward the reference.\n            motor_angle_error = 0\n\n            # We add up all of the motor angle error in time. If this value\n            # gets out of hand, we can use it to drive the robot back to\n            # the reference position a bit quicker.\n            motor_angle_error_acc = 0\n\n            # The motor speed, estimated by how far the motor has turned in\n            # a given amount of time.\n            motor_angular_speed = 0\n\n            # The reference speed during manouvers: how fast we would like\n            # to drive, measured in RAD per second.\n            motor_angular_speed_ref = 0\n\n            # The error: the deviation of the motor speed from the\n            # reference speed.\n            motor_angular_speed_error = 0\n\n            # The 'voltage' signal we send to the motor.\n            # We calculate a new value each time, just right to keep the\n            # robot upright.\n            motor_duty_cycle = 0\n\n            # The raw value from the gyro sensor in rate mode.\n            gyro_rate_raw = 0\n\n            # The angular rate of the robot (how fast it is falling forward\n            # or backward), measured in RAD per second.\n            gyro_rate = 0\n\n            # The gyro doesn't measure the angle of the robot, but we can\n            # estimate this angle by keeping track of the gyro_rate value\n            # in time.\n            gyro_est_angle = 0\n\n            # Over time, the gyro rate value can drift. This causes the\n            # sensor to think it is moving even when it is perfectly still.\n            # We keep track of this offset.\n            gyro_offset = 0\n\n            # Start\n            log.info(\"Hold robot upright. Press touch sensor to start.\")\n            self.sound.speak(\"Press touch sensor to start.\")\n\n            self.touch.wait_for_bump()\n\n            # Read battery voltage\n            voltage_idle = self.power_supply.measured_volts\n            voltage_comp = self.power_voltage_nominal / voltage_idle\n\n            # Offset to limit friction deadlock\n            friction_offset = int(round(self.pwr_friction_offset_nom *\n                                        voltage_comp))\n\n            # Timing settings for the program\n            # Time of each loop, measured in seconds.\n            loop_time_target = self.timing_loop_msec / 1000\n            loop_count = 0  # Loop counter, starting at 0\n\n            # A deque (a fifo array) which we'll use to keep track of\n            # previous motor positions, which we can use to calculate the\n            # rate of change (speed)\n            motor_angle_hist =\\\n                deque([0], self.motor_angle_history_length)\n\n            # The rate at which we'll update the gyro offset (precise\n            # definition given in docs)\n            gyro_drift_comp_rate =\\\n                self.gyro_drift_compensation_factor *\\\n                loop_time_target * RAD_PER_SEC_PER_RAW_GYRO_UNIT\n\n            # Calibrate Gyro\n            log.info(\"-----------------------------------\")\n            log.info(\"Calibrating...\")\n\n            # As you hold the robot still, determine the average sensor\n            # value of 100 samples\n            gyro_calibrate_count = 100\n            for i in range(gyro_calibrate_count):\n                gyro_offset = gyro_offset + self._fast_read(self.gyro_file)\n                time.sleep(0.01)\n            gyro_offset = gyro_offset / gyro_calibrate_count\n\n            # Print the result\n            log.info(\"gyro_offset: \" + str(gyro_offset))\n            log.info(\"-----------------------------------\")\n            log.info(\"GO!\")\n            log.info(\"-----------------------------------\")\n            log.info(\"Press Touch Sensor to re-start.\")\n            log.info(\"-----------------------------------\")\n            self.sound.beep()\n\n            # Remember start time\n            prog_start_time = time.time()\n\n            if self.debug:\n                # Data logging\n                data = OrderedDict()\n                loop_times = OrderedDict()\n                data['loop_times'] = loop_times\n                gyro_readings = OrderedDict()\n                data['gyro_readings'] = gyro_readings\n\n            # Initial fast read touch sensor value\n            touch_pressed = False\n\n            # Driving and Steering\n            speed, steering = (0, 0)\n\n            # Record start time of loop\n            loop_start_time = time.time()\n\n            # Balancing Loop\n            while not touch_pressed and not self.stop_balance.is_set():\n\n                loop_count += 1\n\n                # Check for drive instructions and set speed / steering\n                try:\n                    speed, steering = self.drive_queue.get_nowait()\n                    self.drive_queue.task_done()\n                except queue.Empty:\n                    pass\n\n                # Read the touch sensor (the kill switch)\n                touch_pressed = self._fast_read(self.touch_file)\n\n                # Read the Motor Position\n                motor_angle_raw = ((self._fast_read(self.encoder_left_file) +\n                                   self._fast_read(self.encoder_right_file)) /\n                                   2.0)\n                motor_angle = motor_angle_raw * RAD_PER_RAW_MOTOR_UNIT\n\n                # Read the Gyro\n                gyro_rate_raw = self._fast_read(self.gyro_file)\n\n                # Busy wait for the loop to reach target time length\n                loop_time = 0\n                while(loop_time < loop_time_target):\n                    loop_time = time.time() - loop_start_time\n                    time.sleep(0.001)\n\n                # Calculate most recent loop time\n                loop_time = time.time() - loop_start_time\n\n                # Set start time of next loop\n                loop_start_time = time.time()\n\n                if self.debug:\n                    # Log gyro data and loop time\n                    time_of_sample = time.time() - prog_start_time\n                    gyro_readings[time_of_sample] = gyro_rate_raw\n                    loop_times[time_of_sample] = loop_time * 1000.0\n\n                # Calculate gyro rate\n                gyro_rate = (gyro_rate_raw - gyro_offset) *\\\n                    RAD_PER_SEC_PER_RAW_GYRO_UNIT\n\n                # Calculate Motor Parameters\n                motor_angular_speed_ref =\\\n                    speed * RAD_PER_SEC_PER_PERCENT_SPEED\n                motor_angle_ref = motor_angle_ref +\\\n                    motor_angular_speed_ref * loop_time_target\n                motor_angle_error = motor_angle - motor_angle_ref\n\n                # Compute Motor Speed\n                motor_angular_speed =\\\n                    ((motor_angle - motor_angle_hist[0]) /\n                     (self.motor_angle_history_length * loop_time_target))\n                motor_angular_speed_error = motor_angular_speed\n                motor_angle_hist.append(motor_angle)\n\n                # Compute the motor duty cycle value\n                motor_duty_cycle =\\\n                    (self.gain_gyro_angle * gyro_est_angle +\n                     self.gain_gyro_rate * gyro_rate +\n                     self.gain_motor_angle * motor_angle_error +\n                     self.gain_motor_angular_speed *\n                     motor_angular_speed_error +\n                     self.gain_motor_angle_error_accumulated *\n                     motor_angle_error_acc)\n\n                # Apply the signal to the motor, and add steering\n                self._set_duty(self.dc_right_file, motor_duty_cycle + steering,\n                               friction_offset, voltage_comp)\n                self._set_duty(self.dc_left_file, motor_duty_cycle - steering,\n                               friction_offset, voltage_comp)\n\n                # Update angle estimate and gyro offset estimate\n                gyro_est_angle = gyro_est_angle + gyro_rate *\\\n                    loop_time_target\n                gyro_offset = (1 - gyro_drift_comp_rate) *\\\n                    gyro_offset + gyro_drift_comp_rate * gyro_rate_raw\n\n                # Update Accumulated Motor Error\n                motor_angle_error_acc = motor_angle_error_acc +\\\n                    motor_angle_error * loop_time_target\n\n            # Closing down & Cleaning up\n\n            # Loop end time, for stats\n            prog_end_time = time.time()\n\n            # Turn off the motors\n            self._fast_write(self.dc_left_file, 0)\n            self._fast_write(self.dc_right_file, 0)\n\n            # Wait for the Touch Sensor to be released\n            while self.touch.is_pressed:\n                time.sleep(0.01)\n\n            # Calculate loop time\n            avg_loop_time = (prog_end_time - prog_start_time) / loop_count\n            log.info(\"Loop time:\" + str(avg_loop_time * 1000) + \"ms\")\n\n            # Print a stop message\n            log.info(\"-----------------------------------\")\n            log.info(\"STOP\")\n            log.info(\"-----------------------------------\")\n\n            if self.debug:\n                # Dump logged data to file\n                with open(\"data.txt\", 'w') as data_file:\n                    json.dump(data, data_file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef evdev_device(self):\n        devices = [evdev.InputDevice(fn) for fn in evdev.list_devices()]\n\n        for device in devices:\n            if device.name == self.evdev_device_name:\n                return device\n\n        raise Exception(\"%s: could not find evdev device '%s'\" % (self, self.evdev_device_name))", "response": "Return our corresponding evdev device object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process(self, new_state=None):\n        if new_state is None:\n            new_state = set(self.buttons_pressed)\n        old_state = self._state\n        self._state = new_state\n\n        state_diff = new_state.symmetric_difference(old_state)\n        for button in state_diff:\n            handler = getattr(self, 'on_' + button)\n\n            if handler is not None:\n                handler(button in new_state)\n\n        if self.on_change is not None and state_diff:\n            self.on_change([(button, button in new_state) for button in state_diff])", "response": "Process the currenly pressed buttons."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits for the button to be pressed down and then released.", "response": "def wait_for_bump(self, buttons, timeout_ms=None):\n        \"\"\"\n        Wait for the button to be pressed down and then released.\n        Both actions must happen within timeout_ms.\n        \"\"\"\n        start_time = time.time()\n\n        if self.wait_for_pressed(buttons, timeout_ms):\n            if timeout_ms is not None:\n                timeout_ms -= int((time.time() - start_time) * 1000)\n            return self.wait_for_released(buttons, timeout_ms)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buttons_pressed(self):\n        for b in self._buffer_cache:\n            fcntl.ioctl(self._button_file(b), self.EVIOCGKEY, self._buffer_cache[b])\n\n        pressed = []\n        for k, v in self._buttons.items():\n            buf = self._buffer_cache[v['name']]\n            bit = v['value']\n\n            if bool(buf[int(bit / 8)] & 1 << bit % 8):\n                pressed.append(k)\n\n        return pressed", "response": "Returns a list of names of pressed buttons."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _orted_process():\n    for i in range(5 * 60):\n        procs = [p for p in psutil.process_iter(attrs=['name']) if p.info['name'] == 'orted']\n\n        if procs:\n            return procs\n        time.sleep(1)", "response": "Waits maximum of 5 minutes for orted process to start"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the connection to the provided host and port is possible or not.", "response": "def _can_connect(host, port=22):  # type: (str, int) -> bool\n    \"\"\"Checks if the connection to provided ``host`` and ``port`` is possible or not.\n       Args:\n           host (str): Hostname for the host to check connection.\n           port (int): Port name of the host to check connection on.\n    \"\"\"\n    try:\n        logger.debug('Testing connection to host %s', host)\n        client = paramiko.SSHClient()\n        client.load_system_host_keys()\n        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        client.connect(host,\n                       port=port)\n        client.close()\n        logger.info('Can connect to host %s', host)\n        return True\n    except Exception as e:\n        logger.info('Cannot connect to host %s', host)\n\n        logger.info('Connection failed with exception: \\n %s', str(e))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses custom MPI options provided by user.", "response": "def _parse_custom_mpi_options(custom_mpi_options):\n    # type: (str) -> Tuple[argparse.Namespace, List[str]]\n    \"\"\"Parse custom MPI options provided by user. Known options default value will be overridden\n    and unknown options would be identified separately.\"\"\"\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--NCCL_DEBUG', default=\"INFO\", type=str)\n\n    return parser.parse_known_args(custom_mpi_options.split())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef timeout(seconds=0, minutes=0, hours=0):\n\n    limit = seconds + 60 * minutes + 3600 * hours\n\n    def handler(signum, frame):  # pylint: disable=W0613\n        raise TimeoutError('timed out after {} seconds'.format(limit))\n\n    try:\n        signal.signal(signal.SIGALRM, handler)\n        signal.setitimer(signal.ITIMER_REAL, limit)\n        yield\n    finally:\n        signal.alarm(0)", "response": "A context manager that sets a signal - based timeout to the current time limit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare a Python script or module to be imported as a module.", "response": "def prepare(path, name):  # type: (str, str) -> None\n    \"\"\"Prepare a Python script (or module) to be imported as a module.\n    If the script does not contain a setup.py file, it creates a minimal setup.\n    Args:\n        path (str): path to directory with the script or module.\n        name (str): name of the script or module.\n    \"\"\"\n    setup_path = os.path.join(path, 'setup.py')\n    if not os.path.exists(setup_path):\n        data = textwrap.dedent(\"\"\"\n        from setuptools import setup\n        setup(packages=[''],\n              name=\"%s\",\n              version='1.0.0',\n              include_package_data=True)\n        \"\"\" % name)\n\n        logger.info('Module %s does not provide a setup.py. \\nGenerating setup.py' % name)\n\n        _files.write_file(setup_path, data)\n\n        data = textwrap.dedent(\"\"\"\n        [wheel]\n        universal = 1\n        \"\"\")\n\n        logger.info('Generating setup.cfg')\n\n        _files.write_file(os.path.join(path, 'setup.cfg'), data)\n\n        data = textwrap.dedent(\"\"\"\n        recursive-include . *\n        recursive-exclude . __pycache__*\n        recursive-exclude . *.pyc\n        recursive-exclude . *.pyo\n        \"\"\")\n\n        logger.info('Generating MANIFEST.in')\n\n        _files.write_file(os.path.join(path, 'MANIFEST.in'), data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install(path, capture_error=False):  # type: (str, bool) -> None\n    cmd = '%s -m pip install -U . ' % _process.python_executable()\n\n    if has_requirements(path):\n        cmd += '-r requirements.txt'\n\n    logger.info('Installing module with the following command:\\n%s', cmd)\n\n    _process.check_error(shlex.split(cmd), _errors.InstallModuleError, cwd=path, capture_error=capture_error)", "response": "Install a Python module in the executing Python environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_and_install(uri, name=DEFAULT_MODULE_NAME, cache=True):\n    # type: (str, str, bool) -> None\n    \"\"\"Download, prepare and install a compressed tar file from S3 or local directory as a module.\n\n    The SageMaker Python SDK saves the user provided scripts as compressed tar files in S3.\n    This function downloads this compressed file and, if provided, transforms it\n    into a module before installing it.\n\n    This method is the predecessor of :meth:`~sagemaker_containers.beta.framework.files.download_and_extract`\n    and has been kept for backward-compatibility purposes.\n\n    Args:\n        name (str): name of the script or module.\n        uri (str): the location of the module.\n        cache (bool): defaults to True. It will not download and install the module again if it is already installed.\n    \"\"\"\n    should_use_cache = cache and exists(name)\n\n    if not should_use_cache:\n        with _files.tmpdir() as tmpdir:\n            if uri.startswith('s3://'):\n                dst = os.path.join(tmpdir, 'tar_file')\n                _files.s3_download(uri, dst)\n                module_path = os.path.join(tmpdir, 'module_dir')\n                os.makedirs(module_path)\n\n                with tarfile.open(name=dst, mode='r:gz') as t:\n                    t.extractall(path=module_path)\n\n            else:\n                module_path = uri\n\n            prepare(module_path, name)\n            install(module_path)", "response": "Download prepare and install a compressed tar file from S3 or local directory as a module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(module_name, args=None, env_vars=None, wait=True, capture_error=False):\n    # type: (str, list, dict, bool, bool) -> subprocess.Popen\n    \"\"\"Run Python module as a script.\n\n    Search sys.path for the named module and execute its contents as the __main__ module.\n\n    Since the argument is a module name, you must not give a file extension (.py). The module name should be a valid\n    absolute Python module name, but the implementation may not always enforce this (e.g. it may allow you to use a name\n    that includes a hyphen).\n\n    Package names (including namespace packages) are also permitted. When a package name is supplied instead of a\n    normal module, the interpreter will execute <pkg>.__main__ as the main module. This behaviour is deliberately\n    similar to the handling of directories and zipfiles that are passed to the interpreter as the script argument.\n\n    Note This option cannot be used with built-in modules and extension modules written in C, since they do not have\n    Python module files. However, it can still be used for precompiled modules, even if the original source file is\n    not available. If this option is given, the first element of sys.argv will be the full path to the module file (\n    while the module file is being located, the first element will be set to \"-m\"). As with the -c option,\n    the current directory will be added to the start of sys.path.\n\n    You can find more information at https://docs.python.org/3/using/cmdline.html#cmdoption-m\n\n    Example:\n\n        >>>import sagemaker_containers\n        >>>from sagemaker_containers.beta.framework import mapping, modules\n\n        >>>env = sagemaker_containers.training_env()\n        {'channel-input-dirs': {'training': '/opt/ml/input/training'}, 'model_dir': '/opt/ml/model', ...}\n\n\n        >>>hyperparameters = env.hyperparameters\n        {'batch-size': 128, 'model_dir': '/opt/ml/model'}\n\n        >>>args = mapping.to_cmd_args(hyperparameters)\n        ['--batch-size', '128', '--model_dir', '/opt/ml/model']\n\n        >>>env_vars = mapping.to_env_vars()\n        ['SAGEMAKER_CHANNELS':'training', 'SAGEMAKER_CHANNEL_TRAINING':'/opt/ml/input/training',\n        'MODEL_DIR':'/opt/ml/model', ...}\n\n        >>>modules.run('user_script', args, env_vars)\n        SAGEMAKER_CHANNELS=training SAGEMAKER_CHANNEL_TRAINING=/opt/ml/input/training \\\n        SAGEMAKER_MODEL_DIR=/opt/ml/model python -m user_script --batch-size 128 --model_dir /opt/ml/model\n\n    Args:\n        module_name (str): module name in the same format required by python -m <module-name> cli command.\n        args (list):  A list of program arguments.\n        env_vars (dict): A map containing the environment variables to be written.\n        capture_error (bool): Default false. If True, the running process captures the\n            stderr, and appends it to the returned Exception message in case of errors.\n    \"\"\"\n    args = args or []\n    env_vars = env_vars or {}\n\n    cmd = [_process.python_executable(), '-m', module_name] + args\n\n    _logging.log_script_invocation(cmd, env_vars)\n\n    if wait:\n        return _process.check_error(cmd, _errors.ExecuteUserScriptError, capture_error=capture_error)\n\n    else:\n        return _process.create(cmd, _errors.ExecuteUserScriptError, capture_error=capture_error)", "response": "Run a module as a script."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_module(uri, name=DEFAULT_MODULE_NAME, cache=None):  # type: (str, str, bool) -> module\n    _warning_cache_deprecation(cache)\n    _files.download_and_extract(uri, name, _env.code_dir)\n\n    prepare(_env.code_dir, name)\n    install(_env.code_dir)\n    try:\n        module = importlib.import_module(name)\n        six.moves.reload_module(module)\n\n        return module\n    except Exception as e:\n        six.reraise(_errors.ImportModuleError, _errors.ImportModuleError(e), sys.exc_info()[2])", "response": "Imports a module from S3 or provided directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading prepare and execute a module from S3 or provided directory and runs it.", "response": "def run_module(uri, args, env_vars=None, name=DEFAULT_MODULE_NAME, cache=None, wait=True, capture_error=False):\n    # type: (str, list, dict, str, bool, bool, bool) -> subprocess.Popen\n    \"\"\"Download, prepare and executes a compressed tar file from S3 or provided directory as a module.\n\n    SageMaker Python SDK saves the user provided scripts as compressed tar files in S3\n    https://github.com/aws/sagemaker-python-sdk.\n    This function downloads this compressed file, transforms it as a module, and executes it.\n    Args:\n        uri (str): the location of the module.\n        args (list):  A list of program arguments.\n        env_vars (dict): A map containing the environment variables to be written.\n        name (str): name of the script or module.\n        cache (bool): If True it will avoid downloading the module again, if already installed.\n        wait (bool): If True run_module will wait for the user module to exit and check the exit code,\n                     otherwise it will launch the user module with subprocess and return the process object.\n    \"\"\"\n    _warning_cache_deprecation(cache)\n    env_vars = env_vars or {}\n    env_vars = env_vars.copy()\n\n    _files.download_and_extract(uri, name, _env.code_dir)\n\n    prepare(_env.code_dir, name)\n    install(_env.code_dir)\n\n    _env.write_env_vars(env_vars)\n\n    return run(name, args, env_vars, wait, capture_error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef content_type(self):  # type: () -> str\n        # todo(mvsusp): consider a better default content-type\n        return self.headers.get('ContentType') or self.headers.get(\n            'Content-Type') or _content_types.JSON", "response": "The value of the Content - Type header of the request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef accept(self):  # type: () -> str\n        accept = self.headers.get('Accept')\n\n        if not accept or accept == _content_types.ANY:\n            return self._default_accept\n        else:\n            return accept", "response": "The content - type for the response to the client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef content(self):  # type: () -> object\n        as_text = self.content_type in _content_types.UTF8_TYPES\n\n        return self.get_data(as_text=as_text)", "response": "The request incoming data.\n            It automatic decodes from utf - 8"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(uri,\n        user_entry_point,\n        args,\n        env_vars=None,\n        wait=True,\n        capture_error=False,\n        runner=_runner.ProcessRunnerType,\n        extra_opts=None):\n    # type: (str, str, List[str], Dict[str, str], bool, bool, _runner.RunnerType, Dict[str, str]) -> None\n    \"\"\"Download, prepare and executes a compressed tar file from S3 or provided directory as an user\n    entrypoint. Runs the user entry point, passing env_vars as environment variables and args as command\n    arguments.\n\n    If the entry point is:\n        - A Python package: executes the packages as >>> env_vars python -m module_name + args\n        - A Python script: executes the script as >>> env_vars python module_name + args\n        - Any other: executes the command as >>> env_vars /bin/sh -c ./module_name + args\n\n    Example:\n         >>>import sagemaker_containers\n         >>>from sagemaker_containers.beta.framework import entry_point\n\n         >>>env = sagemaker_containers.training_env()\n         {'channel-input-dirs': {'training': '/opt/ml/input/training'}, 'model_dir': '/opt/ml/model', ...}\n\n\n         >>>hyperparameters = env.hyperparameters\n         {'batch-size': 128, 'model_dir': '/opt/ml/model'}\n\n         >>>args = mapping.to_cmd_args(hyperparameters)\n         ['--batch-size', '128', '--model_dir', '/opt/ml/model']\n\n         >>>env_vars = mapping.to_env_vars()\n         ['SAGEMAKER_CHANNELS':'training', 'SAGEMAKER_CHANNEL_TRAINING':'/opt/ml/input/training',\n         'MODEL_DIR':'/opt/ml/model', ...}\n\n         >>>entry_point.run('user_script', args, env_vars)\n         SAGEMAKER_CHANNELS=training SAGEMAKER_CHANNEL_TRAINING=/opt/ml/input/training \\\n         SAGEMAKER_MODEL_DIR=/opt/ml/model python -m user_script --batch-size 128 --model_dir /opt/ml/model\n\n    Args:\n        uri (str): the location of the module.\n        user_entry_point (str): name of the user provided entry point\n        args (list):  A list of program arguments.\n        env_vars (dict): A map containing the environment variables to be written (default: None).\n        wait (bool): If the user entry point should be run to completion before this method returns\n            (default: True).\n        capture_error (bool): Default false. If True, the running process captures the\n            stderr, and appends it to the returned Exception message in case of errors.\n        runner (sagemaker_containers.beta.framework.runner.RunnerType): the type of runner object to\n            be created (default: sagemaker_containers.beta.framework.runner.ProcessRunnerType).\n        extra_opts (dict): Additional options for running the entry point (default: None).\n            Currently, this only applies for MPI.\n\n    Returns:\n        sagemaker_containers.beta.framework.process.ProcessRunner: the runner object responsible for\n            executing the entry point.\n    \"\"\"\n    env_vars = env_vars or {}\n    env_vars = env_vars.copy()\n\n    _files.download_and_extract(uri, user_entry_point, _env.code_dir)\n\n    install(user_entry_point, _env.code_dir, capture_error)\n\n    _env.write_env_vars(env_vars)\n\n    return _runner.get(runner, user_entry_point, args, env_vars, extra_opts).run(wait, capture_error)", "response": "Download and execute a compressed tar file from S3 or provided directory as an user\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls the user provided entry point to be executed as follow", "response": "def install(name, dst, capture_error=False):\n    \"\"\"Install the user provided entry point to be executed as follow:\n        - add the path to sys path\n        - if the user entry point is a command, gives exec permissions to the script\n\n    Args:\n        name (str): name of the script or module.\n        dst (str): path to directory with the script or module.\n        capture_error (bool): Default false. If True, the running process captures the\n            stderr, and appends it to the returned Exception message in case of errors.\n    \"\"\"\n    if dst not in sys.path:\n        sys.path.insert(0, dst)\n\n    entrypoint_type = _entry_point_type.get(dst, name)\n    if entrypoint_type is _entry_point_type.PYTHON_PACKAGE:\n        _modules.install(dst, capture_error)\n    if entrypoint_type is _entry_point_type.COMMAND:\n        os.chmod(os.path.join(dst, name), 511)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting logger configuration. Args: level (int): Logger level format (str): Logger format", "response": "def configure_logger(level, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s'):\n    # type: (int, str) -> None\n    \"\"\"Set logger configuration.\n\n    Args:\n        level (int): Logger level\n        format (str): Logger format\n    \"\"\"\n    logging.basicConfig(format=format, level=level)\n\n    if level >= logging.INFO:\n        logging.getLogger('boto3').setLevel(logging.INFO)\n        logging.getLogger('s3transfer').setLevel(logging.INFO)\n        logging.getLogger('botocore').setLevel(logging.WARN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _timestamp():\n    moment = time.time()\n    moment_us = repr(moment).split('.')[1]\n    return time.strftime(\"%Y-%m-%d-%H-%M-%S-{}\".format(moment_us), time.gmtime(moment))", "response": "Return a timestamp with microsecond precision."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwatching the directory tree and uploads files to s3.", "response": "def _watch(inotify, watchers, watch_flags, s3_uploader):\n    \"\"\"As soon as a user is done with a file under `/opt/ml/output/intermediate`\n    we would get notified by using inotify. We would copy this file under\n    `/opt/ml/output/intermediate/.tmp.sagemaker_s3_sync` folder preserving\n    the same folder structure to prevent it from being further modified.\n    As we copy the file we would add timestamp with microseconds precision\n    to avoid modification during s3 upload.\n    After that we copy the file to s3 in a separate Thread.\n    We keep the queue of the files we need to move as FIFO.\n    \"\"\"\n    # initialize a thread pool with 1 worker\n    # to be used for uploading files to s3 in a separate thread\n    executor = futures.ThreadPoolExecutor(max_workers=1)\n\n    last_pass_done = False\n    stop_file_exists = False\n\n    # after we see stop file do one additional pass to make sure we didn't miss anything\n    while not last_pass_done:\n        # wait for any events in the directory for 1 sec and then re-check exit conditions\n        for event in inotify.read(timeout=1000):\n            for flag in inotify_simple.flags.from_mask(event.mask):\n                # if new directory was created traverse the directory tree to recursively add all\n                # created folders to the watchers list.\n                # Upload files to s3 if there any files.\n                # There is a potential race condition if upload the file and the see a notification\n                # for it which should cause any problems because when we copy files to temp dir\n                # we add a unique timestamp up to microseconds.\n                if flag is inotify_simple.flags.ISDIR and inotify_simple.flags.CREATE & event.mask:\n                    path = os.path.join(intermediate_path, watchers[event.wd], event.name)\n                    for folder, dirs, files in os.walk(path):\n                        wd = inotify.add_watch(folder, watch_flags)\n                        relative_path = os.path.relpath(folder, intermediate_path)\n                        watchers[wd] = relative_path\n                        tmp_sub_folder = os.path.join(tmp_dir_path, relative_path)\n                        if not os.path.exists(tmp_sub_folder):\n                            os.makedirs(tmp_sub_folder)\n                        for file in files:\n                            _copy_file(executor, s3_uploader, relative_path, file)\n                elif flag is inotify_simple.flags.CLOSE_WRITE:\n                    _copy_file(executor, s3_uploader, watchers[event.wd], event.name)\n\n        last_pass_done = stop_file_exists\n        stop_file_exists = os.path.exists(success_file_path) or os.path.exists(failure_file_path)\n\n    # wait for all the s3 upload tasks to finish and shutdown the executor\n    executor.shutdown(wait=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_sync(s3_output_location, region):\n    if not s3_output_location or os.path.exists(intermediate_path):\n        logger.debug('Could not initialize intermediate folder sync to s3.')\n        return\n\n    # create intermediate and intermediate_tmp directories\n    os.makedirs(intermediate_path)\n    os.makedirs(tmp_dir_path)\n\n    # configure unique s3 output location similar to how SageMaker platform does it\n    # or link it to the local output directory\n    url = urlparse(s3_output_location)\n    if url.scheme == 'file':\n        logger.debug('Local directory is used for output. No need to sync any intermediate output.')\n        return\n    elif url.scheme != 's3':\n        raise ValueError(\"Expecting 's3' scheme, got: %s in %s\" % (url.scheme, url))\n\n    # create s3 transfer client\n    client = boto3.client('s3', region)\n    s3_transfer = s3transfer.S3Transfer(client)\n    s3_uploader = {\n        'transfer': s3_transfer,\n        'bucket': url.netloc,\n        'key_prefix': os.path.join(url.path.lstrip('/'), os.environ.get('TRAINING_JOB_NAME', ''),\n                                   'output', 'intermediate'),\n    }\n\n    # Add intermediate folder to the watch list\n    inotify = inotify_simple.INotify()\n    watch_flags = inotify_simple.flags.CLOSE_WRITE | inotify_simple.flags.CREATE\n    watchers = {}\n    wd = inotify.add_watch(intermediate_path, watch_flags)\n    watchers[wd] = ''\n\n    # start subprocess to sync any files from intermediate folder to s3\n    p = multiprocessing.Process(target=_watch, args=[inotify, watchers, watch_flags, s3_uploader])\n    # Make the process daemonic as a safety switch to prevent training job from hanging forever\n    # in case if something goes wrong and main container process exits in an unexpected way\n    p.daemon = True\n    p.start()\n    return p", "response": "Starts a daemonic process which copies files from opt / ml output directory to the provided s3 output location."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_env_vars(mapping):  # type: (dict) -> dict\n\n    def format_key(key):\n        \"\"\"Decode a key, adds a SM_ prefix to the key and upper case it\"\"\"\n        if key:\n            decoded_name = 'SM_%s' % str(key).upper()\n            return decoded_name\n        else:\n            return ''\n\n    def format_value(_mapping):\n        if six.PY3 and isinstance(_mapping, six.binary_type):\n            # transforms a byte string (b'') in unicode\n            return _mapping.decode('latin1')\n        elif _mapping is None:\n            return ''\n        elif isinstance(_mapping, six.string_types):\n            return str(_mapping)\n        else:\n            return json.dumps(_mapping, sort_keys=True, separators=(',', ':'), ensure_ascii=True)\n\n    return {format_key(k): format_value(v) for k, v in mapping.items()}", "response": "Transform a dictionary of env vars into a dictionary of env vars."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_cmd_args(mapping):  # type: (dict) -> list\n\n    sorted_keys = sorted(mapping.keys())\n\n    def arg_name(obj):\n        string = _decode(obj)\n        if string:\n            return u'--%s' % string if len(string) > 1 else u'-%s' % string\n        else:\n            return u''\n\n    arg_names = [arg_name(argument) for argument in sorted_keys]\n\n    def arg_value(value):\n        if hasattr(value, 'items'):\n            map_items = ['%s=%s' % (k, v) for k, v in sorted(value.items())]\n            return ','.join(map_items)\n        return _decode(value)\n\n    arg_values = [arg_value(mapping[key]) for key in sorted_keys]\n\n    items = zip(arg_names, arg_values)\n\n    return [item for item in itertools.chain.from_iterable(items)]", "response": "Transform a dictionary in a list of cmd arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecodes an object to unicode.", "response": "def _decode(obj):  # type: (bytes or str or unicode or object) -> unicode # noqa ignore=F821\n    \"\"\"Decode an object to unicode.\n    Args:\n        obj (bytes or str or unicode or anything serializable): object to be decoded\n    Returns:\n        object decoded in unicode.\n    \"\"\"\n    if obj is None:\n        return u''\n    if six.PY3 and isinstance(obj, six.binary_type):\n        # transforms a byte string (b'') in unicode\n        return obj.decode('latin1')\n    elif six.PY3:\n        # PY3 strings are unicode.\n        return str(obj)\n    elif isinstance(obj, six.text_type):\n        # returns itself if it is unicode\n        return obj\n    else:\n        # decodes pY2 string to unicode\n        return str(obj).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split_by_criteria(dictionary, keys=None, prefix=None):  # type: (dict, set or list or tuple) -> SplitResultSpec\n    keys = keys or []\n    keys = set(keys)\n\n    included_items = {k: dictionary[k] for k in dictionary.keys() if k in keys or (prefix and k.startswith(prefix))}\n    excluded_items = {k: dictionary[k] for k in dictionary.keys() if k not in included_items}\n\n    return SplitResultSpec(included=included_items, excluded=excluded_items)", "response": "Splits a dictionary into two by the provided keys."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of public properties of the object.", "response": "def properties(self):  # type: () -> list\n        \"\"\"\n            Returns:\n                (list[str]) List of public properties\n        \"\"\"\n\n        _type = type(self)\n        return [_property for _property in dir(_type) if self._is_property(_property)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions responsible to serialize the prediction for the response.", "response": "def default_output_fn(prediction, accept):\n    \"\"\"Function responsible to serialize the prediction for the response.\n\n    Args:\n        prediction (obj): prediction returned by predict_fn .\n        accept (str): accept content-type expected by the client.\n\n    Returns:\n        (worker.Response): a Flask response object with the following args:\n\n            * Args:\n                response: the serialized data to return\n                accept: the content-type that the data was transformed to.\n    \"\"\"\n    return _worker.Response(response=_encoders.encode(prediction, accept), mimetype=accept)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform(self):  # type: () -> _worker.Response\n        request = _worker.Request()\n        result = self._transform_fn(self._model, request.content, request.content_type, request.accept)\n\n        if isinstance(result, tuple):\n            # transforms tuple in Response for backwards compatibility\n            return _worker.Response(response=result[0], mimetype=result[1])\n\n        return result", "response": "Take a request with input data deserialize it make a prediction and return a\n            serialized response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _default_transform_fn(self, model, content, content_type, accept):\n        try:\n            data = self._input_fn(content, content_type)\n        except _errors.UnsupportedFormatError as e:\n            return self._error_response(e, http_client.UNSUPPORTED_MEDIA_TYPE)\n\n        prediction = self._predict_fn(data, model)\n\n        try:\n            result = self._output_fn(prediction, accept)\n        except _errors.UnsupportedFormatError as e:\n            return self._error_response(e, http_client.NOT_ACCEPTABLE)\n\n        return result", "response": "This serves as the default implementation of transform_fn. It will predict the model and return a serialized response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the type of the entry point that is located at path and name.", "response": "def get(path, name):  # type: (str, str) -> _EntryPointType\n    \"\"\"\n    Args:\n        path (string): Directory where the entry point is located\n        name (string): Name of the entry point file\n\n    Returns:\n        (_EntryPointType): The type of the entry point\n    \"\"\"\n    if 'setup.py' in os.listdir(path):\n        return _EntryPointType.PYTHON_PACKAGE\n    elif name.endswith('.py'):\n        return _EntryPointType.PYTHON_PROGRAM\n    else:\n        return _EntryPointType.COMMAND"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a TrainingEnv object for training.", "response": "def training_env():  # type: () -> _env.TrainingEnv\n    \"\"\"Create a TrainingEnv.\n\n    Returns:\n        TrainingEnv: an instance of TrainingEnv\n    \"\"\"\n\n    from sagemaker_containers import _env\n\n    return _env.TrainingEnv(\n        resource_config=_env.read_resource_config(),\n        input_data_config=_env.read_input_data_config(),\n        hyperparameters=_env.read_hyperparameters())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a serializeable object as a JSON file", "response": "def _write_json(obj, path):  # type: (object, str) -> None\n    \"\"\"Writes a serializeable object as a JSON file\"\"\"\n    with open(path, 'w') as f:\n        json.dump(obj, f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_base_path_env():  # type: () -> None\n\n    local_config_dir = os.path.join(os.path.expanduser('~'), 'sagemaker_local', 'jobs',\n                                    str(time.time()), 'opt', 'ml')\n\n    logger.info('Setting environment variable SAGEMAKER_BASE_DIR as %s .' % local_config_dir)\n    os.environ[BASE_PATH_ENV] = local_config_dir", "response": "Sets the environment variable SAGEMAKER_BASE_DIR as\n    ~/sagemaker_local/{timestamp}/opt / ml\n    Returns True if SAGEMAKER_BASE_DIR is set False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_training_directories():\n    logger.info('Creating a new training folder under %s .' % base_dir)\n\n    os.makedirs(model_dir)\n    os.makedirs(input_config_dir)\n    os.makedirs(output_data_dir)\n\n    _write_json({}, hyperparameters_file_dir)\n    _write_json({}, input_data_config_file_dir)\n\n    host_name = socket.gethostname()\n\n    resources_dict = {\n        \"current_host\": host_name,\n        \"hosts\": [host_name]\n    }\n    _write_json(resources_dict, resource_config_file_dir)", "response": "Creates the directories needed for training under the base path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the hyperparameters from the hyperparameters. json file.", "response": "def read_hyperparameters():  # type: () -> dict\n    \"\"\"Read the hyperparameters from /opt/ml/input/config/hyperparameters.json.\n\n    For more information about hyperparameters.json:\n    https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-running-container-hyperparameters\n\n    Returns:\n         (dict[string, object]): a dictionary containing the hyperparameters.\n    \"\"\"\n    hyperparameters = _read_json(hyperparameters_file_dir)\n\n    deserialized_hps = {}\n\n    for k, v in hyperparameters.items():\n        try:\n            v = json.loads(v)\n        except (ValueError, TypeError):\n            logger.info(\"Failed to parse hyperparameter %s value %s to Json.\\n\"\n                        \"Returning the value itself\", k, v)\n\n        deserialized_hps[k] = v\n\n    return deserialized_hps"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef num_gpus():  # type: () -> int\n    try:\n        cmd = shlex.split('nvidia-smi --list-gpus')\n        output = subprocess.check_output(cmd).decode('utf-8')\n        return sum([1 for x in output.split('\\n') if x.startswith('GPU ')])\n    except (OSError, subprocess.CalledProcessError):\n        logger.info('No GPUs detected (normal if no gpus installed)')\n        return 0", "response": "Returns the number of GPUs available in the current container."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the dictionary env_vars in the system as environment variables.", "response": "def write_env_vars(env_vars=None):  # type: (dict) -> None\n    \"\"\"Write the dictionary env_vars in the system, as environment variables.\n\n    Args:\n        env_vars ():\n\n    Returns:\n\n    \"\"\"\n    env_vars = env_vars or {}\n    env_vars['PYTHONPATH'] = ':'.join(sys.path)\n\n    for name, value in env_vars.items():\n        os.environ[name] = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an environment variable representation of the training environment", "response": "def to_env_vars(self):\n        \"\"\"Environment variable representation of the training environment\n\n        Returns:\n            dict: an instance of dictionary\n        \"\"\"\n\n        env = {\n            'hosts': self.hosts, 'network_interface_name': self.network_interface_name,\n            'hps': self.hyperparameters, 'user_entry_point': self.user_entry_point,\n            'framework_params': self.additional_framework_parameters,\n            'resource_config': self.resource_config, 'input_data_config': self.input_data_config,\n            'output_data_dir': self.output_data_dir,\n            'channels': sorted(self.channel_input_dirs.keys()),\n            'current_host': self.current_host, 'module_name': self.module_name,\n            'log_level': self.log_level,\n            'framework_module': self.framework_module, 'input_dir': self.input_dir,\n            'input_config_dir': self.input_config_dir, 'output_dir': self.output_dir,\n            'num_cpus': self.num_cpus,\n            'num_gpus': self.num_gpus, 'model_dir': self.model_dir, 'module_dir': self.module_dir,\n            'training_env': dict(self), 'user_args': self.to_cmd_args(),\n            'output_intermediate_dir': self.output_intermediate_dir\n        }\n\n        for name, path in self.channel_input_dirs.items():\n            env['channel_%s' % name] = path\n\n        for key, value in self.hyperparameters.items():\n            env['hp_%s' % key] = value\n\n        return _mapping.to_env_vars(env)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef array_to_npy(array_like):  # type: (np.array or Iterable or int or float) -> object\n    buffer = BytesIO()\n    np.save(buffer, array_like)\n    return buffer.getvalue()", "response": "Converts an array like object to the NPY format."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts an NPY array into a numpy array.", "response": "def npy_to_numpy(npy_array):  # type: (object) -> np.array\n    \"\"\"Convert an NPY array into numpy.\n\n    Args:\n        npy_array (npy array): to be converted to numpy array\n    Returns:\n        (np.array): converted numpy array.\n    \"\"\"\n    stream = BytesIO(npy_array)\n    return np.load(stream, allow_pickle=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an array like object to JSON.", "response": "def array_to_json(array_like):  # type: (np.array or Iterable or int or float) -> str\n    \"\"\"Convert an array like object to JSON.\n\n    To understand better what an array like object is see:\n    https://docs.scipy.org/doc/numpy/user/basics.creation.html#converting-python-array-like-objects-to-numpy-arrays\n\n    Args:\n        array_like (np.array or Iterable or int or float): array like object to be converted to JSON.\n\n    Returns:\n        (str): object serialized to JSON\n    \"\"\"\n\n    def default(_array_like):\n        if hasattr(_array_like, 'tolist'):\n            return _array_like.tolist()\n        return json.JSONEncoder().default(_array_like)\n\n    return json.dumps(array_like, default=default)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a JSON string to a numpy array.", "response": "def json_to_numpy(string_like, dtype=None):  # type: (str) -> np.array\n    \"\"\"Convert a JSON object to a numpy array.\n\n        Args:\n            string_like (str): JSON string.\n            dtype (dtype, optional):  Data type of the resulting array. If None, the dtypes will be determined by the\n                                        contents of each column, individually. This argument can only be used to\n                                        'upcast' the array.  For downcasting, use the .astype(t) method.\n        Returns:\n            (np.array): numpy array\n        \"\"\"\n    data = json.loads(string_like)\n    return np.array(data, dtype=dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef csv_to_numpy(string_like, dtype=None):  # type: (str) -> np.array\n    stream = StringIO(string_like)\n    return np.genfromtxt(stream, dtype=dtype, delimiter=',')", "response": "Convert a CSV string to a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an array like object to CSV", "response": "def array_to_csv(array_like):  # type: (np.array or Iterable or int or float) -> str\n    \"\"\"Convert an array like object to CSV.\n\n    To understand better what an array like object is see:\n    https://docs.scipy.org/doc/numpy/user/basics.creation.html#converting-python-array-like-objects-to-numpy-arrays\n\n    Args:\n        array_like (np.array or Iterable or int or float): array like object to be converted to CSV.\n\n    Returns:\n        (str): object serialized to CSV\n    \"\"\"\n    stream = StringIO()\n    np.savetxt(stream, array_like, delimiter=',', fmt='%s')\n    return stream.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode an object ton a one of the default content types to a numpy array.", "response": "def decode(obj, content_type):\n    # type: (np.array or Iterable or int or float, str) -> np.array\n    \"\"\"Decode an object ton a one of the default content types to a numpy array.\n\n    Args:\n        obj (object): to be decoded.\n        content_type (str): content type to be used.\n\n    Returns:\n        np.array: decoded object.\n    \"\"\"\n    try:\n        decoder = _decoders_map[content_type]\n        return decoder(obj)\n    except KeyError:\n        raise _errors.UnsupportedFormatError(content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding an array like object in a specific content type to a numpy array.", "response": "def encode(array_like, content_type):\n    # type: (np.array or Iterable or int or float, str) -> np.array\n    \"\"\"Encode an array like object in a specific content_type to a numpy array.\n\n    To understand better what an array like object is see:\n    https://docs.scipy.org/doc/numpy/user/basics.creation.html#converting-python-array-like-objects-to-numpy-arrays\n\n    Args:\n        array_like (np.array or Iterable or int or float): to be converted to numpy.\n        content_type (str): content type to be used.\n\n    Returns:\n        (np.array): object converted as numpy array.\n    \"\"\"\n    try:\n        encoder = _encoders_map[content_type]\n        return encoder(array_like)\n    except KeyError:\n        raise _errors.UnsupportedFormatError(content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_success_file():  # type: () -> None\n    file_path = os.path.join(_env.output_dir, 'success')\n    empty_content = ''\n    write_file(file_path, empty_content)", "response": "Create a file success when training is successful."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_failure_file(failure_msg):  # type: (str) -> None\n    file_path = os.path.join(_env.output_dir, 'failure')\n    write_file(file_path, failure_msg)", "response": "Write a file to the output directory of the failure."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a temporary directory with a context manager.", "response": "def tmpdir(suffix='', prefix='tmp', dir=None):  # type: (str, str, str) -> None\n    \"\"\"Create a temporary directory with a context manager. The file is deleted when the context exits.\n\n    The prefix, suffix, and dir arguments are the same as for mkstemp().\n\n    Args:\n        suffix (str):  If suffix is specified, the file name will end with that suffix, otherwise there will be no\n                        suffix.\n        prefix (str):  If prefix is specified, the file name will begin with that prefix; otherwise,\n                        a default prefix is used.\n        dir (str):  If dir is specified, the file will be created in that directory; otherwise, a default directory is\n                        used.\n    Returns:\n        str: path to the directory\n    \"\"\"\n    tmp = tempfile.mkdtemp(suffix=suffix, prefix=prefix, dir=dir)\n    yield tmp\n    shutil.rmtree(tmp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_file(path, data, mode='w'):  # type: (str, str, str) -> None\n    with open(path, mode) as f:\n        f.write(data)", "response": "Writes data to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads and extract a compressed tar file from S3 or local directory.", "response": "def download_and_extract(uri, name, path):  # type: (str, str, str) -> None\n    \"\"\"Download, prepare and install a compressed tar file from S3 or local directory as an entry point.\n\n    SageMaker Python SDK saves the user provided entry points as compressed tar files in S3\n\n    Args:\n        name (str): name of the entry point.\n        uri (str): the location of the entry point.\n        path (bool): The path where the script will be installed. It will not download and install the\n                        if the path already has the user entry point.\n    \"\"\"\n    if not os.path.exists(path):\n        os.makedirs(path)\n    if not os.listdir(path):\n        with tmpdir() as tmp:\n            if uri.startswith('s3://'):\n                dst = os.path.join(tmp, 'tar_file')\n                s3_download(uri, dst)\n\n                with tarfile.open(name=dst, mode='r:gz') as t:\n                    t.extractall(path=path)\n\n            elif os.path.isdir(uri):\n                if uri == path:\n                    return\n                if os.path.exists(path):\n                    shutil.rmtree(path)\n                shutil.move(uri, path)\n            else:\n                shutil.copy2(uri, os.path.join(path, name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload a file from S3.", "response": "def s3_download(url, dst):  # type: (str, str) -> None\n    \"\"\"Download a file from S3.\n\n    Args:\n        url (str): the s3 url of the file.\n        dst (str): the destination where the file will be saved.\n    \"\"\"\n    url = parse.urlparse(url)\n\n    if url.scheme != 's3':\n        raise ValueError(\"Expecting 's3' scheme, got: %s in %s\" % (url.scheme, url))\n\n    bucket, key = url.netloc, url.path.lstrip('/')\n\n    region = os.environ.get('AWS_REGION', os.environ.get(_params.REGION_NAME_ENV))\n    s3 = boto3.resource('s3', region_name=region)\n\n    s3.Bucket(bucket).download_file(key, dst)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a function fn and a dictionary returns the function arguments that match the dict keys.", "response": "def matching_args(fn, dictionary):  # type: (Callable, _mapping.Mapping) -> dict\n    \"\"\"Given a function fn and a dict dictionary, returns the function arguments that match the dict keys.\n\n    Example:\n\n        def train(channel_dirs, model_dir): pass\n\n        dictionary = {'channel_dirs': {}, 'model_dir': '/opt/ml/model', 'other_args': None}\n\n        args = functions.matching_args(train, dictionary) # {'channel_dirs': {}, 'model_dir': '/opt/ml/model'}\n\n        train(**args)\n    Args:\n        fn (function): a function\n        dictionary (dict): the dictionary with the keys\n\n    Returns:\n        (dict) a dictionary with only matching arguments.\n    \"\"\"\n    arg_spec = getargspec(fn)\n\n    if arg_spec.keywords:\n        return dictionary\n\n    return _mapping.split_by_criteria(dictionary, arg_spec.args).included"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the names and default values of a function s arguments.", "response": "def getargspec(fn):  # type: (Callable) -> inspect.ArgSpec\n    \"\"\"Get the names and default values of a function's arguments.\n\n    Args:\n        fn (function): a function\n\n    Returns:\n        `inspect.ArgSpec`:  A collections.namedtuple with the following attributes:\n\n            * Args:\n                args (list): a list of the argument names (it may contain nested lists).\n                varargs (str): name of the * argument or None.\n                keywords (str): names of the ** argument or None.\n                defaults (tuple): an n-tuple of the default values of the last n arguments.\n    \"\"\"\n    if six.PY2:\n        return inspect.getargspec(fn)\n    elif six.PY3:\n        full_arg_spec = inspect.getfullargspec(fn)\n        return inspect.ArgSpec(full_arg_spec.args, full_arg_spec.varargs, full_arg_spec.varkw, full_arg_spec.defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps a function fn in a try catch block that re - raises error_class.", "response": "def error_wrapper(fn, error_class):  # type: (Callable or None, Exception) -> ...\n    \"\"\"Wraps function fn in a try catch block that re-raises error_class.\n\n    Args:\n        fn (function): function to wrapped\n        error_class (Exception): Error class to be re-raised\n\n    Returns:\n        (object): fn wrapped in a try catch.\n    \"\"\"\n    def wrapper(*args, **kwargs):\n        try:\n            return fn(*args, **kwargs)\n        except Exception as e:\n            six.reraise(error_class, error_class(e), sys.exc_info()[2])\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ceph_is_installed(module):\n    ceph_package = Ceph(module.conn)\n    if not ceph_package.installed:\n        host = module.conn.hostname\n        raise RuntimeError(\n            'ceph needs to be installed in remote host: %s' % host\n        )", "response": "A helper callback to be executed after the connection is made to ensure that Ceph is installed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_version_output(self):\n        if not self.executable:\n            return ''\n        command = [self.executable, '--version']\n        out, _, _ = self._check(self.conn, command)\n        try:\n            return out.decode('utf-8').split()[2]\n        except IndexError:\n            return ''", "response": "Get the version output of ceph version"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the running system s terminal supports color and False otherwise.", "response": "def supports_color():\n    \"\"\"\n    Returns True if the running system's terminal supports color, and False\n    otherwise.\n    \"\"\"\n    unsupported_platform = (sys.platform in ('win32', 'Pocket PC'))\n    # isatty is not always implemented, #6223.\n    is_a_tty = hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()\n    if unsupported_platform or not is_a_tty:\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a ColoredFormatter object that will use the color_message function if the system supports it", "response": "def color_format():\n    \"\"\"\n    Main entry point to get a colored formatter, it will use the\n    BASE_FORMAT by default and fall back to no colors if the system\n    does not support it\n    \"\"\"\n    str_format = BASE_COLOR_FORMAT if supports_color() else BASE_FORMAT\n    color_format = color_message(str_format)\n    return ColoredFormatter(color_format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mon_status_check(conn, logger, hostname, args):\n    asok_path = paths.mon.asok(args.cluster, hostname)\n\n    out, err, code = remoto.process.check(\n        conn,\n        [\n            'ceph',\n            '--cluster={cluster}'.format(cluster=args.cluster),\n            '--admin-daemon',\n            asok_path,\n            'mon_status',\n        ],\n    )\n\n    for line in err:\n        logger.error(line)\n\n    try:\n        return json.loads(b''.join(out).decode('utf-8'))\n    except ValueError:\n        return {}", "response": "A direct check for JSON output on the monitor status."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncatching up common mishaps with monitors and monitor status checks and return a new node.", "response": "def catch_mon_errors(conn, logger, hostname, cfg, args):\n    \"\"\"\n    Make sure we are able to catch up common mishaps with monitors\n    and use that state of a monitor to determine what is missing\n    and warn apropriately about it.\n    \"\"\"\n    monmap = mon_status_check(conn, logger, hostname, args).get('monmap', {})\n    mon_initial_members = get_mon_initial_members(args, _cfg=cfg)\n    public_addr = cfg.safe_get('global', 'public_addr')\n    public_network = cfg.safe_get('global', 'public_network')\n    mon_in_monmap = [\n        mon.get('name')\n        for mon in monmap.get('mons', [{}])\n        if mon.get('name') == hostname\n    ]\n    if mon_initial_members is None or not hostname in mon_initial_members:\n            logger.warning('%s is not defined in `mon initial members`', hostname)\n    if not mon_in_monmap:\n        logger.warning('monitor %s does not exist in monmap', hostname)\n        if not public_addr and not public_network:\n            logger.warning('neither `public_addr` nor `public_network` keys are defined for monitors')\n            logger.warning('monitors may not be able to form quorum')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns ``ceph daemon mon.`hostname` mon_status`` on the remote end and provide not only the output, but be able to return a boolean status of what is going on. ``False`` represents a monitor that is not doing OK even if it is up and running, while ``True`` would mean the monitor is up and running correctly.", "response": "def mon_status(conn, logger, hostname, args, silent=False):\n    \"\"\"\n    run ``ceph daemon mon.`hostname` mon_status`` on the remote end and provide\n    not only the output, but be able to return a boolean status of what is\n    going on.\n    ``False`` represents a monitor that is not doing OK even if it is up and\n    running, while ``True`` would mean the monitor is up and running correctly.\n    \"\"\"\n    mon = 'mon.%s' % hostname\n\n    try:\n        out = mon_status_check(conn, logger, hostname, args)\n        if not out:\n            logger.warning('monitor: %s, might not be running yet' % mon)\n            return False\n\n        if not silent:\n            logger.debug('*'*80)\n            logger.debug('status for monitor: %s' % mon)\n            for line in json.dumps(out, indent=2, sort_keys=True).split('\\n'):\n                logger.debug(line)\n            logger.debug('*'*80)\n        if out['rank'] >= 0:\n            logger.info('monitor: %s is running' % mon)\n            return True\n        if out['rank'] == -1 and out['state']:\n            logger.info('monitor: %s is currently at the state of %s' % (mon, out['state']))\n            return True\n        logger.info('monitor: %s is not running' % mon)\n        return False\n    except RuntimeError:\n        logger.info('monitor: %s is not running' % mon)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef concatenate_keyrings(args):\n    keyring_path = os.path.abspath(args.keyrings)\n    LOG.info('concatenating keyrings from %s' % keyring_path)\n    LOG.info('to seed remote monitors')\n\n    keyrings = [\n        os.path.join(keyring_path, f) for f in os.listdir(keyring_path)\n        if os.path.isfile(os.path.join(keyring_path, f)) and f.endswith('.keyring')\n    ]\n\n    contents = []\n    seen_sections = {}\n\n    if not keyrings:\n        path_from_arg = os.path.abspath(args.keyrings)\n        raise RuntimeError('could not find any keyrings in %s' % path_from_arg)\n\n    for keyring in keyrings:\n        path = os.path.abspath(keyring)\n\n        for section in keyring_parser(path):\n            if not seen_sections.get(section):\n                seen_sections[section] = path\n                LOG.info('adding entity \"%s\" from keyring %s' % (section, path))\n                with open(path) as k:\n                    contents.append(k.read())\n            else:\n                LOG.warning('will not add keyring: %s' % path)\n                LOG.warning('entity \"%s\" from keyring %s is a duplicate' % (section, path))\n                LOG.warning('already present in keyring: %s' % seen_sections[section])\n\n    return ''.join(contents)", "response": "A helper to concatenate all keyrings into a single blob that will be used to inject it into remote monitors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the hostname in the remote host is compatible with the provided hostname.", "response": "def hostname_is_compatible(conn, logger, provided_hostname):\n    \"\"\"\n    Make sure that the host that we are connecting to has the same value as the\n    `hostname` in the remote host, otherwise mons can fail not reaching quorum.\n    \"\"\"\n    logger.debug('determining if provided host has same hostname in remote')\n    remote_hostname = conn.remote_module.shortname()\n    if remote_hostname == provided_hostname:\n        return\n    logger.warning('*'*80)\n    logger.warning('provided hostname must match remote hostname')\n    logger.warning('provided hostname: %s' % provided_hostname)\n    logger.warning('remote hostname: %s' % remote_hostname)\n    logger.warning('monitors may not reach quorum and create-keys will not complete')\n    logger.warning('*'*80)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_mon_initial_members(args, error_on_empty=False, _cfg=None):\n    if _cfg:\n        cfg = _cfg\n    else:\n        cfg = conf.ceph.load(args)\n    mon_initial_members = cfg.safe_get('global', 'mon_initial_members')\n    if not mon_initial_members:\n        if error_on_empty:\n            raise exc.NeedHostError(\n                'could not find `mon initial members` defined in ceph.conf'\n            )\n    else:\n        mon_initial_members = re.split(r'[,\\s]+', mon_initial_members)\n    return mon_initial_members", "response": "Read the Ceph config file and return the value of mon_initial_members"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_running(conn, args):\n    stdout, stderr, _ = remoto.process.check(\n        conn,\n        args\n    )\n    result_string = b' '.join(stdout)\n    for run_check in [b': running', b' start/running']:\n        if run_check in result_string:\n            return True\n    return False", "response": "Check the status of a specific object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef executable_path(conn, executable):\n    executable_path = conn.remote_module.which(executable)\n    if not executable_path:\n        raise ExecutableNotFound(executable, conn.hostname)\n    return executable_path", "response": "Remote validator that accepts a connection object to ensure that a certain\n    executable is available returning its full path if not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_upstart(conn):\n    # it may be possible that we may be systemd and the caller never checked\n    # before so lets do that\n    if is_systemd(conn):\n        return False\n\n    # get the initctl executable, if it doesn't exist we can't proceed so we\n    # are probably not upstart\n    initctl = conn.remote_module.which('initctl')\n    if not initctl:\n        return False\n\n    # finally, try and get output from initctl that might hint this is an upstart\n    # system. On a Ubuntu 14.04.2 system this would look like:\n    # $ initctl version\n    # init (upstart 1.12.1)\n    stdout, stderr, _ = remoto.process.check(\n        conn,\n        [initctl, 'version'],\n    )\n    result_string = b' '.join(stdout)\n    if b'upstart' in result_string:\n        return True\n    return False", "response": "Check if the current system is upstart."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenable a service on a remote host depending on the type of init system.", "response": "def enable_service(conn, service='ceph'):\n    \"\"\"\n    Enable a service on a remote host depending on the type of init system.\n    Obviously, this should be done for RHEL/Fedora/CentOS systems.\n\n    This function does not do any kind of detection.\n    \"\"\"\n    if is_systemd(conn):\n        remoto.process.run(\n            conn,\n            [\n                'systemctl',\n                'enable',\n                '{service}'.format(service=service),\n            ]\n        )\n    else:\n        remoto.process.run(\n            conn,\n            [\n                'chkconfig',\n                '{service}'.format(service=service),\n                'on',\n            ]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisables a service on a remote host depending on the type of init system.", "response": "def disable_service(conn, service='ceph'):\n    \"\"\"\n    Disable a service on a remote host depending on the type of init system.\n    Obviously, this should be done for RHEL/Fedora/CentOS systems.\n\n    This function does not do any kind of detection.\n    \"\"\"\n    if is_systemd(conn):\n        # Without the check, an error is raised trying to disable an\n        # already disabled service\n        if is_systemd_service_enabled(conn, service):\n            remoto.process.run(\n                conn,\n                [\n                    'systemctl',\n                    'disable',\n                    '{service}'.format(service=service),\n                ]\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop a service on a remote host depending on the type of init system.", "response": "def stop_service(conn, service='ceph'):\n    \"\"\"\n    Stop a service on a remote host depending on the type of init system.\n    Obviously, this should be done for RHEL/Fedora/CentOS systems.\n\n    This function does not do any kind of detection.\n    \"\"\"\n    if is_systemd(conn):\n        # Without the check, an error is raised trying to stop an\n        # already stopped service\n        if is_systemd_service_active(conn, service):\n            remoto.process.run(\n                conn,\n                [\n                    'systemctl',\n                    'stop',\n                    '{service}'.format(service=service),\n                ]\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_service(conn, service='ceph'):\n    if is_systemd(conn):\n        remoto.process.run(\n            conn,\n            [\n                'systemctl',\n                'start',\n                '{service}'.format(service=service),\n            ]\n        )", "response": "Start a service on a remote host depending on the type of init system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetecting if a systemd service is enabled or not.", "response": "def is_systemd_service_enabled(conn, service='ceph'):\n    \"\"\"\n    Detects if a systemd service is enabled or not.\n    \"\"\"\n    _, _, returncode = remoto.process.check(\n        conn,\n        [\n            'systemctl',\n            'is-enabled',\n            '--quiet',\n            '{service}'.format(service=service),\n        ]\n    )\n    return returncode == 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make(parser):\n\n    parser.add_argument(\n        'repo_name',\n        metavar='REPO-NAME',\n        help='Name of repo to manage.  Can match an entry in cephdeploy.conf'\n    )\n\n    parser.add_argument(\n        '--repo-url',\n        help='a repo URL that mirrors/contains Ceph packages'\n    )\n\n    parser.add_argument(\n        '--gpg-url',\n        help='a GPG key URL to be used with custom repos'\n    )\n\n    parser.add_argument(\n        '--remove', '--delete',\n        action='store_true',\n        help='remove repo definition on remote host'\n    )\n\n    parser.add_argument(\n        'host',\n        metavar='HOST',\n        nargs='+',\n        help='host(s) to install on'\n    )\n\n    parser.set_defaults(\n        func=repo\n    )", "response": "Manage a repo definition on a remote host"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets flags and defaults from values found in the configuration file.", "response": "def set_overrides(args, _conf=None):\n    \"\"\"\n    Read the configuration file and look for ceph-deploy sections\n    to set flags/defaults from the values found. This will alter the\n    ``args`` object that is created by argparse.\n    \"\"\"\n    # Get the subcommand name to avoid overwritting values from other\n    # subcommands that are not going to be used\n    subcommand = args.func.__name__\n    command_section = 'ceph-deploy-%s' % subcommand\n    conf = _conf or load()\n\n    for section_name in conf.sections():\n        if section_name in ['ceph-deploy-global', command_section]:\n            override_subcommand(\n                section_name,\n                conf.items(section_name),\n                args\n            )\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef override_subcommand(section_name, section_items, args):\n    # XXX We are not coercing here any int-like values, so if ArgParse\n    # does that in the CLI we are totally non-compliant with that expectation\n    # but we will try and infer a few boolean values\n\n    # acceptable boolean states for flags\n    _boolean_states = {'yes': True, 'true': True, 'on': True,\n                       'no': False, 'false': False, 'off': False}\n\n    for k, v, in section_items:\n        # get the lower case value of `v`, fallback to the booleanized\n        # (original) value of `v`\n        try:\n            normalized_value = v.lower()\n        except AttributeError:\n            # probably not a string object that has .lower\n            normalized_value = v\n        value = _boolean_states.get(normalized_value, v)\n        setattr(args, k, value)\n    return args", "response": "Override the subcommand with the values from the command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a configuration value from a certain section and key.", "response": "def get_safe(self, section, key, default=None):\n        \"\"\"\n        Attempt to get a configuration value from a certain section\n        in a ``cfg`` object but returning None if not found. Avoids the need\n        to be doing try/except {ConfigParser Exceptions} every time.\n        \"\"\"\n        try:\n            return self.get(section, key)\n        except (configparser.NoSectionError, configparser.NoOptionError):\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a boolean to reflect whether or not any repository sections are present in the archive.", "response": "def has_repos(self):\n        \"\"\"\n        boolean to reflect having (or not) any repository sections\n        \"\"\"\n        for section in self.sections():\n            if section not in self.reserved_sections:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_list(self, section, key):\n        value = self.get_safe(section, key, [])\n        if value == []:\n            return value\n\n        # strip comments\n        value = re.split(r'\\s+#', value)[0]\n\n        # split on commas\n        value = value.split(',')\n\n        # strip spaces\n        return [x.strip() for x in value]", "response": "Returns a list of items from a given section and key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_default_repo(self):\n        for repo in self.get_repos():\n            if self.get_safe(repo, 'default') and self.getboolean(repo, 'default'):\n                return repo\n        return False", "response": "Return the default repository if it exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_host_ip(ips, subnets):\n    # Make sure we prune ``None`` arguments\n    subnets = [s for s in subnets if s is not None]\n    validate_one_subnet = len(subnets) == 1\n\n    def ip_in_one_subnet(ips, subnet):\n        \"\"\" ensure an ip exists in at least one subnet \"\"\"\n        for ip in ips:\n            if net.ip_in_subnet(ip, subnet):\n                return True\n        return False\n\n    for subnet in subnets:\n        if ip_in_one_subnet(ips, subnet):\n            if validate_one_subnet:\n                return\n            else:  # keep going to make sure the other subnets are ok\n                continue\n        else:\n            msg = \"subnet (%s) is not valid for any of the ips found %s\" % (subnet, str(ips))\n            raise RuntimeError(msg)", "response": "Validate that a given host is valid for any of the given ips."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a list of IP addresses and a public subnet return the one IP that exists in the remote host that exists within the subnet range.", "response": "def get_public_network_ip(ips, public_subnet):\n    \"\"\"\n    Given a public subnet, chose the one IP from the remote host that exists\n    within the subnet range.\n    \"\"\"\n    for ip in ips:\n        if net.ip_in_subnet(ip, public_subnet):\n            return ip\n    msg = \"IPs (%s) are not valid for any of subnet specified %s\" % (str(ips), str(public_subnet))\n    raise RuntimeError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart deploying a new cluster, and write a CLUSTER.conf and keyring for it.", "response": "def make(parser):\n    \"\"\"\n    Start deploying a new cluster, and write a CLUSTER.conf and keyring for it.\n    \"\"\"\n    parser.add_argument(\n        'mon',\n        metavar='MON',\n        nargs='+',\n        help='initial monitor hostname, fqdn, or hostname:fqdn pair',\n        type=arg_validators.Hostname(),\n        )\n    parser.add_argument(\n        '--no-ssh-copykey',\n        dest='ssh_copykey',\n        action='store_false',\n        default=True,\n        help='do not attempt to copy SSH keys',\n    )\n\n    parser.add_argument(\n        '--fsid',\n        dest='fsid',\n        help='provide an alternate FSID for ceph.conf generation',\n    )\n\n    parser.add_argument(\n        '--cluster-network',\n        help='specify the (internal) cluster network',\n        type=arg_validators.Subnet(),\n    )\n\n    parser.add_argument(\n        '--public-network',\n        help='specify the public network for a cluster',\n        type=arg_validators.Subnet(),\n    )\n\n    parser.set_defaults(\n        func=new,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make(parser):\n    mds_parser = parser.add_subparsers(dest='subcommand')\n    mds_parser.required = True\n\n    mds_create = mds_parser.add_parser(\n        'create',\n        help='Deploy Ceph MDS on remote host(s)'\n    )\n    mds_create.add_argument(\n        'mds',\n        metavar='HOST[:NAME]',\n        nargs='+',\n        type=colon_separated,\n        help='host (and optionally the daemon name) to deploy on',\n        )\n    parser.set_defaults(\n        func=mds,\n        )", "response": "A helper function that creates Ceph MDS daemon management"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect a init system", "response": "def choose_init(module):\n    \"\"\"\n    Select a init system\n\n    Returns the name of a init system (upstart, sysvinit ...).\n    \"\"\"\n\n    if module.normalized_release.int_major < 7:\n        return 'sysvinit'\n\n    if not module.conn.remote_module.path_exists(\"/usr/lib/systemd/system/ceph.target\"):\n        return 'sysvinit'\n\n    if is_systemd(module.conn):\n        return 'systemd'\n\n    return 'systemd'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef install_yum_priorities(distro, _yum=None):\n    yum = _yum or pkg_managers.yum\n    package_name = 'yum-plugin-priorities'\n\n    if distro.normalized_name == 'centos':\n        if distro.release[0] != '6':\n            package_name = 'yum-priorities'\n    yum(distro.conn, package_name)", "response": "Installs the yum - priorities for the current package."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_exception_message(exc):\n    if str(exc):\n        return '%s: %s\\n' % (exc.__class__.__name__, exc)\n    else:\n        return '%s\\n' % (exc.__class__.__name__)", "response": "Make a nicely formatted exception message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef platform_information(_linux_distribution=None):\n    linux_distribution = _linux_distribution or platform.linux_distribution\n    distro, release, codename = linux_distribution()\n    if not distro:\n        distro, release, codename = parse_os_release()\n    if not codename and 'debian' in distro.lower():  # this could be an empty string in Debian\n        debian_codenames = {\n            '10': 'buster',\n            '9': 'stretch',\n            '8': 'jessie',\n            '7': 'wheezy',\n            '6': 'squeeze',\n        }\n        major_version = release.split('.')[0]\n        codename = debian_codenames.get(major_version, '')\n\n        # In order to support newer jessie/sid or wheezy/sid strings we test this\n        # if sid is buried in the minor, we should use sid anyway.\n        if not codename and '/' in release:\n            major, minor = release.split('/')\n            if minor == 'sid':\n                codename = minor\n            else:\n                codename = major\n    if not codename and 'oracle' in distro.lower():  # this could be an empty string in Oracle linux\n        codename = 'oracle'\n    if not codename and 'virtuozzo linux' in distro.lower():  # this could be an empty string in Virtuozzo linux\n        codename = 'virtuozzo'\n    if not codename and 'arch' in distro.lower():  # this could be an empty string in Arch linux\n        codename = 'arch'\n\n    return (\n        str(distro).rstrip(),\n        str(release).rstrip(),\n        str(codename).rstrip()\n    )", "response": "detect platform information from remote host"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_os_release(release_path='/etc/os-release'):\n    release_info = {}\n    if os.path.isfile(release_path):\n        for line in open(release_path, 'r').readlines():\n            line = line.strip()\n            if line.startswith('#'):\n                continue\n            parts = line.split('=')\n            if len(parts) != 2:\n                continue\n            release_info[parts[0].strip()] = parts[1].strip(\"\\\"'\\n\\t \")\n    # In theory, we want ID/NAME, VERSION_ID and VERSION_CODENAME (with a\n    # possible fallback to VERSION on the latter), based on information at:\n    # https://www.freedesktop.org/software/systemd/man/os-release.html\n    # However, after reviewing several distros /etc/os-release, getting\n    # the codename is a bit of a mess.  It's usually in parentheses in\n    # VERSION, with some exceptions.\n    distro = release_info.get('ID', '')\n    release = release_info.get('VERSION_ID', '')\n    codename = release_info.get('UBUNTU_CODENAME', release_info.get('VERSION', ''))\n    match = re.match(r'^[^(]+ \\(([^)]+)\\)', codename)\n    if match:\n        codename = match.group(1).lower()\n    if not codename and release_info.get('NAME', '') == 'openSUSE Tumbleweed':\n        codename = 'tumbleweed'\n    return (distro, release, codename)", "response": "Extract the distro release and codename from the os - release file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds deb repo to / etc / apt / sources. list. d", "response": "def write_sources_list(url, codename, filename='ceph.list', mode=0o644):\n    \"\"\"add deb repo to /etc/apt/sources.list.d/\"\"\"\n    repo_path = os.path.join('/etc/apt/sources.list.d', filename)\n    content = 'deb {url} {codename} main\\n'.format(\n        url=url,\n        codename=codename,\n    )\n    write_file(repo_path, content.encode('utf-8'), mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds deb repo to the sources. list. d folder from content", "response": "def write_sources_list_content(content, filename='ceph.list', mode=0o644):\n    \"\"\"add deb repo to /etc/apt/sources.list.d/ from content\"\"\"\n    repo_path = os.path.join('/etc/apt/sources.list.d', filename)\n    if not isinstance(content, str):\n        content = content.decode('utf-8')\n    write_file(repo_path, content.encode('utf-8'), mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_yum_repo(content, filename='ceph.repo'):\n    repo_path = os.path.join('/etc/yum.repos.d', filename)\n    if not isinstance(content, str):\n        content = content.decode('utf-8')\n    write_file(repo_path, content.encode('utf-8'))", "response": "add yum repo file in / etc."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_conf(cluster, conf, overwrite):\n    path = '/etc/ceph/{cluster}.conf'.format(cluster=cluster)\n    tmp_file = tempfile.NamedTemporaryFile('w', dir='/etc/ceph', delete=False)\n    err_msg = 'config file %s exists with different content; use --overwrite-conf to overwrite' % path\n\n    if os.path.exists(path):\n        with open(path, 'r') as f:\n            old = f.read()\n            if old != conf and not overwrite:\n                raise RuntimeError(err_msg)\n        tmp_file.write(conf)\n        tmp_file.close()\n        shutil.move(tmp_file.name, path)\n        os.chmod(path, 0o644)\n        return\n    if os.path.exists('/etc/ceph'):\n        with open(path, 'w') as f:\n            f.write(conf)\n        os.chmod(path, 0o644)\n    else:\n        err_msg = '/etc/ceph/ does not exist - could not write config'\n        raise RuntimeError(err_msg)", "response": "write cluster configuration to / etc."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_keyring(path, key, uid=-1, gid=-1):\n    # Note that we *require* to avoid deletion of the temp file\n    # otherwise we risk not being able to copy the contents from\n    # one file system to the other, hence the `delete=False`\n    tmp_file = tempfile.NamedTemporaryFile('wb', delete=False)\n    tmp_file.write(key)\n    tmp_file.close()\n    keyring_dir = os.path.dirname(path)\n    if not path_exists(keyring_dir):\n        makedir(keyring_dir, uid, gid)\n    shutil.move(tmp_file.name, path)", "response": "write a keyring file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the mon path if it does not exist", "response": "def create_mon_path(path, uid=-1, gid=-1):\n    \"\"\"create the mon path if it does not exist\"\"\"\n    if not os.path.exists(path):\n        os.makedirs(path)\n        os.chown(path, uid, gid);"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_done_path(done_path, uid=-1, gid=-1):\n    with open(done_path, 'wb'):\n        pass\n    os.chown(done_path, uid, gid);", "response": "create a done file to avoid re - doing the mon deployment"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the init path if it does not exist", "response": "def create_init_path(init_path, uid=-1, gid=-1):\n    \"\"\"create the init path if it does not exist\"\"\"\n    if not os.path.exists(init_path):\n        with open(init_path, 'wb'):\n            pass\n        os.chown(init_path, uid, gid);"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the monitor keyring file", "response": "def write_monitor_keyring(keyring, monitor_keyring, uid=-1, gid=-1):\n    \"\"\"create the monitor keyring file\"\"\"\n    write_file(keyring, monitor_keyring, 0o600, None, uid, gid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef which(executable):\n    locations = (\n        '/usr/local/bin',\n        '/bin',\n        '/usr/bin',\n        '/usr/local/sbin',\n        '/usr/sbin',\n        '/sbin',\n    )\n\n    for location in locations:\n        executable_path = os.path.join(location, executable)\n        if os.path.exists(executable_path) and os.path.isfile(executable_path):\n            return executable_path", "response": "find the location of an executable"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_mon_removed_dir(path, file_name):\n    try:\n        os.makedirs('/var/lib/ceph/mon-removed')\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n    shutil.move(path, os.path.join('/var/lib/ceph/mon-removed/', file_name))", "response": "move old monitor data to new monitor data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef safe_mkdir(path, uid=-1, gid=-1):\n    try:\n        os.mkdir(path)\n    except OSError as e:\n        if e.errno == errno.EEXIST:\n            pass\n        else:\n            raise\n    else:\n        os.chown(path, uid, gid)", "response": "create path if it doesn t exist"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating path recursively if it doesn t exist", "response": "def safe_makedirs(path, uid=-1, gid=-1):\n    \"\"\" create path recursively if it doesn't exist \"\"\"\n    try:\n        os.makedirs(path)\n    except OSError as e:\n        if e.errno == errno.EEXIST:\n            pass\n        else:\n            raise\n    else:\n        os.chown(path, uid, gid)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nzeroing the last few blocks of the device", "response": "def zeroing(dev):\n    \"\"\" zeroing last few blocks of device \"\"\"\n    # this kills the crab\n    #\n    # sgdisk will wipe out the main copy of the GPT partition\n    # table (sorry), but it doesn't remove the backup copies, and\n    # subsequent commands will continue to complain and fail when\n    # they see those.  zeroing the last few blocks of the device\n    # appears to do the trick.\n    lba_size = 4096\n    size = 33 * lba_size\n    return True\n    with open(dev, 'wb') as f:\n        f.seek(-size, os.SEEK_END)\n        f.write(size*b'\\0')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enable_yum_priority_obsoletes(path=\"/etc/yum/pluginconf.d/priorities.conf\"):\n    config = configparser.ConfigParser()\n    config.read(path)\n    config.set('main', 'check_obsoletes', '1')\n    with open(path, 'w') as fout:\n        config.write(fout)", "response": "Configure Yum priorities to include obsoletes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make(parser):\n    config_parser = parser.add_subparsers(dest='subcommand')\n    config_parser.required = True\n\n    config_push = config_parser.add_parser(\n        'push',\n        help='push Ceph config file to one or more remote hosts'\n        )\n    config_push.add_argument(\n        'client',\n        metavar='HOST',\n        nargs='+',\n        help='host(s) to push the config file to',\n        )\n\n    config_pull = config_parser.add_parser(\n        'pull',\n        help='pull Ceph config file from one or more remote hosts'\n        )\n    config_pull.add_argument(\n        'client',\n        metavar='HOST',\n        nargs='+',\n        help='host(s) to pull the config file from',\n        )\n    parser.set_defaults(\n        func=config,\n        )", "response": "Create ceph config file parser"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(args):\n    path = args.ceph_conf or '{cluster}.conf'.format(cluster=args.cluster)\n\n    try:\n        f = open(path)\n    except IOError as e:\n        raise exc.ConfigError(\n            \"%s; has `ceph-deploy new` been run in this directory?\" % e\n        )\n    else:\n        with contextlib.closing(f):\n            return parse(f)", "response": "Load the configuration file and parse it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the actual file as is without parsing it as well as maintaining its same properties.", "response": "def load_raw(args):\n    \"\"\"\n    Read the actual file *as is* without parsing/modifiying it\n    so that it can be written maintaining its same properties.\n\n    :param args: Will be used to infer the proper configuration name\n    :paran path: alternatively, use a path for any configuration file loading\n    \"\"\"\n    path = args.ceph_conf or '{cluster}.conf'.format(cluster=args.cluster)\n    try:\n        with open(path) as ceph_conf:\n            return ceph_conf.read()\n    except (IOError, OSError) as e:\n        raise exc.ConfigError(\n            \"%s; has `ceph-deploy new` been run in this directory?\" % e\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_conf(cluster, conf, overwrite):\n    import os\n\n    path = '/etc/ceph/{cluster}.conf'.format(cluster=cluster)\n    tmp = '{path}.{pid}.tmp'.format(path=path, pid=os.getpid())\n\n    if os.path.exists(path):\n        with open(path) as f:\n            old = f.read()\n            if old != conf and not overwrite:\n                raise RuntimeError('config file %s exists with different content; use --overwrite-conf to overwrite' % path)\n    with open(tmp, 'w') as f:\n        f.write(conf)\n        f.flush()\n        os.fsync(f)\n    os.rename(tmp, path)", "response": "write cluster configuration to / etc."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef safe_get(self, section, key):\n        try:\n            #Use full parent function so we can replace it in the class\n            # if desired\n            return configparser.RawConfigParser.get(self, section, key)\n        except (configparser.NoSectionError,\n                configparser.NoOptionError):\n            return None", "response": "Safely gets a configuration value from a certain section and key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string that can be used as a custom repo file.", "response": "def custom_repo(**kw):\n    \"\"\"\n    Repo files need special care in that a whole line should not be present\n    if there is no value for it. Because we were using `format()` we could\n    not conditionally add a line for a repo file. So the end result would\n    contain a key with a missing value (say if we were passing `None`).\n\n    For example, it could look like::\n\n        [ceph repo]\n        name= ceph repo\n        proxy=\n        gpgcheck=\n\n    Which breaks. This function allows us to conditionally add lines,\n    preserving an order and be more careful.\n\n    Previously, and for historical purposes, this is how the template used\n    to look::\n\n        custom_repo =\n        [{repo_name}]\n        name={name}\n        baseurl={baseurl}\n        enabled={enabled}\n        gpgcheck={gpgcheck}\n        type={_type}\n        gpgkey={gpgkey}\n        proxy={proxy}\n\n    \"\"\"\n    lines = []\n\n    # by using tuples (vs a dict) we preserve the order of what we want to\n    # return, like starting with a [repo name]\n    tmpl = (\n        ('reponame', '[%s]'),\n        ('name', 'name=%s'),\n        ('baseurl', 'baseurl=%s'),\n        ('enabled', 'enabled=%s'),\n        ('gpgcheck', 'gpgcheck=%s'),\n        ('_type', 'type=%s'),\n        ('gpgkey', 'gpgkey=%s'),\n        ('proxy', 'proxy=%s'),\n        ('priority', 'priority=%s'),\n    )\n\n    for line in tmpl:\n        tmpl_key, tmpl_value = line  # key values from tmpl\n\n        # ensure that there is an actual value (not None nor empty string)\n        if tmpl_key in kw and kw.get(tmpl_key) not in (None, ''):\n            lines.append(tmpl_value % kw.get(tmpl_key))\n\n    return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_vendor(name):\n    this_dir = path.dirname(path.abspath(__file__))\n    vendor_dest = path.join(this_dir, 'ceph_deploy/lib/vendor/%s' % name)\n    run(['rm', '-rf', vendor_dest])", "response": "Clean up the vendor directory for a given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _keyring_equivalent(keyring_one, keyring_two):\n    def keyring_extract_key(file_path):\n        \"\"\"\n        Cephx keyring files may or may not have white space before some lines.\n        They may have some values in quotes, so a safe way to compare is to\n        extract the key.\n        \"\"\"\n        with open(file_path) as f:\n            for line in f:\n                content = line.strip()\n                if len(content) == 0:\n                    continue\n                split_line = content.split('=')\n                if split_line[0].strip() == 'key':\n                    return \"=\".join(split_line[1:]).strip()\n        raise RuntimeError(\"File '%s' is not a keyring\" % file_path)\n    key_one = keyring_extract_key(keyring_one)\n    key_two = keyring_extract_key(keyring_two)\n    return key_one == key_two", "response": "Check two keyrings are identical"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the local filename for a keyring type", "response": "def keytype_path_to(args, keytype):\n    \"\"\"\n    Get the local filename for a keyring type\n    \"\"\"\n    if keytype == \"admin\":\n        return '{cluster}.client.admin.keyring'.format(\n            cluster=args.cluster)\n    if keytype == \"mon\":\n        return '{cluster}.mon.keyring'.format(\n            cluster=args.cluster)\n    return '{cluster}.bootstrap-{what}.keyring'.format(\n            cluster=args.cluster,\n            what=keytype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngathering keys that are missing from mon keyring", "response": "def gatherkeys_missing(args, distro, rlogger, keypath, keytype, dest_dir):\n    \"\"\"\n    Get or create the keyring from the mon using the mon keyring by keytype and\n    copy to dest_dir\n    \"\"\"\n    args_prefix = [\n        '/usr/bin/ceph',\n        '--connect-timeout=25',\n        '--cluster={cluster}'.format(\n            cluster=args.cluster),\n        '--name', 'mon.',\n        '--keyring={keypath}'.format(\n            keypath=keypath),\n        ]\n\n    identity = keytype_identity(keytype)\n    if identity is None:\n        raise RuntimeError('Could not find identity for keytype:%s' % keytype)\n    capabilites = keytype_capabilities(keytype)\n    if capabilites is None:\n        raise RuntimeError('Could not find capabilites for keytype:%s' % keytype)\n\n    # First try getting the key if it already exists, to handle the case where\n    # it exists but doesn't match the caps we would pass into get-or-create.\n    # This is the same behvaior as in newer ceph-create-keys\n    out, err, code = remoto.process.check(\n        distro.conn,\n        args_prefix + ['auth', 'get', identity]\n        )\n    if code == errno.ENOENT:\n        out, err, code = remoto.process.check(\n            distro.conn,\n            args_prefix + ['auth', 'get-or-create', identity] + capabilites\n            )\n    if code != 0:\n        rlogger.error(\n            '\"ceph auth get-or-create for keytype %s returned %s',\n            keytype, code\n        )\n        for line in err:\n            rlogger.debug(line)\n        return False\n    keyring_name_local = keytype_path_to(args, keytype)\n    keyring_path_local = os.path.join(dest_dir, keyring_name_local)\n    with open(keyring_path_local, 'wb') as f:\n        for line in out:\n            f.write(line + b'\\n')\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects to mon and gather keys if mon is in quorum.", "response": "def gatherkeys_with_mon(args, host, dest_dir):\n    \"\"\"\n    Connect to mon and gather keys if mon is in quorum.\n    \"\"\"\n    distro = hosts.get(host, username=args.username)\n    remote_hostname = distro.conn.remote_module.shortname()\n    dir_keytype_mon = ceph_deploy.util.paths.mon.path(args.cluster, remote_hostname)\n    path_keytype_mon = \"%s/keyring\" % (dir_keytype_mon)\n    mon_key = distro.conn.remote_module.get_file(path_keytype_mon)\n    if mon_key is None:\n        LOG.warning(\"No mon key found in host: %s\", host)\n        return False\n    mon_name_local = keytype_path_to(args, \"mon\")\n    mon_path_local = os.path.join(dest_dir, mon_name_local)\n    with open(mon_path_local, 'wb') as f:\n        f.write(mon_key)\n    rlogger = logging.getLogger(host)\n    path_asok = ceph_deploy.util.paths.mon.asok(args.cluster, remote_hostname)\n    out, err, code = remoto.process.check(\n        distro.conn,\n            [\n                \"/usr/bin/ceph\",\n                \"--connect-timeout=25\",\n                \"--cluster={cluster}\".format(\n                    cluster=args.cluster),\n                \"--admin-daemon={asok}\".format(\n                    asok=path_asok),\n                \"mon_status\"\n            ]\n        )\n    if code != 0:\n        rlogger.error('\"ceph mon_status %s\" returned %s', host, code)\n        for line in err:\n            rlogger.debug(line)\n        return False\n    try:\n        mon_status = json.loads(b''.join(out).decode('utf-8'))\n    except ValueError:\n        rlogger.error('\"ceph mon_status %s\" output was not json', host)\n        for line in out:\n            rlogger.error(line)\n        return False\n    mon_number = None\n    mon_map = mon_status.get('monmap')\n    if mon_map is None:\n        rlogger.error(\"could not find mon map for mons on '%s'\", host)\n        return False\n    mon_quorum = mon_status.get('quorum')\n    if mon_quorum is None:\n        rlogger.error(\"could not find quorum for mons on '%s'\" , host)\n        return False\n    mon_map_mons = mon_map.get('mons')\n    if mon_map_mons is None:\n        rlogger.error(\"could not find mons in monmap on '%s'\", host)\n        return False\n    for mon in mon_map_mons:\n        if mon.get('name') == remote_hostname:\n           mon_number = mon.get('rank')\n           break\n    if mon_number is None:\n        rlogger.error(\"could not find '%s' in monmap\", remote_hostname)\n        return False\n    if not mon_number in mon_quorum:\n        rlogger.error(\"Not yet quorum for '%s'\", host)\n        return False\n    for keytype in [\"admin\", \"mds\", \"mgr\", \"osd\", \"rgw\"]:\n        if not gatherkeys_missing(args, distro, rlogger, path_keytype_mon, keytype, dest_dir):\n            # We will return failure if we fail to gather any key\n            rlogger.error(\"Failed to return '%s' key from host %s\", keytype, host)\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngathering keys from any mon and store in current working directory.", "response": "def gatherkeys(args):\n    \"\"\"\n    Gather keys from any mon and store in current working directory.\n\n    Backs up keys from previous installs and stores new keys.\n    \"\"\"\n    oldmask = os.umask(0o77)\n    try:\n        try:\n            tmpd = tempfile.mkdtemp()\n            LOG.info(\"Storing keys in temp directory %s\", tmpd)\n            sucess = False\n            for host in args.mon:\n                sucess = gatherkeys_with_mon(args, host, tmpd)\n                if sucess:\n                    break\n            if not sucess:\n                LOG.error(\"Failed to connect to host:%s\" ,', '.join(args.mon))\n                raise RuntimeError('Failed to connect any mon')\n            had_error = False\n            date_string = time.strftime(\"%Y%m%d%H%M%S\")\n            for keytype in [\"admin\", \"mds\", \"mgr\", \"mon\", \"osd\", \"rgw\"]:\n                filename = keytype_path_to(args, keytype)\n                tmp_path = os.path.join(tmpd, filename)\n                if not os.path.exists(tmp_path):\n                    LOG.error(\"No key retrived for '%s'\" , keytype)\n                    had_error = True\n                    continue\n                if not os.path.exists(filename):\n                    LOG.info(\"Storing %s\" % (filename))\n                    shutil.move(tmp_path, filename)\n                    continue\n                if _keyring_equivalent(tmp_path, filename):\n                    LOG.info(\"keyring '%s' already exists\" , filename)\n                    continue\n                backup_keyring = \"%s-%s\" % (filename, date_string)\n                LOG.info(\"Replacing '%s' and backing up old key as '%s'\", filename, backup_keyring)\n                shutil.copy(filename, backup_keyring)\n                shutil.move(tmp_path, filename)\n            if had_error:\n                raise RuntimeError('Failed to get all key types')\n        finally:\n            LOG.info(\"Destroy temp directory %s\" %(tmpd))\n            shutil.rmtree(tmpd)\n    finally:\n        os.umask(oldmask)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make(parser):\n    parser.add_argument(\n        'mon',\n        metavar='HOST',\n        nargs='+',\n        help='monitor host to pull keys from',\n        )\n    parser.set_defaults(\n        func=gatherkeys,\n        )", "response": "Initialize the parser for the gatherkeys command."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the module that matches the distribution of a hostname.", "response": "def get(hostname,\n        username=None,\n        fallback=None,\n        detect_sudo=True,\n        use_rhceph=False,\n        callbacks=None):\n    \"\"\"\n    Retrieve the module that matches the distribution of a ``hostname``. This\n    function will connect to that host and retrieve the distribution\n    information, then return the appropriate module and slap a few attributes\n    to that module defining the information it found from the hostname.\n\n    For example, if host ``node1.example.com`` is an Ubuntu server, the\n    ``debian`` module would be returned and the following would be set::\n\n        module.name = 'ubuntu'\n        module.release = '12.04'\n        module.codename = 'precise'\n\n    :param hostname: A hostname that is reachable/resolvable over the network\n    :param fallback: Optional fallback to use if no supported distro is found\n    :param use_rhceph: Whether or not to install RH Ceph on a RHEL machine or\n                       the community distro.  Changes what host module is\n                       returned for RHEL.\n    :params callbacks: A list of callables that accept one argument (the actual\n                       module that contains the connection) that will be\n                       called, in order at the end of the instantiation of the\n                       module.\n    \"\"\"\n    conn = get_connection(\n        hostname,\n        username=username,\n        logger=logging.getLogger(hostname),\n        detect_sudo=detect_sudo\n    )\n    try:\n        conn.import_module(remotes)\n    except IOError as error:\n        if 'already closed' in getattr(error, 'message', ''):\n            raise RuntimeError('remote connection got closed, ensure ``requiretty`` is disabled for %s' % hostname)\n    distro_name, release, codename = conn.remote_module.platform_information()\n    if not codename or not _get_distro(distro_name):\n        raise exc.UnsupportedPlatform(\n            distro=distro_name,\n            codename=codename,\n            release=release)\n\n    machine_type = conn.remote_module.machine_type()\n    module = _get_distro(distro_name, use_rhceph=use_rhceph)\n    module.name = distro_name\n    module.normalized_name = _normalized_distro_name(distro_name)\n    module.normalized_release = _normalized_release(release)\n    module.distro = module.normalized_name\n    module.is_el = module.normalized_name in ['redhat', 'centos', 'fedora', 'scientific', 'oracle', 'virtuozzo']\n    module.is_rpm = module.normalized_name in ['redhat', 'centos',\n                                               'fedora', 'scientific', 'suse', 'oracle', 'virtuozzo', 'alt']\n    module.is_deb = module.normalized_name in ['debian', 'ubuntu']\n    module.is_pkgtarxz = module.normalized_name in ['arch']\n    module.release = release\n    module.codename = codename\n    module.conn = conn\n    module.machine_type = machine_type\n    module.init = module.choose_init(module)\n    module.packager = module.get_packager(module)\n    # execute each callback if any\n    if callbacks:\n        for c in callbacks:\n            c(module)\n    return module"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a connection to the specified host.", "response": "def get_connection(hostname, username, logger, threads=5, use_sudo=None, detect_sudo=True):\n    \"\"\"\n    A very simple helper, meant to return a connection\n    that will know about the need to use sudo.\n    \"\"\"\n    if username:\n        hostname = \"%s@%s\" % (username, hostname)\n    try:\n        conn = remoto.Connection(\n            hostname,\n            logger=logger,\n            threads=threads,\n            detect_sudo=detect_sudo,\n        )\n\n        # Set a timeout value in seconds to disconnect and move on\n        # if no data is sent back.\n        conn.global_timeout = 300\n        logger.debug(\"connected to host: %s \" % hostname)\n        return conn\n\n    except Exception as error:\n        msg = \"connecting to host: %s \" % hostname\n        errors = \"resulted in errors: %s %s\" % (error.__class__.__name__, error)\n        raise RuntimeError(msg + errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_local_connection(logger, use_sudo=False):\n    return get_connection(\n        socket.gethostname(),  # cannot rely on 'localhost' here\n        None,\n        logger=logger,\n        threads=1,\n        use_sudo=use_sudo,\n        detect_sudo=False\n    )", "response": "Returns a connection to the local hosts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make(parser):\n    mgr_parser = parser.add_subparsers(dest='subcommand')\n    mgr_parser.required = True\n\n    mgr_create = mgr_parser.add_parser(\n        'create',\n        help='Deploy Ceph MGR on remote host(s)'\n    )\n    mgr_create.add_argument(\n        'mgr',\n        metavar='HOST[:NAME]',\n        nargs='+',\n        type=colon_separated,\n        help='host (and optionally the daemon name) to deploy on',\n        )\n    parser.set_defaults(\n        func=mgr,\n        )", "response": "Ceph MGR daemon management"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmanages packages on remote hosts.", "response": "def make(parser):\n    \"\"\"\n    Manage packages on remote hosts.\n    \"\"\"\n\n    action = parser.add_mutually_exclusive_group()\n\n    action.add_argument(\n        '--install',\n        metavar='PKG(s)',\n        help='Comma-separated package(s) to install',\n    )\n\n    action.add_argument(\n        '--remove',\n        metavar='PKG(s)',\n        help='Comma-separated package(s) to remove',\n    )\n\n    parser.add_argument(\n        'hosts',\n        nargs='+',\n    )\n\n    parser.set_defaults(\n        func=pkg,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_bootstrap_osd_key(cluster):\n    path = '{cluster}.bootstrap-osd.keyring'.format(cluster=cluster)\n    try:\n        with open(path, 'rb') as f:\n            return f.read()\n    except IOError:\n        raise RuntimeError('bootstrap-osd keyring not found; run \\'gatherkeys\\'')", "response": "Read the bootstrap - osd key for a cluster."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_osd_keyring(conn, cluster, key):\n    logger = conn.logger\n    path = '/var/lib/ceph/bootstrap-osd/{cluster}.keyring'.format(\n        cluster=cluster,\n    )\n    if not conn.remote_module.path_exists(path):\n        logger.warning('osd keyring does not exist yet, creating one')\n        conn.remote_module.write_keyring(path, key)", "response": "Create the osd keyring if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef osd_tree(conn, cluster):\n    ceph_executable = system.executable_path(conn, 'ceph')\n    command = [\n        ceph_executable,\n        '--cluster={cluster}'.format(cluster=cluster),\n        'osd',\n        'tree',\n        '--format=json',\n    ]\n\n    out, err, code = remoto.process.check(\n        conn,\n        command,\n    )\n\n    try:\n        loaded_json = json.loads(b''.join(out).decode('utf-8'))\n        # convert boolean strings to actual booleans because\n        # --format=json fails to do this properly\n        for k, v in loaded_json.items():\n            if v == 'true':\n                loaded_json[k] = True\n            elif v == 'false':\n                loaded_json[k] = False\n        return loaded_json\n    except ValueError:\n        return {}", "response": "Check the status of an OSD and return a dictionary of the OSD s attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef catch_osd_errors(conn, logger, args):\n    logger.info('checking OSD status...')\n    status = osd_status_check(conn, args.cluster)\n    osds = int(status.get('num_osds', 0))\n    up_osds = int(status.get('num_up_osds', 0))\n    in_osds = int(status.get('num_in_osds', 0))\n    full = status.get('full', False)\n    nearfull = status.get('nearfull', False)\n\n    if osds > up_osds:\n        difference = osds - up_osds\n        logger.warning('there %s %d OSD%s down' % (\n            ['is', 'are'][difference != 1],\n            difference,\n            \"s\"[difference == 1:])\n        )\n\n    if osds > in_osds:\n        difference = osds - in_osds\n        logger.warning('there %s %d OSD%s out' % (\n            ['is', 'are'][difference != 1],\n            difference,\n            \"s\"[difference == 1:])\n        )\n\n    if full:\n        logger.warning('OSDs are full!')\n\n    if nearfull:\n        logger.warning('OSDs are near full!')", "response": "Catch and report errors when checking the status of an OSD and the OSDs are up and out."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_osd(\n        conn,\n        cluster,\n        data,\n        journal,\n        zap,\n        fs_type,\n        dmcrypt,\n        dmcrypt_dir,\n        storetype,\n        block_wal,\n        block_db,\n        **kw):\n    \"\"\"\n    Run on osd node, creates an OSD from a data disk.\n    \"\"\"\n    ceph_volume_executable = system.executable_path(conn, 'ceph-volume')\n    args = [\n        ceph_volume_executable,\n        '--cluster', cluster,\n        'lvm',\n        'create',\n        '--%s' % storetype,\n        '--data', data\n    ]\n    if zap:\n        LOG.warning('zapping is no longer supported when preparing')\n    if dmcrypt:\n        args.append('--dmcrypt')\n        # TODO: re-enable dmcrypt support once ceph-volume grows it\n        LOG.warning('dmcrypt is currently not supported')\n\n    if storetype == 'bluestore':\n        if block_wal:\n            args.append('--block.wal')\n            args.append(block_wal)\n        if block_db:\n            args.append('--block.db')\n            args.append(block_db)\n    elif storetype == 'filestore':\n        if not journal:\n            raise RuntimeError('A journal lv or GPT partition must be specified when using filestore')\n        args.append('--journal')\n        args.append(journal)\n\n    if kw.get('debug'):\n        remoto.process.run(\n            conn,\n            args,\n            extend_env={'CEPH_VOLUME_DEBUG': '1'}\n        )\n\n    else:\n        remoto.process.run(\n            conn,\n            args\n        )", "response": "Create an OSD from a data disk."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make(parser):\n    sub_command_help = dedent(\"\"\"\n    Create OSDs from a data disk on a remote host:\n\n        ceph-deploy osd create {node} --data /path/to/device\n\n    For bluestore, optional devices can be used::\n\n        ceph-deploy osd create {node} --data /path/to/data --block-db /path/to/db-device\n        ceph-deploy osd create {node} --data /path/to/data --block-wal /path/to/wal-device\n        ceph-deploy osd create {node} --data /path/to/data --block-db /path/to/db-device --block-wal /path/to/wal-device\n\n    For filestore, the journal must be specified, as well as the objectstore::\n\n        ceph-deploy osd create {node} --filestore --data /path/to/data --journal /path/to/journal\n\n    For data devices, it can be an existing logical volume in the format of:\n    vg/lv, or a device. For other OSD components like wal, db, and journal, it\n    can be logical volume (in vg/lv format) or it must be a GPT partition.\n    \"\"\"\n    )\n    parser.formatter_class = argparse.RawDescriptionHelpFormatter\n    parser.description = sub_command_help\n\n    osd_parser = parser.add_subparsers(dest='subcommand')\n    osd_parser.required = True\n\n    osd_list = osd_parser.add_parser(\n        'list',\n        help='List OSD info from remote host(s)'\n        )\n    osd_list.add_argument(\n        'host',\n        nargs='+',\n        metavar='HOST',\n        help='remote host(s) to list OSDs from'\n        )\n    osd_list.add_argument(\n        '--debug',\n        action='store_true',\n        help='Enable debug mode on remote ceph-volume calls',\n        )\n    osd_create = osd_parser.add_parser(\n        'create',\n        help='Create new Ceph OSD daemon by preparing and activating a device'\n    )\n    osd_create.add_argument(\n        '--data',\n        metavar='DATA',\n        help='The OSD data logical volume (vg/lv) or absolute path to device'\n    )\n    osd_create.add_argument(\n        '--journal',\n        help='Logical Volume (vg/lv) or path to GPT partition',\n        )\n    osd_create.add_argument(\n        '--zap-disk',\n        action='store_true',\n        help='DEPRECATED - cannot zap when creating an OSD'\n    )\n    osd_create.add_argument(\n        '--fs-type',\n        metavar='FS_TYPE',\n        choices=['xfs',\n                 'btrfs'\n                 ],\n        default='xfs',\n        help='filesystem to use to format DEVICE (xfs, btrfs)',\n        )\n    osd_create.add_argument(\n        '--dmcrypt',\n        action='store_true',\n        help='use dm-crypt on DEVICE',\n        )\n    osd_create.add_argument(\n        '--dmcrypt-key-dir',\n        metavar='KEYDIR',\n        default='/etc/ceph/dmcrypt-keys',\n        help='directory where dm-crypt keys are stored',\n        )\n    osd_create.add_argument(\n        '--filestore',\n        action='store_true', default=None,\n        help='filestore objectstore',\n        )\n    osd_create.add_argument(\n        '--bluestore',\n        action='store_true', default=None,\n        help='bluestore objectstore',\n        )\n    osd_create.add_argument(\n        '--block-db',\n        default=None,\n        help='bluestore block.db path'\n        )\n    osd_create.add_argument(\n        '--block-wal',\n        default=None,\n        help='bluestore block.wal path'\n        )\n    osd_create.add_argument(\n        'host',\n        nargs='?',\n        metavar='HOST',\n        help='Remote host to connect'\n        )\n    osd_create.add_argument(\n        '--debug',\n        action='store_true',\n        help='Enable debug mode on remote ceph-volume calls',\n        )\n    parser.set_defaults(\n        func=osd,\n        )", "response": "Create an OSD from a remote host."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmanages disks on a remote host.", "response": "def make_disk(parser):\n    \"\"\"\n    Manage disks on a remote host.\n    \"\"\"\n    disk_parser = parser.add_subparsers(dest='subcommand')\n    disk_parser.required = True\n\n    disk_zap = disk_parser.add_parser(\n        'zap',\n        help='destroy existing data and filesystem on LV or partition',\n        )\n    disk_zap.add_argument(\n        'host',\n        nargs='?',\n        metavar='HOST',\n        help='Remote HOST(s) to connect'\n        )\n    disk_zap.add_argument(\n        'disk',\n        nargs='+',\n        metavar='DISK',\n        help='Disk(s) to zap'\n        )\n    disk_zap.add_argument(\n        '--debug',\n        action='store_true',\n        help='Enable debug mode on remote ceph-volume calls',\n        )\n    disk_list = disk_parser.add_parser(\n        'list',\n        help='List disk info from remote host(s)'\n        )\n    disk_list.add_argument(\n        'host',\n        nargs='+',\n        metavar='HOST',\n        help='Remote HOST(s) to list OSDs from'\n        )\n    disk_list.add_argument(\n        '--debug',\n        action='store_true',\n        help='Enable debug mode on remote ceph-volume calls',\n        )\n    parser.set_defaults(\n        func=disk,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the URL part of the given distro.", "response": "def repository_url_part(distro):\n    \"\"\"\n    Historically everything CentOS, RHEL, and Scientific has been mapped to\n    `el6` urls, but as we are adding repositories for `rhel`, the URLs should\n    map correctly to, say, `rhel6` or `rhel7`.\n\n    This function looks into the `distro` object and determines the right url\n    part for the given distro, falling back to `el6` when all else fails.\n\n    Specifically to work around the issue of CentOS vs RHEL::\n\n        >>> import platform\n        >>> platform.linux_distribution()\n        ('Red Hat Enterprise Linux Server', '7.0', 'Maipo')\n\n    \"\"\"\n    if distro.normalized_release.int_major >= 6:\n        if distro.normalized_name == 'redhat':\n            return 'rhel' + distro.normalized_release.major\n        if distro.normalized_name in ['centos', 'scientific', 'oracle', 'virtuozzo']:\n            return 'el' + distro.normalized_release.major\n\n    return 'el6'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sanitize_args(args):\n    if args.release is None:\n        args.release = 'nautilus'\n        args.default_release = True\n\n    # XXX This whole dance is because --stable is getting deprecated\n    if args.stable is not None:\n        LOG.warning('the --stable flag is deprecated, use --release instead')\n        args.release = args.stable\n    # XXX Tango ends here.\n\n    return args", "response": "Sanitize the arguments for the is\n    command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef detect_components(args, distro):\n    # the flag that prevents all logic here is the `--repo` flag which is used\n    # when no packages should be installed, just the repo files, so check for\n    # that here and return an empty list (which is equivalent to say 'no\n    # packages should be installed')\n    if args.repo:\n        return []\n\n    flags = {\n        'install_osd': 'ceph-osd',\n        'install_rgw': 'ceph-radosgw',\n        'install_mds': 'ceph-mds',\n        'install_mon': 'ceph-mon',\n        'install_mgr': 'ceph-mgr',\n        'install_common': 'ceph-common',\n        'install_tests': 'ceph-test',\n    }\n\n    if distro.is_rpm:\n        defaults = default_components.rpm\n    elif distro.is_pkgtarxz:\n        # archlinux doesn't have components!\n        flags = {\n            'install_osd': 'ceph',\n            'install_rgw': 'ceph',\n            'install_mds': 'ceph',\n            'install_mon': 'ceph',\n            'install_mgr': 'ceph',\n            'install_common': 'ceph',\n            'install_tests': 'ceph',\n        }\n        defaults = default_components.pkgtarxz\n    else:\n        defaults = default_components.deb\n        # different naming convention for deb than rpm for radosgw\n        flags['install_rgw'] = 'radosgw'\n\n    if args.install_all:\n        return defaults\n    else:\n        components = []\n        for k, v in flags.items():\n            if getattr(args, k, False):\n                components.append(v)\n        # if we have some components selected from flags then return that,\n        # otherwise return defaults because no flags and no `--repo` means we\n        # should get all of them by default\n        return components or defaults", "response": "This helper function detects the components of a single package and returns a list of Ceph components that are available for the given distribution."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef should_use_custom_repo(args, cd_conf, repo_url):\n    if repo_url:\n        # repo_url signals a CLI override, return False immediately\n        return False\n    if cd_conf:\n        if cd_conf.has_repos:\n            has_valid_release = args.release in cd_conf.get_repos()\n            has_default_repo = cd_conf.get_default_repo()\n            if has_valid_release or has_default_repo:\n                return True\n    return False", "response": "A boolean to determine if we should use a custom repo."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling Ceph packages for a user.", "response": "def install_repo(args):\n    \"\"\"\n    For a user that only wants to install the repository only (and avoid\n    installing Ceph and its dependencies).\n    \"\"\"\n    cd_conf = getattr(args, 'cd_conf', None)\n\n    for hostname in args.host:\n        LOG.debug('Detecting platform for host %s ...', hostname)\n        distro = hosts.get(\n            hostname,\n            username=args.username,\n            # XXX this should get removed once Ceph packages are split for\n            # upstream. If default_release is True, it means that the user is\n            # trying to install on a RHEL machine and should expect to get RHEL\n            # packages. Otherwise, it will need to specify either a specific\n            # version, or repo, or a development branch. Other distro users should\n            # not see any differences.\n            use_rhceph=args.default_release,\n        )\n        rlogger = logging.getLogger(hostname)\n\n        LOG.info(\n            'Distro info: %s %s %s',\n            distro.name,\n            distro.release,\n            distro.codename\n        )\n\n        custom_repo(distro, args, cd_conf, rlogger, install_ceph=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall Ceph packages on remote hosts.", "response": "def make(parser):\n    \"\"\"\n    Install Ceph packages on remote hosts.\n    \"\"\"\n\n    version = parser.add_mutually_exclusive_group()\n\n    # XXX deprecated in favor of release\n    version.add_argument(\n        '--stable',\n        nargs='?',\n        action=StoreVersion,\n        metavar='CODENAME',\n        help='[DEPRECATED] install a release known as CODENAME\\\n                (done by default) (default: %(default)s)',\n    )\n\n    version.add_argument(\n        '--release',\n        nargs='?',\n        action=StoreVersion,\n        metavar='CODENAME',\n        help='install a release known as CODENAME\\\n                (done by default) (default: %(default)s)',\n    )\n\n    version.add_argument(\n        '--testing',\n        nargs=0,\n        action=StoreVersion,\n        help='install the latest development release',\n    )\n\n    version.add_argument(\n        '--dev',\n        nargs='?',\n        action=StoreVersion,\n        const='master',\n        metavar='BRANCH_OR_TAG',\n        help='install a bleeding edge build from Git branch\\\n                or tag (default: %(default)s)',\n    )\n    parser.add_argument(\n        '--dev-commit',\n        nargs='?',\n        action=StoreVersion,\n        metavar='COMMIT',\n        help='install a bleeding edge build from Git commit (defaults to master branch)',\n    )\n\n    version.set_defaults(\n        stable=None,  # XXX deprecated in favor of release\n        release=None,  # Set the default release in sanitize_args()\n        dev='master',\n        version_kind='stable',\n    )\n\n    parser.add_argument(\n        '--mon',\n        dest='install_mon',\n        action='store_true',\n        help='install the mon component only',\n    )\n\n    parser.add_argument(\n        '--mgr',\n        dest='install_mgr',\n        action='store_true',\n        help='install the mgr component only',\n    )\n\n    parser.add_argument(\n        '--mds',\n        dest='install_mds',\n        action='store_true',\n        help='install the mds component only',\n    )\n\n    parser.add_argument(\n        '--rgw',\n        dest='install_rgw',\n        action='store_true',\n        help='install the rgw component only',\n    )\n\n    parser.add_argument(\n        '--osd',\n        dest='install_osd',\n        action='store_true',\n        help='install the osd component only',\n    )\n\n    parser.add_argument(\n        '--tests',\n        dest='install_tests',\n        action='store_true',\n        help='install the testing components',\n    )\n\n    parser.add_argument(\n        '--cli', '--common',\n        dest='install_common',\n        action='store_true',\n        help='install the common component only',\n    )\n\n    parser.add_argument(\n        '--all',\n        dest='install_all',\n        action='store_true',\n        help='install all Ceph components (mon, osd, mds, rgw) except tests. This is the default',\n    )\n\n    repo = parser.add_mutually_exclusive_group()\n\n    repo.add_argument(\n        '--adjust-repos',\n        dest='adjust_repos',\n        action='store_true',\n        help='install packages modifying source repos',\n    )\n\n    repo.add_argument(\n        '--no-adjust-repos',\n        dest='adjust_repos',\n        action='store_false',\n        help='install packages without modifying source repos',\n    )\n\n    repo.add_argument(\n        '--repo',\n        action='store_true',\n        help='install repo files only (skips package installation)',\n    )\n\n    repo.set_defaults(\n        adjust_repos=True,\n    )\n\n    parser.add_argument(\n        'host',\n        metavar='HOST',\n        nargs='+',\n        help='hosts to install on',\n    )\n\n    parser.add_argument(\n        '--local-mirror',\n        nargs='?',\n        const='PATH',\n        default=None,\n        help='Fetch packages and push them to hosts for a local repo mirror',\n    )\n\n    parser.add_argument(\n        '--repo-url',\n        nargs='?',\n        dest='repo_url',\n        help='specify a repo URL that mirrors/contains Ceph packages',\n    )\n\n    parser.add_argument(\n        '--gpg-url',\n        nargs='?',\n        dest='gpg_url',\n        help='specify a GPG key URL to be used with custom repos\\\n                (defaults to ceph.com)'\n    )\n\n    parser.add_argument(\n        '--nogpgcheck',\n        action='store_true',\n        help='install packages without gpgcheck',\n    )\n\n    parser.set_defaults(\n        func=install,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_uninstall(parser):\n    parser.add_argument(\n        'host',\n        metavar='HOST',\n        nargs='+',\n        help='hosts to uninstall Ceph from',\n        )\n    parser.set_defaults(\n        func=uninstall,\n        )", "response": "A helper function to make a command line parser for uninstalling Ceph packages from remote hosts."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves Ceph packages from remote hosts and purge all data.", "response": "def make_purge(parser):\n    \"\"\"\n    Remove Ceph packages from remote hosts and purge all data.\n    \"\"\"\n    parser.add_argument(\n        'host',\n        metavar='HOST',\n        nargs='+',\n        help='hosts to purge Ceph from',\n        )\n    parser.set_defaults(\n        func=purge,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_purge_data(parser):\n    parser.add_argument(\n        'host',\n        metavar='HOST',\n        nargs='+',\n        help='hosts to purge Ceph data from',\n        )\n    parser.set_defaults(\n        func=purgedata,\n        )", "response": "Purge any Ceph data from the specified hosts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mon_hosts(mons):\n    for m in mons:\n        if m.count(':'):\n            (name, host) = m.split(':')\n        else:\n            name = m\n            host = m\n            if name.count('.') > 0:\n                name = name.split('.')[0]\n        yield (name, host)", "response": "Iterate through list of MON hosts return tuples of name host."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make(parser):\n    rgw_parser = parser.add_subparsers(dest='subcommand')\n    rgw_parser.required = True\n    rgw_create = rgw_parser.add_parser(\n        'create',\n        help='Create an RGW instance'\n        )\n    rgw_create.add_argument(\n        'rgw',\n        metavar='HOST[:NAME]',\n        nargs='+',\n        type=colon_separated,\n        help='host (and optionally the daemon name) to deploy on. \\\n                NAME is automatically prefixed with \\'rgw.\\'',\n        )\n    parser.set_defaults(\n        func=rgw,\n        )", "response": "A helper function to create Ceph RGW daemons."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef can_connect_passwordless(hostname):\n    # Ensure we are not doing this for local hosts\n    if not remoto.backends.needs_ssh(hostname):\n        return True\n\n    logger = logging.getLogger(hostname)\n    with get_local_connection(logger) as conn:\n        # Check to see if we can login, disabling password prompts\n        command = ['ssh', '-CT', '-o', 'BatchMode=yes', hostname, 'true']\n        out, err, retval = remoto.process.check(conn, command, stop_on_error=False)\n        permission_denied_error = 'Permission denied '\n        host_key_verify_error = 'Host key verification failed.'\n        has_key_error = False\n        for line in err:\n            if permission_denied_error in line or host_key_verify_error in line:\n                has_key_error = True\n\n        if retval == 255 and has_key_error:\n            return False\n    return True", "response": "Checks if the current host can be SSH remotely to the remote host using the BatchMode option."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef choose_init(module):\n    # Upstart checks first because when installing ceph, the\n    # `/lib/systemd/system/ceph.target` file may be created, fooling this\n    # detection mechanism.\n    if is_upstart(module.conn):\n        return 'upstart'\n\n    if is_systemd(module.conn) or module.conn.remote_module.path_exists(\n            \"/lib/systemd/system/ceph.target\"):\n        return 'systemd'\n\n    return 'sysvinit'", "response": "Select a system system\n Returns the name of a system sysvinit...."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keyring(cluster, hostname):\n    keyring_file = '%s-%s.mon.keyring' % (cluster, hostname)\n    return join(constants.tmp_path, keyring_file)", "response": "Returns a keyring file for the given cluster and hostname"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef asok(cluster, hostname):\n    asok_file = '%s-mon.%s.asok' % (cluster, hostname)\n    return join(constants.base_run_path, asok_file)", "response": "Returns the path to the asok file for the given cluster and hostname."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef monmap(cluster, hostname):\n    monmap\n    mon_map_file = '%s.%s.monmap' % (cluster, hostname)\n    return join(constants.tmp_path, mon_map_file)", "response": "Monmap cluster to hostname"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches result of getaddrinfo for a non - localhost - net address and return the ip of the non - localhost - net entry.", "response": "def get_nonlocal_ip(host, subnet=None):\n    \"\"\"\n    Search result of getaddrinfo() for a non-localhost-net address\n    \"\"\"\n    try:\n        ailist = socket.getaddrinfo(host, None)\n    except socket.gaierror:\n        raise exc.UnableToResolveError(host)\n    for ai in ailist:\n        # an ai is a 5-tuple; the last element is (ip, port)\n        ip = ai[4][0]\n        if subnet and ip_in_subnet(ip, subnet):\n            LOG.info('found ip (%s) for host (%s) to be in cluster subnet (%s)' % (\n                ip,\n                host,\n                subnet,)\n            )\n\n            return ip\n\n        if not ip.startswith('127.'):\n            if subnet:\n                LOG.warning('could not match ip (%s) for host (%s) for cluster subnet (%s)' % (\n                    ip,\n                    host,\n                    subnet,)\n                )\n            return ip\n    raise exc.UnableToResolveError(host)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a boolean if the given IP exists in a given subnet utility. Returns a boolean if the IP exists in a given subnet utility. Returns a boolean if the IP exists in a given subnet utility.", "response": "def ip_in_subnet(ip, subnet):\n    \"\"\"Does IP exists in a given subnet utility. Returns a boolean\"\"\"\n    ipaddr = int(''.join(['%02x' % int(x) for x in ip.split('.')]), 16)\n    netstr, bits = subnet.split('/')\n    netaddr = int(''.join(['%02x' % int(x) for x in netstr.split('.')]), 16)\n    mask = (0xffffffff << (32 - int(bits))) & 0xffffffff\n    return (ipaddr & mask) == (netaddr & mask)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if host is within specified subnet False otherwise.", "response": "def in_subnet(cidr, addrs=None):\n    \"\"\"\n    Returns True if host is within specified subnet, otherwise False\n    \"\"\"\n    for address in addrs:\n        if ip_in_subnet(address, cidr):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ip_addresses(conn, interface=None, include_loopback=False):\n    ret = set()\n    ifaces = linux_interfaces(conn)\n    if interface is None:\n        target_ifaces = ifaces\n    else:\n        target_ifaces = dict((k, v) for k, v in ifaces.items()\n                             if k == interface)\n        if not target_ifaces:\n            LOG.error('Interface {0} not found.'.format(interface))\n    for info in target_ifaces.values():\n        for ipv4 in info.get('inet', []):\n            loopback = in_subnet('127.0.0.0/8', [ipv4.get('address')]) or ipv4.get('label') == 'lo'\n            if not loopback or include_loopback:\n                ret.add(ipv4['address'])\n        for secondary in info.get('secondary', []):\n            addr = secondary.get('address')\n            if addr and secondary.get('type') == 'inet':\n                if include_loopback or (not include_loopback and not in_subnet('127.0.0.0/8', [addr])):\n                    ret.add(addr)\n        for ipv6 in info.get('inet6', []):\n            # When switching to Python 3 the IPAddress module can do all this work for us\n            if ipv6.get('address').startswith('fe80::'):\n                continue\n\n            if not include_loopback and '::1' == ipv6.get('address'):\n                continue\n\n            ret.add(ipv6['address'])\n    if ret:\n        conn.logger.debug('IP addresses found: %s' % str(list(ret)))\n    return sorted(list(ret))", "response": "Returns a list of IPv4 and IPv6 addresses assigned to the host."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict of linux interfaces for a remote node.", "response": "def linux_interfaces(conn):\n    \"\"\"\n    Obtain interface information for *NIX/BSD variants in remote servers.\n\n    Example output from a remote node with a couple of interfaces::\n\n        {'eth0': {'hwaddr': '08:00:27:08:c2:e4',\n                  'inet': [{'address': '10.0.2.15',\n                            'broadcast': '10.0.2.255',\n                            'label': 'eth0',\n                            'netmask': '255.255.255.0'}],\n                  'inet6': [{'address': 'fe80::a00:27ff:fe08:c2e4',\n                             'prefixlen': '64'}],\n                  'up': True},\n         'eth1': {'hwaddr': '08:00:27:70:06:f1',\n                  'inet': [{'address': '192.168.111.101',\n                            'broadcast': '192.168.111.255',\n                            'label': 'eth1',\n                            'netmask': '255.255.255.0'}],\n                  'inet6': [{'address': 'fe80::a00:27ff:fe70:6f1',\n                             'prefixlen': '64'}],\n                  'up': True},\n         'lo': {'hwaddr': '00:00:00:00:00:00',\n                'inet': [{'address': '127.0.0.1',\n                          'broadcast': None,\n                          'label': 'lo',\n                          'netmask': '255.0.0.0'}],\n                'inet6': [{'address': '::1', 'prefixlen': '128'}],\n                'up': True}}\n\n    :param conn: A connection object to a remote node\n    \"\"\"\n    ifaces = dict()\n    ip_path = conn.remote_module.which('ip')\n    ifconfig_path = None if ip_path else conn.remote_module.which('ifconfig')\n    if ip_path:\n        cmd1, _, _ = remoto.process.check(\n            conn,\n            [\n                '{0}'.format(ip_path),\n                'link',\n                'show',\n            ],\n        )\n        cmd2, _, _ = remoto.process.check(\n            conn,\n            [\n                '{0}'.format(ip_path),\n                'addr',\n                'show',\n            ],\n        )\n        ifaces = _interfaces_ip(b'\\n'.join(cmd1).decode('utf-8') + '\\n' +\n                                b'\\n'.join(cmd2).decode('utf-8'))\n    elif ifconfig_path:\n        cmd, _, _ = remoto.process.check(\n            conn,\n            [\n                '{0}'.format(ifconfig_path),\n                '-a',\n            ]\n        )\n        ifaces = _interfaces_ifconfig('\\n'.join(cmd))\n    return ifaces"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _interfaces_ip(out):\n    ret = dict()\n\n    def parse_network(value, cols):\n        \"\"\"\n        Return a tuple of ip, netmask, broadcast\n        based on the current set of cols\n        \"\"\"\n        brd = None\n        if '/' in value:  # we have a CIDR in this address\n            ip, cidr = value.split('/')  # pylint: disable=C0103\n        else:\n            ip = value  # pylint: disable=C0103\n            cidr = 32\n\n        if type_ == 'inet':\n            mask = cidr_to_ipv4_netmask(int(cidr))\n            if 'brd' in cols:\n                brd = cols[cols.index('brd') + 1]\n        elif type_ == 'inet6':\n            mask = cidr\n        return (ip, mask, brd)\n\n    groups = re.compile('\\r?\\n\\\\d').split(out)\n    for group in groups:\n        iface = None\n        data = dict()\n\n        for line in group.splitlines():\n            if ' ' not in line:\n                continue\n            match = re.match(r'^\\d*:\\s+([\\w.\\-]+)(?:@)?([\\w.\\-]+)?:\\s+<(.+)>', line)\n            if match:\n                iface, parent, attrs = match.groups()\n                if 'UP' in attrs.split(','):\n                    data['up'] = True\n                else:\n                    data['up'] = False\n                if parent:\n                    data['parent'] = parent\n                continue\n\n            cols = line.split()\n            if len(cols) >= 2:\n                type_, value = tuple(cols[0:2])\n                iflabel = cols[-1:][0]\n                if type_ in ('inet', 'inet6'):\n                    if 'secondary' not in cols:\n                        ipaddr, netmask, broadcast = parse_network(value, cols)\n                        if type_ == 'inet':\n                            if 'inet' not in data:\n                                data['inet'] = list()\n                            addr_obj = dict()\n                            addr_obj['address'] = ipaddr\n                            addr_obj['netmask'] = netmask\n                            addr_obj['broadcast'] = broadcast\n                            addr_obj['label'] = iflabel\n                            data['inet'].append(addr_obj)\n                        elif type_ == 'inet6':\n                            if 'inet6' not in data:\n                                data['inet6'] = list()\n                            addr_obj = dict()\n                            addr_obj['address'] = ipaddr\n                            addr_obj['prefixlen'] = netmask\n                            data['inet6'].append(addr_obj)\n                    else:\n                        if 'secondary' not in data:\n                            data['secondary'] = list()\n                        ip_, mask, brd = parse_network(value, cols)\n                        data['secondary'].append({\n                            'type': type_,\n                            'address': ip_,\n                            'netmask': mask,\n                            'broadcast': brd,\n                            'label': iflabel,\n                        })\n                        del ip_, mask, brd\n                elif type_.startswith('link'):\n                    data['hwaddr'] = value\n        if iface:\n            ret[iface] = data\n            del iface, data\n    return ret", "response": "Returns a dictionary of interfaces with various information about the current ip."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of interfaces with various information about each interface.", "response": "def _interfaces_ifconfig(out):\n    \"\"\"\n    Uses ifconfig to return a dictionary of interfaces with various information\n    about each (up/down state, ip address, netmask, and hwaddr)\n    \"\"\"\n    ret = dict()\n\n    piface = re.compile(r'^([^\\s:]+)')\n    pmac = re.compile('.*?(?:HWaddr|ether|address:|lladdr) ([0-9a-fA-F:]+)')\n    pip = re.compile(r'.*?(?:inet addr:|inet )(.*?)\\s')\n    pip6 = re.compile('.*?(?:inet6 addr: (.*?)/|inet6 )([0-9a-fA-F:]+)')\n    pmask = re.compile(r'.*?(?:Mask:|netmask )(?:((?:0x)?[0-9a-fA-F]{8})|([\\d\\.]+))')\n    pmask6 = re.compile(r'.*?(?:inet6 addr: [0-9a-fA-F:]+/(\\d+)|prefixlen (\\d+)).*')\n    pupdown = re.compile('UP')\n    pbcast = re.compile(r'.*?(?:Bcast:|broadcast )([\\d\\.]+)')\n\n    groups = re.compile('\\r?\\n(?=\\\\S)').split(out)\n    for group in groups:\n        data = dict()\n        iface = ''\n        updown = False\n        for line in group.splitlines():\n            miface = piface.match(line)\n            mmac = pmac.match(line)\n            mip = pip.match(line)\n            mip6 = pip6.match(line)\n            mupdown = pupdown.search(line)\n            if miface:\n                iface = miface.group(1)\n            if mmac:\n                data['hwaddr'] = mmac.group(1)\n            if mip:\n                if 'inet' not in data:\n                    data['inet'] = list()\n                addr_obj = dict()\n                addr_obj['address'] = mip.group(1)\n                mmask = pmask.match(line)\n                if mmask:\n                    if mmask.group(1):\n                        mmask = _number_of_set_bits_to_ipv4_netmask(\n                            int(mmask.group(1), 16))\n                    else:\n                        mmask = mmask.group(2)\n                    addr_obj['netmask'] = mmask\n                mbcast = pbcast.match(line)\n                if mbcast:\n                    addr_obj['broadcast'] = mbcast.group(1)\n                data['inet'].append(addr_obj)\n            if mupdown:\n                updown = True\n            if mip6:\n                if 'inet6' not in data:\n                    data['inet6'] = list()\n                addr_obj = dict()\n                addr_obj['address'] = mip6.group(1) or mip6.group(2)\n                mmask6 = pmask6.match(line)\n                if mmask6:\n                    addr_obj['prefixlen'] = mmask6.group(1) or mmask6.group(2)\n                data['inet6'].append(addr_obj)\n        data['up'] = updown\n        ret[iface] = data\n        del data\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_chacra_repo(shaman_url):\n    shaman_response = get_request(shaman_url)\n    chacra_url = shaman_response.geturl()\n    chacra_response = get_request(chacra_url)\n\n    return chacra_response.read()", "response": "Get the chacra url for a repository and return it as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_components(notsplit_packages, components):\n    packages = set()\n\n    for c in components:\n        if c in notsplit_packages:\n            packages.add('ceph')\n        else:\n            packages.add(c)\n\n    return list(packages)", "response": "Map components to their corresponding ceph packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts mon service based on distro init", "response": "def start_mon_service(distro, cluster, hostname):\n    \"\"\"\n    start mon service depending on distro init\n    \"\"\"\n    if distro.init == 'sysvinit':\n        service = distro.conn.remote_module.which_service()\n        remoto.process.run(\n            distro.conn,\n            [\n                service,\n                'ceph',\n                '-c',\n                '/etc/ceph/{cluster}.conf'.format(cluster=cluster),\n                'start',\n                'mon.{hostname}'.format(hostname=hostname)\n            ],\n            timeout=7,\n        )\n        system.enable_service(distro.conn)\n\n    elif distro.init == 'upstart':\n        remoto.process.run(\n             distro.conn,\n             [\n                 'initctl',\n                 'emit',\n                 'ceph-mon',\n                 'cluster={cluster}'.format(cluster=cluster),\n                 'id={hostname}'.format(hostname=hostname),\n             ],\n             timeout=7,\n         )\n\n    elif distro.init == 'systemd':\n       # enable ceph target for this host (in case it isn't already enabled)\n        remoto.process.run(\n            distro.conn,\n            [\n                'systemctl',\n                'enable',\n                'ceph.target'\n            ],\n            timeout=7,\n        )\n\n        # enable and start this mon instance\n        remoto.process.run(\n            distro.conn,\n            [\n                'systemctl',\n                'enable',\n                'ceph-mon@{hostname}'.format(hostname=hostname),\n            ],\n            timeout=7,\n        )\n        remoto.process.run(\n            distro.conn,\n            [\n                'systemctl',\n                'start',\n                'ceph-mon@{hostname}'.format(hostname=hostname),\n            ],\n            timeout=7,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __voronoi_finite_polygons_2d(vor, radius=None):\n\n        if vor.points.shape[1] != 2:\n            raise ValueError(\"Requires 2D input\")\n\n        new_regions = []\n        new_vertices = vor.vertices.tolist()\n\n        center = vor.points.mean(axis=0)\n        if radius is None:\n            radius = vor.points.ptp().max()\n\n        # Construct a map containing all ridges for a given point\n        all_ridges = {}\n        for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n            all_ridges.setdefault(p1, []).append((p2, v1, v2))\n            all_ridges.setdefault(p2, []).append((p1, v1, v2))\n\n        # Reconstruct infinite regions\n        for p1, region in enumerate(vor.point_region):\n            vertices = vor.regions[region]\n\n            if all(v >= 0 for v in vertices):\n                # finite region\n                new_regions.append(vertices)\n                continue\n\n            # reconstruct a non-finite region\n            if p1 not in all_ridges:\n                continue\n\n            ridges = all_ridges[p1]\n            new_region = [v for v in vertices if v >= 0]\n\n            for p2, v1, v2 in ridges:\n                if v2 < 0:\n                    v1, v2 = v2, v1\n                if v1 >= 0:\n                    # finite ridge: already in the region\n                    continue\n\n                # Compute the missing endpoint of an infinite ridge\n\n                t = vor.points[p2] - vor.points[p1] # tangent\n                t /= np.linalg.norm(t)\n                n = np.array([-t[1], t[0]])  # normal\n\n                midpoint = vor.points[[p1, p2]].mean(axis=0)\n                direction = np.sign(np.dot(midpoint - center, n)) * n\n                far_point = vor.vertices[v2] + direction * radius\n\n                new_region.append(len(new_vertices))\n                new_vertices.append(far_point.tolist())\n\n            # sort region counterclockwise\n            vs = np.asarray([new_vertices[v] for v in new_region])\n            c = vs.mean(axis=0)\n            angles = np.arctan2(vs[:,1] - c[1], vs[:,0] - c[0])\n            new_region = np.array(new_region)[np.argsort(angles)]\n\n            # finish\n            new_regions.append(new_region.tolist())\n\n        return new_regions, np.asarray(new_vertices)", "response": "Reconstruct infinite voronoi regions to finite regions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inline(width=900):\n    from IPython.display import Image, HTML, display, clear_output\n    import random\n    import string\n    import urllib\n    import os\n\n    while True:\n        fname = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(32))\n        if not os.path.isfile(fname + '.png'):\n            break\n\n    savefig(fname)\n\n    if os.path.isfile(fname + '.png'):\n        with open(fname + '.png', 'rb') as fin:\n            encoded = base64.b64encode(fin.read())\n            b64 = urllib.parse.quote(encoded)\n\n        image_html = \"<img style='width: %dpx; margin: 0px; float: left; border: 1px solid black;' src='data:image/png;base64,%s' />\" % (width, b64)\n\n        display(HTML(image_html))\n        os.remove(fname + '.png')", "response": "display the map inline in ipython"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a dot density map containing the data.", "response": "def dot(data, color=None, point_size=2, f_tooltip=None):\n    \"\"\"Create a dot density map\n\n    :param data: data access object\n    :param color: color\n    :param point_size: point size\n    :param f_tooltip: function to return a tooltip string for a point\n    \"\"\"\n    from geoplotlib.layers import DotDensityLayer\n    _global_config.layers.append(DotDensityLayer(data, color=color, point_size=point_size, f_tooltip=f_tooltip))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scatter(data, color=None, point_size=2, f_tooltip=None):\n    import warnings\n    warnings.warn(\"deprecated, use geoplotlib.dot\", DeprecationWarning)\n    dot(data, color, point_size, f_tooltip)", "response": "Plot a scatter plot."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a 2D histogram of the object containing the data.", "response": "def hist(data, cmap='hot', alpha=220, colorscale='sqrt', binsize=16, show_tooltip=False,\n         scalemin=0, scalemax=None, f_group=None, show_colorbar=True):\n    \"\"\"Create a 2D histogram\n\n    :param data: data access object\n    :param cmap: colormap name\n    :param alpha: color alpha\n    :param colorscale: scaling [lin, log, sqrt]\n    :param binsize: size of the hist bins\n    :param show_tooltip: if True, will show the value of bins on mouseover\n    :param scalemin: min value for displaying a bin\n    :param scalemax: max value for a bin\n    :param f_group: function to apply to samples in the same bin. Default is to count\n    :param show_colorbar: show colorbar\n    \"\"\"\n    from geoplotlib.layers import HistogramLayer\n    _global_config.layers.append(HistogramLayer(data, cmap=cmap, alpha=alpha, colorscale=colorscale,\n                                    binsize=binsize, show_tooltip=show_tooltip, scalemin=scalemin, \n                                    scalemax=scalemax, f_group=f_group, show_colorbar=show_colorbar))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef graph(data, src_lat, src_lon, dest_lat, dest_lon, linewidth=1, alpha=220, color='hot'):\n    from geoplotlib.layers import GraphLayer\n    _global_config.layers.append(GraphLayer(data, src_lat, src_lon, dest_lat, dest_lon, linewidth, alpha, color))", "response": "Create a graph between each pair of src_lat src_lon and dest_lat and dest_lon."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shapefiles(fname, f_tooltip=None, color=None, linewidth=3, shape_type='full'):\n    from geoplotlib.layers import ShapefileLayer\n    _global_config.layers.append(ShapefileLayer(fname, f_tooltip, color, linewidth, shape_type))", "response": "Load and draws a shapefile from a file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing the voronoi tesselation of the points in the object", "response": "def voronoi(data, line_color=None, line_width=2, f_tooltip=None, cmap=None, max_area=1e4, alpha=220):\n    \"\"\"\n    Draw the voronoi tesselation of the points\n\n    :param data: data access object\n    :param line_color: line color\n    :param line_width: line width\n    :param f_tooltip: function to generate a tooltip on mouseover\n    :param cmap: color map\n    :param max_area: scaling constant to determine the color of the voronoi areas\n    :param alpha: color alpha\n    \"\"\"\n    from geoplotlib.layers import VoronoiLayer\n    _global_config.layers.append(VoronoiLayer(data, line_color, line_width, f_tooltip, cmap, max_area, alpha))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw a delaunay triangulation of the points in a cluster.", "response": "def delaunay(data, line_color=None, line_width=2, cmap=None, max_lenght=100):\n    \"\"\"\n    Draw a delaunay triangulation of the points\n\n    :param data: data access object\n    :param line_color: line color\n    :param line_width: line width\n    :param cmap: color map\n    :param max_lenght: scaling constant for coloring the edges\n    \"\"\"\n    from geoplotlib.layers import DelaunayLayer\n    _global_config.layers.append(DelaunayLayer(data, line_color, line_width, cmap, max_lenght))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convexhull(data, col, fill=True, point_size=4):\n    from geoplotlib.layers import ConvexHullLayer\n    _global_config.layers.append(ConvexHullLayer(data, col, fill, point_size))", "response": "Convex hull for a set of points"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kde(data, bw, cmap='hot', method='hist', scaling='sqrt', alpha=220,\n                 cut_below=None, clip_above=None, binsize=1, cmap_levels=10, show_colorbar=False):\n    \"\"\"\n    Kernel density estimation visualization\n\n    :param data: data access object\n    :param bw: kernel bandwidth (in screen coordinates)\n    :param cmap: colormap\n    :param method: if kde use KDEMultivariate from statsmodel, which provides a more accurate but much slower estimation.\n        If hist, estimates density applying gaussian smoothing on a 2D histogram, which is much faster but less accurate\n    :param scaling: colorscale, lin log or sqrt\n    :param alpha: color alpha\n    :param cut_below: densities below cut_below are not drawn\n    :param clip_above: defines the max value for the colorscale\n    :param binsize: size of the bins for hist estimator\n    :param cmap_levels: discretize colors into cmap_levels levels\n    :param show_colorbar: show colorbar\n    \"\"\"\n    from geoplotlib.layers import KDELayer\n    _global_config.layers.append(KDELayer(data, bw, cmap, method, scaling, alpha,\n                 cut_below, clip_above, binsize, cmap_levels, show_colorbar))", "response": "Kernel density estimation visualization"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndraws markers on the object", "response": "def markers(data, marker, f_tooltip=None, marker_preferred_size=32):\n    \"\"\"\n    Draw markers\n\n    :param data: data access object\n    :param marker: full filename of the marker image\n    :param f_tooltip: function to generate a tooltip on mouseover\n    :param marker_preferred_size: size in pixel for the marker images\n    \"\"\"\n    from geoplotlib.layers import MarkersLayer\n    _global_config.layers.append(MarkersLayer(data, marker, f_tooltip, marker_preferred_size))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef geojson(filename, color='b', linewidth=1, fill=False, f_tooltip=None):\n    from geoplotlib.layers import GeoJSONLayer\n    _global_config.layers.append(GeoJSONLayer(filename, color=color, linewidth=linewidth, fill=fill, f_tooltip=f_tooltip))", "response": "Draw features described in geojson format"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw a text label for each sample in the n - sample dataset", "response": "def labels(data, label_column, color=None, font_name=FONT_NAME, \n           font_size=14, anchor_x='left', anchor_y='top'):\n    \"\"\"\n    Draw a text label for each sample\n\n    :param data: data access object\n    :param label_column: column in the data access object where the labels text is stored\n    :param color: color\n    :param font_name: font name\n    :param font_size: font size\n    :param anchor_x: anchor x\n    :param anchor_y: anchor y\n    \"\"\"\n    from geoplotlib.layers import LabelsLayer\n    _global_config.layers.append(LabelsLayer(data, label_column, color, font_name, \n           font_size, anchor_x, anchor_y))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays a grid of values on a uniform grid of the specified area.", "response": "def grid(lon_edges, lat_edges, values, cmap, alpha=255, vmin=None, vmax=None, levels=10, colormap_scale='lin', show_colorbar=True):\n    \"\"\"\n        Values on a uniform grid\n        \n        :param lon_edges: longitude edges\n        :param lat_edges: latitude edges\n        :param values: matrix representing values on the grid \n        :param cmap: colormap name\n        :param alpha: color alpha\n        :param vmin: minimum value for the colormap\n        :param vmax: maximum value for the colormap\n        :param levels: number of levels for the colormap\n        :param colormap_scale: colormap scale\n        :param show_colorbar: show the colorbar in the UI\n        \"\"\"\n    from geoplotlib.layers import GridLayer\n    _global_config.layers.append(\n        GridLayer(lon_edges, lat_edges, values, cmap, alpha, vmin, vmax, levels, colormap_scale, show_colorbar))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the map alpha color of the base map tiles.", "response": "def set_map_alpha(alpha):\n    \"\"\"\n    Alpha color of the map tiles\n\n    :param alpha: int between 0 and 255. 0 is completely dark, 255 is full brightness\n    \"\"\"\n    if alpha < 0 or alpha > 255:\n        raise Exception('invalid alpha '  + str(alpha))\n    _global_config.map_alpha = alpha"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the distance between two points in meters.", "response": "def haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Distance between geodesic coordinates http://www.movable-type.co.uk/scripts/latlong.html\n\n    :param lon1: point 1 latitude\n    :param lat1: point 1 longitude\n    :param lon2: point 1 latitude\n    :param lat2: point 2 longitude\n    :return: distance in meters between points 1 and 2\n    \"\"\"\n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a))\n    m = 6367000 * c\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a csv file into a DataAccessObject", "response": "def read_csv(fname):\n    \"\"\"\n    Read a csv file into a DataAccessObject\n\n    :param fname: filename\n    \"\"\"\n    values = defaultdict(list)\n    with open(fname) as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            for (k,v) in row.items():\n                values[k].append(v)\n    npvalues = {k: np.array(values[k]) for k in values.keys()}\n    for k in npvalues.keys():\n        for datatype in [np.int, np.float]:\n            try:\n                npvalues[k][:1].astype(datatype)\n                npvalues[k] = npvalues[k].astype(datatype)\n                break\n            except:\n                pass\n    dao = DataAccessObject(npvalues)\n    return dao"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename(self, mapping):\n        for old_key, new_key in mapping:\n            self.dict[new_key] = self.dict[old_key]\n            del self.dict[old_key]", "response": "Rename the keys in the dictionary with the values from the old to new keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a DataAccessObject with a subset of rows matching mask", "response": "def where(self, mask):\n        \"\"\"\n        :param mask: boolean mask\n        :return: a DataAccessObject with a subset of rows matching mask\n        \"\"\"\n        assert len(mask) == len(self)\n        return DataAccessObject({k: self.dict[k][mask] for k in self.dict})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a DataAccessObject containing the first n rows", "response": "def head(self, n):\n        \"\"\"\n        Return a DataAccessObject containing the first n rows\n\n        :param n: number of rows\n        :return: DataAccessObject\n        \"\"\"\n        return DataAccessObject({k: self.dict[k][:n] for k in self.dict})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the BoundingBox from a set of latitudes and longitudes.", "response": "def from_points(lons, lats):\n        \"\"\"\n        Compute the BoundingBox from a set of latitudes and longitudes\n\n        :param lons: longitudes\n        :param lats: latitudes\n        :return: BoundingBox\n        \"\"\"\n        north, west = max(lats), min(lons)\n        south, east = min(lats), max(lons)\n        return BoundingBox(north=north, west=west, south=south, east=east)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_bboxes(bboxes):\n        north = max([b.north for b in bboxes])\n        south = min([b.south for b in bboxes])\n        west = min([b.west for b in bboxes])\n        east = max([b.east for b in bboxes])\n        return BoundingBox(north=north, west=west, south=south, east=east)", "response": "Compute a BoundingBox from a list of BoundingBoxes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_set_cmap(values, cmap_name, alpha=255):\n    unique_values = list(set(values))\n    shuffle(unique_values)\n    from pylab import get_cmap\n    cmap = get_cmap(cmap_name)\n    d = {}\n    for i in range(len(unique_values)):\n        d[unique_values[i]] = _convert_color_format(cmap(1.*i/len(unique_values)), alpha)\n    return d", "response": "Create a dictionary of colors corresponding to the unique values in the set cmap_name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef colorbrewer(values, alpha=255):\n    basecolors = [\n        [31, 120, 180],\n        [178, 223, 138],\n        [51, 160, 44],\n        [251, 154, 153],\n        [227, 26, 28],\n        [253, 191, 111],\n        [255, 127, 0],\n        [202, 178, 214],\n        [106, 61, 154],\n        [255, 255, 153],\n        [177, 89, 40]\n    ]\n    unique_values = list(set(values))\n    return {k: basecolors[i % len(basecolors)] + [alpha]  for i, k in enumerate(unique_values)}", "response": "ColorBrewer. org is adapted from Harrower Mark and Cynthia A. Brewer. org an online tool for selecting colour schemes for maps."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_color(self, value, maxvalue, scale, minvalue=0.0):\n        \n        if scale == 'lin':\n            if minvalue >= maxvalue:\n                raise Exception('minvalue must be less than maxvalue')\n            else:\n                value = 1.*(value-minvalue) / (maxvalue-minvalue)\n        elif scale == 'log':\n            if value < 1 or maxvalue <= 1:\n                raise Exception('value and maxvalue must be >= 1')\n            else:\n                value = math.log(value) / math.log(maxvalue)\n        elif scale == 'sqrt':\n            if value < 0 or maxvalue <= 0:\n                raise Exception('value and maxvalue must be greater than 0')\n            else:\n                value = math.sqrt(value) / math.sqrt(maxvalue)\n        else:\n            raise Exception('scale must be \"lin\", \"log\", or \"sqrt\"')\n\n        if value < 0:\n            value = 0\n        elif value > 1:\n            value = 1\n\n        value = int(1.*self.levels*value)*1./(self.levels-1)\n\n        if value not in self.mapping:\n            self.mapping[value] = _convert_color_format(self.cmap(value), self.alpha)\n        return self.mapping[value]", "response": "convert continuous values into colors using matplotlib colorscales\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a spline from two lists of points x and y.", "response": "def __generate_spline(self, x, y, closed=False, steps=20):\n        \"\"\"\n        catmullrom spline\n        http://www.mvps.org/directx/articles/catmull/\n        \"\"\"\n\n        if closed:\n            x = x.tolist()\n            x.insert(0, x[-1])\n            x.append(x[1])\n            x.append(x[2])\n\n            y = y.tolist()\n            y.insert(0, y[-1])\n            y.append(y[1])\n            y.append(y[2])\n\n        points = np.vstack((x,y)).T\n\n        curve = []\n\n        if not closed:\n            curve.append(points[0])\n\n        for j in range(1, len(points)-2):\n            for s in range(steps):\n                t = 1. * s / steps\n                p0, p1, p2, p3 = points[j-1], points[j], points[j+1], points[j+2]\n                pnew = 0.5 *((2 * p1) + (-p0 + p2) * t + (2*p0 - 5*p1 + 4*p2 - p3) * t**2 + (-p0 + 3*p1- 3*p2 + p3) * t**3)\n                curve.append(pnew)\n\n        if not closed:\n            curve.append(points[-1])\n\n        curve = np.array(curve)\n        return curve[:, 0], curve[:, 1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfit the projector to a BoundingBox", "response": "def fit(self, bbox, max_zoom=MAX_ZOOM, force_zoom=None):\n        \"\"\"\n        Fits the projector to a BoundingBox\n        :param bbox: BoundingBox\n        :param max_zoom: max zoom allowed\n        :param force_zoom: force this specific zoom value even if the whole bbox does not completely fit\n        \"\"\"\n\n        BUFFER_FACTOR = 1.1\n        \n        if force_zoom is not None:\n            self.zoom = force_zoom\n        else:\n            for zoom in range(max_zoom, MIN_ZOOM-1, -1):\n                self.zoom = zoom\n                left, top = self.lonlat_to_screen([bbox.west], [bbox.north])\n                right, bottom = self.lonlat_to_screen([bbox.east], [bbox.south])\n                if (top - bottom < SCREEN_H*BUFFER_FACTOR) and (right - left < SCREEN_W*BUFFER_FACTOR):\n                    break\n\n        west_tile, north_tile = self.deg2num(bbox.north, bbox.west, self.zoom)\n        east_tile, south_tile = self.deg2num(bbox.south, bbox.east, self.zoom)\n        self.xtile = west_tile - self.tiles_horizontally/2. + (east_tile - west_tile)/2\n        self.ytile = north_tile - self.tiles_vertically/2. + (south_tile - north_tile)/2\n        self.calculate_viewport_size()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lonlat_to_screen(self, lon, lat):\n        if type(lon) == list:\n            lon = np.array(lon)\n        if type(lat) == list:\n            lat = np.array(lat)\n\n        lat_rad = np.radians(lat)\n        n = 2.0 ** self.zoom\n        xtile = (lon + 180.0) / 360.0 * n\n        ytile = (1.0 - np.log(np.tan(lat_rad) + (1 / np.cos(lat_rad))) / math.pi) / 2.0 * n\n        x = (xtile * TILE_SIZE).astype(int)\n        y = (SCREEN_H - ytile * TILE_SIZE).astype(int)\n        return x, y", "response": "Projects geodesic coordinates to screen coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef screen_to_latlon(self, x, y):\n        xtile = 1. * x / TILE_SIZE + self.xtile\n        ytile = 1. * y / TILE_SIZE + self.ytile\n        return self.num2deg(xtile, ytile, self.zoom)", "response": "Return the latitude and longitude corresponding to a screen point"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_pydoc_completions(modulename):\n    modulename = compat.ensure_not_unicode(modulename)\n    modulename = modulename.rstrip(\".\")\n    if modulename == \"\":\n        return sorted(get_modules())\n    candidates = get_completions(modulename)\n    if candidates:\n        return sorted(candidates)\n    needle = modulename\n    if \".\" in needle:\n        modulename, part = needle.rsplit(\".\", 1)\n        candidates = get_completions(modulename)\n    else:\n        candidates = get_modules()\n    return sorted(candidate for candidate in candidates\n                  if candidate.startswith(needle))", "response": "Get possible completions for modulename for pydoc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_modules(modulename=None):\n    modulename = compat.ensure_not_unicode(modulename)\n    if not modulename:\n        try:\n            return ([modname for (importer, modname, ispkg)\n                     in iter_modules()\n                     if not modname.startswith(\"_\")] +\n                    list(sys.builtin_module_names))\n        except OSError:\n            # Bug in Python 2.6, see #275\n            return list(sys.builtin_module_names)\n    try:\n        module = safeimport(modulename)\n    except ErrorDuringImport:\n        return []\n    if module is None:\n        return []\n    if hasattr(module, \"__path__\"):\n        return [modname for (importer, modname, ispkg)\n                in iter_modules(module.__path__)\n                if not modname.startswith(\"_\")]\n    return []", "response": "Return a list of modules and packages under modulename."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_json(self):\n        line = self.stdin.readline()\n        if line == '':\n            raise EOFError()\n        return json.loads(line)", "response": "Read a single line and decode it as JSON."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_json(self, **kwargs):\n        self.stdout.write(json.dumps(kwargs) + \"\\n\")\n        self.stdout.flush()", "response": "Write a JSON object on a single line."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle_request(self):\n        request = self.read_json()\n        if 'method' not in request:\n            raise ValueError(\"Received a bad request: {0}\"\n                             .format(request))\n        method_name = request['method']\n        request_id = request.get('id', None)\n        params = request.get('params') or []\n        try:\n            method = getattr(self, \"rpc_\" + method_name, None)\n            if method is not None:\n                result = method(*params)\n            else:\n                result = self.handle(method_name, params)\n            if request_id is not None:\n                self.write_json(result=result,\n                                id=request_id)\n        except Fault as fault:\n            error = {\"message\": fault.message,\n                     \"code\": fault.code}\n            if fault.data is not None:\n                error[\"data\"] = fault.data\n            self.write_json(error=error, id=request_id)\n        except Exception as e:\n            error = {\"message\": str(e),\n                     \"code\": 500,\n                     \"data\": {\"traceback\": traceback.format_exc()}}\n            self.write_json(error=error, id=request_id)", "response": "Handle a single JSON - RPC request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fix_code(code, directory):\n    if not autopep8:\n        raise Fault('autopep8 not installed, cannot fix code.',\n                    code=400)\n    old_dir = os.getcwd()\n    try:\n        os.chdir(directory)\n        return autopep8.fix_code(code, apply_config=True)\n    finally:\n        os.chdir(old_dir)", "response": "Formats Python code to conform to PEP 8 style guide."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntranslating fileobj into file contents.", "response": "def get_source(fileobj):\n    \"\"\"Translate fileobj into file contents.\n\n    fileobj is either a string or a dict. If it's a string, that's the\n    file contents. If it's a string, then the filename key contains\n    the name of the file whose contents we are to use.\n\n    If the dict contains a true value for the key delete_after_use,\n    the file should be deleted once read.\n\n    \"\"\"\n    if not isinstance(fileobj, dict):\n        return fileobj\n    else:\n        try:\n            with io.open(fileobj[\"filename\"], encoding=\"utf-8\",\n                         errors=\"ignore\") as f:\n                return f.read()\n        finally:\n            if fileobj.get('delete_after_use'):\n                try:\n                    os.remove(fileobj[\"filename\"])\n                except:  # pragma: no cover\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _call_backend(self, method, default, *args, **kwargs):\n        meth = getattr(self.backend, method, None)\n        if meth is None:\n            return default\n        else:\n            return meth(*args, **kwargs)", "response": "Call the backend method with args.\n\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the calltip for the function at the offset.", "response": "def rpc_get_calltip(self, filename, source, offset):\n        \"\"\"Get the calltip for the function at the offset.\n\n        \"\"\"\n        return self._call_backend(\"rpc_get_calltip\", None, filename,\n                                  get_source(source), offset)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rpc_get_oneline_docstring(self, filename, source, offset):\n        return self._call_backend(\"rpc_get_oneline_docstring\", None, filename,\n                                  get_source(source), offset)", "response": "Get the oneline docstring for the symbol at the offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of completion candidates for the symbol at offset.", "response": "def rpc_get_completions(self, filename, source, offset):\n        \"\"\"Get a list of completion candidates for the symbol at offset.\n\n        \"\"\"\n        results = self._call_backend(\"rpc_get_completions\", [], filename,\n                                     get_source(source), offset)\n        # Uniquify by name\n        results = list(dict((res['name'], res) for res in results)\n                       .values())\n        results.sort(key=lambda cand: _pysymbol_key(cand[\"name\"]))\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the definition for the symbol at the offset.", "response": "def rpc_get_definition(self, filename, source, offset):\n        \"\"\"Get the location of the definition for the symbol at the offset.\n\n        \"\"\"\n        return self._call_backend(\"rpc_get_definition\", None, filename,\n                                  get_source(source), offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rpc_get_assignment(self, filename, source, offset):\n        return self._call_backend(\"rpc_get_assignment\", None, filename,\n                                  get_source(source), offset)", "response": "Get the location of the assignment for the symbol at the offset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rpc_get_docstring(self, filename, source, offset):\n        return self._call_backend(\"rpc_get_docstring\", None, filename,\n                                  get_source(source), offset)", "response": "Get the docstring for the symbol at the offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rpc_get_pydoc_documentation(self, symbol):\n        try:\n            docstring = pydoc.render_doc(str(symbol),\n                                         \"Elpy Pydoc Documentation for %s\",\n                                         False)\n        except (ImportError, pydoc.ErrorDuringImport):\n            return None\n        else:\n            if isinstance(docstring, bytes):\n                docstring = docstring.decode(\"utf-8\", \"replace\")\n            return docstring", "response": "Get the Pydoc documentation for the given symbol."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of possible refactoring options.", "response": "def rpc_get_refactor_options(self, filename, start, end=None):\n        \"\"\"Return a list of possible refactoring options.\n\n        This list will be filtered depending on whether it's\n        applicable at the point START and possibly the region between\n        START and END.\n\n        \"\"\"\n        try:\n            from elpy import refactor\n        except:\n            raise ImportError(\"Rope not installed, refactorings unavailable\")\n        ref = refactor.Refactor(self.project_root, filename)\n        return ref.get_refactor_options(start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rpc_refactor(self, filename, method, args):\n        try:\n            from elpy import refactor\n        except:\n            raise ImportError(\"Rope not installed, refactorings unavailable\")\n        if args is None:\n            args = ()\n        ref = refactor.Refactor(self.project_root, filename)\n        return ref.get_changes(method, *args)", "response": "Return a list of changes from the refactoring action."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rpc_get_names(self, filename, source, offset):\n        source = get_source(source)\n        if hasattr(self.backend, \"rpc_get_names\"):\n            return self.backend.rpc_get_names(filename, source, offset)\n        else:\n            raise Fault(\"get_names not implemented by current backend\",\n                        code=400)", "response": "Get all possible names for a file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat Python code to conform to PEP 8 style guide.", "response": "def rpc_fix_code(self, source, directory):\n        \"\"\"Formats Python code to conform to the PEP 8 style guide.\n\n        \"\"\"\n        source = get_source(source)\n        return fix_code(source, directory)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rpc_fix_code_with_yapf(self, source, directory):\n        source = get_source(source)\n        return fix_code_with_yapf(source, directory)", "response": "Formats Python code to conform to PEP 8 style guide."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting Python code to conform to PEP 8 style guide.", "response": "def rpc_fix_code_with_black(self, source, directory):\n        \"\"\"Formats Python code to conform to the PEP 8 style guide.\n\n        \"\"\"\n        source = get_source(source)\n        return fix_code_with_black(source, directory)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tuple of line and column for offset pos in text.", "response": "def pos_to_linecol(text, pos):\n    \"\"\"Return a tuple of line and column for offset pos in text.\n\n    Lines are one-based, columns zero-based.\n\n    This is how Jedi wants it. Don't ask me why.\n\n    \"\"\"\n    line_start = text.rfind(\"\\n\", 0, pos) + 1\n    line = text.count(\"\\n\", 0, line_start) + 1\n    col = pos - line_start\n    return line, col"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the offset of this line and column in text.", "response": "def linecol_to_pos(text, line, col):\n    \"\"\"Return the offset of this line and column in text.\n\n    Lines are one-based, columns zero-based.\n\n    This is how Jedi wants it. Don't ask me why.\n\n    \"\"\"\n    nth_newline_offset = 0\n    for i in range(line - 1):\n        new_offset = text.find(\"\\n\", nth_newline_offset)\n        if new_offset < 0:\n            raise ValueError(\"Text does not have {0} lines.\"\n                             .format(line))\n        nth_newline_offset = new_offset + 1\n    offset = nth_newline_offset + col\n    if offset > len(text):\n        raise ValueError(\"Line {0} column {1} is not within the text\"\n                         .format(line, col))\n    return offset"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the oneline docstring for the symbol at offset", "response": "def rpc_get_oneline_docstring(self, filename, source, offset):\n        \"\"\"Return a oneline docstring for the symbol at offset\"\"\"\n        line, column = pos_to_linecol(source, offset)\n        definitions = run_with_debug(jedi, 'goto_definitions',\n                                     source=source, line=line, column=column,\n                                     path=filename, encoding='utf-8')\n        assignments = run_with_debug(jedi, 'goto_assignments',\n                                     source=source, line=line, column=column,\n                                     path=filename, encoding='utf-8')\n        if definitions:\n            definition = definitions[0]\n        else:\n            definition = None\n        if assignments:\n            assignment = assignments[0]\n        else:\n            assignment = None\n        if definition:\n            # Get name\n            if definition.type in ['function', 'class']:\n                raw_name = definition.name\n                name = '{}()'.format(raw_name)\n                doc = definition.docstring().split('\\n')\n            elif definition.type in ['module']:\n                raw_name = definition.name\n                name = '{} {}'.format(raw_name, definition.type)\n                doc = definition.docstring().split('\\n')\n            elif (definition.type in ['instance']\n                  and hasattr(assignment, \"name\")):\n                raw_name = assignment.name\n                name = raw_name\n                doc = assignment.docstring().split('\\n')\n            else:\n                return None\n            # Keep only the first paragraph that is not a function declaration\n            lines = []\n            call = \"{}(\".format(raw_name)\n            # last line\n            doc.append('')\n            for i in range(len(doc)):\n                if doc[i] == '' and len(lines) != 0:\n                    paragraph = \" \".join(lines)\n                    lines = []\n                    if call != paragraph[0:len(call)]:\n                        break\n                    paragraph = \"\"\n                    continue\n                lines.append(doc[i])\n            # Keep only the first sentence\n            onelinedoc = paragraph.split('. ', 1)\n            if len(onelinedoc) == 2:\n                onelinedoc = onelinedoc[0] + '.'\n            else:\n                onelinedoc = onelinedoc[0]\n            if onelinedoc == '':\n                onelinedoc = \"No documentation\"\n            return {\"name\": name,\n                    \"doc\": onelinedoc}\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the uses of the symbol at offset.", "response": "def rpc_get_usages(self, filename, source, offset):\n        \"\"\"Return the uses of the symbol at offset.\n\n        Returns a list of occurrences of the symbol, as dicts with the\n        fields name, filename, and offset.\n\n        \"\"\"\n        line, column = pos_to_linecol(source, offset)\n        uses = run_with_debug(jedi, 'usages',\n                              source=source, line=line, column=column,\n                              path=filename, encoding='utf-8')\n        if uses is None:\n            return None\n        result = []\n        for use in uses:\n            if use.module_path == filename:\n                offset = linecol_to_pos(source, use.line, use.column)\n            elif use.module_path is not None:\n                with open(use.module_path) as f:\n                    text = f.read()\n                offset = linecol_to_pos(text, use.line, use.column)\n\n            result.append({\"name\": use.name,\n                           \"filename\": use.module_path,\n                           \"offset\": offset})\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rpc_get_names(self, filename, source, offset):\n        names = jedi.api.names(source=source,\n                               path=filename, encoding='utf-8',\n                               all_scopes=True,\n                               definitions=True,\n                               references=True)\n\n        result = []\n        for name in names:\n            if name.module_path == filename:\n                offset = linecol_to_pos(source, name.line, name.column)\n            elif name.module_path is not None:\n                with open(name.module_path) as f:\n                    text = f.read()\n                offset = linecol_to_pos(text, name.line, name.column)\n            result.append({\"name\": name.name,\n                           \"filename\": name.module_path,\n                           \"offset\": offset})\n        return result", "response": "Return the list of possible names"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fix_code(code, directory):\n    if not black:\n        raise Fault(\"black not installed\", code=400)\n\n    try:\n        if parse_version(black.__version__) < parse_version(\"19.0\"):\n            reformatted_source = black.format_file_contents(\n                src_contents=code, line_length=black.DEFAULT_LINE_LENGTH, fast=False\n            )\n        else:\n            fm = black.FileMode()\n            reformatted_source = black.format_file_contents(\n                src_contents=code, fast=False, mode=fm\n            )\n        return reformatted_source\n    except black.NothingChanged:\n        return code\n    except Exception as e:\n        raise Fault(\"Error during formatting: {}\".format(e), code=400)", "response": "Formats the code to conform to PEP 8 style guide."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef options(description, **kwargs):\n    def set_notes(function):\n        function.refactor_notes = {'name': function.__name__,\n                                   'category': \"Miscellaneous\",\n                                   'description': description,\n                                   'doc': getattr(function, '__doc__',\n                                                  ''),\n                                   'args': []}\n        function.refactor_notes.update(kwargs)\n        return function\n    return set_notes", "response": "Decorator to set some options on a method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate rope. base. change. Change instances to dictionaries.", "response": "def translate_changes(initial_change):\n    \"\"\"Translate rope.base.change.Change instances to dictionaries.\n\n    See Refactor.get_changes for an explanation of the resulting\n    dictionary.\n\n    \"\"\"\n    agenda = [initial_change]\n    result = []\n    while agenda:\n        change = agenda.pop(0)\n        if isinstance(change, rope_change.ChangeSet):\n            agenda.extend(change.changes)\n        elif isinstance(change, rope_change.ChangeContents):\n            result.append({'action': 'change',\n                           'file': change.resource.real_path,\n                           'contents': change.new_contents,\n                           'diff': change.get_description()})\n        elif isinstance(change, rope_change.CreateFile):\n            result.append({'action': 'create',\n                           'type': 'file',\n                           'file': change.resource.real_path})\n        elif isinstance(change, rope_change.CreateFolder):\n            result.append({'action': 'create',\n                           'type': 'directory',\n                           'path': change.resource.real_path})\n        elif isinstance(change, rope_change.MoveResource):\n            result.append({'action': 'move',\n                           'type': ('directory'\n                                    if change.new_resource.is_folder()\n                                    else 'file'),\n                           'source': change.resource.real_path,\n                           'destination': change.new_resource.real_path})\n        elif isinstance(change, rope_change.RemoveResource):\n            if change.resource.is_folder():\n                result.append({'action': 'delete',\n                               'type': 'directory',\n                               'path': change.resource.real_path})\n            else:\n                result.append({'action': 'delete',\n                               'type': 'file',\n                               'file': change.resource.real_path})\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_refactor_options(self, start, end=None):\n        result = []\n        for symbol in dir(self):\n            if not symbol.startswith(\"refactor_\"):\n                continue\n            method = getattr(self, symbol)\n            if not method.refactor_notes.get('available', True):\n                continue\n            category = method.refactor_notes['category']\n            if end is not None and category != 'Region':\n                continue\n            if end is None and category == 'Region':\n                continue\n            is_on_symbol = self._is_on_symbol(start)\n            if not is_on_symbol and category in ('Symbol', 'Method'):\n                continue\n            requires_import = method.refactor_notes.get('only_on_imports',\n                                                        False)\n            if requires_import and not self._is_on_import_statement(start):\n                continue\n            result.append(method.refactor_notes)\n        return result", "response": "Return a list of options for refactoring at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing this offset point to an import statement?", "response": "def _is_on_import_statement(self, offset):\n        \"Does this offset point to an import statement?\"\n        data = self.resource.read()\n        bol = data.rfind(\"\\n\", 0, offset) + 1\n        eol = data.find(\"\\n\", 0, bol)\n        if eol == -1:\n            eol = len(data)\n        line = data[bol:eol]\n        line = line.strip()\n        if line.startswith(\"import \") or line.startswith(\"from \"):\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbeing this offset on a symbol?", "response": "def _is_on_symbol(self, offset):\n        \"Is this offset on a symbol?\"\n        if not ROPE_AVAILABLE:\n            return False\n        data = self.resource.read()\n        if offset >= len(data):\n            return False\n        if data[offset] != '_' and not data[offset].isalnum():\n            return False\n        word = worder.get_name_at(self.resource, offset)\n        if word:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_changes(self, name, *args):\n        if not name.startswith(\"refactor_\"):\n            raise ValueError(\"Bad refactoring name {0}\".format(name))\n        method = getattr(self, name)\n        if not method.refactor_notes.get('available', True):\n            raise RuntimeError(\"Method not available\")\n        return method(*args)", "response": "Return a list of changes for the named refactoring action."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting froms to imports.", "response": "def refactor_froms_to_imports(self, offset):\n        \"\"\"Converting imports of the form \"from ...\" to \"import ...\".\"\"\"\n        refactor = ImportOrganizer(self.project)\n        changes = refactor.froms_to_imports(self.resource, offset)\n        return translate_changes(changes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refactor_organize_imports(self):\n        refactor = ImportOrganizer(self.project)\n        changes = refactor.organize_imports(self.resource)\n        return translate_changes(changes)", "response": "Clean up and organize imports."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refactor_module_to_package(self):\n        refactor = ModuleToPackage(self.project, self.resource)\n        return self._get_changes(refactor)", "response": "Convert the current module into a package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrename the symbol at point.", "response": "def refactor_rename_at_point(self, offset, new_name, in_hierarchy, docs):\n        \"\"\"Rename the symbol at point.\"\"\"\n        try:\n            refactor = Rename(self.project, self.resource, offset)\n        except RefactoringError as e:\n            raise Fault(str(e), code=400)\n        return self._get_changes(refactor, new_name,\n                                 in_hierarchy=in_hierarchy, docs=docs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrenaming the current module.", "response": "def refactor_rename_current_module(self, new_name):\n        \"\"\"Rename the current module.\"\"\"\n        refactor = Rename(self.project, self.resource, None)\n        return self._get_changes(refactor, new_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refactor_move_module(self, new_name):\n        refactor = create_move(self.project, self.resource)\n        resource = path_to_resource(self.project, new_name)\n        return self._get_changes(refactor, resource)", "response": "Move the current module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refactor_create_inline(self, offset, only_this):\n        refactor = create_inline(self.project, self.resource, offset)\n        if only_this:\n            return self._get_changes(refactor, remove=False, only_current=True)\n        else:\n            return self._get_changes(refactor, remove=True, only_current=False)", "response": "Inline the function call at point."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refactor_extract_method(self, start, end, name,\n                                make_global):\n        \"\"\"Extract region as a method.\"\"\"\n        refactor = ExtractMethod(self.project, self.resource, start, end)\n        return self._get_changes(\n            refactor, name, similar=True, global_=make_global\n        )", "response": "Extract region as a method."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses the function at point wherever possible.", "response": "def refactor_use_function(self, offset):\n        \"\"\"Use the function at point wherever possible.\"\"\"\n        try:\n            refactor = UseFunction(self.project, self.resource, offset)\n        except RefactoringError as e:\n            raise Fault(\n                'Refactoring error: {}'.format(e),\n                code=400\n            )\n        return self._get_changes(refactor)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat the code to conform to PEP 8 style guide.", "response": "def fix_code(code, directory):\n    \"\"\"Formats Python code to conform to the PEP 8 style guide.\n\n    \"\"\"\n    if not yapf_api:\n        raise Fault('yapf not installed', code=400)\n    style_config = file_resources.GetDefaultStyleForDir(directory or os.getcwd())\n    try:\n        reformatted_source, _ = yapf_api.FormatCode(code,\n                                                    filename='<stdin>',\n                                                    style_config=style_config,\n                                                    verify=False)\n        return reformatted_source\n    except Exception as e:\n            raise Fault(\"Error during formatting: {}\".format(e),\n                        code=400)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send_receive(self, payload):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n        s.settimeout(self.connection_timeout)\n        s.connect((self.address, self.port))\n        s.send(payload)\n        data = s.recv(1024)\n        s.close()\n        return data", "response": "Send and receive a single buffer payload and return the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_payload(self, command, data=None):\n        json_data = payload_dict[self.dev_type][command]['command']\n\n        if 'gwId' in json_data:\n            json_data['gwId'] = self.id\n        if 'devId' in json_data:\n            json_data['devId'] = self.id\n        if 'uid' in json_data:\n            json_data['uid'] = self.id  # still use id, no seperate uid\n        if 't' in json_data:\n            json_data['t'] = str(int(time.time()))\n\n        if data is not None:\n            json_data['dps'] = data\n\n        # Create byte buffer from hex data\n        json_payload = json.dumps(json_data)\n        #print(json_payload)\n        json_payload = json_payload.replace(' ', '')  # if spaces are not removed device does not respond!\n        json_payload = json_payload.encode('utf-8')\n        log.debug('json_payload=%r', json_payload)\n\n        if command == SET:\n            # need to encrypt\n            #print('json_payload %r' % json_payload)\n            self.cipher = AESCipher(self.local_key)  # expect to connect and then disconnect to set new\n            json_payload = self.cipher.encrypt(json_payload)\n            #print('crypted json_payload %r' % json_payload)\n            preMd5String = b'data=' + json_payload + b'||lpv=' + PROTOCOL_VERSION_BYTES + b'||' + self.local_key\n            #print('preMd5String %r' % preMd5String)\n            m = md5()\n            m.update(preMd5String)\n            #print(repr(m.digest()))\n            hexdigest = m.hexdigest()\n            #print(hexdigest)\n            #print(hexdigest[8:][:16])\n            json_payload = PROTOCOL_VERSION_BYTES + hexdigest[8:][:16].encode('latin1') + json_payload\n            #print('data_to_send')\n            #print(json_payload)\n            #print('crypted json_payload (%d) %r' % (len(json_payload), json_payload))\n            #print('json_payload  %r' % repr(json_payload))\n            #print('json_payload len %r' % len(json_payload))\n            #print(bin2hex(json_payload))\n            self.cipher = None  # expect to connect and then disconnect to set new\n\n\n        postfix_payload = hex2bin(bin2hex(json_payload) + payload_dict[self.dev_type]['suffix'])\n        #print('postfix_payload %r' % postfix_payload)\n        #print('postfix_payload %r' % len(postfix_payload))\n        #print('postfix_payload %x' % len(postfix_payload))\n        #print('postfix_payload %r' % hex(len(postfix_payload)))\n        assert len(postfix_payload) <= 0xff\n        postfix_payload_hex_len = '%x' % len(postfix_payload)  # TODO this assumes a single byte 0-255 (0x00-0xff)\n        buffer = hex2bin( payload_dict[self.dev_type]['prefix'] + \n                          payload_dict[self.dev_type][command]['hexByte'] + \n                          '000000' +\n                          postfix_payload_hex_len ) + postfix_payload\n        #print('command', command)\n        #print('prefix')\n        #print(payload_dict[self.dev_type][command]['prefix'])\n        #print(repr(buffer))\n        #print(bin2hex(buffer, pretty=True))\n        #print(bin2hex(buffer, pretty=False))\n        #print('full buffer(%d) %r' % (len(buffer), buffer))\n        return buffer", "response": "Generate the payload to send to the remote."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the status of the current user in the cluster.", "response": "def set_status(self, on, switch=1):\n        \"\"\"\n        Set status of the device to 'on' or 'off'.\n        \n        Args:\n            on(bool):  True for 'on', False for 'off'.\n            switch(int): The switch to set\n        \"\"\"\n        # open device, send request, then close connection\n        if isinstance(switch, int):\n            switch = str(switch)  # index and payload is a string\n        payload = self.generate_payload(SET, {switch:on})\n        #print('payload %r' % payload)\n\n        data = self._send_receive(payload)\n        log.debug('set_status received data=%r', data)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a timer. Args: num_secs(int): Number of seconds", "response": "def set_timer(self, num_secs):\n        \"\"\"\n        Set a timer.\n        \n        Args:\n            num_secs(int): Number of seconds\n        \"\"\"\n        # FIXME / TODO support schemas? Accept timer id number as parameter?\n\n        # Dumb heuristic; Query status, pick last device id as that is probably the timer\n        status = self.status()\n        devices = status['dps']\n        devices_numbers = list(devices.keys())\n        devices_numbers.sort()\n        dps_id = devices_numbers[-1]\n\n        payload = self.generate_payload(SET, {dps_id:num_secs})\n\n        data = self._send_receive(payload)\n        log.debug('set_timer received data=%r', data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _rgb_to_hexvalue(r, g, b):\n        rgb = [r,g,b]\n        hsv = colorsys.rgb_to_hsv(rgb[0]/255, rgb[1]/255, rgb[2]/255)\n\n        hexvalue = \"\"\n        for value in rgb:\n            temp = str(hex(int(value))).replace(\"0x\",\"\")\n            if len(temp) == 1:\n                temp = \"0\" + temp\n            hexvalue = hexvalue + temp\n\n        hsvarray = [int(hsv[0] * 360), int(hsv[1] * 255), int(hsv[2] * 255)]\n        hexvalue_hsv = \"\"\n        for value in hsvarray:\n            temp = str(hex(int(value))).replace(\"0x\",\"\")\n            if len(temp) == 1:\n                temp = \"0\" + temp\n            hexvalue_hsv = hexvalue_hsv + temp\n        if len(hexvalue_hsv) == 7:\n            hexvalue = hexvalue + \"0\" + hexvalue_hsv\n        else:\n            hexvalue = hexvalue + \"00\" + hexvalue_hsv\n\n        return hexvalue", "response": "Convert an RGB value to the hexadecimal representation expected by tuya."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _hexvalue_to_rgb(hexvalue):\n        r = int(hexvalue[0:2], 16)\n        g = int(hexvalue[2:4], 16)\n        b = int(hexvalue[4:6], 16)\n\n        return (r, g, b)", "response": "Converts the hex value used by tuya for colour representation into a RGB value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _hexvalue_to_hsv(hexvalue):\n        h = int(hexvalue[7:10], 16) / 360\n        s = int(hexvalue[10:12], 16) / 255\n        v = int(hexvalue[12:14], 16) / 255\n\n        return (h, s, v)", "response": "Converts the hex value used by tuya for colour representation into a HSV value."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets colour of an rgb bulb.", "response": "def set_colour(self, r, g, b):\n        \"\"\"\n        Set colour of an rgb bulb.\n\n        Args:\n            r(int): Value for the colour red as int from 0-255.\n            g(int): Value for the colour green as int from 0-255.\n            b(int): Value for the colour blue as int from 0-255.\n        \"\"\"\n        if not 0 <= r <= 255:\n            raise ValueError(\"The value for red needs to be between 0 and 255.\")\n        if not 0 <= g <= 255:\n            raise ValueError(\"The value for green needs to be between 0 and 255.\")\n        if not 0 <= b <= 255:\n            raise ValueError(\"The value for blue needs to be between 0 and 255.\")\n\n        #print(BulbDevice)\n        hexvalue = BulbDevice._rgb_to_hexvalue(r, g, b)\n\n        payload = self.generate_payload(SET, {\n            self.DPS_INDEX_MODE: self.DPS_MODE_COLOUR,\n            self.DPS_INDEX_COLOUR: hexvalue})\n        data = self._send_receive(payload)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting white coloured theme of an rgb bulb.", "response": "def set_white(self, brightness, colourtemp):\n        \"\"\"\n        Set white coloured theme of an rgb bulb.\n\n        Args:\n            brightness(int): Value for the brightness (25-255).\n            colourtemp(int): Value for the colour temperature (0-255).\n        \"\"\"\n        if not 25 <= brightness <= 255:\n            raise ValueError(\"The brightness needs to be between 25 and 255.\")\n        if not 0 <= colourtemp <= 255:\n            raise ValueError(\"The colour temperature needs to be between 0 and 255.\")\n\n        payload = self.generate_payload(SET, {\n            self.DPS_INDEX_MODE: self.DPS_MODE_WHITE,\n            self.DPS_INDEX_BRIGHTNESS: brightness,\n            self.DPS_INDEX_COLOURTEMP: colourtemp})\n\n        data = self._send_receive(payload)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the brightness of an rgb bulb.", "response": "def set_brightness(self, brightness):\n        \"\"\"\n        Set the brightness value of an rgb bulb.\n\n        Args:\n            brightness(int): Value for the brightness (25-255).\n        \"\"\"\n        if not 25 <= brightness <= 255:\n            raise ValueError(\"The brightness needs to be between 25 and 255.\")\n\n        payload = self.generate_payload(SET, {self.DPS_INDEX_BRIGHTNESS: brightness})\n        data = self._send_receive(payload)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_colourtemp(self, colourtemp):\n        if not 0 <= colourtemp <= 255:\n            raise ValueError(\"The colour temperature needs to be between 0 and 255.\")\n\n        payload = self.generate_payload(SET, {self.DPS_INDEX_COLOURTEMP: colourtemp})\n        data = self._send_receive(payload)\n        return data", "response": "Set the colour temperature of an rgb bulb."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn colour as RGB value", "response": "def colour_rgb(self):\n        \"\"\"Return colour as RGB value\"\"\"\n        hexvalue = self.status()[self.DPS][self.DPS_INDEX_COLOUR]\n        return BulbDevice._hexvalue_to_rgb(hexvalue)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef colour_hsv(self):\n        hexvalue = self.status()[self.DPS][self.DPS_INDEX_COLOUR]\n        return BulbDevice._hexvalue_to_hsv(hexvalue)", "response": "Return colour as HSV value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the group mask that the Crazyflie belongs to.", "response": "def set_group_mask(self, group_mask=ALL_GROUPS):\n        \"\"\"\n        Set the group mask that the Crazyflie belongs to\n\n        :param group_mask: mask for which groups this CF belongs to\n        \"\"\"\n        self._send_packet(struct.pack('<BB',\n                                      self.COMMAND_SET_GROUP_MASK,\n                                      group_mask))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef takeoff(self, absolute_height_m, duration_s, group_mask=ALL_GROUPS):\n        self._send_packet(struct.pack('<BBff',\n                                      self.COMMAND_TAKEOFF,\n                                      group_mask,\n                                      absolute_height_m,\n                                      duration_s))", "response": "This method is used to takeoff the current vertical position to given height."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef land(self, absolute_height_m, duration_s, group_mask=ALL_GROUPS):\n        self._send_packet(struct.pack('<BBff',\n                                      self.COMMAND_LAND,\n                                      group_mask,\n                                      absolute_height_m,\n                                      duration_s))", "response": "This method is used to land the current x - y position to the given height."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop(self, group_mask=ALL_GROUPS):\n        self._send_packet(struct.pack('<BB',\n                                      self.COMMAND_STOP,\n                                      group_mask))", "response": "Stops the current trajectory"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef go_to(self, x, y, z, yaw, duration_s, relative=False,\n              group_mask=ALL_GROUPS):\n        \"\"\"\n        Go to an absolute or relative position\n\n        :param x: x (m)\n        :param y: y (m)\n        :param z: z (m)\n        :param yaw: yaw (radians)\n        :param duration_s: time it should take to reach the position (s)\n        :param relative: True if x, y, z is relative to the current position\n        :param group_mask: mask for which CFs this should apply to\n        \"\"\"\n        self._send_packet(struct.pack('<BBBfffff',\n                                      self.COMMAND_GO_TO,\n                                      group_mask,\n                                      relative,\n                                      x, y, z,\n                                      yaw,\n                                      duration_s))", "response": "Go to an absolute or relative position."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_trajectory(self, trajectory_id, time_scale=1.0, relative=False,\n                         reversed=False, group_mask=ALL_GROUPS):\n        \"\"\"\n        starts executing a specified trajectory\n\n        :param trajectory_id: id of the trajectory (previously defined by\n               define_trajectory)\n        :param time_scale: time factor; 1.0 = original speed;\n                                        >1.0: slower;\n                                        <1.0: faster\n        :param relative: set to True, if trajectory should be shifted to\n               current setpoint\n        :param reversed: set to True, if trajectory should be executed in\n               reverse\n        :param group_mask: mask for which CFs this should apply to\n        :return:\n        \"\"\"\n        self._send_packet(struct.pack('<BBBBBf',\n                                      self.COMMAND_START_TRAJECTORY,\n                                      group_mask,\n                                      relative,\n                                      reversed,\n                                      trajectory_id,\n                                      time_scale))", "response": "starts executing a specified trajectory"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndefine a trajectory that has previously been uploaded to memory.", "response": "def define_trajectory(self, trajectory_id, offset, n_pieces):\n        \"\"\"\n        Define a trajectory that has previously been uploaded to memory.\n\n        :param trajectory_id: The id of the trajectory\n        :param offset: offset in uploaded memory\n        :param n_pieces: Nr of pieces in the trajectory\n        :return:\n        \"\"\"\n        self._send_packet(struct.pack('<BBBBIB',\n                                      self.COMMAND_DEFINE_TRAJECTORY,\n                                      trajectory_id,\n                                      self.TRAJECTORY_LOCATION_MEM,\n                                      self.TRAJECTORY_TYPE_POLY4D,\n                                      offset,\n                                      n_pieces))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef choose(items, title_text, question_text):\n    print(title_text)\n\n    for i, item in enumerate(items, start=1):\n        print('%d) %s' % (i, item))\n    print('%d) Abort' % (i + 1))\n\n    selected = input(question_text)\n    try:\n        index = int(selected)\n    except ValueError:\n        index = -1\n    if not (index - 1) in range(len(items)):\n        print('Aborting.')\n        return None\n\n    return items[index - 1]", "response": "Interactively choose one of the items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscan for Crazyflie and return its URI.", "response": "def scan():\n    \"\"\"\n    Scan for Crazyflie and return its URI.\n    \"\"\"\n\n    # Initiate the low level drivers\n    cflib.crtp.init_drivers(enable_debug_driver=False)\n\n    # Scan for Crazyflies\n    print('Scanning interfaces for Crazyflies...')\n    available = cflib.crtp.scan_interfaces()\n    interfaces = [uri for uri, _ in available]\n\n    if not interfaces:\n        return None\n    return choose(interfaces, 'Crazyflies found:', 'Select interface: ')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconnecting to the crazyflie.", "response": "def connect(self):\n        \"\"\"\n        Connect to the crazyflie.\n        \"\"\"\n        print('Connecting to %s' % self._link_uri)\n        self._cf.open_link(self._link_uri)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_for_connection(self, timeout=10):\n        start_time = datetime.datetime.now()\n        while True:\n            if self.connected:\n                return True\n            now = datetime.datetime.now()\n            if (now - start_time).total_seconds() > timeout:\n                return False\n            time.sleep(0.5)", "response": "Busy loop until connection is established."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_memories(self):\n        if not self.connected:\n            raise NotConnected()\n        return self._cf.mem.get_mems(MemoryElement.TYPE_1W)", "response": "Search and return list of 1 - wire memories."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _stab_log_data(self, timestamp, data, logconf):\n        print('[%d][%s]: %s' % (timestamp, logconf.name, data))", "response": "Callback froma the log API when data arrives"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _connection_failed(self, link_uri, msg):\n        print('Connection to %s failed: %s' % (link_uri, msg))\n        self.is_connected = False", "response": "Callback when the connection to the Crazyflie has failed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_platform_informations(self, callback):\n\n        self._protocolVersion = -1\n        self._callback = callback\n\n        self._request_protocol_version()", "response": "Fetch platform info from the firmware"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nenabling or disable the client side X - mode.", "response": "def set_continous_wave(self, enabled):\n        \"\"\"\n        Enable/disable the client side X-mode. When enabled this recalculates\n        the setpoints before sending them to the Crazyflie.\n        \"\"\"\n        pk = CRTPPacket()\n        pk.set_header(CRTPPort.PLATFORM, PLATFORM_COMMAND)\n        pk.data = (0, enabled)\n        self._cf.send_packet(pk)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(self, uri, link_quality_callback, link_error_callback):\n\n        # check if the URI is a radio URI\n        if not re.search('^usb://', uri):\n            raise WrongUriType('Not a radio URI')\n\n        # Open the USB dongle\n        if not re.search('^usb://([0-9]+)$',\n                         uri):\n            raise WrongUriType('Wrong radio URI format!')\n\n        uri_data = re.search('^usb://([0-9]+)$',\n                             uri)\n\n        self.uri = uri\n\n        if self.cfusb is None:\n            self.cfusb = CfUsb(devid=int(uri_data.group(1)))\n            if self.cfusb.dev:\n                self.cfusb.set_crtp_to_usb(True)\n            else:\n                self.cfusb = None\n                raise Exception('Could not open {}'.format(self.uri))\n\n        else:\n            raise Exception('Link already open!')\n\n        # Prepare the inter-thread communication queue\n        self.in_queue = queue.Queue()\n        # Limited size out queue to avoid \"ReadBack\" effect\n        self.out_queue = queue.Queue(50)\n\n        # Launch the comm thread\n        self._thread = _UsbReceiveThread(self.cfusb, self.in_queue,\n                                         link_quality_callback,\n                                         link_error_callback)\n        self._thread.start()\n\n        self.link_error_callback = link_error_callback", "response": "Connects the link driver to a specified URI."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreceives a packet from the link.", "response": "def receive_packet(self, time=0):\n        \"\"\"\n        Receive a packet though the link. This call is blocking but will\n        timeout and return None if a timeout is supplied.\n        \"\"\"\n        if time == 0:\n            try:\n                return self.in_queue.get(False)\n            except queue.Empty:\n                return None\n        elif time < 0:\n            try:\n                return self.in_queue.get(True)\n            except queue.Empty:\n                return None\n        else:\n            try:\n                return self.in_queue.get(True, time)\n            except queue.Empty:\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends the packet pk though the link", "response": "def send_packet(self, pk):\n        \"\"\" Send the packet pk though the link \"\"\"\n        # if self.out_queue.full():\n        #    self.out_queue.get()\n        if (self.cfusb is None):\n            return\n\n        try:\n            dataOut = (pk.header,)\n            dataOut += pk.datat\n            self.cfusb.send_packet(dataOut)\n        except queue.Full:\n            if self.link_error_callback:\n                self.link_error_callback(\n                    'UsbDriver: Could not send packet to Crazyflie')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scan_interface(self, address):\n        if self.cfusb is None:\n            try:\n                self.cfusb = CfUsb()\n            except Exception as e:\n                logger.warn(\n                    'Exception while scanning for Crazyflie USB: {}'.format(\n                        str(e)))\n                return []\n        else:\n            raise Exception('Cannot scan for links while the link is open!')\n\n        # FIXME: implements serial number in the Crazyradio driver!\n        # serial = \"N/A\"\n\n        found = self.cfusb.scan()\n\n        self.cfusb.close()\n        self.cfusb = None\n\n        return found", "response": "Scan for Crazyflies in the USB device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the receiver thread", "response": "def run(self):\n        \"\"\" Run the receiver thread \"\"\"\n\n        while (True):\n            if (self.sp):\n                break\n            try:\n                # Blocking until USB data available\n                data = self.cfusb.receive_packet()\n                if len(data) > 0:\n                    pk = CRTPPacket(data[0], list(data[1:]))\n                    self.in_queue.put(pk)\n            except Exception as e:\n                import traceback\n\n                self.link_error_callback(\n                    'Error communicating with the Crazyflie'\n                    ' ,it has probably been unplugged!\\n'\n                    'Exception:%s\\n\\n%s' % (e,\n                                            traceback.format_exc()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _connected(self, link_uri):\n        print('Connected to %s' % link_uri)\n\n        mems = self._cf.mem.get_mems(MemoryElement.TYPE_1W)\n        self._mems_to_update = len(mems)\n        print('Found {} 1-wire memories'.format(len(mems)))\n        for m in mems:\n            print('Updating id={}'.format(m.id))\n            m.update(self._data_updated)", "response": "This callback is called by the Crazyflie API when a Crazyflie API has been connected to a Crazyflie link URI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_callback(self, cb):\n        if ((cb in self.callbacks) is False):\n            self.callbacks.append(cb)", "response": "Register cb as a new callback. Will not register duplicates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _connected(self, link_uri):\n        print('Connected to %s' % link_uri)\n        self._is_link_open = True\n        self._connect_event.set()", "response": "This callback is called when a Crazyflie API has been successfully connected to a Crazyflie link URI."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a flash page from the specified target", "response": "def read_cf1_config(self):\n        \"\"\"Read a flash page from the specified target\"\"\"\n        target = self._cload.targets[0xFF]\n        config_page = target.flash_pages - 1\n\n        return self._cload.read_flash(addr=0xFF, page=config_page)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_devices(serial=None):\n    ret = []\n\n    if pyusb1:\n        for d in usb.core.find(idVendor=0x1915, idProduct=0x7777, find_all=1,\n                               backend=pyusb_backend):\n            if serial is not None and serial == d.serial_number:\n                return d\n            ret.append(d)\n    else:\n        busses = usb.busses()\n        for bus in busses:\n            for device in bus.devices:\n                if device.idVendor == CRADIO_VID:\n                    if device.idProduct == CRADIO_PID:\n                        if serial == device.serial_number:\n                            return device\n                        ret += [device, ]\n\n    return ret", "response": "Returns a list of CrazyRadio devices currently connected to the computer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_channel(self, channel):\n        if channel != self.current_channel:\n            _send_vendor_setup(self.handle, SET_RADIO_CHANNEL, channel, 0, ())\n            self.current_channel = channel", "response": "Set the radio channel to be used"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the radio address to be used", "response": "def set_address(self, address):\n        \"\"\" Set the radio address to be used\"\"\"\n        if len(address) != 5:\n            raise Exception('Crazyradio: the radio address shall be 5'\n                            ' bytes long')\n        if address != self.current_address:\n            _send_vendor_setup(self.handle, SET_RADIO_ADDRESS, 0, 0, address)\n            self.current_address = address"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_data_rate(self, datarate):\n        if datarate != self.current_datarate:\n            _send_vendor_setup(self.handle, SET_DATA_RATE, datarate, 0, ())\n            self.current_datarate = datarate", "response": "Set the radio datarate to be used"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the ACK retry count for radio communication", "response": "def set_arc(self, arc):\n        \"\"\" Set the ACK retry count for radio communication \"\"\"\n        _send_vendor_setup(self.handle, SET_RADIO_ARC, arc, 0, ())\n        self.arc = arc"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the ACK retry delay for radio communication", "response": "def set_ard_time(self, us):\n        \"\"\" Set the ACK retry delay for radio communication \"\"\"\n        # Auto Retransmit Delay:\n        # 0000 - Wait 250uS\n        # 0001 - Wait 500uS\n        # 0010 - Wait 750uS\n        # ........\n        # 1111 - Wait 4000uS\n\n        # Round down, to value representing a multiple of 250uS\n        t = int((us / 250) - 1)\n        if (t < 0):\n            t = 0\n        if (t > 0xF):\n            t = 0xF\n        _send_vendor_setup(self.handle, SET_RADIO_ARD, t, 0, ())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_packet(self, dataOut):\n        ackIn = None\n        data = None\n        try:\n            if (pyusb1 is False):\n                self.handle.bulkWrite(1, dataOut, 1000)\n                data = self.handle.bulkRead(0x81, 64, 1000)\n            else:\n                self.handle.write(endpoint=1, data=dataOut, timeout=1000)\n                data = self.handle.read(0x81, 64, timeout=1000)\n        except usb.USBError:\n            pass\n\n        if data is not None:\n            ackIn = _radio_ack()\n            if data[0] != 0:\n                ackIn.ack = (data[0] & 0x01) != 0\n                ackIn.powerDet = (data[0] & 0x02) != 0\n                ackIn.retry = data[0] >> 4\n                ackIn.data = data[1:]\n            else:\n                ackIn.retry = self.arc\n\n        return ackIn", "response": "Send a packet and receive the ack from the radio dongle\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends the current X Y Z position to the Crazyflie s position estimator.", "response": "def send_extpos(self, x, y, z):\n        \"\"\"\n        Send the current Crazyflie X, Y, Z position. This is going to be\n        forwarded to the Crazyflie's position estimator.\n        \"\"\"\n\n        self._cf.loc.send_extpos([x, y, z])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch(self, crc):\n        cache_data = None\n        pattern = '%08X.json' % crc\n        hit = None\n\n        for name in self._cache_files:\n            if (name.endswith(pattern)):\n                hit = name\n\n        if (hit):\n            try:\n                cache = open(hit)\n                cache_data = json.load(cache,\n                                       object_hook=self._decoder)\n                cache.close()\n            except Exception as exp:\n                logger.warning('Error while parsing cache file [%s]:%s',\n                               hit, str(exp))\n\n        return cache_data", "response": "Try to get a hit in the cache return None otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves a new cache to file", "response": "def insert(self, crc, toc):\n        \"\"\" Save a new cache to file \"\"\"\n        if self._rw_cache:\n            try:\n                filename = '%s/%08X.json' % (self._rw_cache, crc)\n                cache = open(filename, 'w')\n                cache.write(json.dumps(toc, indent=2,\n                                       default=self._encoder))\n                cache.close()\n                logger.info('Saved cache to [%s]', filename)\n                self._cache_files += [filename]\n            except Exception as exp:\n                logger.warning('Could not save cache to file [%s]: %s',\n                               filename, str(exp))\n        else:\n            logger.warning('Could not save cache, no writable directory')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _encoder(self, obj):\n        return {'__class__': obj.__class__.__name__,\n                'ident': obj.ident,\n                'group': obj.group,\n                'name': obj.name,\n                'ctype': obj.ctype,\n                'pytype': obj.pytype,\n                'access': obj.access}\n        raise TypeError(repr(obj) + ' is not JSON serializable')", "response": "Encode a toc element leaf - node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode a toc element leaf - node", "response": "def _decoder(self, obj):\n        \"\"\" Decode a toc element leaf-node \"\"\"\n        if '__class__' in obj:\n            elem = eval(obj['__class__'])()\n            elem.ident = obj['ident']\n            elem.group = str(obj['group'])\n            elem.name = str(obj['name'])\n            elem.ctype = str(obj['ctype'])\n            elem.pytype = str(obj['pytype'])\n            elem.access = obj['access']\n            return elem\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_position(self, anchor_id, position):\n        x = position[0]\n        y = position[1]\n        z = position[2]\n        data = struct.pack('<Bfff', LoPoAnchor.LPP_TYPE_POSITION, x, y, z)\n\n        self.crazyflie.loc.send_short_lpp_packet(anchor_id, data)", "response": "Send a packet with a position to one anchor."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_mode(self, anchor_id, mode):\n        data = struct.pack('<BB', LoPoAnchor.LPP_TYPE_MODE, mode)\n        self.crazyflie.loc.send_short_lpp_packet(anchor_id, data)", "response": "Send a packet to change the anchor mode."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_links(self):\n        if self._is_open:\n            raise Exception('Already opened')\n\n        try:\n            self.parallel_safe(lambda scf: scf.open_link())\n            self._is_open = True\n        except Exception as e:\n            self.close_links()\n            raise e", "response": "Open links to all individuals in the swarm"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close_links(self):\n        for uri, cf in self._cfs.items():\n            cf.close_link()\n\n        self._is_open = False", "response": "Close all open links"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a function for all Crazyflies in the swarm in sequence.", "response": "def sequential(self, func, args_dict=None):\n        \"\"\"\n        Execute a function for all Crazyflies in the swarm, in sequence.\n\n        The first argument of the function that is passed in will be a\n        SyncCrazyflie instance connected to the Crazyflie to operate on.\n        A list of optional parameters (per Crazyflie) may follow defined by\n        the args_dict. The dictionary is keyed on URI.\n\n        Example:\n        def my_function(scf, optional_param0, optional_param1)\n            ...\n\n        args_dict = {\n            URI0: [optional_param0_cf0, optional_param1_cf0],\n            URI1: [optional_param0_cf1, optional_param1_cf1],\n            ...\n        }\n\n\n        self.sequential(my_function, args_dict)\n\n        :param func: the function to execute\n        :param args_dict: parameters to pass to the function\n        \"\"\"\n        for uri, cf in self._cfs.items():\n            args = self._process_args_dict(cf, uri, args_dict)\n            func(*args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parallel_safe(self, func, args_dict=None):\n        threads = []\n        reporter = self.Reporter()\n\n        for uri, scf in self._cfs.items():\n            args = [func, reporter] + \\\n                self._process_args_dict(scf, uri, args_dict)\n\n            thread = Thread(target=self._thread_function_wrapper, args=args)\n            threads.append(thread)\n            thread.start()\n\n        for thread in threads:\n            thread.join()\n\n        if reporter.is_error_reported():\n            raise Exception('One or more threads raised an exception when '\n                            'executing parallel task')", "response": "Execute a function for all Crazyflies in the swarm in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef take_off(self, height=DEFAULT, velocity=DEFAULT):\n        if self._is_flying:\n            raise Exception('Already flying')\n\n        if not self._cf.is_connected():\n            raise Exception('Crazyflie is not connected')\n\n        self._is_flying = True\n        self._reset_position_estimator()\n        self._activate_controller()\n        self._activate_high_level_commander()\n        self._hl_commander = self._cf.high_level_commander\n\n        height = self._height(height)\n\n        duration_s = height / self._velocity(velocity)\n        self._hl_commander.takeoff(height, duration_s)\n        time.sleep(duration_s)\n        self._z = height", "response": "Take off the motors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngoing straight down and turn off motors.", "response": "def land(self, velocity=DEFAULT):\n        \"\"\"\n        Go straight down and turn off the motors.\n\n        Do not call this function if you use the with keyword. Landing is\n        done automatically when the context goes out of scope.\n\n        :param velocity: The velocity (meters/second) when going down\n        :return:\n        \"\"\"\n        if self._is_flying:\n            duration_s = self._z / self._velocity(velocity)\n            self._hl_commander.land(0, duration_s)\n            time.sleep(duration_s)\n            self._z = 0.0\n\n            self._hl_commander.stop()\n            self._is_flying = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove the log entry in a straight line.", "response": "def move_distance(self, distance_x_m, distance_y_m, distance_z_m,\n                      velocity=DEFAULT):\n        \"\"\"\n        Move in a straight line.\n        positive X is forward\n        positive Y is left\n        positive Z is up\n\n        :param distance_x_m: The distance to travel along the X-axis (meters)\n        :param distance_y_m: The distance to travel along the Y-axis (meters)\n        :param distance_z_m: The distance to travel along the Z-axis (meters)\n        :param velocity: the velocity of the motion (meters/second)\n        :return:\n        \"\"\"\n\n        x = self._x + distance_x_m\n        y = self._y + distance_y_m\n        z = self._z + distance_z_m\n\n        self.go_to(x, y, z, velocity)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngoes to a position", "response": "def go_to(self, x, y, z=DEFAULT, velocity=DEFAULT):\n        \"\"\"\n        Go to a position\n\n        :param x: X coordinate\n        :param y: Y coordinate\n        :param z: Z coordinate\n        :param velocity: the velocity (meters/second)\n        :return:\n        \"\"\"\n\n        z = self._height(z)\n\n        dx = x - self._x\n        dy = y - self._y\n        dz = z - self._z\n        distance = math.sqrt(dx * dx + dy * dy + dz * dz)\n\n        duration_s = distance / self._velocity(velocity)\n        self._hl_commander.go_to(x, y, z, 0, duration_s)\n        time.sleep(duration_s)\n\n        self._x = x\n        self._y = y\n        self._z = z"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrequests an update of all the parameters in the TOC", "response": "def request_update_of_all_params(self):\n        \"\"\"Request an update of all the parameters in the TOC\"\"\"\n        for group in self.toc.toc:\n            for name in self.toc.toc[group]:\n                complete_name = '%s.%s' % (group, name)\n                self.request_param_update(complete_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_if_all_updated(self):\n        for g in self.toc.toc:\n            if g not in self.values:\n                return False\n            for n in self.toc.toc[g]:\n                if n not in self.values[g]:\n                    return False\n\n        return True", "response": "Check if all parameters from the TOC have at least been fetched\n        once"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving the supplied callback for a group or a name", "response": "def remove_update_callback(self, group, name=None, cb=None):\n        \"\"\"Remove the supplied callback for a group or a group.name\"\"\"\n        if not cb:\n            return\n\n        if not name:\n            if group in self.group_update_callbacks:\n                self.group_update_callbacks[group].remove_callback(cb)\n        else:\n            paramname = '{}.{}'.format(group, name)\n            if paramname in self.param_update_callbacks:\n                self.param_update_callbacks[paramname].remove_callback(cb)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a callback for a specific parameter name. This callback will be executed when a new value is read from the Crazyflie.", "response": "def add_update_callback(self, group=None, name=None, cb=None):\n        \"\"\"\n        Add a callback for a specific parameter name. This callback will be\n        executed when a new value is read from the Crazyflie.\n        \"\"\"\n        if not group and not name:\n            self.all_update_callback.add_callback(cb)\n        elif not name:\n            if group not in self.group_update_callbacks:\n                self.group_update_callbacks[group] = Caller()\n            self.group_update_callbacks[group].add_callback(cb)\n        else:\n            paramname = '{}.{}'.format(group, name)\n            if paramname not in self.param_update_callbacks:\n                self.param_update_callbacks[paramname] = Caller()\n            self.param_update_callbacks[paramname].add_callback(cb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh_toc(self, refresh_done_callback, toc_cache):\n        self._useV2 = self.cf.platform.get_protocol_version() >= 4\n        toc_fetcher = TocFetcher(self.cf, ParamTocElement,\n                                 CRTPPort.PARAM, self.toc,\n                                 refresh_done_callback, toc_cache)\n        toc_fetcher.start()", "response": "Refresh the parameter TOC."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _disconnected(self, uri):\n        self.param_updater.close()\n        self.is_updated = False\n        # Clear all values from the previous Crazyflie\n        self.toc = Toc()\n        self.values = {}", "response": "Disconnect callback from Crazyflie API"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request_param_update(self, complete_name):\n        self.param_updater.request_param_update(\n            self.toc.get_element_id(complete_name))", "response": "Request an update of the value of the supplied parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_value(self, complete_name, value):\n        element = self.toc.get_element_by_complete_name(complete_name)\n\n        if not element:\n            logger.warning(\"Cannot set value for [%s], it's not in the TOC!\",\n                           complete_name)\n            raise KeyError('{} not in param TOC'.format(complete_name))\n        elif element.access == ParamTocElement.RO_ACCESS:\n            logger.debug('[%s] is read only, no trying to set value',\n                         complete_name)\n            raise AttributeError('{} is read-only!'.format(complete_name))\n        else:\n            varid = element.ident\n            pk = CRTPPacket()\n            pk.set_header(CRTPPort.PARAM, WRITE_CHANNEL)\n            if self._useV2:\n                pk.data = struct.pack('<H', varid)\n            else:\n                pk.data = struct.pack('<B', varid)\n\n            try:\n                value_nr = eval(value)\n            except TypeError:\n                value_nr = value\n\n            pk.data += struct.pack(element.pytype, value_nr)\n            self.param_updater.request_param_setvalue(pk)", "response": "Set the value for the supplied parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _new_packet_cb(self, pk):\n        if pk.channel == READ_CHANNEL or pk.channel == WRITE_CHANNEL:\n            if self._useV2:\n                var_id = struct.unpack('<H', pk.data[:2])[0]\n                if pk.channel == READ_CHANNEL:\n                    pk.data = pk.data[:2] + pk.data[3:]\n            else:\n                var_id = pk.data[0]\n            if (pk.channel != TOC_CHANNEL and self._req_param == var_id and\n                    pk is not None):\n                self.updated_callback(pk)\n                self._req_param = -1\n                try:\n                    self.wait_lock.release()\n                except Exception:\n                    pass", "response": "Callback for newly arrived packets"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request_param_update(self, var_id):\n        self._useV2 = self.cf.platform.get_protocol_version() >= 4\n        pk = CRTPPacket()\n        pk.set_header(CRTPPort.PARAM, READ_CHANNEL)\n        if self._useV2:\n            pk.data = struct.pack('<H', var_id)\n        else:\n            pk.data = struct.pack('<B', var_id)\n        logger.debug('Requesting request to update param [%d]', var_id)\n        self.request_queue.put(pk)", "response": "Place a param update request on the queue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new TocElement to the TOC container.", "response": "def add_element(self, element):\n        \"\"\"Add a new TocElement to the TOC container.\"\"\"\n        try:\n            self.toc[element.group][element.name] = element\n        except KeyError:\n            self.toc[element.group] = {}\n            self.toc[element.group][element.name] = element"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_element_id(self, complete_name):\n        [group, name] = complete_name.split('.')\n        element = self.get_element(group, name)\n        if element:\n            return element.ident\n        else:\n            logger.warning('Unable to find variable [%s]', complete_name)\n            return None", "response": "Get the TocElement element id - number of the element with the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_element_by_id(self, ident):\n        for group in list(self.toc.keys()):\n            for name in list(self.toc[group].keys()):\n                if self.toc[group][name].ident == ident:\n                    return self.toc[group][name]\n        return None", "response": "Get a TocElement element identified by index number from the TocElement container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n        self._useV2 = self.cf.platform.get_protocol_version() >= 4\n\n        logger.debug('[%d]: Using V2 protocol: %d', self.port, self._useV2)\n\n        logger.debug('[%d]: Start fetching...', self.port)\n        # Register callback in this class for the port\n        self.cf.add_port_callback(self.port, self._new_packet_cb)\n\n        # Request the TOC CRC\n        self.state = GET_TOC_INFO\n        pk = CRTPPacket()\n        pk.set_header(self.port, TOC_CHANNEL)\n        if self._useV2:\n            pk.data = (CMD_TOC_INFO_V2,)\n            self.cf.send_packet(pk, expected_reply=(CMD_TOC_INFO_V2,))\n        else:\n            pk.data = (CMD_TOC_INFO,)\n            self.cf.send_packet(pk, expected_reply=(CMD_TOC_INFO,))", "response": "Initiate fetching of the TOC."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _toc_fetch_finished(self):\n        self.cf.remove_port_callback(self.port, self._new_packet_cb)\n        logger.debug('[%d]: Done!', self.port)\n        self.finished_callback()", "response": "Callback for when the TOC fetching is finished"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles a newly arrived packet.", "response": "def _new_packet_cb(self, packet):\n        \"\"\"Handle a newly arrived packet\"\"\"\n        chan = packet.channel\n        if (chan != 0):\n            return\n        payload = packet.data[1:]\n\n        if (self.state == GET_TOC_INFO):\n            if self._useV2:\n                [self.nbr_of_items, self._crc] = struct.unpack(\n                    '<HI', payload[:6])\n            else:\n                [self.nbr_of_items, self._crc] = struct.unpack(\n                    '<BI', payload[:5])\n            logger.debug('[%d]: Got TOC CRC, %d items and crc=0x%08X',\n                         self.port, self.nbr_of_items, self._crc)\n\n            cache_data = self._toc_cache.fetch(self._crc)\n            if (cache_data):\n                self.toc.toc = cache_data\n                logger.info('TOC for port [%s] found in cache' % self.port)\n                self._toc_fetch_finished()\n            else:\n                self.state = GET_TOC_ELEMENT\n                self.requested_index = 0\n                self._request_toc_element(self.requested_index)\n\n        elif (self.state == GET_TOC_ELEMENT):\n            # Always add new element, but only request new if it's not the\n            # last one.\n            if self._useV2:\n                ident = struct.unpack('<H', payload[:2])[0]\n            else:\n                ident = payload[0]\n\n            if ident != self.requested_index:\n                return\n            if self._useV2:\n                self.toc.add_element(self.element_class(ident, payload[2:]))\n            else:\n                self.toc.add_element(self.element_class(ident, payload[1:]))\n            logger.debug('Added element [%s]', ident)\n            if (self.requested_index < (self.nbr_of_items - 1)):\n                logger.debug('[%d]: More variables, requesting index %d',\n                             self.port, self.requested_index + 1)\n                self.requested_index = self.requested_index + 1\n                self._request_toc_element(self.requested_index)\n            else:  # No more variables in TOC\n                self._toc_cache.insert(self._crc, self.toc.toc)\n                self._toc_fetch_finished()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _request_toc_element(self, index):\n        logger.debug('Requesting index %d on port %d', index, self.port)\n        pk = CRTPPacket()\n        if self._useV2:\n            pk.set_header(self.port, TOC_CHANNEL)\n            pk.data = (CMD_TOC_ITEM_V2, index & 0x0ff, (index >> 8) & 0x0ff)\n            self.cf.send_packet(pk, expected_reply=(\n                CMD_TOC_ITEM_V2, index & 0x0ff, (index >> 8) & 0x0ff))\n        else:\n            pk.set_header(self.port, TOC_CHANNEL)\n            pk.data = (CMD_TOC_ELEMENT, index)\n            self.cf.send_packet(pk, expected_reply=(CMD_TOC_ELEMENT, index))", "response": "Request information about a specific item in the TOC."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _start_connection_setup(self):\n        logger.info('We are connected[%s], request connection setup',\n                    self.link_uri)\n        self.platform.fetch_platform_informations(self._platform_info_fetched)", "response": "Start the connection setup by refreshing the TOCs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when the param TOC has been fully updated", "response": "def _param_toc_updated_cb(self):\n        \"\"\"Called when the param TOC has been fully updated\"\"\"\n        logger.info('Param TOC finished updating')\n        self.connected_ts = datetime.datetime.now()\n        self.connected.call(self.link_uri)\n        # Trigger the update for all the parameters\n        self.param.request_update_of_all_params()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mems_updated_cb(self):\n        logger.info('Memories finished updating')\n        self.param.refresh_toc(self._param_toc_updated_cb, self._toc_cache)", "response": "Called when the memories have been identified"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _link_error_cb(self, errmsg):\n        logger.warning('Got link error callback [%s] in state [%s]',\n                       errmsg, self.state)\n        if (self.link is not None):\n            self.link.close()\n        self.link = None\n        if (self.state == State.INITIALIZED):\n            self.connection_failed.call(self.link_uri, errmsg)\n        if (self.state == State.CONNECTED or\n                self.state == State.SETUP_FINISHED):\n            self.disconnected.call(self.link_uri)\n            self.connection_lost.call(self.link_uri, errmsg)\n        self.state = State.DISCONNECTED", "response": "Called from the link driver when there s an error"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when the initial packet arrives from Crazyflie.", "response": "def _check_for_initial_packet_cb(self, data):\n        \"\"\"\n        Called when first packet arrives from Crazyflie.\n\n        This is used to determine if we are connected to something that is\n        answering.\n        \"\"\"\n        self.state = State.CONNECTED\n        self.link_established.call(self.link_uri)\n        self.packet_received.remove_callback(self._check_for_initial_packet_cb)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the communication link to a copter at the given URI and setup the communication link connection.", "response": "def open_link(self, link_uri):\n        \"\"\"\n        Open the communication link to a copter at the given URI and setup the\n        connection (download log/parameter TOC).\n        \"\"\"\n        self.connection_requested.call(link_uri)\n        self.state = State.INITIALIZED\n        self.link_uri = link_uri\n        try:\n            self.link = cflib.crtp.get_link_driver(\n                link_uri, self._link_quality_cb, self._link_error_cb)\n\n            if not self.link:\n                message = 'No driver found or malformed URI: {}' \\\n                    .format(link_uri)\n                logger.warning(message)\n                self.connection_failed.call(link_uri, message)\n            else:\n                # Add a callback so we can check that any data is coming\n                # back from the copter\n                self.packet_received.add_callback(\n                    self._check_for_initial_packet_cb)\n\n                self._start_connection_setup()\n        except Exception as ex:  # pylint: disable=W0703\n            # We want to catch every possible exception here and show\n            # it in the user interface\n            import traceback\n\n            logger.error(\"Couldn't load link driver: %s\\n\\n%s\",\n                         ex, traceback.format_exc())\n            exception_text = \"Couldn't load link driver: %s\\n\\n%s\" % (\n                ex, traceback.format_exc())\n            if self.link:\n                self.link.close()\n                self.link = None\n            self.connection_failed.call(link_uri, exception_text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the communication link.", "response": "def close_link(self):\n        \"\"\"Close the communication link.\"\"\"\n        logger.info('Closing link')\n        if (self.link is not None):\n            self.commander.send_setpoint(0, 0, 0, 0)\n        if (self.link is not None):\n            self.link.close()\n            self.link = None\n        self._answer_patterns = {}\n        self.disconnected.call(self.link_uri)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend packets that we have not gotten answers to", "response": "def _no_answer_do_retry(self, pk, pattern):\n        \"\"\"Resend packets that we have not gotten answers to\"\"\"\n        logger.info('Resending for pattern %s', pattern)\n        # Set the timer to None before trying to send again\n        self.send_packet(pk, expected_reply=pattern, resend=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_packet(self, pk, expected_reply=(), resend=False, timeout=0.2):\n        self._send_lock.acquire()\n        if self.link is not None:\n            if len(expected_reply) > 0 and not resend and \\\n                    self.link.needs_resending:\n                pattern = (pk.header,) + expected_reply\n                logger.debug(\n                    'Sending packet and expecting the %s pattern back',\n                    pattern)\n                new_timer = Timer(timeout,\n                                  lambda: self._no_answer_do_retry(pk,\n                                                                   pattern))\n                self._answer_patterns[pattern] = new_timer\n                new_timer.start()\n            elif resend:\n                # Check if we have gotten an answer, if not try again\n                pattern = expected_reply\n                if pattern in self._answer_patterns:\n                    logger.debug('We want to resend and the pattern is there')\n                    if self._answer_patterns[pattern]:\n                        new_timer = Timer(timeout,\n                                          lambda:\n                                          self._no_answer_do_retry(\n                                              pk, pattern))\n                        self._answer_patterns[pattern] = new_timer\n                        new_timer.start()\n                else:\n                    logger.debug('Resend requested, but no pattern found: %s',\n                                 self._answer_patterns)\n            self.link.send_packet(pk)\n            self.packet_sent.call(pk)\n        self._send_lock.release()", "response": "Send a packet through the link interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a callback for data that comes on a specific port", "response": "def add_port_callback(self, port, cb):\n        \"\"\"Add a callback for data that comes on a specific port\"\"\"\n        logger.debug('Adding callback on port [%d] to [%s]', port, cb)\n        self.add_header_callback(cb, port, 0, 0xff, 0x0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a callback for data that comes on a specific port", "response": "def remove_port_callback(self, port, cb):\n        \"\"\"Remove a callback for data that comes on a specific port\"\"\"\n        logger.debug('Removing callback on port [%d] to [%s]', port, cb)\n        for port_callback in self.cb:\n            if port_callback.port == port and port_callback.callback == cb:\n                self.cb.remove(port_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_header_callback(self, cb, port, channel, port_mask=0xFF,\n                            channel_mask=0xFF):\n        \"\"\"\n        Add a callback for a specific port/header callback with the\n        possibility to add a mask for channel and port for multiple\n        hits for same callback.\n        \"\"\"\n        self.cb.append(_CallbackContainer(port, port_mask,\n                                          channel, channel_mask, cb))", "response": "Add a callback for a specific port and channel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new variable to the configuration.", "response": "def add_variable(self, name, fetch_as=None):\n        \"\"\"Add a new variable to the configuration.\n\n        name - Complete name of the variable in the form group.name\n        fetch_as - String representation of the type the variable should be\n                   fetched as (i.e uint8_t, float, FP16, etc)\n\n        If no fetch_as type is supplied, then the stored as type will be used\n        (i.e the type of the fetched variable is the same as it's stored in the\n        Crazyflie).\"\"\"\n        if fetch_as:\n            self.variables.append(LogVariable(name, fetch_as))\n        else:\n            # We cannot determine the default type until we have connected. So\n            # save the name and we will add these once we are connected.\n            self.default_fetch_as.append(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_memory(self, name, fetch_as, stored_as, address):\n        self.variables.append(LogVariable(name, fetch_as, LogVariable.MEM_TYPE,\n                                          stored_as, address))", "response": "Add a raw memory position to the log."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the log configuration in the Crazyflie.", "response": "def create(self):\n        \"\"\"Save the log configuration in the Crazyflie\"\"\"\n        pk = CRTPPacket()\n        pk.set_header(5, CHAN_SETTINGS)\n        if self.useV2:\n            pk.data = (CMD_CREATE_BLOCK_V2, self.id)\n        else:\n            pk.data = (CMD_CREATE_BLOCK, self.id)\n        for var in self.variables:\n            if (var.is_toc_variable() is False):  # Memory location\n                logger.debug('Logging to raw memory %d, 0x%04X',\n                             var.get_storage_and_fetch_byte(), var.address)\n                pk.data.append(struct.pack('<B',\n                                           var.get_storage_and_fetch_byte()))\n                pk.data.append(struct.pack('<I', var.address))\n            else:  # Item in TOC\n                logger.debug('Adding %s with id=%d and type=0x%02X',\n                             var.name,\n                             self.cf.log.toc.get_element_id(\n                                 var.name), var.get_storage_and_fetch_byte())\n                pk.data.append(var.get_storage_and_fetch_byte())\n                if self.useV2:\n                    ident = self.cf.log.toc.get_element_id(var.name)\n                    pk.data.append(ident & 0x0ff)\n                    pk.data.append((ident >> 8) & 0x0ff)\n                else:\n                    pk.data.append(self.cf.log.toc.get_element_id(var.name))\n        logger.debug('Adding log block id {}'.format(self.id))\n        if self.useV2:\n            self.cf.send_packet(pk, expected_reply=(\n                CMD_CREATE_BLOCK_V2, self.id))\n        else:\n            self.cf.send_packet(pk, expected_reply=(CMD_CREATE_BLOCK, self.id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the logging for this entry", "response": "def start(self):\n        \"\"\"Start the logging for this entry\"\"\"\n        if (self.cf.link is not None):\n            if (self._added is False):\n                self.create()\n                logger.debug('First time block is started, add block')\n            else:\n                logger.debug('Block already registered, starting logging'\n                             ' for id=%d', self.id)\n                pk = CRTPPacket()\n                pk.set_header(5, CHAN_SETTINGS)\n                pk.data = (CMD_START_LOGGING, self.id, self.period)\n                self.cf.send_packet(pk, expected_reply=(\n                    CMD_START_LOGGING, self.id))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop(self):\n        if (self.cf.link is not None):\n            if (self.id is None):\n                logger.warning('Stopping block, but no block registered')\n            else:\n                logger.debug('Sending stop logging for block id=%d', self.id)\n                pk = CRTPPacket()\n                pk.set_header(5, CHAN_SETTINGS)\n                pk.data = (CMD_STOP_LOGGING, self.id)\n                self.cf.send_packet(\n                    pk, expected_reply=(CMD_STOP_LOGGING, self.id))", "response": "Stop the logging for this entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n        if (self.cf.link is not None):\n            if (self.id is None):\n                logger.warning('Delete block, but no block registered')\n            else:\n                logger.debug('LogEntry: Sending delete logging for block id=%d'\n                             % self.id)\n                pk = CRTPPacket()\n                pk.set_header(5, CHAN_SETTINGS)\n                pk.data = (CMD_DELETE_BLOCK, self.id)\n                self.cf.send_packet(\n                    pk, expected_reply=(CMD_DELETE_BLOCK, self.id))", "response": "Delete this entry in the Crazyflie"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunpacking received logging data so it represent real values according to the configuration in the entry", "response": "def unpack_log_data(self, log_data, timestamp):\n        \"\"\"Unpack received logging data so it represent real values according\n        to the configuration in the entry\"\"\"\n        ret_data = {}\n        data_index = 0\n        for var in self.variables:\n            size = LogTocElement.get_size_from_id(var.fetch_as)\n            name = var.name\n            unpackstring = LogTocElement.get_unpack_string_from_id(\n                var.fetch_as)\n            value = struct.unpack(\n                unpackstring, log_data[data_index:data_index + size])[0]\n            data_index += size\n            ret_data[name] = value\n        self.data_received_cb.call(timestamp, ret_data, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_id_from_cstring(name):\n        for key in list(LogTocElement.types.keys()):\n            if (LogTocElement.types[key][0] == name):\n                return key\n        raise KeyError('Type [%s] not found in LogTocElement.types!' % name)", "response": "Return variable type id given the C - storage name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a log configuration to the logging framework.", "response": "def add_config(self, logconf):\n        \"\"\"Add a log configuration to the logging framework.\n\n        When doing this the contents of the log configuration will be validated\n        and listeners for new log configurations will be notified. When\n        validating the configuration the variables are checked against the TOC\n        to see that they actually exist. If they don't then the configuration\n        cannot be used. Since a valid TOC is required, a Crazyflie has to be\n        connected when calling this method, otherwise it will fail.\"\"\"\n\n        if not self.cf.link:\n            logger.error('Cannot add configs without being connected to a '\n                         'Crazyflie!')\n            return\n\n        # If the log configuration contains variables that we added without\n        # type (i.e we want the stored as type for fetching as well) then\n        # resolve this now and add them to the block again.\n        for name in logconf.default_fetch_as:\n            var = self.toc.get_element_by_complete_name(name)\n            if not var:\n                logger.warning(\n                    '%s not in TOC, this block cannot be used!', name)\n                logconf.valid = False\n                raise KeyError('Variable {} not in TOC'.format(name))\n            # Now that we know what type this variable has, add it to the log\n            # config again with the correct type\n            logconf.add_variable(name, var.ctype)\n\n        # Now check that all the added variables are in the TOC and that\n        # the total size constraint of a data packet with logging data is\n        # not\n        size = 0\n        for var in logconf.variables:\n            size += LogTocElement.get_size_from_id(var.fetch_as)\n            # Check that we are able to find the variable in the TOC so\n            # we can return error already now and not when the config is sent\n            if var.is_toc_variable():\n                if (self.toc.get_element_by_complete_name(var.name) is None):\n                    logger.warning(\n                        'Log: %s not in TOC, this block cannot be used!',\n                        var.name)\n                    logconf.valid = False\n                    raise KeyError('Variable {} not in TOC'.format(var.name))\n\n        if (size <= MAX_LOG_DATA_PACKET_SIZE and\n                (logconf.period > 0 and logconf.period < 0xFF)):\n            logconf.valid = True\n            logconf.cf = self.cf\n            logconf.id = self._config_id_counter\n            logconf.useV2 = self._useV2\n            self._config_id_counter = (self._config_id_counter + 1) % 255\n            self.log_blocks.append(logconf)\n            self.block_added_cb.call(logconf)\n        else:\n            logconf.valid = False\n            raise AttributeError(\n                'The log configuration is too large or has an invalid '\n                'parameter')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refresh_toc(self, refresh_done_callback, toc_cache):\n\n        self._useV2 = self.cf.platform.get_protocol_version() >= 4\n\n        self._toc_cache = toc_cache\n        self._refresh_callback = refresh_done_callback\n        self.toc = None\n\n        pk = CRTPPacket()\n        pk.set_header(CRTPPort.LOGGING, CHAN_SETTINGS)\n        pk.data = (CMD_RESET_LOGGING,)\n        self.cf.send_packet(pk, expected_reply=(CMD_RESET_LOGGING,))", "response": "Start refreshing the table of loggale variables"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _new_packet_cb(self, packet):\n        chan = packet.channel\n        cmd = packet.data[0]\n        payload = packet.data[1:]\n\n        if (chan == CHAN_SETTINGS):\n            id = payload[0]\n            error_status = payload[1]\n            block = self._find_block(id)\n            if cmd == CMD_CREATE_BLOCK or cmd == CMD_CREATE_BLOCK_V2:\n                if (block is not None):\n                    if error_status == 0 or error_status == errno.EEXIST:\n                        if not block.added:\n                            logger.debug('Have successfully added id=%d', id)\n\n                            pk = CRTPPacket()\n                            pk.set_header(5, CHAN_SETTINGS)\n                            pk.data = (CMD_START_LOGGING, id, block.period)\n                            self.cf.send_packet(pk, expected_reply=(\n                                CMD_START_LOGGING, id))\n                            block.added = True\n                    else:\n                        msg = self._err_codes[error_status]\n                        logger.warning('Error %d when adding id=%d (%s)',\n                                       error_status, id, msg)\n                        block.err_no = error_status\n                        block.added_cb.call(False)\n                        block.error_cb.call(block, msg)\n\n                else:\n                    logger.warning('No LogEntry to assign block to !!!')\n            if (cmd == CMD_START_LOGGING):\n                if (error_status == 0x00):\n                    logger.info('Have successfully started logging for id=%d',\n                                id)\n                    if block:\n                        block.started = True\n\n                else:\n                    msg = self._err_codes[error_status]\n                    logger.warning('Error %d when starting id=%d (%s)',\n                                   error_status, id, msg)\n                    if block:\n                        block.err_no = error_status\n                        block.started_cb.call(self, False)\n                        # This is a temporary fix, we are adding a new issue\n                        # for this. For some reason we get an error back after\n                        # the block has been started and added. This will show\n                        # an error in the UI, but everything is still working.\n                        # block.error_cb.call(block, msg)\n\n            if (cmd == CMD_STOP_LOGGING):\n                if (error_status == 0x00):\n                    logger.info('Have successfully stopped logging for id=%d',\n                                id)\n                    if block:\n                        block.started = False\n\n            if (cmd == CMD_DELETE_BLOCK):\n                # Accept deletion of a block that isn't added. This could\n                # happen due to timing (i.e add/start/delete in fast sequence)\n                if error_status == 0x00 or error_status == errno.ENOENT:\n                    logger.info('Have successfully deleted id=%d', id)\n                    if block:\n                        block.started = False\n                        block.added = False\n\n            if (cmd == CMD_RESET_LOGGING):\n                # Guard against multiple responses due to re-sending\n                if not self.toc:\n                    logger.debug('Logging reset, continue with TOC download')\n                    self.log_blocks = []\n\n                    self.toc = Toc()\n                    toc_fetcher = TocFetcher(self.cf, LogTocElement,\n                                             CRTPPort.LOGGING,\n                                             self.toc, self._refresh_callback,\n                                             self._toc_cache)\n                    toc_fetcher.start()\n\n        if (chan == CHAN_LOGDATA):\n            chan = packet.channel\n            id = packet.data[0]\n            block = self._find_block(id)\n            timestamps = struct.unpack('<BBB', packet.data[1:4])\n            timestamp = (\n                timestamps[0] | timestamps[1] << 8 | timestamps[2] << 16)\n            logdata = packet.data[4:]\n            if (block is not None):\n                block.unpack_log_data(logdata, timestamp)\n            else:\n                logger.warning('Error no LogEntry to handle id=%d', id)", "response": "Callback for newly arrived packets with TOC information"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize all the drivers.", "response": "def init_drivers(enable_debug_driver=False):\n    \"\"\"Initialize all the drivers.\"\"\"\n    for driver in DRIVERS:\n        try:\n            if driver != DebugDriver or enable_debug_driver:\n                CLASSES.append(driver)\n        except Exception:  # pylint: disable=W0703\n            continue"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scan_interfaces(address=None):\n    available = []\n    found = []\n    for driverClass in CLASSES:\n        try:\n            logger.debug('Scanning: %s', driverClass)\n            instance = driverClass()\n            found = instance.scan_interface(address)\n            available += found\n        except Exception:\n            raise\n    return available", "response": "Scan all the interfaces for available Crazyflies."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the status of all the interfaces", "response": "def get_interfaces_status():\n    \"\"\"Get the status of all the interfaces\"\"\"\n    status = {}\n    for driverClass in CLASSES:\n        try:\n            instance = driverClass()\n            status[instance.get_name()] = instance.get_status()\n        except Exception:\n            raise\n    return status"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the link driver for the given URI. Returns None if no link driver was found for the given URI. Returns None if no driver was found for the given URI. Returns None if no driver was found for the given URI.", "response": "def get_link_driver(uri, link_quality_callback=None, link_error_callback=None):\n    \"\"\"Return the link driver for the given URI. Returns None if no driver\n    was found for the URI or the URI was not well formatted for the matching\n    driver.\"\"\"\n    for driverClass in CLASSES:\n        try:\n            instance = driverClass()\n            instance.connect(uri, link_quality_callback, link_error_callback)\n            return instance\n        except WrongUriType:\n            continue\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_extpos(self, pos):\n\n        pk = CRTPPacket()\n        pk.port = CRTPPort.LOCALIZATION\n        pk.channel = self.POSITION_CH\n        pk.data = struct.pack('<fff', pos[0], pos[1], pos[2])\n        self._cf.send_packet(pk)", "response": "Send the current position of the current Crazyflie X Y Z position."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_short_lpp_packet(self, dest_id, data):\n\n        pk = CRTPPacket()\n        pk.port = CRTPPort.LOCALIZATION\n        pk.channel = self.GENERIC_CH\n        pk.data = struct.pack('<BB', self.LPS_SHORT_LPP_PACKET, dest_id) + data\n        self._cf.send_packet(pk)", "response": "Send a short LPP packet to dest_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_setpoint(self, roll, pitch, yaw, thrust):\n        if thrust > 0xFFFF or thrust < 0:\n            raise ValueError('Thrust must be between 0 and 0xFFFF')\n\n        if self._x_mode:\n            roll, pitch = 0.707 * (roll - pitch), 0.707 * (roll + pitch)\n\n        pk = CRTPPacket()\n        pk.port = CRTPPort.COMMANDER\n        pk.data = struct.pack('<fffH', roll, -pitch, yaw, thrust)\n        self._cf.send_packet(pk)", "response": "Send a new control setpoint to the copter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend STOP setpoint to the motors and falling.", "response": "def send_stop_setpoint(self):\n        \"\"\"\n        Send STOP setpoing, stopping the motors and (potentially) falling.\n        \"\"\"\n        pk = CRTPPacket()\n        pk.port = CRTPPort.COMMANDER_GENERIC\n        pk.data = struct.pack('<B', TYPE_STOP)\n        self._cf.send_packet(pk)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend Velocity in the world frame of reference setpoint.", "response": "def send_velocity_world_setpoint(self, vx, vy, vz, yawrate):\n        \"\"\"\n        Send Velocity in the world frame of reference setpoint.\n\n        vx, vy, vz are in m/s\n        yawrate is in degrees/s\n        \"\"\"\n        pk = CRTPPacket()\n        pk.port = CRTPPort.COMMANDER_GENERIC\n        pk.data = struct.pack('<Bffff', TYPE_VELOCITY_WORLD,\n                              vx, vy, vz, yawrate)\n        self._cf.send_packet(pk)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a setpoint to the Crazflie.", "response": "def send_zdistance_setpoint(self, roll, pitch, yawrate, zdistance):\n        \"\"\"\n        Control mode where the height is send as an absolute setpoint (intended\n        to be the distance to the surface under the Crazflie).\n\n        Roll, pitch, yawrate are defined as degrees, degrees, degrees/s\n        \"\"\"\n        pk = CRTPPacket()\n        pk.port = CRTPPort.COMMANDER_GENERIC\n        pk.data = struct.pack('<Bffff', TYPE_ZDISTANCE,\n                              roll, pitch, yawrate, zdistance)\n        self._cf.send_packet(pk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a hover setpoint to the Crazflie.", "response": "def send_hover_setpoint(self, vx, vy, yawrate, zdistance):\n        \"\"\"\n        Control mode where the height is send as an absolute setpoint (intended\n        to be the distance to the surface under the Crazflie).\n\n        vx and vy are in m/s\n        yawrate is in degrees/s\n        \"\"\"\n        pk = CRTPPacket()\n        pk.port = CRTPPort.COMMANDER_GENERIC\n        pk.data = struct.pack('<Bffff', TYPE_HOVER,\n                              vx, vy, yawrate, zdistance)\n        self._cf.send_packet(pk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_position_setpoint(self, x, y, z, yaw):\n        pk = CRTPPacket()\n        pk.port = CRTPPort.COMMANDER_GENERIC\n        pk.data = struct.pack('<Bffff', TYPE_POSITION,\n                              x, y, z, yaw)\n        self._cf.send_packet(pk)", "response": "Send a position setpoint to the local system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget string representation of memory type", "response": "def type_to_string(t):\n        \"\"\"Get string representation of memory type\"\"\"\n        if t == MemoryElement.TYPE_I2C:\n            return 'I2C'\n        if t == MemoryElement.TYPE_1W:\n            return '1-wire'\n        if t == MemoryElement.TYPE_DRIVER_LED:\n            return 'LED driver'\n        if t == MemoryElement.TYPE_LOCO:\n            return 'Loco Positioning'\n        if t == MemoryElement.TYPE_TRAJ:\n            return 'Trajectory'\n        if t == MemoryElement.TYPE_LOCO2:\n            return 'Loco Positioning 2'\n        return 'Unknown'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set(self, r, g, b, intensity=None):\n        self.r = r\n        self.g = g\n        self.b = b\n        if intensity:\n            self.intensity = intensity", "response": "Set the R G and B values in one call"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_data(self, write_finished_cb):\n        self._write_finished_cb = write_finished_cb\n        data = bytearray()\n        for led in self.leds:\n            # In order to fit all the LEDs in one radio packet RGB565 is used\n            # to compress the colors. The calculations below converts 3 bytes\n            # RGB into 2 bytes RGB565. Then shifts the value of each color to\n            # LSB, applies the intensity and shifts them back for correct\n            # alignment on 2 bytes.\n            R5 = ((int)((((int(led.r) & 0xFF) * 249 + 1014) >> 11) & 0x1F) *\n                  led.intensity / 100)\n            G6 = ((int)((((int(led.g) & 0xFF) * 253 + 505) >> 10) & 0x3F) *\n                  led.intensity / 100)\n            B5 = ((int)((((int(led.b) & 0xFF) * 249 + 1014) >> 11) & 0x1F) *\n                  led.intensity / 100)\n            tmp = (int(R5) << 11) | (int(G6) << 5) | (int(B5) << 0)\n            data += bytearray((tmp >> 8, tmp & 0xFF))\n        self.mem_handler.write(self, 0x00, data, flush_queue=True)", "response": "Write the saved LED - ring data to the Crazyflie"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_data(self, mem, addr, data):\n        if mem.id == self.id:\n            if addr == 0:\n                if self._parse_and_check_header(data[0:8]):\n                    if self._parse_and_check_elements(data[9:11]):\n                        self.valid = True\n                        self._update_finished_cb(self)\n                        self._update_finished_cb = None\n                    else:\n                        # We need to fetch the elements, find out the length\n                        (elem_ver, elem_len) = struct.unpack('BB', data[8:10])\n                        self.mem_handler.read(self, 8, elem_len + 3)\n                else:\n                    # Call the update if the CRC check of the header fails,\n                    # we're done here\n                    if self._update_finished_cb:\n                        self._update_finished_cb(self)\n                        self._update_finished_cb = None\n            elif addr == 0x08:\n                if self._parse_and_check_elements(data):\n                    self.valid = True\n                if self._update_finished_cb:\n                    self._update_finished_cb(self)\n                    self._update_finished_cb = None", "response": "Callback for when new data has been fetched"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse and check the elements part of the memory and store them in self. elements.", "response": "def _parse_and_check_elements(self, data):\n        \"\"\"\n        Parse and check the CRC and length of the elements part of the memory\n        \"\"\"\n        crc = data[-1]\n        test_crc = crc32(data[:-1]) & 0x0ff\n        elem_data = data[2:-1]\n        if test_crc == crc:\n            while len(elem_data) > 0:\n                (eid, elen) = struct.unpack('BB', elem_data[:2])\n                self.elements[self.element_mapping[eid]] = \\\n                    elem_data[2:2 + elen].decode('ISO-8859-1')\n                elem_data = elem_data[2 + elen:]\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrequests an update of the memory content", "response": "def update(self, update_finished_cb):\n        \"\"\"Request an update of the memory content\"\"\"\n        if not self._update_finished_cb:\n            self._update_finished_cb = update_finished_cb\n            self.valid = False\n            logger.debug('Updating content of memory {}'.format(self.id))\n            # Start reading the header\n            self.mem_handler.read(self, 0, 11)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_and_check_header(self, data):\n        (start, self.pins, self.vid, self.pid, crc) = struct.unpack('<BIBBB',\n                                                                    data)\n        test_crc = crc32(data[:-1]) & 0x0ff\n        if start == 0xEB and crc == test_crc:\n            return True\n        return False", "response": "Parse and check the CRC of the header part of the memory"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_data(self, mem, addr, data):\n        done = False\n        if mem.id == self.id:\n            if addr == LocoMemory.MEM_LOCO_INFO:\n                self.nr_of_anchors = data[0]\n                if self.nr_of_anchors == 0:\n                    done = True\n                else:\n                    self.anchor_data = \\\n                        [AnchorData() for _ in range(self.nr_of_anchors)]\n                    self._request_page(0)\n            else:\n                page = int((addr - LocoMemory.MEM_LOCO_ANCHOR_BASE) /\n                           LocoMemory.MEM_LOCO_ANCHOR_PAGE_SIZE)\n\n                self.anchor_data[page].set_from_mem_data(data)\n\n                next_page = page + 1\n                if next_page < self.nr_of_anchors:\n                    self._request_page(next_page)\n                else:\n                    done = True\n\n        if done:\n            self.valid = True\n            if self._update_finished_cb:\n                self._update_finished_cb(self)\n                self._update_finished_cb = None", "response": "Callback for when new memory data has been fetched"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, update_finished_cb):\n        if not self._update_finished_cb:\n            self._update_finished_cb = update_finished_cb\n            self.anchor_data = []\n            self.nr_of_anchors = 0\n            self.valid = False\n            logger.debug('Updating content of memory {}'.format(self.id))\n\n            # Start reading the header\n            self.mem_handler.read(self, LocoMemory.MEM_LOCO_INFO,\n                                  LocoMemory.MEM_LOCO_INFO_LEN)", "response": "Request an update of the memory content"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new_data(self, mem, addr, data):\n        if mem.id == self.id:\n            if addr == LocoMemory2.ADR_ID_LIST:\n                self._handle_id_list_data(data)\n            elif addr == LocoMemory2.ADR_ACTIVE_ID_LIST:\n                self._handle_active_id_list_data(data)\n            else:\n                id = int((addr - LocoMemory2.ADR_ANCHOR_BASE) /\n                         LocoMemory2.ANCHOR_PAGE_SIZE)\n                self._handle_anchor_data(id, data)", "response": "Callback for when new data has been fetched"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequests an update of the id list", "response": "def update_id_list(self, update_ids_finished_cb):\n        \"\"\"Request an update of the id list\"\"\"\n        if not self._update_ids_finished_cb:\n            self._update_ids_finished_cb = update_ids_finished_cb\n            self.anchor_ids = []\n            self.active_anchor_ids = []\n            self.anchor_data = {}\n\n            self.nr_of_anchors = 0\n            self.ids_valid = False\n            self.data_valid = False\n\n            logger.debug('Updating ids of memory {}'.format(self.id))\n\n            # Start reading the header\n            self.mem_handler.read(self, LocoMemory2.ADR_ID_LIST,\n                                  LocoMemory2.ID_LIST_LEN)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrequest an update of the active id list", "response": "def update_active_id_list(self, update_active_ids_finished_cb):\n        \"\"\"Request an update of the active id list\"\"\"\n        if not self._update_active_ids_finished_cb:\n            self._update_active_ids_finished_cb = update_active_ids_finished_cb\n            self.active_anchor_ids = []\n\n            self.active_ids_valid = False\n\n            logger.debug('Updating active ids of memory {}'.format(self.id))\n\n            # Start reading the header\n            self.mem_handler.read(self, LocoMemory2.ADR_ACTIVE_ID_LIST,\n                                  LocoMemory2.ID_LIST_LEN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrequests an update of the anchor data", "response": "def update_data(self, update_data_finished_cb):\n        \"\"\"Request an update of the anchor data\"\"\"\n        if not self._update_data_finished_cb and self.nr_of_anchors > 0:\n            self._update_data_finished_cb = update_data_finished_cb\n            self.anchor_data = {}\n\n            self.data_valid = False\n            self._nr_of_anchors_to_fetch = self.nr_of_anchors\n\n            logger.debug('Updating anchor data of memory {}'.format(self.id))\n\n            # Start reading the first anchor\n            self._currently_fetching_index = 0\n            self._request_page(self.anchor_ids[self._currently_fetching_index])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_data(self, write_finished_cb):\n        self._write_finished_cb = write_finished_cb\n        data = bytearray()\n\n        for poly4D in self.poly4Ds:\n            data += struct.pack('<ffffffff', *poly4D.x.values)\n            data += struct.pack('<ffffffff', *poly4D.y.values)\n            data += struct.pack('<ffffffff', *poly4D.z.values)\n            data += struct.pack('<ffffffff', *poly4D.yaw.values)\n            data += struct.pack('<f', poly4D.duration)\n\n        self.mem_handler.write(self, 0x00, data, flush_queue=True)", "response": "Write trajectory data to the Crazyflie"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _request_new_chunk(self):\n        # Figure out the length of the next request\n        new_len = self._bytes_left\n        if new_len > _ReadRequest.MAX_DATA_LENGTH:\n            new_len = _ReadRequest.MAX_DATA_LENGTH\n\n        logger.debug('Requesting new chunk of {}bytes at 0x{:X}'.format(\n            new_len, self._current_addr))\n\n        # Request the data for the next address\n        pk = CRTPPacket()\n        pk.set_header(CRTPPort.MEM, CHAN_READ)\n        pk.data = struct.pack('<BIB', self.mem.id, self._current_addr, new_len)\n        reply = struct.unpack('<BBBBB', pk.data[:-1])\n        self.cf.send_packet(pk, expected_reply=reply, timeout=1)", "response": "Request a new chunk of data from the Crazyflie."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a new chunk of data from the Crazyflie.", "response": "def _write_new_chunk(self):\n        \"\"\"\n        Called to request a new chunk of data to be read from the Crazyflie\n        \"\"\"\n        # Figure out the length of the next request\n        new_len = len(self._data)\n        if new_len > _WriteRequest.MAX_DATA_LENGTH:\n            new_len = _WriteRequest.MAX_DATA_LENGTH\n\n        logger.debug('Writing new chunk of {}bytes at 0x{:X}'.format(\n            new_len, self._current_addr))\n\n        data = self._data[:new_len]\n        self._data = self._data[new_len:]\n\n        pk = CRTPPacket()\n        pk.set_header(CRTPPort.MEM, CHAN_WRITE)\n        pk.data = struct.pack('<BI', self.mem.id, self._current_addr)\n        # Create a tuple used for matching the reply using id and address\n        reply = struct.unpack('<BBBBB', pk.data)\n        self._sent_reply = reply\n        # Add the data\n        pk.data += struct.pack('B' * len(data), *data)\n        self._sent_packet = pk\n        self.cf.send_packet(pk, expected_reply=reply, timeout=1)\n\n        self._addr_add = len(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_mem(self, id):\n        for m in self.mems:\n            if m.id == id:\n                return m\n\n        return None", "response": "Fetch the memory with the supplied id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch all the memories of the supplied type", "response": "def get_mems(self, type):\n        \"\"\"Fetch all the memories of the supplied type\"\"\"\n        ret = ()\n        for m in self.mems:\n            if m.type == type:\n                ret += (m,)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for specific memory id or name and return it", "response": "def ow_search(self, vid=0xBC, pid=None, name=None):\n        \"\"\"Search for specific memory id/name and return it\"\"\"\n        for m in self.get_mems(MemoryElement.TYPE_1W):\n            if pid and m.pid == pid or name and m.name == name:\n                return m\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the specified data to the given memory at the given address.", "response": "def write(self, memory, addr, data, flush_queue=False):\n        \"\"\"Write the specified data to the given memory at the given address\"\"\"\n        wreq = _WriteRequest(memory, addr, data, self.cf)\n        if memory.id not in self._write_requests:\n            self._write_requests[memory.id] = []\n\n        # Workaround until we secure the uplink and change messages for\n        # mems to non-blocking\n        self._write_requests_lock.acquire()\n        if flush_queue:\n            self._write_requests[memory.id] = self._write_requests[\n                memory.id][:1]\n        self._write_requests[memory.id].insert(len(self._write_requests), wreq)\n        if len(self._write_requests[memory.id]) == 1:\n            wreq.start()\n        self._write_requests_lock.release()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, memory, addr, length):\n        if memory.id in self._read_requests:\n            logger.warning('There is already a read operation ongoing for '\n                           'memory id {}'.format(memory.id))\n            return False\n\n        rreq = _ReadRequest(memory, addr, length, self.cf)\n        self._read_requests[memory.id] = rreq\n\n        rreq.start()\n\n        return True", "response": "Read the specified amount of bytes from the given memory at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart fetching all the detected memories", "response": "def refresh(self, refresh_done_callback):\n        \"\"\"Start fetching all the detected memories\"\"\"\n        self._refresh_callback = refresh_done_callback\n        self._fetch_id = 0\n        for m in self.mems:\n            try:\n                self.mem_read_cb.remove_callback(m.new_data)\n                m.disconnect()\n            except Exception as e:\n                logger.info(\n                    'Error when removing memory after update: {}'.format(e))\n        self.mems = []\n\n        self.nbr_of_mems = 0\n        self._getting_count = False\n\n        logger.debug('Requesting number of memories')\n        pk = CRTPPacket()\n        pk.set_header(CRTPPort.MEM, CHAN_INFO)\n        pk.data = (CMD_INFO_NBR,)\n        self.cf.send_packet(pk, expected_reply=(CMD_INFO_NBR,))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _new_packet_cb(self, packet):\n        chan = packet.channel\n        cmd = packet.data[0]\n        payload = packet.data[1:]\n\n        if chan == CHAN_INFO:\n            if cmd == CMD_INFO_NBR:\n                self.nbr_of_mems = payload[0]\n                logger.info('{} memories found'.format(self.nbr_of_mems))\n\n                # Start requesting information about the memories,\n                # if there are any...\n                if self.nbr_of_mems > 0:\n                    if not self._getting_count:\n                        self._getting_count = True\n                        logger.debug('Requesting first id')\n                        pk = CRTPPacket()\n                        pk.set_header(CRTPPort.MEM, CHAN_INFO)\n                        pk.data = (CMD_INFO_DETAILS, 0)\n                        self.cf.send_packet(pk, expected_reply=(\n                            CMD_INFO_DETAILS, 0))\n                else:\n                    self._refresh_callback()\n\n            if cmd == CMD_INFO_DETAILS:\n\n                # Did we get a good reply, otherwise try again:\n                if len(payload) < 5:\n                    # Workaround for 1-wire bug when memory is detected\n                    # but updating the info crashes the communication with\n                    # the 1-wire. Fail by saying we only found 1 memory\n                    # (the I2C).\n                    logger.error(\n                        '-------->Got good count, but no info on mem!')\n                    self.nbr_of_mems = 1\n                    if self._refresh_callback:\n                        self._refresh_callback()\n                        self._refresh_callback = None\n                    return\n\n                # Create information about a new memory\n                # Id - 1 byte\n                mem_id = payload[0]\n                # Type - 1 byte\n                mem_type = payload[1]\n                # Size 4 bytes (as addr)\n                mem_size = struct.unpack('I', payload[2:6])[0]\n                # Addr (only valid for 1-wire?)\n                mem_addr_raw = struct.unpack('B' * 8, payload[6:14])\n                mem_addr = ''\n                for m in mem_addr_raw:\n                    mem_addr += '{:02X}'.format(m)\n\n                if (not self.get_mem(mem_id)):\n                    if mem_type == MemoryElement.TYPE_1W:\n                        mem = OWElement(id=mem_id, type=mem_type,\n                                        size=mem_size,\n                                        addr=mem_addr, mem_handler=self)\n                        self.mem_read_cb.add_callback(mem.new_data)\n                        self.mem_write_cb.add_callback(mem.write_done)\n                        self._ow_mems_left_to_update.append(mem.id)\n                    elif mem_type == MemoryElement.TYPE_I2C:\n                        mem = I2CElement(id=mem_id, type=mem_type,\n                                         size=mem_size,\n                                         mem_handler=self)\n                        self.mem_read_cb.add_callback(mem.new_data)\n                        self.mem_write_cb.add_callback(mem.write_done)\n                    elif mem_type == MemoryElement.TYPE_DRIVER_LED:\n                        mem = LEDDriverMemory(id=mem_id, type=mem_type,\n                                              size=mem_size, mem_handler=self)\n                        logger.debug(mem)\n                        self.mem_read_cb.add_callback(mem.new_data)\n                        self.mem_write_cb.add_callback(mem.write_done)\n                    elif mem_type == MemoryElement.TYPE_LOCO:\n                        mem = LocoMemory(id=mem_id, type=mem_type,\n                                         size=mem_size, mem_handler=self)\n                        logger.debug(mem)\n                        self.mem_read_cb.add_callback(mem.new_data)\n                    elif mem_type == MemoryElement.TYPE_TRAJ:\n                        mem = TrajectoryMemory(id=mem_id, type=mem_type,\n                                               size=mem_size, mem_handler=self)\n                        logger.debug(mem)\n                        self.mem_write_cb.add_callback(mem.write_done)\n                    elif mem_type == MemoryElement.TYPE_LOCO2:\n                        mem = LocoMemory2(id=mem_id, type=mem_type,\n                                          size=mem_size, mem_handler=self)\n                        logger.debug(mem)\n                        self.mem_read_cb.add_callback(mem.new_data)\n                    else:\n                        mem = MemoryElement(id=mem_id, type=mem_type,\n                                            size=mem_size, mem_handler=self)\n                        logger.debug(mem)\n                    self.mems.append(mem)\n                    self.mem_added_cb.call(mem)\n\n                    self._fetch_id = mem_id + 1\n\n                if self.nbr_of_mems - 1 >= self._fetch_id:\n                    logger.debug(\n                        'Requesting information about memory {}'.format(\n                            self._fetch_id))\n                    pk = CRTPPacket()\n                    pk.set_header(CRTPPort.MEM, CHAN_INFO)\n                    pk.data = (CMD_INFO_DETAILS, self._fetch_id)\n                    self.cf.send_packet(pk, expected_reply=(\n                        CMD_INFO_DETAILS, self._fetch_id))\n                else:\n                    logger.debug(\n                        'Done getting all the memories, start reading the OWs')\n                    ows = self.get_mems(MemoryElement.TYPE_1W)\n                    # If there are any OW mems start reading them, otherwise\n                    # we are done\n                    for ow_mem in ows:\n                        ow_mem.update(self._mem_update_done)\n                    if len(ows) == 0:\n                        if self._refresh_callback:\n                            self._refresh_callback()\n                            self._refresh_callback = None\n\n        if chan == CHAN_WRITE:\n            id = cmd\n            (addr, status) = struct.unpack('<IB', payload[0:5])\n            logger.debug(\n                'WRITE: Mem={}, addr=0x{:X}, status=0x{}'.format(\n                    id, addr, status))\n            # Find the read request\n            if id in self._write_requests:\n                self._write_requests_lock.acquire()\n                wreq = self._write_requests[id][0]\n                if status == 0:\n                    if wreq.write_done(addr):\n                        # self._write_requests.pop(id, None)\n                        # Remove the first item\n                        self._write_requests[id].pop(0)\n                        self.mem_write_cb.call(wreq.mem, wreq.addr)\n\n                        # Get a new one to start (if there are any)\n                        if len(self._write_requests[id]) > 0:\n                            self._write_requests[id][0].start()\n                else:\n                    logger.debug(\n                        'Status {}: write resending...'.format(status))\n                    wreq.resend()\n                self._write_requests_lock.release()\n\n        if chan == CHAN_READ:\n            id = cmd\n            (addr, status) = struct.unpack('<IB', payload[0:5])\n            data = struct.unpack('B' * len(payload[5:]), payload[5:])\n            logger.debug('READ: Mem={}, addr=0x{:X}, status=0x{}, '\n                         'data={}'.format(id, addr, status, data))\n            # Find the read request\n            if id in self._read_requests:\n                logger.debug(\n                    'READING: We are still interested in request for '\n                    'mem {}'.format(id))\n                rreq = self._read_requests[id]\n                if status == 0:\n                    if rreq.add_data(addr, payload[5:]):\n                        self._read_requests.pop(id, None)\n                        self.mem_read_cb.call(rreq.mem, rreq.addr, rreq.data)\n                else:\n                    logger.debug('Status {}: resending...'.format(status))\n                    rreq.resend()", "response": "Callback for newly arrived packets for the memory port"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresetting the current CPU to bootloader 1.", "response": "def reset_to_bootloader1(self, cpu_id):\n        \"\"\" Reset to the bootloader\n        The parameter cpuid shall correspond to the device to reset.\n\n        Return true if the reset has been done and the contact with the\n        bootloader is established.\n        \"\"\"\n        # Send an echo request and wait for the answer\n        # Mainly aim to bypass a bug of the crazyflie firmware that prevents\n        # reset before normal CRTP communication\n        pk = CRTPPacket()\n        pk.port = CRTPPort.LINKCTRL\n        pk.data = (1, 2, 3) + cpu_id\n        self.link.send_packet(pk)\n\n        pk = None\n        while True:\n            pk = self.link.receive_packet(2)\n            if not pk:\n                return False\n\n            if pk.port == CRTPPort.LINKCTRL:\n                break\n\n        # Send the reset to bootloader request\n        pk = CRTPPacket()\n        pk.set_header(0xFF, 0xFF)\n        pk.data = (0xFF, 0xFE) + cpu_id\n        self.link.send_packet(pk)\n\n        # Wait to ack the reset ...\n        pk = None\n        while True:\n            pk = self.link.receive_packet(2)\n            if not pk:\n                return False\n\n            if pk.port == 0xFF and tuple(pk.data) == (0xFF, 0xFE) + cpu_id:\n                pk.data = (0xFF, 0xF0) + cpu_id\n                self.link.send_packet(pk)\n                break\n\n        time.sleep(0.1)\n        self.link.close()\n        self.link = cflib.crtp.get_link_driver(self.clink_address)\n        # time.sleep(0.1)\n\n        return self._update_info()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset_to_firmware(self, target_id):\n        # The fake CPU ID is legacy from the Crazyflie 1.0\n        # In order to reset the CPU id had to be sent, but this\n        # was removed before launching it. But the length check is\n        # still in the bootloader. So to work around this bug so\n        # some extra data needs to be sent.\n        fake_cpu_id = (1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n        # Send the reset to bootloader request\n        pk = CRTPPacket()\n        pk.set_header(0xFF, 0xFF)\n        pk.data = (target_id, 0xFF) + fake_cpu_id\n        self.link.send_packet(pk)\n\n        # Wait to ack the reset ...\n        pk = None\n        while True:\n            pk = self.link.receive_packet(2)\n            if not pk:\n                return False\n\n            if (pk.header == 0xFF and struct.unpack(\n                    'B' * len(pk.data), pk.data)[:2] == (target_id, 0xFF)):\n                # Difference in CF1 and CF2 (CPU ID)\n                if target_id == 0xFE:\n                    pk.data = (target_id, 0xF0, 0x01)\n                else:\n                    pk.data = (target_id, 0xF0) + fake_cpu_id\n                self.link.send_packet(pk)\n                break\n\n        time.sleep(0.1)", "response": "Reset the current CPU ID to the specified target_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_link_and_get_info(self, target_id=0xFF):\n        for _ in range(0, 5):\n            if self._update_info(target_id):\n                if self._in_boot_cb:\n                    self._in_boot_cb.call(True, self.targets[\n                        target_id].protocol_version)\n                if self._info_cb:\n                    self._info_cb.call(self.targets[target_id])\n                return True\n        return False", "response": "Try to get a connection with the bootloader by requesting info about the link."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_info(self, target_id):\n\n        # Call getInfo ...\n        pk = CRTPPacket()\n        pk.set_header(0xFF, 0xFF)\n        pk.data = (target_id, 0x10)\n        self.link.send_packet(pk)\n\n        # Wait for the answer\n        pk = self.link.receive_packet(2)\n\n        if (pk and pk.header == 0xFF and struct.unpack('<BB', pk.data[0:2]) ==\n                (target_id, 0x10)):\n            tab = struct.unpack('BBHHHH', pk.data[0:10])\n            cpuid = struct.unpack('B' * 12, pk.data[10:22])\n            if target_id not in self.targets:\n                self.targets[target_id] = Target(target_id)\n            self.targets[target_id].addr = target_id\n            if len(pk.data) > 22:\n                self.targets[target_id].protocol_version = pk.datat[22]\n                self.protocol_version = pk.datat[22]\n            self.targets[target_id].page_size = tab[2]\n            self.targets[target_id].buffer_pages = tab[3]\n            self.targets[target_id].flash_pages = tab[4]\n            self.targets[target_id].start_page = tab[5]\n            self.targets[target_id].cpuid = '%02X' % cpuid[0]\n            for i in cpuid[1:]:\n                self.targets[target_id].cpuid += ':%02X' % i\n\n            if (self.protocol_version == 0x10 and\n                    target_id == TargetTypes.STM32):\n                self._update_mapping(target_id)\n\n            return True\n\n        return False", "response": "Update the information of the object in the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupload data into a buffer on the Crazyflie", "response": "def upload_buffer(self, target_id, page, address, buff):\n        \"\"\"Upload data into a buffer on the Crazyflie\"\"\"\n        # print len(buff)\n        count = 0\n        pk = CRTPPacket()\n        pk.set_header(0xFF, 0xFF)\n        pk.data = struct.pack('=BBHH', target_id, 0x14, page, address)\n\n        for i in range(0, len(buff)):\n            pk.data.append(buff[i])\n\n            count += 1\n\n            if count > 24:\n                self.link.send_packet(pk)\n                count = 0\n                pk = CRTPPacket()\n                pk.set_header(0xFF, 0xFF)\n                pk.data = struct.pack('=BBHH', target_id, 0x14, page,\n                                      i + address + 1)\n\n        self.link.send_packet(pk)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads back a flash page from the Crazyflie and return it", "response": "def read_flash(self, addr=0xFF, page=0x00):\n        \"\"\"Read back a flash page from the Crazyflie and return it\"\"\"\n        buff = bytearray()\n\n        page_size = self.targets[addr].page_size\n\n        for i in range(0, int(math.ceil(page_size / 25.0))):\n            pk = None\n            retry_counter = 5\n            while ((not pk or pk.header != 0xFF or\n                    struct.unpack('<BB', pk.data[0:2]) != (addr, 0x1C)) and\n                    retry_counter >= 0):\n                pk = CRTPPacket()\n                pk.set_header(0xFF, 0xFF)\n                pk.data = struct.pack('<BBHH', addr, 0x1C, page, (i * 25))\n                self.link.send_packet(pk)\n\n                pk = self.link.receive_packet(1)\n                retry_counter -= 1\n            if (retry_counter < 0):\n                return None\n            else:\n                buff += pk.data[6:]\n\n        # For some reason we get one byte extra here...\n        return buff[0:page_size]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the buffer to flash.", "response": "def write_flash(self, addr, page_buffer, target_page, page_count):\n        \"\"\"Initiate flashing of data in the buffer to flash.\"\"\"\n        # print \"Write page\", flashPage\n        # print \"Writing page [%d] and [%d] forward\" % (flashPage, nPage)\n        pk = None\n\n        # Flushing downlink ...\n        pk = self.link.receive_packet(0)\n        while pk is not None:\n            pk = self.link.receive_packet(0)\n\n        retry_counter = 5\n        # print \"Flasing to 0x{:X}\".format(addr)\n        while ((not pk or pk.header != 0xFF or\n                struct.unpack('<BB', pk.data[0:2]) != (addr, 0x18)) and\n               retry_counter >= 0):\n            pk = CRTPPacket()\n            pk.set_header(0xFF, 0xFF)\n            pk.data = struct.pack('<BBHHH', addr, 0x18, page_buffer,\n                                  target_page, page_count)\n            self.link.send_packet(pk)\n            pk = self.link.receive_packet(1)\n            retry_counter -= 1\n\n        if retry_counter < 0:\n            self.error_code = -1\n            return False\n\n        self.error_code = pk.data[3]\n\n        return pk.data[2] == 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding the CPU id into a string", "response": "def decode_cpu_id(self, cpuid):\n        \"\"\"Decode the CPU id into a string\"\"\"\n        ret = ()\n        for i in cpuid.split(':'):\n            ret += (eval('0x' + i),)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the port and channel for this packet.", "response": "def set_header(self, port, channel):\n        \"\"\"\n        Set the port and channel for this packet.\n        \"\"\"\n        self._port = port\n        self.channel = channel\n        self._update_header()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_data(self, data):\n        if type(data) == bytearray:\n            self._data = data\n        elif type(data) == str:\n            if sys.version_info < (3,):\n                self._data = bytearray(data)\n            else:\n                self._data = bytearray(data.encode('ISO-8859-1'))\n        elif type(data) == list or type(data) == tuple:\n            self._data = bytearray(data)\n        elif sys.version_info >= (3,) and type(data) == bytes:\n            self._data = bytearray(data)\n        else:\n            raise Exception('Data must be bytearray, string, list or tuple,'\n                            ' not {}'.format(type(data)))", "response": "Set the packet data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef take_off(self, height=None, velocity=VELOCITY):\n        if self._is_flying:\n            raise Exception('Already flying')\n\n        if not self._cf.is_connected():\n            raise Exception('Crazyflie is not connected')\n\n        self._is_flying = True\n        self._reset_position_estimator()\n\n        self._thread = _SetPointThread(self._cf)\n        self._thread.start()\n\n        if height is None:\n            height = self.default_height\n\n        self.up(height, velocity)", "response": "Take off the motors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngo straight down and turn off motors.", "response": "def land(self, velocity=VELOCITY):\n        \"\"\"\n        Go straight down and turn off the motors.\n\n        Do not call this function if you use the with keyword. Landing is\n        done automatically when the context goes out of scope.\n\n        :param velocity: The velocity (meters/second) when going down\n        :return:\n        \"\"\"\n        if self._is_flying:\n            self.down(self._thread.get_height(), velocity)\n\n            self._thread.stop()\n            self._thread = None\n\n            self._cf.commander.send_stop_setpoint()\n            self._is_flying = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef turn_left(self, angle_degrees, rate=RATE):\n        flight_time = angle_degrees / rate\n\n        self.start_turn_left(rate)\n        time.sleep(flight_time)\n        self.stop()", "response": "Turn to the left"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef turn_right(self, angle_degrees, rate=RATE):\n        flight_time = angle_degrees / rate\n\n        self.start_turn_right(rate)\n        time.sleep(flight_time)\n        self.stop()", "response": "Turn to the right"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef circle_left(self, radius_m, velocity=VELOCITY, angle_degrees=360.0):\n        distance = 2 * radius_m * math.pi * angle_degrees / 360.0\n        flight_time = distance / velocity\n\n        self.start_circle_left(radius_m, velocity)\n        time.sleep(flight_time)\n        self.stop()", "response": "Go in circle counter clock wise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef circle_right(self, radius_m, velocity=VELOCITY, angle_degrees=360.0):\n        distance = 2 * radius_m * math.pi * angle_degrees / 360.0\n        flight_time = distance / velocity\n\n        self.start_circle_right(radius_m, velocity)\n        time.sleep(flight_time)\n        self.stop()", "response": "Go in circle clock wise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves in a straight line.", "response": "def move_distance(self, distance_x_m, distance_y_m, distance_z_m,\n                      velocity=VELOCITY):\n        \"\"\"\n        Move in a straight line.\n        positive X is forward\n        positive Y is left\n        positive Z is up\n\n        :param distance_x_m: The distance to travel along the X-axis (meters)\n        :param distance_y_m: The distance to travel along the Y-axis (meters)\n        :param distance_z_m: The distance to travel along the Z-axis (meters)\n        :param velocity: the velocity of the motion (meters/second)\n        :return:\n        \"\"\"\n        distance = math.sqrt(distance_x_m * distance_x_m +\n                             distance_y_m * distance_y_m +\n                             distance_z_m * distance_z_m)\n        flight_time = distance / velocity\n\n        velocity_x = velocity * distance_x_m / distance\n        velocity_y = velocity * distance_y_m / distance\n        velocity_z = velocity * distance_z_m / distance\n\n        self.start_linear_motion(velocity_x, velocity_y, velocity_z)\n        time.sleep(flight_time)\n        self.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a circular motion to the left. This function returns immediately.", "response": "def start_circle_left(self, radius_m, velocity=VELOCITY):\n        \"\"\"\n        Start a circular motion to the left. This function returns immediately.\n\n        :param radius_m: The radius of the circle (meters)\n        :param velocity: The velocity of the motion (meters/second)\n        :return:\n        \"\"\"\n        circumference = 2 * radius_m * math.pi\n        rate = 360.0 * velocity / circumference\n\n        self._set_vel_setpoint(velocity, 0.0, 0.0, -rate)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_linear_motion(self, velocity_x_m, velocity_y_m, velocity_z_m):\n        self._set_vel_setpoint(\n            velocity_x_m, velocity_y_m, velocity_z_m, 0.0)", "response": "This function starts a linear motion. This function returns immediately."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the velocity setpoint to use for future motion", "response": "def set_vel_setpoint(self, velocity_x, velocity_y, velocity_z, rate_yaw):\n        \"\"\"Set the velocity setpoint to use for the future motion\"\"\"\n        self._queue.put((velocity_x, velocity_y, velocity_z, rate_yaw))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_devices():\n    ret = []\n\n    logger.info('Looking for devices....')\n\n    if pyusb1:\n        for d in usb.core.find(idVendor=USB_VID, idProduct=USB_PID, find_all=1,\n                               backend=pyusb_backend):\n            ret.append(d)\n    else:\n        busses = usb.busses()\n        for bus in busses:\n            for device in bus.devices:\n                if device.idVendor == USB_VID:\n                    if device.idProduct == USB_PID:\n                        ret += [device, ]\n\n    return ret", "response": "Returns a list of CrazyRadio devices currently connected to the computer\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a packet and receive the ack from the radio dongle", "response": "def send_packet(self, dataOut):\n        \"\"\" Send a packet and receive the ack from the radio dongle\n            The ack contains information about the packet transmition\n            and a data payload if the ack packet contained any \"\"\"\n        try:\n            if (pyusb1 is False):\n                self.handle.bulkWrite(1, dataOut, 20)\n            else:\n                self.handle.write(endpoint=1, data=dataOut, timeout=20)\n        except usb.USBError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _param_callback(self, name, value):\n        print('{0}: {1}'.format(name, value))\n\n        # Remove each parameter from the list and close the link when\n        # all are fetched\n        self._param_check_list.remove(name)\n        if len(self._param_check_list) == 0:\n            print('Have fetched all parameter values.')\n\n            # First remove all the group callbacks\n            for g in self._param_groups:\n                self._cf.param.remove_update_callback(group=g,\n                                                      cb=self._param_callback)\n\n            # Create a new random value [0.00,1.00] for pid_attitude.pitch_kd\n            # and set it\n            pkd = random.random()\n            print('')\n            print('Write: pid_attitude.pitch_kd={:.2f}'.format(pkd))\n            self._cf.param.add_update_callback(group='pid_attitude',\n                                               name='pitch_kd',\n                                               cb=self._a_pitch_kd_callback)\n            # When setting a value the parameter is automatically read back\n            # and the registered callbacks will get the updated value\n            self._cf.param.set_value('pid_attitude.pitch_kd',\n                                     '{:.2f}'.format(pkd))", "response": "Generic callback registered for all the groups"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconnecting the link driver to a specified URI.", "response": "def connect(self, uri, link_quality_callback, link_error_callback):\n        \"\"\"\n        Connect the link driver to a specified URI of the format:\n        radio://<dongle nbr>/<radio channel>/[250K,1M,2M]\n\n        The callback for linkQuality can be called at any moment from the\n        driver to report back the link quality in percentage. The\n        callback from linkError will be called when a error occurs with\n        an error message.\n        \"\"\"\n\n        # check if the URI is a radio URI\n        if not re.search('^radio://', uri):\n            raise WrongUriType('Not a radio URI')\n\n        # Open the USB dongle\n        if not re.search('^radio://([0-9a-fA-F]+)((/([0-9]+))'\n                         '((/(250K|1M|2M))?(/([A-F0-9]+))?)?)?$', uri):\n            raise WrongUriType('Wrong radio URI format!')\n\n        uri_data = re.search('^radio://([0-9a-fA-F]+)((/([0-9]+))'\n                             '((/(250K|1M|2M))?(/([A-F0-9]+))?)?)?$', uri)\n\n        self.uri = uri\n\n        if len(uri_data.group(1)) < 10 and uri_data.group(1).isdigit():\n            devid = int(uri_data.group(1))\n        else:\n            try:\n                devid = crazyradio.get_serials().index(\n                    uri_data.group(1).upper())\n            except ValueError:\n                raise Exception('Cannot find radio with serial {}'.format(\n                    uri_data.group(1)))\n\n        channel = 2\n        if uri_data.group(4):\n            channel = int(uri_data.group(4))\n\n        datarate = Crazyradio.DR_2MPS\n        if uri_data.group(7) == '250K':\n            datarate = Crazyradio.DR_250KPS\n        if uri_data.group(7) == '1M':\n            datarate = Crazyradio.DR_1MPS\n        if uri_data.group(7) == '2M':\n            datarate = Crazyradio.DR_2MPS\n\n        address = DEFAULT_ADDR_A\n        if uri_data.group(9):\n            addr = str(uri_data.group(9))\n            new_addr = struct.unpack('<BBBBB', binascii.unhexlify(addr))\n            address = new_addr\n\n        if self._radio_manager is None:\n            self._radio_manager = _RadioManager(devid,\n                                                channel,\n                                                datarate,\n                                                address)\n        else:\n            raise Exception('Link already open!')\n\n        with self._radio_manager as cradio:\n            if cradio.version >= 0.4:\n                cradio.set_arc(_nr_of_arc_retries)\n            else:\n                logger.warning('Radio version <0.4 will be obsoleted soon!')\n\n        # Prepare the inter-thread communication queue\n        self.in_queue = queue.Queue()\n        # Limited size out queue to avoid \"ReadBack\" effect\n        self.out_queue = queue.Queue(1)\n\n        # Launch the comm thread\n        self._thread = _RadioDriverThread(self._radio_manager,\n                                          self.in_queue,\n                                          self.out_queue,\n                                          link_quality_callback,\n                                          link_error_callback,\n                                          self)\n        self._thread.start()\n\n        self.link_error_callback = link_error_callback"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_packet(self, pk):\n        try:\n            self.out_queue.put(pk, True, 2)\n        except queue.Full:\n            if self.link_error_callback:\n                self.link_error_callback('RadioDriver: Could not send packet'\n                                         ' to copter')", "response": "Send the packet pk though the link"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _scan_radio_channels(self, cradio, start=0, stop=125):\n        return list(cradio.scan_channels(start, stop, (0xff,)))", "response": "Scan for Crazyflies between the supplied channels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scan_interface(self, address):\n\n        if self._radio_manager is None:\n            try:\n                self._radio_manager = _RadioManager(0)\n            except Exception:\n                return []\n\n        with self._radio_manager as cradio:\n            # FIXME: implements serial number in the Crazyradio driver!\n            serial = 'N/A'\n\n            logger.info('v%s dongle with serial %s found', cradio.version,\n                        serial)\n            found = []\n\n            if address is not None:\n                addr = '{:X}'.format(address)\n                new_addr = struct.unpack('<BBBBB', binascii.unhexlify(addr))\n                cradio.set_address(new_addr)\n\n            cradio.set_arc(1)\n\n            cradio.set_data_rate(cradio.DR_250KPS)\n\n            if address is None or address == DEFAULT_ADDR:\n                found += [['radio://0/{}/250K'.format(c), '']\n                          for c in self._scan_radio_channels(cradio)]\n                cradio.set_data_rate(cradio.DR_1MPS)\n                found += [['radio://0/{}/1M'.format(c), '']\n                          for c in self._scan_radio_channels(cradio)]\n                cradio.set_data_rate(cradio.DR_2MPS)\n                found += [['radio://0/{}/2M'.format(c), '']\n                          for c in self._scan_radio_channels(cradio)]\n            else:\n                found += [['radio://0/{}/250K/{:X}'.format(c, address), '']\n                          for c in self._scan_radio_channels(cradio)]\n                cradio.set_data_rate(cradio.DR_1MPS)\n                found += [['radio://0/{}/1M/{:X}'.format(c, address), '']\n                          for c in self._scan_radio_channels(cradio)]\n                cradio.set_data_rate(cradio.DR_2MPS)\n                found += [['radio://0/{}/2M/{:X}'.format(c, address), '']\n                          for c in self._scan_radio_channels(cradio)]\n\n        self._radio_manager.close()\n        self._radio_manager = None\n\n        return found", "response": "Scan interface for Crazyflies"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _send_packet_safe(self, cr, packet):\n        # packet = bytearray(packet)\n        packet[0] &= 0xF3\n        packet[0] |= self._curr_up << 3 | self._curr_down << 2\n        resp = cr.send_packet(packet)\n        if resp and resp.ack and len(resp.data) and \\\n           (resp.data[0] & 0x04) == (self._curr_down << 2):\n            self._curr_down = 1 - self._curr_down\n        if resp and resp.ack:\n            self._curr_up = 1 - self._curr_up\n\n        return resp", "response": "Send a packet to the specified CRTP server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        dataOut = array.array('B', [0xFF])\n        waitTime = 0\n        emptyCtr = 0\n\n        # Try up to 10 times to enable the safelink mode\n        with self._radio_manager as cradio:\n            for _ in range(10):\n                resp = cradio.send_packet((0xff, 0x05, 0x01))\n                if resp and resp.data and tuple(resp.data) == (\n                        0xff, 0x05, 0x01):\n                    self._has_safelink = True\n                    self._curr_up = 0\n                    self._curr_down = 0\n                    break\n        self._link.needs_resending = not self._has_safelink\n\n        while (True):\n            if (self._sp):\n                break\n\n            with self._radio_manager as cradio:\n                try:\n                    if self._has_safelink:\n                        ackStatus = self._send_packet_safe(cradio, dataOut)\n                    else:\n                        ackStatus = cradio.send_packet(dataOut)\n                except Exception as e:\n                    import traceback\n\n                    self._link_error_callback(\n                        'Error communicating with crazy radio ,it has '\n                        'probably been unplugged!\\nException:%s\\n\\n%s' % (\n                            e, traceback.format_exc()))\n\n            # Analyse the in data packet ...\n            if ackStatus is None:\n                logger.info('Dongle reported ACK status == None')\n                continue\n\n            if (self._link_quality_callback is not None):\n                # track the mean of a sliding window of the last N packets\n                retry = 10 - ackStatus.retry\n                self._retries.append(retry)\n                self._retry_sum += retry\n                if len(self._retries) > 100:\n                    self._retry_sum -= self._retries.popleft()\n                link_quality = float(self._retry_sum) / len(self._retries) * 10\n                self._link_quality_callback(link_quality)\n\n            # If no copter, retry\n            if ackStatus.ack is False:\n                self._retry_before_disconnect = \\\n                    self._retry_before_disconnect - 1\n                if (self._retry_before_disconnect == 0 and\n                        self._link_error_callback is not None):\n                    self._link_error_callback('Too many packets lost')\n                continue\n            self._retry_before_disconnect = _nr_of_retries\n\n            data = ackStatus.data\n\n            # If there is a copter in range, the packet is analysed and the\n            # next packet to send is prepared\n            if (len(data) > 0):\n                inPacket = CRTPPacket(data[0], list(data[1:]))\n                self._in_queue.put(inPacket)\n                waitTime = 0\n                emptyCtr = 0\n            else:\n                emptyCtr += 1\n                if (emptyCtr > 10):\n                    emptyCtr = 10\n                    # Relaxation time if the last 10 packet where empty\n                    waitTime = 0.01\n                else:\n                    waitTime = 0\n\n            # get the next packet to send of relaxation (wait 10ms)\n            outPacket = None\n            try:\n                outPacket = self._out_queue.get(True, waitTime)\n            except queue.Empty:\n                outPacket = None\n\n            dataOut = array.array('B')\n\n            if outPacket:\n                dataOut.append(outPacket.header)\n                for X in outPacket.data:\n                    if type(X) == int:\n                        dataOut.append(X)\n                    else:\n                        dataOut.append(ord(X))\n            else:\n                dataOut.append(0xFF)", "response": "This method is run in a thread. It will send the in data packet to the receiver thread and then wait for the receiver thread to finish."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _connected(self, link_uri):\n        print('Connected to %s' % link_uri)\n\n        mems = self._cf.mem.get_mems(MemoryElement.TYPE_1W)\n        print('Found {} 1-wire memories'.format(len(mems)))\n        if len(mems) > 0:\n            print('Writing test configuration to'\n                  ' memory {}'.format(mems[0].id))\n\n            mems[0].vid = 0xBC\n            mems[0].pid = 0xFF\n\n            board_name_id = OWElement.element_mapping[1]\n            board_rev_id = OWElement.element_mapping[2]\n\n            mems[0].elements[board_name_id] = 'Test board'\n            mems[0].elements[board_rev_id] = 'A'\n\n            mems[0].write_data(self._data_written)", "response": "This callback is called by the Crazyflie API when a Crazyflie API has been successfully downloaded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a requests. OAuth2Session from a client secrets file.", "response": "def session_from_client_config(client_config, scopes, **kwargs):\n    \"\"\"Creates a :class:`requests_oauthlib.OAuth2Session` from client\n    configuration loaded from a Google-format client secrets file.\n\n    Args:\n        client_config (Mapping[str, Any]): The client\n            configuration in the Google `client secrets`_ format.\n        scopes (Sequence[str]): The list of scopes to request during the\n            flow.\n        kwargs: Any additional parameters passed to\n            :class:`requests_oauthlib.OAuth2Session`\n\n    Raises:\n        ValueError: If the client configuration is not in the correct\n            format.\n\n    Returns:\n        Tuple[requests_oauthlib.OAuth2Session, Mapping[str, Any]]: The new\n            oauthlib session and the validated client configuration.\n\n    .. _client secrets:\n        https://developers.google.com/api-client-library/python/guide\n        /aaa_client_secrets\n    \"\"\"\n\n    if 'web' in client_config:\n        config = client_config['web']\n    elif 'installed' in client_config:\n        config = client_config['installed']\n    else:\n        raise ValueError(\n            'Client secrets must be for a web or installed app.')\n\n    if not _REQUIRED_CONFIG_KEYS.issubset(config.keys()):\n        raise ValueError('Client secrets is not in the correct format.')\n\n    session = requests_oauthlib.OAuth2Session(\n        client_id=config['client_id'],\n        scope=scopes,\n        **kwargs)\n\n    return session, client_config"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new immutable session from a Google - format client secrets file.", "response": "def session_from_client_secrets_file(client_secrets_file, scopes, **kwargs):\n    \"\"\"Creates a :class:`requests_oauthlib.OAuth2Session` instance from a\n    Google-format client secrets file.\n\n    Args:\n        client_secrets_file (str): The path to the `client secrets`_ .json\n            file.\n        scopes (Sequence[str]): The list of scopes to request during the\n            flow.\n        kwargs: Any additional parameters passed to\n            :class:`requests_oauthlib.OAuth2Session`\n\n    Returns:\n        Tuple[requests_oauthlib.OAuth2Session, Mapping[str, Any]]: The new\n            oauthlib session and the validated client configuration.\n\n    .. _client secrets:\n        https://developers.google.com/api-client-library/python/guide\n        /aaa_client_secrets\n    \"\"\"\n    with open(client_secrets_file, 'r') as json_file:\n        client_config = json.load(json_file)\n\n    return session_from_client_config(client_config, scopes, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef credentials_from_session(session, client_config=None):\n    client_config = client_config if client_config is not None else {}\n\n    if not session.token:\n        raise ValueError(\n            'There is no access token for this session, did you call '\n            'fetch_token?')\n\n    credentials = google.oauth2.credentials.Credentials(\n        session.token['access_token'],\n        refresh_token=session.token.get('refresh_token'),\n        id_token=session.token.get('id_token'),\n        token_uri=client_config.get('token_uri'),\n        client_id=client_config.get('client_id'),\n        client_secret=client_config.get('client_secret'),\n        scopes=session.scope)\n    credentials.expiry = datetime.datetime.utcfromtimestamp(\n        session.token['expires_at'])\n    return credentials", "response": "Creates a new credentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new Flow instance from a client secrets file.", "response": "def from_client_config(cls, client_config, scopes, **kwargs):\n        \"\"\"Creates a :class:`requests_oauthlib.OAuth2Session` from client\n        configuration loaded from a Google-format client secrets file.\n\n        Args:\n            client_config (Mapping[str, Any]): The client\n                configuration in the Google `client secrets`_ format.\n            scopes (Sequence[str]): The list of scopes to request during the\n                flow.\n            kwargs: Any additional parameters passed to\n                :class:`requests_oauthlib.OAuth2Session`\n\n        Returns:\n            Flow: The constructed Flow instance.\n\n        Raises:\n            ValueError: If the client configuration is not in the correct\n                format.\n\n        .. _client secrets:\n            https://developers.google.com/api-client-library/python/guide\n            /aaa_client_secrets\n        \"\"\"\n        if 'web' in client_config:\n            client_type = 'web'\n        elif 'installed' in client_config:\n            client_type = 'installed'\n        else:\n            raise ValueError(\n                'Client secrets must be for a web or installed app.')\n\n        session, client_config = (\n            google_auth_oauthlib.helpers.session_from_client_config(\n                client_config, scopes, **kwargs))\n\n        redirect_uri = kwargs.get('redirect_uri', None)\n        return cls(session, client_type, client_config, redirect_uri)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Flow instance from a Google client secrets file.", "response": "def from_client_secrets_file(cls, client_secrets_file, scopes, **kwargs):\n        \"\"\"Creates a :class:`Flow` instance from a Google client secrets file.\n\n        Args:\n            client_secrets_file (str): The path to the client secrets .json\n                file.\n            scopes (Sequence[str]): The list of scopes to request during the\n                flow.\n            kwargs: Any additional parameters passed to\n                :class:`requests_oauthlib.OAuth2Session`\n\n        Returns:\n            Flow: The constructed Flow instance.\n        \"\"\"\n        with open(client_secrets_file, 'r') as json_file:\n            client_config = json.load(json_file)\n\n        return cls.from_client_config(client_config, scopes=scopes, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating an authorization URL.", "response": "def authorization_url(self, **kwargs):\n        \"\"\"Generates an authorization URL.\n\n        This is the first step in the OAuth 2.0 Authorization Flow. The user's\n        browser should be redirected to the returned URL.\n\n        This method calls\n        :meth:`requests_oauthlib.OAuth2Session.authorization_url`\n        and specifies the client configuration's authorization URI (usually\n        Google's authorization server) and specifies that \"offline\" access is\n        desired. This is required in order to obtain a refresh token.\n\n        Args:\n            kwargs: Additional arguments passed through to\n                :meth:`requests_oauthlib.OAuth2Session.authorization_url`\n\n        Returns:\n            Tuple[str, str]: The generated authorization URL and state. The\n                user must visit the URL to complete the flow. The state is used\n                when completing the flow to verify that the request originated\n                from your application. If your application is using a different\n                :class:`Flow` instance to obtain the token, you will need to\n                specify the ``state`` when constructing the :class:`Flow`.\n        \"\"\"\n        kwargs.setdefault('access_type', 'offline')\n        url, state = self.oauth2session.authorization_url(\n            self.client_config['auth_uri'], **kwargs)\n\n        return url, state"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch_token(self, **kwargs):\n        kwargs.setdefault('client_secret', self.client_config['client_secret'])\n        return self.oauth2session.fetch_token(\n            self.client_config['token_uri'], **kwargs)", "response": "Completes the Authorization Flow and obtains an access token."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the flow using the console strategy.", "response": "def run_console(\n            self,\n            authorization_prompt_message=_DEFAULT_AUTH_PROMPT_MESSAGE,\n            authorization_code_message=_DEFAULT_AUTH_CODE_MESSAGE,\n            **kwargs):\n        \"\"\"Run the flow using the console strategy.\n\n        The console strategy instructs the user to open the authorization URL\n        in their browser. Once the authorization is complete the authorization\n        server will give the user a code. The user then must copy & paste this\n        code into the application. The code is then exchanged for a token.\n\n        Args:\n            authorization_prompt_message (str): The message to display to tell\n                the user to navigate to the authorization URL.\n            authorization_code_message (str): The message to display when\n                prompting the user for the authorization code.\n            kwargs: Additional keyword arguments passed through to\n                :meth:`authorization_url`.\n\n        Returns:\n            google.oauth2.credentials.Credentials: The OAuth 2.0 credentials\n                for the user.\n        \"\"\"\n        kwargs.setdefault('prompt', 'consent')\n\n        self.redirect_uri = self._OOB_REDIRECT_URI\n\n        auth_url, _ = self.authorization_url(**kwargs)\n\n        print(authorization_prompt_message.format(url=auth_url))\n\n        code = input(authorization_code_message)\n\n        self.fetch_token(code=code)\n\n        return self.credentials"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the flow using the server strategy. The server strategy instructs the user to open the authorization URL in their browser and will attempt to automatically open the URL for them. It will start a local web server to listen for the authorization response. Once authorization is complete the authorization server will redirect the user's browser to the local web server. The web server will get the authorization code from the response and shutdown. The code is then exchanged for a token. Args: host (str): The hostname for the local redirect server. This will be served over http, not https. port (int): The port for the local redirect server. authorization_prompt_message (str): The message to display to tell the user to navigate to the authorization URL. success_message (str): The message to display in the web browser the authorization flow is complete. open_browser (bool): Whether or not to open the authorization URL in the user's browser. kwargs: Additional keyword arguments passed through to :meth:`authorization_url`. Returns: google.oauth2.credentials.Credentials: The OAuth 2.0 credentials for the user.", "response": "def run_local_server(\n            self, host='localhost', port=8080,\n            authorization_prompt_message=_DEFAULT_AUTH_PROMPT_MESSAGE,\n            success_message=_DEFAULT_WEB_SUCCESS_MESSAGE,\n            open_browser=True,\n            **kwargs):\n        \"\"\"Run the flow using the server strategy.\n\n        The server strategy instructs the user to open the authorization URL in\n        their browser and will attempt to automatically open the URL for them.\n        It will start a local web server to listen for the authorization\n        response. Once authorization is complete the authorization server will\n        redirect the user's browser to the local web server. The web server\n        will get the authorization code from the response and shutdown. The\n        code is then exchanged for a token.\n\n        Args:\n            host (str): The hostname for the local redirect server. This will\n                be served over http, not https.\n            port (int): The port for the local redirect server.\n            authorization_prompt_message (str): The message to display to tell\n                the user to navigate to the authorization URL.\n            success_message (str): The message to display in the web browser\n                the authorization flow is complete.\n            open_browser (bool): Whether or not to open the authorization URL\n                in the user's browser.\n            kwargs: Additional keyword arguments passed through to\n                :meth:`authorization_url`.\n\n        Returns:\n            google.oauth2.credentials.Credentials: The OAuth 2.0 credentials\n                for the user.\n        \"\"\"\n        self.redirect_uri = 'http://{}:{}/'.format(host, port)\n\n        auth_url, _ = self.authorization_url(**kwargs)\n\n        wsgi_app = _RedirectWSGIApp(success_message)\n        local_server = wsgiref.simple_server.make_server(\n            host, port, wsgi_app, handler_class=_WSGIRequestHandler)\n\n        if open_browser:\n            webbrowser.open(auth_url, new=1, autoraise=True)\n\n        print(authorization_prompt_message.format(url=auth_url))\n\n        local_server.handle_request()\n\n        # Note: using https here because oauthlib is very picky that\n        # OAuth 2.0 should only occur over https.\n        authorization_response = wsgi_app.last_request_uri.replace(\n            'http', 'https')\n        self.fetch_token(authorization_response=authorization_response)\n\n        return self.credentials"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall an opener. Arguments: opener (`Opener`): an `Opener` instance, or a callable that returns an opener instance. Note: May be used as a class decorator. For example:: registry = Registry() @registry.install class ArchiveOpener(Opener): protocols = ['zip', 'tar']", "response": "def install(self, opener):\n        # type: (Union[Type[Opener], Opener, Callable[[], Opener]]) -> None\n        \"\"\"Install an opener.\n\n        Arguments:\n            opener (`Opener`): an `Opener` instance, or a callable that\n                returns an opener instance.\n\n        Note:\n            May be used as a class decorator. For example::\n                registry = Registry()\n                @registry.install\n                class ArchiveOpener(Opener):\n                    protocols = ['zip', 'tar']\n        \"\"\"\n        _opener = opener if isinstance(opener, Opener) else opener()\n        assert isinstance(_opener, Opener), \"Opener instance required\"\n        assert _opener.protocols, \"must list one or more protocols\"\n        for protocol in _opener.protocols:\n            self._protocols[protocol] = _opener\n        return opener"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of supported protocols.", "response": "def protocols(self):\n        # type: () -> List[Text]\n        \"\"\"`list`: the list of supported protocols.\n        \"\"\"\n\n        _protocols = list(self._protocols)\n        if self.load_extern:\n            _protocols.extend(\n                entry_point.name\n                for entry_point in pkg_resources.iter_entry_points(\"fs.opener\")\n            )\n            _protocols = list(collections.OrderedDict.fromkeys(_protocols))\n        return _protocols"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the Opener class associated to a given filesystem protocol.", "response": "def get_opener(self, protocol):\n        # type: (Text) -> Opener\n        \"\"\"Get the opener class associated to a given protocol.\n\n        Arguments:\n            protocol (str): A filesystem protocol.\n\n        Returns:\n            Opener: an opener instance.\n\n        Raises:\n            ~fs.opener.errors.UnsupportedProtocol: If no opener\n                could be found for the given protocol.\n            EntryPointLoadingError: If the returned entry point\n                is not an `Opener` subclass or could not be loaded\n                successfully.\n\n        \"\"\"\n        protocol = protocol or self.default_opener\n\n        if self.load_extern:\n            entry_point = next(\n                pkg_resources.iter_entry_points(\"fs.opener\", protocol), None\n            )\n        else:\n            entry_point = None\n\n        # If not entry point was loaded from the extensions, try looking\n        # into the registered protocols\n        if entry_point is None:\n            if protocol in self._protocols:\n                opener_instance = self._protocols[protocol]\n            else:\n                raise UnsupportedProtocol(\n                    \"protocol '{}' is not supported\".format(protocol)\n                )\n\n        # If an entry point was found in an extension, attempt to load it\n        else:\n            try:\n                opener = entry_point.load()\n            except Exception as exception:\n                raise EntryPointError(\n                    \"could not load entry point; {}\".format(exception)\n                )\n            if not issubclass(opener, Opener):\n                raise EntryPointError(\"entry point did not return an opener\")\n\n            try:\n                opener_instance = opener()\n            except Exception as exception:\n                raise EntryPointError(\n                    \"could not instantiate opener; {}\".format(exception)\n                )\n\n        return opener_instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen a filesystem from a URL.", "response": "def open(\n        self,\n        fs_url,  # type: Text\n        writeable=True,  # type: bool\n        create=False,  # type: bool\n        cwd=\".\",  # type: Text\n        default_protocol=\"osfs\",  # type: Text\n    ):\n        # type: (...) -> Tuple[FS, Text]\n        \"\"\"Open a filesystem from a FS URL.\n\n        Returns a tuple of a filesystem object and a path. If there is\n        no path in the FS URL, the path value will be `None`.\n\n        Arguments:\n            fs_url (str): A filesystem URL.\n            writeable (bool, optional): `True` if the filesystem must be\n                writeable.\n            create (bool, optional): `True` if the filesystem should be\n                created if it does not exist.\n            cwd (str): The current working directory.\n\n        Returns:\n            (FS, str): a tuple of ``(<filesystem>, <path from url>)``\n\n        \"\"\"\n        if \"://\" not in fs_url:\n            # URL may just be a path\n            fs_url = \"{}://{}\".format(default_protocol, fs_url)\n\n        parse_result = parse_fs_url(fs_url)\n        protocol = parse_result.protocol\n        open_path = parse_result.path\n\n        opener = self.get_opener(protocol)\n\n        open_fs = opener.open_fs(fs_url, parse_result, writeable, create, cwd)\n        return open_fs, open_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens a filesystem from a URL.", "response": "def open_fs(\n        self,\n        fs_url,  # type: Union[FS, Text]\n        writeable=False,  # type: bool\n        create=False,  # type: bool\n        cwd=\".\",  # type: Text\n        default_protocol=\"osfs\",  # type: Text\n    ):\n        # type: (...) -> FS\n        \"\"\"Open a filesystem from a FS URL (ignoring the path component).\n\n        Arguments:\n            fs_url (str): A filesystem URL.\n            writeable (bool, optional): `True` if the filesystem must\n                be writeable.\n            create (bool, optional): `True` if the filesystem should be\n                created if it does not exist.\n            cwd (str): The current working directory (generally only\n                relevant for OS filesystems).\n            default_protocol (str): The protocol to use if one is not\n                supplied in the FS URL (defaults to ``\"osfs\"``).\n\n        Returns:\n            ~fs.base.FS: A filesystem instance.\n\n        \"\"\"\n        from ..base import FS\n\n        if isinstance(fs_url, FS):\n            _fs = fs_url\n        else:\n            _fs, _path = self.open(\n                fs_url,\n                writeable=writeable,\n                create=create,\n                cwd=cwd,\n                default_protocol=default_protocol,\n            )\n        return _fs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening and close a filesystem.", "response": "def manage_fs(\n        self,\n        fs_url,  # type: Union[FS, Text]\n        create=False,  # type: bool\n        writeable=False,  # type: bool\n        cwd=\".\",  # type: Text\n    ):\n        # type: (...) -> Iterator[FS]\n        \"\"\"Get a context manager to open and close a filesystem.\n\n        Arguments:\n            fs_url (FS or str): A filesystem instance or a FS URL.\n            create (bool, optional): If `True`, then create the filesystem if\n                it doesn't already exist.\n            writeable (bool, optional): If `True`, then the filesystem\n                must be writeable.\n            cwd (str): The current working directory, if opening a\n                `~fs.osfs.OSFS`.\n\n        Sometimes it is convenient to be able to pass either a FS object\n        *or* an FS URL to a function. This context manager handles the\n        required logic for that.\n\n        Example:\n            >>> def print_ls(list_fs):\n            ...     '''List a directory.'''\n            ...     with manage_fs(list_fs) as fs:\n            ...         print(' '.join(fs.listdir()))\n\n            This function may be used in two ways. You may either pass\n            a ``str``, as follows::\n\n                >>> print_list('zip://projects.zip')\n\n            Or, an filesystem instance::\n\n                >>> from fs.osfs import OSFS\n                >>> projects_fs = OSFS('~/')\n                >>> print_list(projects_fs)\n\n        \"\"\"\n        from ..base import FS\n\n        if isinstance(fs_url, FS):\n            yield fs_url\n        else:\n            _fs = self.open_fs(fs_url, create=create, writeable=writeable, cwd=cwd)\n            try:\n                yield _fs\n            except:\n                raise\n            finally:\n                _fs.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_fs(\n    src_fs,  # type: Union[FS, Text]\n    dst_fs,  # type: Union[FS, Text]\n    walker=None,  # type: Optional[Walker]\n    on_copy=None,  # type: Optional[_OnCopy]\n    workers=0,  # type: int\n):\n    # type: (...) -> None\n    \"\"\"Copy the contents of one filesystem to another.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (URL or instance).\n        dst_fs (FS or str): Destination filesystem (URL or instance).\n        walker (~fs.walk.Walker, optional): A walker object that will be\n            used to scan for files in ``src_fs``. Set this if you only want\n            to consider a sub-set of the resources in ``src_fs``.\n        on_copy (callable): A function callback called after a single file copy\n            is executed. Expected signature is ``(src_fs, src_path, dst_fs,\n            dst_path)``.\n        workers (int): Use `worker` threads to copy data, or ``0`` (default) for\n            a single-threaded copy.\n\n    \"\"\"\n    return copy_dir(\n        src_fs, \"/\", dst_fs, \"/\", walker=walker, on_copy=on_copy, workers=workers\n    )", "response": "Copy the contents of one filesystem to another."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy the contents of one filesystem to another checking times.", "response": "def copy_fs_if_newer(\n    src_fs,  # type: Union[FS, Text]\n    dst_fs,  # type: Union[FS, Text]\n    walker=None,  # type: Optional[Walker]\n    on_copy=None,  # type: Optional[_OnCopy]\n    workers=0,  # type: int\n):\n    # type: (...) -> None\n    \"\"\"Copy the contents of one filesystem to another, checking times.\n\n    If both source and destination files exist, the copy is executed\n    only if the source file is newer than the destination file. In case\n    modification times of source or destination files are not available,\n    copy file is always executed.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (URL or instance).\n        dst_fs (FS or str): Destination filesystem (URL or instance).\n        walker (~fs.walk.Walker, optional): A walker object that will be\n            used to scan for files in ``src_fs``. Set this if you only want\n            to consider a sub-set of the resources in ``src_fs``.\n        on_copy (callable):A function callback called after a single file copy\n            is executed. Expected signature is ``(src_fs, src_path, dst_fs,\n            dst_path)``.\n        workers (int): Use ``worker`` threads to copy data, or ``0`` (default) for\n            a single-threaded copy.\n\n    \"\"\"\n    return copy_dir_if_newer(\n        src_fs, \"/\", dst_fs, \"/\", walker=walker, on_copy=on_copy, workers=workers\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if source file is newer than destination file.", "response": "def _source_is_newer(src_fs, src_path, dst_fs, dst_path):\n    # type: (FS, Text, FS, Text) -> bool\n    \"\"\"Determine if source file is newer than destination file.\n\n    Arguments:\n        src_fs (FS): Source filesystem (instance or URL).\n        src_path (str): Path to a file on the source filesystem.\n        dst_fs (FS): Destination filesystem (instance or URL).\n        dst_path (str): Path to a file on the destination filesystem.\n\n    Returns:\n        bool: `True` if the source file is newer than the destination\n        file or file modification time cannot be determined, `False`\n        otherwise.\n\n    \"\"\"\n    try:\n        if dst_fs.exists(dst_path):\n            namespace = (\"details\", \"modified\")\n            src_modified = src_fs.getinfo(src_path, namespace).modified\n            if src_modified is not None:\n                dst_modified = dst_fs.getinfo(dst_path, namespace).modified\n                return dst_modified is None or src_modified > dst_modified\n        return True\n    except FSError:  # pragma: no cover\n        # todo: should log something here\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_file(\n    src_fs,  # type: Union[FS, Text]\n    src_path,  # type: Text\n    dst_fs,  # type: Union[FS, Text]\n    dst_path,  # type: Text\n):\n    # type: (...) -> None\n    \"\"\"Copy a file from one filesystem to another.\n\n    If the destination exists, and is a file, it will be first truncated.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (instance or URL).\n        src_path (str): Path to a file on the source filesystem.\n        dst_fs (FS or str): Destination filesystem (instance or URL).\n        dst_path (str): Path to a file on the destination filesystem.\n\n    \"\"\"\n    with manage_fs(src_fs, writeable=False) as _src_fs:\n        with manage_fs(dst_fs, create=True) as _dst_fs:\n            if _src_fs is _dst_fs:\n                # Same filesystem, so we can do a potentially optimized\n                # copy\n                _src_fs.copy(src_path, dst_path, overwrite=True)\n            else:\n                # Standard copy\n                with _src_fs.lock(), _dst_fs.lock():\n                    if _dst_fs.hassyspath(dst_path):\n                        with _dst_fs.openbin(dst_path, \"w\") as write_file:\n                            _src_fs.download(src_path, write_file)\n                    else:\n                        with _src_fs.openbin(src_path) as read_file:\n                            _dst_fs.upload(dst_path, read_file)", "response": "Copy a file from one filesystem to another."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_file_internal(\n    src_fs,  # type: FS\n    src_path,  # type: Text\n    dst_fs,  # type: FS\n    dst_path,  # type: Text\n):\n    # type: (...) -> None\n    \"\"\"Low level copy, that doesn't call manage_fs or lock.\n\n    If the destination exists, and is a file, it will be first truncated.\n\n    This method exists to optimize copying in loops. In general you\n    should prefer `copy_file`.\n\n    Arguments:\n        src_fs (FS): Source filesystem.\n        src_path (str): Path to a file on the source filesystem.\n        dst_fs (FS: Destination filesystem.\n        dst_path (str): Path to a file on the destination filesystem.\n\n    \"\"\"\n    if src_fs is dst_fs:\n        # Same filesystem, so we can do a potentially optimized\n        # copy\n        src_fs.copy(src_path, dst_path, overwrite=True)\n    elif dst_fs.hassyspath(dst_path):\n        with dst_fs.openbin(dst_path, \"w\") as write_file:\n            src_fs.download(src_path, write_file)\n    else:\n        with src_fs.openbin(src_path) as read_file:\n            dst_fs.upload(dst_path, read_file)", "response": "Copy a file from one filesystem to another."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_file_if_newer(\n    src_fs,  # type: Union[FS, Text]\n    src_path,  # type: Text\n    dst_fs,  # type: Union[FS, Text]\n    dst_path,  # type: Text\n):\n    # type: (...) -> bool\n    \"\"\"Copy a file from one filesystem to another, checking times.\n\n    If the destination exists, and is a file, it will be first truncated.\n    If both source and destination files exist, the copy is executed only\n    if the source file is newer than the destination file. In case\n    modification times of source or destination files are not available,\n    copy is always executed.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (instance or URL).\n        src_path (str): Path to a file on the source filesystem.\n        dst_fs (FS or str): Destination filesystem (instance or URL).\n        dst_path (str): Path to a file on the destination filesystem.\n\n    Returns:\n        bool: `True` if the file copy was executed, `False` otherwise.\n\n    \"\"\"\n    with manage_fs(src_fs, writeable=False) as _src_fs:\n        with manage_fs(dst_fs, create=True) as _dst_fs:\n            if _src_fs is _dst_fs:\n                # Same filesystem, so we can do a potentially optimized\n                # copy\n                if _source_is_newer(_src_fs, src_path, _dst_fs, dst_path):\n                    _src_fs.copy(src_path, dst_path, overwrite=True)\n                    return True\n                else:\n                    return False\n            else:\n                # Standard copy\n                with _src_fs.lock(), _dst_fs.lock():\n                    if _source_is_newer(_src_fs, src_path, _dst_fs, dst_path):\n                        copy_file_internal(_src_fs, src_path, _dst_fs, dst_path)\n                        return True\n                    else:\n                        return False", "response": "Copy a file from one filesystem to another checking times."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_structure(\n    src_fs,  # type: Union[FS, Text]\n    dst_fs,  # type: Union[FS, Text]\n    walker=None,  # type: Optional[Walker]\n):\n    # type: (...) -> None\n    \"\"\"Copy directories (but not files) from ``src_fs`` to ``dst_fs``.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (instance or URL).\n        dst_fs (FS or str): Destination filesystem (instance or URL).\n        walker (~fs.walk.Walker, optional): A walker object that will be\n            used to scan for files in ``src_fs``. Set this if you only\n            want to consider a sub-set of the resources in ``src_fs``.\n\n    \"\"\"\n    walker = walker or Walker()\n    with manage_fs(src_fs) as _src_fs:\n        with manage_fs(dst_fs, create=True) as _dst_fs:\n            with _src_fs.lock(), _dst_fs.lock():\n                for dir_path in walker.dirs(_src_fs):\n                    _dst_fs.makedir(dir_path, recreate=True)", "response": "Copy a tree from one filesystem to another."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_dir(\n    src_fs,  # type: Union[FS, Text]\n    src_path,  # type: Text\n    dst_fs,  # type: Union[FS, Text]\n    dst_path,  # type: Text\n    walker=None,  # type: Optional[Walker]\n    on_copy=None,  # type: Optional[_OnCopy]\n    workers=0,  # type: int\n):\n    # type: (...) -> None\n    \"\"\"Copy a directory from one filesystem to another.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (instance or URL).\n        src_path (str): Path to a directory on the source filesystem.\n        dst_fs (FS or str): Destination filesystem (instance or URL).\n        dst_path (str): Path to a directory on the destination filesystem.\n        walker (~fs.walk.Walker, optional): A walker object that will be\n            used to scan for files in ``src_fs``. Set this if you only\n            want to consider a sub-set of the resources in ``src_fs``.\n        on_copy (callable, optional):  A function callback called after\n            a single file copy is executed. Expected signature is\n            ``(src_fs, src_path, dst_fs, dst_path)``.\n        workers (int): Use ``worker`` threads to copy data, or ``0`` (default) for\n            a single-threaded copy.\n\n    \"\"\"\n    on_copy = on_copy or (lambda *args: None)\n    walker = walker or Walker()\n    _src_path = abspath(normpath(src_path))\n    _dst_path = abspath(normpath(dst_path))\n\n    def src():\n        return manage_fs(src_fs, writeable=False)\n\n    def dst():\n        return manage_fs(dst_fs, create=True)\n\n    from ._bulk import Copier\n\n    with src() as _src_fs, dst() as _dst_fs:\n        with _src_fs.lock(), _dst_fs.lock():\n            _thread_safe = is_thread_safe(_src_fs, _dst_fs)\n            with Copier(num_workers=workers if _thread_safe else 0) as copier:\n                _dst_fs.makedir(_dst_path, recreate=True)\n                for dir_path, dirs, files in walker.walk(_src_fs, _src_path):\n                    copy_path = combine(_dst_path, frombase(_src_path, dir_path))\n                    for info in dirs:\n                        _dst_fs.makedir(info.make_path(copy_path), recreate=True)\n                    for info in files:\n                        src_path = info.make_path(dir_path)\n                        dst_path = info.make_path(copy_path)\n                        copier.copy(_src_fs, src_path, _dst_fs, dst_path)\n                        on_copy(_src_fs, src_path, _dst_fs, dst_path)", "response": "Copy a directory from one filesystem to another."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy a directory from one filesystem to another.", "response": "def copy_dir_if_newer(\n    src_fs,  # type: Union[FS, Text]\n    src_path,  # type: Text\n    dst_fs,  # type: Union[FS, Text]\n    dst_path,  # type: Text\n    walker=None,  # type: Optional[Walker]\n    on_copy=None,  # type: Optional[_OnCopy]\n    workers=0,  # type: int\n):\n    # type: (...) -> None\n    \"\"\"Copy a directory from one filesystem to another, checking times.\n\n    If both source and destination files exist, the copy is executed only\n    if the source file is newer than the destination file. In case\n    modification times of source or destination files are not available,\n    copy is always executed.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (instance or URL).\n        src_path (str): Path to a directory on the source filesystem.\n        dst_fs (FS or str): Destination filesystem (instance or URL).\n        dst_path (str): Path to a directory on the destination filesystem.\n        walker (~fs.walk.Walker, optional): A walker object that will be\n            used to scan for files in ``src_fs``. Set this if you only\n            want to consider a sub-set of the resources in ``src_fs``.\n        on_copy (callable, optional):  A function callback called after\n            a single file copy is executed. Expected signature is\n            ``(src_fs, src_path, dst_fs, dst_path)``.\n        workers (int): Use ``worker`` threads to copy data, or ``0`` (default) for\n            a single-threaded copy.\n\n    \"\"\"\n    on_copy = on_copy or (lambda *args: None)\n    walker = walker or Walker()\n    _src_path = abspath(normpath(src_path))\n    _dst_path = abspath(normpath(dst_path))\n\n    def src():\n        return manage_fs(src_fs, writeable=False)\n\n    def dst():\n        return manage_fs(dst_fs, create=True)\n\n    from ._bulk import Copier\n\n    with src() as _src_fs, dst() as _dst_fs:\n        with _src_fs.lock(), _dst_fs.lock():\n            _thread_safe = is_thread_safe(_src_fs, _dst_fs)\n            with Copier(num_workers=workers if _thread_safe else 0) as copier:\n                _dst_fs.makedir(_dst_path, recreate=True)\n                namespace = (\"details\", \"modified\")\n                dst_state = {\n                    path: info\n                    for path, info in walker.info(_dst_fs, _dst_path, namespace)\n                    if info.is_file\n                }\n                src_state = [\n                    (path, info)\n                    for path, info in walker.info(_src_fs, _src_path, namespace)\n                ]\n                for dir_path, copy_info in src_state:\n                    copy_path = combine(_dst_path, frombase(_src_path, dir_path))\n                    if copy_info.is_dir:\n                        _dst_fs.makedir(copy_path, recreate=True)\n                    elif copy_info.is_file:\n                        # dst file is present, try to figure out if copy\n                        # is necessary\n                        try:\n                            src_modified = copy_info.modified\n                            dst_modified = dst_state[dir_path].modified\n                        except KeyError:\n                            do_copy = True\n                        else:\n                            do_copy = (\n                                src_modified is None\n                                or dst_modified is None\n                                or src_modified > dst_modified\n                            )\n\n                        if do_copy:\n                            copier.copy(_src_fs, dir_path, _dst_fs, copy_path)\n                            on_copy(_src_fs, dir_path, _dst_fs, copy_path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_ftp_error(error):\n    # type: (ftplib.Error) -> Tuple[Text, Text]\n    \"\"\"Extract code and message from ftp error.\"\"\"\n    code, _, message = text_type(error).partition(\" \")\n    return code, message", "response": "Extract code and message from ftp error."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening an ftp object for the file.", "response": "def _open_ftp(self):\n        # type: () -> FTP\n        \"\"\"Open an ftp object for the file.\"\"\"\n        ftp = self.fs._open_ftp()\n        ftp.voidcmd(str(\"TYPE I\"))\n        return ftp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_features(cls, feat_response):\n        # type: (Text) -> Dict[Text, Text]\n        \"\"\"Parse a dict of features from FTP feat response.\n        \"\"\"\n        features = {}\n        if feat_response.split(\"-\")[0] == \"211\":\n            for line in feat_response.splitlines():\n                if line.startswith(\" \"):\n                    key, _, value = line[1:].partition(\" \")\n                    features[key] = value\n        return features", "response": "Parse a dict of features from FTP feat response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _open_ftp(self):\n        # type: () -> FTP\n        \"\"\"Open a new ftp object.\n        \"\"\"\n        _ftp = FTP()\n        _ftp.set_debuglevel(0)\n        with ftp_errors(self):\n            _ftp.connect(self.host, self.port, self.timeout)\n            _ftp.login(self.user, self.passwd, self.acct)\n            self._features = {}\n            try:\n                feat_response = _decode(_ftp.sendcmd(\"FEAT\"), \"latin-1\")\n            except error_perm:  # pragma: no cover\n                self.encoding = \"latin-1\"\n            else:\n                self._features = self._parse_features(feat_response)\n                self.encoding = \"utf-8\" if \"UTF8\" in self._features else \"latin-1\"\n                if not PY2:\n                    _ftp.file = _ftp.sock.makefile(  # type: ignore\n                        \"r\", encoding=self.encoding\n                    )\n        _ftp.encoding = self.encoding\n        self._welcome = _ftp.welcome\n        return _ftp", "response": "Open a new ftp object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the FTP url this filesystem will open.", "response": "def ftp_url(self):\n        # type: () -> Text\n        \"\"\"Get the FTP url this filesystem will open.\"\"\"\n        url = (\n            \"ftp://{}\".format(self.host)\n            if self.port == 21\n            else \"ftp://{}:{}\".format(self.host, self.port)\n        )\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a time from an ftp directory listing.", "response": "def _parse_ftp_time(cls, time_text):\n        # type: (Text) -> Optional[int]\n        \"\"\"Parse a time from an ftp directory listing.\n        \"\"\"\n        try:\n            tm_year = int(time_text[0:4])\n            tm_month = int(time_text[4:6])\n            tm_day = int(time_text[6:8])\n            tm_hour = int(time_text[8:10])\n            tm_min = int(time_text[10:12])\n            tm_sec = int(time_text[12:14])\n        except ValueError:\n            return None\n        epoch_time = calendar.timegm(\n            (tm_year, tm_month, tm_day, tm_hour, tm_min, tm_sec)\n        )\n        return epoch_time"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_zip(\n    src_fs,  # type: FS\n    file,  # type: Union[Text, BinaryIO]\n    compression=zipfile.ZIP_DEFLATED,  # type: int\n    encoding=\"utf-8\",  # type: Text\n    walker=None,  # type: Optional[Walker]\n):\n    # type: (...) -> None\n    \"\"\"Write the contents of a filesystem to a zip file.\n\n    Arguments:\n        src_fs (~fs.base.FS): The source filesystem to compress.\n        file (str or io.IOBase): Destination file, may be a file name\n            or an open file object.\n        compression (int): Compression to use (one of the constants\n            defined in the `zipfile` module in the stdlib). Defaults\n            to `zipfile.ZIP_DEFLATED`.\n        encoding (str):\n             The encoding to use for filenames. The default is ``\"utf-8\"``,\n             use ``\"CP437\"`` if compatibility with WinZip is desired.\n        walker (~fs.walk.Walker, optional): A `Walker` instance, or `None`\n            to use default walker. You can use this to specify which files\n            you want to compress.\n\n    \"\"\"\n    _zip = zipfile.ZipFile(file, mode=\"w\", compression=compression, allowZip64=True)\n    walker = walker or Walker()\n    with _zip:\n        gen_walk = walker.info(src_fs, namespaces=[\"details\", \"stat\", \"access\"])\n        for path, info in gen_walk:\n            # Zip names must be relative, directory names must end\n            # with a slash.\n            zip_name = relpath(path + \"/\" if info.is_dir else path)\n            if not six.PY3:\n                # Python2 expects bytes filenames\n                zip_name = zip_name.encode(encoding, \"replace\")\n\n            if info.has_namespace(\"stat\"):\n                # If the file has a stat namespace, get the\n                # zip time directory from the stat structure\n                st_mtime = info.get(\"stat\", \"st_mtime\", None)\n                _mtime = time.localtime(st_mtime)\n                zip_time = _mtime[0:6]  # type: ZipTime\n            else:\n                # Otherwise, use the modified time from details\n                # namespace.\n                mt = info.modified or datetime.utcnow()\n                zip_time = (mt.year, mt.month, mt.day, mt.hour, mt.minute, mt.second)\n\n            # NOTE(@althonos): typeshed's `zipfile.py` on declares\n            #     ZipInfo.__init__ for Python < 3 ?!\n            zip_info = zipfile.ZipInfo(zip_name, zip_time)  # type: ignore\n\n            try:\n                if info.permissions is not None:\n                    zip_info.external_attr = info.permissions.mode << 16\n            except MissingInfoNamespace:\n                pass\n\n            if info.is_dir:\n                zip_info.external_attr |= 0x10\n                # This is how to record directories with zipfile\n                _zip.writestr(zip_info, b\"\")\n            else:\n                # Get a syspath if possible\n                try:\n                    sys_path = src_fs.getsyspath(path)\n                except NoSysPath:\n                    # Write from bytes\n                    _zip.writestr(zip_info, src_fs.readbytes(path))\n                else:\n                    # Write from a file which is (presumably)\n                    # more memory efficient\n                    _zip.write(sys_path, zip_name)", "response": "Writes the contents of a filesystem to a zip file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the contents of a filesystem to a tar file.", "response": "def write_tar(\n    src_fs,  # type: FS\n    file,  # type: Union[Text, BinaryIO]\n    compression=None,  # type: Optional[Text]\n    encoding=\"utf-8\",  # type: Text\n    walker=None,  # type: Optional[Walker]\n):\n    # type: (...) -> None\n    \"\"\"Write the contents of a filesystem to a tar file.\n\n    Arguments:\n        file (str or io.IOBase): Destination file, may be a file\n            name or an open file object.\n        compression (str, optional): Compression to use, or `None`\n            for a plain Tar archive without compression.\n        encoding(str): The encoding to use for filenames. The\n            default is ``\"utf-8\"``.\n        walker (~fs.walk.Walker, optional): A `Walker` instance, or\n            `None` to use default walker. You can use this to specify\n            which files you want to compress.\n\n    \"\"\"\n    type_map = {\n        ResourceType.block_special_file: tarfile.BLKTYPE,\n        ResourceType.character: tarfile.CHRTYPE,\n        ResourceType.directory: tarfile.DIRTYPE,\n        ResourceType.fifo: tarfile.FIFOTYPE,\n        ResourceType.file: tarfile.REGTYPE,\n        ResourceType.socket: tarfile.AREGTYPE,  # no type for socket\n        ResourceType.symlink: tarfile.SYMTYPE,\n        ResourceType.unknown: tarfile.AREGTYPE,  # no type for unknown\n    }\n\n    tar_attr = [(\"uid\", \"uid\"), (\"gid\", \"gid\"), (\"uname\", \"user\"), (\"gname\", \"group\")]\n\n    mode = \"w:{}\".format(compression or \"\")\n    if isinstance(file, (six.text_type, six.binary_type)):\n        _tar = tarfile.open(file, mode=mode)\n    else:\n        _tar = tarfile.open(fileobj=file, mode=mode)\n\n    current_time = time.time()\n    walker = walker or Walker()\n    with _tar:\n        gen_walk = walker.info(src_fs, namespaces=[\"details\", \"stat\", \"access\"])\n        for path, info in gen_walk:\n            # Tar names must be relative\n            tar_name = relpath(path)\n            if not six.PY3:\n                # Python2 expects bytes filenames\n                tar_name = tar_name.encode(encoding, \"replace\")\n\n            tar_info = tarfile.TarInfo(tar_name)\n\n            if info.has_namespace(\"stat\"):\n                mtime = info.get(\"stat\", \"st_mtime\", current_time)\n            else:\n                mtime = info.modified or current_time\n\n            if isinstance(mtime, datetime):\n                mtime = datetime_to_epoch(mtime)\n            if isinstance(mtime, float):\n                mtime = int(mtime)\n            tar_info.mtime = mtime\n\n            for tarattr, infoattr in tar_attr:\n                if getattr(info, infoattr, None) is not None:\n                    setattr(tar_info, tarattr, getattr(info, infoattr, None))\n\n            if info.has_namespace(\"access\"):\n                tar_info.mode = getattr(info.permissions, \"mode\", 0o420)\n\n            if info.is_dir:\n                tar_info.type = tarfile.DIRTYPE\n                _tar.addfile(tar_info)\n            else:\n                tar_info.type = type_map.get(info.type, tarfile.REGTYPE)\n                tar_info.size = info.size\n                with src_fs.openbin(path) as bin_file:\n                    _tar.addfile(tar_info, bin_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match(pattern, path):\n    # type: (str, str) -> bool\n    \"\"\"Compare a glob pattern with a path (case sensitive).\n\n    Arguments:\n        pattern (str): A glob pattern.\n        path (str): A path.\n\n    Returns:\n        bool: ``True`` if the path matches the pattern.\n\n    Example:\n\n        >>> from fs.glob import match\n        >>> match(\"**/*.py\", \"/fs/glob.py\")\n        True\n\n    \"\"\"\n    try:\n        levels, recursive, re_pattern = _PATTERN_CACHE[(pattern, True)]\n    except KeyError:\n        levels, recursive, re_pattern = _translate_glob(pattern, case_sensitive=True)\n        _PATTERN_CACHE[(pattern, True)] = (levels, recursive, re_pattern)\n    return bool(re_pattern.match(path))", "response": "Compare a glob pattern with a path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef count(self):\n        # type: () -> Counts\n        \"\"\"Count files / directories / data in matched paths.\n\n        Example:\n            >>> import fs\n            >>> fs.open_fs('~/projects').glob('**/*.py').count()\n            Counts(files=18519, directories=0, data=206690458)\n\n        Returns:\n            `~Counts`: A named tuple containing results.\n\n        \"\"\"\n        directories = 0\n        files = 0\n        data = 0\n        for path, info in self._make_iter(namespaces=[\"details\"]):\n            if info.is_dir:\n                directories += 1\n            else:\n                files += 1\n            data += info.size\n        return Counts(directories=directories, files=files, data=data)", "response": "Count the number of files directories and data in matched paths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncounting the lines in the matched files.", "response": "def count_lines(self):\n        # type: () -> LineCounts\n        \"\"\"Count the lines in the matched files.\n\n        Returns:\n            `~LineCounts`: A named tuple containing line counts.\n\n        Example:\n            >>> import fs\n            >>> fs.open_fs('~/projects').glob('**/*.py').count_lines()\n            LineCounts(lines=5767102, non_blank=4915110)\n\n        \"\"\"\n\n        lines = 0\n        non_blank = 0\n        for path, info in self._make_iter():\n            if info.is_file:\n                for line in self.fs.open(path, \"rb\"):\n                    lines += 1\n                    if line.rstrip():\n                        non_blank += 1\n        return LineCounts(lines=lines, non_blank=non_blank)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove all matched paths.", "response": "def remove(self):\n        # type: () -> int\n        \"\"\"Removed all matched paths.\n\n        Returns:\n            int: Number of file and directories removed.\n\n        Example:\n            >>> import fs\n            >>> fs.open_fs('~/projects/my_project').glob('**/*.pyc').remove()\n            29\n\n        \"\"\"\n        removes = 0\n        for path, info in self._make_iter(search=\"depth\"):\n            if info.is_dir:\n                self.fs.removetree(path)\n            else:\n                self.fs.remove(path)\n            removes += 1\n        return removes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef move_file(\n    src_fs,  # type: Union[Text, FS]\n    src_path,  # type: Text\n    dst_fs,  # type: Union[Text, FS]\n    dst_path,  # type: Text\n):\n    # type: (...) -> None\n    \"\"\"Move a file from one filesystem to another.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (instance or URL).\n        src_path (str): Path to a file on ``src_fs``.\n        dst_fs (FS or str); Destination filesystem (instance or URL).\n        dst_path (str): Path to a file on ``dst_fs``.\n\n    \"\"\"\n    with manage_fs(src_fs) as _src_fs:\n        with manage_fs(dst_fs, create=True) as _dst_fs:\n            if _src_fs is _dst_fs:\n                # Same filesystem, may be optimized\n                _src_fs.move(src_path, dst_path, overwrite=True)\n            else:\n                # Standard copy and delete\n                with _src_fs.lock(), _dst_fs.lock():\n                    copy_file(_src_fs, src_path, _dst_fs, dst_path)\n                    _src_fs.remove(src_path)", "response": "Move a file from one filesystem to another."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move_dir(\n    src_fs,  # type: Union[Text, FS]\n    src_path,  # type: Text\n    dst_fs,  # type: Union[Text, FS]\n    dst_path,  # type: Text\n    workers=0,  # type: int\n):\n    # type: (...) -> None\n    \"\"\"Move a directory from one filesystem to another.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (instance or URL).\n        src_path (str): Path to a directory on ``src_fs``\n        dst_fs (FS or str): Destination filesystem (instance or URL).\n        dst_path (str): Path to a directory on ``dst_fs``.\n        workers (int): Use `worker` threads to copy data, or ``0`` (default) for\n            a single-threaded copy.\n\n    \"\"\"\n\n    def src():\n        return manage_fs(src_fs, writeable=False)\n\n    def dst():\n        return manage_fs(dst_fs, create=True)\n\n    with src() as _src_fs, dst() as _dst_fs:\n        with _src_fs.lock(), _dst_fs.lock():\n            _dst_fs.makedir(dst_path, recreate=True)\n            copy_dir(src_fs, src_path, dst_fs, dst_path, workers=workers)\n            _src_fs.removetree(src_path)", "response": "Move a directory from one filesystem to another."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing a path. This function simplifies a path by collapsing back-references and removing duplicated separators. Arguments: path (str): Path to normalize. Returns: str: A valid FS path. Example: >>> normpath(\"/foo//bar/frob/../baz\") '/foo/bar/baz' >>> normpath(\"foo/../../bar\") Traceback (most recent call last) ... IllegalBackReference: path 'foo/../../bar' contains back-references outside of filesystem\"", "response": "def normpath(path):\n    # type: (Text) -> Text\n    \"\"\"Normalize a path.\n\n    This function simplifies a path by collapsing back-references\n    and removing duplicated separators.\n\n    Arguments:\n        path (str): Path to normalize.\n\n    Returns:\n        str: A valid FS path.\n\n    Example:\n        >>> normpath(\"/foo//bar/frob/../baz\")\n        '/foo/bar/baz'\n        >>> normpath(\"foo/../../bar\")\n        Traceback (most recent call last)\n            ...\n        IllegalBackReference: path 'foo/../../bar' contains back-references outside of filesystem\"\n\n    \"\"\"\n    if path in \"/\":\n        return path\n\n    # An early out if there is no need to normalize this path\n    if not _requires_normalization(path):\n        return path.rstrip(\"/\")\n\n    prefix = \"/\" if path.startswith(\"/\") else \"\"\n    components = []  # type: List[Text]\n    try:\n        for component in path.split(\"/\"):\n            if component in \"..\":  # True for '..', '.', and ''\n                if component == \"..\":\n                    components.pop()\n            else:\n                components.append(component)\n    except IndexError:\n        raise IllegalBackReference(path)\n    return prefix + \"/\".join(components)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recursepath(path, reverse=False):\n    # type: (Text, bool) -> List[Text]\n    \"\"\"Get intermediate paths from the root to the given path.\n\n    Arguments:\n        path (str): A PyFilesystem path\n        reverse (bool): Reverses the order of the paths\n            (default `False`).\n\n    Returns:\n        list: A list of paths.\n\n    Example:\n        >>> recursepath('a/b/c')\n        ['/', '/a', '/a/b', '/a/b/c']\n\n    \"\"\"\n    if path in \"/\":\n        return [\"/\"]\n\n    path = abspath(normpath(path)) + \"/\"\n\n    paths = [\"/\"]\n    find = path.find\n    append = paths.append\n    pos = 1\n    len_path = len(path)\n\n    while pos < len_path:\n        pos = find(\"/\", pos)\n        append(path[:pos])\n        pos += 1\n\n    if reverse:\n        return paths[::-1]\n    return paths", "response": "Recursively finds intermediate paths from the root to the given path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef join(*paths):\n    # type: (*Text) -> Text\n    \"\"\"Join any number of paths together.\n\n    Arguments:\n        *paths (str): Paths to join, given as positional arguments.\n\n    Returns:\n        str: The joined path.\n\n    Example:\n        >>> join('foo', 'bar', 'baz')\n        'foo/bar/baz'\n        >>> join('foo/bar', '../baz')\n        'foo/baz'\n        >>> join('foo/bar', '/baz')\n        '/baz'\n\n    \"\"\"\n    absolute = False\n    relpaths = []  # type: List[Text]\n    for p in paths:\n        if p:\n            if p[0] == \"/\":\n                del relpaths[:]\n                absolute = True\n            relpaths.append(p)\n\n    path = normpath(\"/\".join(relpaths))\n    if absolute:\n        path = abspath(path)\n    return path", "response": "Joins any number of paths together."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncombine two paths together.", "response": "def combine(path1, path2):\n    # type: (Text, Text) -> Text\n    \"\"\"Join two paths together.\n\n    This is faster than :func:`~fs.path.join`, but only works when the\n    second path is relative, and there are no back references in either\n    path.\n\n    Arguments:\n        path1 (str): A PyFilesytem path.\n        path2 (str): A PyFilesytem path.\n\n    Returns:\n        str: The joint path.\n\n    Example:\n        >>> combine(\"foo/bar\", \"baz\")\n        'foo/bar/baz'\n\n    \"\"\"\n    if not path1:\n        return path2.lstrip()\n    return \"{}/{}\".format(path1.rstrip(\"/\"), path2.lstrip(\"/\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parts(path):\n    # type: (Text) -> List[Text]\n    \"\"\"Split a path in to its component parts.\n\n    Arguments:\n        path (str): Path to split in to parts.\n\n    Returns:\n        list: List of components\n\n    Example:\n        >>> parts('/foo/bar/baz')\n        ['/', 'foo', 'bar', 'baz']\n\n    \"\"\"\n    _path = normpath(path)\n    components = _path.strip(\"/\")\n\n    _parts = [\"/\" if _path.startswith(\"/\") else \"./\"]\n    if components:\n        _parts += components.split(\"/\")\n    return _parts", "response": "Split a path in to its component parts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef splitext(path):\n    # type: (Text) -> Tuple[Text, Text]\n    \"\"\"Split the extension from the path.\n\n    Arguments:\n        path (str): A path to split.\n\n    Returns:\n        (str, str): A tuple containing the path and the extension.\n\n    Example:\n        >>> splitext('baz.txt')\n        ('baz', '.txt')\n        >>> splitext('foo/bar/baz.txt')\n        ('foo/bar/baz', '.txt')\n        >>> splitext('foo/bar/.foo')\n        ('foo/bar/.foo', '')\n\n    \"\"\"\n    parent_path, pathname = split(path)\n    if pathname.startswith(\".\") and pathname.count(\".\") == 1:\n        return path, \"\"\n    if \".\" not in pathname:\n        return path, \"\"\n    pathname, ext = pathname.rsplit(\".\", 1)\n    path = join(parent_path, pathname)\n    return path, \".\" + ext", "response": "Splits the extension from the path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if path1 is a base of path2.", "response": "def isbase(path1, path2):\n    # type: (Text, Text) -> bool\n    \"\"\"Check if ``path1`` is a base of ``path2``.\n\n    Arguments:\n        path1 (str): A PyFilesytem path.\n        path2 (str): A PyFilesytem path.\n\n    Returns:\n        bool: `True` if ``path2`` starts with ``path1``\n\n    Example:\n        >>> isbase('foo/bar', 'foo/bar/baz/egg.txt')\n        True\n\n    \"\"\"\n    _path1 = forcedir(abspath(path1))\n    _path2 = forcedir(abspath(path2))\n    return _path2.startswith(_path1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if path1 is a parent directory of path2.", "response": "def isparent(path1, path2):\n    # type: (Text, Text) -> bool\n    \"\"\"Check if ``path1`` is a parent directory of ``path2``.\n\n    Arguments:\n        path1 (str): A PyFilesytem path.\n        path2 (str): A PyFilesytem path.\n\n    Returns:\n        bool: `True` if ``path1`` is a parent directory of ``path2``\n\n    Example:\n        >>> isparent(\"foo/bar\", \"foo/bar/spam.txt\")\n        True\n        >>> isparent(\"foo/bar/\", \"foo/bar\")\n        True\n        >>> isparent(\"foo/barry\", \"foo/baz/bar\")\n        False\n        >>> isparent(\"foo/bar/baz/\", \"foo/baz/bar\")\n        False\n\n    \"\"\"\n    bits1 = path1.split(\"/\")\n    bits2 = path2.split(\"/\")\n    while bits1 and bits1[-1] == \"\":\n        bits1.pop()\n    if len(bits1) > len(bits2):\n        return False\n    for (bit1, bit2) in zip(bits1, bits2):\n        if bit1 != bit2:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef frombase(path1, path2):\n    # type: (Text, Text) -> Text\n    \"\"\"Get the final path of ``path2`` that isn't in ``path1``.\n\n    Arguments:\n        path1 (str): A PyFilesytem path.\n        path2 (str): A PyFilesytem path.\n\n    Returns:\n        str: the final part of ``path2``.\n\n    Example:\n        >>> frombase('foo/bar/', 'foo/bar/baz/egg')\n        'baz/egg'\n\n    \"\"\"\n    if not isparent(path1, path2):\n        raise ValueError(\"path1 must be a prefix of path2\")\n    return path2[len(path1) :]", "response": "Returns the final part of path2 that isn t in path1."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef relativefrom(base, path):\n    # type: (Text, Text) -> Text\n    \"\"\"Return a path relative from a given base path.\n\n    Insert backrefs as appropriate to reach the path from the base.\n\n    Arguments:\n        base (str): Path to a directory.\n        path (str): Path to make relative.\n\n    Returns:\n        str: the path to ``base`` from ``path``.\n\n    >>> relativefrom(\"foo/bar\", \"baz/index.html\")\n    '../../baz/index.html'\n\n    \"\"\"\n    base_parts = list(iteratepath(base))\n    path_parts = list(iteratepath(path))\n\n    common = 0\n    for component_a, component_b in zip(base_parts, path_parts):\n        if component_a != component_b:\n            break\n        common += 1\n\n    return \"/\".join([\"..\"] * (len(base_parts) - common) + path_parts[common:])", "response": "Return a path relative from a given base path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unwrap_errors(path_replace):\n    # type: (Union[Text, Mapping[Text, Text]]) -> Iterator[None]\n    \"\"\"Get a context to map OS errors to their `fs.errors` counterpart.\n\n    The context will re-write the paths in resource exceptions to be\n    in the same context as the wrapped filesystem.\n\n    The only parameter may be the path from the parent, if only one path\n    is to be unwrapped. Or it may be a dictionary that maps wrapped\n    paths on to unwrapped paths.\n\n    \"\"\"\n    try:\n        yield\n    except errors.ResourceError as e:\n        if hasattr(e, \"path\"):\n            if isinstance(path_replace, Mapping):\n                e.path = path_replace.get(e.path, e.path)\n            else:\n                e.path = path_replace\n        reraise(type(e), e)", "response": "Get a context to map OS errors to their fs. errors counterpart."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode_windowsnt(line, match):\n    is_dir = match.group(\"size\") == \"<DIR>\"\n\n    raw_info = {\n        \"basic\": {\n            \"name\": match.group(\"name\"),\n            \"is_dir\": is_dir,\n        },\n        \"details\": {\n            \"type\": int(ResourceType.directory if is_dir else ResourceType.file),\n        },\n        \"ftp\": {\"ls\": line},\n    }\n\n    if not is_dir:\n        raw_info[\"details\"][\"size\"] = int(match.group(\"size\"))\n\n    modified = _parse_time(match.group(\"modified\"), formats=[\"%d-%m-%y %I:%M%p\"])\n    if modified is not None:\n        raw_info[\"details\"][\"modified\"] = modified\n\n    return raw_info", "response": "Decodes a Windows NT FTP LIST line like these two"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting whether a filename matches a wildcard pattern.", "response": "def match(pattern, name):\n    # type: (Text, Text) -> bool\n    \"\"\"Test whether a name matches a wildcard pattern.\n\n    Arguments:\n        pattern (str): A wildcard pattern, e.g. ``\"*.py\"``.\n        name (str): A filename.\n\n    Returns:\n        bool: `True` if the filename matches the pattern.\n\n    \"\"\"\n    try:\n        re_pat = _PATTERN_CACHE[(pattern, True)]\n    except KeyError:\n        res = \"(?ms)\" + _translate(pattern) + r'\\Z'\n        _PATTERN_CACHE[(pattern, True)] = re_pat = re.compile(res)\n    return re_pat.match(name) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest whether a filename matches a wildcard pattern.", "response": "def imatch(pattern, name):\n    # type: (Text, Text) -> bool\n    \"\"\"Test whether a name matches a wildcard pattern (case insensitive).\n\n    Arguments:\n        pattern (str): A wildcard pattern, e.g. ``\"*.py\"``.\n        name (bool): A filename.\n\n    Returns:\n        bool: `True` if the filename matches the pattern.\n\n    \"\"\"\n    try:\n        re_pat = _PATTERN_CACHE[(pattern, False)]\n    except KeyError:\n        res = \"(?ms)\" + _translate(pattern, case_sensitive=False) + r'\\Z'\n        _PATTERN_CACHE[(pattern, False)] = re_pat = re.compile(res, re.IGNORECASE)\n    return re_pat.match(name) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef match_any(patterns, name):\n    # type: (Iterable[Text], Text) -> bool\n    \"\"\"Test if a name matches any of a list of patterns.\n\n    Will return `True` if ``patterns`` is an empty list.\n\n    Arguments:\n        patterns (list): A list of wildcard pattern, e.g ``[\"*.py\",\n            \"*.pyc\"]``\n        name (str): A filename.\n\n    Returns:\n        bool: `True` if the name matches at least one of the patterns.\n\n    \"\"\"\n    if not patterns:\n        return True\n    return any(match(pattern, name) for pattern in patterns)", "response": "Test if a name matches any of a list of patterns."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef imatch_any(patterns, name):\n    # type: (Iterable[Text], Text) -> bool\n    \"\"\"Test if a name matches any of a list of patterns (case insensitive).\n\n    Will return `True` if ``patterns`` is an empty list.\n\n    Arguments:\n        patterns (list): A list of wildcard pattern, e.g ``[\"*.py\",\n            \"*.pyc\"]``\n        name (str): A filename.\n\n    Returns:\n        bool: `True` if the name matches at least one of the patterns.\n\n    \"\"\"\n    if not patterns:\n        return True\n    return any(imatch(pattern, name) for pattern in patterns)", "response": "Test if a name matches any of a list of patterns ( case insensitive."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a callable that matches names against the given patterns.", "response": "def get_matcher(patterns, case_sensitive):\n    # type: (Iterable[Text], bool) -> Callable[[Text], bool]\n    \"\"\"Get a callable that matches names against the given patterns.\n\n    Arguments:\n        patterns (list): A list of wildcard pattern. e.g. ``[\"*.py\",\n            \"*.pyc\"]``\n        case_sensitive (bool): If ``True``, then the callable will be case\n            sensitive, otherwise it will be case insensitive.\n\n    Returns:\n        callable: a matcher that will return `True` if the name given as\n        an argument matches any of the given patterns.\n\n    Example:\n        >>> from fs import wildcard\n        >>> is_python = wildcard.get_matcher(['*.py'], True)\n        >>> is_python('__init__.py')\n        True\n        >>> is_python('foo.txt')\n        False\n\n    \"\"\"\n    if not patterns:\n        return lambda name: True\n    if case_sensitive:\n        return partial(match_any, patterns)\n    else:\n        return partial(imatch_any, patterns)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _translate(pattern, case_sensitive=True):\n    # type: (Text, bool) -> Text\n    \"\"\"Translate a wildcard pattern to a regular expression.\n\n    There is no way to quote meta-characters.\n\n    Arguments:\n        pattern (str): A wildcard pattern.\n        case_sensitive (bool): Set to `False` to use a case\n            insensitive regex (default `True`).\n\n    Returns:\n        str: A regex equivalent to the given pattern.\n\n    \"\"\"\n    if not case_sensitive:\n        pattern = pattern.lower()\n    i, n = 0, len(pattern)\n    res = \"\"\n    while i < n:\n        c = pattern[i]\n        i = i + 1\n        if c == \"*\":\n            res = res + \"[^/]*\"\n        elif c == \"?\":\n            res = res + \".\"\n        elif c == \"[\":\n            j = i\n            if j < n and pattern[j] == \"!\":\n                j = j + 1\n            if j < n and pattern[j] == \"]\":\n                j = j + 1\n            while j < n and pattern[j] != \"]\":\n                j = j + 1\n            if j >= n:\n                res = res + \"\\\\[\"\n            else:\n                stuff = pattern[i:j].replace(\"\\\\\", \"\\\\\\\\\")\n                i = j + 1\n                if stuff[0] == \"!\":\n                    stuff = \"^\" + stuff[1:]\n                elif stuff[0] == \"^\":\n                    stuff = \"\\\\\" + stuff\n                res = \"%s[%s]\" % (res, stuff)\n        else:\n            res = res + re.escape(c)\n    return res", "response": "Translate a wildcard pattern to a regular expression."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _delegate(self, path):\n        # type: (Text) -> Tuple[FS, Text]\n        \"\"\"Get the delegate FS for a given path.\n\n        Arguments:\n            path (str): A path.\n\n        Returns:\n            (FS, str): a tuple of ``(<fs>, <path>)`` for a mounted filesystem,\n            or ``(None, None)`` if no filesystem is mounted on the\n            given ``path``.\n\n        \"\"\"\n        _path = forcedir(abspath(normpath(path)))\n        is_mounted = _path.startswith\n\n        for mount_path, fs in self.mounts:\n            if is_mounted(mount_path):\n                return fs, _path[len(mount_path) :].rstrip(\"/\")\n\n        return self.default_fs, path", "response": "Returns the delegate FS for a given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mount(self, path, fs):\n        # type: (Text, Union[FS, Text]) -> None\n        \"\"\"Mounts a host FS object on a given path.\n\n        Arguments:\n            path (str): A path within the MountFS.\n            fs (FS or str): A filesystem (instance or URL) to mount.\n\n        \"\"\"\n        if isinstance(fs, text_type):\n            from .opener import open_fs\n\n            fs = open_fs(fs)\n\n        if not isinstance(fs, FS):\n            raise TypeError(\"fs argument must be an FS object or a FS URL\")\n\n        if fs is self:\n            raise ValueError(\"Unable to mount self\")\n        _path = forcedir(abspath(normpath(path)))\n\n        for mount_path, _ in self.mounts:\n            if _path.startswith(mount_path):\n                raise MountError(\"mount point overlaps existing mount\")\n\n        self.mounts.append((_path, fs))\n        self.default_fs.makedirs(_path, recreate=True)", "response": "Mounts a host FS object on a given path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping the workers (will block until they are finished).", "response": "def stop(self):\n        \"\"\"Stop the workers (will block until they are finished).\"\"\"\n        if self.running and self.num_workers:\n            for worker in self.workers:\n                self.queue.put(None)\n            for worker in self.workers:\n                worker.join()\n            # Free up references held by workers\n            del self.workers[:]\n            self.queue.join()\n        self.running = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self, src_fs, src_path, dst_fs, dst_path):\n        # type: (FS, Text, FS, Text) -> None\n        \"\"\"Copy a file from one fs to another.\"\"\"\n        if self.queue is None:\n            # This should be the most performant for a single-thread\n            copy_file_internal(src_fs, src_path, dst_fs, dst_path)\n        else:\n            src_file = src_fs.openbin(src_path, \"r\")\n            try:\n                dst_file = dst_fs.openbin(dst_path, \"w\")\n            except Exception:\n                src_file.close()\n                raise\n            task = _CopyTask(src_file, dst_file)\n            self.queue.put(task)", "response": "Copy a file from one fs to another."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a filesystem to the MultiFS.", "response": "def add_fs(self, name, fs, write=False, priority=0):\n        # type: (Text, FS, bool, int) -> None\n        \"\"\"Add a filesystem to the MultiFS.\n\n        Arguments:\n            name (str): A unique name to refer to the filesystem being\n                added.\n            fs (FS or str): The filesystem (instance or URL) to add.\n            write (bool): If this value is True, then the ``fs`` will\n                be used as the writeable FS (defaults to False).\n            priority (int): An integer that denotes the priority of the\n                filesystem being added. Filesystems will be searched in\n                descending priority order and then by the reverse order\n                they were added. So by default, the most recently added\n                filesystem will be looked at first.\n\n        \"\"\"\n        if isinstance(fs, text_type):\n            fs = open_fs(fs)\n\n        if not isinstance(fs, FS):\n            raise TypeError(\"fs argument should be an FS object or FS URL\")\n\n        self._filesystems[name] = _PrioritizedFS(\n            priority=(priority, self._sort_index), fs=fs\n        )\n        self._sort_index += 1\n        self._resort()\n\n        if write:\n            self.write_fs = fs\n            self._write_fs_name = name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iterate_fs(self):\n        # type: () -> Iterator[Tuple[Text, FS]]\n        \"\"\"Get iterator that returns (name, fs) in priority order.\n        \"\"\"\n        if self._fs_sequence is None:\n            self._fs_sequence = [\n                (name, fs)\n                for name, (_order, fs) in sorted(\n                    self._filesystems.items(), key=itemgetter(1), reverse=True\n                )\n            ]\n        return iter(self._fs_sequence)", "response": "Get iterator that returns ( name fs ) in priority order."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _delegate(self, path):\n        # type: (Text) -> Optional[FS]\n        \"\"\"Get a filesystem which has a given path.\n        \"\"\"\n        for _name, fs in self.iterate_fs():\n            if fs.exists(path):\n                return fs\n        return None", "response": "Get a filesystem which has a given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _delegate_required(self, path):\n        # type: (Text) -> FS\n        \"\"\"Check that there is a filesystem with the given ``path``.\n        \"\"\"\n        fs = self._delegate(path)\n        if fs is None:\n            raise errors.ResourceNotFound(path)\n        return fs", "response": "Check that there is a filesystem with the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _writable_required(self, path):\n        # type: (Text) -> FS\n        \"\"\"Check that ``path`` is writeable.\n        \"\"\"\n        if self.write_fs is None:\n            raise errors.ResourceReadOnly(path)\n        return self.write_fs", "response": "Check that path is writeable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef which(self, path, mode=\"r\"):\n        # type: (Text, Text) -> Tuple[Optional[Text], Optional[FS]]\n        \"\"\"Get a tuple of (name, fs) that the given path would map to.\n\n        Arguments:\n            path (str): A path on the filesystem.\n            mode (str): An `io.open` mode.\n\n        \"\"\"\n        if check_writable(mode):\n            return self._write_fs_name, self.write_fs\n        for name, fs in self.iterate_fs():\n            if fs.exists(path):\n                return name, fs\n        return None, None", "response": "Returns a tuple of the name and filesystem that the given path would map to."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_stream(\n    name,  # type: Text\n    bin_file,  # type: RawIOBase\n    mode=\"r\",  # type: Text\n    buffering=-1,  # type: int\n    encoding=None,  # type: Optional[Text]\n    errors=None,  # type: Optional[Text]\n    newline=\"\",  # type: Optional[Text]\n    line_buffering=False,  # type: bool\n    **kwargs  # type: Any\n):\n    # type: (...) -> IO\n    \"\"\"Take a Python 2.x binary file and return an IO Stream.\n    \"\"\"\n    reading = \"r\" in mode\n    writing = \"w\" in mode\n    appending = \"a\" in mode\n    binary = \"b\" in mode\n    if \"+\" in mode:\n        reading = True\n        writing = True\n\n    encoding = None if binary else (encoding or \"utf-8\")\n\n    io_object = RawWrapper(bin_file, mode=mode, name=name)  # type: io.IOBase\n    if buffering >= 0:\n        if reading and writing:\n            io_object = io.BufferedRandom(\n                typing.cast(io.RawIOBase, io_object),\n                buffering or io.DEFAULT_BUFFER_SIZE,\n            )\n        elif reading:\n            io_object = io.BufferedReader(\n                typing.cast(io.RawIOBase, io_object),\n                buffering or io.DEFAULT_BUFFER_SIZE,\n            )\n        elif writing or appending:\n            io_object = io.BufferedWriter(\n                typing.cast(io.RawIOBase, io_object),\n                buffering or io.DEFAULT_BUFFER_SIZE,\n            )\n\n    if not binary:\n        io_object = io.TextIOWrapper(\n            io_object,\n            encoding=encoding,\n            errors=errors,\n            newline=newline,\n            line_buffering=line_buffering,\n        )\n\n    return io_object", "response": "Takes a Python 2. x binary file and returns an IO Stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the lines of a file.", "response": "def line_iterator(readable_file, size=None):\n    # type: (IO[bytes], Optional[int]) -> Iterator[bytes]\n    \"\"\"Iterate over the lines of a file.\n\n    Implementation reads each char individually, which is not very\n    efficient.\n\n    Yields:\n        str: a single line in the file.\n\n    \"\"\"\n    read = readable_file.read\n    line = []\n    byte = b\"1\"\n    if size is None or size < 0:\n        while byte:\n            byte = read(1)\n            line.append(byte)\n            if byte in b\"\\n\":\n                yield b\"\".join(line)\n                del line[:]\n\n    else:\n        while byte and size:\n            byte = read(1)\n            size -= len(byte)\n            line.append(byte)\n            if byte in b\"\\n\" or not size:\n                yield b\"\".join(line)\n                del line[:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that mode parameter of ~fs. base. FS. openbin is valid.", "response": "def validate_openbin_mode(mode, _valid_chars=frozenset(\"rwxab+\")):\n    # type: (Text, Union[Set[Text], FrozenSet[Text]]) -> None\n    \"\"\"Check ``mode`` parameter of `~fs.base.FS.openbin` is valid.\n\n    Arguments:\n        mode (str): Mode parameter.\n\n    Raises:\n        `ValueError` if mode is not valid.\n\n    \"\"\"\n    if \"t\" in mode:\n        raise ValueError(\"text mode not valid in openbin\")\n    if not mode:\n        raise ValueError(\"mode must not be empty\")\n    if mode[0] not in \"rwxa\":\n        raise ValueError(\"mode must start with 'r', 'w', 'a' or 'x'\")\n    if not _valid_chars.issuperset(mode):\n        raise ValueError(\"mode '{}' contains invalid characters\".format(mode))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(\n    fs,  # type: FS\n    path=\"/\",  # type: Text\n    file=None,  # type: Optional[TextIO]\n    encoding=None,  # type: Optional[Text]\n    max_levels=5,  # type: int\n    with_color=None,  # type: Optional[bool]\n    dirs_first=True,  # type: bool\n    exclude=None,  # type: Optional[List[Text]]\n    filter=None,  # type: Optional[List[Text]]\n):\n    # type: (...) -> Tuple[int, int]\n    \"\"\"Render a directory structure in to a pretty tree.\n\n    Arguments:\n        fs (~fs.base.FS): A filesystem instance.\n        path (str): The path of the directory to start rendering\n            from (defaults to root folder, i.e. ``'/'``).\n        file (io.IOBase): An open file-like object to render the\n            tree, or `None` for stdout.\n        encoding (str, optional): Unicode encoding, or `None` to\n            auto-detect.\n        max_levels (int, optional): Maximum number of levels to\n            display, or `None` for no maximum.\n        with_color (bool, optional): Enable terminal color output,\n            or `None` to auto-detect terminal.\n        dirs_first (bool): Show directories first.\n        exclude (list, optional): Option list of directory patterns\n            to exclude from the tree render.\n        filter (list, optional): Optional list of files patterns to\n            match in the tree render.\n\n    Returns:\n        (int, int): A tuple of ``(<directory count>, <file count>)``.\n\n    \"\"\"\n    file = file or sys.stdout\n    if encoding is None:\n        encoding = getattr(file, \"encoding\", \"utf-8\") or \"utf-8\"\n    is_tty = hasattr(file, \"isatty\") and file.isatty()\n\n    if with_color is None:\n        is_windows = sys.platform.startswith(\"win\")\n        with_color = False if is_windows else is_tty\n\n    if encoding.lower() == \"utf-8\" and with_color:\n        char_vertline = \"\u2502\"\n        char_newnode = \"\u251c\"\n        char_line = \"\u2500\u2500\"\n        char_corner = \"\u2514\"\n    else:\n        char_vertline = \"|\"\n        char_newnode = \"|\"\n        char_line = \"--\"\n        char_corner = \"`\"\n\n    indent = \" \" * 4\n    line_indent = char_vertline + \" \" * 3\n\n    def write(line):\n        # type: (Text) -> None\n        \"\"\"Write a line to the output.\n        \"\"\"\n        print(line, file=file)\n\n    # FIXME(@althonos): define functions using `with_color` and\n    #      avoid checking `with_color` at every function call !\n\n    def format_prefix(prefix):\n        # type: (Text) -> Text\n        \"\"\"Format the prefix lines.\n        \"\"\"\n        if not with_color:\n            return prefix\n        return \"\\x1b[32m%s\\x1b[0m\" % prefix\n\n    def format_dirname(dirname):\n        # type: (Text) -> Text\n        \"\"\"Format a directory name.\n        \"\"\"\n        if not with_color:\n            return dirname\n        return \"\\x1b[1;34m%s\\x1b[0m\" % dirname\n\n    def format_error(msg):\n        # type: (Text) -> Text\n        \"\"\"Format an error.\n        \"\"\"\n        if not with_color:\n            return msg\n        return \"\\x1b[31m%s\\x1b[0m\" % msg\n\n    def format_filename(fname):\n        # type: (Text) -> Text\n        \"\"\"Format a filename.\n        \"\"\"\n        if not with_color:\n            return fname\n        if fname.startswith(\".\"):\n            fname = \"\\x1b[33m%s\\x1b[0m\" % fname\n        return fname\n\n    def sort_key_dirs_first(info):\n        # type: (Info) -> Tuple[bool, Text]\n        \"\"\"Get the info sort function with directories first.\n        \"\"\"\n        return (not info.is_dir, info.name.lower())\n\n    def sort_key(info):\n        # type: (Info) -> Text\n        \"\"\"Get the default info sort function using resource name.\n        \"\"\"\n        return info.name.lower()\n\n    counts = {\"dirs\": 0, \"files\": 0}\n\n    def format_directory(path, levels):\n        # type: (Text, List[bool]) -> None\n        \"\"\"Recursive directory function.\n        \"\"\"\n        try:\n            directory = sorted(\n                fs.filterdir(path, exclude_dirs=exclude, files=filter),\n                key=sort_key_dirs_first if dirs_first else sort_key,\n            )\n        except Exception as error:\n            prefix = (\n                \"\".join(indent if last else line_indent for last in levels)\n                + char_corner\n                + char_line\n            )\n            write(\n                \"{} {}\".format(\n                    format_prefix(prefix), format_error(\"error ({})\".format(error))\n                )\n            )\n            return\n        _last = len(directory) - 1\n        for i, info in enumerate(directory):\n            is_last_entry = i == _last\n            counts[\"dirs\" if info.is_dir else \"files\"] += 1\n            prefix = \"\".join(indent if last else line_indent for last in levels)\n            prefix += char_corner if is_last_entry else char_newnode\n            if info.is_dir:\n                write(\n                    \"{} {}\".format(\n                        format_prefix(prefix + char_line), format_dirname(info.name)\n                    )\n                )\n                if max_levels is None or len(levels) < max_levels:\n                    format_directory(join(path, info.name), levels + [is_last_entry])\n            else:\n                write(\n                    \"{} {}\".format(\n                        format_prefix(prefix + char_line), format_filename(info.name)\n                    )\n                )\n\n    format_directory(abspath(normpath(path)), [])\n    return counts[\"dirs\"], counts[\"files\"]", "response": "Render a directory structure in to a pretty tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _compare(info1, info2):\n    # type: (Info, Info) -> bool\n    \"\"\"Compare two `Info` objects to see if they should be copied.\n\n    Returns:\n        bool: `True` if the `Info` are different in size or mtime.\n\n    \"\"\"\n    # Check filesize has changed\n    if info1.size != info2.size:\n        return True\n    # Check modified dates\n    date1 = info1.modified\n    date2 = info2.modified\n    return date1 is None or date2 is None or date1 > date2", "response": "Compares two Info objects to see if they should be copied."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmirrors a file system to another filesystem.", "response": "def mirror(\n    src_fs,  # type: Union[FS, Text]\n    dst_fs,  # type: Union[FS, Text]\n    walker=None,  # type: Optional[Walker]\n    copy_if_newer=True,  # type: bool\n    workers=0,  # type: int\n):\n    # type: (...) -> None\n    \"\"\"Mirror files / directories from one filesystem to another.\n\n    Mirroring a filesystem will create an exact copy of ``src_fs`` on\n    ``dst_fs``, by removing any files / directories on the destination\n    that aren't on the source, and copying files that aren't.\n\n    Arguments:\n        src_fs (FS or str): Source filesystem (URL or instance).\n        dst_fs (FS or str): Destination filesystem (URL or instance).\n        walker (~fs.walk.Walker, optional): An optional walker instance.\n        copy_if_newer (bool): Only copy newer files (the default).\n        workers (int): Number of worker threads used\n            (0 for single threaded). Set to a relatively low number\n            for network filesystems, 4 would be a good start.\n    \"\"\"\n\n    def src():\n        return manage_fs(src_fs, writeable=False)\n\n    def dst():\n        return manage_fs(dst_fs, create=True)\n\n    with src() as _src_fs, dst() as _dst_fs:\n        with _src_fs.lock(), _dst_fs.lock():\n            _thread_safe = is_thread_safe(_src_fs, _dst_fs)\n            with Copier(num_workers=workers if _thread_safe else 0) as copier:\n                _mirror(\n                    _src_fs,\n                    _dst_fs,\n                    walker=walker,\n                    copy_if_newer=copy_if_newer,\n                    copy_file=copier.copy,\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a filesystem URL and return a ParseResult.", "response": "def parse_fs_url(fs_url):\n    # type: (Text) -> ParseResult\n    \"\"\"Parse a Filesystem URL and return a `ParseResult`.\n\n    Arguments:\n        fs_url (str): A filesystem URL.\n\n    Returns:\n        ~fs.opener.parse.ParseResult: a parse result instance.\n\n    Raises:\n        ~fs.errors.ParseError: if the FS URL is not valid.\n\n    \"\"\"\n    match = _RE_FS_URL.match(fs_url)\n    if match is None:\n        raise ParseError(\"{!r} is not a fs2 url\".format(fs_url))\n\n    fs_name, credentials, url1, url2, path = match.groups()\n    if not credentials:\n        username = None  # type: Optional[Text]\n        password = None  # type: Optional[Text]\n        url = url2\n    else:\n        username, _, password = credentials.partition(\":\")\n        username = unquote(username)\n        password = unquote(password)\n        url = url1\n    url, has_qs, qs = url.partition(\"?\")\n    resource = unquote(url)\n    if has_qs:\n        _params = parse_qs(qs, keep_blank_values=True)\n        params = {k: unquote(v[0]) for k, v in six.iteritems(_params)}\n    else:\n        params = {}\n    return ParseResult(fs_name, username, password, resource, params, path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a method with a deprecation warning.", "response": "def _new_name(method, old_name):\n    \"\"\"Return a method with a deprecation warning.\"\"\"\n    # Looks suspiciously like a decorator, but isn't!\n\n    @wraps(method)\n    def _method(*args, **kwargs):\n        warnings.warn(\n            \"method '{}' has been deprecated, please rename to '{}'\".format(\n                old_name, method.__name__\n            ),\n            DeprecationWarning,\n        )\n        return method(*args, **kwargs)\n\n    deprecated_msg = \"\"\"\n        Note:\n            .. deprecated:: 2.2.0\n                Please use `~{}`\n\"\"\".format(\n        method.__name__\n    )\n    if getattr(_method, \"__doc__\"):\n        _method.__doc__ += deprecated_msg\n\n    return _method"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef seek(self, offset, whence=Seek.set):\n        # type: (int, SupportsInt) -> int\n        \"\"\"Change stream position.\n\n        Change the stream position to the given byte offset. The\n        offset is interpreted relative to the position indicated by\n        ``whence``.\n\n        Arguments:\n            offset (int): the offset to the new position, in bytes.\n            whence (int): the position reference. Possible values are:\n                * `Seek.set`: start of stream (the default).\n                * `Seek.current`: current position; offset may be negative.\n                * `Seek.end`: end of stream; offset must be negative.\n\n        Returns:\n            int: the new absolute position.\n\n        Raises:\n            ValueError: when ``whence`` is not known, or ``offset``\n                is invalid.\n\n        Note:\n            Zip compression does not support seeking, so the seeking\n            is emulated. Seeking somewhere else than the current position\n            will need to either:\n                * reopen the file and restart decompression\n                * read and discard data to advance in the file\n\n        \"\"\"\n        _whence = int(whence)\n        if _whence == Seek.current:\n            offset += self._pos\n        if _whence == Seek.current or _whence == Seek.set:\n            if offset < 0:\n                raise ValueError(\"Negative seek position {}\".format(offset))\n        elif _whence == Seek.end:\n            if offset > 0:\n                raise ValueError(\"Positive seek position {}\".format(offset))\n            offset += self._end\n        else:\n            raise ValueError(\n                \"Invalid whence ({}, should be {}, {} or {})\".format(\n                    _whence, Seek.set, Seek.current, Seek.end\n                )\n            )\n\n        if offset < self._pos:\n            self._f = self._zip.open(self.name)  # type: ignore\n            self._pos = 0\n        self.read(offset - self._pos)\n        return self._pos", "response": "Change the stream position."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _iter_walk(\n        self,\n        fs,  # type: FS\n        path,  # type: Text\n        namespaces=None,  # type: Optional[Collection[Text]]\n    ):\n        # type: (...) -> Iterator[Tuple[Text, Optional[Info]]]\n        \"\"\"Get the walk generator.\"\"\"\n        if self.search == \"breadth\":\n            return self._walk_breadth(fs, path, namespaces=namespaces)\n        else:\n            return self._walk_depth(fs, path, namespaces=namespaces)", "response": "Get the walk generator."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_open_dir(self, fs, path, info):\n        # type: (FS, Text, Info) -> bool\n        \"\"\"Check if a directory should be considered in the walk.\n        \"\"\"\n        if self.exclude_dirs is not None and fs.match(self.exclude_dirs, info.name):\n            return False\n        if self.filter_dirs is not None and not fs.match(self.filter_dirs, info.name):\n            return False\n        return self.check_open_dir(fs, path, info)", "response": "Check if a directory should be considered in the walk."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_scan_dir(self, fs, path, info, depth):\n        # type: (FS, Text, Info, int) -> bool\n        \"\"\"Check if a directory contents should be scanned.\"\"\"\n        if self.max_depth is not None and depth >= self.max_depth:\n            return False\n        return self.check_scan_dir(fs, path, info)", "response": "Check if a directory contents should be scanned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_file(self, fs, info):\n        # type: (FS, Info) -> bool\n        \"\"\"Check if a filename should be included.\n\n        Override to exclude files from the walk.\n\n        Arguments:\n            fs (FS): A filesystem instance.\n            info (Info): A resource info object.\n\n        Returns:\n            bool: `True` if the file should be included.\n\n        \"\"\"\n\n        if self.exclude is not None and fs.match(self.exclude, info.name):\n            return False\n        return fs.match(self.filter, info.name)", "response": "Check if a filename should be included."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _scan(\n        self,\n        fs,  # type: FS\n        dir_path,  # type: Text\n        namespaces=None,  # type: Optional[Collection[Text]]\n    ):\n        # type: (...) -> Iterator[Info]\n        \"\"\"Get an iterator of `Info` objects for a directory path.\n\n        Arguments:\n            fs (FS): A filesystem instance.\n            dir_path (str): A path to a directory on the filesystem.\n            namespaces (list): A list of additional namespaces to\n                include in the `Info` objects.\n\n        Returns:\n            ~collections.Iterator: iterator of `Info` objects for\n            resources within the given path.\n\n        \"\"\"\n        try:\n            for info in fs.scandir(dir_path, namespaces=namespaces):\n                yield info\n        except FSError as error:\n            if not self.on_error(dir_path, error):\n                six.reraise(type(error), error)", "response": "Yields the info objects for the given directory path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef walk(\n        self,\n        fs,  # type: FS\n        path=\"/\",  # type: Text\n        namespaces=None,  # type: Optional[Collection[Text]]\n    ):\n        # type: (...) -> Iterator[Step]\n        \"\"\"Walk the directory structure of a filesystem.\n\n        Arguments:\n            fs (FS): A filesystem instance.\n            path (str): A path to a directory on the filesystem.\n            namespaces (list, optional): A list of additional namespaces\n                to add to the `Info` objects.\n\n        Returns:\n            collections.Iterator: an iterator of `~fs.walk.Step` instances.\n\n        The return value is an iterator of ``(<path>, <dirs>, <files>)``\n        named tuples,  where ``<path>`` is an absolute path to a\n        directory, and ``<dirs>`` and ``<files>`` are a list of\n        `~fs.info.Info` objects for directories and files in ``<path>``.\n\n        Example:\n            >>> home_fs = open_fs('~/')\n            >>> walker = Walker(filter=['*.py'])\n            >>> namespaces = ['details']\n            >>> for path, dirs, files in walker.walk(home_fs, namespaces)\n            ...    print(\"[{}]\".format(path))\n            ...    print(\"{} directories\".format(len(dirs)))\n            ...    total = sum(info.size for info in files)\n            ...    print(\"{} bytes {}\".format(total))\n\n        \"\"\"\n        _path = abspath(normpath(path))\n        dir_info = defaultdict(list)  # type: MutableMapping[Text, List[Info]]\n        _walk = self._iter_walk(fs, _path, namespaces=namespaces)\n        for dir_path, info in _walk:\n            if info is None:\n                dirs = []  # type: List[Info]\n                files = []  # type: List[Info]\n                for _info in dir_info[dir_path]:\n                    (dirs if _info.is_dir else files).append(_info)\n                yield Step(dir_path, dirs, files)\n                del dir_info[dir_path]\n            else:\n                dir_info[dir_path].append(info)", "response": "Walks the directory structure of a filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef files(self, fs, path=\"/\"):\n        # type: (FS, Text) -> Iterator[Text]\n        \"\"\"Walk a filesystem, yielding absolute paths to files.\n\n        Arguments:\n            fs (FS): A filesystem instance.\n            path (str): A path to a directory on the filesystem.\n\n        Yields:\n            str: absolute path to files on the filesystem found\n            recursively within the given directory.\n\n        \"\"\"\n        _combine = combine\n        for _path, info in self._iter_walk(fs, path=path):\n            if info is not None and not info.is_dir:\n                yield _combine(_path, info.name)", "response": "Walk a filesystem yielding absolute paths to files within the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info(\n        self,\n        fs,  # type: FS\n        path=\"/\",  # type: Text\n        namespaces=None,  # type: Optional[Collection[Text]]\n    ):\n        # type: (...) -> Iterator[Tuple[Text, Info]]\n        \"\"\"Walk a filesystem, yielding tuples of ``(<path>, <info>)``.\n\n        Arguments:\n            fs (FS): A filesystem instance.\n            path (str): A path to a directory on the filesystem.\n            namespaces (list, optional): A list of additional namespaces\n                to add to the `Info` objects.\n\n        Yields:\n            (str, Info): a tuple of ``(<absolute path>, <resource info>)``.\n\n        \"\"\"\n        _combine = combine\n        _walk = self._iter_walk(fs, path=path, namespaces=namespaces)\n        for _path, info in _walk:\n            if info is not None:\n                yield _combine(_path, info.name), info", "response": "Walk a filesystem yielding tuples of path and Info objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwalking the directory tree using a breadth first search.", "response": "def _walk_breadth(\n        self,\n        fs,  # type: FS\n        path,  # type: Text\n        namespaces=None,  # type: Optional[Collection[Text]]\n    ):\n        # type: (...) -> Iterator[Tuple[Text, Optional[Info]]]\n        \"\"\"Walk files using a *breadth first* search.\n        \"\"\"\n        queue = deque([path])\n        push = queue.appendleft\n        pop = queue.pop\n\n        _combine = combine\n        _scan = self._scan\n        _calculate_depth = self._calculate_depth\n        _check_open_dir = self._check_open_dir\n        _check_scan_dir = self._check_scan_dir\n        _check_file = self.check_file\n\n        depth = _calculate_depth(path)\n\n        while queue:\n            dir_path = pop()\n            for info in _scan(fs, dir_path, namespaces=namespaces):\n                if info.is_dir:\n                    _depth = _calculate_depth(dir_path) - depth + 1\n                    if _check_open_dir(fs, dir_path, info):\n                        yield dir_path, info  # Opened a directory\n                        if _check_scan_dir(fs, dir_path, info, _depth):\n                            push(_combine(dir_path, info.name))\n                else:\n                    if _check_file(fs, info):\n                        yield dir_path, info  # Found a file\n            yield dir_path, None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _walk_depth(\n        self,\n        fs,  # type: FS\n        path,  # type: Text\n        namespaces=None,  # type: Optional[Collection[Text]]\n    ):\n        # type: (...) -> Iterator[Tuple[Text, Optional[Info]]]\n        \"\"\"Walk files using a *depth first* search.\n        \"\"\"\n        # No recursion!\n\n        _combine = combine\n        _scan = self._scan\n        _calculate_depth = self._calculate_depth\n        _check_open_dir = self._check_open_dir\n        _check_scan_dir = self._check_scan_dir\n        _check_file = self.check_file\n        depth = _calculate_depth(path)\n\n        stack = [\n            (path, _scan(fs, path, namespaces=namespaces), None)\n        ]  # type: List[Tuple[Text, Iterator[Info], Optional[Tuple[Text, Info]]]]\n\n        push = stack.append\n\n        while stack:\n            dir_path, iter_files, parent = stack[-1]\n            info = next(iter_files, None)\n            if info is None:\n                if parent is not None:\n                    yield parent\n                yield dir_path, None\n                del stack[-1]\n            elif info.is_dir:\n                _depth = _calculate_depth(dir_path) - depth + 1\n                if _check_open_dir(fs, dir_path, info):\n                    if _check_scan_dir(fs, dir_path, info, _depth):\n                        _path = _combine(dir_path, info.name)\n                        push(\n                            (\n                                _path,\n                                _scan(fs, _path, namespaces=namespaces),\n                                (dir_path, info),\n                            )\n                        )\n                    else:\n                        yield dir_path, info\n            else:\n                if _check_file(fs, info):\n                    yield dir_path, info", "response": "Walk the directory tree using a depth first search."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_walker(self, *args, **kwargs):\n        # type: (*Any, **Any) -> Walker\n        \"\"\"Create a walker instance.\n        \"\"\"\n        walker = self.walker_class(*args, **kwargs)\n        return walker", "response": "Create a walker instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef walk(\n        self,\n        path=\"/\",  # type: Text\n        namespaces=None,  # type: Optional[Collection[Text]]\n        **kwargs  # type: Any\n    ):\n        # type: (...) -> Iterator[Step]\n        \"\"\"Walk the directory structure of a filesystem.\n\n        Arguments:\n            path (str):\n            namespaces (list, optional): A list of namespaces to include\n                in the resource information, e.g. ``['basic', 'access']``\n                (defaults to ``['basic']``).\n\n        Keyword Arguments:\n            ignore_errors (bool): If `True`, any errors reading a\n                directory will be ignored, otherwise exceptions will be\n                raised.\n            on_error (callable): If ``ignore_errors`` is `False`, then\n                this callable will be invoked with a path and the exception\n                object. It should return `True` to ignore the error, or\n                `False` to re-raise it.\n            search (str): If ``'breadth'`` then the directory will be\n                walked *top down*. Set to ``'depth'`` to walk *bottom up*.\n            filter (list): If supplied, this parameter should be a list\n                of file name patterns, e.g. ``['*.py']``. Files will only be\n                returned if the final component matches one of the\n                patterns.\n            exclude (list, optional): If supplied, this parameter should be\n                a list of filename patterns, e.g. ``['~*', '.*']``. Files matching\n                any of these patterns will be removed from the walk.\n            filter_dirs (list, optional): A list of patterns that will be used\n                to match directories paths. The walk will only open directories\n                that match at least one of these patterns.\n            exclude_dirs (list): A list of patterns that will be used\n                to filter out directories from the walk, e.g. ``['*.svn',\n                '*.git']``.\n            max_depth (int, optional): Maximum directory depth to walk.\n\n        Returns:\n            ~collections.Iterator: an iterator of ``(<path>, <dirs>, <files>)``\n            named tuples,  where ``<path>`` is an absolute path to a\n            directory, and ``<dirs>`` and ``<files>`` are a list of\n            `~fs.info.Info` objects for directories and files in ``<path>``.\n\n        Example:\n            >>> home_fs = open_fs('~/')\n            >>> walker = Walker(filter=['*.py'])\n            >>> for path, dirs, files in walker.walk(home_fs, namespaces=['details']):\n            ...     print(\"[{}]\".format(path))\n            ...     print(\"{} directories\".format(len(dirs)))\n            ...     total = sum(info.size for info in files)\n            ...     print(\"{} bytes {}\".format(total))\n\n        This method invokes `Walker.walk` with bound `FS` object.\n\n        \"\"\"\n        walker = self._make_walker(**kwargs)\n        return walker.walk(self.fs, path=path, namespaces=namespaces)", "response": "Walks the directory structure of a resource file system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwalk a filesystem yielding absolute paths to files.", "response": "def files(self, path=\"/\", **kwargs):\n        # type: (Text, **Any) -> Iterator[Text]\n        \"\"\"Walk a filesystem, yielding absolute paths to files.\n\n        Arguments:\n            path (str): A path to a directory.\n\n        Keyword Arguments:\n            ignore_errors (bool): If `True`, any errors reading a\n                directory will be ignored, otherwise exceptions will be\n                raised.\n            on_error (callable): If ``ignore_errors`` is `False`, then\n                this callable will be invoked with a path and the exception\n                object. It should return `True` to ignore the error, or\n                `False` to re-raise it.\n            search (str): If ``'breadth'`` then the directory will be\n                walked *top down*. Set to ``'depth'`` to walk *bottom up*.\n            filter (list): If supplied, this parameter should be a list\n                of file name patterns, e.g. ``['*.py']``. Files will only be\n                returned if the final component matches one of the\n                patterns.\n            exclude (list, optional): If supplied, this parameter should be\n                a list of filename patterns, e.g. ``['~*', '.*']``. Files matching\n                any of these patterns will be removed from the walk.\n            filter_dirs (list, optional): A list of patterns that will be used\n                to match directories paths. The walk will only open directories\n                that match at least one of these patterns.\n            exclude_dirs (list): A list of patterns that will be used\n                to filter out directories from the walk, e.g. ``['*.svn',\n                '*.git']``.\n            max_depth (int, optional): Maximum directory depth to walk.\n\n        Returns:\n            ~collections.Iterator: An iterator over file paths (absolute\n            from the filesystem root).\n\n        This method invokes `Walker.files` with the bound `FS` object.\n\n        \"\"\"\n        walker = self._make_walker(**kwargs)\n        return walker.files(self.fs, path=path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwalks a filesystem yielding absolute paths to directories.", "response": "def dirs(self, path=\"/\", **kwargs):\n        # type: (Text, **Any) -> Iterator[Text]\n        \"\"\"Walk a filesystem, yielding absolute paths to directories.\n\n        Arguments:\n            path (str): A path to a directory.\n\n        Keyword Arguments:\n            ignore_errors (bool): If `True`, any errors reading a\n                directory will be ignored, otherwise exceptions will be\n                raised.\n            on_error (callable): If ``ignore_errors`` is `False`, then\n                this callable will be invoked with a path and the exception\n                object. It should return `True` to ignore the error, or\n                `False` to re-raise it.\n            search (str): If ``'breadth'`` then the directory will be\n                walked *top down*. Set to ``'depth'`` to walk *bottom up*.\n            filter_dirs (list, optional): A list of patterns that will be used\n                to match directories paths. The walk will only open directories\n                that match at least one of these patterns.\n            exclude_dirs (list): A list of patterns that will be used\n                to filter out directories from the walk, e.g. ``['*.svn',\n                '*.git']``.\n            max_depth (int, optional): Maximum directory depth to walk.\n\n        Returns:\n            ~collections.Iterator: an iterator over directory paths\n            (absolute from the filesystem root).\n\n        This method invokes `Walker.dirs` with the bound `FS` object.\n\n        \"\"\"\n        walker = self._make_walker(**kwargs)\n        return walker.dirs(self.fs, path=path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(\n        self,\n        path=\"/\",  # type: Text\n        namespaces=None,  # type: Optional[Collection[Text]]\n        **kwargs  # type: Any\n    ):\n        # type: (...) -> Iterator[Tuple[Text, Info]]\n        \"\"\"Walk a filesystem, yielding path and `Info` of resources.\n\n        Arguments:\n            path (str): A path to a directory.\n            namespaces (list, optional): A list of namespaces to include\n                in the resource information, e.g. ``['basic', 'access']``\n                (defaults to ``['basic']``).\n\n        Keyword Arguments:\n            ignore_errors (bool): If `True`, any errors reading a\n                directory will be ignored, otherwise exceptions will be\n                raised.\n            on_error (callable): If ``ignore_errors`` is `False`, then\n                this callable will be invoked with a path and the exception\n                object. It should return `True` to ignore the error, or\n                `False` to re-raise it.\n            search (str): If ``'breadth'`` then the directory will be\n                walked *top down*. Set to ``'depth'`` to walk *bottom up*.\n            filter (list): If supplied, this parameter should be a list\n                of file name patterns, e.g. ``['*.py']``. Files will only be\n                returned if the final component matches one of the\n                patterns.\n            exclude (list, optional): If supplied, this parameter should be\n                a list of filename patterns, e.g. ``['~*', '.*']``. Files matching\n                any of these patterns will be removed from the walk.\n            filter_dirs (list, optional): A list of patterns that will be used\n                to match directories paths. The walk will only open directories\n                that match at least one of these patterns.\n            exclude_dirs (list): A list of patterns that will be used\n                to filter out directories from the walk, e.g. ``['*.svn',\n                '*.git']``.\n            max_depth (int, optional): Maximum directory depth to walk.\n\n        Returns:\n            ~collections.Iterable: an iterable yielding tuples of\n            ``(<absolute path>, <resource info>)``.\n\n        This method invokes `Walker.info` with the bound `FS` object.\n\n        \"\"\"\n        walker = self._make_walker(**kwargs)\n        return walker.info(self.fs, path=path, namespaces=namespaces)", "response": "Walk a filesystem yielding path and Info of resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves all empty parents from a directory.", "response": "def remove_empty(fs, path):\n    # type: (FS, Text) -> None\n    \"\"\"Remove all empty parents.\n\n    Arguments:\n        fs (FS): A filesystem instance.\n        path (str): Path to a directory on the filesystem.\n\n    \"\"\"\n    path = abspath(normpath(path))\n    try:\n        while path not in (\"\", \"/\"):\n            fs.removedir(path)\n            path = dirname(path)\n    except DirectoryNotEmpty:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_file_data(src_file, dst_file, chunk_size=None):\n    # type: (IO, IO, Optional[int]) -> None\n    \"\"\"Copy data from one file object to another.\n\n    Arguments:\n        src_file (io.IOBase): File open for reading.\n        dst_file (io.IOBase): File open for writing.\n        chunk_size (int): Number of bytes to copy at\n            a time (or `None` to use sensible default).\n\n    \"\"\"\n    _chunk_size = 1024 * 1024 if chunk_size is None else chunk_size\n    read = src_file.read\n    write = dst_file.write\n    # The 'or None' is so that it works with binary and text files\n    for chunk in iter(lambda: read(_chunk_size) or None, None):\n        write(chunk)", "response": "Copy data from one file object to another."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of non - existing intermediate directories.", "response": "def get_intermediate_dirs(fs, dir_path):\n    # type: (FS, Text) -> List[Text]\n    \"\"\"Get a list of non-existing intermediate directories.\n\n    Arguments:\n        fs (FS): A filesystem instance.\n        dir_path (str): A path to a new directory on the filesystem.\n\n    Returns:\n        list: A list of non-existing paths.\n\n    Raises:\n        ~fs.errors.DirectoryExpected: If a path component\n            references a file and not a directory.\n\n    \"\"\"\n    intermediates = []\n    with fs.lock():\n        for path in recursepath(abspath(dir_path), reverse=True):\n            try:\n                resource = fs.getinfo(path)\n            except ResourceNotFound:\n                intermediates.append(abspath(path))\n            else:\n                if resource.is_dir:\n                    break\n                raise errors.DirectoryExpected(dir_path)\n    return intermediates[::-1][:-1]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prettify_json(json_string):\n    try:\n        data = json.loads(json_string)\n        html = '<pre>' + json.dumps(data, sort_keys=True, indent=4) + '</pre>'\n    except:\n        html = json_string\n    return mark_safe(html)", "response": "Given a JSON string it returns it as a\n    safe formatted HTML"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef purge_objects(self, request):\n\n        def truncate_table(model):\n            if settings.TRUNCATE_TABLE_SQL_STATEMENT:\n                from django.db import connection\n                sql = settings.TRUNCATE_TABLE_SQL_STATEMENT.format(db_table=model._meta.db_table)\n                cursor = connection.cursor()\n                cursor.execute(sql)\n            else:\n                model.objects.all().delete()\n\n        modeladmin = self\n        opts = modeladmin.model._meta\n\n        # Check that the user has delete permission for the actual model\n        if not request.user.is_superuser:\n           raise PermissionDenied\n        if not modeladmin.has_delete_permission(request):\n            raise PermissionDenied\n\n        # If the user has already confirmed or cancelled the deletion,\n        # (eventually) do the deletion and return to the change list view again.\n        if request.method == 'POST':\n            if 'btn-confirm' in request.POST:\n                try:\n                    n = modeladmin.model.objects.count()\n                    truncate_table(modeladmin.model)\n                    modeladmin.message_user(request, _(\"Successfully removed %d rows\" % n), messages.SUCCESS);\n                except Exception as e:\n                    modeladmin.message_user(request, _(u'ERROR') + ': %r' % e, messages.ERROR)\n            else:\n                modeladmin.message_user(request, _(\"Action cancelled by user\"), messages.SUCCESS);\n            return HttpResponseRedirect(reverse('admin:%s_%s_changelist' % (opts.app_label, opts.model_name)))\n\n        context = {\n            \"title\": _(\"Purge all %s ... are you sure?\") % opts.verbose_name_plural,\n            \"opts\": opts,\n            \"app_label\": opts.app_label,\n        }\n\n        # Display the confirmation page\n        return render(\n            request,\n            'admin/easyaudit/purge_confirmation.html',\n            context\n        )", "response": "This action deletes all objects in this table and redirects back to the change list view."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_model_list(class_list):\n    for idx, item in enumerate(class_list):\n        if isinstance(item, six.string_types):\n            model_class = apps.get_model(item)\n            class_list[idx] = model_class", "response": "Takes a list of strings with app_name. model_name format\n    and turns them into classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_field_value(obj, field):\n    if isinstance(field, DateTimeField):\n        # DateTimeFields are timezone-aware, so we need to convert the field\n        # to its naive form before we can accuratly compare them for changes.\n        try:\n            value = field.to_python(getattr(obj, field.name, None))\n            if value is not None and settings.USE_TZ and not timezone.is_naive(value):\n                value = timezone.make_naive(value, timezone=timezone.utc)\n        except ObjectDoesNotExist:\n            value = field.default if field.default is not NOT_PROVIDED else None\n    else:\n        try:\n            value = smart_text(getattr(obj, field.name, None))\n        except ObjectDoesNotExist:\n            value = field.default if field.default is not NOT_PROVIDED else None\n\n    return value", "response": "Gets the value of a given model instance field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef model_delta(old_model, new_model):\n\n    delta = {}\n    fields = new_model._meta.fields\n    for field in fields:\n        old_value = get_field_value(old_model, field)\n        new_value = get_field_value(new_model, field)\n        if old_value != new_value:\n            delta[field.name] = [smart_text(old_value),\n                                 smart_text(new_value)]\n\n    if len(delta) == 0:\n        delta = None\n\n    return delta", "response": "Provides delta between two models\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True or False to indicate whether the instance should be audited or not depending on the project settings.", "response": "def should_audit(instance):\n    \"\"\"Returns True or False to indicate whether the instance\n    should be audited or not, depending on the project settings.\"\"\"\n\n    # do not audit any model listed in UNREGISTERED_CLASSES\n    for unregistered_class in UNREGISTERED_CLASSES:\n        if isinstance(instance, unregistered_class):\n            return False\n\n    # only audit models listed in REGISTERED_CLASSES (if it's set)\n    if len(REGISTERED_CLASSES) > 0:\n        for registered_class in REGISTERED_CLASSES:\n            if isinstance(instance, registered_class):\n                break\n        else:\n            return False\n\n    # all good\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate or update a new object in the database.", "response": "def pre_save(sender, instance, raw, using, update_fields, **kwargs):\n    \"\"\"https://docs.djangoproject.com/es/1.10/ref/signals/#post-save\"\"\"\n    if raw:\n        # Return if loading Fixtures\n        return\n\n    try:\n        with transaction.atomic():\n            if not should_audit(instance):\n                return False\n            try:\n                object_json_repr = serializers.serialize(\"json\", [instance])\n            except Exception:\n                # We need a better way for this to work. ManyToMany will fail on pre_save on create\n                return None\n\n            if instance.pk is None:\n                created = True\n            else:\n                created = False\n\n            # created or updated?\n            if not created:\n                old_model = sender.objects.get(pk=instance.pk)\n                delta = model_delta(old_model, instance)\n                changed_fields = json.dumps(delta)\n                event_type = CRUDEvent.UPDATE\n\n            # user\n            try:\n                user = get_current_user()\n                # validate that the user still exists\n                user = get_user_model().objects.get(pk=user.pk)\n            except:\n                user = None\n\n            if isinstance(user, AnonymousUser):\n                user = None\n\n            # callbacks\n            kwargs['request'] = get_current_request()  # make request available for callbacks\n            create_crud_event = all(\n                callback(instance, object_json_repr, created, raw, using, update_fields, **kwargs)\n                for callback in CRUD_DIFFERENCE_CALLBACKS if callable(callback))\n            # create crud event only if all callbacks returned True\n            if create_crud_event and not created:\n                c_t = ContentType.objects.get_for_model(instance)\n                sid = transaction.savepoint()\n                try:\n                    with transaction.atomic():\n                        crud_event = CRUDEvent.objects.create(\n                            event_type=event_type,\n                            object_repr=str(instance),\n                            object_json_repr=object_json_repr,\n                            changed_fields=changed_fields,\n                            content_type_id=c_t.id,\n                            object_id=instance.pk,\n                            user_id=getattr(user, 'id', None),\n                            datetime=timezone.now(),\n                            user_pk_as_string=str(user.pk) if user else user\n                        )\n                except Exception as e:\n                    logger.exception(\n                        \"easy audit had a pre-save exception on CRUDEvent creation. instance: {}, instance pk: {}\".format(\n                            instance, instance.pk))\n                    transaction.savepoint_rollback(sid)\n    except Exception:\n        logger.exception('easy audit had a pre-save exception.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _m2m_rev_field_name(model1, model2):\n    m2m_field_names = [\n        rel.get_accessor_name() for rel in model1._meta.get_fields()\n        if rel.many_to_many\n           and rel.auto_created\n           and rel.related_model == model2\n    ]\n    return m2m_field_names[0]", "response": "Gets the name of the reverse m2m accessor from model1 to model2."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post_delete(sender, instance, using, **kwargs):\n    try:\n        with transaction.atomic():\n            if not should_audit(instance):\n                return False\n\n            object_json_repr = serializers.serialize(\"json\", [instance])\n\n            # user\n            try:\n                user = get_current_user()\n                # validate that the user still exists\n                user = get_user_model().objects.get(pk=user.pk)\n            except:\n                user = None\n\n            if isinstance(user, AnonymousUser):\n                user = None\n            c_t = ContentType.objects.get_for_model(instance)\n            sid = transaction.savepoint()\n            try:\n                with transaction.atomic():\n                    # crud event\n                    crud_event = CRUDEvent.objects.create(\n                        event_type=CRUDEvent.DELETE,\n                        object_repr=str(instance),\n                        object_json_repr=object_json_repr,\n                        content_type_id=c_t.id,\n                        object_id=instance.pk,\n                        user_id=getattr(user, 'id', None),\n                        datetime=timezone.now(),\n                        user_pk_as_string=str(user.pk) if user else user\n                    )\n\n            except Exception as e:\n                logger.exception(\n                    \"easy audit had a pre-save exception on CRUDEvent creation. instance: {}, instance pk: {}\".format(\n                        instance, instance.pk))\n                transaction.savepoint_rollback(sid)\n    except Exception:\n        logger.exception('easy audit had a post-delete exception.')", "response": "A post - delete signal handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new_query():\n\n        N.nvmlInit()\n\n        def _decode(b):\n            if isinstance(b, bytes):\n                return b.decode()    # for python3, to unicode\n            return b\n\n        def get_gpu_info(handle):\n            \"\"\"Get one GPU information specified by nvml handle\"\"\"\n\n            def get_process_info(nv_process):\n                \"\"\"Get the process information of specific pid\"\"\"\n                process = {}\n                ps_process = psutil.Process(pid=nv_process.pid)\n                process['username'] = ps_process.username()\n                # cmdline returns full path;\n                # as in `ps -o comm`, get short cmdnames.\n                _cmdline = ps_process.cmdline()\n                if not _cmdline:\n                    # sometimes, zombie or unknown (e.g. [kworker/8:2H])\n                    process['command'] = '?'\n                else:\n                    process['command'] = os.path.basename(_cmdline[0])\n                # Bytes to MBytes\n                process['gpu_memory_usage'] = nv_process.usedGpuMemory // MB\n                process['pid'] = nv_process.pid\n                return process\n\n            name = _decode(N.nvmlDeviceGetName(handle))\n            uuid = _decode(N.nvmlDeviceGetUUID(handle))\n\n            try:\n                temperature = N.nvmlDeviceGetTemperature(\n                    handle, N.NVML_TEMPERATURE_GPU\n                )\n            except N.NVMLError:\n                temperature = None  # Not supported\n\n            try:\n                memory = N.nvmlDeviceGetMemoryInfo(handle)  # in Bytes\n            except N.NVMLError:\n                memory = None  # Not supported\n\n            try:\n                utilization = N.nvmlDeviceGetUtilizationRates(handle)\n            except N.NVMLError:\n                utilization = None  # Not supported\n\n            try:\n                power = N.nvmlDeviceGetPowerUsage(handle)\n            except N.NVMLError:\n                power = None\n\n            try:\n                power_limit = N.nvmlDeviceGetEnforcedPowerLimit(handle)\n            except N.NVMLError:\n                power_limit = None\n\n            try:\n                nv_comp_processes = \\\n                    N.nvmlDeviceGetComputeRunningProcesses(handle)\n            except N.NVMLError:\n                nv_comp_processes = None  # Not supported\n            try:\n                nv_graphics_processes = \\\n                    N.nvmlDeviceGetGraphicsRunningProcesses(handle)\n            except N.NVMLError:\n                nv_graphics_processes = None  # Not supported\n\n            if nv_comp_processes is None and nv_graphics_processes is None:\n                processes = None\n            else:\n                processes = []\n                nv_comp_processes = nv_comp_processes or []\n                nv_graphics_processes = nv_graphics_processes or []\n                for nv_process in nv_comp_processes + nv_graphics_processes:\n                    # TODO: could be more information such as system memory\n                    # usage, CPU percentage, create time etc.\n                    try:\n                        process = get_process_info(nv_process)\n                        processes.append(process)\n                    except psutil.NoSuchProcess:\n                        # TODO: add some reminder for NVML broken context\n                        # e.g. nvidia-smi reset  or  reboot the system\n                        pass\n\n            index = N.nvmlDeviceGetIndex(handle)\n            gpu_info = {\n                'index': index,\n                'uuid': uuid,\n                'name': name,\n                'temperature.gpu': temperature,\n                'utilization.gpu': utilization.gpu if utilization else None,\n                'power.draw': power // 1000 if power is not None else None,\n                'enforced.power.limit': power_limit // 1000\n                if power_limit is not None else None,\n                # Convert bytes into MBytes\n                'memory.used': memory.used // MB if memory else None,\n                'memory.total': memory.total // MB if memory else None,\n                'processes': processes,\n            }\n            return gpu_info\n\n        # 1. get the list of gpu and status\n        gpu_list = []\n        device_count = N.nvmlDeviceGetCount()\n\n        for index in range(device_count):\n            handle = N.nvmlDeviceGetHandleByIndex(index)\n            gpu_info = get_gpu_info(handle)\n            gpu_stat = GPUStat(gpu_info)\n            gpu_list.append(gpu_stat)\n\n        # 2. additional info (driver version, etc).\n        try:\n            driver_version = _decode(N.nvmlSystemGetDriverVersion())\n        except N.NVMLError:\n            driver_version = None    # N/A\n\n        N.nvmlShutdown()\n        return GPUStatCollection(gpu_list, driver_version=driver_version)", "response": "Query the information of all the GPUs on the local machine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint the GPU query results into standard output.", "response": "def print_gpustat(json=False, debug=False, **kwargs):\n    '''\n    Display the GPU query results into standard output.\n    '''\n    try:\n        gpu_stats = GPUStatCollection.new_query()\n    except Exception as e:\n        sys.stderr.write('Error on querying NVIDIA devices.'\n                         ' Use --debug flag for details\\n')\n        if debug:\n            try:\n                import traceback\n                traceback.print_exc(file=sys.stderr)\n            except Exception:\n                # NVMLError can't be processed by traceback:\n                #   https://bugs.python.org/issue28603\n                # as a workaround, simply re-throw the exception\n                raise e\n        sys.exit(1)\n\n    if json:\n        gpu_stats.print_json(sys.stdout)\n    else:\n        gpu_stats.print_formatted(sys.stdout, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch instruments by ids", "response": "def fetch_list(cls, client, ids):\n        \"\"\"\n        fetch instruments by ids\n        \"\"\"\n        results = []\n        request_url = \"https://api.robinhood.com/options/instruments/\"\n\n        for _ids in chunked_list(ids, 50):\n\n            params = {\"ids\": \",\".join(_ids)}\n            data = client.get(request_url, params=params)\n            partial_results = data[\"results\"]\n\n            while data[\"next\"]:\n                data = client.get(data[\"next\"])\n                partial_results.extend(data[\"results\"])\n            results.extend(partial_results)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches all option instruments in an options chain", "response": "def in_chain(cls, client, chain_id, expiration_dates=[]):\n        \"\"\"\n        fetch all option instruments in an options chain\n        - expiration_dates = optionally scope\n        \"\"\"\n\n        request_url = \"https://api.robinhood.com/options/instruments/\"\n        params = {\n            \"chain_id\": chain_id,\n            \"expiration_dates\": \",\".join(expiration_dates)\n        }\n\n        data = client.get(request_url, params=params)\n        results = data['results']\n\n        while data['next']:\n            data = client.get(data['next'])\n            results.extend(data['results'])\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unroll_option_legs(cls, client, option_orders):\n        '''\n        unroll option orders like this,\n        https://github.com/joshfraser/robinhood-to-csv/blob/master/csv-options-export.py\n        '''\n\n        #\n        # @TODO write this with python threats to make concurrent HTTP requests\n        #\n\n        results = []\n\n        for oo in option_orders:\n            for index, leg in enumerate(oo['legs']):\n                for execution in leg['executions']:\n                    order = dict()\n\n                    keys_in_question = ['legs', 'price', 'type', 'premium',\n                                        'processed_premium',\n                                        'response_category', 'cancel_url']\n                    for k, v in oo.items():\n                        if k not in keys_in_question:\n                            order[k] = oo[k]\n\n                    order['order_type'] = oo['type']\n\n                    contract = client.get(leg['option'])\n                    order['leg'] = index+1\n                    order['symbol'] = contract['chain_symbol']\n                    order['strike_price'] = contract['strike_price']\n                    order['expiration_date'] = contract['expiration_date']\n                    order['contract_type'] = contract['type']\n\n                    for k, v in leg.items():\n                        if k not in ['id', 'executions']:\n                            order[k] = leg[k]\n\n                    coef = (-1.0 if leg['side'] == 'buy' else 1.0)\n                    order['price'] = float(execution['price']) * 100.0 * coef\n                    order['execution_id'] = execution['id']\n\n                    results.append(order)\n        return results", "response": "unroll option legs like this"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef submit(cls, client, direction, legs, price, quantity, time_in_force,\n               trigger, order_type, run_validations=True):\n        '''\n        params:\n        - client\n        - direction\n        - legs\n        - price\n        - quantity\n        - time_in_force\n        - trigger\n        - order_type\n        - run_validations. default = True\n        '''\n\n        if run_validations:\n            assert(direction in [\"debit\", \"credit\"])\n            assert(type(price) is str)\n            assert(type(quantity) is int)\n            assert(time_in_force in [\"gfd\", \"gtc\"])\n            assert(trigger in [\"immediate\"])\n            assert(order_type in [\"limit\", \"market\"])\n            assert(cls._validate_legs(legs) is True)\n\n        payload = json.dumps({\n            \"account\": client.account_url,\n            \"direction\": direction,\n            \"legs\": legs,\n            \"price\": price,\n            \"quantity\": quantity,\n            \"time_in_force\": time_in_force,\n            \"trigger\": trigger,\n            \"type\": order_type,\n            \"override_day_trade_checks\": False,\n            \"override_dtbp_checks\": False,\n            \"ref_id\": str(uuid.uuid4())\n        })\n\n        request_url = \"https://api.robinhood.com/options/orders/\"\n        data = client.post(request_url, payload=payload)\n        return data", "response": "Submit an order to ROBinhood."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a set of unique entries for the given set of deltas.", "response": "def generate_by_deltas(cls, options,\n                           width, put_inner_lte_delta, call_inner_lte_delta):\n        \"\"\"\n        totally just playing around ideas for the API.\n\n        this IC sells\n        - credit put spread\n        - credit call spread\n\n        the approach\n        - set width for the wing spread (eg, 1, ie, 1 unit width spread)\n        - set delta for inner leg of the put credit spread (eg, -0.2)\n        - set delta for inner leg of the call credit spread (eg, 0.1)\n        \"\"\"\n\n        raise Exception(\"Not Implemented starting at the 0.3.0 release\")\n\n        #\n        # put credit spread\n        #\n        put_options_unsorted = list(\n            filter(lambda x: x['type'] == 'put', options))\n        put_options = cls.sort_by_strike_price(put_options_unsorted)\n\n        deltas_as_strings = [x['delta'] for x in put_options]\n        deltas = cls.strings_to_np_array(deltas_as_strings)\n\n        put_inner_index = np.argmin(deltas >= put_inner_lte_delta) - 1\n        put_outer_index = put_inner_index - width\n\n        put_inner_leg = cls.gen_leg(\n            put_options[put_inner_index][\"instrument\"], \"sell\")\n        put_outer_leg = cls.gen_leg(\n            put_options[put_outer_index][\"instrument\"], \"buy\")\n\n        #\n        # call credit spread\n        #\n        call_options_unsorted = list(\n            filter(lambda x: x['type'] == 'call', options))\n        call_options = cls.sort_by_strike_price(call_options_unsorted)\n\n        deltas_as_strings = [x['delta'] for x in call_options]\n        x = np.array(deltas_as_strings)\n        deltas = x.astype(np.float)\n        # because deep ITM call options have a delta that comes up as NaN,\n        # but are approximately 0.99 or 1.0, I'm replacing Nan with 1.0\n        # so np.argmax is able to walk up the index until it finds\n        # \"call_inner_lte_delta\"\n        # @TODO change this so (put credit / call credit) spreads work the same\n        where_are_NaNs = np.isnan(deltas)\n        deltas[where_are_NaNs] = 1.0\n\n        call_inner_index = np.argmax(deltas <= call_inner_lte_delta)\n        call_outer_index = call_inner_index + width\n\n        call_inner_leg = cls.gen_leg(\n            call_options[call_inner_index][\"instrument\"], \"sell\")\n        call_outer_leg = cls.gen_leg(\n            call_options[call_outer_index][\"instrument\"], \"buy\")\n\n        legs = [put_outer_leg, put_inner_leg, call_inner_leg, call_outer_leg]\n\n        #\n        # price calcs\n        #\n        price = (\n            - Decimal(put_options[put_outer_index]['adjusted_mark_price'])\n            + Decimal(put_options[put_inner_index]['adjusted_mark_price'])\n            + Decimal(call_options[call_inner_index]['adjusted_mark_price'])\n            - Decimal(call_options[call_outer_index]['adjusted_mark_price'])\n        )\n\n        #\n        # provide max bid ask spread diff\n        #\n        ic_options = [\n            put_options[put_outer_index],\n            put_options[put_inner_index],\n            call_options[call_inner_index],\n            call_options[call_outer_index]\n        ]\n\n        max_bid_ask_spread = cls.max_bid_ask_spread(ic_options)\n\n        return {\"legs\": legs, \"price\": price,\n                \"max_bid_ask_spread\": max_bid_ask_spread}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch(cls, client, _id, symbol):\n        url = \"https://api.robinhood.com/options/chains/\"\n        params = {\n            \"equity_instrument_ids\": _id,\n            \"state\": \"active\",\n            \"tradability\": \"tradable\"\n        }\n        data = client.get(url, params=params)\n\n        def filter_func(x):\n            return x[\"symbol\"] == symbol\n        results = list(filter(filter_func, data[\"results\"]))\n        return results[0]", "response": "fetch option chain for instrument _id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef authenticate(self):\n        '''\n        Authenticate using data in `options`\n        '''\n        if \"username\" in self.options and \"password\" in self.options:\n            self.login_oauth2(\n                self.options[\"username\"],\n                self.options[\"password\"],\n                self.options.get('mfa_code'))\n        elif \"access_token\" in self.options:\n            if \"refresh_token\" in self.options:\n                self.access_token = self.options[\"access_token\"]\n                self.refresh_token = self.options[\"refresh_token\"]\n                self.__set_account_info()\n        else:\n            self.authenticated = False\n        return self.authenticated", "response": "Authenticate using data in options"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, url=None, params=None, retry=True):\n        '''\n        Execute HTTP GET\n        '''\n        headers = self._gen_headers(self.access_token, url)\n        attempts = 1\n        while attempts <= HTTP_ATTEMPTS_MAX:\n            try:\n                res = requests.get(url,\n                                   headers=headers,\n                                   params=params,\n                                   timeout=15,\n                                   verify=self.certs)\n                res.raise_for_status()\n                return res.json()\n            except requests.exceptions.RequestException as e:\n                attempts += 1\n                if res.status_code in [400]:\n                    raise e\n                elif retry and res.status_code in [403]:\n                    self.relogin_oauth2()", "response": "Execute HTTP GET HTTP GET"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _gen_headers(self, bearer, url):\n        '''\n        Generate headders, adding in Oauth2 bearer token if present\n        '''\n        headers = {\n            \"Accept\": \"*/*\",\n            \"Accept-Encoding\": \"gzip, deflate\",\n            \"Accept-Language\": (\"en;q=1, fr;q=0.9, de;q=0.8, ja;q=0.7, \" +\n                                \"nl;q=0.6, it;q=0.5\"),\n            \"User-Agent\": (\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) \" +\n                           \"AppleWebKit/537.36 (KHTML, like Gecko) \" +\n                           \"Chrome/68.0.3440.106 Safari/537.36\"),\n\n        }\n        if bearer:\n            headers[\"Authorization\"] = \"Bearer {0}\".format(bearer)\n        if url == \"https://api.robinhood.com/options/orders/\":\n            headers[\"Content-Type\"] = \"application/json; charset=utf-8\"\n        return headers", "response": "Generate headders headers for the given bearer token and url"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef login_oauth2(self, username, password, mfa_code=None):\n        '''\n        Login using username and password\n        '''\n        data = {\n            \"grant_type\": \"password\",\n            \"scope\": \"internal\",\n            \"client_id\": CLIENT_ID,\n            \"expires_in\": 86400,\n            \"password\": password,\n            \"username\": username\n        }\n        if mfa_code is not None:\n            data['mfa_code'] = mfa_code\n        url = \"https://api.robinhood.com/oauth2/token/\"\n        res = self.post(url, payload=data, retry=False)\n\n        if res is None:\n            if mfa_code is None:\n                msg = (\"Client.login_oauth2(). Could not authenticate. Check \"\n                       + \"username and password.\")\n                raise AuthenticationError(msg)\n            else:\n                msg = (\"Client.login_oauth2(). Could not authenticate. Check\" +\n                       \"username and password, and enter a valid MFA code.\")\n                raise AuthenticationError(msg)\n        elif res.get('mfa_required') is True:\n            msg = \"Client.login_oauth2(). Couldn't authenticate. MFA required.\"\n            raise AuthenticationError(msg)\n\n        self.access_token = res[\"access_token\"]\n        self.refresh_token = res[\"refresh_token\"]\n        self.mfa_code = res[\"mfa_code\"]\n        self.scope = res[\"scope\"]\n        self.__set_account_info()\n        return self.authenticated", "response": "Login using username and password using MFA code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relogin_oauth2(self):\n        '''\n        (Re)login using the Oauth2 refresh token\n        '''\n        url = \"https://api.robinhood.com/oauth2/token/\"\n        data = {\n            \"grant_type\": \"refresh_token\",\n            \"refresh_token\": self.refresh_token,\n            \"scope\": \"internal\",\n            \"client_id\": CLIENT_ID,\n            \"expires_in\": 86400,\n        }\n        res = self.post(url, payload=data, retry=False)\n        self.access_token = res[\"access_token\"]\n        self.refresh_token = res[\"refresh_token\"]\n        self.mfa_code = res[\"mfa_code\"]\n        self.scope = res[\"scope\"]", "response": "Re - login using the Oauth2 refresh token"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef logout_oauth2(self):\n        '''\n        Logout for given Oauth2 bearer token\n        '''\n        url = \"https://api.robinhood.com/oauth2/revoke_token/\"\n        data = {\n            \"client_id\": CLIENT_ID,\n            \"token\": self.refresh_token,\n        }\n        res = self.post(url, payload=data)\n        if res is None:\n            self.account_id = None\n            self.account_url = None\n            self.access_token = None\n            self.refresh_token = None\n            self.mfa_code = None\n            self.scope = None\n            self.authenticated = False\n            return True\n        else:\n            raise AuthenticationError(\"fast_arrow could not log out.\")", "response": "Logout for given Oauth2 bearer token"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch(cls, client, symbol):\n        assert(type(symbol) is str)\n\n        url = (\"https://api.robinhood.com/instruments/?symbol={0}\".\n               format(symbol))\n        data = client.get(url)\n        return data[\"results\"][0]", "response": "fetch data for stock\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all(cls, client, symbols):\n        params = {\"symbol\": \",\".join(symbols)}\n        request_url = \"https://api.robinhood.com/instruments/\"\n\n        data = client.get(request_url, params=params)\n        results = data[\"results\"]\n\n        while data[\"next\"]:\n            data = client.get(data[\"next\"])\n            results.extend(data[\"results\"])\n        return results", "response": "fetch data for multiple stocks\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gen_df(cls, options, width, spread_type=\"call\", spread_kind=\"buy\"):\n        assert type(width) is int\n        assert spread_type in [\"call\", \"put\"]\n        assert spread_kind in [\"buy\", \"sell\"]\n\n        # get CALLs or PUTs\n        options = list(filter(lambda x: x[\"type\"] == spread_type, options))\n\n        coef = (1 if spread_type == \"put\" else -1)\n        shift = width * coef\n\n        df = pd.DataFrame.from_dict(options)\n        df['expiration_date'] = pd.to_datetime(\n            df['expiration_date'], format=\"%Y-%m-%d\")\n        df['adjusted_mark_price'] = pd.to_numeric(df['adjusted_mark_price'])\n        df['strike_price'] = pd.to_numeric(df['strike_price'])\n\n        df.sort_values([\"expiration_date\", \"strike_price\"], inplace=True)\n\n        for k, v in df.groupby(\"expiration_date\"):\n            sdf = v.shift(shift)\n\n            df.loc[v.index, \"strike_price_shifted\"] = sdf[\"strike_price\"]\n            df.loc[v.index, \"delta_shifted\"] = sdf[\"delta\"]\n            df.loc[v.index, \"volume_shifted\"] = sdf[\"volume\"]\n            df.loc[v.index, \"open_interest_shifted\"] = sdf[\"open_interest\"]\n            df.loc[v.index, \"instrument_shifted\"] = sdf[\"instrument\"]\n            df.loc[v.index, \"adjusted_mark_price_shift\"] = \\\n                sdf[\"adjusted_mark_price\"]\n\n            if spread_kind == \"sell\":\n                df.loc[v.index, \"margin\"] = \\\n                    abs(sdf[\"strike_price\"] - v[\"strike_price\"])\n            else:\n                df.loc[v.index, \"margin\"] = 0.0\n\n            if spread_kind == \"buy\":\n                df.loc[v.index, \"premium_adjusted_mark_price\"] = (\n                    v[\"adjusted_mark_price\"] - sdf[\"adjusted_mark_price\"])\n            elif spread_kind == \"sell\":\n                df.loc[v.index, \"premium_adjusted_mark_price\"] = (\n                    sdf[\"adjusted_mark_price\"] - v[\"adjusted_mark_price\"])\n        return df", "response": "Generate Pandas Dataframe of Vertical\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching data for multiple stocks", "response": "def all(cls, client):\n        \"\"\"\"\n        fetch data for multiple stocks\n        \"\"\"\n        url = \"https://api.robinhood.com/orders/\"\n        data = client.get(url)\n        results = data[\"results\"]\n        while data[\"next\"]:\n            data = client.get(data[\"next\"])\n            results.extend(data[\"results\"])\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields a list of lists of size _chunk_size", "response": "def chunked_list(_list, _chunk_size=50):\n    \"\"\"\n    Break lists into small lists for processing:w\n    \"\"\"\n    for i in range(0, len(_list), _chunk_size):\n        yield _list[i:i + _chunk_size]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quote_by_instruments(cls, client, ids):\n        base_url = \"https://api.robinhood.com/instruments\"\n        id_urls = [\"{}/{}/\".format(base_url, _id) for _id in ids]\n        return cls.quotes_by_instrument_urls(client, id_urls)", "response": "quote by instrument ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches and return results from the API for a list of instruments.", "response": "def quotes_by_instrument_urls(cls, client, urls):\n        \"\"\"\n        fetch and return results\n        \"\"\"\n        instruments = \",\".join(urls)\n        params = {\"instruments\": instruments}\n        url = \"https://api.robinhood.com/marketdata/quotes/\"\n        data = client.get(url, params=params)\n        results = data[\"results\"]\n        while \"next\" in data and data[\"next\"]:\n            data = client.get(data[\"next\"])\n            results.extend(data[\"results\"])\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all(cls, client, **kwargs):\n        max_date = kwargs['max_date'] if 'max_date' in kwargs else None\n        max_fetches = \\\n            kwargs['max_fetches'] if 'max_fetches' in kwargs else None\n\n        url = 'https://api.robinhood.com/options/positions/'\n        params = {}\n        data = client.get(url, params=params)\n        results = data[\"results\"]\n\n        if is_max_date_gt(max_date, results[-1]['updated_at'][0:10]):\n            return results\n        if max_fetches == 1:\n            return results\n\n        fetches = 1\n        while data[\"next\"]:\n            fetches = fetches + 1\n            data = client.get(data[\"next\"])\n            results.extend(data[\"results\"])\n            if is_max_date_gt(max_date, results[-1]['updated_at'][0:10]):\n                return results\n            if max_fetches and (fetches >= max_fetches):\n                return results\n        return results", "response": "fetch all option positions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mergein_marketdata_list(cls, client, option_positions):\n        ids = cls._extract_ids(option_positions)\n        mds = OptionMarketdata.quotes_by_instrument_ids(client, ids)\n\n        results = []\n        for op in option_positions:\n            # @TODO optimize this so it's better than O(n^2)\n            md = [x for x in mds if x['instrument'] == op['option']][0]\n            # there is no overlap in keys so this is fine\n            merged_dict = dict(list(op.items()) + list(md.items()))\n            results.append(merged_dict)\n        return results", "response": "Fetch and merge in Marketdata for each option position\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evaluateRawString(self, escaped):\n        unescaped = []\n        hexdigit = None\n        escape = False\n\n        for char in escaped:\n\n            number = ord(char)\n\n            if hexdigit is not None:\n                if hexdigit:\n                    number = (int(hexdigit, 16) << 4) + int(char, 16)\n                    hexdigit = None\n\n                else:\n                    hexdigit = char\n                    continue\n\n            if escape:\n                escape = False\n\n                try:\n                    number = self.ESCAPE_CHARS[number]\n\n                except KeyError:\n                    if number == 120:\n                        hexdigit = ''\n                        continue\n\n                    raise ValueError('Unknown escape character %c' % char)\n\n            elif number == 92:  # '\\'\n                escape = True\n                continue\n\n            unescaped.append(number)\n\n        return unescaped", "response": "Evaluates raw Python string like ast. literal_eval does"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list corresponding to the lines of text in the txt list containing the indented by prepend.", "response": "def shift(txt, indent = '    ', prepend = ''):\n    \"\"\"Return a list corresponding to the lines of text in the `txt` list\n    indented by `indent`. Prepend instead the string given in `prepend` to the\n    beginning of the first line. Note that if len(prepend) > len(indent), then\n    `prepend` will be truncated (doing better is tricky!). This preserves a \n    special '' entry at the end of `txt` (see `do_para` for the meaning).\n    \"\"\"\n    if type(indent) is int:\n        indent = indent * ' '\n    special_end = txt[-1:] == ['']\n    lines = ''.join(txt).splitlines(True)\n    for i in range(1,len(lines)):\n        if lines[i].strip() or indent.strip():\n            lines[i] = indent + lines[i]\n    if not lines:\n        return prepend\n    prepend = prepend[:len(indent)]\n    indent = indent[len(prepend):]\n    lines[0] = prepend + indent + lines[0]\n    ret = [''.join(lines)]\n    if special_end:\n        ret.append('')\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a given node.", "response": "def parse(self, node):\n        \"\"\"Parse a given node.  This function in turn calls the\n        `parse_<nodeType>` functions which handle the respective\n        nodes.\n\n        \"\"\"\n        pm = getattr(self, \"parse_%s\" % node.__class__.__name__)\n        pm(node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the subnodes of a given node.", "response": "def subnode_parse(self, node, pieces=None, indent=0, ignore=[], restrict=None):\n        \"\"\"Parse the subnodes of a given node. Subnodes with tags in the\n        `ignore` list are ignored. If pieces is given, use this as target for\n        the parse results instead of self.pieces. Indent all lines by the amount\n        given in `indent`. Note that the initial content in `pieces` is not\n        indented. The final result is in any case added to self.pieces.\"\"\"\n        if pieces is not None:\n            old_pieces, self.pieces = self.pieces, pieces\n        else:\n            old_pieces = []\n        if type(indent) is int:\n            indent = indent * ' '\n        if len(indent) > 0:\n            pieces = ''.join(self.pieces)\n            i_piece = pieces[:len(indent)]\n            if self.pieces[-1:] == ['']:\n                self.pieces = [pieces[len(indent):]] + ['']\n            elif self.pieces != []:\n                self.pieces = [pieces[len(indent):]]\n        self.indent += len(indent)\n        for n in node.childNodes:\n            if restrict is not None:\n                if n.nodeType == n.ELEMENT_NODE and n.tagName in restrict:\n                    self.parse(n)\n            elif n.nodeType != n.ELEMENT_NODE or n.tagName not in ignore:\n                self.parse(n)\n        if len(indent) > 0:\n            self.pieces = shift(self.pieces, indent, i_piece)\n        self.indent -= len(indent)\n        old_pieces.extend(self.pieces)\n        self.pieces = old_pieces"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef surround_parse(self, node, pre_char, post_char):\n        self.add_text(pre_char)\n        self.subnode_parse(node)\n        self.add_text(post_char)", "response": "Parse the subnodes of a given node. Prepend pre_char and append post_char to the output in self. pieces."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_specific_subnodes(self, node, name, recursive=0):\n        children = [x for x in node.childNodes if x.nodeType == x.ELEMENT_NODE]\n        ret = [x for x in children if x.tagName == name]\n        if recursive > 0:\n            for x in children:\n                ret.extend(self.get_specific_subnodes(x, name, recursive-1))\n        return ret", "response": "Given a node and a name return a list of child ELEMENT_NODEs that have a tagName matching the name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_specific_nodes(self, node, names):\n        nodes = [(x.tagName, x) for x in node.childNodes\n                 if x.nodeType == x.ELEMENT_NODE and\n                 x.tagName in names]\n        return dict(nodes)", "response": "Given a node and a sequence of strings in names return a dictionary containing the names as keys and child\n        s whose tagName equal to the name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_text(self, value):\n        if isinstance(value, (list, tuple)):\n            self.pieces.extend(value)\n        else:\n            self.pieces.append(value)", "response": "Adds text corresponding to value into self. pieces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking sure to create an empty line.", "response": "def start_new_paragraph(self):\n        \"\"\"Make sure to create an empty line. This is overridden, if the previous\n        text ends with the special marker ''. In that case, nothing is done.\n        \"\"\"\n        if self.pieces[-1:] == ['']: # respect special marker\n            return\n        elif self.pieces == []: # first paragraph, add '\\n', override with ''\n            self.pieces = ['\\n']\n        elif self.pieces[-1][-1:] != '\\n': # previous line not ended\n            self.pieces.extend(['  \\n' ,'\\n'])\n        else: #default\n            self.pieces.append('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds line of text and wrap such that subsequent lines are indented by indent spaces.", "response": "def add_line_with_subsequent_indent(self, line, indent=4):\n        \"\"\"Add line of text and wrap such that subsequent lines are indented\n        by `indent` spaces.\n        \"\"\"\n        if isinstance(line, (list, tuple)):\n            line = ''.join(line)\n        line = line.strip()\n        width = self.textwidth-self.indent-indent\n        wrapped_lines = textwrap.wrap(line[indent:], width=width)\n        for i in range(len(wrapped_lines)):\n            if wrapped_lines[i] != '':\n                wrapped_lines[i] = indent * ' ' + wrapped_lines[i]\n        self.pieces.append(line[:indent] + '\\n'.join(wrapped_lines)[indent:] + '  \\n')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract the string representation of the node or list of nodes by parsing the subnodes and then adding it to self. pieces.", "response": "def extract_text(self, node):\n        \"\"\"Return the string representation of the node or list of nodes by parsing the\n        subnodes, but returning the result as a string instead of adding it to `self.pieces`.\n        Note that this allows extracting text even if the node is in the ignore list.\n        \"\"\"\n        if not isinstance(node, (list, tuple)):\n            node = [node]\n        pieces, self.pieces = self.pieces, ['']\n        for n in node:\n            for sn in n.childNodes:\n                self.parse(sn)\n        ret = ''.join(self.pieces)\n        self.pieces = pieces\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_function_signature(self, node):\n        name = self.extract_text(self.get_specific_subnodes(node, 'name'))\n        if self.with_type_info:\n            argsstring = self.extract_text(self.get_specific_subnodes(node, 'argsstring'))\n        else:\n            argsstring = []\n            param_id = 1\n            for n_param in self.get_specific_subnodes(node, 'param'):\n                declname = self.extract_text(self.get_specific_subnodes(n_param, 'declname'))\n                if not declname:\n                    declname = 'arg' + str(param_id)\n                defval = self.extract_text(self.get_specific_subnodes(n_param, 'defval'))\n                if defval:\n                    defval = '=' + defval\n                argsstring.append(declname + defval)\n                param_id = param_id + 1\n            argsstring = '(' + ', '.join(argsstring) + ')'\n        type = self.extract_text(self.get_specific_subnodes(node, 'type'))\n        function_definition = name + argsstring\n        if type != '' and type != 'void':\n            function_definition = function_definition + ' -> ' + type\n        return '`' + function_definition + '`  '", "response": "Returns the function signature string for memberdef nodes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nproduce theConstructors section and the constructor signatures getTaxonomyName", "response": "def make_constructor_list(self, constructor_nodes, classname):\n        \"\"\"Produces the \"Constructors\" section and the constructor signatures\n        (since swig does not do so for classes) for class docstrings.\"\"\"\n        if constructor_nodes == []:\n            return\n        self.add_text(['\\n', 'Constructors',\n                       '\\n', '------------'])\n        for n in constructor_nodes:\n            self.add_text('\\n')\n            self.add_line_with_subsequent_indent('* ' + self.get_function_signature(n))\n            self.subnode_parse(n, pieces = [], indent=4, ignore=['definition', 'name'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the Attributes section in class docstrings for public ArcGIS class member variables.", "response": "def make_attribute_list(self, node):\n        \"\"\"Produces the \"Attributes\" section in class docstrings for public\n        member variables (attributes).\n        \"\"\"\n        atr_nodes = []\n        for n in self.get_specific_subnodes(node, 'memberdef', recursive=2):\n            if n.attributes['kind'].value == 'variable' and n.attributes['prot'].value == 'public':\n                atr_nodes.append(n)\n        if not atr_nodes:\n            return\n        self.add_text(['\\n', 'Attributes',\n                       '\\n', '----------'])\n        for n in atr_nodes:\n            name = self.extract_text(self.get_specific_subnodes(n, 'name'))\n            self.add_text(['\\n* ', '`', name, '`', ' : '])\n            self.add_text(['`', self.extract_text(self.get_specific_subnodes(n, 'type')), '`'])\n            self.add_text('  \\n')\n            restrict = ['briefdescription', 'detaileddescription']\n            self.subnode_parse(n, pieces=[''], indent=4, restrict=restrict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_memberdef_nodes_and_signatures(self, node, kind):\n        sig_dict = {}\n        sig_prefix = ''\n        if kind in ('file', 'namespace'):\n            ns_node = node.getElementsByTagName('innernamespace')\n            if not ns_node and kind == 'namespace':\n                ns_node = node.getElementsByTagName('compoundname')\n            if ns_node:\n                sig_prefix = self.extract_text(ns_node[0]) + '::'\n        elif kind in ('class', 'struct'):\n            # Get the full function name.\n            cn_node = node.getElementsByTagName('compoundname')\n            sig_prefix = self.extract_text(cn_node[0]) + '::'\n\n        md_nodes = self.get_specific_subnodes(node, 'memberdef', recursive=2)\n        for n in md_nodes:\n            if n.attributes['prot'].value != 'public':\n                continue\n            if n.attributes['kind'].value in ['variable', 'typedef']:\n                continue\n            if not self.get_specific_subnodes(n, 'definition'):\n                continue\n            name = self.extract_text(self.get_specific_subnodes(n, 'name'))\n            if name[:8] == 'operator':\n                continue\n            sig = sig_prefix + name\n            if sig in sig_dict:\n                sig_dict[sig].append(n)\n            else:\n                sig_dict[sig] = [n]\n        return sig_dict", "response": "Collects the memberdef nodes and corresponding signatures that are at most depth 2 deeper\n            than the current node. Returns a dictionary with the keys and values of corresponding memberdef nodes as keys and a list of corresponding memberdef nodes as values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_typical_memberdefs_no_overload(self, signature, memberdef_nodes):\n        for n in memberdef_nodes:\n            self.add_text(['\\n', '%feature(\"docstring\") ', signature, ' \"', '\\n'])\n            if self.with_function_signature:\n                self.add_line_with_subsequent_indent(self.get_function_signature(n))\n            self.subnode_parse(n, pieces=[], ignore=['definition', 'name'])\n            self.add_text(['\";', '\\n'])", "response": "Produce standard documentation for memberdef_nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nproduces docstring entries containing an Overloaded function section with the documentation for each overload.", "response": "def handle_typical_memberdefs(self, signature, memberdef_nodes):\n        \"\"\"Produces docstring entries containing an \"Overloaded function\"\n        section with the documentation for each overload, if the function is\n        overloaded and self.with_overloaded_functions is set. Else, produce\n        normal documentation.\n        \"\"\"\n        if len(memberdef_nodes) == 1 or not self.with_overloaded_functions:\n            self.handle_typical_memberdefs_no_overload(signature, memberdef_nodes)\n            return\n\n        self.add_text(['\\n', '%feature(\"docstring\") ', signature, ' \"', '\\n'])\n        if self.with_function_signature:\n            for n in memberdef_nodes:\n                self.add_line_with_subsequent_indent(self.get_function_signature(n))\n        self.add_text('\\n')\n        self.add_text(['Overloaded function', '\\n',\n                       '-------------------'])\n        for n in memberdef_nodes:\n            self.add_text('\\n')\n            self.add_line_with_subsequent_indent('* ' + self.get_function_signature(n))\n            self.subnode_parse(n, pieces=[], indent=4, ignore=['definition', 'name'])\n        self.add_text(['\";', '\\n'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the compounddef node and generates the docstring for the class namespace and file memberdef entries.", "response": "def do_compounddef(self, node):\n        \"\"\"This produces %feature(\"docstring\") entries for classes, and handles\n        class, namespace and file memberdef entries specially to allow for \n        overloaded functions. For other cases, passes parsing on to standard\n        handlers (which may produce unexpected results).\n        \"\"\"\n        kind = node.attributes['kind'].value\n        if kind in ('class', 'struct'):\n            prot = node.attributes['prot'].value\n            if prot != 'public':\n                return\n            self.add_text('\\n\\n')\n            classdefn = self.extract_text(self.get_specific_subnodes(node, 'compoundname'))\n            classname = classdefn.split('::')[-1]\n            self.add_text('%%feature(\"docstring\") %s \"\\n' % classdefn)\n\n            if self.with_constructor_list:\n                constructor_nodes = []\n                for n in self.get_specific_subnodes(node, 'memberdef', recursive=2):\n                    if n.attributes['prot'].value == 'public':\n                        if self.extract_text(self.get_specific_subnodes(n, 'definition')) == classdefn + '::' + classname:\n                            constructor_nodes.append(n)\n                for n in constructor_nodes:\n                    self.add_line_with_subsequent_indent(self.get_function_signature(n))\n\n            names = ('briefdescription','detaileddescription')\n            sub_dict = self.get_specific_nodes(node, names)\n            for n in ('briefdescription','detaileddescription'):\n                if n in sub_dict:\n                    self.parse(sub_dict[n])\n            if self.with_constructor_list:\n                self.make_constructor_list(constructor_nodes, classname)\n            if self.with_attribute_list:\n                self.make_attribute_list(node)\n\n            sub_list = self.get_specific_subnodes(node, 'includes')\n            if sub_list:\n                self.parse(sub_list[0])\n            self.add_text(['\";', '\\n'])\n\n            names = ['compoundname', 'briefdescription','detaileddescription', 'includes']\n            self.subnode_parse(node, ignore = names)\n\n        elif kind in ('file', 'namespace'):\n            nodes = node.getElementsByTagName('sectiondef')\n            for n in nodes:\n                self.parse(n)\n\n        # now explicitely handle possibly overloaded member functions.\n        if kind in ['class', 'struct','file', 'namespace']:\n            md_nodes = self.get_memberdef_nodes_and_signatures(node, kind)\n            for sig in md_nodes:\n                self.handle_typical_memberdefs(sig, md_nodes[sig])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle cases outside of class, struct, file or namespace. These are now dealt with by `handle_overloaded_memberfunction`. Do these even exist???", "response": "def do_memberdef(self, node):\n        \"\"\"Handle cases outside of class, struct, file or namespace. These are\n        now dealt with by `handle_overloaded_memberfunction`.\n        Do these even exist???\n        \"\"\"\n        prot = node.attributes['prot'].value\n        id = node.attributes['id'].value\n        kind = node.attributes['kind'].value\n        tmp = node.parentNode.parentNode.parentNode\n        compdef = tmp.getElementsByTagName('compounddef')[0]\n        cdef_kind = compdef.attributes['kind'].value\n        if cdef_kind in ('file', 'namespace', 'class', 'struct'):\n            # These cases are now handled by `handle_typical_memberdefs`\n            return\n        if prot != 'public':\n            return\n        first = self.get_specific_nodes(node, ('definition', 'name'))\n        name = self.extract_text(first['name'])\n        if name[:8] == 'operator':  # Don't handle operators yet.\n            return\n        if not 'definition' in first or kind in ['variable', 'typedef']:\n            return\n\n        data = self.extract_text(first['definition'])\n        self.add_text('\\n')\n        self.add_text(['/* where did this entry come from??? */', '\\n'])\n        self.add_text('%feature(\"docstring\") %s \"\\n%s' % (data, data))\n\n        for n in node.childNodes:\n            if n not in first.values():\n                self.parse(n)\n        self.add_text(['\";', '\\n'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visiblename(name, all=None, obj=None):\n\n    \"\"\"Decide whether to show documentation on a variable.\"\"\"\n\n    # Certain special names are redundant or internal.\n\n    # XXX Remove __initializing__?\n\n    if name in {'__author__', '__builtins__', '__cached__', '__credits__',\n\n                '__date__', '__doc__', '__file__', '__spec__',\n\n                '__loader__', '__module__', '__name__', '__package__',\n\n                '__path__', '__qualname__', '__slots__', '__version__'}:\n\n        return 0\n\n    if name.endswith(\"_swigregister\"):\n        return 0\n\n    if name.startswith(\"__swig\"):\n        return 0\n\n    # Private names are hidden, but special names are displayed.\n\n    if name.startswith('__') and name.endswith('__'): return 1\n\n    # Namedtuples have public fields and methods with a single leading underscore\n\n    if name.startswith('_') and hasattr(obj, '_fields'):\n\n        return True\n\n    if all is not None:\n\n        # only document that which the programmer exported in __all__\n\n        return name in all\n\n    else:\n\n        return not name.startswith('_')", "response": "Decide whether to show documentation on a variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _download_file(uri, bulk_api):\n    resp = requests.get(uri, headers=bulk_api.headers(), stream=True)\n    with tempfile.TemporaryFile(\"w+b\") as f:\n        for chunk in resp.iter_content(chunk_size=None):\n            f.write(chunk)\n        f.seek(0)\n        yield f", "response": "Download the bulk API result file for a single batch"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _split_batches(self, data, batch_size):\n        for i in range(0, len(data), batch_size):\n            yield data[i : i + batch_size]", "response": "Yield successive n - sized chunks from l."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_mapping(self, mapping):\n        mapping[\"oid_as_pk\"] = bool(mapping.get(\"fields\", {}).get(\"Id\"))\n        job_id, local_ids_for_batch = self._create_job(mapping)\n        result = self._wait_for_job(job_id)\n        # We store inserted ids even if some batches failed\n        self._store_inserted_ids(mapping, job_id, local_ids_for_batch)\n        return result", "response": "Load data for a single step."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitiates a bulk insert and upload batches to run in parallel.", "response": "def _create_job(self, mapping):\n        \"\"\"Initiate a bulk insert and upload batches to run in parallel.\"\"\"\n        job_id = self.bulk.create_insert_job(mapping[\"sf_object\"], contentType=\"CSV\")\n        self.logger.info(\"  Created bulk job {}\".format(job_id))\n\n        # Upload batches\n        local_ids_for_batch = {}\n        for batch_file, local_ids in self._get_batches(mapping):\n            batch_id = self.bulk.post_batch(job_id, batch_file)\n            local_ids_for_batch[batch_id] = local_ids\n            self.logger.info(\"    Uploaded batch {}\".format(batch_id))\n\n        self.bulk.close_job(job_id)\n        return job_id, local_ids_for_batch"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_batches(self, mapping, batch_size=10000):\n        action = mapping.get(\"action\", \"insert\")\n        fields = mapping.get(\"fields\", {}).copy()\n        static = mapping.get(\"static\", {})\n        lookups = mapping.get(\"lookups\", {})\n        record_type = mapping.get(\"record_type\")\n\n        # Skip Id field on insert\n        if action == \"insert\" and \"Id\" in fields:\n            del fields[\"Id\"]\n\n        # Build the list of fields to import\n        columns = []\n        columns.extend(fields.keys())\n        columns.extend(lookups.keys())\n        columns.extend(static.keys())\n\n        if record_type:\n            columns.append(\"RecordTypeId\")\n            # default to the profile assigned recordtype if we can't find any\n            # query for the RT by developer name\n            query = (\n                \"SELECT Id FROM RecordType WHERE SObjectType='{0}'\"\n                \"AND DeveloperName = '{1}' LIMIT 1\"\n            )\n            record_type_id = self.sf.query(\n                query.format(mapping.get(\"sf_object\"), record_type)\n            )[\"records\"][0][\"Id\"]\n\n        query = self._query_db(mapping)\n\n        total_rows = 0\n        batch_num = 1\n\n        def start_batch():\n            batch_file = io.BytesIO()\n            writer = unicodecsv.writer(batch_file)\n            writer.writerow(columns)\n            batch_ids = []\n            return batch_file, writer, batch_ids\n\n        batch_file, writer, batch_ids = start_batch()\n        for row in query.yield_per(batch_size):\n            total_rows += 1\n\n            # Add static values to row\n            pkey = row[0]\n            row = list(row[1:]) + list(static.values())\n            if record_type:\n                row.append(record_type_id)\n\n            writer.writerow([self._convert(value) for value in row])\n            batch_ids.append(pkey)\n\n            # Yield and start a new file every [batch_size] rows\n            if not total_rows % batch_size:\n                batch_file.seek(0)\n                self.logger.info(\"    Processing batch {}\".format(batch_num))\n                yield batch_file, batch_ids\n                batch_file, writer, batch_ids = start_batch()\n                batch_num += 1\n\n        # Yield result file for final batch\n        if batch_ids:\n            batch_file.seek(0)\n            yield batch_file, batch_ids\n\n        self.logger.info(\n            \"  Prepared {} rows for import to {}\".format(\n                total_rows, mapping[\"sf_object\"]\n            )\n        )", "response": "Get data from the local db and return a list of batches"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a query to retrieve data from the local db.", "response": "def _query_db(self, mapping):\n        \"\"\"Build a query to retrieve data from the local db.\n\n        Includes columns from the mapping\n        as well as joining to the id tables to get real SF ids\n        for lookups.\n        \"\"\"\n        model = self.models[mapping.get(\"table\")]\n\n        # Use primary key instead of the field mapped to SF Id\n        fields = mapping.get(\"fields\", {}).copy()\n        if mapping[\"oid_as_pk\"]:\n            del fields[\"Id\"]\n        id_column = model.__table__.primary_key.columns.keys()[0]\n        columns = [getattr(model, id_column)]\n\n        for f in fields.values():\n            columns.append(model.__table__.columns[f])\n        lookups = mapping.get(\"lookups\", {}).copy()\n        for lookup in lookups.values():\n            lookup[\"aliased_table\"] = aliased(\n                self.metadata.tables[\"{}_sf_ids\".format(lookup[\"table\"])]\n            )\n            columns.append(lookup[\"aliased_table\"].columns.sf_id)\n\n        query = self.session.query(*columns)\n        if \"record_type\" in mapping and hasattr(model, \"record_type\"):\n            query = query.filter(model.record_type == mapping[\"record_type\"])\n        if \"filters\" in mapping:\n            filter_args = []\n            for f in mapping[\"filters\"]:\n                filter_args.append(text(f))\n            query = query.filter(*filter_args)\n        for sf_field, lookup in lookups.items():\n            # Outer join with lookup ids table:\n            # returns main obj even if lookup is null\n            key_field = get_lookup_key_field(lookup, sf_field)\n            value_column = getattr(model, key_field)\n            query = query.outerjoin(\n                lookup[\"aliased_table\"],\n                lookup[\"aliased_table\"].columns.id == value_column,\n            )\n            # Order by foreign key to minimize lock contention\n            # by trying to keep lookup targets in the same batch\n            lookup_column = getattr(model, key_field)\n            query = query.order_by(lookup_column)\n        self.logger.info(str(query))\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading the job results and store inserted SF Ids in a new table", "response": "def _store_inserted_ids(self, mapping, job_id, local_ids_for_batch):\n        \"\"\"Get the job results and store inserted SF Ids in a new table\"\"\"\n        id_table_name = self._reset_id_table(mapping)\n        conn = self.session.connection()\n        for batch_id, local_ids in local_ids_for_batch.items():\n            try:\n                results_url = \"{}/job/{}/batch/{}/result\".format(\n                    self.bulk.endpoint, job_id, batch_id\n                )\n                # Download entire result file to a temporary file first\n                # to avoid the server dropping connections\n                with _download_file(results_url, self.bulk) as f:\n                    self.logger.info(\n                        \"  Downloaded results for batch {}\".format(batch_id)\n                    )\n                    self._store_inserted_ids_for_batch(\n                        f, local_ids, id_table_name, conn\n                    )\n                self.logger.info(\n                    \"  Updated {} for batch {}\".format(id_table_name, batch_id)\n                )\n            except Exception:  # pragma: nocover\n                # If we can't download one result file,\n                # don't let that stop us from downloading the others\n                self.logger.error(\n                    \"Could not download batch results: {}\".format(batch_id)\n                )\n                continue\n        self.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _reset_id_table(self, mapping):\n        if not hasattr(self, \"_initialized_id_tables\"):\n            self._initialized_id_tables = set()\n        id_table_name = \"{}_sf_ids\".format(mapping[\"table\"])\n        if id_table_name not in self._initialized_id_tables:\n            if id_table_name in self.metadata.tables:\n                self.metadata.remove(self.metadata.tables[id_table_name])\n            id_table = Table(\n                id_table_name,\n                self.metadata,\n                Column(\"id\", Unicode(255), primary_key=True),\n                Column(\"sf_id\", Unicode(18)),\n            )\n            if id_table.exists():\n                id_table.drop()\n            id_table.create()\n            self._initialized_id_tables.add(id_table_name)\n        return id_table_name", "response": "Create an empty table to hold the inserted SF Ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the first mapping for a table name", "response": "def _get_mapping_for_table(self, table):\n        \"\"\" Returns the first mapping for a table name \"\"\"\n        for mapping in self.mappings.values():\n            if mapping[\"table\"] == table:\n                return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_config(self):\n\n        if (\n            self.config\n        ):  # any config being pre-set at init will short circuit out, but not a plain {}\n            return\n\n        # Verify that we're in a project\n        repo_root = self.repo_root\n        if not repo_root:\n            raise NotInProject(\n                \"No git repository was found in the current path. You must be in a git repository to set up and use CCI for a project.\"\n            )\n\n        # Verify that the project's root has a config file\n        if not self.config_project_path:\n            raise ProjectConfigNotFound(\n                \"The file {} was not found in the repo root: {}. Are you in a CumulusCI Project directory?\".format(\n                    self.config_filename, repo_root\n                )\n            )\n\n        # Load the project's yaml config file\n        with open(self.config_project_path, \"r\") as f_config:\n            project_config = ordered_yaml_load(f_config)\n\n        if project_config:\n            self.config_project.update(project_config)\n\n        # Load the local project yaml config file if it exists\n        if self.config_project_local_path:\n            with open(self.config_project_local_path, \"r\") as f_local_config:\n                local_config = ordered_yaml_load(f_local_config)\n            if local_config:\n                self.config_project_local.update(local_config)\n\n        # merge in any additional yaml that was passed along\n        if self.additional_yaml:\n            additional_yaml_config = ordered_yaml_load(self.additional_yaml)\n            if additional_yaml_config:\n                self.config_additional_yaml.update(additional_yaml_config)\n\n        self.config = merge_config(\n            OrderedDict(\n                [\n                    (\"global_config\", self.config_global),\n                    (\"global_local\", self.config_global_local),\n                    (\"project_config\", self.config_project),\n                    (\"project_local_config\", self.config_project_local),\n                    (\"additional_yaml\", self.config_additional_yaml),\n                ]\n            )\n        )", "response": "Loads the configuration from YAML and updates the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize sentry. io error logging for this session", "response": "def init_sentry(self,):\n        \"\"\" Initializes sentry.io error logging for this session \"\"\"\n        if not self.use_sentry:\n            return\n\n        sentry_config = self.keychain.get_service(\"sentry\")\n\n        tags = {\n            \"repo\": self.repo_name,\n            \"branch\": self.repo_branch,\n            \"commit\": self.repo_commit,\n            \"cci version\": cumulusci.__version__,\n        }\n        tags.update(self.config.get(\"sentry_tags\", {}))\n\n        env = self.config.get(\"sentry_environment\", \"CumulusCI CLI\")\n\n        self.sentry = raven.Client(\n            dsn=sentry_config.dsn,\n            environment=env,\n            tags=tags,\n            processors=(\"raven.processors.SanitizePasswordsProcessor\",),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery GitHub releases to find the previous production release", "response": "def get_previous_version(self):\n        \"\"\"Query GitHub releases to find the previous production release\"\"\"\n        gh = self.get_github_api()\n        repo = gh.repository(self.repo_owner, self.repo_name)\n        most_recent = None\n        for release in repo.releases():\n            # Return the second release that matches the release prefix\n            if release.tag_name.startswith(self.project__git__prefix_release):\n                if most_recent is None:\n                    most_recent = release\n                else:\n                    return LooseVersion(self.get_version_for_tag(release.tag_name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef project_local_dir(self):\n\n        # depending on where we are in bootstrapping the BaseGlobalConfig\n        # the canonical projectname could be located in one of two places\n        if self.project__name:\n            name = self.project__name\n        else:\n            name = self.config_project.get(\"project\", {}).get(\"name\", \"\")\n        if name is None:\n            name = (\n                \"\"\n            )  # not entirely sure why this was happening in tests but this is the goal...\n\n        path = os.path.join(\n            os.path.expanduser(\"~\"), self.global_config_obj.config_local_dir, name\n        )\n        if not os.path.isdir(path):\n            os.makedirs(path)\n        return path", "response": "location of the user local directory for the project"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_static_dependencies(self, dependencies=None, include_beta=None):\n        if not dependencies:\n            dependencies = self.project__dependencies\n\n        if not dependencies:\n            return []\n\n        static_dependencies = []\n        for dependency in dependencies:\n            if \"github\" not in dependency:\n                static_dependencies.append(dependency)\n            else:\n                static = self.process_github_dependency(\n                    dependency, include_beta=include_beta\n                )\n                static_dependencies.extend(static)\n        return static_dependencies", "response": "Resolves the project - > dependencies section of cumulusci. yml\n            to convert dynamic github dependencies into static dependencies\n            by inspecting the referenced repositories\n            and returning a list of the static release names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_options(self, kwargs):\n        self.options = self.task_config.options\n        if self.options is None:\n            self.options = {}\n        if kwargs:\n            self.options.update(kwargs)\n\n        # Handle dynamic lookup of project_config values via $project_config.attr\n        for option, value in list(self.options.items()):\n            try:\n                if value.startswith(\"$project_config.\"):\n                    attr = value.replace(\"$project_config.\", \"\", 1)\n                    self.options[option] = getattr(self.project_config, attr, None)\n            except AttributeError:\n                pass", "response": "Initializes self. options based on kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _log_begin(self):\n        self.logger.info(\"Beginning task: %s\", self.__class__.__name__)\n        if self.salesforce_task and not self.flow:\n            self.logger.info(\"%15s %s\", \"As user:\", self.org_config.username)\n            self.logger.info(\"%15s %s\", \"In org:\", self.org_config.org_id)\n        self.logger.info(\"\")", "response": "Log the beginning of the execution of the task execution"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npolling for a result in a loop", "response": "def _poll(self):\n        \"\"\" poll for a result in a loop \"\"\"\n        while True:\n            self.poll_count += 1\n            self._poll_action()\n            if self.poll_complete:\n                break\n            time.sleep(self.poll_interval_s)\n            self._poll_update_interval()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _poll_update_interval(self):\n        # Increase by 1 second every 3 polls\n        if old_div(self.poll_count, 3) > self.poll_interval_level:\n            self.poll_interval_level += 1\n            self.poll_interval_s += 1\n            self.logger.info(\n                \"Increased polling interval to %d seconds\", self.poll_interval_s\n            )", "response": "update the polling interval to be used next iteration"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_project_config(self, *args, **kwargs):\n        warnings.warn(\n            \"BaseGlobalConfig.get_project_config is pending deprecation\",\n            DeprecationWarning,\n        )\n        return self.project_config_class(self, *args, **kwargs)", "response": "Returns a ProjectConfig object for the given project."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_config(self):\n        # load the global config\n        with open(self.config_global_path, \"r\") as f_config:\n            config = ordered_yaml_load(f_config)\n        self.config_global = config\n\n        # Load the local config\n        if self.config_global_local_path:\n            config = ordered_yaml_load(open(self.config_global_local_path, \"r\"))\n            self.config_global_local = config\n\n        self.config = merge_config(\n            OrderedDict(\n                [\n                    (\"global_config\", self.config_global),\n                    (\"global_local\", self.config_global_local),\n                ]\n            )\n        )", "response": "Loads the global configuration and local configuration"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef timestamp_file():\n    config_dir = os.path.join(\n        os.path.expanduser(\"~\"), BaseGlobalConfig.config_local_dir\n    )\n\n    if not os.path.exists(config_dir):\n        os.mkdir(config_dir)\n\n    timestamp_file = os.path.join(config_dir, \"cumulus_timestamp\")\n\n    try:\n        with open(timestamp_file, \"r+\") as f:\n            yield f\n    except IOError:  # file does not exist\n        with open(timestamp_file, \"w+\") as f:\n            yield f", "response": "Opens a file for tracking the time of the last version check"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pass_config(func=None, **config_kw):\n\n    def decorate(func):\n        def new_func(*args, **kw):\n            config = load_config(**config_kw)\n            func(config, *args, **kw)\n\n        return functools.update_wrapper(new_func, func)\n\n    if func is None:\n        return decorate\n    else:\n        return decorate(func)", "response": "Decorator which passes the CCI config object as the first arg to a click command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist the commands that can be configured", "response": "def list_commands(self, ctx):\n        \"\"\" list the services that can be configured \"\"\"\n        config = load_config(**self.load_config_kwargs)\n        services = self._get_services_config(config)\n        return sorted(services.keys())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_api_datetime(value):\n    dt = datetime.strptime(value[0:DATETIME_LEN], API_DATE_FORMAT)\n    offset_str = value[DATETIME_LEN:]\n    assert offset_str in [\"+0000\", \"Z\"], \"The Salesforce API returned a weird timezone.\"\n    return dt", "response": "parse a datetime returned from the Salesforce API"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_xml_element_file(name, path):\n    ET.register_namespace(\"\", \"http://soap.sforce.com/2006/04/metadata\")\n    tree = elementtree_parse_file(path)\n    tree = remove_xml_element(name, tree)\n    return tree.write(path, encoding=UTF8, xml_declaration=True)", "response": "Remove XML elements from a single file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves XML elements from a string", "response": "def remove_xml_element_string(name, content):\n    \"\"\" Remove XML elements from a string \"\"\"\n    ET.register_namespace(\"\", \"http://soap.sforce.com/2006/04/metadata\")\n    tree = ET.fromstring(content)\n    tree = remove_xml_element(name, tree)\n    clean_content = ET.tostring(tree, encoding=UTF8)\n    return clean_content"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves XML elements from an ElementTree content tree", "response": "def remove_xml_element(name, tree):\n    \"\"\" Removes XML elements from an ElementTree content tree \"\"\"\n    # root = tree.getroot()\n    remove = tree.findall(\n        \".//{{http://soap.sforce.com/2006/04/metadata}}{}\".format(name)\n    )\n    if not remove:\n        return tree\n\n    parent_map = {c: p for p in tree.iter() for c in p}\n\n    for elem in remove:\n        parent = parent_map[elem]\n        parent.remove(elem)\n\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zip_inject_namespace(\n    zip_src,\n    namespace=None,\n    managed=None,\n    filename_token=None,\n    namespace_token=None,\n    namespaced_org=None,\n    logger=None,\n):\n    \"\"\" Replaces %%%NAMESPACE%%% for all files and ___NAMESPACE___ in all\n        filenames in the zip with the either '' if no namespace is provided\n        or 'namespace__' if provided.\n    \"\"\"\n\n    # Handle namespace and filename tokens\n    if not filename_token:\n        filename_token = \"___NAMESPACE___\"\n    if not namespace_token:\n        namespace_token = \"%%%NAMESPACE%%%\"\n    if managed is True and namespace:\n        namespace_prefix = namespace + \"__\"\n    else:\n        namespace_prefix = \"\"\n\n    # Handle tokens %%%NAMESPACED_ORG%%% and ___NAMESPACED_ORG___\n    namespaced_org_token = \"%%%NAMESPACED_ORG%%%\"\n    namespaced_org_file_token = \"___NAMESPACED_ORG___\"\n    namespaced_org = namespace_prefix if namespaced_org else \"\"\n\n    # Handle token %%%NAMESPACE_OR_C%%% for lightning components\n    namespace_or_c_token = \"%%%NAMESPACE_OR_C%%%\"\n    namespace_or_c = namespace if managed and namespace else \"c\"\n\n    # Handle token %%%NAMESPACED_ORG_OR_C%%%\n    namespaced_org_or_c_token = \"%%%NAMESPACED_ORG_OR_C%%%\"\n    namespaced_org_or_c = namespace if namespaced_org else \"c\"\n\n    zip_dest = zipfile.ZipFile(io.BytesIO(), \"w\", zipfile.ZIP_DEFLATED)\n\n    for name in zip_src.namelist():\n        orig_name = str(name)\n        content = zip_src.read(name)\n        try:\n            content = content.decode(\"utf-8\")\n        except UnicodeDecodeError:\n            # if we cannot decode the content, don't try and replace it.\n            pass\n        else:\n            prev_content = content\n            content = content.replace(namespace_token, namespace_prefix)\n            if logger and content != prev_content:\n                logger.info(\n                    '  {}: Replaced %%%NAMESPACE%%% with \"{}\"'.format(name, namespace)\n                )\n\n            prev_content = content\n            content = content.replace(namespace_or_c_token, namespace_or_c)\n            if logger and content != prev_content:\n                logger.info(\n                    '  {}: Replaced %%%NAMESPACE_OR_C%%% with \"{}\"'.format(\n                        name, namespace_or_c\n                    )\n                )\n\n            prev_content = content\n            content = content.replace(namespaced_org_token, namespaced_org)\n            if logger and content != prev_content:\n                logger.info(\n                    '  {}: Replaced %%%NAMESPACED_ORG%%% with \"{}\"'.format(\n                        name, namespaced_org\n                    )\n                )\n\n            prev_content = content\n            content = content.replace(namespaced_org_or_c_token, namespaced_org_or_c)\n            if logger and content != prev_content:\n                logger.info(\n                    '  {}: Replaced %%%NAMESPACED_ORG_OR_C%%% with \"{}\"'.format(\n                        name, namespaced_org_or_c\n                    )\n                )\n\n            content = content.encode(\"utf-8\")\n\n        # Replace namespace token in file name\n        name = name.replace(filename_token, namespace_prefix)\n        name = name.replace(namespaced_org_file_token, namespaced_org)\n        if logger and name != orig_name:\n            logger.info(\"  {}: renamed to {}\".format(orig_name, name))\n        zip_dest.writestr(name, content)\n\n    return zip_dest", "response": "Injects the given namespace into the zip file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef zip_strip_namespace(zip_src, namespace, logger=None):\n    namespace_prefix = \"{}__\".format(namespace)\n    lightning_namespace = \"{}:\".format(namespace)\n    zip_dest = zipfile.ZipFile(io.BytesIO(), \"w\", zipfile.ZIP_DEFLATED)\n    for name in zip_src.namelist():\n        orig_content = zip_src.read(name)\n        try:\n            orig_content = orig_content.decode(\"utf-8\")\n        except UnicodeDecodeError:\n            # if we cannot decode the content, don't try and replace it.\n            new_content = orig_content\n        else:\n            new_content = orig_content.replace(namespace_prefix, \"\")\n            new_content = new_content.replace(lightning_namespace, \"c:\")\n            name = name.replace(namespace_prefix, \"\")  # not...sure...this..gets...used\n            if orig_content != new_content and logger:\n                logger.info(\n                    \"  {file_name}: removed {namespace}\".format(\n                        file_name=name, namespace=namespace_prefix\n                    )\n                )\n            new_content = new_content.encode(\"utf-8\")\n\n        zip_dest.writestr(name, new_content)\n    return zip_dest", "response": "Given a namespace strips namespace from all files and filenames\n            in the zip file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a namespace replaces namespace__ with %%%NAMESPACE%%% for all available all AttributeNames in all filenames in the zip file.", "response": "def zip_tokenize_namespace(zip_src, namespace, logger=None):\n    \"\"\" Given a namespace, replaces 'namespace__' with %%%NAMESPACE%%% for all\n        files and ___NAMESPACE___ in all filenames in the zip\n    \"\"\"\n    if not namespace:\n        return zip_src\n\n    namespace_prefix = \"{}__\".format(namespace)\n    lightning_namespace = \"{}:\".format(namespace)\n    zip_dest = zipfile.ZipFile(io.BytesIO(), \"w\", zipfile.ZIP_DEFLATED)\n    for name in zip_src.namelist():\n        content = zip_src.read(name)\n        try:\n            content = content.decode(\"utf-8\")\n        except UnicodeDecodeError:\n            # Probably a binary file; leave it untouched\n            pass\n        else:\n            content = content.replace(namespace_prefix, \"%%%NAMESPACE%%%\")\n            content = content.replace(lightning_namespace, \"%%%NAMESPACE_OR_C%%%\")\n            content = content.encode(\"utf-8\")\n            name = name.replace(namespace_prefix, \"___NAMESPACE___\")\n        zip_dest.writestr(name, content)\n    return zip_dest"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef zip_clean_metaxml(zip_src, logger=None):\n    zip_dest = zipfile.ZipFile(io.BytesIO(), \"w\", zipfile.ZIP_DEFLATED)\n    changed = []\n    for name in zip_src.namelist():\n        content = zip_src.read(name)\n        if name.startswith(META_XML_CLEAN_DIRS) and name.endswith(\"-meta.xml\"):\n            try:\n                content.decode(\"utf-8\")\n            except UnicodeDecodeError:\n                # if we cannot decode the content, it may be binary;\n                # don't try and replace it.\n                pass\n            else:\n                clean_content = remove_xml_element_string(\"packageVersions\", content)\n                if clean_content != content:\n                    changed.append(name)\n                    content = clean_content\n        zip_dest.writestr(name, content)\n    if changed and logger:\n        logger.info(\n            \"Cleaned package versions from {} meta.xml files\".format(len(changed))\n        )\n    return zip_dest", "response": "Given a zipfile cleans all meta. xml files in the zip for\n        deployment by stripping all packageVersions elements in the zip for\n        deployment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef doc_task(task_name, task_config, project_config=None, org_config=None):\n    from cumulusci.core.utils import import_class\n\n    doc = []\n    doc.append(\"{}\\n==========================================\\n\".format(task_name))\n    doc.append(\"**Description:** {}\\n\".format(task_config.description))\n    doc.append(\"**Class::** {}\\n\".format(task_config.class_path))\n\n    task_class = import_class(task_config.class_path)\n    task_docs = textwrap.dedent(task_class.task_docs.strip(\"\\n\"))\n    if task_docs:\n        doc.append(task_docs + \"\\n\")\n    if task_class.task_options:\n        doc.append(\"Options:\\n------------------------------------------\\n\")\n        defaults = task_config.options or {}\n        for name, option in list(task_class.task_options.items()):\n            default = defaults.get(name)\n            if default:\n                default = \" **Default: {}**\".format(default)\n            else:\n                default = \"\"\n            if option.get(\"required\"):\n                doc.append(\n                    \"* **{}** *(required)*: {}{}\".format(\n                        name, option.get(\"description\"), default\n                    )\n                )\n            else:\n                doc.append(\n                    \"* **{}**: {}{}\".format(name, option.get(\"description\"), default)\n                )\n\n    return \"\\n\".join(doc)", "response": "Return a RST formatted task configuration in RST format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef temporary_dir():\n    d = tempfile.mkdtemp()\n    try:\n        with cd(d):\n            yield d\n    finally:\n        if os.path.exists(d):\n            shutil.rmtree(d)", "response": "Context manager that creates a temporary directory and chdirs to it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a boolean for whether filepath is contained in dirpath.", "response": "def in_directory(filepath, dirpath):\n    \"\"\"Returns a boolean for whether filepath is contained in dirpath.\n\n    Normalizes the paths (e.g. resolving symlinks and ..)\n    so this is the safe way to make sure a user-configured path\n    is located inside the user's project repo.\n    \"\"\"\n    filepath = os.path.realpath(filepath)\n    dirpath = os.path.realpath(dirpath)\n    return filepath == dirpath or filepath.startswith(os.path.join(dirpath, \"\"))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_progress(\n    iterable,\n    logger,\n    batch_size=10000,\n    progress_message=\"Processing... ({})\",\n    done_message=\"Done! (Total: {})\",\n):\n    \"\"\"Log progress while iterating.\n    \"\"\"\n    i = 0\n    for x in iterable:\n        yield x\n        i += 1\n        if not i % batch_size:\n            logger.info(progress_message.format(i))\n    logger.info(done_message.format(i))", "response": "Log progress while iterating."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef login_url(self, org=None):\n        if org is None:\n            org = self.org\n        else:\n            org = self.keychain.get_org(org)\n        return org.start_url", "response": "Returns the login url which will automatically log into the target\n            Salesforce org."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_namespace_prefix(self, package=None):\n        result = \"\"\n        if package is None:\n            package = self.project_config.project__package__name_managed\n        packages = self.tooling.query(\n            \"SELECT SubscriberPackage.NamespacePrefix, SubscriberPackage.Name \"\n            \"FROM InstalledSubscriberPackage\"\n        )\n        match = [\n            p for p in packages[\"records\"] if p[\"SubscriberPackage\"][\"Name\"] == package\n        ]\n        if match:\n            result = match[0][\"SubscriberPackage\"][\"NamespacePrefix\"] + \"__\"\n        return result", "response": "Returns the namespace prefix for the specified package name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a named CumulusCI task for the current project.", "response": "def run_task(self, task_name, **options):\n        \"\"\" Runs a named CumulusCI task for the current project with optional\n            support for overriding task options via kwargs.\n\n            Examples:\n            | =Keyword= | =task_name= | =task_options=             | =comment=                        |\n            | Run Task  | deploy      |                            | Run deploy with standard options |\n            | Run Task  | deploy      | path=path/to/some/metadata | Run deploy with custom path      |\n        \"\"\"\n        task_config = self.project_config.get_task(task_name)\n        class_path = task_config.class_path\n        logger.console(\"\\n\")\n        task_class, task_config = self._init_task(class_path, options, task_config)\n        return self._run_task(task_class, task_config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_task_class(self, class_path, **options):\n        logger.console(\"\\n\")\n        task_class, task_config = self._init_task(class_path, options, TaskConfig())\n        return self._run_task(task_class, task_config)", "response": "Runs a CumulusCI task class with task options via kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a TaskConfig object for the given name.", "response": "def get_task(self, name):\n        \"\"\" Returns a TaskConfig \"\"\"\n        config = getattr(self, \"tasks__{}\".format(name))\n        if not config:\n            raise TaskNotFoundError(\"Task not found: {}\".format(name))\n        return TaskConfig(config)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a FlowConfig object for the given name.", "response": "def get_flow(self, name):\n        \"\"\" Returns a FlowConfig \"\"\"\n        config = getattr(self, \"flows__{}\".format(name))\n        if not config:\n            raise FlowNotFoundError(\"Flow not found: {}\".format(name))\n        return FlowConfig(config)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render(self):\n        release_notes = []\n        for parser in self.parsers:\n            parser_content = parser.render()\n            if parser_content is not None:\n                release_notes.append(parser_content)\n        return u\"\\r\\n\\r\\n\".join(release_notes)", "response": "Returns the rendered release notes from all parsers as a string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge existing and new release content.", "response": "def _update_release_content(self, release, content):\n        \"\"\"Merge existing and new release content.\"\"\"\n        if release.body:\n            new_body = []\n            current_parser = None\n            is_start_line = False\n            for parser in self.parsers:\n                parser.replaced = False\n\n            # update existing sections\n            for line in release.body.splitlines():\n\n                if current_parser:\n                    if current_parser._is_end_line(current_parser._process_line(line)):\n                        parser_content = current_parser.render()\n                        if parser_content:\n                            # replace existing section with new content\n                            new_body.append(parser_content + \"\\r\\n\")\n                        current_parser = None\n\n                for parser in self.parsers:\n                    if (\n                        parser._render_header().strip()\n                        == parser._process_line(line).strip()\n                    ):\n                        parser.replaced = True\n                        current_parser = parser\n                        is_start_line = True\n                        break\n                    else:\n                        is_start_line = False\n\n                if is_start_line:\n                    continue\n                if current_parser:\n                    continue\n                else:\n                    # preserve existing sections\n                    new_body.append(line.strip())\n\n            # catch section without end line\n            if current_parser:\n                new_body.append(current_parser.render())\n\n            # add new sections at bottom\n            for parser in self.parsers:\n                parser_content = parser.render()\n                if parser_content and not parser.replaced:\n                    new_body.append(parser_content + \"\\r\\n\")\n\n            content = u\"\\r\\n\".join(new_body)\n\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_flow(self, name, options=None):\n        config = self.project_config.get_flow(name)\n        callbacks = self.callback_class()\n        coordinator = FlowCoordinator(\n            self.project_config,\n            config,\n            name=name,\n            options=options,\n            skip=None,\n            callbacks=callbacks,\n        )\n        return coordinator", "response": "Get a primed and readytogo FlowCoordinator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_env(self):\n        env = {}\n        for k, v in os.environ.items():\n            k = k.decode() if isinstance(k, bytes) else k\n            v = v.decode() if isinstance(v, bytes) else v\n            env[k] = v\n        return list(env.items())", "response": "loads the environment variables as unicode if ascii"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_class(path):\n    components = path.split(\".\")\n    module = components[:-1]\n    module = \".\".join(module)\n    mod = __import__(module, fromlist=[native_str(components[-1])])\n    return getattr(mod, native_str(components[-1]))", "response": "Imports a class from a string module class path"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a timezone - aware datetime object from a datetime string.", "response": "def parse_datetime(dt_str, format):\n    \"\"\"Create a timezone-aware datetime object from a datetime string.\"\"\"\n    t = time.strptime(dt_str, format)\n    return datetime(t[0], t[1], t[2], t[3], t[4], t[5], t[6], pytz.UTC)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine True or False from argument", "response": "def process_bool_arg(arg):\n    \"\"\" Determine True/False from argument \"\"\"\n    if isinstance(arg, bool):\n        return arg\n    elif isinstance(arg, basestring):\n        if arg.lower() in [\"true\", \"1\"]:\n            return True\n        elif arg.lower() in [\"false\", \"0\"]:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a string into a list separated by commas with whitespace stripped", "response": "def process_list_arg(arg):\n    \"\"\" Parse a string into a list separated by commas with whitespace stripped \"\"\"\n    if isinstance(arg, list):\n        return arg\n    elif isinstance(arg, basestring):\n        args = []\n        for part in arg.split(\",\"):\n            args.append(part.strip())\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding ISO - 8859 - 1 to unicode", "response": "def decode_to_unicode(content):\n    \"\"\" decode ISO-8859-1 to unicode, when using sf api \"\"\"\n    if content and not isinstance(content, str):\n        try:\n            # Try to decode ISO-8859-1 to unicode\n            return content.decode(\"ISO-8859-1\")\n        except UnicodeEncodeError:\n            # Assume content is unicode already\n            return content\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_config(configs):\n    new_config = {}\n\n    for name, config in configs.items():\n        new_config = dictmerge(new_config, config, name)\n\n    return new_config", "response": "Merge the configs into one."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges two dicts that consist of lists dicts and scalars.", "response": "def dictmerge(a, b, name=None):\n    \"\"\" Deeply merge two ``dict``s that consist of lists, dicts, and scalars.\n    This function (recursively) merges ``b`` INTO ``a``, does not copy any values, and returns ``a``.\n\n    based on https://stackoverflow.com/a/15836901/5042831\n    NOTE: tuples and arbitrary objects are NOT handled and will raise TypeError \"\"\"\n\n    key = None\n\n    if b is None:\n        return a\n\n    try:\n        if a is None or isinstance(a, (bytes, int, str, float)):\n            # first run, or if ``a``` is a scalar\n            a = b\n        elif isinstance(a, list):\n            # lists can be only appended\n            if isinstance(b, list):\n                # merge lists\n                a.extend(b)\n            else:\n                # append to list\n                a.append(b)\n        elif isinstance(a, dict):\n            # dicts must be merged\n            if isinstance(b, dict):\n                for key in b:\n                    if key in a:\n                        a[key] = dictmerge(a[key], b[key], name)\n                    else:\n                        a[key] = copy.copy(b[key])\n            else:\n                raise TypeError(\n                    'Cannot merge non-dict of type \"{}\" into dict \"{}\"'.format(\n                        type(b), a\n                    )\n                )\n        else:\n            raise TypeError(\n                'dictmerge does not supporting merging \"{}\" into \"{}\"'.format(\n                    type(b), type(a)\n                )\n            )\n    except TypeError as e:\n        raise ConfigMergeError(\n            'TypeError \"{}\" in key \"{}\" when merging \"{}\" into \"{}\"'.format(\n                e, key, type(b), type(a)\n            ),\n            config_name=name,\n        )\n    return a"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_or_create_version(self, product):\n        tag = self.options[\"tag\"]\n\n        label = self.project_config.get_version_for_tag(tag)\n        result = self._call_api(\n            \"GET\", \"/versions\", params={\"product\": product[\"id\"], \"label\": label}\n        )\n        if len(result[\"data\"]) == 0:\n            version = self._call_api(\n                \"POST\",\n                \"/versions\",\n                json={\n                    \"product\": product[\"url\"],\n                    \"label\": label,\n                    \"description\": self.options.get(\"description\", \"\"),\n                    \"is_production\": True,\n                    \"commit_ish\": tag,\n                    \"is_listed\": False,\n                },\n            )\n            self.logger.info(\"Created {}\".format(version[\"url\"]))\n        else:\n            version = result[\"data\"][0]\n            self.logger.info(\"Found {}\".format(version[\"url\"]))\n        return version", "response": "Find or create a Version in MetaDeploy if it doesn t already exist"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the html. `libraries` is a list of LibraryDocumentation objects", "response": "def _render_html(self, libraries):\n        \"\"\"Generate the html. `libraries` is a list of LibraryDocumentation objects\"\"\"\n\n        title = self.options.get(\"title\", \"Keyword Documentation\")\n        date = time.strftime(\"%A %B %d, %I:%M %p\")\n        cci_version = cumulusci.__version__\n\n        stylesheet_path = os.path.join(os.path.dirname(__file__), \"stylesheet.css\")\n        with open(stylesheet_path) as f:\n            stylesheet = f.read()\n\n        jinjaenv = jinja2.Environment(\n            loader=jinja2.FileSystemLoader(os.path.dirname(__file__)), autoescape=False\n        )\n        jinjaenv.filters[\"robot_html\"] = robot.utils.html_format\n        template = jinjaenv.get_template(\"template.html\")\n        return template.render(\n            libraries=libraries,\n            title=title,\n            cci_version=cci_version,\n            stylesheet=stylesheet,\n            date=date,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_org(self):\n        if not self.config_file:\n            # FIXME: raise exception\n            return\n        if not self.scratch_org_type:\n            self.config[\"scratch_org_type\"] = \"workspace\"\n\n        # If the scratch org definition itself contains an `adminEmail` entry,\n        # we don't want to override it from our own configuration, which may\n        # simply come from the user's Git config.\n\n        with open(self.config_file, \"r\") as org_def:\n            org_def_data = json.load(org_def)\n            org_def_has_email = \"adminEmail\" in org_def_data\n\n        options = {\n            \"config_file\": self.config_file,\n            \"devhub\": \" --targetdevhubusername {}\".format(self.devhub)\n            if self.devhub\n            else \"\",\n            \"namespaced\": \" -n\" if not self.namespaced else \"\",\n            \"days\": \" --durationdays {}\".format(self.days) if self.days else \"\",\n            \"alias\": sarge.shell_format(' -a \"{0!s}\"', self.sfdx_alias)\n            if self.sfdx_alias\n            else \"\",\n            \"email\": sarge.shell_format('adminEmail=\"{0!s}\"', self.email_address)\n            if self.email_address and not org_def_has_email\n            else \"\",\n            \"extraargs\": os.environ.get(\"SFDX_ORG_CREATE_ARGS\", \"\"),\n        }\n\n        # This feels a little dirty, but the use cases for extra args would mostly\n        # work best with env vars\n        command = \"sfdx force:org:create -f {config_file}{devhub}{namespaced}{days}{alias} {email} {extraargs}\".format(\n            **options\n        )\n        self.logger.info(\"Creating scratch org with command {}\".format(command))\n        p = sarge.Command(\n            command,\n            stdout=sarge.Capture(buffer_size=-1),\n            stderr=sarge.Capture(buffer_size=-1),\n            shell=True,\n        )\n        p.run()\n\n        stderr = [line.strip() for line in io.TextIOWrapper(p.stderr)]\n        stdout = [line.strip() for line in io.TextIOWrapper(p.stdout)]\n\n        if p.returncode:\n            message = \"{}: \\n{}\\n{}\".format(\n                FAILED_TO_CREATE_SCRATCH_ORG, \"\\n\".join(stdout), \"\\n\".join(stderr)\n            )\n            raise ScratchOrgException(message)\n\n        re_obj = re.compile(\"Successfully created scratch org: (.+), username: (.+)\")\n        for line in stdout:\n            match = re_obj.search(line)\n            if match:\n                self.config[\"org_id\"] = match.group(1)\n                self.config[\"username\"] = match.group(2)\n            self.logger.info(line)\n        for line in stderr:\n            self.logger.error(line)\n\n        self.config[\"date_created\"] = datetime.datetime.now()\n\n        if self.config.get(\"set_password\"):\n            self.generate_password()\n\n        # Flag that this org has been created\n        self.config[\"created\"] = True", "response": "Creates the scratch org."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_password(self):\n\n        if self.password_failed:\n            self.logger.warning(\"Skipping resetting password since last attempt failed\")\n            return\n\n        # Set a random password so it's available via cci org info\n        command = sarge.shell_format(\n            \"sfdx force:user:password:generate -u {0}\", self.username\n        )\n        self.logger.info(\n            \"Generating scratch org user password with command {}\".format(command)\n        )\n        p = sarge.Command(\n            command,\n            stdout=sarge.Capture(buffer_size=-1),\n            stderr=sarge.Capture(buffer_size=-1),\n            shell=True,\n        )\n        p.run()\n\n        stderr = io.TextIOWrapper(p.stderr).readlines()\n        stdout = io.TextIOWrapper(p.stdout).readlines()\n\n        if p.returncode:\n            self.config[\"password_failed\"] = True\n            # Don't throw an exception because of failure creating the\n            # password, just notify in a log message\n            self.logger.warning(\n                \"Failed to set password: \\n{}\\n{}\".format(\n                    \"\\n\".join(stdout), \"\\n\".join(stderr)\n                )\n            )", "response": "Generates an org user password with the sfdx utility."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting the scratch org", "response": "def delete_org(self):\n        \"\"\" Uses sfdx force:org:delete to delete the org \"\"\"\n        if not self.created:\n            self.logger.info(\n                \"Skipping org deletion: the scratch org has not been created\"\n            )\n            return\n\n        command = sarge.shell_format(\"sfdx force:org:delete -p -u {0}\", self.username)\n        self.logger.info(\"Deleting scratch org with command {}\".format(command))\n        p = sarge.Command(command, stdout=sarge.Capture(buffer_size=-1), shell=True)\n        p.run()\n\n        stdout = []\n        for line in io.TextIOWrapper(p.stdout):\n            stdout.append(line)\n            if line.startswith(\"An error occurred deleting this org\"):\n                self.logger.error(line)\n            else:\n                self.logger.info(line)\n\n        if p.returncode:\n            message = \"Failed to delete scratch org: \\n{}\".format(\"\".join(stdout))\n            raise ScratchOrgException(message)\n\n        # Flag that this org has been deleted\n        self.config[\"created\"] = False\n        self.config[\"username\"] = None\n        self.config[\"date_created\"] = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrefresh the OAuth token for the specified keychain.", "response": "def refresh_oauth_token(self, keychain):\n        \"\"\" Use sfdx force:org:describe to refresh token instead of built in OAuth handling \"\"\"\n        if hasattr(self, \"_scratch_info\"):\n            # Cache the scratch_info for 1 hour to avoid unnecessary calls out\n            # to sfdx CLI\n            delta = datetime.datetime.utcnow() - self._scratch_info_date\n            if delta.total_seconds() > 3600:\n                del self._scratch_info\n\n                # Force a token refresh\n                self.force_refresh_oauth_token()\n\n        # Get org info via sfdx force:org:display\n        self.scratch_info\n        # Get additional org info by querying API\n        self._load_orginfo()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the time that the batch took if complete", "response": "def delta(self):\n        \"\"\" returns the time (in seconds) that the batch took, if complete \"\"\"\n        completed_date = parse_api_datetime(self.batch[\"CompletedDate\"])\n        created_date = parse_api_datetime(self.batch[\"CreatedDate\"])\n        td = completed_date - created_date\n        return td.total_seconds()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert Connected App to service", "response": "def _convert_connected_app(self):\n        \"\"\"Convert Connected App to service\"\"\"\n        if self.services and \"connected_app\" in self.services:\n            # already a service\n            return\n        connected_app = self.get_connected_app()\n        if not connected_app:\n            # not configured\n            return\n        self.logger.warning(\n            \"Reading Connected App info from deprecated config.\"\n            \" Connected App should be changed to a service.\"\n            \" If using environment keychain, update the environment variable.\"\n            \" Otherwise, it has been handled automatically and you should not\"\n            \" see this message again.\"\n        )\n        ca_config = ServiceConfig(\n            {\n                \"callback_url\": connected_app.callback_url,\n                \"client_id\": connected_app.client_id,\n                \"client_secret\": connected_app.client_secret,\n            }\n        )\n        self.set_service(\"connected_app\", ca_config)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _load_scratch_orgs(self):\n        current_orgs = self.list_orgs()\n        if not self.project_config.orgs__scratch:\n            return\n        for config_name in self.project_config.orgs__scratch.keys():\n            if config_name in current_orgs:\n                # Don't overwrite an existing keychain org\n                continue\n            self.create_scratch_org(config_name, config_name)", "response": "Creates all scratch org configs for the project in the keychain"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a scratch org config from a named config", "response": "def create_scratch_org(self, org_name, config_name, days=None, set_password=True):\n        \"\"\" Adds/Updates a scratch org config to the keychain from a named config \"\"\"\n        scratch_config = getattr(\n            self.project_config, \"orgs__scratch__{}\".format(config_name)\n        )\n        if days is not None:\n            # Allow override of scratch config's default days\n            scratch_config[\"days\"] = days\n        else:\n            # Use scratch config days or default of 1 day\n            scratch_config.setdefault(\"days\", 1)\n        scratch_config[\"set_password\"] = bool(set_password)\n        scratch_config[\"scratch\"] = True\n        scratch_config.setdefault(\"namespaced\", False)\n        scratch_config[\"config_name\"] = config_name\n        scratch_config[\"sfdx_alias\"] = \"{}__{}\".format(\n            self.project_config.project__name, org_name\n        )\n        org_config = ScratchOrgConfig(scratch_config, org_name)\n        self.set_org(org_config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_default_org(self):\n        for org in self.list_orgs():\n            org_config = self.get_org(org)\n            if org_config.default:\n                return org, org_config\n        return None, None", "response": "retrieve the name and configuration of the default org"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_default_org(self, name):\n        org = self.get_org(name)\n        self.unset_default_org()\n        org.config[\"default\"] = True\n        self.set_org(org)", "response": "set the default org for the given name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving an org configuration by name", "response": "def get_org(self, name):\n        \"\"\" retrieve an org configuration by name key \"\"\"\n        if name not in self.orgs:\n            self._raise_org_not_found(name)\n        return self._get_org(name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting the orgs configured in the keychain", "response": "def list_orgs(self):\n        \"\"\" list the orgs configured in the keychain \"\"\"\n        orgs = list(self.orgs.keys())\n        orgs.sort()\n        return orgs"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstores a ServiceConfig in the keychain.", "response": "def set_service(self, name, service_config, project=False):\n        \"\"\" Store a ServiceConfig in the keychain \"\"\"\n        if not self.project_config.services or name not in self.project_config.services:\n            self._raise_service_not_valid(name)\n        self._validate_service(name, service_config)\n        self._set_service(name, service_config, project)\n        self._load_services()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_service(self, name):\n        self._convert_connected_app()\n        if not self.project_config.services or name not in self.project_config.services:\n            self._raise_service_not_valid(name)\n        if name not in self.services:\n            self._raise_service_not_configured(name)\n\n        return self._get_service(name)", "response": "Retrieve a stored ServiceConfig from the keychain or exception\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist the services configured in the keychain", "response": "def list_services(self):\n        \"\"\" list the services configured in the keychain \"\"\"\n        services = list(self.services.keys())\n        services.sort()\n        return services"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the Python debugger when robotframework is running.", "response": "def set_pdb_trace(pm=False):\n    \"\"\"Start the Python debugger when robotframework is running.\n\n    This makes sure that pdb can use stdin/stdout even though\n    robotframework has redirected I/O.\n    \"\"\"\n    import sys\n    import pdb\n\n    for attr in (\"stdin\", \"stdout\", \"stderr\"):\n        setattr(sys, attr, getattr(sys, \"__%s__\" % attr))\n    if pm:\n        # Post-mortem debugging of an exception\n        pdb.post_mortem()\n    else:\n        pdb.set_trace()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef selenium_retry(target=None, retry=True):\n\n    if isinstance(target, bool):\n        # Decorator was called with a single boolean argument\n        retry = target\n        target = None\n\n    def decorate(target):\n        if isinstance(target, type):\n            cls = target\n            # Metaclass time.\n            # We're going to generate a new subclass that:\n            # a) mixes in RetryingSeleniumLibraryMixin\n            # b) sets the initial value of `retry_selenium`\n            return type(\n                cls.__name__,\n                (cls, RetryingSeleniumLibraryMixin),\n                {\"retry_selenium\": retry, \"__doc__\": cls.__doc__},\n            )\n        func = target\n\n        @functools.wraps(func)\n        def run_with_retry(self, *args, **kwargs):\n            # Set the retry setting and run the original function.\n            old_retry = self.retry_selenium\n            self.retry = retry\n            try:\n                return func(self, *args, **kwargs)\n            finally:\n                # Restore the previous value\n                self.retry_selenium = old_retry\n\n        set_pdb_trace()\n        run_with_retry.is_selenium_retry_decorator = True\n        return run_with_retry\n\n    if target is None:\n        # Decorator is being used with arguments\n        return decorate\n    else:\n        # Decorator was used without arguments\n        return decorate(target)", "response": "Decorator to turn on automatic retries of flaky selenium failures."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns a single selenium command and retry once.", "response": "def selenium_execute_with_retry(self, execute, command, params):\n        \"\"\"Run a single selenium command and retry once.\n\n        The retry happens for certain errors that are likely to be resolved\n        by retrying.\n        \"\"\"\n        try:\n            return execute(command, params)\n        except Exception as e:\n            if isinstance(e, ALWAYS_RETRY_EXCEPTIONS) or (\n                isinstance(e, WebDriverException)\n                and \"Other element would receive the click\" in str(e)\n            ):\n                # Retry\n                self.builtin.log(\"Retrying {} command\".format(command), level=\"WARN\")\n                time.sleep(2)\n                return execute(command, params)\n            else:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the last release tag before self. current_tag", "response": "def _get_last_tag(self):\n        \"\"\" Gets the last release tag before self.current_tag \"\"\"\n\n        current_version = LooseVersion(\n            self._get_version_from_tag(self.release_notes_generator.current_tag)\n        )\n\n        versions = []\n        for tag in self.repo.tags():\n            if not tag.name.startswith(self.github_info[\"prefix_prod\"]):\n                continue\n            version = LooseVersion(self._get_version_from_tag(tag.name))\n            if version >= current_version:\n                continue\n            versions.append(version)\n        if versions:\n            versions.sort()\n            return \"{}{}\".format(self.github_info[\"prefix_prod\"], versions[-1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all pull requests from the repo since we can t do a merged search", "response": "def _get_pull_requests(self):\n        \"\"\" Gets all pull requests from the repo since we can't do a filtered\n        date merged search \"\"\"\n        for pull in self.repo.pull_requests(\n            state=\"closed\", base=self.github_info[\"master_branch\"], direction=\"asc\"\n        ):\n            if self._include_pull_request(pull):\n                yield pull"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _include_pull_request(self, pull_request):\n\n        merged_date = pull_request.merged_at\n        if not merged_date:\n            return False\n        if self.last_tag:\n            last_tag_sha = self.last_tag_info[\"commit\"].sha\n            if pull_request.merge_commit_sha == last_tag_sha:\n                # Github commit dates can be different from the merged_at date\n                return False\n\n        current_tag_sha = self.current_tag_info[\"commit\"].sha\n        if pull_request.merge_commit_sha == current_tag_sha:\n            return True\n\n        # include PRs before current tag\n        if merged_date <= self.start_date:\n            if self.end_date:\n                # include PRs after last tag\n                if (\n                    merged_date > self.end_date\n                    and pull_request.merge_commit_sha != last_tag_sha\n                ):\n                    return True\n            else:\n                # no last tag, include all PRs before current tag\n                return True\n\n        return False", "response": "Checks if the given pull_request was merged to the default branch branch\n        between self. start_date and self. end_date. Returns True if the pull_request was merged to the default branch branch\n        False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef patch_statusreporter():\n    from robot.running.statusreporter import StatusReporter\n\n    orig_exit = StatusReporter.__exit__\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_val and isinstance(exc_val, Exception):\n            set_pdb_trace(pm=True)\n        return orig_exit(self, exc_type, exc_val, exc_tb)\n\n    StatusReporter.__exit__ = __exit__", "response": "Monkey patch robotframework to do postmortem debugging\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the value of the first name element found inside of the item.", "response": "def get_item_name(self, item, parent):\n        \"\"\" Returns the value of the first name element found inside of element \"\"\"\n        names = self.get_name_elements(item)\n        if not names:\n            raise MissingNameElementError\n\n        name = names[0].text\n        prefix = self.item_name_prefix(parent)\n        if prefix:\n            name = prefix + name\n\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string that can be used to display the current step details.", "response": "def for_display(self):\n        \"\"\" Step details formatted for logging output. \"\"\"\n        skip = \"\"\n        if self.skip:\n            skip = \" [SKIP]\"\n        result = \"{step_num}: {path}{skip}\".format(\n            step_num=self.step_num, path=self.path, skip=skip\n        )\n        description = self.task_config.get(\"description\")\n        if description:\n            result += \": {}\".format(description)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_step(self):\n\n        # Resolve ^^task_name.return_value style option syntax\n        task_config = self.step.task_config.copy()\n        task_config[\"options\"] = task_config[\"options\"].copy()\n        self.flow.resolve_return_value_options(task_config[\"options\"])\n\n        exc = None\n        try:\n            task = self.step.task_class(\n                self.project_config,\n                TaskConfig(task_config),\n                org_config=self.org_config,\n                name=self.step.task_name,\n                stepnum=self.step.step_num,\n                flow=self.flow,\n            )\n            self._log_options(task)\n            task()\n        except Exception as e:\n            self.flow.logger.exception(\n                \"Exception in task {}\".format(self.step.task_name)\n            )\n            exc = e\n        return StepResult(\n            self.step.step_num,\n            self.step.task_name,\n            self.step.path,\n            task.result,\n            task.return_values,\n            exc,\n        )", "response": "Runs a single step."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_steps(self,):\n        self._check_old_yaml_format()\n        config_steps = self.flow_config.steps\n        self._check_infinite_flows(config_steps)\n\n        steps = []\n\n        for number, step_config in config_steps.items():\n            specs = self._visit_step(number, step_config)\n            steps.extend(specs)\n\n        return sorted(steps, key=attrgetter(\"step_num\"))", "response": "Create a list of steps to run sorted by step number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _visit_step(\n        self,\n        number,\n        step_config,\n        visited_steps=None,\n        parent_options=None,\n        parent_ui_options=None,\n        from_flow=None,\n    ):\n        \"\"\"\n        for each step (as defined in the flow YAML), _visit_step is called with only\n        the first two parameters. this takes care of validating the step, collating the\n        option overrides, and if it is a task, creating a StepSpec for it.\n\n        If it is a flow, we recursively call _visit_step with the rest of the parameters of context.\n\n        :param number: LooseVersion representation of the current step number\n        :param step_config: the current step's config (dict from YAML)\n        :param visited_steps: used when called recursively for nested steps, becomes the return value\n        :param parent_options: used when called recursively for nested steps, options from parent flow\n        :param parent_ui_options: used when called recursively for nested steps, UI options from parent flow\n        :param from_flow: used when called recursively for nested steps, name of parent flow\n        :return: List[StepSpec] a list of all resolved steps including/under the one passed in\n        \"\"\"\n        number = LooseVersion(str(number))\n\n        if visited_steps is None:\n            visited_steps = []\n        if parent_options is None:\n            parent_options = {}\n        if parent_ui_options is None:\n            parent_ui_options = {}\n\n        # Step Validation\n        # - A step is either a task OR a flow.\n        if all(k in step_config for k in (\"flow\", \"task\")):\n            raise FlowConfigError(\n                \"Step {} is configured as both a flow AND a task. \\n\\t{}.\".format(\n                    number, step_config\n                )\n            )\n\n        # Skips\n        # - either in YAML (with the None string)\n        # - or by providing a skip list to the FlowRunner at initialization.\n        if (\n            (\"flow\" in step_config and step_config[\"flow\"] == \"None\")\n            or (\"task\" in step_config and step_config[\"task\"] == \"None\")\n            or (\"task\" in step_config and step_config[\"task\"] in self.skip)\n        ):\n            visited_steps.append(\n                StepSpec(\n                    number,\n                    step_config.get(\"task\", step_config.get(\"flow\")),\n                    step_config.get(\"options\", {}),\n                    None,\n                    from_flow=from_flow,\n                    skip=True,  # someday we could use different vals for why skipped\n                )\n            )\n            return visited_steps\n\n        if \"task\" in step_config:\n            name = step_config[\"task\"]\n\n            # get the base task_config from the project config, as a dict for easier manipulation.\n            # will raise if the task doesn't exist / is invalid\n            task_config = copy.deepcopy(self.project_config.get_task(name).config)\n            if \"options\" not in task_config:\n                task_config[\"options\"] = {}\n\n            # merge the options together, from task_config all the way down through parent_options\n            step_overrides = copy.deepcopy(parent_options.get(name, {}))\n            step_overrides.update(step_config.get(\"options\", {}))\n            task_config[\"options\"].update(step_overrides)\n\n            # merge UI options from task config and parent flow\n            if \"ui_options\" not in task_config:\n                task_config[\"ui_options\"] = {}\n            step_ui_overrides = copy.deepcopy(parent_ui_options.get(name, {}))\n            step_ui_overrides.update(step_config.get(\"ui_options\", {}))\n            task_config[\"ui_options\"].update(step_ui_overrides)\n\n            # merge runtime options\n            if name in self.runtime_options:\n                task_config[\"options\"].update(self.runtime_options[name])\n\n            # get implementation class. raise/fail if it doesn't exist, because why continue\n            try:\n                task_class = import_class(task_config[\"class_path\"])\n            except (ImportError, AttributeError):\n                # TODO: clean this up and raise a taskimporterror or something else correcter.\n                raise FlowConfigError(\"Task named {} has bad classpath\")\n\n            visited_steps.append(\n                StepSpec(\n                    number,\n                    name,\n                    task_config,\n                    task_class,\n                    step_config.get(\"ignore_failure\", False),\n                    from_flow=from_flow,\n                )\n            )\n            return visited_steps\n\n        if \"flow\" in step_config:\n            name = step_config[\"flow\"]\n            if from_flow:\n                path = \".\".join([from_flow, name])\n            else:\n                path = name\n            step_options = step_config.get(\"options\", {})\n            step_ui_options = step_config.get(\"ui_options\", {})\n            flow_config = self.project_config.get_flow(name)\n            for sub_number, sub_stepconf in flow_config.steps.items():\n                # append the flow number to the child number, since its a LooseVersion.\n                # e.g. if we're in step 2.3 which references a flow with steps 1-5, it\n                #   simply ends up as five steps: 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.3.5\n                # TODO: how does this work with nested flowveride? what does defining step 2.3.2 later do?\n                num = \"{}.{}\".format(number, sub_number)\n                self._visit_step(\n                    num,\n                    sub_stepconf,\n                    visited_steps,\n                    parent_options=step_options,\n                    parent_ui_options=step_ui_options,\n                    from_flow=path,\n                )\n\n        return visited_steps", "response": "This function is called by the FlowRunner to validate the current step and return a list of all resolved steps under the current step."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_org(self):\n        self.logger.info(\n            \"Verifying and refreshing credentials for the specified org: {}.\".format(\n                self.org_config.name\n            )\n        )\n        orig_config = self.org_config.config.copy()\n\n        # attempt to refresh the token, this can throw...\n        self.org_config.refresh_oauth_token(self.project_config.keychain)\n\n        if self.org_config.config != orig_config:\n            self.logger.info(\"Org info has changed, updating org in keychain\")\n            self.project_config.keychain.set_org(self.org_config)", "response": "Initialize the org info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve dynamic option value lookups in the format ^^task_name. attr", "response": "def resolve_return_value_options(self, options):\n        \"\"\"Handle dynamic option value lookups in the format ^^task_name.attr\"\"\"\n        for key, value in options.items():\n            if isinstance(value, str) and value.startswith(RETURN_VALUE_OPTION_PREFIX):\n                path, name = value[len(RETURN_VALUE_OPTION_PREFIX) :].rsplit(\".\", 1)\n                result = self._find_result_by_path(path)\n                options[key] = result.return_values.get(name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef control(self, key):\n        if not self.connection:\n            raise exceptions.ConnectionClosed()\n\n        payload = json.dumps({\n            \"method\": \"ms.remote.control\",\n            \"params\": {\n                \"Cmd\": \"Click\",\n                \"DataOfCmd\": key,\n                \"Option\": \"false\",\n                \"TypeOfRemote\": \"SendRemoteKey\"\n            }\n        })\n\n        logging.info(\"Sending control command: %s\", key)\n        self.connection.send(payload)\n        time.sleep(self._key_interval)", "response": "Send a control command to the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef control(self, key):\n        if not self.connection:\n            raise exceptions.ConnectionClosed()\n\n        payload = b\"\\x00\\x00\\x00\" + self._serialize_string(key)\n        packet = b\"\\x00\\x00\\x00\" + self._serialize_string(payload, True)\n\n        logging.info(\"Sending control command: %s\", key)\n        self.connection.send(packet)\n        self._read_response()\n        time.sleep(self._key_interval)", "response": "Send a control command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_new_suffix_tree(case_insensitive=False):\n    assert isinstance(case_insensitive, bool)\n    root_node = register_new_node()\n\n    suffix_tree_id = uuid4()\n    event = SuffixTree.Created(\n        originator_id=suffix_tree_id,\n        root_node_id=root_node.id,\n        case_insensitive=case_insensitive,\n    )\n    entity = SuffixTree.mutate(event=event)\n\n    assert isinstance(entity, SuffixTree)\n\n    entity.nodes[root_node.id] = root_node\n\n    publish(event)\n\n    return entity", "response": "Factory method returns new suffix tree object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_substring(substring, suffix_tree, edge_repo):\n    assert isinstance(substring, str)\n    assert isinstance(suffix_tree, SuffixTree)\n    assert isinstance(edge_repo, EventSourcedRepository)\n    if not substring:\n        return -1\n    if suffix_tree.case_insensitive:\n        substring = substring.lower()\n    curr_node_id = suffix_tree.root_node_id\n    i = 0\n    while i < len(substring):\n        edge_id = make_edge_id(curr_node_id, substring[i])\n        try:\n            edge = edge_repo[edge_id]\n        except RepositoryKeyError:\n            return -1\n        ln = min(edge.length + 1, len(substring) - i)\n        if substring[i:i + ln] != suffix_tree.string[edge.first_char_index:edge.first_char_index + ln]:\n            return -1\n        i += edge.length + 1\n        curr_node_id = edge.dest_node_id\n    return edge.first_char_index - len(substring) + ln", "response": "Find the index of substring in tree if substring in tree otherwise - 1."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _canonize_suffix(self, suffix):\n        if not suffix.explicit():\n            edge_id = make_edge_id(suffix.source_node_id, self.string[suffix.first_char_index])\n            e = self.edges[edge_id]\n            if e.length <= suffix.length:\n                suffix.first_char_index += e.length + 1\n                suffix.source_node_id = e.dest_node_id\n                self._canonize_suffix(suffix)", "response": "This canonizes the suffix by walking along its suffix string until it is explicit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef entity_from_snapshot(snapshot):\n    assert isinstance(snapshot, AbstractSnapshop), type(snapshot)\n    if snapshot.state is not None:\n        entity_class = resolve_topic(snapshot.topic)\n        return reconstruct_object(entity_class, snapshot.state)", "response": "Reconstructs domain entity from given snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_snapshot(self, entity_id, lt=None, lte=None):\n        snapshots = self.snapshot_store.get_domain_events(entity_id, lt=lt, lte=lte, limit=1, is_ascending=False)\n        if len(snapshots) == 1:\n            return snapshots[0]", "response": "Gets the last snapshot for the given entity optionally until a particular version number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef take_snapshot(self, entity_id, entity, last_event_version):\n\n        # Create the snapshot.\n        snapshot = Snapshot(\n            originator_id=entity_id,\n            originator_version=last_event_version,\n            topic=get_topic(entity.__class__),\n            state=None if entity is None else deepcopy(entity.__dict__)\n        )\n\n        self.snapshot_store.store(snapshot)\n\n        # Return the snapshot.\n        return snapshot", "response": "Creates a snapshot from the given state and appends it to the snapshot store."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_entity(self, entity_id, at=None):\n\n        # Get a snapshot (None if none exist).\n        if self._snapshot_strategy is not None:\n            snapshot = self._snapshot_strategy.get_snapshot(entity_id, lte=at)\n        else:\n            snapshot = None\n\n        # Decide the initial state of the entity, and the\n        # version of the last item applied to the entity.\n        if snapshot is None:\n            initial_state = None\n            gt = None\n        else:\n            initial_state = entity_from_snapshot(snapshot)\n            gt = snapshot.originator_version\n\n        # Obtain and return current state.\n        return self.get_and_project_events(entity_id, gt=gt, lte=at, initial_state=initial_state)", "response": "Returns the entity with given ID optionally until position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_and_project_events(self, entity_id, gt=None, gte=None, lt=None, lte=None, limit=None, initial_state=None,\n                               query_descending=False):\n        \"\"\"\n        Reconstitutes requested domain entity from domain events found in event store.\n        \"\"\"\n        # Decide if query is in ascending order.\n        #  - A \"speed up\" for when events are stored in descending order (e.g.\n        #  in Cassandra) and it is faster to get them in that order.\n        #  - This isn't useful when 'until' or 'after' or 'limit' are set,\n        #    because the inclusiveness or exclusiveness of until and after\n        #    and the end of the stream that is truncated by limit both depend on\n        #    the direction of the query. Also paging backwards isn't useful, because\n        #    all the events are needed eventually, so it would probably slow things\n        #    down. Paging is intended to support replaying longer event streams, and\n        #    only makes sense to work in ascending order.\n        if gt is None and gte is None and lt is None and lte is None and self.__page_size__ is None:\n            is_ascending = False\n        else:\n            is_ascending = not query_descending\n\n        # Get entity's domain events from the event store.\n        domain_events = self.event_store.get_domain_events(\n            originator_id=entity_id,\n            gt=gt,\n            gte=gte,\n            lt=lt,\n            lte=lte,\n            limit=limit,\n            is_ascending=is_ascending,\n            page_size=self.__page_size__\n        )\n\n        # The events will be replayed in ascending order.\n        if not is_ascending:\n            domain_events = list(reversed(list(domain_events)))\n\n        # Project the domain events onto the initial state.\n        return self.project_events(initial_state, domain_events)", "response": "Get the domain events for the given entity and project them into the initial state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a snapshot of the entity as it existed after the most recent event optionally less than or equal to a particular position.", "response": "def take_snapshot(self, entity_id, lt=None, lte=None):\n        \"\"\"\n        Takes a snapshot of the entity as it existed after the most recent\n        event, optionally less than, or less than or equal to, a particular position.\n        \"\"\"\n        snapshot = None\n        if self._snapshot_strategy:\n            # Get the latest event (optionally until a particular position).\n            latest_event = self.event_store.get_most_recent_event(entity_id, lt=lt, lte=lte)\n\n            # If there is something to snapshot, then look for a snapshot\n            # taken before or at the entity version of the latest event. Please\n            # note, the snapshot might have a smaller version number than\n            # the latest event if events occurred since the latest snapshot was taken.\n            if latest_event is not None:\n                latest_snapshot = self._snapshot_strategy.get_snapshot(\n                    entity_id, lt=lt, lte=lte\n                )\n                latest_version = latest_event.originator_version\n\n                if latest_snapshot and latest_snapshot.originator_version == latest_version:\n                    # If up-to-date snapshot exists, there's nothing to do.\n                    snapshot = latest_snapshot\n                else:\n                    # Otherwise recover entity state from latest snapshot.\n                    if latest_snapshot:\n                        initial_state = entity_from_snapshot(latest_snapshot)\n                        gt = latest_snapshot.originator_version\n                    else:\n                        initial_state = None\n                        gt = None\n\n                    # Fast-forward entity state to latest version.\n                    entity = self.get_and_project_events(\n                        entity_id=entity_id,\n                        gt=gt,\n                        lte=latest_version,\n                        initial_state=initial_state,\n                    )\n\n                    # Take snapshot from entity.\n                    snapshot = self._snapshot_strategy.take_snapshot(entity_id, entity, latest_version)\n\n        return snapshot"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new example object.", "response": "def create_new_example(self, foo='', a='', b=''):\n        \"\"\"Entity object factory.\"\"\"\n        return create_new_example(foo=foo, a=a, b=b)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an integer value representing a unix timestamp in tenths of microseconds.", "response": "def timestamp_long_from_uuid(uuid_arg):\n    \"\"\"\n    Returns an integer value representing a unix timestamp in tenths of microseconds.\n\n    :param uuid_arg:\n    :return: Unix timestamp integer in tenths of microseconds.\n    :rtype: int\n    \"\"\"\n    if isinstance(uuid_arg, str):\n        uuid_arg = UUID(uuid_arg)\n    assert isinstance(uuid_arg, UUID), uuid_arg\n    uuid_time = uuid_arg.time\n    return uuid_time - 0x01B21DD213814000"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a Decimal object representing the given floating point number t.", "response": "def decimaltimestamp(t=None):\n    \"\"\"\n    A UNIX timestamp as a Decimal object (exact number type).\n\n    Returns current time when called without args, otherwise\n    converts given floating point number ``t`` to a Decimal\n    with 9 decimal places.\n\n    :param t: Floating point UNIX timestamp (\"seconds since epoch\").\n    :return: A Decimal with 6 decimal places, representing the\n            given floating point or the value returned by time.time().\n    \"\"\"\n    t = time.time() if t is None else t\n    return Decimal('{:.6f}'.format(t))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef subscribe_to(*event_classes):\n    event_classes = list(event_classes)\n\n    def wrap(func):\n        def handler(event):\n            if isinstance(event, (list, tuple)):\n                for e in event:\n                    handler(e)\n            elif not event_classes or isinstance(event, tuple(event_classes)):\n                func(event)\n\n        subscribe(handler=handler, predicate=lambda _: True)\n        return func\n\n    if len(event_classes) == 1 and isfunction(event_classes[0]):\n        func = event_classes.pop()\n        return wrap(func)\n    else:\n        return wrap", "response": "This is a custom event handler function that subscribes to a certain class of event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstructuring mutator functions by allowing handlers to be registered for different types of event.", "response": "def mutator(arg=None):\n    \"\"\"Structures mutator functions by allowing handlers\n    to be registered for different types of event. When\n    the decorated function is called with an initial\n    value and an event, it will call the handler that\n    has been registered for that type of event.\n\n    It works like singledispatch, which it uses. The\n    difference is that when the decorated function is\n    called, this decorator dispatches according to the\n    type of last call arg, which fits better with reduce().\n    The builtin Python function reduce() is used by the\n    library to replay a sequence of events against an\n    initial state. If a mutator function is given to reduce(),\n    along with a list of events and an initializer, reduce()\n    will call the mutator function once for each event in the\n    list, but the initializer will be the first value, and the\n    event will be the last argument, and we want to dispatch\n    according to the type of the event. It happens that\n    singledispatch is coded to switch on the type of the first\n    argument, which makes it unsuitable for structuring a mutator\n    function without the modifications introduced here.\n\n    The other aspect introduced by this decorator function is the\n    option to set the type of the handled entity in the decorator.\n    When an entity is replayed from scratch, in other words when\n    all its events are replayed, the initial state is None. The\n    handler which handles the first event in the sequence will\n    probably construct an object instance. It is possible to write\n    the type into the handler, but that makes the entity more difficult\n    to subclass because you will also need to write a handler for it.\n    If the decorator is invoked with the type, when the initial\n    value passed as a call arg to the mutator function is None,\n    the handler will instead receive the type of the entity, which\n    it can use to construct the entity object.\n\n    .. code::\n\n        class Entity(object):\n            class Created(object):\n                pass\n\n        @mutator(Entity)\n        def mutate(initial, event):\n            raise NotImplementedError(type(event))\n\n        @mutate.register(Entity.Created)\n        def _(initial, event):\n            return initial(**event.__dict__)\n\n        entity = mutate(None, Entity.Created())\n    \"\"\"\n\n    domain_class = None\n\n    def _mutator(func):\n        wrapped = singledispatch(func)\n\n        @wraps(wrapped)\n        def wrapper(initial, event):\n            initial = initial or domain_class\n            return wrapped.dispatch(type(event))(initial, event)\n\n        wrapper.register = wrapped.register\n\n        return wrapper\n\n    if isfunction(arg):\n        return _mutator(arg)\n    else:\n        domain_class = arg\n        return _mutator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encrypt(self, plaintext):\n\n        # String to bytes.\n        plainbytes = plaintext.encode('utf8')\n\n        # Compress plaintext bytes.\n        compressed = zlib.compress(plainbytes)\n\n        # Construct AES-GCM cipher, with 96-bit nonce.\n        cipher = AES.new(self.cipher_key, AES.MODE_GCM, nonce=random_bytes(12))\n\n        # Encrypt and digest.\n        encrypted, tag = cipher.encrypt_and_digest(compressed)\n\n        # Combine with nonce.\n        combined = cipher.nonce + tag + encrypted\n\n        # Encode as Base64.\n        cipherbytes = base64.b64encode(combined)\n\n        # Bytes to string.\n        ciphertext = cipherbytes.decode('utf8')\n\n        # Return ciphertext.\n        return ciphertext", "response": "Encrypt a string with the given plaintext."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decrypt(self, ciphertext):\n\n        # String to bytes.\n        cipherbytes = ciphertext.encode('utf8')\n\n        # Decode from Base64.\n        try:\n            combined = base64.b64decode(cipherbytes)\n        except (base64.binascii.Error, TypeError) as e:\n            # base64.binascii.Error for Python 3.\n            # TypeError for Python 2.\n            raise DataIntegrityError(\"Cipher text is damaged: {}\".format(e))\n\n        # Split out the nonce, tag, and encrypted data.\n        nonce = combined[:12]\n        if len(nonce) != 12:\n            raise DataIntegrityError(\"Cipher text is damaged: invalid nonce length\")\n\n        tag = combined[12:28]\n        if len(tag) != 16:\n            raise DataIntegrityError(\"Cipher text is damaged: invalid tag length\")\n\n        encrypted = combined[28:]\n\n        # Construct AES cipher, with old nonce.\n        cipher = AES.new(self.cipher_key, AES.MODE_GCM, nonce)\n\n        # Decrypt and verify.\n        try:\n            compressed = cipher.decrypt_and_verify(encrypted, tag)\n        except ValueError as e:\n            raise DataIntegrityError(\"Cipher text is damaged: {}\".format(e))\n\n        # Decompress plaintext bytes.\n        plainbytes = zlib.decompress(compressed)\n\n        # Bytes to string.\n        plaintext = plainbytes.decode('utf8')\n\n        # Return plaintext.\n        return plaintext", "response": "Return plaintext for given ciphertext."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets domain events for given entity ID.", "response": "def get_domain_events(self, originator_id, gt=None, gte=None, lt=None, lte=None, limit=None, is_ascending=True,\n                          page_size=None):\n        \"\"\"\n        Returns domain events for given entity ID.\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores given domain event or list of domain events to their sequenced item.", "response": "def store(self, domain_event_or_events):\n        \"\"\"\n        Appends given domain event, or list of domain events, to their sequence.\n\n        :param domain_event_or_events: domain event, or list of domain events\n        \"\"\"\n\n        # Convert to sequenced item.\n        sequenced_item_or_items = self.item_from_event(domain_event_or_events)\n\n        # Append to the sequenced item(s) to the sequence.\n        try:\n            self.record_manager.record_sequenced_items(sequenced_item_or_items)\n        except RecordConflictError as e:\n            raise ConcurrencyError(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef item_from_event(self, domain_event_or_events):\n        # Convert the domain event(s) to sequenced item(s).\n        if isinstance(domain_event_or_events, (list, tuple)):\n            return [self.item_from_event(e) for e in domain_event_or_events]\n        else:\n            return self.mapper.item_from_event(domain_event_or_events)", "response": "Maps domain event to sequenced item namedtuple."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_domain_events(self, originator_id, gt=None, gte=None, lt=None, lte=None, limit=None, is_ascending=True,\n                          page_size=None):\n        \"\"\"\n        Gets domain events from the sequence identified by `originator_id`.\n\n        :param originator_id: ID of a sequence of events\n        :param gt: get items after this position\n        :param gte: get items at or after this position\n        :param lt: get items before this position\n        :param lte: get items before or at this position\n        :param limit: get limited number of items\n        :param is_ascending: get items from lowest position\n        :param page_size: restrict and repeat database query\n        :return: list of domain events\n        \"\"\"\n        if page_size:\n            sequenced_items = self.iterator_class(\n                record_manager=self.record_manager,\n                sequence_id=originator_id,\n                page_size=page_size,\n                gt=gt,\n                gte=gte,\n                lt=lt,\n                lte=lte,\n                limit=limit,\n                is_ascending=is_ascending,\n            )\n        else:\n            sequenced_items = self.record_manager.get_items(\n                sequence_id=originator_id,\n                gt=gt,\n                gte=gte,\n                lt=lt,\n                lte=lte,\n                limit=limit,\n                query_ascending=is_ascending,\n                results_ascending=is_ascending,\n            )\n\n        # Deserialize to domain events.\n        domain_events = map(self.mapper.event_from_item, sequenced_items)\n        return list(domain_events)", "response": "Gets the domain events from the sequence identified by originator_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a domain event from the sequence identified by originator_id at position eq.", "response": "def get_domain_event(self, originator_id, position):\n        \"\"\"\n        Gets a domain event from the sequence identified by `originator_id`\n        at position `eq`.\n\n        :param originator_id: ID of a sequence of events\n        :param position: get item at this position\n        :return: domain event\n        \"\"\"\n\n        sequenced_item = self.record_manager.get_item(\n            sequence_id=originator_id,\n            position=position,\n        )\n        return self.mapper.event_from_item(sequenced_item)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_most_recent_event(self, originator_id, lt=None, lte=None):\n        events = self.get_domain_events(originator_id=originator_id, lt=lt, lte=lte, limit=1, is_ascending=False)\n        events = list(events)\n        try:\n            return events[0]\n        except IndexError:\n            pass", "response": "Gets a domain event from the sequence identified by originator_id at the highest position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_domain_events(self):\n        for originator_id in self.record_manager.all_sequence_ids():\n            for domain_event in self.get_domain_events(originator_id=originator_id, page_size=100):\n                yield domain_event", "response": "Yields all domain events in the event store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef publish_prompt(self, event=None):\n\n        prompt = Prompt(self.name, self.pipeline_id)\n        try:\n            publish(prompt)\n        except PromptFailed:\n            raise\n        except Exception as e:\n            raise PromptFailed(\"{}: {}\".format(type(e), str(e)))", "response": "Publishes a prompt for a given event."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares the insert statement for the record_class.", "response": "def _prepare_insert(self, tmpl, record_class, field_names, placeholder_for_id=False):\n        \"\"\"\n        With transaction isolation level of \"read committed\" this should\n        generate records with a contiguous sequence of integer IDs, using\n        an indexed ID column, the database-side SQL max function, the\n        insert-select-from form, and optimistic concurrency control.\n        \"\"\"\n        field_names = list(field_names)\n        if hasattr(record_class, 'application_name') and 'application_name' not in field_names:\n            field_names.append('application_name')\n        if hasattr(record_class, 'pipeline_id') and 'pipeline_id' not in field_names:\n            field_names.append('pipeline_id')\n        if hasattr(record_class, 'causal_dependencies') and 'causal_dependencies' not in field_names:\n            field_names.append('causal_dependencies')\n        if placeholder_for_id:\n            if self.notification_id_name:\n                if self.notification_id_name not in field_names:\n                    field_names.append('id')\n\n        statement = tmpl.format(\n            tablename=self.get_record_table_name(record_class),\n            columns=\", \".join(field_names),\n            placeholders=\", \".join(['%s' for _ in field_names]),\n            notification_id=self.notification_id_name\n        )\n        return statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_notifications(self, start=None, stop=None, *args, **kwargs):\n        filter_kwargs = {}\n        # Todo: Also support sequencing by 'position' if items are sequenced by timestamp?\n        if start is not None:\n            filter_kwargs['%s__gte' % self.notification_id_name] = start + 1\n        if stop is not None:\n            filter_kwargs['%s__lt' % self.notification_id_name] = stop + 1\n        objects = self.record_class.objects.filter(**filter_kwargs)\n\n        if hasattr(self.record_class, 'application_name'):\n            objects = objects.filter(application_name=self.application_name)\n        if hasattr(self.record_class, 'pipeline_id'):\n            objects = objects.filter(pipeline_id=self.pipeline_id)\n\n        objects = objects.order_by('%s' % self.notification_id_name)\n        return objects.all()", "response": "Returns all the records in the table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self):\n        # Subscribe to broadcast prompts published by a process\n        # application in the parent operating system process.\n        subscribe(handler=self.forward_prompt, predicate=self.is_prompt)\n\n        # Initialise the system actor.\n        msg = SystemInitRequest(\n            self.system.process_classes,\n            self.infrastructure_class,\n            self.system.followings,\n            self.pipeline_ids\n        )\n        response = self.actor_system.ask(self.system_actor, msg)\n\n        # Keep the pipeline actor addresses, to send prompts directly.\n        assert isinstance(response, SystemInitResponse), type(response)\n\n        assert list(response.pipeline_actors.keys()) == self.pipeline_ids, (\n            \"Configured pipeline IDs mismatch initialised system {} {}\").format(\n            list(self.pipeline_actors.keys()), self.pipeline_ids\n        )\n\n        self.pipeline_actors = response.pipeline_actors", "response": "Starts all the actors to run a system of process applications."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstop all the actors running a system of process applications.", "response": "def close(self):\n        \"\"\"Stops all the actors running a system of process applications.\"\"\"\n        super(ActorModelRunner, self).close()\n        unsubscribe(handler=self.forward_prompt, predicate=self.is_prompt)\n        if self.shutdown_on_close:\n            self.shutdown()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new suffix tree entity.", "response": "def register_new_suffix_tree(self, case_insensitive=False):\n        \"\"\"Returns a new suffix tree entity.\n        \"\"\"\n        suffix_tree = register_new_suffix_tree(case_insensitive=case_insensitive)\n        suffix_tree._node_repo = self.node_repo\n        suffix_tree._node_child_collection_repo = self.node_child_collection_repo\n        suffix_tree._edge_repo = self.edge_repo\n        suffix_tree._stringid_collection_repo = self.stringid_collection_repo\n        return suffix_tree"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_suffix_tree(self, suffix_tree_id):\n        suffix_tree = self.suffix_tree_repo[suffix_tree_id]\n        assert isinstance(suffix_tree, GeneralizedSuffixTree)\n        suffix_tree._node_repo = self.node_repo\n        suffix_tree._node_child_collection_repo = self.node_child_collection_repo\n        suffix_tree._edge_repo = self.edge_repo\n        suffix_tree._stringid_collection_repo = self.stringid_collection_repo\n        return suffix_tree", "response": "Returns a GeneralizedSuffixTree entity equipped with node and edge repos it needs."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a set of strings that contain the given substring.", "response": "def find_string_ids(self, substring, suffix_tree_id, limit=None):\n        \"\"\"Returns a set of IDs for strings that contain the given substring.\n        \"\"\"\n\n        # Find an edge for the substring.\n        edge, ln = self.find_substring_edge(substring=substring, suffix_tree_id=suffix_tree_id)\n\n        # If there isn't an edge, return an empty set.\n        if edge is None:\n            return set()\n\n        # Get all the string IDs beneath the edge's destination node.\n        string_ids = get_string_ids(\n            node_id=edge.dest_node_id,\n            node_repo=self.node_repo,\n            node_child_collection_repo=self.node_child_collection_repo,\n            stringid_collection_repo=self.stringid_collection_repo,\n            length_until_end=edge.length + 1 - ln,\n            limit=limit\n        )\n\n        # Return a set of string IDs.\n        return set(string_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_substring_edge(self, substring, suffix_tree_id):\n        suffix_tree = self.suffix_tree_repo[suffix_tree_id]\n        started = datetime.datetime.now()\n        edge, ln = find_substring_edge(substring=substring, suffix_tree=suffix_tree, edge_repo=self.edge_repo)\n        # if edge is not None:\n        #     print(\"Got edge for substring '{}': {}\".format(substring, edge))\n        # else:\n        #     print(\"No edge for substring '{}'\".format(substring))\n        print(\" - searched for edge in {} for substring: '{}'\".format(datetime.datetime.now() - started, substring))\n        return edge, ln", "response": "Returns an edge that matches the given substring."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning followers of a prompt.", "response": "def run_followers(self, prompt):\n        \"\"\"\n        First caller adds a prompt to queue and\n        runs followers until there are no more\n        pending prompts.\n\n        Subsequent callers just add a prompt\n        to the queue, avoiding recursion.\n        \"\"\"\n        assert isinstance(prompt, Prompt)\n        # Put the prompt on the queue.\n        self.pending_prompts.put(prompt)\n\n        if self.iteration_lock.acquire(False):\n            start_time = time.time()\n            i = 0\n            try:\n                while True:\n                    try:\n                        prompt = self.pending_prompts.get(False)\n                    except Empty:\n                        break\n                    else:\n                        followers = self.system.followers[prompt.process_name]\n                        for follower_name in followers:\n                            follower = self.system.processes[follower_name]\n                            follower.run(prompt)\n                            i += 1\n                        self.pending_prompts.task_done()\n            finally:\n                run_frequency = i / (time.time() - start_time)\n                # print(f\"Run frequency: {run_frequency}\")\n                self.iteration_lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef put(self, prompt):\n        for queue in self.downstream_inboxes.values():\n            queue.put(prompt)", "response": "Put a prompt in all the downstream inboxes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_new_example(foo='', a='', b=''):\n    return Example.__create__(foo=foo, a=a, b=b)", "response": "Factory method for example entities."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef construct_infrastructure_factory(self, *args, **kwargs):\n        factory_class = self.infrastructure_factory_class\n        assert issubclass(factory_class, InfrastructureFactory)\n        return factory_class(\n            record_manager_class=self.record_manager_class,\n            integer_sequenced_record_class=self.stored_event_record_class,\n            sequenced_item_class=self.sequenced_item_class,\n            contiguous_record_ids=self.contiguous_record_ids,\n            application_name=self.name,\n            pipeline_id=self.pipeline_id,\n            snapshot_record_class=self.snapshot_record_class,\n            *args, **kwargs\n        )", "response": "Constructs an infrastructure factory object from the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prepare_insert(self, tmpl, record_class, field_names, placeholder_for_id=False):\n        field_names = list(field_names)\n        if hasattr(record_class, 'application_name') and 'application_name' not in field_names:\n            field_names.append('application_name')\n        if hasattr(record_class, 'pipeline_id') and 'pipeline_id' not in field_names:\n            field_names.append('pipeline_id')\n        if hasattr(record_class, 'causal_dependencies') and 'causal_dependencies' not in field_names:\n            field_names.append('causal_dependencies')\n        if self.notification_id_name:\n            if placeholder_for_id:\n                if self.notification_id_name not in field_names:\n                    field_names.append(self.notification_id_name)\n\n        statement = text(tmpl.format(\n            tablename=self.get_record_table_name(record_class),\n            columns=\", \".join(field_names),\n            placeholders=\", \".join([\":{}\".format(f) for f in field_names]),\n            notification_id=self.notification_id_name\n        ))\n\n        # Define bind parameters with explicit types taken from record column types.\n        bindparams = []\n        for col_name in field_names:\n            column_type = getattr(record_class, col_name).type\n            bindparams.append(bindparam(col_name, type_=column_type))\n\n        # Redefine statement with explicitly typed bind parameters.\n        statement = statement.bindparams(*bindparams)\n\n        # Compile the statement with the session dialect.\n        compiled = statement.compile(dialect=self.session.bind.dialect)\n\n        return compiled", "response": "Prepare the insert statement for the record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting or creates a timebucketed log.", "response": "def get_or_create(self, log_name, bucket_size):\n        \"\"\"\n        Gets or creates a log.\n\n        :rtype: Timebucketedlog\n        \"\"\"\n        try:\n            return self[log_name]\n        except RepositoryKeyError:\n            return start_new_timebucketedlog(log_name, bucket_size=bucket_size)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef project_events(self, initial_state, domain_events):\n        return reduce(self._mutator_func or self.mutate, domain_events, initial_state)", "response": "Evolves initial state using the sequence of domain events and a mutator function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_last_array(self):\n        # Get the root array (might not have been registered).\n        root = self.repo[self.id]\n\n        # Get length and last item in the root array.\n        apex_id, apex_height = root.get_last_item_and_next_position()\n\n        # Bail if there isn't anything yet.\n        if apex_id is None:\n            return None, None\n\n        # Get the current apex array.\n        apex = self.repo[apex_id]\n        assert isinstance(apex, Array)\n\n        # Descend until hitting the bottom.\n        array = apex\n        array_i = 0\n        height = apex_height\n        while height > 1:\n            height -= 1\n            array_id, width = array.get_last_item_and_next_position()\n            assert width > 0\n            offset = width - 1\n            array_i += offset * self.repo.array_size ** height\n            array = self.repo[array_id]\n\n        return array, array_i", "response": "Returns the last array in the compound."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calc_parent(self, i, j, h):\n        N = self.repo.array_size\n        c_i = i\n        c_j = j\n        c_h = h\n        # Calculate the number of the sequence in its row (sequences\n        # with same height), from left to right, starting from 0.\n        c_n = c_i // (N ** c_h)\n        p_n = c_n // N\n        # Position of the child ID in the parent array.\n        p_p = c_n % N\n        # Parent height is child height plus one.\n        p_h = c_h + 1\n        # Span of sequences in parent row is max size N, to the power of the height.\n        span = N ** p_h\n        # Calculate parent i and j.\n        p_i = p_n * span\n        p_j = p_i + span\n        # Check the parent i,j bounds the child i,j, ie child span is contained by parent span.\n        assert p_i <= c_i, 'i greater on parent than child: {}'.format(p_i, p_j)\n        assert p_j >= c_j, 'j less on parent than child: {}'.format(p_i, p_j)\n        # Return parent i, j, h, p.\n        return p_i, p_j, p_h, p_p", "response": "Calculates the parent i j h and p."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs a sequenced item from a domain event.", "response": "def item_from_event(self, domain_event):\n        \"\"\"\n        Constructs a sequenced item from a domain event.\n        \"\"\"\n        item_args = self.construct_item_args(domain_event)\n        return self.construct_sequenced_item(item_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct_item_args(self, domain_event):\n        # Get the sequence ID.\n        sequence_id = domain_event.__dict__[self.sequence_id_attr_name]\n\n        # Get the position in the sequence.\n        position = getattr(domain_event, self.position_attr_name, None)\n\n        # Get topic and data.\n        topic, state = self.get_item_topic_and_state(\n            domain_event.__class__,\n            domain_event.__dict__\n        )\n\n        # Get the 'other' args.\n        # - these are meant to be derivative of the other attributes,\n        #   to populate database fields, and shouldn't affect the hash.\n        other_args = tuple((getattr(domain_event, name) for name in self.other_attr_names))\n\n        return (sequence_id, position, topic, state) + other_args", "response": "Constructs the attributes of a sequenced item from the given domain event."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef event_from_item(self, sequenced_item):\n        assert isinstance(sequenced_item, self.sequenced_item_class), (\n            self.sequenced_item_class, type(sequenced_item)\n        )\n\n        # Get the topic and state.\n        topic = getattr(sequenced_item, self.field_names.topic)\n        state = getattr(sequenced_item, self.field_names.state)\n\n        return self.event_from_topic_and_state(topic, state)", "response": "Reconstructs domain event from stored event topic and event attrs. Used in the event store when getting domain events."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the item from the datastore.", "response": "def get_item(self, sequence_id, position):\n        \"\"\"\n        Gets sequenced item from the datastore.\n        \"\"\"\n        return self.from_record(self.get_record(sequence_id, position))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_items(self, sequence_id, gt=None, gte=None, lt=None, lte=None, limit=None,\n                  query_ascending=True, results_ascending=True):\n        \"\"\"\n        Returns sequenced item generator.\n        \"\"\"\n        records = self.get_records(\n            sequence_id=sequence_id,\n            gt=gt,\n            gte=gte,\n            lt=lt,\n            lte=lte,\n            limit=limit,\n            query_ascending=query_ascending,\n            results_ascending=results_ascending,\n\n        )\n        for item in map(self.from_record, records):\n            yield item", "response": "Returns a generator that yields items from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_records(self, sequence_id, gt=None, gte=None, lt=None, lte=None, limit=None,\n                    query_ascending=True, results_ascending=True):\n        \"\"\"\n        Returns records for a sequence.\n        \"\"\"", "response": "Get records for a sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_record(self, sequenced_item):\n        kwargs = self.get_field_kwargs(sequenced_item)\n        # Supply application_name, if needed.\n        if hasattr(self.record_class, 'application_name'):\n            kwargs['application_name'] = self.application_name\n        # Supply pipeline_id, if needed.\n        if hasattr(self.record_class, 'pipeline_id'):\n            kwargs['pipeline_id'] = self.pipeline_id\n        return self.record_class(**kwargs)", "response": "Constructs a record object from given sequenced item object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_record(self, record):\n        kwargs = self.get_field_kwargs(record)\n        return self.sequenced_item_class(**kwargs)", "response": "Constructs and returns a sequenced item object from given ORM object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn pipeline ID and notification ID for given sequence ID and position.", "response": "def get_pipeline_and_notification_id(self, sequence_id, position):\n        \"\"\"\n        Returns pipeline ID and notification ID for\n        event at given position in given sequence.\n        \"\"\"\n        # Todo: Optimise query by selecting only two columns, pipeline_id and id (notification ID)?\n        record = self.get_record(sequence_id, position)\n        notification_id = getattr(record, self.notification_id_name)\n        return record.pipeline_id, notification_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the SQL statement that inserts records with contiguous IDs by selecting max ID from indexed table records.", "response": "def insert_select_max(self):\n        \"\"\"\n        SQL statement that inserts records with contiguous IDs,\n        by selecting max ID from indexed table records.\n        \"\"\"\n        if self._insert_select_max is None:\n            if hasattr(self.record_class, 'application_name'):\n                # Todo: Maybe make it support application_name without pipeline_id?\n                assert hasattr(self.record_class, 'pipeline_id'), self.record_class\n                tmpl = self._insert_select_max_tmpl + self._where_application_name_tmpl\n            else:\n                tmpl = self._insert_select_max_tmpl\n            self._insert_select_max = self._prepare_insert(\n                tmpl=tmpl,\n                record_class=self.record_class,\n                field_names=list(self.field_names),\n            )\n        return self._insert_select_max"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert_tracking_record(self):\n        if self._insert_tracking_record is None:\n            self._insert_tracking_record = self._prepare_insert(\n                tmpl=self._insert_values_tmpl,\n                placeholder_for_id=True,\n                record_class=self.tracking_record_class,\n                field_names=self.tracking_record_field_names,\n            )\n        return self._insert_tracking_record", "response": "Returns a SQL statement that inserts tracking records."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an instance of the class PaxosInstance with the constant attributes set.", "response": "def paxos_instance(self):\n        \"\"\"\n        Returns instance of PaxosInstance (protocol implementation).\n        \"\"\"\n        # Construct instance with the constant attributes.\n        instance = PaxosInstance(self.network_uid, self.quorum_size)\n\n        # Set the variable attributes from the aggregate.\n        for name in self.paxos_variables:\n            value = getattr(self, name, None)\n            if value is not None:\n                if isinstance(value, (set, list, dict, tuple)):\n                    value = deepcopy(value)\n                setattr(instance, name, value)\n\n        # Return the instance.\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(cls, originator_id, quorum_size, network_uid):\n        assert isinstance(quorum_size, int), \"Not an integer: {}\".format(quorum_size)\n        return cls.__create__(\n            event_class=cls.Started,\n            originator_id=originator_id,\n            quorum_size=quorum_size,\n            network_uid=network_uid\n        )", "response": "This method returns a new Paxos aggregate. A new Paxos aggregate is created with the specified originator_id and quorum_size and network_uid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npropose a value to the network.", "response": "def propose_value(self, value, assume_leader=False):\n        \"\"\"\n        Proposes a value to the network.\n        \"\"\"\n        if value is None:\n            raise ValueError(\"Not allowed to propose value None\")\n        paxos = self.paxos_instance\n        paxos.leader = assume_leader\n        msg = paxos.propose_value(value)\n        if msg is None:\n            msg = paxos.prepare()\n        self.setattrs_from_paxos(paxos)\n        self.announce(msg)\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef receive_message(self, msg):\n        if isinstance(msg, Resolution):\n            return\n        paxos = self.paxos_instance\n        while msg:\n            if isinstance(msg, Resolution):\n                self.print_if_verbose(\"{} resolved value {}\".format(self.network_uid, msg.value))\n                break\n            else:\n                self.print_if_verbose(\"{} <- {} <- {}\".format(self.network_uid, msg.__class__.__name__, msg.from_uid))\n                msg = paxos.receive(msg)\n                # Todo: Make it optional not to announce resolution (without which it's hard to see final value).\n                do_announce_resolution = True\n                if msg and (do_announce_resolution or not isinstance(msg, Resolution)):\n                    self.announce(msg)\n\n        self.setattrs_from_paxos(paxos)", "response": "Responds to messages from other participants."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nannounces a Paxos message.", "response": "def announce(self, msg):\n        \"\"\"\n        Announces a Paxos message.\n        \"\"\"\n        self.print_if_verbose(\"{} -> {}\".format(self.network_uid, msg.__class__.__name__))\n        self.__trigger_event__(\n            event_class=self.MessageAnnounced,\n            msg=msg,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the attributes of the object from the given Paxos instance.", "response": "def setattrs_from_paxos(self, paxos):\n        \"\"\"\n        Registers changes of attribute value on Paxos instance.\n        \"\"\"\n        changes = {}\n        for name in self.paxos_variables:\n            paxos_value = getattr(paxos, name)\n            if paxos_value != getattr(self, name, None):\n                self.print_if_verbose(\"{} {}: {}\".format(self.network_uid, name, paxos_value))\n                changes[name] = paxos_value\n                setattr(self, name, paxos_value)\n        if changes:\n            self.__trigger_event__(\n                event_class=self.AttributesChanged,\n                changes=changes\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nproposes a value for a key.", "response": "def propose_value(self, key, value, assume_leader=False):\n        \"\"\"\n        Starts new Paxos aggregate and proposes a value for a key.\n\n        Decorated with retry in case of notification log conflict\n        or operational error.\n        \"\"\"\n        assert isinstance(key, UUID)\n        paxos_aggregate = PaxosAggregate.start(\n            originator_id=key,\n            quorum_size=self.quorum_size,\n            network_uid=self.name\n        )\n        msg = paxos_aggregate.propose_value(value, assume_leader=assume_leader)\n        while msg:\n            msg = paxos_aggregate.receive_message(msg)\n        new_events = paxos_aggregate.__batch_pending_events__()\n        self.record_process_event(ProcessEvent(new_events))\n        self.repository.take_snapshot(paxos_aggregate.id)\n        self.publish_prompt()\n        return paxos_aggregate"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef propose_value(self, value):\n        '''\n        Sets the proposal value for this node iff this node is not already aware of\n        a previous proposal value. If the node additionally believes itself to be\n        the current leader, an Accept message will be returned\n        '''\n        if self.proposed_value is None:\n            self.proposed_value = value\n\n            if self.leader:\n                self.current_accept_msg = Accept(self.network_uid, self.proposal_id, value)\n                return self.current_accept_msg", "response": "Sets the proposal value for this node iff this node is not already aware of\n        a previous proposal value."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new Prepare message with the highest proposal id higher than that of any observed proposals. A side effect of this method is to clear the leader flag.", "response": "def prepare(self):\n        '''\n        Returns a new Prepare message with a proposal id higher than\n        that of any observed proposals. A side effect of this method is\n        to clear the leader flag if it is currently set.\n        '''\n\n        self.leader = False\n        self.promises_received = set()\n        self.nacks_received = set()\n        self.proposal_id = ProposalID(self.highest_proposal_id.number + 1, self.network_uid)\n        self.highest_proposal_id = self.proposal_id\n        self.current_prepare_msg = Prepare(self.network_uid, self.proposal_id)\n\n        return self.current_prepare_msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receive_nack(self, msg):\n        '''\n        Returns a new Prepare message if the number of Nacks received reaches\n        a quorum.\n        '''\n        self.observe_proposal(msg.promised_proposal_id)\n\n        if msg.proposal_id == self.proposal_id and self.nacks_received is not None:\n            self.nacks_received.add(msg.from_uid)\n\n            if len(self.nacks_received) == self.quorum_size:\n                return self.prepare()", "response": "Returns a new Prepare message if the number of Nacks received reaches the quorum size."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an Accept message if a quorum of Promise messages is achieved", "response": "def receive_promise(self, msg):\n        '''\n        Returns an Accept messages if a quorum of Promise messages is achieved\n        '''\n        self.observe_proposal(msg.proposal_id)\n\n        if not self.leader and msg.proposal_id == self.proposal_id and msg.from_uid not in self.promises_received:\n\n            self.promises_received.add(msg.from_uid)\n\n            if self.highest_accepted_id is None or msg.last_accepted_id > self.highest_accepted_id:\n                self.highest_accepted_id = msg.last_accepted_id\n                if msg.last_accepted_value is not None:\n                    self.proposed_value = msg.last_accepted_value\n\n            if len(self.promises_received) == self.quorum_size:\n                self.leader = True\n\n                if self.proposed_value is not None:\n                    self.current_accept_msg = Accept(self.network_uid, self.proposal_id, self.proposed_value)\n                    return self.current_accept_msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receive_prepare(self, msg):\n        '''\n        Returns either a Promise or a Nack in response. The Acceptor's state must be persisted to disk\n        prior to transmitting the Promise message.\n        '''\n        if self.promised_id is None or msg.proposal_id >= self.promised_id:\n            self.promised_id = msg.proposal_id\n            return Promise(self.network_uid, msg.from_uid, self.promised_id, self.accepted_id, self.accepted_value)\n        else:\n            return Nack(self.network_uid, msg.from_uid, msg.proposal_id, self.promised_id)", "response": "Receives a prepare message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef receive_accept(self, msg):\n        '''\n        Returns either an Accepted or Nack message in response. The Acceptor's state must be persisted\n        to disk prior to transmitting the Accepted message.\n        '''\n        if self.promised_id is None or msg.proposal_id >= self.promised_id:\n            self.promised_id = msg.proposal_id\n            self.accepted_id = msg.proposal_id\n            self.accepted_value = msg.proposal_value\n            return Accepted(self.network_uid, msg.proposal_id, msg.proposal_value)\n        else:\n            return Nack(self.network_uid, msg.from_uid, msg.proposal_id, self.promised_id)", "response": "Receives an Accepted or Nack message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receive_accepted(self, msg):\n        '''\n        Called when an Accepted message is received from an acceptor. Once the final value\n        is determined, the return value of this method will be a Resolution message containing\n        the consentual value. Subsequent calls after the resolution is chosen will continue to add\n        new Acceptors to the final_acceptors set and return Resolution messages.\n        '''\n        if self.final_value is not None:\n            if msg.proposal_id >= self.final_proposal_id and msg.proposal_value == self.final_value:\n                self.final_acceptors.add(msg.from_uid)\n            return Resolution(self.network_uid, self.final_value)\n\n        last_pn = self.acceptors.get(msg.from_uid)\n\n        if last_pn is not None and msg.proposal_id <= last_pn:\n            return  # Old message\n\n        self.acceptors[msg.from_uid] = msg.proposal_id\n\n        if last_pn is not None:\n            # String proposal_key, need string keys for JSON.\n            proposal_key = str(last_pn)\n            ps = self.proposals[proposal_key]\n            ps.retain_count -= 1\n            ps.acceptors.remove(msg.from_uid)\n            if ps.retain_count == 0:\n                del self.proposals[proposal_key]\n\n        # String proposal_key, need string keys for JSON.\n        proposal_key = str(msg.proposal_id)\n        if not proposal_key in self.proposals:\n            self.proposals[proposal_key] = ProposalStatus(msg.proposal_value)\n\n        ps = self.proposals[proposal_key]\n\n        assert msg.proposal_value == ps.value, 'Value mismatch for single proposal!'\n\n        ps.accept_count += 1\n        ps.retain_count += 1\n        ps.acceptors.add(msg.from_uid)\n\n        if ps.accept_count == self.quorum_size:\n            self.final_proposal_id = msg.proposal_id\n            self.final_value = msg.proposal_value\n            self.final_acceptors = ps.acceptors\n            self.proposals = None\n            self.acceptors = None\n\n            return Resolution(self.network_uid, self.final_value)", "response": "Called when an Accepted message is received from an acceptor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_topic(topic):\n    try:\n        module_name, _, class_name = topic.partition('#')\n        module = importlib.import_module(module_name)\n    except ImportError as e:\n        raise TopicResolutionError(\"{}: {}\".format(topic, e))\n    try:\n        cls = resolve_attr(module, class_name)\n    except AttributeError as e:\n        raise TopicResolutionError(\"{}: {}\".format(topic, e))\n    return cls", "response": "Returns a class described by given topic."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_attr(obj, path):\n    if not path:\n        return obj\n    head, _, tail = path.partition('.')\n    head_obj = getattr(obj, head)\n    return resolve_attr(head_obj, tail)", "response": "A recursive version of getattr for navigating dotted paths."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef country_list_maker():\n    cts = {\"Afghanistan\":\"AFG\", \"\u00c5land Islands\":\"ALA\", \"Albania\":\"ALB\", \"Algeria\":\"DZA\",\n    \"American Samoa\":\"ASM\", \"Andorra\":\"AND\", \"Angola\":\"AGO\", \"Anguilla\":\"AIA\",\n    \"Antarctica\":\"ATA\", \"Antigua Barbuda\":\"ATG\", \"Argentina\":\"ARG\",\n    \"Armenia\":\"ARM\", \"Aruba\":\"ABW\", \"Ascension Island\":\"NA\", \"Australia\":\"AUS\",\n    \"Austria\":\"AUT\", \"Azerbaijan\":\"AZE\", \"Bahamas\":\"BHS\", \"Bahrain\":\"BHR\",\n    \"Bangladesh\":\"BGD\", \"Barbados\":\"BRB\", \"Belarus\":\"BLR\", \"Belgium\":\"BEL\",\n    \"Belize\":\"BLZ\", \"Benin\":\"BEN\", \"Bermuda\":\"BMU\", \"Bhutan\":\"BTN\",\n    \"Bolivia\":\"BOL\", \"Bosnia Herzegovina\":\"BIH\",\n    \"Botswana\":\"BWA\", \"Bouvet Island\":\"BVT\", \"Brazil\":\"BRA\",\n    \"Britain\":\"GBR\", \"Great Britain\":\"GBR\",\n    \"British Virgin Islands\":\"VGB\", \"Brunei\":\"BRN\", \"Bulgaria\":\"BGR\", \"Burkina Faso\":\"BFA\",\n    \"Burundi\":\"BDI\", \"Cambodia\":\"KHM\", \"Cameroon\":\"CMR\",\n    \"Canada\":\"CAN\",\"Cape Verde\":\"CPV\", \"Cayman Islands\":\"CYM\",\n    \"Central African Republic\":\"CAF\", \"Chad\":\"TCD\", \"Chile\":\"CHL\", \"China\":\"CHN\",\n    \"Cocos Islands\":\"CCK\", \"Colombia\":\"COL\",\n    \"Comoros\":\"COM\",     \"Republic of Congo\":\"COG\", \"Cook Islands\":\"COK\",\n    \"Costa Rica\":\"CRI\", \"Cote Ivoire\":\"CIV\", \"Ivory Coast\":\"CIV\",\"Croatia\":\"HRV\", \"Cuba\":\"CUB\",\n    \"Cura\u00e7ao\":\"CUW\", \"Cyprus\":\"CYP\", \"Czech Republic\":\"CZE\", \"Denmark\":\"DNK\",\n    \"Djibouti\":\"DJI\", \"Dominica\":\"DMA\", \"Dominican Republic\":\"DOM\", \"Democratic Republic of Congo\" : \"COD\",\n    \"Ecuador\":\"ECU\", \"Egypt\":\"EGY\", \"El Salvador\":\"SLV\", \"England\" : \"GBR\",\n    \"Equatorial Guinea\":\"GNQ\", \"Eritrea\":\"ERI\", \"Estonia\":\"EST\", \"Ethiopia\":\"ETH\",\n    \"Falkland Islands\":\"FLK\", \"Faroe Islands\":\"FRO\",\n    \"Fiji\":\"FJI\", \"Finland\":\"FIN\", \"France\":\"FRA\", \"French Guiana\":\"GUF\",\n    \"French Polynesia\":\"PYF\",\"Gabon\":\"GAB\",\n    \"Gambia\":\"GMB\", \"Georgia\":\"GEO\", \"Germany\":\"DEU\", \"Ghana\":\"GHA\",\n    \"Gibraltar\":\"GIB\", \"Greece\":\"GRC\", \"Greenland\":\"GRL\", \"Grenada\":\"GRD\",\n    \"Guadeloupe\":\"GLP\", \"Guam\":\"GUM\", \"Guatemala\":\"GTM\", \"Guernsey\":\"GGY\",\n    \"Guinea\":\"GIN\", \"Guinea Bissau\":\"GNB\", \"Guyana\":\"GUY\", \"Haiti\":\"HTI\",\"Honduras\":\"HND\",\n    \"Hong Kong\":\"HKG\",  \"Hungary\":\"HUN\", \"Iceland\":\"ISL\",\n    \"India\":\"IND\", \"Indonesia\":\"IDN\", \"Iran\":\"IRN\", \"Iraq\":\"IRQ\", \"Ireland\":\"IRL\",\n    \"Israel\":\"ISR\", \"Italy\":\"ITA\", \"Jamaica\":\"JAM\", \"Japan\":\"JPN\",\n    \"Jordan\":\"JOR\", \"Kazakhstan\":\"KAZ\", \"Kenya\":\"KEN\",\n    \"Kiribati\":\"KIR\", \"Kosovo\": \"XKX\", \"Kuwait\":\"KWT\", \"Kyrgyzstan\":\"KGZ\", \"Laos\":\"LAO\",\n    \"Latvia\":\"LVA\", \"Lebanon\":\"LBN\", \"Lesotho\":\"LSO\", \"Liberia\":\"LBR\",\n    \"Libya\":\"LBY\", \"Liechtenstein\":\"LIE\", \"Lithuania\":\"LTU\", \"Luxembourg\":\"LUX\",\n    \"Macau\":\"MAC\", \"Macedonia\":\"MKD\", \"Madagascar\":\"MDG\", \"Malawi\":\"MWI\",\n    \"Malaysia\":\"MYS\", \"Maldives\":\"MDV\", \"Mali\":\"MLI\", \"Malta\":\"MLT\", \"Marshall Islands\":\"MHL\",\n    \"Martinique\":\"MTQ\", \"Mauritania\":\"MRT\", \"Mauritius\":\"MUS\",\n    \"Mayotte\":\"MYT\", \"Mexico\":\"MEX\", \"Micronesia\":\"FSM\", \"Moldova\":\"MDA\",\n    \"Monaco\":\"MCO\", \"Mongolia\":\"MNG\", \"Montenegro\":\"MNE\", \"Montserrat\":\"MSR\",\n    \"Morocco\":\"MAR\", \"Mozambique\":\"MOZ\", \"Myanmar\":\"MMR\", \"Burma\":\"MMR\", \"Namibia\":\"NAM\",\n    \"Nauru\":\"NRU\", \"Nepal\":\"NPL\", \"Netherlands\":\"NLD\", \"Netherlands Antilles\":\"ANT\",\n    \"New Caledonia\":\"NCL\", \"New Zealand\":\"NZL\", \"Nicaragua\":\"NIC\",\n    \"Niger\":\"NER\", \"Nigeria\":\"NGA\", \"Niue\":\"NIU\", \"North Korea\":\"PRK\",\n    \"Northern Ireland\":\"IRL\", \"Northern Mariana Islands\":\"MNP\",\n    \"Norway\":\"NOR\", \"Oman\":\"OMN\", \"Pakistan\":\"PAK\",\n    \"Palau\":\"PLW\", \"Palestine\":\"PSE\",\"Panama\":\"PAN\", \"Papua New Guinea\":\"PNG\",\n    \"Paraguay\":\"PRY\", \"Peru\":\"PER\", \"Philippines\":\"PHL\", \"Pitcairn Islands\":\"PCN\",\n    \"Poland\":\"POL\", \"Portugal\":\"PRT\", \"Puerto Rico\":\"PRI\",\n    \"Qatar\":\"QAT\", \"R\u00e9union\":\"REU\", \"Romania\":\"ROU\", \"Russia\":\"RUS\",\n    \"Rwanda\":\"RWA\", \"Saint Barth\u00e9lemy\":\"BLM\", \"Saint Helena\":\"SHN\",\n    \"Saint Kitts Nevis\":\"KNA\", \"Saint Lucia\":\"LCA\",\n    \"Saint Pierre Miquelon\":\"SPM\", \"Saint Vincent Grenadines\":\"VCT\",\n    \"Samoa\":\"WSM\", \"San Marino\":\"SMR\", \"S\u00e3o Tom\u00e9 Pr\u00edncipe\":\"STP\", \"Saudi Arabia\":\"SAU\",\n    \"Senegal\":\"SEN\", \"Serbia\":\"SRB\",\n    \"Seychelles\":\"SYC\", \"Sierra Leone\":\"SLE\", \"Singapore\":\"SGP\", \"Sint Maarten\":\"SXM\",\n    \"Slovakia\":\"SVK\", \"Slovenia\":\"SVN\", \"Solomon Islands\":\"SLB\",\n    \"Somalia\":\"SOM\", \"South Africa\":\"ZAF\",\n    \"South Korea\":\"KOR\", \"South Sudan\":\"SSD\", \"Spain\":\"ESP\", \"Sri Lanka\":\"LKA\", \"Sudan\":\"SDN\",\n    \"Suriname\":\"SUR\", \"Svalbard Jan Mayen\":\"SJM\",\n    \"Swaziland\":\"SWZ\", \"Sweden\":\"SWE\", \"Switzerland\":\"CHE\", \"Syria\":\"SYR\",\n    \"Taiwan\":\"TWN\", \"Tajikistan\":\"TJK\", \"Tanzania\":\"TZA\", \"Thailand\":\"THA\",\n    \"Timor Leste\":\"TLS\", \"East Timor\":\"TLS\",\"Togo\":\"TGO\", \"Tokelau\":\"TKL\", \"Tonga\":\"TON\", \"Trinidad Tobago\":\"TTO\",\n    \"Tunisia\":\"TUN\", \"Turkey\":\"TUR\",\n    \"Turkmenistan\":\"TKM\", \"Turks Caicos Islands\":\"TCA\", \"Tuvalu\":\"TUV\", \"U.S. Minor Outlying Islands\":\"UMI\",\n    \"Virgin Islands\":\"VIR\", \"Uganda\":\"UGA\",\n    \"Ukraine\":\"UKR\", \"United Arab Emirates\":\"ARE\", \"United Kingdom\":\"GBR\",\n    \"United States\":\"USA\",    \"Uruguay\":\"URY\", \"Uzbekistan\":\"UZB\", \"Vanuatu\":\"VUT\", \"Vatican\":\"VAT\",\n    \"Venezuela\":\"VEN\",\n    \"Vietnam\":\"VNM\", \"Wallis Futuna\":\"WLF\",\n    \"Western Sahara\":\"ESH\", \"Yemen\":\"YEM\", \"Zambia\":\"ZMB\", \"Zimbabwe\":\"ZWE\",\n    \"UK\":\"GBR\",  \"USA\":\"USA\", \"America\":\"USA\",  \"Palestinian Territories\":\"PSE\",\n    \"Congo Brazzaville\":\"COG\", \"Congo Kinshasa\":\"COD\", \"Wales\" : \"GBR\",\n    \"Scotland\" : \"GBR\", \"Britain\" : \"GBR\",}\n\n    return cts", "response": "Returns a dictionary of countries in ISO format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_skip_list(cts):\n    # maybe make these non-country searches but don't discard, at least for\n    # some (esp. bodies of water)\n    special_terms = [\"Europe\", \"West\", \"the West\", \"South Pacific\", \"Gulf of Mexico\", \"Atlantic\",\n                    \"the Black Sea\", \"Black Sea\", \"North America\", \"Mideast\", \"Middle East\",\n                     \"the Middle East\", \"Asia\", \"the Caucasus\", \"Africa\",\n                    \"Central Asia\", \"Balkans\", \"Eastern Europe\", \"Arctic\", \"Ottoman Empire\",\n                    \"Asia-Pacific\", \"East Asia\", \"Horn of Africa\", \"Americas\",\n                    \"North Africa\", \"the Strait of Hormuz\", \"Mediterranean\", \"East\", \"North\",\n                     \"South\", \"Latin America\", \"Southeast Asia\", \"Western Pacific\", \"South Asia\",\n                    \"Persian Gulf\", \"Central Europe\", \"Western Hemisphere\", \"Western Europe\",\n                    \"European Union (E.U.)\", \"EU\", \"European Union\", \"E.U.\", \"Asia-Pacific\",\n                 \"Europe\", \"Caribbean\", \"US\", \"U.S.\", \"Persian Gulf\", \"West Africa\", \"North\", \"East\",\n                     \"South\", \"West\", \"Western Countries\"\n                ]\n\n    # Some words are recurring spacy problems...\n    spacy_problems = [\"Kurd\", \"Qur'an\"]\n\n    #skip_list = list(cts.keys()) + special_terms\n    skip_list =  special_terms + spacy_problems\n    skip_list = set(skip_list)\n    return skip_list", "response": "Return the list of place names to skip and not attempt to geolocate."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of NLP countries so we can use vector comparisons", "response": "def country_list_nlp(cts):\n    \"\"\"NLP countries so we can use for vector comparisons\"\"\"\n    ct_nlp = []\n    for i in cts.keys():\n        nlped = nlp(i)\n        ct_nlp.append(nlped)\n    return ct_nlp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncombining list of countries and list of nationalities", "response": "def make_country_nationality_list(cts, ct_file):\n    \"\"\"Combine list of countries and list of nationalities\"\"\"\n    countries = pd.read_csv(ct_file)\n    nationality = dict(zip(countries.nationality,countries.alpha_3_code))\n    both_codes = {**nationality, **cts}\n    return both_codes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake inv_cts is the inverse of cts", "response": "def make_inv_cts(cts):\n    \"\"\"\n    cts is e.g. {\"Germany\" : \"DEU\"}. inv_cts is the inverse: {\"DEU\" : \"Germany\"}\n    \"\"\"\n    inv_ct = {}\n    for old_k, old_v in cts.items():\n        if old_v not in inv_ct.keys():\n            inv_ct.update({old_v : old_k})\n    return inv_ct"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_in_admin1(filepath):\n    with open(filepath) as admin1file:\n        admin1_dict = json.loads(admin1file.read())\n    return admin1_dict", "response": "Small helper function to read in admin1 code file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat Elasticsearch result as Python dictionary", "response": "def structure_results(res):\n    \"\"\"Format Elasticsearch result as Python dictionary\"\"\"\n    out = {'hits': {'hits': []}}\n    keys = [u'admin1_code', u'admin2_code', u'admin3_code', u'admin4_code',\n            u'alternativenames', u'asciiname', u'cc2', u'coordinates',\n            u'country_code2', u'country_code3', u'dem', u'elevation',\n            u'feature_class', u'feature_code', u'geonameid',\n            u'modification_date', u'name', u'population', u'timezone']\n    for i in res:\n        i_out = {}\n        for k in keys:\n            i_out[k] = i[k]\n        out['hits']['hits'].append(i_out)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_es(hosts, port, use_ssl=False, auth=None):\n    kwargs = dict(\n        hosts=hosts or ['localhost'],\n        port=port or 9200,\n        use_ssl=use_ssl,\n    )\n    if auth:\n        kwargs.update(http_auth=auth)\n\n    CLIENT = Elasticsearch(**kwargs)\n    S = Search(using=CLIENT, index=\"geonames\")\n    return S", "response": "Setup an Elasticsearch connection object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _feature_country_mentions(self, doc):\n        c_list = []\n        for i in doc.ents:\n            try:\n                country = self._both_codes[i.text]\n                c_list.append(country)\n            except KeyError:\n                pass\n        count = Counter(c_list).most_common()\n        try:\n            top, top_count = count[0]\n        except:\n            top = \"\"\n            top_count = 0\n        try:\n            two, two_count = count[1]\n        except:\n            two = \"\"\n            two_count = 0\n\n        countries = (top, top_count, two, two_count)\n        return countries", "response": "Given a spaCy nlped piece of text count how many times different country names and adjectives are mentioned."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_entity(self, ent):\n        dump_list = ['province', 'the', 'area', 'airport', 'district', 'square',\n                    'town', 'village', 'prison', \"river\", \"valley\", \"provincial\", \"prison\",\n                    \"region\", \"municipality\", \"state\", \"territory\", \"of\", \"in\",\n                    \"county\", \"central\"]\n                    # maybe have 'city'? Works differently in different countries\n                    # also, \"District of Columbia\". Might need to use cap/no cap\n        keep_positions = []\n        for word in ent:\n            if word.text.lower() not in dump_list:\n                keep_positions.append(word.i)\n\n        keep_positions = np.asarray(keep_positions)\n        try:\n            new_ent = ent.doc[keep_positions.min():keep_positions.max() + 1]\n            # can't set directly\n            #new_ent.label_.__set__(ent.label_)\n        except ValueError:\n            new_ent = ent\n        return new_ent", "response": "Clean an entity to remove extra words that often get picked up by spaCy s NER."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the most common country name in ES / Geonames results and return the ISO code of that country.", "response": "def _feature_most_common(self, results):\n        \"\"\"\n        Find the most common country name in ES/Geonames results\n\n        Paramaters\n        ----------\n        results: dict\n            output of `query_geonames`\n\n        Returns\n        -------\n        most_common: str\n            ISO code of most common country, or empty string if none\n        \"\"\"\n        try:\n            country_count = Counter([i['country_code3'] for i in results['hits']['hits']])\n            most_common = country_count.most_common()[0][0]\n            return most_common\n        except IndexError:\n            return \"\"\n        except TypeError:\n            return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _feature_most_alternative(self, results, full_results=False):\n        try:\n            alt_names = [len(i['alternativenames']) for i in results['hits']['hits']]\n            most_alt = results['hits']['hits'][np.array(alt_names).argmax()]\n            if full_results:\n                return most_alt\n            else:\n                return most_alt['country_code3']\n        except (IndexError, ValueError, TypeError):\n            return \"\"", "response": "Return the most alternative name for the placename with the most alternative names and return its country."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _feature_most_population(self, results):\n\n        try:\n            populations = [i['population'] for i in results['hits']['hits']]\n            most_pop = results['hits']['hits'][np.array(populations).astype(\"int\").argmax()]\n            return most_pop['country_code3']\n        except Exception as e:\n            return \"\"", "response": "Find the placename with the largest population and return its country."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _feature_word_embedding(self, text):\n        try:\n            simils = np.dot(self._prebuilt_vec, text.vector)\n        except Exception as e:\n            #print(\"Vector problem, \", Exception, e)\n            return {\"country_1\" : \"\",\n                \"confid_a\" : 0,\n                \"confid_b\" : 0,\n                \"country_2\" : \"\"}\n        ranks = simils.argsort()[::-1]\n        confid = simils.max()\n        confid2 = simils[ranks[0]] - simils[ranks[1]]\n        if confid == 0 or confid2 == 0:\n            return \"\"\n        country_code = self._cts[str(self._ct_nlp[ranks[0]])]\n        country_picking = {\"country_1\" : country_code,\n                \"confid_a\" : confid,\n                \"confid_b\" : confid2,\n                \"country_2\" : self._cts[str(self._ct_nlp[ranks[1]])]}\n        return country_picking", "response": "Given a word text guess the appropriate country by word vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _feature_first_back(self, results):\n        try:\n            first_back = results['hits']['hits'][0]['country_code3']\n        except (TypeError, IndexError):\n            # usually occurs if no Geonames result\n            first_back = \"\"\n        try:\n            second_back = results['hits']['hits'][1]['country_code3']\n        except (TypeError, IndexError):\n            second_back = \"\"\n        top = (first_back, second_back)\n        return top", "response": "Get the country of the first two results back from geonames."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a piece of text is in the list of countries", "response": "def is_country(self, text):\n        \"\"\"Check if a piece of text is in the list of countries\"\"\"\n        ct_list = self._just_cts.keys()\n        if text in ct_list:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_geonames(self, placename):\n        # first first, try for country name\n        if self.is_country(placename):\n            q = {\"multi_match\": {\"query\": placename,\n                                 \"fields\": ['name', 'asciiname', 'alternativenames'],\n                                \"type\" : \"phrase\"}}\n            res = self.conn.filter(\"term\", feature_code='PCLI').query(q)[0:5].execute()  # always 5\n        else:\n            # second, try for an exact phrase match\n            q = {\"multi_match\": {\"query\": placename,\n                                 \"fields\": ['name^5', 'asciiname^5', 'alternativenames'],\n                                \"type\" : \"phrase\"}}\n            res = self.conn.query(q)[0:50].execute()\n            # if no results, use some fuzziness, but still require all terms to be present.\n            # Fuzzy is not allowed in \"phrase\" searches.\n            if res.hits.total == 0:\n                # tried wrapping this in a {\"constant_score\" : {\"query\": ... but made it worse\n                q = {\"multi_match\": {\"query\": placename,\n                                     \"fields\": ['name', 'asciiname', 'alternativenames'],\n                                         \"fuzziness\" : 1,\n                                         \"operator\":   \"and\"\n                                     }\n                    }\n                res = self.conn.query(q)[0:50].execute()\n        es_result = utilities.structure_results(res)\n        return es_result", "response": "Wrap search parameters into an elasticsearch query to the geonames index\n        and return results."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_geonames_country(self, placename, country):\n        # first, try for an exact phrase match\n        q = {\"multi_match\": {\"query\": placename,\n                             \"fields\": ['name^5', 'asciiname^5', 'alternativenames'],\n                            \"type\": \"phrase\"}}\n        res = self.conn.filter(\"term\", country_code3=country).query(q)[0:50].execute()\n\n        # if no results, use some fuzziness, but still require all terms to be present.\n        # Fuzzy is not allowed in \"phrase\" searches.\n        if res.hits.total == 0:\n            # tried wrapping this in a {\"constant_score\" : {\"query\": ... but made it worse\n            q = {\"multi_match\": {\"query\": placename,\n                                 \"fields\": ['name', 'asciiname', 'alternativenames'],\n                                     \"fuzziness\": 1,\n                                     \"operator\":   \"and\"}}\n            res = self.conn.filter(\"term\", country_code3=country).query(q)[0:50].execute()\n        out = utilities.structure_results(res)\n        return out", "response": "Like query_geonames but this time limited to a specified country."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _feature_location_type_mention(self, ent):\n\n        P_list = [\"city\", \"cities\", \"town\", \"towns\", \"villages\", \"village\", \"settlement\",\n                  \"capital\", \"town\", \"towns\", \"neighborhood\", \"neighborhoods\",\n                 \"municipality\"]\n        ADM1_list = [\"province\", \"governorate\", \"state\", \"department\", \"oblast\",\n                     \"changwat\"]\n        ADM2_list = [\"district\", \"rayon\", \"amphoe\", \"county\"]\n        A_other = [\"region\"]\n        AIRPORT_list = [\"airport\"]\n        TERRAIN_list = [\"mountain\", \"mountains\", \"stream\", \"river\"]\n        FOREST_list = [\"forest\"]\n        # TODO: incorporate positions, especially now that we don't split by\n        # sentence\n        feature_positions = []\n        feature_class = feature_code = \"\"\n\n        interest_words = ent.doc[ent.end - 1 : ent.end + 1]  # last word or next word following\n\n        for word in interest_words:\n            if ent.text in self._just_cts.keys():\n                feature_class = \"A\"\n                feature_code = \"PCLI\"\n            elif word.text.lower() in P_list:\n                feature_class = \"P\"\n                feature_code = \"\"\n            elif word.text.lower() in ADM1_list:\n                feature_class = \"A\"\n                feature_code = \"ADM1\"\n            elif word.text.lower() in ADM2_list:\n                feature_class = \"A\"\n                feature_code = \"ADM2\"\n            elif word.text.lower() in TERRAIN_list:\n                feature_class = \"T\"\n                feature_code = \"\"\n            elif word.text.lower() in AIRPORT_list:\n                feature_class = \"S\"\n                feature_code = \"AIRP\"\n            elif word.text.lower() in A_other:\n                feature_class = \"A\"\n                feature_code = \"\"\n        return (feature_class, feature_code)", "response": "Return the feature type and feature code for a specific entity."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_country_features(self, doc, require_maj=False):\n        if not hasattr(doc, \"ents\"):\n            doc = nlp(doc)\n        # initialize the place to store finalized tasks\n        task_list = []\n\n        # get document vector\n        #doc_vec = self._feature_word_embedding(text)['country_1']\n\n        # get explicit counts of country names\n        ct_mention, ctm_count1, ct_mention2, ctm_count2 = self._feature_country_mentions(doc)\n\n        #  pull out the place names, skipping empty ones, countries, and known\n        #  junk from the skip list (like \"Atlanic Ocean\"\n        ents = []\n        for ent in doc.ents:\n            if not ent.text.strip():\n                continue\n            if ent.label_ not in [\"GPE\", \"LOC\", \"FAC\"]:\n                continue\n            # don't include country names (make a parameter)\n            if ent.text.strip() in self._skip_list:\n                continue\n            ents.append(ent)\n        if not ents:\n            return []\n        # Look them up in geonames, either sequentially if no threading, or\n        # in parallel if threads.\n        if self.threads:\n            pool = ThreadPool(len(ents))\n            ent_text = [i.text for i in ents]\n            ent_results = pool.map(self.simple_lookup, ent_text)\n            pool.close()\n            pool.join()\n        else:\n            ent_results = []\n            for ent in ents:\n                try:\n                    result = self.query_geonames(ent.text)\n                except ConnectionTimeout:\n                    result = \"\"\n                ent_results.append(result)\n\n        for n, ent in enumerate(ents):\n            result = ent_results[n]\n            #skip_list.add(ent.text.strip())\n            ent_label = ent.label_  # destroyed by trimming\n            ent = self.clean_entity(ent)\n\n            # vector for just the solo word\n            vp = self._feature_word_embedding(ent)\n            try:\n                word_vec = vp['country_1']\n                wv_confid = float(vp['confid_a'])\n            except TypeError:\n                # no idea why this comes up\n                word_vec = \"\"\n                wv_confid = \"0\"\n\n            # look for explicit mentions of feature names\n            class_mention, code_mention = self._feature_location_type_mention(ent)\n            # build results-based features\n            most_alt = self._feature_most_alternative(result)\n            # TODO check if most_common feature really isn't that useful\n            most_common = self._feature_most_common(result)\n            most_pop = self._feature_most_population(result)\n            first_back, second_back = self._feature_first_back(result)\n\n            try:\n                maj_vote = Counter([word_vec, most_alt,\n                                    first_back, most_pop,\n                                    ct_mention\n                                    #doc_vec_sent, doc_vec\n                                    ]).most_common()[0][0]\n            except Exception as e:\n                print(\"Problem taking majority vote: \", ent, e)\n                maj_vote = \"\"\n\n            if not maj_vote:\n                maj_vote = \"\"\n            # We only want all this junk for the labeling task. We just want to straight to features\n            # and the model when in production.\n            try:\n                start = ent.start_char\n                end = ent.end_char\n                iso_label = maj_vote\n                try:\n                    text_label = self._inv_cts[iso_label]\n                except KeyError:\n                    text_label = \"\"\n                task = {\"text\" : ent.text,\n                        \"label\" : text_label,  # human-readable country name\n                        \"word\" : ent.text,\n                        \"spans\" : [{\n                            \"start\" : start,\n                            \"end\" : end,\n                            }  # make sure to rename for Prodigy\n                                ],\n                        \"features\" : {\n                                \"maj_vote\" : iso_label,\n                                \"word_vec\" : word_vec,\n                                \"first_back\" : first_back,\n                                #\"doc_vec\" : doc_vec,\n                                \"most_alt\" : most_alt,\n                                \"most_pop\" : most_pop,\n                                \"ct_mention\" : ct_mention,\n                                \"ctm_count1\" : ctm_count1,\n                                \"ct_mention2\" : ct_mention2,\n                                \"ctm_count2\" : ctm_count2,\n                                \"wv_confid\" : wv_confid,\n                                \"class_mention\" : class_mention,  # inferred geonames class from mentions\n                                \"code_mention\" : code_mention,\n                                #\"places_vec\" : places_vec,\n                                #\"doc_vec_sent\" : doc_vec_sent\n                                }\n                        }\n                task_list.append(task)\n            except Exception as e:\n                print(ent.text,)\n                print(e)\n        return task_list", "response": "Create features for the country picking model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating features for all possible country labels and return as matrix for keras.", "response": "def make_country_matrix(self, loc):\n        \"\"\"\n        Create features for all possible country labels, return as matrix for keras.\n\n        Parameters\n        ----------\n        loc: dict\n            one entry from the list of locations and features that come out of make_country_features\n\n        Returns\n        --------\n        keras_inputs: dict with two keys, \"label\" and \"matrix\"\n        \"\"\"\n\n        top = loc['features']['ct_mention']\n        top_count = loc['features']['ctm_count1']\n        two = loc['features']['ct_mention2']\n        two_count = loc['features']['ctm_count2']\n        word_vec = loc['features']['word_vec']\n        first_back = loc['features']['first_back']\n        most_alt = loc['features']['most_alt']\n        most_pop = loc['features']['most_pop']\n\n        possible_labels = set([top, two, word_vec, first_back, most_alt, most_pop])\n        possible_labels = [i for i in possible_labels if i]\n\n        X_mat = []\n\n        for label in possible_labels:\n            inputs = np.array([word_vec, first_back, most_alt, most_pop])\n            x = inputs == label\n            x = np.asarray((x * 2) - 1) # convert to -1, 1\n\n            # get missing values\n            exists = inputs != \"\"\n            exists = np.asarray((exists * 2) - 1)\n\n            counts = np.asarray([top_count, two_count])  # cludgy, should be up with \"inputs\"\n            right = np.asarray([top, two]) == label\n            right = right * 2 - 1\n            right[counts == 0] = 0\n\n            # get correct values\n            features = np.concatenate([x, exists, counts, right])\n            X_mat.append(np.asarray(features))\n\n        keras_inputs = {\"labels\": possible_labels,\n                        \"matrix\" : np.asmatrix(X_mat)}\n        return keras_inputs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef infer_country(self, doc):\n        if not hasattr(doc, \"ents\"):\n            doc = nlp(doc)\n        proced = self.make_country_features(doc, require_maj=False)\n        if not proced:\n            pass\n            # logging!\n            #print(\"Nothing came back from make_country_features\")\n        feat_list = []\n        #proced = self.ent_list_to_matrix(proced)\n\n        for loc in proced:\n            feat = self.make_country_matrix(loc)\n            #labels = loc['labels']\n            feat_list.append(feat)\n            #try:\n            # for each potential country...\n            for n, i in enumerate(feat_list):\n                labels = i['labels']\n                try:\n                    prediction = self.country_model.predict(i['matrix']).transpose()[0]\n                    ranks = prediction.argsort()[::-1]\n                    labels = np.asarray(labels)[ranks]\n                    prediction = prediction[ranks]\n                except ValueError:\n                    prediction = np.array([0])\n                    labels = np.array([\"\"])\n\n            loc['country_predicted'] = labels[0]\n            loc['country_conf'] = prediction[0]\n            loc['all_countries'] = labels\n            loc['all_confidence'] = prediction\n\n        return proced", "response": "NLP a doc to find its entities get their features and return the model s country guess for each entity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_admin1(self, country_code2, admin1_code):\n        lookup_key = \".\".join([country_code2, admin1_code])\n        try:\n            admin1_name = self._admin1_dict[lookup_key]\n            return admin1_name\n        except KeyError:\n            #print(\"No admin code found for country {} and code {}\".format(country_code2, admin1_code))\n            return \"NA\"", "response": "Returns the admin1 name for a geonames admin1 code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute features for ranking results from ES and geonames.", "response": "def features_for_rank(self, proc, results):\n        \"\"\"Compute features for ranking results from ES/geonames\n\n\n        Parameters\n        ----------\n        proc : dict\n            One dictionary from the list that comes back from geoparse or from make_country_features (doesn't matter)\n        results : dict\n            the response from a geonames query\n\n        Returns\n        --------\n        X : numpy matrix\n            holding the computed features\n\n        meta: list of dicts\n            including feature information\n        \"\"\"\n        feature_list = []\n        meta = []\n        results = results['hits']['hits']\n        search_name = proc['word']\n        code_mention = proc['features']['code_mention']\n        class_mention = proc['features']['class_mention']\n\n        for rank, entry in enumerate(results):\n            # go through the results and calculate some features\n            # get population number and exists\n            try:\n                pop = int(entry['population'])\n                has_pop = 1\n            except Exception as e:\n                pop = 0\n                has_pop = 0\n            if pop > 0:\n                logp = np.log(pop)\n            else:\n                logp = 0\n            ### order the results came back\n            adj_rank = 1 / np.log(rank + 2)\n            # alternative names\n            len_alt = len(entry['alternativenames'])\n            adj_alt = np.log(len_alt)\n            ### feature class (just boost the good ones)\n            if entry['feature_class'] == \"A\" or entry['feature_class'] == \"P\":\n                good_type = 1\n            else:\n                good_type = 0\n                #fc_score = 3\n            ### feature class/code matching\n            if entry['feature_class'] == class_mention:\n                good_class_mention = 1\n            else:\n                good_class_mention = 0\n            if entry['feature_code'] == code_mention:\n                good_code_mention = 1\n            else:\n                good_code_mention = 0\n            ### edit distance\n            ed = editdistance.eval(search_name, entry['name'])\n            ed = ed  # shrug\n            # maybe also get min edit distance to alternative names...\n\n            features = [has_pop, pop, logp, adj_rank, len_alt, adj_alt,\n                        good_type, good_class_mention, good_code_mention, ed]\n            m = self.format_geonames(entry)\n\n            feature_list.append(features)\n            meta.append(m)\n\n        #meta = geo.format_geonames(results)\n        X = np.asmatrix(feature_list)\n        return (X, meta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ranker(self, X, meta):\n        # total score is just a sum of each row\n        total_score = X.sum(axis=1).transpose()\n        total_score = np.squeeze(np.asarray(total_score))  # matrix to array\n        ranks = total_score.argsort()\n        ranks = ranks[::-1]\n        # sort the list of dicts according to ranks\n        sorted_meta = [meta[r] for r in ranks]\n        sorted_X = X[ranks]\n        return (sorted_X, sorted_meta)", "response": "Sort the place features list by the score of its relevance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a feature matrix geonames data and a original query return a list of dicts that can be used to generate a prodigy task.", "response": "def format_for_prodigy(self, X, meta, placename, return_feature_subset=False):\n        \"\"\"\n        Given a feature matrix, geonames data, and the original query,\n        construct a prodigy task.\n\n        Make meta nicely readable: \"A town in Germany\"\n\n        Parameters\n        ----------\n\n        X: matrix\n            vector of features for ranking. Output of features_for_rank()\n        meta: list of dictionaries\n            other place information. Output of features_for_rank(). Used to provide\n            information like \"city in Germany\" to the coding task.\n        placename: str\n            The extracted place name from text\n\n\n        Returns\n        --------\n        task_list: list of dicts\n            Tasks ready to be written to JSONL and use in Prodigy. Each potential match includes\n            a text description to the annotator can pick the right one.\n        \"\"\"\n\n        all_tasks = []\n\n        sorted_X, sorted_meta = self.ranker(X, meta)\n        sorted_meta = sorted_meta[:4]\n        sorted_X = sorted_X[:4]\n        for n, i in enumerate(sorted_meta):\n            feature_code = i['feature_code']\n            try:\n                fc = self._code_to_text[feature_code]\n            except KeyError:\n                fc = ''\n            text = ''.join(['\"', i['place_name'], '\"',\n                            \", a \", fc,\n                            \" in \", i['country_code3'],\n                            \", id: \", i['geonameid']])\n            d = {\"id\" : n + 1, \"text\" : text}\n            all_tasks.append(d)\n\n        if return_feature_subset:\n            return (all_tasks, sorted_meta, sorted_X)\n        else:\n            return all_tasks"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats a geonames entry into a dict that can be used to pick out the fields we want from a geonames entry", "response": "def format_geonames(self, entry, searchterm=None):\n        \"\"\"\n        Pull out just the fields we want from a geonames entry\n\n        To do:\n        - switch to model picking\n\n        Parameters\n        -----------\n        res : dict\n            ES/geonames result\n\n        searchterm : str\n            (not implemented). Needed for better results picking\n\n        Returns\n        --------\n        new_res : dict\n            containing selected fields from selected geonames entry\n        \"\"\"\n        try:\n            lat, lon = entry['coordinates'].split(\",\")\n            new_res = {\"admin1\" : self.get_admin1(entry['country_code2'], entry['admin1_code']),\n                  \"lat\" : lat,\n                  \"lon\" : lon,\n                  \"country_code3\" : entry[\"country_code3\"],\n                  \"geonameid\" : entry[\"geonameid\"],\n                  \"place_name\" : entry[\"name\"],\n                  \"feature_class\" : entry[\"feature_class\"],\n                   \"feature_code\" : entry[\"feature_code\"]}\n            return new_res\n        except (IndexError, TypeError):\n            # two conditions for these errors:\n            # 1. there are no results for some reason (Index)\n            # 2. res is set to \"\" because the country model was below the thresh\n            new_res = {\"admin1\" : \"\",\n                  \"lat\" : \"\",\n                  \"lon\" : \"\",\n                  \"country_code3\" : \"\",\n                  \"geonameid\" : \"\",\n                  \"place_name\" : \"\",\n                  \"feature_class\" : \"\",\n                   \"feature_code\" : \"\"}\n            return new_res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_proced(self, proced):\n        for loc in proced:\n            try:\n                del loc['all_countries']\n            except KeyError:\n                pass\n            try:\n                del loc['matrix']\n            except KeyError:\n                pass\n            try:\n                del loc['all_confidence']\n            except KeyError:\n                pass\n            try:\n                del loc['place_confidence']\n            except KeyError:\n                pass\n            try:\n                del loc['text']\n            except KeyError:\n                pass\n            try:\n                del loc['label']\n            except KeyError:\n                pass\n            try:\n                del loc['features']\n            except KeyError:\n                pass\n        return proced", "response": "Small helper function to delete the features from the final dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbatching geoparsing function. Take in a list of text documents and return a list of lists .", "response": "def batch_geoparse(self, text_list):\n        \"\"\"\n        Batch geoparsing function. Take in a list of text documents and return a list of lists\n        of the geoparsed documents. The speed improvements come exclusively from using spaCy's `nlp.pipe`.\n\n        Parameters\n        ----------\n        text_list : list of strs\n            List of documents. The documents should not have been pre-processed by spaCy.\n\n        Returns\n        -------\n        processed : list of list of dictionaries.\n            The list is the same length as the input list of documents. Each element is a list of dicts, one for\n            each geolocated entity.\n        \"\"\"\n        if not self.threads:\n            print(\"batch_geoparsed should be used with threaded searches. Please set `threads=True` when initializing the geoparser.\")\n        nlped_docs = list(nlp.pipe(text_list, as_tuples=False, n_threads=multiprocessing.cpu_count()))\n        processed = []\n        for i in tqdm(nlped_docs, disable=not self.progress):\n            p = self.geoparse(i)\n            processed.append(p)\n        return processed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef entry_to_matrix(prodigy_entry):\n    doc = prodigy_entry['text']\n    doc = nlp(doc)\n    geo_proced = geo.process_text(doc, require_maj=False)\n\n    # find the geoproced entity that matches the Prodigy entry\n    ent_text = np.asarray([gp['word'] for gp in geo_proced]) # get mask for correct ent\n    #print(ent_text)\n    match = ent_text == entry['meta']['word']\n    #print(\"match: \", match)\n    anti_match = np.abs(match - 1)\n    #print(\"Anti-match \", anti_match)\n    match_position = match.argmax()\n\n    geo_proc = geo_proced[match_position]\n\n    iso = geo.cts[prodigy_entry['label']] # convert country text label to ISO\n    feat = geo.features_to_matrix(geo_proc)\n    answer_x = feat['matrix']\n    label = np.asarray(feat['labels'])\n\n    if prodigy_entry['answer'] == \"accept\":\n        answer_binary = label == iso\n        answer_binary = answer_binary.astype('int')\n        #print(answer_x.shape)\n        #print(answer_binary.shape)\n\n\n    elif prodigy_entry['answer'] == \"reject\":\n        # all we know is that the label that was presented is wrong.\n        # just return the corresponding row in the feature matrix,\n        #   and force the label to be 0\n        answer_binary = label == iso\n        answer_x = answer_x[answer_binary,:] # just take the row corresponding to the answer\n        answer_binary = np.asarray([0]) # set the outcome to 0 because reject\n\n    # NEED TO SHARE LABELS ACROSS! THE CORRECT ONE MIGHT NOT EVEN APPEAR FOR ALL ENTITIES\n\n    x = feat['matrix']\n    other_x = x[anti_match,:]\n    #print(other_x)\n    #print(label[anti_match])\n    # here, need to get the rows corresponding to the correct label\n\n    #    print(geo_proc['meta'])\n        # here's where we get the other place name features.\n        # Need to:\n        #  1. do features_to_matrix but use the label of the current entity\n        #     to determine 0/1 in the feature matrix\n        #  2. put them all into one big feature matrix,\n        #  3. ...ordering by distance? And need to decide max entity length\n        #  4. also include these distances as one of the features\n\n    #print(answer_x.shape[0])\n    #print(answer_binary.shape[0])\n    try:\n        if answer_x.shape[0] == answer_binary.shape[0]:\n            return (answer_x, answer_binary)\n    except:\n        pass", "response": "Convert a Prodigy entry to a matrix of features."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh_client(self):\n        req = self.session.post(\n            self._fmip_refresh_url,\n            params=self.params,\n            data=json.dumps(\n                {\n                    'clientContext': {\n                        'fmly': True,\n                        'shouldLocate': True,\n                        'selectedDevice': 'all',\n                    }\n                }\n            )\n        )\n        self.response = req.json()\n\n        for device_info in self.response['content']:\n            device_id = device_info['id']\n            if device_id not in self._devices:\n                self._devices[device_id] = AppleDevice(\n                    device_info,\n                    self.session,\n                    self.params,\n                    manager=self,\n                    sound_url=self._fmip_sound_url,\n                    lost_url=self._fmip_lost_url,\n                    message_url=self._fmip_message_url,\n                )\n            else:\n                self._devices[device_id].update(device_info)\n\n        if not self._devices:\n            raise PyiCloudNoDevicesException()", "response": "Refreshes the FindMyiPhoneService endpoint and updates the client context with the new data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning status information for the device.", "response": "def status(self, additional=[]):\n        \"\"\" Returns status information for device.\n\n        This returns only a subset of possible properties.\n        \"\"\"\n        self.manager.refresh_client()\n        fields = ['batteryLevel', 'deviceDisplayName', 'deviceStatus', 'name']\n        fields += additional\n        properties = {}\n        for field in fields:\n            properties[field] = self.content.get(field)\n        return properties"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef play_sound(self, subject='Find My iPhone Alert'):\n        data = json.dumps({\n            'device': self.content['id'],\n            'subject': subject,\n            'clientContext': {\n                'fmly': True\n            }\n        })\n        self.session.post(\n            self.sound_url,\n            params=self.params,\n            data=data\n        )", "response": "Send a request to the device to play a sound."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a request to the device to play a sound.", "response": "def display_message(\n        self, subject='Find My iPhone Alert', message=\"This is a note\",\n        sounds=False\n    ):\n        \"\"\" Send a request to the device to play a sound.\n\n        It's possible to pass a custom message by changing the `subject`.\n        \"\"\"\n        data = json.dumps(\n            {\n                'device': self.content['id'],\n                'subject': subject,\n                'sound': sounds,\n                'userText': True,\n                'text': message\n            }\n        )\n        self.session.post(\n            self.message_url,\n            params=self.params,\n            data=data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a request to the device to trigger the lost mode.", "response": "def lost_device(\n        self, number,\n        text='This iPhone has been lost. Please call me.',\n        newpasscode=\"\"\n    ):\n        \"\"\" Send a request to the device to trigger 'lost mode'.\n\n        The device will show the message in `text`, and if a number has\n        been passed, then the person holding the device can call\n        the number without entering the passcode.\n        \"\"\"\n        data = json.dumps({\n            'text': text,\n            'userText': True,\n            'ownerNbr': number,\n            'lostModeEnabled': True,\n            'trackingEnabled': True,\n            'device': self.content['id'],\n            'passcode': newpasscode\n        })\n        self.session.post(\n            self.lost_url,\n            params=self.params,\n            data=data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches a single event s details by specifying a pguid and guid.", "response": "def get_event_detail(self, pguid, guid):\n        \"\"\"\n        Fetches a single event's details by specifying a pguid\n        (a calendar) and a guid (an event's ID).\n        \"\"\"\n        params = dict(self.params)\n        params.update({'lang': 'en-us', 'usertz': get_localzone().zone})\n        url = '%s/%s/%s' % (self._calendar_event_detail_url, pguid, guid)\n        req = self.session.get(url, params=params)\n        self.response = req.json()\n        return self.response['Event'][0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef events(self, from_dt=None, to_dt=None):\n        self.refresh_client(from_dt, to_dt)\n        return self.response['Event']", "response": "Retrieve events for a given date range by default this month."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the calendars for this month", "response": "def calendars(self):\n        \"\"\"\n        Retrieves calendars for this month\n        \"\"\"\n        today = datetime.today()\n        first_day, last_day = monthrange(today.year, today.month)\n        from_dt = datetime(today.year, today.month, first_day)\n        to_dt = datetime(today.year, today.month, last_day)\n        params = dict(self.params)\n        params.update({\n            'lang': 'en-us',\n            'usertz': get_localzone().zone,\n            'startDate': from_dt.strftime('%Y-%m-%d'),\n            'endDate': to_dt.strftime('%Y-%m-%d')\n        })\n        req = self.session.get(self._calendars, params=params)\n        self.response = req.json()\n        return self.response['Collection']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_pickled_data(idevice, filename):\n    data = {}\n    for x in idevice.content:\n        data[x] = idevice.content[x]\n    location = filename\n    pickle_file = open(location, 'wb')\n    pickle.dump(data, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n    pickle_file.close()", "response": "This helper will output the idevice to a pickled file named\n    after the passed filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refresh_client(self, from_dt=None, to_dt=None):\n        params_contacts = dict(self.params)\n        params_contacts.update({\n            'clientVersion': '2.1',\n            'locale': 'en_US',\n            'order': 'last,first',\n        })\n        req = self.session.get(\n            self._contacts_refresh_url,\n            params=params_contacts\n        )\n        self.response = req.json()\n        params_refresh = dict(self.params)\n        params_refresh.update({\n            'prefToken': req.json()[\"prefToken\"],\n            'syncToken': req.json()[\"syncToken\"],\n        })\n        self.session.post(self._contacts_changeset_url, params=params_refresh)\n        req = self.session.get(\n            self._contacts_refresh_url,\n            params=params_contacts\n        )\n        self.response = req.json()", "response": "Refreshes the contacts service endpoint ensuring that the contacts data is up - to - date."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles authentication and saves the cookie jar and the user s data.", "response": "def authenticate(self):\n        \"\"\"\n        Handles authentication, and persists the X-APPLE-WEB-KB cookie so that\n        subsequent logins will not cause additional e-mails from Apple.\n        \"\"\"\n\n        logger.info(\"Authenticating as %s\", self.user['apple_id'])\n\n        data = dict(self.user)\n\n        # We authenticate every time, so \"remember me\" is not needed\n        data.update({'extended_login': False})\n\n        try:\n            req = self.session.post(\n                self._base_login_url,\n                params=self.params,\n                data=json.dumps(data)\n            )\n        except PyiCloudAPIResponseError as error:\n            msg = 'Invalid email/password combination.'\n            raise PyiCloudFailedLoginException(msg, error)\n\n        resp = req.json()\n        self.params.update({'dsid': resp['dsInfo']['dsid']})\n\n        if not os.path.exists(self._cookie_directory):\n            os.mkdir(self._cookie_directory)\n        self.session.cookies.save()\n        logger.debug(\"Cookies saved to %s\", self._get_cookiejar_path())\n\n        self.data = resp\n        self.webservices = self.data['webservices']\n\n        logger.info(\"Authentication completed successfully\")\n        logger.debug(self.params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trusted_devices(self):\n        request = self.session.get(\n            '%s/listDevices' % self._setup_endpoint,\n            params=self.params\n        )\n        return request.json().get('devices')", "response": "Returns devices trusted for two - step authentication."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a verification code to the given device", "response": "def send_verification_code(self, device):\n        \"\"\" Requests that a verification code is sent to the given device\"\"\"\n        data = json.dumps(device)\n        request = self.session.post(\n            '%s/sendVerificationCode' % self._setup_endpoint,\n            params=self.params,\n            data=data\n        )\n        return request.json().get('success', False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_verification_code(self, device, code):\n        device.update({\n            'verificationCode': code,\n            'trustBrowser': True\n        })\n        data = json.dumps(device)\n\n        try:\n            request = self.session.post(\n                '%s/validateVerificationCode' % self._setup_endpoint,\n                params=self.params,\n                data=data\n            )\n        except PyiCloudAPIResponseError as error:\n            if error.code == -21669:\n                # Wrong verification code\n                return False\n            raise\n\n        # Re-authenticate, which will both update the HSA data, and\n        # ensure that we save the X-APPLE-WEBAUTH-HSA-TRUST cookie.\n        self.authenticate()\n\n        return not self.requires_2sa", "response": "Verifies a verification code received on a trusted device and returns True if the verification code is valid False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send(r, pool=None, stream=False):\n    if pool is not None:\n        return pool.spawn(r.send, stream=stream)\n\n    return gevent.spawn(r.send, stream=stream)", "response": "Sends the request object using the specified pool."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map(requests, stream=False, size=None, exception_handler=None, gtimeout=None):\n\n    requests = list(requests)\n\n    pool = Pool(size) if size else None\n    jobs = [send(r, pool, stream=stream) for r in requests]\n    gevent.joinall(jobs, timeout=gtimeout)\n\n    ret = []\n\n    for request in requests:\n        if request.response is not None:\n            ret.append(request.response)\n        elif exception_handler and hasattr(request, 'exception'):\n            ret.append(exception_handler(request, request.exception))\n        else:\n            ret.append(None)\n\n    return ret", "response": "Concurrently converts a list of Requests to Responses."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef imap(requests, stream=False, size=2, exception_handler=None):\n\n    pool = Pool(size)\n\n    def send(r):\n        return r.send(stream=stream)\n\n    for request in pool.imap_unordered(send, requests):\n        if request.response is not None:\n            yield request.response\n        elif exception_handler:\n            ex_result = exception_handler(request, request.exception)\n            if ex_result is not None:\n                yield ex_result\n\n    pool.join()", "response": "Concurrently converts a generator object of Requests to\n    a generator of Responses."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends the request and saves the response to self. response.", "response": "def send(self, **kwargs):\n        \"\"\"\n        Prepares request based on parameter passed to constructor and optional ``kwargs```.\n        Then sends request and saves response to :attr:`response`\n\n        :returns: ``Response``\n        \"\"\"\n        merged_kwargs = {}\n        merged_kwargs.update(self.kwargs)\n        merged_kwargs.update(kwargs)\n        try:\n            self.response = self.session.request(self.method,\n                                                self.url, **merged_kwargs)\n        except Exception as e:\n            self.exception = e\n            self.traceback = traceback.format_exc()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets user profile within a room.", "response": "def set_user_profile(self,\n                         displayname=None,\n                         avatar_url=None,\n                         reason=\"Changing room profile information\"):\n        \"\"\"Set user profile within a room.\n\n        This sets displayname and avatar_url for the logged in user only in a\n        specific room. It does not change the user's global user profile.\n        \"\"\"\n        member = self.client.api.get_membership(self.room_id, self.client.user_id)\n        if member[\"membership\"] != \"join\":\n            raise Exception(\"Can't set profile if you have not joined the room.\")\n        if displayname is None:\n            displayname = member[\"displayname\"]\n        if avatar_url is None:\n            avatar_url = member[\"avatar_url\"]\n        self.client.api.set_membership(\n            self.room_id,\n            self.client.user_id,\n            'join',\n            reason, {\n                \"displayname\": displayname,\n                \"avatar_url\": avatar_url\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef display_name(self):\n        if self.name:\n            return self.name\n        elif self.canonical_alias:\n            return self.canonical_alias\n\n        # Member display names without me\n        members = [u.get_display_name(self) for u in self.get_joined_members() if\n                   self.client.user_id != u.user_id]\n        members.sort()\n\n        if len(members) == 1:\n            return members[0]\n        elif len(members) == 2:\n            return \"{0} and {1}\".format(members[0], members[1])\n        elif len(members) > 2:\n            return \"{0} and {1} others\".format(members[0], len(members) - 1)\n        else:  # len(members) <= 0 or not an integer\n            # TODO i18n\n            return \"Empty room\"", "response": "Calculates the display name for a room."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_text(self, text):\n        return self.client.api.send_message(self.room_id, text)", "response": "Send a plain text message to the room."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend an html formatted message.", "response": "def send_html(self, html, body=None, msgtype=\"m.text\"):\n        \"\"\"Send an html formatted message.\n\n        Args:\n            html (str): The html formatted message to be sent.\n            body (str): The unformatted body of the message to be sent.\n        \"\"\"\n        return self.client.api.send_message_event(\n            self.room_id, \"m.room.message\", self.get_html_content(html, body, msgtype))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_emote(self, text):\n        return self.client.api.send_emote(self.room_id, text)", "response": "Send an emote to the room."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a pre - uploaded file to the room.", "response": "def send_file(self, url, name, **fileinfo):\n        \"\"\"Send a pre-uploaded file to the room.\n\n        See http://matrix.org/docs/spec/r0.2.0/client_server.html#m-file for\n        fileinfo.\n\n        Args:\n            url (str): The mxc url of the file.\n            name (str): The filename of the image.\n            fileinfo (): Extra information about the file\n        \"\"\"\n\n        return self.client.api.send_content(\n            self.room_id, url, name, \"m.file\",\n            extra_information=fileinfo\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a notice to the room.", "response": "def send_notice(self, text):\n        \"\"\"Send a notice (from bot) message to the room.\"\"\"\n        return self.client.api.send_notice(self.room_id, text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a pre - uploaded image to the room.", "response": "def send_image(self, url, name, **imageinfo):\n        \"\"\"Send a pre-uploaded image to the room.\n\n        See http://matrix.org/docs/spec/r0.0.1/client_server.html#m-image\n        for imageinfo\n\n        Args:\n            url (str): The mxc url of the image.\n            name (str): The filename of the image.\n            imageinfo (): Extra information about the image.\n        \"\"\"\n        return self.client.api.send_content(\n            self.room_id, url, name, \"m.image\",\n            extra_information=imageinfo\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_location(self, geo_uri, name, thumb_url=None, **thumb_info):\n        return self.client.api.send_location(self.room_id, geo_uri, name,\n                                             thumb_url, thumb_info)", "response": "Send a location to the room."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a pre - uploaded video to the room.", "response": "def send_video(self, url, name, **videoinfo):\n        \"\"\"Send a pre-uploaded video to the room.\n\n        See http://matrix.org/docs/spec/client_server/r0.2.0.html#m-video\n        for videoinfo\n\n        Args:\n            url (str): The mxc url of the video.\n            name (str): The filename of the video.\n            videoinfo (): Extra information about the video.\n        \"\"\"\n        return self.client.api.send_content(self.room_id, url, name, \"m.video\",\n                                            extra_information=videoinfo)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_audio(self, url, name, **audioinfo):\n        return self.client.api.send_content(self.room_id, url, name, \"m.audio\",\n                                            extra_information=audioinfo)", "response": "Send a pre - uploaded audio to the room."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef redact_message(self, event_id, reason=None):\n        return self.client.api.redact_event(self.room_id, event_id, reason)", "response": "Redacts the message with the specified event_id for the given reason."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a callback handler for events going to this room.", "response": "def add_listener(self, callback, event_type=None):\n        \"\"\"Add a callback handler for events going to this room.\n\n        Args:\n            callback (func(room, event)): Callback called when an event arrives.\n            event_type (str): The event_type to filter for.\n        Returns:\n            uuid.UUID: Unique id of the listener, can be used to identify the listener.\n        \"\"\"\n        listener_id = uuid4()\n        self.listeners.append(\n            {\n                'uid': listener_id,\n                'callback': callback,\n                'event_type': event_type\n            }\n        )\n        return listener_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving listener with given uid.", "response": "def remove_listener(self, uid):\n        \"\"\"Remove listener with given uid.\"\"\"\n        self.listeners[:] = (listener for listener in self.listeners\n                             if listener['uid'] != uid)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a callback handler for ephemeral events going to this room.", "response": "def add_ephemeral_listener(self, callback, event_type=None):\n        \"\"\"Add a callback handler for ephemeral events going to this room.\n\n        Args:\n            callback (func(room, event)): Callback called when an ephemeral event arrives.\n            event_type (str): The event_type to filter for.\n        Returns:\n            uuid.UUID: Unique id of the listener, can be used to identify the listener.\n        \"\"\"\n        listener_id = uuid4()\n        self.ephemeral_listeners.append(\n            {\n                'uid': listener_id,\n                'callback': callback,\n                'event_type': event_type\n            }\n        )\n        return listener_id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an ephemeral listener with given uid.", "response": "def remove_ephemeral_listener(self, uid):\n        \"\"\"Remove ephemeral listener with given uid.\"\"\"\n        self.ephemeral_listeners[:] = (listener for listener in self.ephemeral_listeners\n                                       if listener['uid'] != uid)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninviting a user to this room.", "response": "def invite_user(self, user_id):\n        \"\"\"Invite a user to this room.\n\n        Returns:\n            boolean: Whether invitation was sent.\n        \"\"\"\n        try:\n            self.client.api.invite_user(self.room_id, user_id)\n            return True\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nkick a user from this room.", "response": "def kick_user(self, user_id, reason=\"\"):\n        \"\"\"Kick a user from this room.\n\n\n        Args:\n            user_id (str): The matrix user id of a user.\n            reason  (str): A reason for kicking the user.\n\n        Returns:\n            boolean: Whether user was kicked.\n        \"\"\"\n        try:\n            self.client.api.kick_user(self.room_id, user_id)\n            return True\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nleave the room. Returns: boolean: Leaving the room was successful.", "response": "def leave(self):\n        \"\"\"Leave the room.\n\n        Returns:\n            boolean: Leaving the room was successful.\n        \"\"\"\n        try:\n            self.client.api.leave_room(self.room_id)\n            del self.client.rooms[self.room_id]\n            return True\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_room_name(self):\n        try:\n            response = self.client.api.get_room_name(self.room_id)\n            if \"name\" in response and response[\"name\"] != self.name:\n                self.name = response[\"name\"]\n                return True\n            else:\n                return False\n        except MatrixRequestError:\n            return False", "response": "Updates self. name and returns True if room name has changed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if room name successfully changed.", "response": "def set_room_name(self, name):\n        \"\"\"Return True if room name successfully changed.\"\"\"\n        try:\n            self.client.api.set_room_name(self.room_id, name)\n            self.name = name\n            return True\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_state_event(self, event_type, content, state_key=\"\"):\n        return self.client.api.send_state_event(\n            self.room_id,\n            event_type,\n            content,\n            state_key\n        )", "response": "Send a state event to the room."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates self. topic and returns True if room topic has changed.", "response": "def update_room_topic(self):\n        \"\"\"Updates self.topic and returns True if room topic has changed.\"\"\"\n        try:\n            response = self.client.api.get_room_topic(self.room_id)\n            if \"topic\" in response and response[\"topic\"] != self.topic:\n                self.topic = response[\"topic\"]\n                return True\n            else:\n                return False\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_room_topic(self, topic):\n        try:\n            self.client.api.set_room_topic(self.room_id, topic)\n            self.topic = topic\n            return True\n        except MatrixRequestError:\n            return False", "response": "Sets the topic of the current room."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_aliases(self):\n        try:\n            response = self.client.api.get_room_state(self.room_id)\n            for chunk in response:\n                if \"content\" in chunk and \"aliases\" in chunk[\"content\"]:\n                    if chunk[\"content\"][\"aliases\"] != self.aliases:\n                        self.aliases = chunk[\"content\"][\"aliases\"]\n                        return True\n                    else:\n                        return False\n        except MatrixRequestError:\n            return False", "response": "Update aliases of the room."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an alias to the room and return True if successful.", "response": "def add_room_alias(self, room_alias):\n        \"\"\"Add an alias to the room and return True if successful.\"\"\"\n        try:\n            self.client.api.set_room_alias(self.room_id, room_alias)\n            return True\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list of joined members ( User objects ).", "response": "def get_joined_members(self):\n        \"\"\"Returns list of joined members (User objects).\"\"\"\n        if self._members:\n            return list(self._members.values())\n        response = self.client.api.get_room_members(self.room_id)\n        for event in response[\"chunk\"]:\n            if event[\"content\"][\"membership\"] == \"join\":\n                user_id = event[\"state_key\"]\n                self._add_member(user_id, event[\"content\"].get(\"displayname\"))\n        return list(self._members.values())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modify_user_power_levels(self, users=None, users_default=None):\n        try:\n            content = self.client.api.get_power_levels(self.room_id)\n            if users_default:\n                content[\"users_default\"] = users_default\n\n            if users:\n                if \"users\" in content:\n                    content[\"users\"].update(users)\n                else:\n                    content[\"users\"] = users\n\n                # Remove any keys with value None\n                for user, power_level in list(content[\"users\"].items()):\n                    if power_level is None:\n                        del content[\"users\"][user]\n            self.client.api.set_power_levels(self.room_id, content)\n            return True\n        except MatrixRequestError:\n            return False", "response": "Modify the power level for a subset of users in a room."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef modify_required_power_levels(self, events=None, **kwargs):\n        try:\n            content = self.client.api.get_power_levels(self.room_id)\n            content.update(kwargs)\n            for key, value in list(content.items()):\n                if value is None:\n                    del content[key]\n\n            if events:\n                if \"events\" in content:\n                    content[\"events\"].update(events)\n                else:\n                    content[\"events\"] = events\n\n                # Remove any keys with value None\n                for event, power_level in list(content[\"events\"].items()):\n                    if power_level is None:\n                        del content[\"events\"][event]\n\n            self.client.api.set_power_levels(self.room_id, content)\n            return True\n        except MatrixRequestError:\n            return False", "response": "Modifies the room power level requirements."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets whether the users can invited the room.", "response": "def set_invite_only(self, invite_only):\n        \"\"\"Set how the room can be joined.\n\n        Args:\n            invite_only(bool): If True, users will have to be invited to join\n                the room. If False, anyone who knows the room link can join.\n\n        Returns:\n            True if successful, False if not\n        \"\"\"\n        join_rule = \"invite\" if invite_only else \"public\"\n        try:\n            self.client.api.set_join_rule(self.room_id, join_rule)\n            self.invite_only = invite_only\n            return True\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting whether guests can join the room and return True if successful.", "response": "def set_guest_access(self, allow_guests):\n        \"\"\"Set whether guests can join the room and return True if successful.\"\"\"\n        guest_access = \"can_join\" if allow_guests else \"forbidden\"\n        try:\n            self.client.api.set_guest_access(self.room_id, guest_access)\n            self.guest_access = allow_guests\n            return True\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nenable encryption in the room.", "response": "def enable_encryption(self):\n        \"\"\"Enables encryption in the room.\n\n        NOTE: Once enabled, encryption cannot be disabled.\n\n        Returns:\n        True if successful, False if not\n        \"\"\"\n        try:\n            self.send_state_event(\"m.room.encryption\",\n                                  {\"algorithm\": \"m.megolm.v1.aes-sha2\"})\n            self.encrypted = True\n            return True\n        except MatrixRequestError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef initial_sync(self, limit=1):\n        warnings.warn(\"initial_sync is deprecated. Use sync instead.\", DeprecationWarning)\n        return self._send(\"GET\", \"/initialSync\", query_params={\"limit\": limit})", "response": "Perform an initial sync."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform a sync request.", "response": "def sync(self, since=None, timeout_ms=30000, filter=None,\n             full_state=None, set_presence=None):\n        \"\"\" Perform a sync request.\n\n        Args:\n            since (str): Optional. A token which specifies where to continue a sync from.\n            timeout_ms (int): Optional. The time in milliseconds to wait.\n            filter (int|str): Either a Filter ID or a JSON string.\n            full_state (bool): Return the full state for every room the user has joined\n                Defaults to false.\n            set_presence (str): Should the client be marked as \"online\" or\" offline\"\n        \"\"\"\n\n        request = {\n            # non-integer timeouts appear to cause issues\n            \"timeout\": int(timeout_ms)\n        }\n\n        if since:\n            request[\"since\"] = since\n\n        if filter:\n            request[\"filter\"] = filter\n\n        if full_state:\n            request[\"full_state\"] = json.dumps(full_state)\n\n        if set_presence:\n            request[\"set_presence\"] = set_presence\n\n        return self._send(\"GET\", \"/sync\", query_params=request,\n                          api_path=MATRIX_V2_API_PATH)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a new user with the specified parameters.", "response": "def register(self, auth_body=None, kind=\"user\", bind_email=None,\n                 username=None, password=None, device_id=None,\n                 initial_device_display_name=None, inhibit_login=None):\n        \"\"\"Performs /register.\n\n        Args:\n            auth_body (dict): Authentication Params.\n            kind (str): Specify kind of account to register. Can be 'guest' or 'user'.\n            bind_email (bool): Whether to use email in registration and authentication.\n            username (str): The localpart of a Matrix ID.\n            password (str): The desired password of the account.\n            device_id (str): ID of the client device.\n            initial_device_display_name (str): Display name to be assigned.\n            inhibit_login (bool): Whether to login after registration. Defaults to false.\n        \"\"\"\n        content = {}\n        content[\"kind\"] = kind\n        if auth_body:\n            content[\"auth\"] = auth_body\n        if username:\n            content[\"username\"] = username\n        if password:\n            content[\"password\"] = password\n        if device_id:\n            content[\"device_id\"] = device_id\n        if initial_device_display_name:\n            content[\"initial_device_display_name\"] = \\\n                    initial_device_display_name\n        if bind_email:\n            content[\"bind_email\"] = bind_email\n        if inhibit_login:\n            content[\"inhibit_login\"] = inhibit_login\n        return self._send(\n            \"POST\",\n            \"/register\",\n            content=content,\n            query_params={'kind': kind}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform /login. Args: login_type (str): The value for the 'type' key. **kwargs: Additional key/values to add to the JSON submitted.", "response": "def login(self, login_type, **kwargs):\n        \"\"\"Perform /login.\n\n        Args:\n            login_type (str): The value for the 'type' key.\n            **kwargs: Additional key/values to add to the JSON submitted.\n        \"\"\"\n        content = {\n            \"type\": login_type\n        }\n        for key in kwargs:\n            if kwargs[key]:\n                content[key] = kwargs[key]\n\n        return self._send(\"POST\", \"/login\", content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new room in the specified modules.", "response": "def create_room(\n                self,\n                alias=None,\n                name=None,\n                is_public=False,\n                invitees=None,\n                federate=None\n            ):\n        \"\"\"Perform /createRoom.\n\n        Args:\n            alias (str): Optional. The room alias name to set for this room.\n            name (str): Optional. Name for new room.\n            is_public (bool): Optional. The public/private visibility.\n            invitees (list<str>): Optional. The list of user IDs to invite.\n            federate (bool): Optional. \u0421an a room be federated.\n                Default to True.\n        \"\"\"\n        content = {\n            \"visibility\": \"public\" if is_public else \"private\"\n        }\n        if alias:\n            content[\"room_alias_name\"] = alias\n        if invitees:\n            content[\"invite\"] = invitees\n        if name:\n            content[\"name\"] = name\n        if federate is not None:\n            content[\"creation_content\"] = {'m.federate': federate}\n        return self._send(\"POST\", \"/createRoom\", content)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef join_room(self, room_id_or_alias):\n        if not room_id_or_alias:\n            raise MatrixError(\"No alias or room ID to join.\")\n\n        path = \"/join/%s\" % quote(room_id_or_alias)\n\n        return self._send(\"POST\", path)", "response": "Joins the room with the specified alias or room ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a generator that yields the events from the specified token.", "response": "def event_stream(self, from_token, timeout=30000):\n        \"\"\" Deprecated. Use sync instead.\n        Performs /events\n\n        Args:\n            from_token (str): The 'from' query parameter.\n            timeout (int): Optional. The 'timeout' query parameter.\n        \"\"\"\n        warnings.warn(\"event_stream is deprecated. Use sync instead.\",\n                      DeprecationWarning)\n        path = \"/events\"\n        return self._send(\n            \"GET\", path, query_params={\n                \"timeout\": timeout,\n                \"from\": from_token\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_state_event(self, room_id, event_type, content, state_key=\"\",\n                         timestamp=None):\n        \"\"\"Perform PUT /rooms/$room_id/state/$event_type\n\n        Args:\n            room_id(str): The room ID to send the state event in.\n            event_type(str): The state event type to send.\n            content(dict): The JSON content to send.\n            state_key(str): Optional. The state key for the event.\n            timestamp (int): Set origin_server_ts (For application services only)\n        \"\"\"\n        path = \"/rooms/%s/state/%s\" % (\n            quote(room_id), quote(event_type),\n        )\n        if state_key:\n            path += \"/%s\" % (quote(state_key))\n        params = {}\n        if timestamp:\n            params[\"ts\"] = timestamp\n        return self._send(\"PUT\", path, content, query_params=params)", "response": "Send a state event in the specified room."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_state_event(self, room_id, event_type):\n        return self._send(\"GET\", \"/rooms/{}/state/{}\".format(quote(room_id), event_type))", "response": "Perform a GET request to get the state of an event."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a message event to the specified room.", "response": "def send_message_event(self, room_id, event_type, content, txn_id=None,\n                           timestamp=None):\n        \"\"\"Perform PUT /rooms/$room_id/send/$event_type\n\n        Args:\n            room_id (str): The room ID to send the message event in.\n            event_type (str): The event type to send.\n            content (dict): The JSON content to send.\n            txn_id (int): Optional. The transaction ID to use.\n            timestamp (int): Set origin_server_ts (For application services only)\n        \"\"\"\n        if not txn_id:\n            txn_id = self._make_txn_id()\n\n        path = \"/rooms/%s/send/%s/%s\" % (\n            quote(room_id), quote(event_type), quote(str(txn_id)),\n        )\n        params = {}\n        if timestamp:\n            params[\"ts\"] = timestamp\n        return self._send(\"PUT\", path, content, query_params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef redact_event(self, room_id, event_id, reason=None, txn_id=None, timestamp=None):\n        if not txn_id:\n            txn_id = self._make_txn_id()\n\n        path = '/rooms/%s/redact/%s/%s' % (\n            room_id, event_id, txn_id\n        )\n        content = {}\n        if reason:\n            content['reason'] = reason\n        params = {}\n        if timestamp:\n            params[\"ts\"] = timestamp\n        return self._send(\"PUT\", path, content, query_params=params)", "response": "Redact a message in a room."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a m. location message to the specified room.", "response": "def send_location(self, room_id, geo_uri, name, thumb_url=None, thumb_info=None,\n                      timestamp=None):\n        \"\"\"Send m.location message event\n\n        Args:\n            room_id (str): The room ID to send the event in.\n            geo_uri (str): The geo uri representing the location.\n            name (str): Description for the location.\n            thumb_url (str): URL to the thumbnail of the location.\n            thumb_info (dict): Metadata about the thumbnail, type ImageInfo.\n            timestamp (int): Set origin_server_ts (For application services only)\n        \"\"\"\n        content_pack = {\n            \"geo_uri\": geo_uri,\n            \"msgtype\": \"m.location\",\n            \"body\": name,\n        }\n        if thumb_url:\n            content_pack[\"thumbnail_url\"] = thumb_url\n        if thumb_info:\n            content_pack[\"thumbnail_info\"] = thumb_info\n\n        return self.send_message_event(room_id, \"m.room.message\", content_pack,\n                                       timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform PUT / rooms/$room_id / send m. room. message", "response": "def send_message(self, room_id, text_content, msgtype=\"m.text\", timestamp=None):\n        \"\"\"Perform PUT /rooms/$room_id/send/m.room.message\n\n        Args:\n            room_id (str): The room ID to send the event in.\n            text_content (str): The m.text body to send.\n            timestamp (int): Set origin_server_ts (For application services only)\n        \"\"\"\n        return self.send_message_event(\n            room_id, \"m.room.message\",\n            self.get_text_body(text_content, msgtype),\n            timestamp=timestamp\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms PUT / rooms/$room_id / send m. room. message with m. emote body.", "response": "def send_emote(self, room_id, text_content, timestamp=None):\n        \"\"\"Perform PUT /rooms/$room_id/send/m.room.message with m.emote msgtype\n\n        Args:\n            room_id (str): The room ID to send the event in.\n            text_content (str): The m.emote body to send.\n            timestamp (int): Set origin_server_ts (For application services only)\n        \"\"\"\n        return self.send_message_event(\n            room_id, \"m.room.message\",\n            self.get_emote_body(text_content),\n            timestamp=timestamp\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming PUT / rooms. room. message with m. notice msgtype.", "response": "def send_notice(self, room_id, text_content, timestamp=None):\n        \"\"\"Perform PUT /rooms/$room_id/send/m.room.message with m.notice msgtype\n\n        Args:\n            room_id (str): The room ID to send the event in.\n            text_content (str): The m.notice body to send.\n            timestamp (int): Set origin_server_ts (For application services only)\n        \"\"\"\n        body = {\n            \"msgtype\": \"m.notice\",\n            \"body\": text_content\n        }\n        return self.send_message_event(room_id, \"m.room.message\", body,\n                                       timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming a GET request to get the messages from a room.", "response": "def get_room_messages(self, room_id, token, direction, limit=10, to=None):\n        \"\"\"Perform GET /rooms/{roomId}/messages.\n\n        Args:\n            room_id (str): The room's id.\n            token (str): The token to start returning events from.\n            direction (str):  The direction to return events from. One of: [\"b\", \"f\"].\n            limit (int): The maximum number of events to return.\n            to (str): The token to stop returning events at.\n        \"\"\"\n        query = {\n            \"roomId\": room_id,\n            \"from\": token,\n            \"dir\": direction,\n            \"limit\": limit,\n        }\n\n        if to:\n            query[\"to\"] = to\n\n        return self._send(\"GET\", \"/rooms/{}/messages\".format(quote(room_id)),\n                          query_params=query, api_path=\"/_matrix/client/r0\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms PUT / rooms/$room_id / state / m. room. name", "response": "def set_room_name(self, room_id, name, timestamp=None):\n        \"\"\"Perform PUT /rooms/$room_id/state/m.room.name\n        Args:\n            room_id (str): The room ID\n            name (str): The new room name\n            timestamp (int): Set origin_server_ts (For application services only)\n        \"\"\"\n        body = {\n            \"name\": name\n        }\n        return self.send_state_event(room_id, \"m.room.name\", body, timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_room_topic(self, room_id, topic, timestamp=None):\n        body = {\n            \"topic\": topic\n        }\n        return self.send_state_event(room_id, \"m.room.topic\", body, timestamp=timestamp)", "response": "Perform PUT / rooms/$room_id / state / m. room. topic\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the power levels of the user in a room.", "response": "def set_power_levels(self, room_id, content):\n        \"\"\"Perform PUT /rooms/$room_id/state/m.room.power_levels\n\n        Note that any power levels which are not explicitly specified\n        in the content arg are reset to default values.\n\n        Args:\n            room_id (str): The room ID\n            content (dict): The JSON content to send. See example content below.\n\n        Example::\n\n            api = MatrixHttpApi(\"http://example.com\", token=\"foobar\")\n            api.set_power_levels(\"!exampleroom:example.com\",\n                {\n                    \"ban\": 50, # defaults to 50 if unspecified\n                    \"events\": {\n                        \"m.room.name\": 100, # must have PL 100 to change room name\n                        \"m.room.power_levels\": 100 # must have PL 100 to change PLs\n                    },\n                    \"events_default\": 0, # defaults to 0\n                    \"invite\": 50, # defaults to 50\n                    \"kick\": 50, # defaults to 50\n                    \"redact\": 50, # defaults to 50\n                    \"state_default\": 50, # defaults to 50 if m.room.power_levels exists\n                    \"users\": {\n                        \"@someguy:example.com\": 100 # defaults to 0\n                    },\n                    \"users_default\": 0 # defaults to 0\n                }\n            )\n        \"\"\"\n        # Synapse returns M_UNKNOWN if body['events'] is omitted,\n        #  as of 2016-10-31\n        if \"events\" not in content:\n            content[\"events\"] = {}\n\n        return self.send_state_event(room_id, \"m.room.power_levels\", content)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef invite_user(self, room_id, user_id):\n        body = {\n            \"user_id\": user_id\n        }\n        return self._send(\"POST\", \"/rooms/\" + room_id + \"/invite\", body)", "response": "Invite a user to a room"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls set_membership with membership = leave for the user_id provided", "response": "def kick_user(self, room_id, user_id, reason=\"\"):\n        \"\"\"Calls set_membership with membership=\"leave\" for the user_id provided\n        \"\"\"\n        self.set_membership(room_id, user_id, \"leave\", reason)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming PUT / rooms/$room_id / state / m. room. member/$user_id", "response": "def set_membership(self, room_id, user_id, membership, reason=\"\", profile=None,\n                       timestamp=None):\n        \"\"\"Perform PUT /rooms/$room_id/state/m.room.member/$user_id\n\n        Args:\n            room_id (str): The room ID\n            user_id (str): The user ID\n            membership (str): New membership value\n            reason (str): The reason\n            timestamp (int): Set origin_server_ts (For application services only)\n        \"\"\"\n        if profile is None:\n            profile = {}\n        body = {\n            \"membership\": membership,\n            \"reason\": reason\n        }\n        if 'displayname' in profile:\n            body[\"displayname\"] = profile[\"displayname\"]\n        if 'avatar_url' in profile:\n            body[\"avatar_url\"] = profile[\"avatar_url\"]\n\n        return self.send_state_event(room_id, \"m.room.member\", body, state_key=user_id,\n                                     timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ban_user(self, room_id, user_id, reason=\"\"):\n        body = {\n            \"user_id\": user_id,\n            \"reason\": reason\n        }\n        return self._send(\"POST\", \"/rooms/\" + room_id + \"/ban\", body)", "response": "Ban a user from a room."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unban_user(self, room_id, user_id):\n        body = {\n            \"user_id\": user_id\n        }\n        return self._send(\"POST\", \"/rooms/\" + room_id + \"/unban\", body)", "response": "Unban a user from a room."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads raw media from provided mxc URL.", "response": "def media_download(self, mxcurl, allow_remote=True):\n        \"\"\"Download raw media from provided mxc URL.\n\n        Args:\n            mxcurl (str): mxc media URL.\n            allow_remote (bool): indicates to the server that it should not\n                attempt to fetch the media if it is deemed remote. Defaults\n                to true if not provided.\n        \"\"\"\n        query_params = {}\n        if not allow_remote:\n            query_params[\"allow_remote\"] = False\n        if mxcurl.startswith('mxc://'):\n            return self._send(\n                \"GET\", mxcurl[6:],\n                api_path=\"/_matrix/media/r0/download/\",\n                query_params=query_params,\n                return_json=False\n            )\n        else:\n            raise ValueError(\n                \"MXC URL '%s' did not begin with 'mxc://'\" % mxcurl\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_thumbnail(self, mxcurl, width, height, method='scale', allow_remote=True):\n        if method not in ['scale', 'crop']:\n            raise ValueError(\n                \"Unsupported thumb method '%s'\" % method\n            )\n        query_params = {\n                    \"width\": width,\n                    \"height\": height,\n                    \"method\": method\n                }\n        if not allow_remote:\n            query_params[\"allow_remote\"] = False\n        if mxcurl.startswith('mxc://'):\n            return self._send(\n                \"GET\", mxcurl[6:],\n                query_params=query_params,\n                api_path=\"/_matrix/media/r0/thumbnail/\",\n                return_json=False\n            )\n        else:\n            raise ValueError(\n                \"MXC URL '%s' did not begin with 'mxc://'\" % mxcurl\n            )", "response": "Download the raw media thumbnail from provided mxc URL."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_url_preview(self, url, ts=None):\n        params = {'url': url}\n        if ts:\n            params['ts'] = ts\n        return self._send(\n            \"GET\", \"\",\n            query_params=params,\n            api_path=\"/_matrix/media/r0/preview_url\"\n        )", "response": "Get preview for URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets room id from its alias.", "response": "def get_room_id(self, room_alias):\n        \"\"\"Get room id from its alias.\n\n        Args:\n            room_alias (str): The room alias name.\n\n        Returns:\n            Wanted room's id.\n        \"\"\"\n        content = self._send(\"GET\", \"/directory/room/{}\".format(quote(room_alias)))\n        return content.get(\"room_id\", None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the room alias.", "response": "def set_room_alias(self, room_id, room_alias):\n        \"\"\"Set alias to room id\n\n        Args:\n            room_id (str): The room id.\n            room_alias (str): The room wanted alias name.\n        \"\"\"\n        data = {\n            \"room_id\": room_id\n        }\n\n        return self._send(\"PUT\", \"/directory/room/{}\".format(quote(room_alias)),\n                          content=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the rule for users wishing to join the room.", "response": "def set_join_rule(self, room_id, join_rule):\n        \"\"\"Set the rule for users wishing to join the room.\n\n        Args:\n            room_id(str): The room to set the rules for.\n            join_rule(str): The chosen rule. One of: [\"public\", \"knock\",\n                \"invite\", \"private\"]\n        \"\"\"\n        content = {\n            \"join_rule\": join_rule\n        }\n        return self.send_state_event(room_id, \"m.room.join_rules\", content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the guest access policy of the room.", "response": "def set_guest_access(self, room_id, guest_access):\n        \"\"\"Set the guest access policy of the room.\n\n        Args:\n            room_id(str): The room to set the rules for.\n            guest_access(str): Wether guests can join. One of: [\"can_join\",\n                \"forbidden\"]\n        \"\"\"\n        content = {\n            \"guest_access\": guest_access\n        }\n        return self.send_state_event(room_id, \"m.room.guest_access\", content)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the display name of a device.", "response": "def update_device_info(self, device_id, display_name):\n        \"\"\"Update the display name of a device.\n\n        Args:\n            device_id (str): The device ID of the device to update.\n            display_name (str): New display name for the device.\n        \"\"\"\n        content = {\n            \"display_name\": display_name\n        }\n        return self._send(\"PUT\", \"/devices/%s\" % device_id, content=content)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_device(self, auth_body, device_id):\n        content = {\n            \"auth\": auth_body\n        }\n        return self._send(\"DELETE\", \"/devices/%s\" % device_id, content=content)", "response": "Deletes the given device and invalidates any access token associated with it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbulk deletion of devices.", "response": "def delete_devices(self, auth_body, devices):\n        \"\"\"Bulk deletion of devices.\n\n        NOTE: This endpoint uses the User-Interactive Authentication API.\n\n        Args:\n            auth_body (dict): Authentication params.\n            devices (list): List of device ID\"s to delete.\n        \"\"\"\n        content = {\n            \"auth\": auth_body,\n            \"devices\": devices\n        }\n        return self._send(\"POST\", \"/delete_devices\", content=content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npublishes end - to - end encryption keys for the given device.", "response": "def upload_keys(self, device_keys=None, one_time_keys=None):\n        \"\"\"Publishes end-to-end encryption keys for the device.\n\n        Said device must be the one used when logging in.\n\n        Args:\n            device_keys (dict): Optional. Identity keys for the device. The required\n                keys are:\n\n                | user_id (str): The ID of the user the device belongs to. Must match\n                    the user ID used when logging in.\n                | device_id (str): The ID of the device these keys belong to. Must match\n                    the device ID used when logging in.\n                | algorithms (list<str>): The encryption algorithms supported by this\n                    device.\n                | keys (dict): Public identity keys. Should be formatted as\n                    <algorithm:device_id>: <key>.\n                | signatures (dict): Signatures for the device key object. Should be\n                    formatted as <user_id>: {<algorithm:device_id>: <key>}\n\n            one_time_keys (dict): Optional. One-time public keys. Should be\n                formatted as <algorithm:key_id>: <key>, the key format being\n                determined by the algorithm.\n        \"\"\"\n        content = {}\n        if device_keys:\n            content[\"device_keys\"] = device_keys\n        if one_time_keys:\n            content[\"one_time_keys\"] = one_time_keys\n        return self._send(\"POST\", \"/keys/upload\", content=content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery HS for public keys by user and optionally device.", "response": "def query_keys(self, user_devices, timeout=None, token=None):\n        \"\"\"Query HS for public keys by user and optionally device.\n\n        Args:\n            user_devices (dict): The devices whose keys to download. Should be\n                formatted as <user_id>: [<device_ids>]. No device_ids indicates\n                all devices for the corresponding user.\n            timeout (int): Optional. The time (in milliseconds) to wait when\n                downloading keys from remote servers.\n            token (str): Optional. If the client is fetching keys as a result of\n                a device update received in a sync request, this should be the\n                'since' token of that sync request, or any later sync token.\n        \"\"\"\n        content = {\"device_keys\": user_devices}\n        if timeout:\n            content[\"timeout\"] = timeout\n        if token:\n            content[\"token\"] = token\n        return self._send(\"POST\", \"/keys/query\", content=content)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclaiming one - time keys for use in pre - key messages.", "response": "def claim_keys(self, key_request, timeout=None):\n        \"\"\"Claims one-time keys for use in pre-key messages.\n\n        Args:\n            key_request (dict): The keys to be claimed. Format should be\n                <user_id>: { <device_id>: <algorithm> }.\n            timeout (int): Optional. The time (in milliseconds) to wait when\n                downloading keys from remote servers.\n        \"\"\"\n        content = {\"one_time_keys\": key_request}\n        if timeout:\n            content[\"timeout\"] = timeout\n        return self._send(\"POST\", \"/keys/claim\", content=content)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef key_changes(self, from_token, to_token):\n        params = {\"from\": from_token, \"to\": to_token}\n        return self._send(\"GET\", \"/keys/changes\", query_params=params)", "response": "Gets a list of users who have updated their device identity keys."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a set of messages to a set of client devices.", "response": "def send_to_device(self, event_type, messages, txn_id=None):\n        \"\"\"Sends send-to-device events to a set of client devices.\n\n        Args:\n            event_type (str): The type of event to send.\n            messages (dict): The messages to send. Format should be\n                <user_id>: {<device_id>: <event_content>}.\n                The device ID may also be '*', meaning all known devices for the user.\n            txn_id (str): Optional. The transaction ID for this event, will be generated\n                automatically otherwise.\n        \"\"\"\n        txn_id = txn_id if txn_id else self._make_txn_id()\n        return self._send(\n            \"PUT\",\n            \"/sendToDevice/{}/{}\".format(event_type, txn_id),\n            content={\"messages\": messages}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a guest account on this HS.", "response": "def register_as_guest(self):\n        \"\"\" Register a guest account on this HS.\n        Note: HS must have guest registration enabled.\n        Returns:\n            str: Access Token\n        Raises:\n            MatrixRequestError\n        \"\"\"\n        response = self.api.register(auth_body=None, kind='guest')\n        return self._post_registration(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a new user with a password.", "response": "def register_with_password(self, username, password):\n        \"\"\" Register for a new account on this HS.\n\n        Args:\n            username (str): Account username\n            password (str): Account password\n\n        Returns:\n            str: Access Token\n\n        Raises:\n            MatrixRequestError\n        \"\"\"\n        response = self.api.register(\n                auth_body={\"type\": \"m.login.dummy\"},\n                kind='user',\n                username=username,\n                password=password,\n        )\n        return self._post_registration(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef login_with_password_no_sync(self, username, password):\n        warn(\"login_with_password_no_sync is deprecated. Use login with sync=False.\",\n             DeprecationWarning)\n        return self.login(username, password, sync=False)", "response": "Deprecated. Use login with sync = False."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef login_with_password(self, username, password, limit=10):\n        warn(\"login_with_password is deprecated. Use login with sync=True.\",\n             DeprecationWarning)\n        return self.login(username, password, limit, sync=True)", "response": "Deprecated. Use login with sync = True."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging-in to the homeserver.", "response": "def login(self, username, password, limit=10, sync=True, device_id=None):\n        \"\"\"Login to the homeserver.\n\n        Args:\n            username (str): Account username\n            password (str): Account password\n            limit (int): Deprecated. How many messages to return when syncing.\n                This will be replaced by a filter API in a later release.\n            sync (bool): Optional. Whether to initiate a /sync request after logging in.\n            device_id (str): Optional. ID of the client device. The server will\n                auto-generate a device_id if this is not specified.\n\n        Returns:\n            str: Access token\n\n        Raises:\n            MatrixRequestError\n        \"\"\"\n        response = self.api.login(\n            \"m.login.password\", user=username, password=password, device_id=device_id\n        )\n        self.user_id = response[\"user_id\"]\n        self.token = response[\"access_token\"]\n        self.hs = response[\"home_server\"]\n        self.api.token = self.token\n        self.device_id = response[\"device_id\"]\n\n        if self._encryption:\n            self.olm_device = OlmDevice(\n                self.api, self.user_id, self.device_id, **self.encryption_conf)\n            self.olm_device.upload_identity_keys()\n            self.olm_device.upload_one_time_keys()\n\n        if sync:\n            \"\"\" Limit Filter \"\"\"\n            self.sync_filter = '{ \"room\": { \"timeline\" : { \"limit\" : %i } } }' % limit\n            self._sync()\n        return self.token"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new room on the homeserver.", "response": "def create_room(self, alias=None, is_public=False, invitees=None):\n        \"\"\" Create a new room on the homeserver.\n\n        Args:\n            alias (str): The canonical_alias of the room.\n            is_public (bool):  The public/private visibility of the room.\n            invitees (str[]): A set of user ids to invite into the room.\n\n        Returns:\n            Room\n\n        Raises:\n            MatrixRequestError\n        \"\"\"\n        response = self.api.create_room(alias=alias,\n                                        is_public=is_public,\n                                        invitees=invitees)\n        return self._mkroom(response[\"room_id\"])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\njoining a room. Args: room_id_or_alias (str): Room ID or an alias. Returns: Room Raises: MatrixRequestError", "response": "def join_room(self, room_id_or_alias):\n        \"\"\" Join a room.\n\n        Args:\n            room_id_or_alias (str): Room ID or an alias.\n\n        Returns:\n            Room\n\n        Raises:\n            MatrixRequestError\n        \"\"\"\n        response = self.api.join_room(room_id_or_alias)\n        room_id = (\n            response[\"room_id\"] if \"room_id\" in response else room_id_or_alias\n        )\n        return self._mkroom(room_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_listener(self, callback, event_type=None):\n        listener_uid = uuid4()\n        # TODO: listeners should be stored in dict and accessed/deleted directly. Add\n        # convenience method such that MatrixClient.listeners.new(Listener(...)) performs\n        # MatrixClient.listeners[uuid4()] = Listener(...)\n        self.listeners.append(\n            {\n                'uid': listener_uid,\n                'callback': callback,\n                'event_type': event_type\n            }\n        )\n        return listener_uid", "response": "Add a listener that will send a callback when an event arrives."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_presence_listener(self, callback):\n        listener_uid = uuid4()\n        self.presence_listeners[listener_uid] = callback\n        return listener_uid", "response": "Add a presence listener that will send a callback when the client receives a new presence update."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef listen_forever(self, timeout_ms=30000, exception_handler=None,\n                       bad_sync_timeout=5):\n        \"\"\" Keep listening for events forever.\n\n        Args:\n            timeout_ms (int): How long to poll the Home Server for before\n               retrying.\n            exception_handler (func(exception)): Optional exception handler\n               function which can be used to handle exceptions in the caller\n               thread.\n            bad_sync_timeout (int): Base time to wait after an error before\n                retrying. Will be increased according to exponential backoff.\n        \"\"\"\n        _bad_sync_timeout = bad_sync_timeout\n        self.should_listen = True\n        while (self.should_listen):\n            try:\n                self._sync(timeout_ms)\n                _bad_sync_timeout = bad_sync_timeout\n            # TODO: we should also handle MatrixHttpLibError for retry in case no response\n            except MatrixRequestError as e:\n                logger.warning(\"A MatrixRequestError occured during sync.\")\n                if e.code >= 500:\n                    logger.warning(\"Problem occured serverside. Waiting %i seconds\",\n                                   bad_sync_timeout)\n                    sleep(bad_sync_timeout)\n                    _bad_sync_timeout = min(_bad_sync_timeout * 2,\n                                            self.bad_sync_timeout_limit)\n                elif exception_handler is not None:\n                    exception_handler(e)\n                else:\n                    raise\n            except Exception as e:\n                logger.exception(\"Exception thrown during sync\")\n                if exception_handler is not None:\n                    exception_handler(e)\n                else:\n                    raise", "response": "Keep listening for events forever."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a listener thread to listen for events in the background.", "response": "def start_listener_thread(self, timeout_ms=30000, exception_handler=None):\n        \"\"\" Start a listener thread to listen for events in the background.\n\n        Args:\n            timeout (int): How long to poll the Home Server for before\n               retrying.\n            exception_handler (func(exception)): Optional exception handler\n               function which can be used to handle exceptions in the caller\n               thread.\n        \"\"\"\n        try:\n            thread = Thread(target=self.listen_forever,\n                            args=(timeout_ms, exception_handler))\n            thread.daemon = True\n            self.sync_thread = thread\n            self.should_listen = True\n            thread.start()\n        except RuntimeError:\n            e = sys.exc_info()[0]\n            logger.error(\"Error: unable to start thread. %s\", str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop_listener_thread(self):\n        if self.sync_thread:\n            self.should_listen = False\n            self.sync_thread.join()\n            self.sync_thread = None", "response": "Stop listener thread running in the background"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upload(self, content, content_type, filename=None):\n        try:\n            response = self.api.media_upload(content, content_type, filename)\n            if \"content_uri\" in response:\n                return response[\"content_uri\"]\n            else:\n                raise MatrixUnexpectedResponse(\n                    \"The upload was successful, but content_uri wasn't found.\"\n                )\n        except MatrixRequestError as e:\n            raise MatrixRequestError(\n                code=e.code,\n                content=\"Upload failed: %s\" % e\n            )", "response": "Uploads the content to the homeserver and recieve a MXC url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_room_alias(self, room_alias):\n        try:\n            self.api.remove_room_alias(room_alias)\n            return True\n        except MatrixRequestError:\n            return False", "response": "Removes an alias from a room."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upload_identity_keys(self):\n        device_keys = {\n            'user_id': self.user_id,\n            'device_id': self.device_id,\n            'algorithms': self._algorithms,\n            'keys': {'{}:{}'.format(alg, self.device_id): key\n                     for alg, key in self.identity_keys.items()}\n        }\n        self.sign_json(device_keys)\n        ret = self.api.upload_keys(device_keys=device_keys)\n        self.one_time_keys_manager.server_counts = ret['one_time_key_counts']\n        logger.info('Uploaded identity keys.')", "response": "Uploads this device s identity keys to HS."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upload_one_time_keys(self, force_update=False):\n        if force_update or not self.one_time_keys_manager.server_counts:\n            counts = self.api.upload_keys()['one_time_key_counts']\n            self.one_time_keys_manager.server_counts = counts\n\n        signed_keys_to_upload = self.one_time_keys_manager.signed_curve25519_to_upload\n        unsigned_keys_to_upload = self.one_time_keys_manager.curve25519_to_upload\n\n        self.olm_account.generate_one_time_keys(signed_keys_to_upload +\n                                                unsigned_keys_to_upload)\n\n        one_time_keys = {}\n        keys = self.olm_account.one_time_keys['curve25519']\n        for i, key_id in enumerate(keys):\n            if i < signed_keys_to_upload:\n                key = self.sign_json({'key': keys[key_id]})\n                key_type = 'signed_curve25519'\n            else:\n                key = keys[key_id]\n                key_type = 'curve25519'\n            one_time_keys['{}:{}'.format(key_type, key_id)] = key\n\n        ret = self.api.upload_keys(one_time_keys=one_time_keys)\n        self.one_time_keys_manager.server_counts = ret['one_time_key_counts']\n        self.olm_account.mark_keys_as_published()\n\n        keys_uploaded = {}\n        if unsigned_keys_to_upload:\n            keys_uploaded['curve25519'] = unsigned_keys_to_upload\n        if signed_keys_to_upload:\n            keys_uploaded['signed_curve25519'] = signed_keys_to_upload\n        logger.info('Uploaded new one-time keys: %s.', keys_uploaded)\n        return keys_uploaded", "response": "Uploads new one - time keys to the HS."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_one_time_key_counts(self, counts):\n        self.one_time_keys_manager.server_counts = counts\n        if self.one_time_keys_manager.should_upload():\n            logger.info('Uploading new one-time keys.')\n            self.upload_one_time_keys()", "response": "Update data on one - time keys count and upload new ones if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sign_json(self, json):\n        signatures = json.pop('signatures', {})\n        unsigned = json.pop('unsigned', None)\n\n        signature_base64 = self.olm_account.sign(encode_canonical_json(json))\n\n        key_id = 'ed25519:{}'.format(self.device_id)\n        signatures.setdefault(self.user_id, {})[key_id] = signature_base64\n\n        json['signatures'] = signatures\n        if unsigned:\n            json['unsigned'] = unsigned\n\n        return json", "response": "Signs a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_json(self, json, user_key, user_id, device_id):\n        try:\n            signatures = json.pop('signatures')\n        except KeyError:\n            return False\n\n        key_id = 'ed25519:{}'.format(device_id)\n        try:\n            signature_base64 = signatures[user_id][key_id]\n        except KeyError:\n            json['signatures'] = signatures\n            return False\n\n        unsigned = json.pop('unsigned', None)\n\n        try:\n            olm.ed25519_verify(user_key, encode_canonical_json(json), signature_base64)\n            success = True\n        except olm.utility.OlmVerifyError:\n            success = False\n\n        json['signatures'] = signatures\n        if unsigned:\n            json['unsigned'] = unsigned\n\n        return success", "response": "Verifies a signed key object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the display name of the user.", "response": "def get_display_name(self, room=None):\n        \"\"\"Get this user's display name.\n\n        Args:\n            room (Room): Optional. When specified, return the display name of the user\n                in this room.\n\n        Returns:\n            The display name. Defaults to the user ID if not set.\n        \"\"\"\n        if room:\n            try:\n                return room.members_displaynames[self.user_id]\n            except KeyError:\n                return self.user_id\n        if not self.displayname:\n            self.displayname = self.api.get_display_name(self.user_id)\n        return self.displayname or self.user_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_display_name(self, display_name):\n        self.displayname = display_name\n        return self.api.set_display_name(self.user_id, display_name)", "response": "Set this users display name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_encrypted_request(self, session, endpoint, message):\n        host = urlsplit(endpoint).hostname\n\n        if self.protocol == 'credssp' and len(message) > self.SIXTEN_KB:\n            content_type = 'multipart/x-multi-encrypted'\n            encrypted_message = b''\n            message_chunks = [message[i:i+self.SIXTEN_KB] for i in range(0, len(message), self.SIXTEN_KB)]\n            for message_chunk in message_chunks:\n                encrypted_chunk = self._encrypt_message(message_chunk, host)\n                encrypted_message += encrypted_chunk\n        else:\n            content_type = 'multipart/encrypted'\n            encrypted_message = self._encrypt_message(message, host)\n        encrypted_message += self.MIME_BOUNDARY + b\"--\\r\\n\"\n\n        request = requests.Request('POST', endpoint, data=encrypted_message)\n        prepared_request = session.prepare_request(request)\n        prepared_request.headers['Content-Length'] = str(len(prepared_request.body))\n        prepared_request.headers['Content-Type'] = '{0};protocol=\"{1}\";boundary=\"Encrypted Boundary\"'\\\n            .format(content_type, self.protocol_string.decode())\n\n        return prepared_request", "response": "Prepares a request that has an encrypted message and correct headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_encrypted_response(self, response):\n        content_type = response.headers['Content-Type']\n        if 'protocol=\"{0}\"'.format(self.protocol_string.decode()) in content_type:\n            host = urlsplit(response.request.url).hostname\n            msg = self._decrypt_response(response, host)\n        else:\n            msg = response.text\n\n        return msg", "response": "Takes in the encrypted response from the server and decrypts it\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a Shell on the remote machine.", "response": "def open_shell(self, i_stream='stdin', o_stream='stdout stderr',\n                   working_directory=None, env_vars=None, noprofile=False,\n                   codepage=437, lifetime=None, idle_timeout=None):\n        \"\"\"\n        Create a Shell on the destination host\n        @param string i_stream: Which input stream to open. Leave this alone\n         unless you know what you're doing (default: stdin)\n        @param string o_stream: Which output stream to open. Leave this alone\n         unless you know what you're doing (default: stdout stderr)\n        @param string working_directory: the directory to create the shell in\n        @param dict env_vars: environment variables to set for the shell. For\n         instance: {'PATH': '%PATH%;c:/Program Files (x86)/Git/bin/', 'CYGWIN':\n          'nontsec codepage:utf8'}\n        @returns The ShellId from the SOAP response. This is our open shell\n         instance on the remote machine.\n        @rtype string\n        \"\"\"\n        req = {'env:Envelope': self._get_soap_header(\n            resource_uri='http://schemas.microsoft.com/wbem/wsman/1/windows/shell/cmd',  # NOQA\n            action='http://schemas.xmlsoap.org/ws/2004/09/transfer/Create')}\n        header = req['env:Envelope']['env:Header']\n        header['w:OptionSet'] = {\n            'w:Option': [\n                {\n                    '@Name': 'WINRS_NOPROFILE',\n                    '#text': str(noprofile).upper()  # TODO remove str call\n                },\n                {\n                    '@Name': 'WINRS_CODEPAGE',\n                    '#text': str(codepage)  # TODO remove str call\n                }\n            ]\n        }\n\n        shell = req['env:Envelope'].setdefault(\n            'env:Body', {}).setdefault('rsp:Shell', {})\n        shell['rsp:InputStreams'] = i_stream\n        shell['rsp:OutputStreams'] = o_stream\n\n        if working_directory:\n            # TODO ensure that rsp:WorkingDirectory should be nested within rsp:Shell  # NOQA\n            shell['rsp:WorkingDirectory'] = working_directory\n            # TODO check Lifetime param: http://msdn.microsoft.com/en-us/library/cc251546(v=PROT.13).aspx  # NOQA\n            #if lifetime:\n            #    shell['rsp:Lifetime'] = iso8601_duration.sec_to_dur(lifetime)\n        # TODO make it so the input is given in milliseconds and converted to xs:duration  # NOQA\n        if idle_timeout:\n            shell['rsp:IdleTimeOut'] = idle_timeout\n        if env_vars:\n            env = shell.setdefault('rsp:Environment', {})\n            for key, value in env_vars.items():\n                env['rsp:Variable'] = {'@Name': key, '#text': value}\n\n        res = self.send_message(xmltodict.unparse(req))\n\n        #res = xmltodict.parse(res)\n        #return res['s:Envelope']['s:Body']['x:ResourceCreated']['a:ReferenceParameters']['w:SelectorSet']['w:Selector']['#text']\n        root = ET.fromstring(res)\n        return next(\n            node for node in root.findall('.//*')\n            if node.get('Name') == 'ShellId').text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close_shell(self, shell_id):\n        message_id = uuid.uuid4()\n        req = {'env:Envelope': self._get_soap_header(\n            resource_uri='http://schemas.microsoft.com/wbem/wsman/1/windows/shell/cmd',  # NOQA\n            action='http://schemas.xmlsoap.org/ws/2004/09/transfer/Delete',\n            shell_id=shell_id,\n            message_id=message_id)}\n\n        # SOAP message requires empty env:Body\n        req['env:Envelope'].setdefault('env:Body', {})\n\n        res = self.send_message(xmltodict.unparse(req))\n        root = ET.fromstring(res)\n        relates_to = next(\n            node for node in root.findall('.//*')\n            if node.tag.endswith('RelatesTo')).text\n        # TODO change assert into user-friendly exception\n        assert uuid.UUID(relates_to.replace('uuid:', '')) == message_id", "response": "Close the shell with the given shell id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_command(\n            self, shell_id, command, arguments=(), console_mode_stdin=True,\n            skip_cmd_shell=False):\n        \"\"\"\n        Run a command on a machine with an open shell\n        @param string shell_id: The shell id on the remote machine.\n         See #open_shell\n        @param string command: The command to run on the remote machine\n        @param iterable of string arguments: An array of arguments for this\n         command\n        @param bool console_mode_stdin: (default: True)\n        @param bool skip_cmd_shell: (default: False)\n        @return: The CommandId from the SOAP response.\n         This is the ID we need to query in order to get output.\n        @rtype string\n        \"\"\"\n        req = {'env:Envelope': self._get_soap_header(\n            resource_uri='http://schemas.microsoft.com/wbem/wsman/1/windows/shell/cmd',  # NOQA\n            action='http://schemas.microsoft.com/wbem/wsman/1/windows/shell/Command',  # NOQA\n            shell_id=shell_id)}\n        header = req['env:Envelope']['env:Header']\n        header['w:OptionSet'] = {\n            'w:Option': [\n                {\n                    '@Name': 'WINRS_CONSOLEMODE_STDIN',\n                    '#text': str(console_mode_stdin).upper()\n                },\n                {\n                    '@Name': 'WINRS_SKIP_CMD_SHELL',\n                    '#text': str(skip_cmd_shell).upper()\n                }\n            ]\n        }\n        cmd_line = req['env:Envelope'].setdefault(\n            'env:Body', {}).setdefault('rsp:CommandLine', {})\n        cmd_line['rsp:Command'] = {'#text': command}\n        if arguments:\n            unicode_args = [a if isinstance(a, text_type) else a.decode('utf-8') for a in arguments]\n            cmd_line['rsp:Arguments'] = u' '.join(unicode_args)\n\n        res = self.send_message(xmltodict.unparse(req))\n        root = ET.fromstring(res)\n        command_id = next(\n            node for node in root.findall('.//*')\n            if node.tag.endswith('CommandId')).text\n        return command_id", "response": "Runs a command on a remote machine with an open shell."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_command_output(self, shell_id, command_id):\n        stdout_buffer, stderr_buffer = [], []\n        command_done = False\n        while not command_done:\n            try:\n                stdout, stderr, return_code, command_done = \\\n                    self._raw_get_command_output(shell_id, command_id)\n                stdout_buffer.append(stdout)\n                stderr_buffer.append(stderr)\n            except WinRMOperationTimeoutError as e:\n                # this is an expected error when waiting for a long-running process, just silently retry\n                pass\n        return b''.join(stdout_buffer), b''.join(stderr_buffer), return_code", "response": "Get the output of the given shell and command."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _clean_error_msg(self, msg):\n        # TODO prepare unit test, beautify code\n        # if the msg does not start with this, return it as is\n        if msg.startswith(b\"#< CLIXML\\r\\n\"):\n            # for proper xml, we need to remove the CLIXML part\n            # (the first line)\n            msg_xml = msg[11:]\n            try:\n                # remove the namespaces from the xml for easier processing\n                msg_xml = self._strip_namespace(msg_xml)\n                root = ET.fromstring(msg_xml)\n                # the S node is the error message, find all S nodes\n                nodes = root.findall(\"./S\")\n                new_msg = \"\"\n                for s in nodes:\n                    # append error msg string to result, also\n                    # the hex chars represent CRLF so we replace with newline\n                    new_msg += s.text.replace(\"_x000D__x000A_\", \"\\n\")\n            except Exception as e:\n                # if any of the above fails, the msg was not true xml\n                # print a warning and return the orignal string\n                # TODO do not print, raise user defined error instead\n                print(\"Warning: there was a problem converting the Powershell\"\n                      \" error message: %s\" % (e))\n            else:\n                # if new_msg was populated, that's our error message\n                # otherwise the original error message will be used\n                if len(new_msg):\n                    # remove leading and trailing whitespace while we are here\n                    return new_msg.strip().encode('utf-8')\n\n        # either failed to decode CLIXML or there was nothing to decode\n        # just return the original message\n        return msg", "response": "converts a Powershell CLIXML message to a more human readable string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _strip_namespace(self, xml):\n        p = re.compile(b\"xmlns=*[\\\"\\\"][^\\\"\\\"]*[\\\"\\\"]\")\n        allmatches = p.finditer(xml)\n        for match in allmatches:\n            xml = xml.replace(match.group(), b\"\")\n        return xml", "response": "strips any namespaces from an xml string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pass_control(self, primary_address, secondary_address):\n        return self.visalib.gpib_pass_control(self.session, primary_address, secondary_address)", "response": "Tells the GPIB device to become controller in charge ( CIC."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns installed backends. Backends are installed python packages named pyvisa-<something> where <something> is the name of the backend. :rtype: list", "response": "def list_backends():\n    \"\"\"Return installed backends.\n\n    Backends are installed python packages named pyvisa-<something> where <something>\n    is the name of the backend.\n\n    :rtype: list\n    \"\"\"\n    return ['ni'] + [name for (loader, name, ispkg) in pkgutil.iter_modules()\n                     if name.startswith('pyvisa-') and not name.endswith('-script')]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the WRAPPER_CLASS for a given backend.", "response": "def get_wrapper_class(backend_name):\n    \"\"\"Return the WRAPPER_CLASS for a given backend.\n\n    :rtype: pyvisa.highlevel.VisaLibraryBase\n    \"\"\"\n    try:\n        return _WRAPPERS[backend_name]\n    except KeyError:\n        if backend_name == 'ni':\n            from .ctwrapper import NIVisaLibrary\n            _WRAPPERS['ni'] = NIVisaLibrary\n            return NIVisaLibrary\n\n    try:\n        pkg = __import__('pyvisa-' + backend_name)\n        _WRAPPERS[backend_name] = cls = pkg.WRAPPER_CLASS\n        return cls\n    except ImportError:\n        raise ValueError('Wrapper not found: No package named pyvisa-%s' % backend_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_default_wrapper():\n\n    from .ctwrapper import NIVisaLibrary\n    ni_binary_found = bool(NIVisaLibrary.get_library_paths())\n    if ni_binary_found:\n        logger.debug('The NI implementation available')\n        return 'ni'\n    else:\n        logger.debug('Did not find NI binary')\n\n    try:\n        get_wrapper_class('py')  # check for pyvisa-py availability\n        logger.debug('pyvisa-py is available.')\n        return 'py'\n    except ValueError:\n        logger.debug('Did not find pyvisa-py package')\n    raise ValueError('Could not locate a VISA implementation. Install either the NI binary or pyvisa-py.')", "response": "Return an available default VISA wrapper as a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the last status in a session.", "response": "def get_last_status_in_session(self, session):\n        \"\"\"Last status in session.\n\n        Helper function to be called by resources properties.\n        \"\"\"\n        try:\n            return self._last_status_in_session[session]\n        except KeyError:\n            raise errors.Error('The session %r does not seem to be valid as it does not have any last status' % session)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ignore_warning(self, session, *warnings_constants):\n        self._ignore_warning_in_session[session].update(warnings_constants)\n        yield\n        self._ignore_warning_in_session[session].difference_update(warnings_constants)", "response": "A context dependent context for ignoring warnings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls a handler for an event.", "response": "def install_visa_handler(self, session, event_type, handler, user_handle=None):\n        \"\"\"Installs handlers for event callbacks.\n\n        :param session: Unique logical identifier to a session.\n        :param event_type: Logical event identifier.\n        :param handler: Interpreted as a valid reference to a handler to be installed by a client application.\n        :param user_handle: A value specified by an application that can be used for identifying handlers\n                            uniquely for an event type.\n        :returns: user handle (a ctypes object)\n        \"\"\"\n        try:\n            new_handler = self.install_handler(session, event_type, handler, user_handle)\n        except TypeError as e:\n            raise errors.VisaTypeError(str(e))\n\n        self.handlers[session].append(new_handler + (event_type,))\n        return new_handler[1]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uninstall_visa_handler(self, session, event_type, handler, user_handle=None):\n        for ndx, element in enumerate(self.handlers[session]):\n            if element[0] is handler and element[1] is user_handle and element[4] == event_type:\n                del self.handlers[session][ndx]\n                break\n        else:\n            raise errors.UnknownHandler(event_type, handler, user_handle)\n        self.uninstall_handler(session, event_type,  element[2], user_handle)", "response": "Uninstalls a handler for an event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uninstall_all_visa_handlers(self, session):\n\n        if session is not None:\n            self.__uninstall_all_handlers_helper(session)\n        else:\n            for session in list(self.handlers):\n                self.__uninstall_all_handlers_helper(session)", "response": "Uninstalls all previously installed handlers for a particular session."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_memory(self, session, space, offset, data, width, extended=False):\n        if width == 8:\n            return self.out_8(session, space, offset, data, extended)\n        elif width == 16:\n            return self.out_16(session, space, offset, data, extended)\n        elif width == 32:\n            return self.out_32(session, space, offset, data, extended)\n        elif width == 64:\n            return self.out_64(session, space, offset, data, extended)\n\n        raise ValueError('%s is not a valid size. Valid values are 8, 16, 32, or 64' % width)", "response": "Write in an 8 - bit 16 - bit 32 - bit 64 - bit value to the specified memory space and offset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_in(self, session, space, offset, length, width, extended=False):\n        if width == 8:\n            return self.move_in_8(session, space, offset, length, extended)\n        elif width == 16:\n            return self.move_in_16(session, space, offset, length, extended)\n        elif width == 32:\n            return self.move_in_32(session, space, offset, length, extended)\n        elif width == 64:\n            return self.move_in_64(session, space, offset, length, extended)\n\n        raise ValueError('%s is not a valid size. Valid values are 8, 16, 32 or 64' % width)", "response": "Moves a block of data from the specified address space and offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef peek(self, session, address, width):\n\n        if width == 8:\n            return self.peek_8(session, address)\n        elif width == 16:\n            return self.peek_16(session, address)\n        elif width == 32:\n            return self.peek_32(session, address)\n        elif width == 64:\n            return self.peek_64(session, address)\n\n        raise ValueError('%s is not a valid size. Valid values are 8, 16, 32 or 64' % width)", "response": "Reads an 8 16 32 or 64 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef poke(self, session, address, width, data):\n\n        if width == 8:\n            return self.poke_8(session, address, data)\n        elif width == 16:\n            return self.poke_16(session, address, data)\n        elif width == 32:\n            return self.poke_32(session, address, data)\n        elif width == 64:\n            return self.poke_64(session, address, data)\n\n        raise ValueError('%s is not a valid size. Valid values are 8, 16, 32, or 64' % width)", "response": "Writes an 8 16 32 or 64 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps the specified memory space into the process s address space.", "response": "def map_address(self, session, map_space, map_base, map_size,\n                    access=False, suggested=None):\n        \"\"\"Maps the specified memory space into the process's address space.\n\n        Corresponds to viMapAddress function of the VISA library.\n\n        :param session: Unique logical identifier to a session.\n        :param map_space: Specifies the address space to map. (Constants.*SPACE*)\n        :param map_base: Offset (in bytes) of the memory to be mapped.\n        :param map_size: Amount of memory to map (in bytes).\n        :param access:\n        :param suggested: If not Constants.VI_NULL (0), the operating system attempts to map the memory to the address\n                          specified in suggested. There is no guarantee, however, that the memory will be mapped to\n                          that address. This operation may map the memory into an address region different from\n                          suggested.\n\n        :return: address in your process space where the memory was mapped, return value of the library call.\n        :rtype: address, :class:`pyvisa.constants.StatusCode`\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move(self, session, source_space, source_offset, source_width, destination_space,\n             destination_offset, destination_width, length):\n        \"\"\"Moves a block of data.\n\n        Corresponds to viMove function of the VISA library.\n\n        :param session: Unique logical identifier to a session.\n        :param source_space: Specifies the address space of the source.\n        :param source_offset: Offset of the starting address or register from which to read.\n        :param source_width: Specifies the data width of the source.\n        :param destination_space: Specifies the address space of the destination.\n        :param destination_offset: Offset of the starting address or register to which to write.\n        :param destination_width: Specifies the data width of the destination.\n        :param length: Number of elements to transfer, where the data width of the elements to transfer\n                       is identical to the source data width.\n        :return: return value of the library call.\n        :rtype: :class:`pyvisa.constants.StatusCode`\n        \"\"\"\n        raise NotImplementedError", "response": "Moves a block of data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving an 8 - bit block of data from local memory to the specified address space and offset.", "response": "def move_out_8(self, session, space, offset, length, data, extended=False):\n        \"\"\"Moves an 8-bit block of data from local memory to the specified address space and offset.\n\n        Corresponds to viMoveOut8* functions of the VISA library.\n\n        :param session: Unique logical identifier to a session.\n        :param space: Specifies the address space. (Constants.*SPACE*)\n        :param offset: Offset (in bytes) of the address or register from which to read.\n        :param length: Number of elements to transfer, where the data width of the elements to transfer\n                       is identical to the source data width.\n        :param data: Data to write to bus.\n        :param extended: Use 64 bits offset independent of the platform.\n        :return: return value of the library call.\n        :rtype: :class:`pyvisa.constants.StatusCode`\n\n        Corresponds to viMoveOut8 function of the VISA library.\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen a session to the specified resource.", "response": "def open(self, session, resource_name,\n             access_mode=constants.AccessModes.no_lock, open_timeout=constants.VI_TMO_IMMEDIATE):\n        \"\"\"Opens a session to the specified resource.\n\n        Corresponds to viOpen function of the VISA library.\n\n        :param session: Resource Manager session (should always be a session returned from open_default_resource_manager()).\n        :param resource_name: Unique symbolic name of a resource.\n        :param access_mode: Specifies the mode by which the resource is to be accessed.\n        :type access_mode: :class:`pyvisa.constants.AccessModes`\n        :param open_timeout: Specifies the maximum time period (in milliseconds) that this operation waits\n                             before returning an error.\n        :return: Unique logical identifier reference to a session, return value of the library call.\n        :rtype: session, :class:`pyvisa.constants.StatusCode`\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_resource_extended(self, session, resource_name):\n        try:\n            parsed = rname.parse_resource_name(resource_name)\n\n            return (ResourceInfo(parsed.interface_type_const,\n                                 parsed.board,\n                                 parsed.resource_class,\n                                 str(parsed), None),\n                    constants.StatusCode.success)\n        except ValueError:\n            return 0, constants.StatusCode.error_invalid_resource_name", "response": "Parse a resource string to get extended interface information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclosing the resource manager session.", "response": "def close(self):\n        \"\"\"Close the resource manager session.\n        \"\"\"\n        try:\n            logger.debug('Closing ResourceManager (session: %s)', self.session)\n            # Cleanly close all resources when closing the manager.\n            for resource in self._created_resources:\n                resource.close()\n            self.visalib.close(self.session)\n            self.session = None\n            self.visalib.resource_manager = None\n        except errors.InvalidSession:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary mapping resource names to resource extended information of all connected devices matching query.", "response": "def list_resources_info(self, query='?*::INSTR'):\n        \"\"\"Returns a dictionary mapping resource names to resource extended\n        information of all connected devices matching query.\n\n        For details of the VISA Resource Regular Expression syntax used in query,\n        refer to list_resources().\n\n        :param query: a VISA Resource Regular Expression used to match devices.\n        :return: Mapping of resource name to ResourceInfo\n        :rtype: dict[str, :class:`pyvisa.highlevel.ResourceInfo`]\n        \"\"\"\n\n        return dict((resource, self.resource_info(resource))\n                    for resource in self.list_resources(query))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the extended or resource information of a particular resource.", "response": "def resource_info(self, resource_name, extended=True):\n        \"\"\"Get the (extended) information of a particular resource.\n\n        :param resource_name: Unique symbolic name of a resource.\n\n        :rtype: :class:`pyvisa.highlevel.ResourceInfo`\n        \"\"\"\n\n        if extended:\n            ret, err = self.visalib.parse_resource_extended(self.session, resource_name)\n        else:\n            ret, err = self.visalib.parse_resource(self.session, resource_name)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen the specified resource without wrapping into a class .", "response": "def open_bare_resource(self, resource_name,\n                          access_mode=constants.AccessModes.no_lock,\n                          open_timeout=constants.VI_TMO_IMMEDIATE):\n        \"\"\"Open the specified resource without wrapping into a class\n\n        :param resource_name: name or alias of the resource to open.\n        :param access_mode: access mode.\n        :type access_mode: :class:`pyvisa.constants.AccessModes`\n        :param open_timeout: time out to open.\n\n        :return: Unique logical identifier reference to a session.\n        \"\"\"\n        return self.visalib.open(self.session, resource_name, access_mode, open_timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens a resource and return an instrument for the resource name.", "response": "def open_resource(self, resource_name,\n                      access_mode=constants.AccessModes.no_lock,\n                      open_timeout=constants.VI_TMO_IMMEDIATE,\n                      resource_pyclass=None,\n                      **kwargs):\n        \"\"\"Return an instrument for the resource name.\n\n        :param resource_name: name or alias of the resource to open.\n        :param access_mode: access mode.\n        :type access_mode: :class:`pyvisa.constants.AccessModes`\n        :param open_timeout: time out to open.\n        :param resource_pyclass: resource python class to use to instantiate the Resource.\n                                 Defaults to None: select based on the resource name.\n        :param kwargs: keyword arguments to be used to change instrument attributes\n                       after construction.\n\n        :rtype: :class:`pyvisa.resources.Resource`\n        \"\"\"\n\n        if resource_pyclass is None:\n            info = self.resource_info(resource_name, extended=True)\n\n            try:\n                resource_pyclass = self._resource_classes[(info.interface_type, info.resource_class)]\n            except KeyError:\n                resource_pyclass = self._resource_classes[(constants.InterfaceType.unknown, '')]\n                logger.warning('There is no class defined for %r. Using Resource', (info.interface_type, info.resource_class))\n\n        res = resource_pyclass(self, resource_name)\n        for key in kwargs.keys():\n            try:\n                getattr(res, key)\n                present = True\n            except AttributeError:\n                present = False\n            except errors.InvalidSession:\n                present = True\n\n            if not present:\n                raise ValueError('%r is not a valid attribute for type %s' % (key, res.__class__.__name__))\n\n        res.open(access_mode, open_timeout)\n\n        self._created_resources.add(res)\n\n        for key, value in kwargs.items():\n            setattr(res, key, value)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a subclass for a given interface type and resource class.", "response": "def register_subclass(cls):\n    \"\"\"Register a subclass for a given interface type and resource class.\n    \"\"\"\n\n    key = cls.interface_type, cls.resource_class\n\n    if key in _SUBCLASSES:\n        raise ValueError('Class already registered for %s and %s' % key)\n\n    _SUBCLASSES[(cls.interface_type, cls.resource_class)] = cls\n\n    _INTERFACE_TYPES.add(cls.interface_type)\n    _RESOURCE_CLASSES[cls.interface_type].add(cls.resource_class)\n\n    if cls.is_rc_optional:\n        if cls.interface_type in _DEFAULT_RC:\n            raise ValueError('Default already specified for %s' %\n                             cls.interface_type)\n        _DEFAULT_RC[cls.interface_type] = cls.resource_class\n\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_rn_class(interface_type, resource_parts, resource_class,\n                   is_rc_optional=True):\n    \"\"\"Builds a resource name class by mixing a named tuple and ResourceName.\n\n    It also registers the class.\n\n    The field names are changed to lower case and the spaces replaced\n    by underscores ('_').\n\n    :param interface_type: the interface type\n    :type: interface_type: str\n    :param resource_parts: each of the parts of the resource name indicating\n                           name and default value.\n                           Use None for mandatory fields.\n    :type resource_parts: tuple[(str, str)]\n    :param resource_class: the resource class\n    :type resource_class: str\n    :param is_rc_optional: indicates if the resource class part is optional\n    :type is_rc_optional: boolean.\n    \"\"\"\n\n    interface_type = interface_type.upper()\n    resource_class = resource_class.upper()\n\n    syntax = interface_type\n    fmt = interface_type\n    fields = []\n\n    # Contains the resource parts but using python friendly names\n    # (all lower case and replacing spaces by underscores)\n    p_resource_parts = []\n\n    kwdoc = []\n\n    # Assemble the syntax and format string based on the resource parts\n    for ndx, (name, default_value) in enumerate(resource_parts):\n        pname = name.lower().replace(' ', '_')\n        fields.append(pname)\n        p_resource_parts.append((pname, default_value))\n\n        sep = '::' if ndx else ''\n\n        fmt += sep + '{0.%s}' % pname\n\n        if default_value is None:\n            syntax += sep + name\n        else:\n            syntax += '[' + sep + name + ']'\n\n        kwdoc.append('- %s (%s)' % (pname, 'required' if default_value is None\n                                    else default_value))\n\n    fmt += '::' + resource_class\n\n    if not is_rc_optional:\n        syntax += '::' + resource_class\n    else:\n        syntax += '[' + '::' + resource_class + ']'\n\n    class _C(namedtuple('Internal', ' '.join(fields)), ResourceName):\n        \"\"\"%s %s\"\n\n        Can be created with the following keyword only arguments:\n            %s\n\n        Format :\n            %s\n        \"\"\" % (resource_class, interface_type, '    \\n'.join(kwdoc), syntax)\n\n        def __new__(cls, **kwargs):\n            new_kwargs = dict(p_resource_parts, **kwargs)\n\n            for key, value in new_kwargs.items():\n                if value is None:\n                    raise ValueError(key + ' is a required parameter')\n\n            return super(_C, cls).__new__(cls, **new_kwargs)\n\n        @classmethod\n        def from_parts(cls, *parts):\n\n            if len(parts) < sum(1 for _, v in p_resource_parts\n                                if v is not None):\n                raise ValueError('not enough parts')\n            elif len(parts) > len(p_resource_parts):\n                raise ValueError('too many parts')\n\n            (k, default), rp = p_resource_parts[0], p_resource_parts[1:]\n\n            # The first part (just after the interface_type) is the only\n            # optional part which can be and empty and therefore the\n            # default value should be used.\n            p, pending = parts[0], parts[1:]\n            kwargs = {k: default if p == '' else p}\n\n            # The rest of the parts are consumed when mandatory elements are required.\n            while len(pending) < len(rp):\n                (k, default), rp = rp[0], rp[1:]\n                if default is None:\n                    if not parts:\n                        raise ValueError(k + ' part is mandatory')\n                    p, pending = pending[0], pending[1:]\n                    if not p:\n                        raise ValueError(k + ' part is mandatory')\n                    kwargs[k] = p\n                else:\n                    kwargs[k] = default\n\n            # When the length of the pending provided and resource parts\n            # are equal, we just consume everything.\n            kwargs.update((k, p) for (k, v), p in zip(rp, pending))\n\n            return cls(**kwargs)\n\n    _C.interface_type = interface_type\n    _C.resource_class = resource_class\n    _C.is_rc_optional = is_rc_optional\n    _C._canonical_fmt = fmt\n    _C._visa_syntax = syntax\n\n    _C.__name__ = str(interface_type + resource_class.title())\n\n    return register_subclass(_C)", "response": "Builds a resource name class by mixing a named tuple and ResourceName."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter(resources, query):\n\n    if '{' in query:\n        query, _ = query.split('{')\n        logger.warning('optional part of the query expression not supported. '\n                       'See filter2')\n\n    try:\n        query = query.replace('?', '.')\n        matcher = re.compile(query, re.IGNORECASE)\n    except re.error:\n        raise errors.VisaIOError(constants.VI_ERROR_INV_EXPR)\n\n    return tuple(res for res in resources if matcher.match(res))", "response": "Filter a list of resources according to a query expression."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter a list of resources according to a query expression.", "response": "def filter2(resources, query, open_resource):\n    \"\"\"Filter a list of resources according to a query expression.\n\n    It accepts the optional part of the expression.\n\n    .. warning: This function is experimental and unsafe as it uses eval,\n                It also might require to open the resource.\n\n    :param resources: iterable of resources.\n    :param query: query expression.\n    :param open_resource: function to open the resource.\n    \"\"\"\n\n    if '{' in query:\n        try:\n            query, optional = query.split('{')\n            optional, _ = optional.split('}')\n        except ValueError:\n            raise errors.VisaIOError(constants.VI_ERROR_INV_EXPR)\n    else:\n        optional = None\n\n    filtered = filter(resources, query)\n\n    if not optional:\n        return filtered\n\n    optional = optional.replace('&&', 'and').replace('||', 'or').replace('!', 'not ')\n    optional = optional.replace('VI_', 'res.VI_')\n\n    class AttrGetter():\n\n        def __init__(self, resource_name):\n            self.resource_name = resource_name\n            self.parsed = parse_resource_name(resource_name)\n            self.resource = None\n\n        def __getattr__(self, item):\n            if item == 'VI_ATTR_INTF_NUM':\n                   return int(self.parsed.board)\n            elif item == 'VI_ATTR_MANF_ID':\n                   return self.parsed.manufacturer_id\n            elif item == 'VI_ATTR_MODEL_CODE':\n                   return self.parsed.model_code\n            elif item == 'VI_ATTR_USB_SERIAL_NUM':\n                   return self.parsed.serial_number\n            elif item == 'VI_ATTR_USB_INTFC_NUM':\n                   return int(self.parsed.board)\n            elif item == 'VI_ATTR_TCPIP_ADDR':\n                   return self.parsed.host_address\n            elif item == 'VI_ATTR_TCPIP_DEVICE_NAME':\n                   return self.parsed.lan_device_name\n            elif item == 'VI_ATTR_TCPIP_PORT':\n                   return int(self.parsed.port)\n            elif item == 'VI_ATTR_INTF_NUM':\n                   return int(self.parsed.board)\n            elif item == 'VI_ATTR_GPIB_PRIMARY_ADDR':\n                   return int(self.parsed.primary_address)\n            elif item == 'VI_ATTR_GPIB_SECONDARY_ADDR':\n                   return int(self.parsed.secondary_address)\n            elif item == 'VI_ATTR_PXI_CHASSIS':\n                return self.parsed.chassis_number\n            elif item == 'VI_ATTR_MAINFRAME_LA':\n                return self.parsed.vxi_logical_address\n\n            if self.resource is None:\n                self.resource = open_resource(self.resource_name)\n\n            return self.resource.get_visa_attribute(item)\n\n    @contextlib.contextmanager\n    def open_close(resource_name):\n        getter = AttrGetter(resource_name)\n        yield getter\n        if getter.resource is not None:\n            getter.resource.close()\n\n    selected = []\n    for rn in filtered:\n        with open_close(rn) as getter:\n            if eval(optional, None, dict(res=getter)):\n                selected.append(rn)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bad_syntax(cls, syntax, resource_name, ex=None):\n\n        if ex:\n            msg = \"The syntax is '%s' (%s).\" % (syntax, ex)\n        else:\n            msg = \"The syntax is '%s'.\" % syntax\n\n        msg = \"Could not parse '%s'. %s\" % (resource_name, msg)\n\n        return cls(msg)", "response": "Exception used when the resource name cannot be parsed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rc_notfound(cls, interface_type, resource_name=None):\n\n        msg = \"Resource class for %s not provided and default not found.\" % interface_type\n\n        if resource_name:\n            msg = \"Could not parse '%s'. %s\" % (resource_name, msg)\n\n        return cls(msg)", "response": "Exception used when no resource class is provided and no default is found."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a resource name and return a ResourceName object.", "response": "def from_string(cls, resource_name):\n        \"\"\"Parse a resource name and return a ResourceName\n\n        :type resource_name: str\n        :rtype: ResourceName\n\n        :raises InvalidResourceName: if the resource name is invalid.\n        \"\"\"\n        # TODO Remote VISA\n\n        uname = resource_name.upper()\n\n        for interface_type in _INTERFACE_TYPES:\n\n            # Loop through all known interface types until we found one\n            # that matches the beginning of the resource name\n            if not uname.startswith(interface_type):\n                continue\n\n            if len(resource_name) == len(interface_type):\n                parts = ()\n            else:\n                parts = resource_name[len(interface_type):].split('::')\n\n            # Try to match the last part of the resource name to\n            # one of the known resource classes for the given interface type.\n            # If not possible, use the default resource class\n            # for the given interface type.\n            if parts and parts[-1] in _RESOURCE_CLASSES[interface_type]:\n                parts, resource_class = parts[:-1], parts[-1]\n            else:\n                try:\n                    resource_class = _DEFAULT_RC[interface_type]\n                except KeyError:\n                    raise InvalidResourceName.rc_notfound(interface_type,\n                                                          resource_name)\n\n            # Look for the subclass\n            try:\n                subclass = _SUBCLASSES[(interface_type, resource_class)]\n            except KeyError:\n                raise InvalidResourceName.subclass_notfound(\n                    (interface_type, resource_class), resource_name)\n\n            # And create the object\n            try:\n                rn = subclass.from_parts(*parts)\n                rn.user = resource_name\n                return rn\n            except ValueError as ex:\n                raise InvalidResourceName.bad_syntax(subclass._visa_syntax,\n                                                     resource_name, ex)\n\n        raise InvalidResourceName('Could not parse %s: unknown interface type'\n                                  % resource_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_user_handle_type(library, user_handle):\n\n    # Actually, it's not necessary to change ViHndlr *globally*.  However,\n    # I don't want to break symmetry too much with all the other VPP43\n    # routines.\n    global ViHndlr\n\n    if user_handle is None:\n        user_handle_p = c_void_p\n    else:\n        user_handle_p = POINTER(type(user_handle))\n\n    ViHndlr = FUNCTYPE(ViStatus, ViSession, ViEventType, ViEvent, user_handle_p)\n    library.viInstallHandler.argtypes = [ViSession, ViEventType, ViHndlr, user_handle_p]\n    library.viUninstallHandler.argtypes = [ViSession, ViEventType, ViHndlr, user_handle_p]", "response": "Set the type of the user handle to install and uninstall handler signature."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the signatures of the most visa functions in the given library.", "response": "def set_signatures(library, errcheck=None):\n    \"\"\"Set the signatures of most visa functions in the library.\n\n    All instrumentation related functions are specified here.\n\n    :param library: the visa library wrapped by ctypes.\n    :type library: ctypes.WinDLL or ctypes.CDLL\n    :param errcheck: error checking callable used for visa functions that return\n                     ViStatus.\n                     It should be take three areguments (result, func, arguments).\n                     See errcheck in ctypes.\n    \"\"\"\n\n    # Somehow hasattr(library, '_functions') segfaults in cygwin (See #131)\n    if '_functions' not in dir(library):\n        library._functions = []\n        library._functions_failed = []\n\n    def _applier(restype, errcheck_):\n        def _internal(function_name, argtypes, required=False):\n            try:\n                set_signature(library, function_name, argtypes, restype, errcheck_)\n                # noinspection PyProtectedMember\n                library._functions.append(function_name)\n            except AttributeError:\n                library._functions_failed.append(function_name)\n                if required:\n                    raise\n        return _internal\n\n    # Visa functions with ViStatus return code\n    apply = _applier(ViStatus, errcheck)\n    apply(\"viAssertIntrSignal\", [ViSession, ViInt16, ViUInt32])\n    apply(\"viAssertTrigger\", [ViSession, ViUInt16])\n    apply(\"viAssertUtilSignal\", [ViSession, ViUInt16])\n    apply(\"viBufRead\", [ViSession, ViPBuf, ViUInt32, ViPUInt32])\n    apply(\"viBufWrite\", [ViSession, ViBuf, ViUInt32, ViPUInt32])\n    apply(\"viClear\", [ViSession])\n    apply(\"viClose\", [ViObject])\n    apply(\"viDisableEvent\", [ViSession, ViEventType, ViUInt16])\n    apply(\"viDiscardEvents\", [ViSession, ViEventType, ViUInt16])\n    apply(\"viEnableEvent\", [ViSession, ViEventType, ViUInt16, ViEventFilter])\n    apply(\"viFindNext\", [ViSession, ViAChar])\n    apply(\"viFindRsrc\", [ViSession, ViString, ViPFindList, ViPUInt32, ViAChar])\n    apply(\"viFlush\", [ViSession, ViUInt16])\n    apply(\"viGetAttribute\", [ViObject, ViAttr, c_void_p])\n    apply(\"viGpibCommand\", [ViSession, ViBuf, ViUInt32, ViPUInt32])\n    apply(\"viGpibControlATN\", [ViSession, ViUInt16])\n    apply(\"viGpibControlREN\", [ViSession, ViUInt16])\n    apply(\"viGpibPassControl\", [ViSession, ViUInt16, ViUInt16])\n    apply(\"viGpibSendIFC\", [ViSession])\n\n    apply(\"viIn8\", [ViSession, ViUInt16, ViBusAddress, ViPUInt8])\n    apply(\"viIn16\", [ViSession, ViUInt16, ViBusAddress, ViPUInt16])\n    apply(\"viIn32\", [ViSession, ViUInt16, ViBusAddress, ViPUInt32])\n    apply(\"viIn64\", [ViSession, ViUInt16, ViBusAddress, ViPUInt64])\n\n    apply(\"viIn8Ex\", [ViSession, ViUInt16, ViBusAddress64, ViPUInt8])\n    apply(\"viIn16Ex\", [ViSession, ViUInt16, ViBusAddress64, ViPUInt16])\n    apply(\"viIn32Ex\", [ViSession, ViUInt16, ViBusAddress64, ViPUInt32])\n    apply(\"viIn64Ex\", [ViSession, ViUInt16, ViBusAddress64, ViPUInt64])\n\n    apply(\"viInstallHandler\", [ViSession, ViEventType, ViHndlr, ViAddr])\n    apply(\"viLock\", [ViSession, ViAccessMode, ViUInt32, ViKeyId, ViAChar])\n    apply(\"viMapAddress\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViBoolean, ViAddr, ViPAddr])\n    apply(\"viMapTrigger\", [ViSession, ViInt16, ViInt16, ViUInt16])\n    apply(\"viMemAlloc\", [ViSession, ViBusSize, ViPBusAddress])\n    apply(\"viMemFree\", [ViSession, ViBusAddress])\n    apply(\"viMove\", [ViSession, ViUInt16, ViBusAddress, ViUInt16,\n                     ViUInt16, ViBusAddress, ViUInt16, ViBusSize])\n    apply(\"viMoveAsync\", [ViSession, ViUInt16, ViBusAddress, ViUInt16,\n                          ViUInt16, ViBusAddress, ViUInt16, ViBusSize,\n                          ViPJobId])\n\n    apply(\"viMoveIn8\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViAUInt8])\n    apply(\"viMoveIn16\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViAUInt16])\n    apply(\"viMoveIn32\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViAUInt32])\n    apply(\"viMoveIn64\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViAUInt64])\n\n    apply(\"viMoveIn8Ex\", [ViSession, ViUInt16, ViBusAddress64, ViBusSize, ViAUInt8])\n    apply(\"viMoveIn16Ex\", [ViSession, ViUInt16, ViBusAddress64, ViBusSize, ViAUInt16])\n    apply(\"viMoveIn32Ex\", [ViSession, ViUInt16, ViBusAddress64, ViBusSize, ViAUInt32])\n    apply(\"viMoveIn64Ex\", [ViSession, ViUInt16, ViBusAddress64, ViBusSize, ViAUInt64])\n\n    apply(\"viMoveOut8\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViAUInt8])\n    apply(\"viMoveOut16\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViAUInt16])\n    apply(\"viMoveOut32\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViAUInt32])\n    apply(\"viMoveOut64\", [ViSession, ViUInt16, ViBusAddress, ViBusSize, ViAUInt64])\n\n    apply(\"viMoveOut8Ex\", [ViSession, ViUInt16, ViBusAddress64, ViBusSize, ViAUInt8])\n    apply(\"viMoveOut16Ex\", [ViSession, ViUInt16, ViBusAddress64, ViBusSize, ViAUInt16])\n    apply(\"viMoveOut32Ex\", [ViSession, ViUInt16, ViBusAddress64, ViBusSize, ViAUInt32])\n    apply(\"viMoveOut64Ex\", [ViSession, ViUInt16, ViBusAddress64, ViBusSize, ViAUInt64])\n\n    apply(\"viOpen\", [ViSession, ViRsrc, ViAccessMode, ViUInt32, ViPSession], required=True)\n\n    apply(\"viOpenDefaultRM\", [ViPSession], required=True)\n\n    apply(\"viOut8\", [ViSession, ViUInt16, ViBusAddress, ViUInt8])\n    apply(\"viOut16\", [ViSession, ViUInt16, ViBusAddress, ViUInt16])\n    apply(\"viOut32\", [ViSession, ViUInt16, ViBusAddress, ViUInt32])\n    apply(\"viOut64\", [ViSession, ViUInt16, ViBusAddress, ViUInt64])\n\n    apply(\"viOut8Ex\", [ViSession, ViUInt16, ViBusAddress64, ViUInt8])\n    apply(\"viOut16Ex\", [ViSession, ViUInt16, ViBusAddress64, ViUInt16])\n    apply(\"viOut32Ex\", [ViSession, ViUInt16, ViBusAddress64, ViUInt32])\n    apply(\"viOut64Ex\", [ViSession, ViUInt16, ViBusAddress64, ViUInt64])\n\n    apply(\"viParseRsrc\", [ViSession, ViRsrc, ViPUInt16, ViPUInt16])\n    apply(\"viParseRsrcEx\", [ViSession, ViRsrc, ViPUInt16, ViPUInt16, ViAChar, ViAChar, ViAChar])\n\n    apply(\"viRead\", [ViSession, ViPBuf, ViUInt32, ViPUInt32])\n    apply(\"viReadAsync\", [ViSession, ViPBuf, ViUInt32, ViPJobId])\n    apply(\"viReadSTB\", [ViSession, ViPUInt16])\n    apply(\"viReadToFile\", [ViSession, ViString, ViUInt32, ViPUInt32])\n\n    apply(\"viSetAttribute\", [ViObject, ViAttr, ViAttrState])\n    apply(\"viSetBuf\", [ViSession, ViUInt16, ViUInt32])\n\n    apply(\"viStatusDesc\", [ViObject, ViStatus, ViAChar])\n    apply(\"viTerminate\", [ViSession, ViUInt16, ViJobId])\n    apply(\"viUninstallHandler\", [ViSession, ViEventType, ViHndlr, ViAddr])\n    apply(\"viUnlock\", [ViSession])\n    apply(\"viUnmapAddress\", [ViSession])\n    apply(\"viUnmapTrigger\", [ViSession, ViInt16, ViInt16])\n    apply(\"viUsbControlIn\", [ViSession, ViInt16, ViInt16, ViUInt16,\n                             ViUInt16, ViUInt16, ViPBuf, ViPUInt16])\n    apply(\"viUsbControlOut\", [ViSession, ViInt16, ViInt16, ViUInt16,\n                              ViUInt16, ViUInt16, ViPBuf])\n\n    # The following \"V\" routines are *not* implemented in PyVISA, and will\n    # never be: viVPrintf, viVQueryf, viVScanf, viVSPrintf, viVSScanf\n\n    apply(\"viVxiCommandQuery\", [ViSession, ViUInt16, ViUInt32, ViPUInt32])\n    apply(\"viWaitOnEvent\", [ViSession, ViEventType, ViUInt32, ViPEventType, ViPEvent])\n    apply(\"viWrite\", [ViSession, ViBuf, ViUInt32, ViPUInt32])\n    apply(\"viWriteAsync\", [ViSession, ViBuf, ViUInt32, ViPJobId])\n    apply(\"viWriteFromFile\", [ViSession, ViString, ViUInt32, ViPUInt32])\n\n    # Functions that return void.\n    apply = _applier(None, None)\n    apply(\"viPeek8\", [ViSession, ViAddr, ViPUInt8])\n    apply(\"viPeek16\", [ViSession, ViAddr, ViPUInt16])\n    apply(\"viPeek32\", [ViSession, ViAddr, ViPUInt32])\n    apply(\"viPeek64\", [ViSession, ViAddr, ViPUInt64])\n\n    apply(\"viPoke8\", [ViSession, ViAddr, ViUInt8])\n    apply(\"viPoke16\", [ViSession, ViAddr, ViUInt16])\n    apply(\"viPoke32\", [ViSession, ViAddr, ViUInt32])\n    apply(\"viPoke64\", [ViSession, ViAddr, ViUInt64])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_signature(library, function_name, argtypes, restype, errcheck):\n\n    func = getattr(library, function_name)\n    func.argtypes = argtypes\n    if restype is not None:\n        func.restype = restype\n    if errcheck is not None:\n        func.errcheck = errcheck", "response": "Set the signature of a single function in a library."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nasserting the specified interrupt or signal.", "response": "def assert_interrupt_signal(library, session, mode, status_id):\n    \"\"\"Asserts the specified interrupt or signal.\n\n    Corresponds to viAssertIntrSignal function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param mode: How to assert the interrupt. (Constants.ASSERT*)\n    :param status_id: This is the status value to be presented during an interrupt acknowledge cycle.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viAssertIntrSignal(session, mode, status_id)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef buffer_read(library, session, count):\n    buffer = create_string_buffer(count)\n    return_count = ViUInt32()\n    ret = library.viBufRead(session, buffer, count, byref(return_count))\n    return buffer.raw[:return_count.value], ret", "response": "Reads data from device or interface through the use of a formatted I/O read buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef buffer_write(library, session, data):\n\n    return_count = ViUInt32()\n    # [ViSession, ViBuf, ViUInt32, ViPUInt32]\n    ret = library.viBufWrite(session, data, len(data), byref(return_count))\n    return return_count.value, ret", "response": "Writes data to a formatted I/O write buffer synchronously."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisabling notification of the specified event type via the specified mechanism.", "response": "def disable_event(library, session, event_type, mechanism):\n    \"\"\"Disables notification of the specified event type(s) via the specified mechanism(s).\n\n    Corresponds to viDisableEvent function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param event_type: Logical event identifier.\n    :param mechanism: Specifies event handling mechanisms to be disabled.\n                      (Constants.VI_QUEUE, .VI_HNDLR, .VI_SUSPEND_HNDLR, .VI_ALL_MECH)\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viDisableEvent(session, event_type, mechanism)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndiscard event occurrences for specified event types and mechanisms in a session.", "response": "def discard_events(library, session, event_type, mechanism):\n    \"\"\"Discards event occurrences for specified event types and mechanisms in a session.\n\n    Corresponds to viDiscardEvents function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param event_type: Logical event identifier.\n    :param mechanism: Specifies event handling mechanisms to be dicarded.\n                      (Constants.VI_QUEUE, .VI_HNDLR, .VI_SUSPEND_HNDLR, .VI_ALL_MECH)\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viDiscardEvents(session, event_type, mechanism)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enable_event(library, session, event_type, mechanism, context=None):\n    if context is None:\n        context = constants.VI_NULL\n    elif context != constants.VI_NULL:\n        warnings.warn('In enable_event, context will be set VI_NULL.')\n        context = constants.VI_NULL  # according to spec VPP-4.3, section 3.7.3.1\n    return library.viEnableEvent(session, event_type, mechanism, context)", "response": "Enable event occurrences for specified event types and mechanisms in a session."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_next(library, find_list):\n    instrument_description = create_string_buffer(constants.VI_FIND_BUFLEN)\n    ret = library.viFindNext(find_list, instrument_description)\n    return buffer_to_text(instrument_description), ret", "response": "Returns the next resource from the list of resources found during a previous call to find_resources."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying a VISA system to locate the resources associated with a specified interface.", "response": "def find_resources(library, session, query):\n    \"\"\"Queries a VISA system to locate the resources associated with a specified interface.\n\n    Corresponds to viFindRsrc function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session (unused, just to uniform signatures).\n    :param query: A regular expression followed by an optional logical expression. Use '?*' for all.\n    :return: find_list, return_counter, instrument_description, return value of the library call.\n    :rtype: ViFindList, int, unicode (Py2) or str (Py3), :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    find_list = ViFindList()\n    return_counter = ViUInt32()\n    instrument_description = create_string_buffer(constants.VI_FIND_BUFLEN)\n\n    # [ViSession, ViString, ViPFindList, ViPUInt32, ViAChar]\n    # ViString converts from (str, unicode, bytes) to bytes\n    ret = library.viFindRsrc(session, query,\n                             byref(find_list), byref(return_counter),\n                             instrument_description)\n    return find_list, return_counter.value, buffer_to_text(instrument_description), ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the state of an attribute.", "response": "def get_attribute(library, session, attribute):\n    \"\"\"Retrieves the state of an attribute.\n\n    Corresponds to viGetAttribute function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session, event, or find list.\n    :param attribute: Resource attribute for which the state query is made (see Attributes.*)\n    :return: The state of the queried attribute for a specified resource, return value of the library call.\n    :rtype: unicode (Py2) or str (Py3), list or other type, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n\n    # FixMe: How to deal with ViBuf?\n    attr = attributes.AttributesByID[attribute]\n    datatype = getattr(types, attr.visa_type)\n    if datatype == ViString:\n        attribute_state = create_string_buffer(256)\n        ret = library.viGetAttribute(session, attribute, attribute_state)\n        return buffer_to_text(attribute_state), ret\n    elif datatype == ViAUInt8:\n        length = get_attribute(library, session, constants.VI_ATTR_USB_RECV_INTR_SIZE)\n        attribute_state = (ViUInt8 * length)()\n        ret = library.viGetAttribute(session, attribute, byref(attribute_state))\n        return list(attribute_state), ret\n    else:\n        attribute_state = datatype()\n        ret = library.viGetAttribute(session, attribute, byref(attribute_state))\n        return attribute_state.value, ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites GPIB command bytes on the bus.", "response": "def gpib_command(library, session, data):\n    \"\"\"Write GPIB command bytes on the bus.\n\n    Corresponds to viGpibCommand function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param data: data tor write.\n    :type data: bytes\n    :return: Number of written bytes, return value of the library call.\n    :rtype: int, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return_count = ViUInt32()\n\n    # [ViSession, ViBuf, ViUInt32, ViPUInt32]\n    ret = library.viGpibCommand(session, data, len(data), byref(return_count))\n    return return_count.value, ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gpib_pass_control(library, session, primary_address, secondary_address):\n    return library.viGpibPassControl(session, primary_address, secondary_address)", "response": "This function is used to tell the GPIB device at the specified address to become controller in charge ( CIC."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading in an 8 - bit 16 - bit 32 - bit or 64 - bit value from the specified memory space and offset.", "response": "def read_memory(library, session, space, offset, width, extended=False):\n    \"\"\"Reads in an 8-bit, 16-bit, 32-bit, or 64-bit value from the specified memory space and offset.\n\n    Corresponds to viIn* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param width: Number of bits to read.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: Data read from memory, return value of the library call.\n    :rtype: int, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    if width == 8:\n        return in_8(library, session, space, offset, extended)\n    elif width == 16:\n        return in_16(library, session, space, offset, extended)\n    elif width == 32:\n        return in_32(library, session, space, offset, extended)\n    elif width == 64:\n        return in_64(library, session, space, offset, extended)\n\n    raise ValueError('%s is not a valid size. Valid values are 8, 16, 32 or 64' % width)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading in an 8 - bit value from the specified memory space and offset.", "response": "def in_8(library, session, space, offset, extended=False):\n    \"\"\"Reads in an 8-bit value from the specified memory space and offset.\n\n    Corresponds to viIn8* function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: Data read from memory, return value of the library call.\n    :rtype: int, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    value_8 = ViUInt8()\n    if extended:\n        ret = library.viIn8Ex(session, space, offset, byref(value_8))\n    else:\n        ret = library.viIn8(session, space, offset, byref(value_8))\n    return value_8.value, ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread in an 16 - bit value from the specified memory space and offset.", "response": "def in_16(library, session, space, offset, extended=False):\n    \"\"\"Reads in an 16-bit value from the specified memory space and offset.\n\n    Corresponds to viIn16* function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: Data read from memory, return value of the library call.\n    :rtype: int, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    value_16 = ViUInt16()\n    if extended:\n        ret = library.viIn16Ex(session, space, offset, byref(value_16))\n    else:\n        ret = library.viIn16(session, space, offset, byref(value_16))\n    return value_16.value, ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef in_32(library, session, space, offset, extended=False):\n    value_32 = ViUInt32()\n    if extended:\n        ret = library.viIn32Ex(session, space, offset, byref(value_32))\n    else:\n        ret = library.viIn32(session, space, offset, byref(value_32))\n    return value_32.value, ret", "response": "Reads in an 32 - bit value from the specified memory space and offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef in_64(library, session, space, offset, extended=False):\n    value_64 = ViUInt64()\n    if extended:\n        ret = library.viIn64Ex(session, space, offset, byref(value_64))\n    else:\n        ret = library.viIn64(session, space, offset, byref(value_64))\n    return value_64.value, ret", "response": "Reads in an 64 - bit value from the specified memory space and offset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling handlers for event callbacks.", "response": "def install_handler(library, session, event_type, handler, user_handle):\n    \"\"\"Installs handlers for event callbacks.\n\n    Corresponds to viInstallHandler function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param event_type: Logical event identifier.\n    :param handler: Interpreted as a valid reference to a handler to be installed by a client application.\n    :param user_handle: A value specified by an application that can be used for identifying handlers\n                        uniquely for an event type. Can be a regular python object (int, float, str, list\n                        of floats or ints) or a ctypes object.\n    :returns: a handler descriptor which consists of three elements:\n             - handler (a python callable)\n             - user handle (a ctypes object)\n             - ctypes handler (ctypes object wrapping handler)\n             and return value of the library call.\n    :rtype: int, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    if user_handle is None:\n        converted_user_handle = None\n    else:\n        if isinstance(user_handle, int):\n            converted_user_handle = c_long(user_handle)\n        elif isinstance(user_handle, float):\n            converted_user_handle = c_double(user_handle)\n        elif isinstance(user_handle, str):\n            converted_user_handle = create_string_buffer(user_handle)\n        elif isinstance(user_handle, list):\n            for element in user_handle:\n                if not isinstance(element, int):\n                    converted_user_handle = \\\n                        (c_double * len(user_handle))(tuple(user_handle))\n                    break\n            else:\n                converted_user_handle = \\\n                    (c_long * len(user_handle))(*tuple(user_handle))\n        else:\n            try:\n                # check if it is already a ctypes\n                byref(user_handle)\n                converted_user_handle = user_handle\n            except TypeError:\n                raise TypeError(\"Type not allowed as user handle: %s\" % type(user_handle))\n\n    set_user_handle_type(library, converted_user_handle)\n    converted_handler = ViHndlr(handler)\n    if user_handle is None:\n        ret = library.viInstallHandler(session, event_type, converted_handler, None)\n    else:\n        ret = library.viInstallHandler(session, event_type, converted_handler,\n                                       byref(converted_user_handle))\n\n    return handler, converted_user_handle, converted_handler, ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lock(library, session, lock_type, timeout, requested_key=None):\n    if lock_type == constants.AccessModes.exclusive_lock:\n        requested_key = None\n        access_key = None\n    else:\n        access_key = create_string_buffer(256)\n    ret = library.viLock(session, lock_type, timeout, requested_key, access_key)\n    if access_key is None:\n        return None, ret\n    else:\n        return access_key.value, ret", "response": "Establishes an access mode to the specified resources."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_address(library, session, map_space, map_base, map_size,\n                access=False, suggested=None):\n    \"\"\"Maps the specified memory space into the process's address space.\n\n    Corresponds to viMapAddress function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param map_space: Specifies the address space to map. (Constants.*SPACE*)\n    :param map_base: Offset (in bytes) of the memory to be mapped.\n    :param map_size: Amount of memory to map (in bytes).\n    :param access:\n    :param suggested: If not Constants.NULL (0), the operating system attempts to map the memory to the address\n                      specified in suggested. There is no guarantee, however, that the memory will be mapped to\n                      that address. This operation may map the memory into an address region different from\n                      suggested.\n\n    :return: address in your process space where the memory was mapped, return value of the library call.\n    :rtype: address, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    if access is False:\n        access = constants.VI_FALSE\n    elif access != constants.VI_FALSE:\n        warnings.warn('In enable_event, context will be set VI_NULL.')\n        access = constants.VI_FALSE\n    address = ViAddr()\n    ret = library.viMapAddress(session, map_space, map_base, map_size, access,\n                               suggested, byref(address))\n    return address, ret", "response": "Maps the specified memory space into the process s address space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmapping the specified trigger source line to the specified destination line.", "response": "def map_trigger(library, session, trigger_source, trigger_destination, mode):\n    \"\"\"Map the specified trigger source line to the specified destination line.\n\n    Corresponds to viMapTrigger function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param trigger_source: Source line from which to map. (Constants.TRIG*)\n    :param trigger_destination: Destination line to which to map. (Constants.TRIG*)\n    :param mode:\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viMapTrigger(session, trigger_source, trigger_destination, mode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef memory_allocation(library, session, size, extended=False):\n    offset = ViBusAddress()\n    if extended:\n        ret = library.viMemAllocEx(session, size, byref(offset))\n    else:\n        ret = library.viMemAlloc(session, size, byref(offset))\n    return offset, ret", "response": "Allocates memory from a resource s memory region."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef memory_free(library, session, offset, extended=False):\n    if extended:\n        return library.viMemFreeEx(session, offset)\n    else:\n        return library.viMemFree(session, offset)", "response": "Frees memory previously allocated using the memory_allocation function of the VISA library."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef move(library, session, source_space, source_offset, source_width, destination_space,\n         destination_offset, destination_width, length):\n    \"\"\"Moves a block of data.\n\n    Corresponds to viMove function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param source_space: Specifies the address space of the source.\n    :param source_offset: Offset of the starting address or register from which to read.\n    :param source_width: Specifies the data width of the source.\n    :param destination_space: Specifies the address space of the destination.\n    :param destination_offset: Offset of the starting address or register to which to write.\n    :param destination_width: Specifies the data width of the destination.\n    :param length: Number of elements to transfer, where the data width of the elements to transfer\n                   is identical to the source data width.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viMove(session, source_space, source_offset, source_width,\n                          destination_space, destination_offset,\n                          destination_width, length)", "response": "Moves a block of data from one location to another."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_asynchronously(library, session, source_space, source_offset, source_width,\n                        destination_space, destination_offset,\n                        destination_width, length):\n    \"\"\"Moves a block of data asynchronously.\n\n    Corresponds to viMoveAsync function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param source_space: Specifies the address space of the source.\n    :param source_offset: Offset of the starting address or register from which to read.\n    :param source_width: Specifies the data width of the source.\n    :param destination_space: Specifies the address space of the destination.\n    :param destination_offset: Offset of the starting address or register to which to write.\n    :param destination_width: Specifies the data width of the destination.\n    :param length: Number of elements to transfer, where the data width of the elements to transfer\n                   is identical to the source data width.\n    :return: Job identifier of this asynchronous move operation, return value of the library call.\n    :rtype: jobid, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    job_id = ViJobId()\n    ret = library.viMoveAsync(session, source_space, source_offset, source_width,\n                              destination_space, destination_offset,\n                              destination_width, length, byref(job_id))\n    return job_id, ret", "response": "This function is used to move a block of data asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_in_8(library, session, space, offset, length, extended=False):\n    buffer_8 = (ViUInt8 * length)()\n    if extended:\n        ret = library.viMoveIn8Ex(session, space, offset, length, buffer_8)\n    else:\n        ret = library.viMoveIn8(session, space, offset, length, buffer_8)\n    return list(buffer_8), ret", "response": "Moves an 8 - bit block of data from the specified address space and offset to local memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_in_16(library, session, space, offset, length, extended=False):\n    buffer_16 = (ViUInt16 * length)()\n    if extended:\n        ret = library.viMoveIn16Ex(session, space, offset, length, buffer_16)\n    else:\n        ret = library.viMoveIn16(session, space, offset, length, buffer_16)\n\n    return list(buffer_16), ret", "response": "Moves an 16 - bit block of data from the specified address space and offset to local memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves an 32 - bit block of data from the specified address space and offset to local memory.", "response": "def move_in_32(library, session, space, offset, length, extended=False):\n    \"\"\"Moves an 32-bit block of data from the specified address space and offset to local memory.\n\n    Corresponds to viMoveIn32* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param length: Number of elements to transfer, where the data width of the elements to transfer\n                   is identical to the source data width.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: Data read from the bus, return value of the library call.\n    :rtype: list, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    buffer_32 = (ViUInt32 * length)()\n    if extended:\n        ret = library.viMoveIn32Ex(session, space, offset, length, buffer_32)\n    else:\n        ret = library.viMoveIn32(session, space, offset, length, buffer_32)\n\n    return list(buffer_32), ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_in_64(library, session, space, offset, length, extended=False):\n    buffer_64 = (ViUInt64 * length)()\n    if extended:\n        ret = library.viMoveIn64Ex(session, space, offset, length, buffer_64)\n    else:\n        ret = library.viMoveIn64(session, space, offset, length, buffer_64)\n\n    return list(buffer_64), ret", "response": "Moves an 64 - bit block of data from the specified address space and offset to local memory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_out(library, session, space, offset, length, data, width, extended=False):\n    if width == 8:\n        return move_out_8(library, session, space, offset, length, data, extended)\n    elif width == 16:\n        return move_out_16(library, session, space, offset, length, data, extended)\n    elif width == 32:\n        return move_out_32(library, session, space, offset, length, data, extended)\n    elif width == 64:\n        return move_out_64(library, session, space, offset, length, data, extended)\n\n    raise ValueError('%s is not a valid size. Valid values are 8, 16, 32 or 64' % width)", "response": "Moves a block of data from local memory to the specified address space and offset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_out_8(library, session, space, offset, length, data, extended=False):\n    converted_buffer = (ViUInt8 * length)(*tuple(data))\n    if extended:\n        return library.viMoveOut8Ex(session, space, offset, length, converted_buffer)\n    else:\n        return library.viMoveOut8(session, space, offset, length, converted_buffer)", "response": "Moves an 8 - bit block of data from local memory to the specified address space and offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_out_16(library, session, space, offset, length, data, extended=False):\n    converted_buffer = (ViUInt16 * length)(*tuple(data))\n    if extended:\n        return library.viMoveOut16Ex(session, space, offset, length, converted_buffer)\n    else:\n        return library.viMoveOut16(session, space, offset, length, converted_buffer)", "response": "Moves an 16 - bit block of data from local memory to the specified address space and offset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving an 32 - bit block of data from local memory to the specified address space and offset.", "response": "def move_out_32(library, session, space, offset, length, data, extended=False):\n    \"\"\"Moves an 32-bit block of data from local memory to the specified address space and offset.\n\n    Corresponds to viMoveOut32* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param length: Number of elements to transfer, where the data width of the elements to transfer\n                   is identical to the source data width.\n    :param data: Data to write to bus.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    converted_buffer = (ViUInt32 * length)(*tuple(data))\n    if extended:\n        return library.viMoveOut32Ex(session, space, offset, length, converted_buffer)\n    else:\n        return library.viMoveOut32(session, space, offset, length, converted_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove an 64 - bit block of data from local memory to the specified address space and offset.", "response": "def move_out_64(library, session, space, offset, length, data, extended=False):\n    \"\"\"Moves an 64-bit block of data from local memory to the specified address space and offset.\n\n    Corresponds to viMoveOut64* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param length: Number of elements to transfer, where the data width of the elements to transfer\n                   is identical to the source data width.\n    :param data: Data to write to bus.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    converted_buffer = (ViUInt64 * length)(*tuple(data))\n    if extended:\n        return library.viMoveOut64Ex(session, space, offset, length, converted_buffer)\n    else:\n        return library.viMoveOut64(session, space, offset, length, converted_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens a session to the specified resource.", "response": "def open(library, session, resource_name,\n         access_mode=constants.AccessModes.no_lock, open_timeout=constants.VI_TMO_IMMEDIATE):\n    \"\"\"Opens a session to the specified resource.\n\n    Corresponds to viOpen function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Resource Manager session (should always be a session returned from open_default_resource_manager()).\n    :param resource_name: Unique symbolic name of a resource.\n    :param access_mode: Specifies the mode by which the resource is to be accessed. (constants.AccessModes)\n    :param open_timeout: Specifies the maximum time period (in milliseconds) that this operation waits\n                         before returning an error.\n    :return: Unique logical identifier reference to a session, return value of the library call.\n    :rtype: session, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    try:\n        open_timeout = int(open_timeout)\n    except ValueError:\n        raise ValueError('open_timeout (%r) must be an integer (or compatible type)' % open_timeout)\n    out_session = ViSession()\n\n    # [ViSession, ViRsrc, ViAccessMode, ViUInt32, ViPSession]\n    # ViRsrc converts from (str, unicode, bytes) to bytes\n    ret = library.viOpen(session, resource_name, access_mode, open_timeout, byref(out_session))\n    return out_session.value, ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open_default_resource_manager(library):\n    session = ViSession()\n    ret = library.viOpenDefaultRM(byref(session))\n    return session.value, ret", "response": "This function returns a session to the Default Resource Manager resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting in an 8 - bit 16 - bit 32 - bit value to the specified memory space and offset.", "response": "def write_memory(library, session, space, offset, data, width, extended=False):\n    \"\"\"Write in an 8-bit, 16-bit, 32-bit, value to the specified memory space and offset.\n\n    Corresponds to viOut* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param data: Data to write to bus.\n    :param width: Number of bits to read.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    if width == 8:\n        return out_8(library, session, space, offset, data, extended)\n    elif width == 16:\n        return out_16(library, session, space, offset, data, extended)\n    elif width == 32:\n        return out_32(library, session, space, offset, data, extended)\n\n    raise ValueError('%s is not a valid size. Valid values are 8, 16 or 32' % width)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites in an 8 - bit value from the specified memory space and offset.", "response": "def out_8(library, session, space, offset, data, extended=False):\n    \"\"\"Write in an 8-bit value from the specified memory space and offset.\n\n    Corresponds to viOut8* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param data: Data to write to bus.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    if extended:\n        return library.viOut8Ex(session, space, offset, data)\n    else:\n        return library.viOut8(session, space, offset, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite in an 16 - bit value from the specified memory space and offset.", "response": "def out_16(library, session, space, offset, data, extended=False):\n    \"\"\"Write in an 16-bit value from the specified memory space and offset.\n\n    Corresponds to viOut16* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param data: Data to write to bus.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    if extended:\n        return library.viOut16Ex(session, space, offset, data, extended=False)\n    else:\n        return library.viOut16(session, space, offset, data, extended=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites in an 32 - bit value from the specified memory space and offset.", "response": "def out_32(library, session, space, offset, data, extended=False):\n    \"\"\"Write in an 32-bit value from the specified memory space and offset.\n\n    Corresponds to viOut32* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param data: Data to write to bus.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    if extended:\n        return library.viOut32Ex(session, space, offset, data)\n    else:\n        return library.viOut32(session, space, offset, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite in an 64 - bit value from the specified memory space and offset.", "response": "def out_64(library, session, space, offset, data, extended=False):\n    \"\"\"Write in an 64-bit value from the specified memory space and offset.\n\n    Corresponds to viOut64* functions of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param space: Specifies the address space. (Constants.*SPACE*)\n    :param offset: Offset (in bytes) of the address or register from which to read.\n    :param data: Data to write to bus.\n    :param extended: Use 64 bits offset independent of the platform.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    if extended:\n        return library.viOut64Ex(session, space, offset, data)\n    else:\n        return library.viOut64(session, space, offset, data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a resource string to get the interface type and board number.", "response": "def parse_resource(library, session, resource_name):\n    \"\"\"Parse a resource string to get the interface information.\n\n    Corresponds to viParseRsrc function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Resource Manager session (should always be the Default Resource Manager for VISA\n                    returned from open_default_resource_manager()).\n    :param resource_name: Unique symbolic name of a resource.\n    :return: Resource information with interface type and board number, return value of the library call.\n    :rtype: :class:`pyvisa.highlevel.ResourceInfo`, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    interface_type = ViUInt16()\n    interface_board_number = ViUInt16()\n\n    # [ViSession, ViRsrc, ViPUInt16, ViPUInt16]\n    # ViRsrc converts from (str, unicode, bytes) to bytes\n    ret = library.viParseRsrc(session, resource_name, byref(interface_type),\n                              byref(interface_board_number))\n    return ResourceInfo(constants.InterfaceType(interface_type.value),\n                        interface_board_number.value,\n                        None, None, None), ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_resource_extended(library, session, resource_name):\n    interface_type = ViUInt16()\n    interface_board_number = ViUInt16()\n    resource_class = create_string_buffer(constants.VI_FIND_BUFLEN)\n    unaliased_expanded_resource_name = create_string_buffer(constants.VI_FIND_BUFLEN)\n    alias_if_exists = create_string_buffer(constants.VI_FIND_BUFLEN)\n\n    # [ViSession, ViRsrc, ViPUInt16, ViPUInt16, ViAChar, ViAChar, ViAChar]\n    # ViRsrc converts from (str, unicode, bytes) to bytes\n    ret = library.viParseRsrcEx(session, resource_name, byref(interface_type),\n                                byref(interface_board_number), resource_class,\n                                unaliased_expanded_resource_name,\n                                alias_if_exists)\n\n    res = [buffer_to_text(val)\n           for val in (resource_class,\n                       unaliased_expanded_resource_name,\n                       alias_if_exists)]\n\n    if res[-1] == '':\n        res[-1] = None\n\n    return ResourceInfo(constants.InterfaceType(interface_type.value),\n                        interface_board_number.value, *res), ret", "response": "Parses a resource string to get extended interface information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef peek(library, session, address, width):\n\n    if width == 8:\n        return peek_8(library, session, address)\n    elif width == 16:\n        return peek_16(library, session, address)\n    elif width == 32:\n        return peek_32(library, session, address)\n    elif width == 64:\n        return peek_64(library, session, address)\n\n    raise ValueError('%s is not a valid size. Valid values are 8, 16, 32 or 64' % width)", "response": "Reads an 8 16 or 32 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef peek_8(library, session, address):\n    value_8 = ViUInt8()\n    ret = library.viPeek8(session, address, byref(value_8))\n    return value_8.value, ret", "response": "Reads an 8 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread an 16 - bit value from the specified address.", "response": "def peek_16(library, session, address):\n    \"\"\"Read an 16-bit value from the specified address.\n\n    Corresponds to viPeek16 function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param address: Source address to read the value.\n    :return: Data read from bus, return value of the library call.\n    :rtype: bytes, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    value_16 = ViUInt16()\n    ret = library.viPeek16(session, address, byref(value_16))\n    return value_16.value, ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef peek_32(library, session, address):\n    value_32 = ViUInt32()\n    ret = library.viPeek32(session, address, byref(value_32))\n    return value_32.value, ret", "response": "Reads an 32 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef peek_64(library, session, address):\n    value_64 = ViUInt64()\n    ret = library.viPeek64(session, address, byref(value_64))\n    return value_64.value, ret", "response": "Reads an 64 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef poke(library, session, address, width, data):\n\n    if width == 8:\n        return poke_8(library, session, address, data)\n    elif width == 16:\n        return poke_16(library, session, address, data)\n    elif width == 32:\n        return poke_32(library, session, address, data)\n\n    raise ValueError('%s is not a valid size. Valid values are 8, 16 or 32' % width)", "response": "Writes an 8 16 or 32 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef poke_8(library, session, address, data):\n    return library.viPoke8(session, address, data)", "response": "Writes an 8 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef poke_16(library, session, address, data):\n    return library.viPoke16(session, address, data)", "response": "Writes an 16 - bit value from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite an 32 - bit value from the specified address.", "response": "def poke_32(library, session, address, data):\n    \"\"\"Write an 32-bit value from the specified address.\n\n    Corresponds to viPoke32 function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param address: Source address to read the value.\n    :param data: value to be written to the bus.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viPoke32(session, address, data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite an 64 - bit value from the specified address.", "response": "def poke_64(library, session, address, data):\n    \"\"\"Write an 64-bit value from the specified address.\n\n    Corresponds to viPoke64 function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param address: Source address to read the value.\n    :param data: value to be written to the bus.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viPoke64(session, address, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread data from device or interface synchronously.", "response": "def read(library, session, count):\n    \"\"\"Reads data from device or interface synchronously.\n\n    Corresponds to viRead function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param count: Number of bytes to be read.\n    :return: data read, return value of the library call.\n    :rtype: bytes, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    buffer = create_string_buffer(count)\n    return_count = ViUInt32()\n    ret = library.viRead(session, buffer, count, byref(return_count))\n    return buffer.raw[:return_count.value], ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading data from device or interface asynchronously.", "response": "def read_asynchronously(library, session, count):\n    \"\"\"Reads data from device or interface asynchronously.\n\n    Corresponds to viReadAsync function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param count: Number of bytes to be read.\n    :return: result, jobid, return value of the library call.\n    :rtype: ctypes buffer, jobid, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    buffer = create_string_buffer(count)\n    job_id = ViJobId()\n    ret = library.viReadAsync(session, buffer, count, byref(job_id))\n    return buffer, job_id, ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_stb(library, session):\n    status = ViUInt16()\n    ret = library.viReadSTB(session, byref(status))\n    return status.value, ret", "response": "Reads a status byte of the service request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_to_file(library, session, filename, count):\n    return_count = ViUInt32()\n    ret = library.viReadToFile(session, filename, count, return_count)\n    return return_count, ret", "response": "Reads data synchronously and store the transferred data in a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the state of an attribute.", "response": "def set_attribute(library, session, attribute, attribute_state):\n    \"\"\"Sets the state of an attribute.\n\n    Corresponds to viSetAttribute function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param attribute: Attribute for which the state is to be modified. (Attributes.*)\n    :param attribute_state: The state of the attribute to be set for the specified object.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viSetAttribute(session, attribute, attribute_state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the size for the formatted I / O and low - level I / O communication buffer ( s ).", "response": "def set_buffer(library, session, mask, size):\n    \"\"\"Sets the size for the formatted I/O and/or low-level I/O communication buffer(s).\n\n    Corresponds to viSetBuf function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param mask: Specifies the type of buffer. (Constants.READ_BUF, .WRITE_BUF, .IO_IN_BUF, .IO_OUT_BUF)\n    :param size: The size to be set for the specified buffer(s).\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return library.viSetBuf(session, mask, size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a user - readable description of the status code passed to the operation.", "response": "def status_description(library, session, status):\n    \"\"\"Returns a user-readable description of the status code passed to the operation.\n\n    Corresponds to viStatusDesc function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param status: Status code to interpret.\n    :return: - The user-readable string interpretation of the status code passed to the operation,\n             - return value of the library call.\n    :rtype: - unicode (Py2) or str (Py3)\n            - :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    description = create_string_buffer(256)\n    ret = library.viStatusDesc(session, status, description)\n    return buffer_to_text(description), ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef terminate(library, session, degree, job_id):\n    return library.viTerminate(session, degree, job_id)", "response": "Requests a VISA session to terminate normal execution of an operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unmap_trigger(library, session, trigger_source, trigger_destination):\n    return library.viUnmapTrigger(session, trigger_source, trigger_destination)", "response": "Undo a previous map from the specified source line to the specified destination line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming a USB control pipe transfer from the device. Corresponds to viUsbControlIn function of the VISA library. :param library: the visa library wrapped by ctypes. :param session: Unique logical identifier to a session. :param request_type_bitmap_field: bmRequestType parameter of the setup stage of a USB control transfer. :param request_id: bRequest parameter of the setup stage of a USB control transfer. :param request_value: wValue parameter of the setup stage of a USB control transfer. :param index: wIndex parameter of the setup stage of a USB control transfer. This is usually the index of the interface or endpoint. :param length: wLength parameter of the setup stage of a USB control transfer. This value also specifies the size of the data buffer to receive the data from the optional data stage of the control transfer. :return: - The data buffer that receives the data from the optional data stage of the control transfer - return value of the library call. :rtype: - bytes - :class:`pyvisa.constants.StatusCode`", "response": "def usb_control_in(library, session, request_type_bitmap_field, request_id, request_value,\n                   index, length=0):\n    \"\"\"Performs a USB control pipe transfer from the device.\n\n    Corresponds to viUsbControlIn function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param request_type_bitmap_field: bmRequestType parameter of the setup stage of a USB control transfer.\n    :param request_id: bRequest parameter of the setup stage of a USB control transfer.\n    :param request_value: wValue parameter of the setup stage of a USB control transfer.\n    :param index: wIndex parameter of the setup stage of a USB control transfer.\n                  This is usually the index of the interface or endpoint.\n    :param length: wLength parameter of the setup stage of a USB control transfer.\n                   This value also specifies the size of the data buffer to receive the data from the\n                   optional data stage of the control transfer.\n    :return: - The data buffer that receives the data from the optional data stage of the control transfer\n             - return value of the library call.\n    :rtype: - bytes\n            - :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    buffer = create_string_buffer(length)\n    return_count = ViUInt16()\n    ret = library.viUsbControlIn(session, request_type_bitmap_field, request_id,\n                                 request_value, index, length, buffer,\n                                 byref(return_count))\n    return buffer.raw[:return_count.value], ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a USB control pipe transfer to the device. Corresponds to viUsbControlOut function of the VISA library. :param library: the visa library wrapped by ctypes. :param session: Unique logical identifier to a session. :param request_type_bitmap_field: bmRequestType parameter of the setup stage of a USB control transfer. :param request_id: bRequest parameter of the setup stage of a USB control transfer. :param request_value: wValue parameter of the setup stage of a USB control transfer. :param index: wIndex parameter of the setup stage of a USB control transfer. This is usually the index of the interface or endpoint. :param data: The data buffer that sends the data in the optional data stage of the control transfer. :return: return value of the library call. :rtype: :class:`pyvisa.constants.StatusCode`", "response": "def usb_control_out(library, session, request_type_bitmap_field, request_id, request_value,\n                    index, data=\"\"):\n    \"\"\"Performs a USB control pipe transfer to the device.\n\n    Corresponds to viUsbControlOut function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param request_type_bitmap_field: bmRequestType parameter of the setup stage of a USB control transfer.\n    :param request_id: bRequest parameter of the setup stage of a USB control transfer.\n    :param request_value: wValue parameter of the setup stage of a USB control transfer.\n    :param index: wIndex parameter of the setup stage of a USB control transfer.\n                  This is usually the index of the interface or endpoint.\n    :param data: The data buffer that sends the data in the optional data stage of the control transfer.\n    :return: return value of the library call.\n    :rtype: :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    length = len(data)\n    return library.viUsbControlOut(session, request_type_bitmap_field, request_id,\n                                   request_value, index, length, data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vxi_command_query(library, session, mode, command):\n    response = ViUInt32()\n    ret = library.viVxiCommandQuery(session, mode, command, byref(response))\n    return response.value, ret", "response": "Sends a command to the VISA device and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_on_event(library, session, in_event_type, timeout):\n    out_event_type = ViEventType()\n    out_context = ViEvent()\n    ret = library.viWaitOnEvent(session, in_event_type, timeout,\n                                byref(out_event_type), byref(out_context))\n    return out_event_type.value, out_context, ret", "response": "Waits for an occurrence of a specified event for a given session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(library, session, data):\n    return_count = ViUInt32()\n    # [ViSession, ViBuf, ViUInt32, ViPUInt32]\n    ret = library.viWrite(session, data, len(data), byref(return_count))\n    return return_count.value, ret", "response": "Writes data to the device or interface synchronously."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite data to device or interface asynchronously.", "response": "def write_asynchronously(library, session, data):\n    \"\"\"Writes data to device or interface asynchronously.\n\n    Corresponds to viWriteAsync function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param data: data to be written.\n    :return: Job ID of this asynchronous write operation, return value of the library call.\n    :rtype: jobid, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    job_id = ViJobId()\n    # [ViSession, ViBuf, ViUInt32, ViPJobId]\n    ret = library.viWriteAsync(session, data, len(data), byref(job_id))\n    return job_id, ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes data from a file and write it out synchronously.", "response": "def write_from_file(library, session, filename, count):\n    \"\"\"Take data from a file and write it out synchronously.\n\n    Corresponds to viWriteFromFile function of the VISA library.\n\n    :param library: the visa library wrapped by ctypes.\n    :param session: Unique logical identifier to a session.\n    :param filename: Name of file from which data will be read.\n    :param count: Number of bytes to be written.\n    :return: Number of bytes actually transferred, return value of the library call.\n    :rtype: int, :class:`pyvisa.constants.StatusCode`\n    \"\"\"\n    return_count = ViUInt32()\n    ret = library.viWriteFromFile(session, filename, count, return_count)\n    return return_count, ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading in an 8 - bit 16 - bit 32 - bit or 64 - bit value from the specified memory space and offset.", "response": "def read_memory(self, space, offset, width, extended=False):\n        \"\"\"Reads in an 8-bit, 16-bit, 32-bit, or 64-bit value from the specified memory space and offset.\n\n        :param space: Specifies the address space. (Constants.*SPACE*)\n        :param offset: Offset (in bytes) of the address or register from which to read.\n        :param width: Number of bits to read.\n        :param extended: Use 64 bits offset independent of the platform.\n        :return: Data read from memory.\n\n        Corresponds to viIn* functions of the visa library.\n        \"\"\"\n        return self.visalib.read_memory(self.session, space, offset, width, extended)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_memory(self, space, offset, data, width, extended=False):\n        return self.visalib.write_memory(self.session, space, offset, data, width, extended)", "response": "Write in an 8 - bit 16 - bit 32 - bit value to the specified memory space and offset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move_in(self, space, offset, length, width, extended=False):\n        return self.visalib.move_in(self.session, space, offset, length, width, extended)", "response": "Moves a block of data from the specified address space and offset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move_out(self, space, offset, length, data, width, extended=False):\n        return self.visalib.move_out(space, offset, length, data, width, extended)", "response": "Moves a block of data from local memory to the specified address space and offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef in_resource(cls, session_type):\n        if cls.resources is AllSessionTypes:\n            return True\n        return session_type in cls.resources", "response": "Returns True if the attribute is part of a given session type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_list(self, args):\n\n        try:\n            resources = self.resource_manager.list_resources_info()\n        except Exception as e:\n            print(e)\n        else:\n            self.resources = []\n            for ndx, (resource_name, value) in enumerate(resources.items()):\n                if not args:\n                    print('({0:2d}) {1}'.format(ndx, resource_name))\n                    if value.alias:\n                        print('     alias: {}'.format(value.alias))\n\n                self.resources.append((resource_name, value.alias or None))", "response": "List all connected resources."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens resource by number or resource name or alias.", "response": "def do_open(self, args):\n        \"\"\"Open resource by number, resource name or alias: open 3\"\"\"\n\n        if not args:\n            print('A resource name must be specified.')\n            return\n\n        if self.current:\n            print('You can only open one resource at a time. Please close the current one first.')\n            return\n\n        if args.isdigit():\n            try:\n                args = self.resources[int(args)][0]\n            except IndexError:\n                print('Not a valid resource number. Use the command \"list\".')\n                return\n\n        try:\n            self.current = self.resource_manager.open_resource(args)\n            print('{} has been opened.\\n'\n                  'You can talk to the device using \"write\", \"read\" or \"query\".\\n'\n                  'The default end of message is added to each message.'.format(args))\n\n            self.py_attr = []\n            self.vi_attr = []\n            for attr in getattr(self.current, 'visa_attributes_classes', ()):\n                if attr.py_name:\n                    self.py_attr.append(attr.py_name)\n                self.vi_attr.append(attr.visa_name)\n\n            self.prompt = '(open) '\n        except Exception as e:\n            print(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses resource in use.", "response": "def do_close(self, args):\n        \"\"\"Close resource in use.\"\"\"\n\n        if not self.current:\n            print('There are no resources in use. Use the command \"open\".')\n            return\n\n        try:\n            self.current.close()\n        except Exception as e:\n            print(e)\n        else:\n            print('The resource has been closed.')\n            self.current = None\n            self.prompt = self.default_prompt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_query(self, args):\n\n        if not self.current:\n            print('There are no resources in use. Use the command \"open\".')\n            return\n\n        try:\n            print('Response: {}'.format(self.current.query(args)))\n        except Exception as e:\n            print(e)", "response": "Query the resource in use"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreceives from the resource in use.", "response": "def do_read(self, args):\n        \"\"\"Receive from the resource in use.\"\"\"\n\n        if not self.current:\n            print('There are no resources in use. Use the command \"open\".')\n            return\n\n        try:\n            print(self.current.read())\n        except Exception as e:\n            print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending to the resource in use? send *IDN?", "response": "def do_write(self, args):\n        \"\"\"Send to the resource in use: send *IDN? \"\"\"\n\n        if not self.current:\n            print('There are no resources in use. Use the command \"open\".')\n            return\n\n        try:\n            self.current.write(args)\n        except Exception as e:\n            print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset or get timeout for resource in use.", "response": "def do_timeout(self, args):\n        \"\"\"Get or set timeout (in ms) for resource in use.\n\n        Get timeout:\n\n            timeout\n\n        Set timeout:\n\n            timeout <mstimeout>\n\n        \"\"\"\n\n        if not self.current:\n            print('There are no resources in use. Use the command \"open\".')\n            return\n\n        args = args.strip()\n\n        if not args:\n            try:\n                print('Timeout: {}ms'.format(self.current.timeout))\n            except Exception as e:\n                print(e)\n        else:        \n            args = args.split(' ')\n            try:\n                self.current.timeout = float(args[0])\n                print('Done')\n            except Exception as e:\n                print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget or set the state for a visa attribute.", "response": "def do_attr(self, args):\n        \"\"\"Get or set the state for a visa attribute.\n\n        List all attributes:\n\n            attr\n\n        Get an attribute state:\n\n            attr <name>\n\n        Set an attribute state:\n\n            attr <name> <state>\n        \"\"\"\n\n        if not self.current:\n            print('There are no resources in use. Use the command \"open\".')\n            return\n\n        args = args.strip()\n\n        if not args:\n            self.print_attribute_list()\n            return\n\n        args = args.split(' ')\n\n        if len(args) > 2:\n            print('Invalid syntax, use `attr <name>` to get; or `attr <name> <value>` to set')\n        elif len(args) == 1:\n            # Get\n            attr_name = args[0]\n            if attr_name.startswith('VI_'):\n                try:\n                    print(self.current.get_visa_attribute(getattr(constants, attr_name)))\n                except Exception as e:\n                    print(e)\n            else:\n                try:\n                    print(getattr(self.current, attr_name))\n                except Exception as e:\n                    print(e)\n        else:\n            attr_name, attr_state = args[0], args[1]\n            if attr_name.startswith('VI_'):\n                try:\n                    attributeId = getattr(constants, attr_name)\n                    attr = attributes.AttributesByID[attributeId]\n                    datatype = attr.visa_type\n                    retcode = None\n                    if datatype == 'ViBoolean':\n                        if attr_state == 'True':\n                            attr_state = True\n                        elif attr_state == 'False':\n                            attr_state = False\n                        else:\n                            retcode = constants.StatusCode.error_nonsupported_attribute_state\n                    elif datatype in ['ViUInt8', 'ViUInt16', 'ViUInt32', 'ViInt8', 'ViInt16', 'ViInt32']:\n                        try:\n                            attr_state = int(attr_state)\n                        except ValueError:\n                            retcode = constants.StatusCode.error_nonsupported_attribute_state\n                    if not retcode:\n                        retcode = self.current.set_visa_attribute(attributeId, attr_state)\n                    if retcode:\n                        print('Error {}'.format(str(retcode)))\n                    else:\n                        print('Done')\n                except Exception as e:\n                    print(e)\n            else:\n                print('Setting Resource Attributes by python name is not yet supported.')\n                return\n                try:\n                    print(getattr(self.current, attr_name))\n                    print('Done')\n                except Exception as e:\n                    print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting or get or set termination character for resource in use.", "response": "def do_termchar(self, args):\n        \"\"\"Get or set termination character for resource in use.\n        <termchar> can be one of: CR, LF, CRLF, NUL or None.\n        None is used to disable termination character\n        \n        Get termination character:\n\n            termchar\n\n        Set termination character read or read+write:\n\n            termchar <termchar> [<termchar>]\n\n        \"\"\"\n\n        if not self.current:\n            print('There are no resources in use. Use the command \"open\".')\n            return\n\n        args = args.strip()\n\n        if not args:\n            try:\n                charmap = { u'\\r': 'CR', u'\\n': 'LF', u'\\r\\n': 'CRLF', u'\\0': 'NUL' }\n                chr = self.current.read_termination\n                if chr in charmap:\n                    chr = charmap[chr]\n                chw = self.current.write_termination\n                if chw in charmap:\n                    chw = charmap[chw]\n                print('Termchar read: {} write: {}'.format(chr, chw))\n            except Exception as e:\n                print(e)\n        else:        \n            args = args.split(' ')\n            charmap = { 'CR': u'\\r', 'LF': u'\\n', 'CRLF': u'\\r\\n', 'NUL': u'\\0', 'None': None }\n            chr = args[0]\n            chw = args[0 if len(args) == 1 else 1]\n            if chr in charmap and chw in charmap:\n                try:\n                    self.current.read_termination = charmap[chr]\n                    self.current.write_termination = charmap[chw]\n                    print('Done')\n                except Exception as e:\n                    print(e)\n            else:\n                print('use CR, LF, CRLF, NUL or None to set termchar')\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_exit(self, arg):\n\n        if self.current:\n            self.current.close()\n        self.resource_manager.close()\n        del self.resource_manager\n        return True", "response": "Exit the shell session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timeout(self):\n        timeout = self.get_visa_attribute(constants.VI_ATTR_TMO_VALUE)\n        if timeout == constants.VI_TMO_INFINITE:\n            return float('+inf')\n        return timeout", "response": "The timeout in milliseconds for all resource I/O operations."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resource_info(self):\n        return self.visalib.parse_resource_extended(self._resource_manager.session, self.resource_name)", "response": "Get the extended information of this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interface_type(self):\n        return self.visalib.parse_resource(self._resource_manager.session,\n                                           self.resource_name)[0].interface_type", "response": "The interface type of the resource as a number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open(self, access_mode=constants.AccessModes.no_lock, open_timeout=5000):\n\n        logger.debug('%s - opening ...', self._resource_name, extra=self._logging_extra)\n        with self._resource_manager.ignore_warning(constants.VI_SUCCESS_DEV_NPRESENT):\n            self.session, status = self._resource_manager.open_bare_resource(self._resource_name, access_mode, open_timeout)\n\n            if status == constants.VI_SUCCESS_DEV_NPRESENT:\n                # The device was not ready when we opened the session.\n                # Now it gets five seconds more to become ready.\n                # Every 0.1 seconds we probe it with viClear.\n                start_time = time.time()\n                sleep_time = 0.1\n                try_time = 5\n                while time.time() - start_time < try_time:\n                    time.sleep(sleep_time)\n                    try:\n                        self.clear()\n                        break\n                    except errors.VisaIOError as error:\n                        if error.error_code != constants.VI_ERROR_NLISTENERS:\n                            raise\n\n        self._logging_extra['session'] = self.session\n        logger.debug('%s - is open with session %s',\n                     self._resource_name, self.session,\n                     extra=self._logging_extra)", "response": "Opens a session to the specified resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef close(self):\n        try:\n            logger.debug('%s - closing', self._resource_name,\n                         extra=self._logging_extra)\n            self.before_close()\n            self.visalib.close(self.session)\n            logger.debug('%s - is closed', self._resource_name,\n                         extra=self._logging_extra)\n            self.session = None\n        except errors.InvalidSession:\n            pass", "response": "Closes the VISA session and marks the handle as invalid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_visa_attribute(self, name, state):\n        return self.visalib.set_attribute(self.session, name, state)", "response": "Sets the state of an attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls a handler for an event.", "response": "def install_handler(self, event_type, handler, user_handle=None):\n        \"\"\"Installs handlers for event callbacks in this resource.\n\n        :param event_type: Logical event identifier.\n        :param handler: Interpreted as a valid reference to a handler to be installed by a client application.\n        :param user_handle: A value specified by an application that can be used for identifying handlers\n                            uniquely for an event type.\n        :returns: user handle (a ctypes object)\n        \"\"\"\n\n        return self.visalib.install_visa_handler(self.session, event_type, handler, user_handle)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisable notification of the specified event type via the specified mechanism.", "response": "def disable_event(self, event_type, mechanism):\n        \"\"\"Disables notification of the specified event type(s) via the specified mechanism(s).\n\n        :param event_type: Logical event identifier.\n        :param mechanism: Specifies event handling mechanisms to be disabled.\n                          (Constants.VI_QUEUE, .VI_HNDLR, .VI_SUSPEND_HNDLR, .VI_ALL_MECH)\n        \"\"\"\n        self.visalib.disable_event(self.session, event_type, mechanism)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndiscards events for specified event types and mechanisms in this resource.", "response": "def discard_events(self, event_type, mechanism):\n        \"\"\"Discards event occurrences for specified event types and mechanisms in this resource.\n\n        :param event_type: Logical event identifier.\n        :param mechanism: Specifies event handling mechanisms to be dicarded.\n                          (Constants.VI_QUEUE, .VI_HNDLR, .VI_SUSPEND_HNDLR, .VI_ALL_MECH)\n        \"\"\"\n        self.visalib.discard_events(self.session, event_type, mechanism)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nenables event occurrences for specified event types and mechanisms in this resource.", "response": "def enable_event(self, event_type, mechanism, context=None):\n        \"\"\"Enable event occurrences for specified event types and mechanisms in this resource.\n\n        :param event_type: Logical event identifier.\n        :param mechanism: Specifies event handling mechanisms to be enabled.\n                          (Constants.VI_QUEUE, .VI_HNDLR, .VI_SUSPEND_HNDLR)\n        :param context:  Not currently used, leave as None.\n        \"\"\"\n        self.visalib.enable_event(self.session, event_type, mechanism, context)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait_on_event(self, in_event_type, timeout, capture_timeout=False):\n        try:\n            event_type, context, ret = self.visalib.wait_on_event(self.session, in_event_type, timeout)\n        except errors.VisaIOError as exc:\n            if capture_timeout and exc.error_code == constants.StatusCode.error_timeout:\n                return WaitResponse(in_event_type, None, exc.error_code, self.visalib, timed_out=True)\n            raise\n        return WaitResponse(event_type, context, ret, self.visalib)", "response": "Waits for an occurrence of a specified event in this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lock(self, timeout='default', requested_key=None):\n        timeout = self.timeout if timeout == 'default' else timeout\n        timeout = self._cleanup_timeout(timeout)\n        return self.visalib.lock(self.session, constants.AccessModes.shared_lock, timeout, requested_key)[0]", "response": "Establish a shared lock to the resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lock_excl(self, timeout='default'):\n        timeout = self.timeout if timeout == 'default' else timeout\n        timeout = self._cleanup_timeout(timeout)\n        self.visalib.lock(self.session, constants.AccessModes.exclusive_lock, timeout, None)", "response": "Establish an exclusive lock to the resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_html(html_code, **kwargs):\n\n    parser = TableHandler(**kwargs)\n    parser.feed(html_code)\n    return parser.tables", "response": "Generates a list of PrettyTables from a string of HTML code."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a PrettyTables from a string of HTML code which contains only one a single <table >", "response": "def from_html_one(html_code, **kwargs):\n    \"\"\"\n    Generates a PrettyTables from a string of HTML code which contains only a\n    single <table>\n    \"\"\"\n\n    tables = from_html(html_code, **kwargs)\n    try:\n        assert len(tables) == 1\n    except AssertionError:\n        raise Exception(\"More than one <table> in provided HTML code!  Use from_html instead.\")\n    return tables[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a row to the table Taxonomy object", "response": "def add_row(self, row):\n\n        \"\"\"Add a row to the table\n\n        Arguments:\n\n        row - row of data, should be a list with as many elements as the table\n        has fields\"\"\"\n\n        if self._field_names and len(row) != len(self._field_names):\n            raise Exception(\"Row has incorrect number of values, (actual) %d!=%d (expected)\" %(len(row),len(self._field_names)))\n        if not self._field_names:\n            self.field_names = [(\"Field %d\" % (n+1)) for n in range(0,len(row))]\n        self._rows.append(list(row))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef del_row(self, row_index):\n\n        \"\"\"Delete a row to the table\n\n        Arguments:\n\n        row_index - The index of the row you want to delete.  Indexing starts at 0.\"\"\"\n\n        if row_index > len(self._rows)-1:\n            raise Exception(\"Cant delete row at index %d, table only has %d rows!\" % (row_index, len(self._rows)))\n        del self._rows[row_index]", "response": "Deletes a row from the table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_column(self, fieldname, column, align=\"c\", valign=\"t\"):\n\n        \"\"\"Add a column to the table.\n\n        Arguments:\n\n        fieldname - name of the field to contain the new column of data\n        column - column of data, should be a list with as many elements as the\n        table has rows\n        align - desired alignment for this column - \"l\" for left, \"c\" for centre and \"r\" for right\n        valign - desired vertical alignment for new columns - \"t\" for top, \"m\" for middle and \"b\" for bottom\"\"\"\n\n        if len(self._rows) in (0, len(column)):\n            self._validate_align(align)\n            self._validate_valign(valign)\n            self._field_names.append(fieldname)\n            self._align[fieldname] = align\n            self._valign[fieldname] = valign\n            for i in range(0, len(column)):\n                if len(self._rows) < i+1:\n                    self._rows.append([])\n                self._rows[i].append(column[i])\n        else:\n            raise Exception(\"Column length %d does not match number of rows %d!\" % (len(column), len(self._rows)))", "response": "Add a column to the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string representation of HTML formatted version of the table in current state.", "response": "def get_html_string(self, **kwargs):\n\n        \"\"\"Return string representation of HTML formatted version of table in current state.\n\n        Arguments:\n\n        start - index of first data row to include in output\n        end - index of last data row to include in output PLUS ONE (list slice style)\n        fields - names of fields (columns) to include\n        header - print a header showing field names (True or False)\n        border - print a border around the table (True or False)\n        hrules - controls printing of horizontal rules after rows.  Allowed values: ALL, FRAME, HEADER, NONE\n        vrules - controls printing of vertical rules between columns.  Allowed values: FRAME, ALL, NONE\n        int_format - controls formatting of integer data\n        float_format - controls formatting of floating point data\n        padding_width - number of spaces on either side of column data (only used if left and right paddings are None)\n        left_padding_width - number of spaces on left hand side of column data\n        right_padding_width - number of spaces on right hand side of column data\n        sortby - name of field to sort rows by\n        sort_key - sorting key function, applied to data points before sorting\n        attributes - dictionary of name/value pairs to include as HTML attributes in the <table> tag\n        xhtml - print <br/> tags if True, <br> tags if false\"\"\"\n\n        options = self._get_options(kwargs)\n\n        if options[\"format\"]:\n            string = self._get_formatted_html_string(options)\n        else:\n            string = self._get_simple_html_string(options)\n\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_fields_unique(self, fields):\n        for i in range(0, len(fields)):\n            for j in range(i+1, len(fields)):\n                if fields[i] == fields[j]:\n                    fields[j] += \"'\"", "response": "Make the fields unique"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling parsing response structure and translating API Exceptions", "response": "def meta_request(func):\n    \"\"\" Handles parsing response structure and translating API Exceptions \"\"\"\n    def inner(self, resource, *args, **kwargs):\n        serialize_response = kwargs.pop('serialize', True)\n        try:\n            resp = func(self, resource, *args, **kwargs)\n        except ApiException as e:\n            raise api_exception(e)\n        if serialize_response:\n            return serialize(resource, resp)\n        return resp\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstream events for a resource instance in the Kubernetes API.", "response": "def watch(self, resource, namespace=None, name=None, label_selector=None, field_selector=None, resource_version=None, timeout=None):\n        \"\"\"\n        Stream events for a resource from the Kubernetes API\n\n        :param resource: The API resource object that will be used to query the API\n        :param namespace: The namespace to query\n        :param name: The name of the resource instance to query\n        :param label_selector: The label selector with which to filter results\n        :param field_selector: The field selector with which to filter results\n        :param resource_version: The version with which to filter results. Only events with\n                                 a resource_version greater than this value will be returned\n        :param timeout: The amount of time in seconds to wait before terminating the stream\n\n        :return: Event object with these keys:\n                   'type': The type of event such as \"ADDED\", \"DELETED\", etc.\n                   'raw_object': a dict representing the watched object.\n                   'object': A ResourceInstance wrapping raw_object.\n\n        Example:\n            client = DynamicClient(k8s_client)\n            v1_pods = client.resources.get(api_version='v1', kind='Pod')\n\n            for e in v1_pods.watch(resource_version=0, namespace=default, timeout=5):\n                print(e['type'])\n                print(e['object'].metadata)\n        \"\"\"\n        watcher = watch.Watch()\n        for event in watcher.stream(\n            resource.get,\n            namespace=namespace,\n            name=name,\n            field_selector=field_selector,\n            label_selector=label_selector,\n            resource_version=resource_version,\n            serialize=False,\n            timeout_seconds=timeout\n        ):\n            event['object'] = ResourceInstance(resource, event['object'])\n            yield event"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate(self, definition, version=None, strict=False):\n        if not HAS_KUBERNETES_VALIDATE:\n            raise KubernetesValidateMissing()\n\n        errors = list()\n        warnings = list()\n        try:\n            if version is None:\n                try:\n                    version = self.version['kubernetes']['gitVersion']\n                except KeyError:\n                    version = kubernetes_validate.latest_version()\n            kubernetes_validate.validate(definition, version, strict)\n        except kubernetes_validate.utils.ValidationError as e:\n            errors.append(\"resource definition validation error at %s: %s\" % ('.'.join([str(item) for item in e.path]), e.message))  # noqa: B306\n        except VersionNotSupportedError as e:\n            errors.append(\"Kubernetes version %s is not supported by kubernetes-validate\" % version)\n        except kubernetes_validate.utils.SchemaNotFoundError as e:\n            warnings.append(\"Could not find schema for object kind %s with API version %s in Kubernetes version %s (possibly Custom Resource?)\" %\n                            (e.kind, e.api_version, e.version))\n        return warnings, errors", "response": "validate checks a kubernetes resource definition against a given kubernetes version"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _items_to_resources(self, body):\n        if body is None:\n            raise ValueError(\"You must provide a body when calling methods on a ResourceList\")\n\n        api_version = body['apiVersion']\n        kind = body['kind']\n        items = body.get('items')\n        if not items:\n            raise ValueError('The `items` field in the body must be populated when calling methods on a ResourceList')\n\n        if self.kind != kind:\n            raise ValueError('Methods on a {} must be called with a body containing the same kind. Receieved {} instead'.format(self.kind, kind))\n\n        return {\n            'api_version': api_version,\n            'kind': kind,\n            'items': [self._item_to_resource(item) for item in items]\n        }", "response": "Takes a list body and returns a dictionary with the following structure"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndiscovers all API groups present in the cluster", "response": "def parse_api_groups(self, request_resources=False, update=False):\n        \"\"\" Discovers all API groups present in the cluster \"\"\"\n        if not self._cache.get('resources') or update:\n            self._cache['resources'] = self._cache.get('resources', {})\n            groups_response = load_json(self.client.request('GET', '/{}'.format(DISCOVERY_PREFIX)))['groups']\n\n            groups = self.default_groups(request_resources=request_resources)\n\n            for group in groups_response:\n                new_group = {}\n                for version_raw in group['versions']:\n                    version = version_raw['version']\n                    resource_group = self._cache.get('resources', {}).get(DISCOVERY_PREFIX, {}).get(group['name'], {}).get(version)\n                    preferred = version_raw == group['preferredVersion']\n                    resources = resource_group.resources if resource_group else {}\n                    if request_resources:\n                        resources = self.get_resources_for_api_version(DISCOVERY_PREFIX, group['name'], version, preferred)\n                    new_group[version] = ResourceGroup(preferred, resources=resources)\n                groups[DISCOVERY_PREFIX][group['name']] = new_group\n            self._cache['resources'].update(groups)\n            self._write_cache()\n\n        return self._cache['resources']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of resources associated with provided api_version", "response": "def get_resources_for_api_version(self, prefix, group, version, preferred):\n        \"\"\" returns a dictionary of resources associated with provided (prefix, group, version)\"\"\"\n\n        resources = defaultdict(list)\n        subresources = {}\n\n        path = '/'.join(filter(None, [prefix, group, version]))\n        resources_response = load_json(self.client.request('GET', path))['resources']\n\n        resources_raw = list(filter(lambda resource: '/' not in resource['name'], resources_response))\n        subresources_raw = list(filter(lambda resource: '/' in resource['name'], resources_response))\n        for subresource in subresources_raw:\n            resource, name = subresource['name'].split('/')\n            if not subresources.get(resource):\n                subresources[resource] = {}\n            subresources[resource][name] = subresource\n\n        for resource in resources_raw:\n            # Prevent duplicate keys\n            for key in ('prefix', 'group', 'api_version', 'client', 'preferred'):\n                resource.pop(key, None)\n\n            resourceobj = Resource(\n                prefix=prefix,\n                group=group,\n                api_version=version,\n                client=self.client,\n                preferred=preferred,\n                subresources=subresources.get(resource['name']),\n                **resource\n            )\n            resources[resource['kind']].append(resourceobj)\n\n            resource_list = ResourceList(self.client, group=group, api_version=version, base_kind=resource['kind'])\n            resources[resource_list.kind].append(resource_list)\n        return resources"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, **kwargs):\n        results = self.search(**kwargs)\n        # If there are multiple matches, prefer exact matches on api_version\n        if len(results) > 1 and kwargs.get('api_version'):\n            results = [\n                result for result in results if result.group_version == kwargs['api_version']\n            ]\n        # If there are multiple matches, prefer non-List kinds\n        if len(results) > 1 and not all([isinstance(x, ResourceList) for x in results]):\n            results = [result for result in results if not isinstance(result, ResourceList)]\n        if len(results) == 1:\n            return results[0]\n        elif not results:\n            raise ResourceNotFoundError('No matches found for {}'.format(kwargs))\n        else:\n            raise ResourceNotUniqueError('Multiple matches found for {}: {}'.format(kwargs, results))", "response": "Search for a resource in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef api_exception(e):\n    _, _, exc_traceback = sys.exc_info()\n    tb = '\\n'.join(traceback.format_tb(exc_traceback))\n    return {\n        400: BadRequestError,\n        401: UnauthorizedError,\n        403: ForbiddenError,\n        404: NotFoundError,\n        405: MethodNotAllowedError,\n        409: ConflictError,\n        410: GoneError,\n        422: UnprocessibleEntityError,\n        429: TooManyRequestsError,\n        500: InternalServerError,\n        503: ServiceUnavailableError,\n        504: ServerTimeoutError,\n    }.get(e.status, DynamicApiError)(e, tb)", "response": "Returns the proper Exception class for the given kubernetes. client. rest. ApiException"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_device(dev):\n    global DEV_IDX, DEFAULT_DEV\n    with DEV_LOCK:\n        for idx in range(len(DEVS)):\n            test_dev = DEVS[idx]\n            if test_dev.dev_name_short == dev.dev_name_short:\n                # This device is already in our list. Delete the old one\n                if test_dev is DEFAULT_DEV:\n                    DEFAULT_DEV = None\n                del DEVS[idx]\n                break\n        if find_device_by_name(dev.name):\n            # This name is taken - make it unique\n            dev.name += '-%d' % DEV_IDX\n        dev.name_path = '/' + dev.name + '/'\n        DEVS.append(dev)\n        DEV_IDX += 1\n        if DEFAULT_DEV is None:\n            DEFAULT_DEV = dev", "response": "Adds a device to the list of devices we know about."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_device_by_name(name):\n    if not name:\n        return DEFAULT_DEV\n    with DEV_LOCK:\n        for dev in DEVS:\n            if dev.name == name:\n                return dev\n    return None", "response": "Tries to find a board by board name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_micropython_usb_device(port):\n    if type(port).__name__ == 'Device':\n        # Assume its a pyudev.device.Device\n        if ('ID_BUS' not in port or port['ID_BUS'] != 'usb' or\n            'SUBSYSTEM' not in port or port['SUBSYSTEM'] != 'tty'):\n            return False\n        usb_id = 'usb vid:pid={}:{}'.format(port['ID_VENDOR_ID'], port['ID_MODEL_ID'])\n    else:\n        # Assume its a port from serial.tools.list_ports.comports()\n        usb_id = port[2].lower()\n    # We don't check the last digit of the PID since there are 3 possible\n    # values.\n    if usb_id.startswith('usb vid:pid=f055:980'):\n        return True\n    # Check for Teensy VID:PID\n    if usb_id.startswith('usb vid:pid=16c0:0483'):\n        return True\n    return False", "response": "Checks a USB device to see if it looks like a MicroPython USB device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_micropython_usb_port(portName):\n    for port in serial.tools.list_ports.comports():\n        if port.device == portName:\n            return is_micropython_usb_device(port)\n    return False", "response": "Checks to see if the given portname is a MicroPython device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef autoconnect():\n    if not USE_AUTOCONNECT:\n        return\n    try:\n        import pyudev\n    except ImportError:\n        return\n    context = pyudev.Context()\n    monitor = pyudev.Monitor.from_netlink(context)\n    connect_thread = threading.Thread(target=autoconnect_thread, args=(monitor,), name='AutoConnect')\n    connect_thread.daemon = True\n    connect_thread.start()", "response": "Sets up a thread to detect when USB devices are plugged and unplugged."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nthreads which detects USB Serial devices connecting and disconnecting.", "response": "def autoconnect_thread(monitor):\n    \"\"\"Thread which detects USB Serial devices connecting and disconnecting.\"\"\"\n    monitor.start()\n    monitor.filter_by('tty')\n\n    epoll = select.epoll()\n    epoll.register(monitor.fileno(), select.POLLIN)\n\n    while True:\n        try:\n            events = epoll.poll()\n        except InterruptedError:\n            continue\n        for fileno, _ in events:\n            if fileno == monitor.fileno():\n                usb_dev = monitor.poll()\n                print('autoconnect: {} action: {}'.format(usb_dev.device_node, usb_dev.action))\n                dev = find_serial_device_by_port(usb_dev.device_node)\n                if usb_dev.action == 'add':\n                    # Try connecting a few times. Sometimes the serial port\n                    # reports itself as busy, which causes the connection to fail.\n                    for i in range(8):\n                        if dev:\n                            connected = connect_serial(dev.port, dev.baud, dev.wait)\n                        elif is_micropython_usb_device(usb_dev):\n                            connected = connect_serial(usb_dev.device_node)\n                        else:\n                            connected = False\n                        if connected:\n                            break\n                        time.sleep(0.25)\n                elif usb_dev.action == 'remove':\n                    print('')\n                    print(\"USB Serial device '%s' disconnected\" % usb_dev.device_node)\n                    if dev:\n                        dev.close()\n                        break"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks all of the serial ports to see if they have a matching VID : PID.", "response": "def autoscan():\n    \"\"\"autoscan will check all of the serial ports to see if they have\n       a matching VID:PID for a MicroPython board.\n    \"\"\"\n    for port in serial.tools.list_ports.comports():\n        if is_micropython_usb_device(port):\n            connect_serial(port[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extra_info(port):\n    extra_items = []\n    if port.manufacturer:\n        extra_items.append(\"vendor '{}'\".format(port.manufacturer))\n    if port.serial_number:\n        extra_items.append(\"serial '{}'\".format(port.serial_number))\n    if port.interface:\n        extra_items.append(\"intf '{}'\".format(port.interface))\n    if extra_items:\n        return ' with ' + ' '.join(extra_items)\n    return ''", "response": "Collects the serial nunber and manufacturer into a string if\n       the fields are available."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listports():\n    detected = False\n    for port in serial.tools.list_ports.comports():\n        detected = True\n        if port.vid:\n            micropythonPort = ''\n            if is_micropython_usb_device(port):\n                micropythonPort = ' *'\n            print('USB Serial Device {:04x}:{:04x}{} found @{}{}\\r'.format(\n                  port.vid, port.pid,\n                  extra_info(port), port.device, micropythonPort))\n        else:\n            print('Serial Device:', port.device)\n    if not detected:\n        print('No serial devices detected')", "response": "listports will display a list of all of the serial ports."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef escape(str):\n    out = ''\n    for char in str:\n        if char in '\\\\ ':\n            out += '\\\\'\n        out += char\n    return out", "response": "Precede all special characters with a backslash."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unescape(str):\n    out = ''\n    prev_backslash = False\n    for char in str:\n        if not prev_backslash and char == '\\\\':\n            prev_backslash = True\n            continue\n        out += char\n        prev_backslash = False\n    return out", "response": "Unescapes the effects of the escape function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an aligned element.", "response": "def align_cell(fmt, elem, width):\n    \"\"\"Returns an aligned element.\"\"\"\n    if fmt == \"<\":\n        return elem + ' ' * (width - len(elem))\n    if fmt == \">\":\n        return ' ' * (width - len(elem)) + elem\n    return elem"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef column_print(fmt, rows, print_func):\n    # Figure out the max width of each column\n    num_cols = len(fmt)\n    width = [max(0 if isinstance(row, str) else len(row[i]) for row in rows)\n             for i in range(num_cols)]\n    for row in rows:\n        if isinstance(row, str):\n            # Print a separator line\n            print_func(' '.join([row * width[i] for i in range(num_cols)]))\n        else:\n            print_func(' '.join([align_cell(fmt[i], row[i], width[i])\n                                 for i in range(num_cols)]))", "response": "Prints a formatted list of rows to a given function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_macthing_files(match):\n    last_slash = match.rfind('/')\n    if last_slash == -1:\n        dirname = '.'\n        match_prefix = match\n        result_prefix = ''\n    else:\n        dirname = match[0:last_slash]\n        match_prefix = match[last_slash + 1:]\n        result_prefix = dirname + '/'\n    return [result_prefix + filename for filename in os.listdir(dirname) if filename.startswith(match_prefix)]", "response": "Finds all of the files which match the given string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_pattern(s):\n    if '{' in s:\n        return None, None  # Unsupported by fnmatch\n    if s and s[0] == '~':\n        s = os.path.expanduser(s)\n    parts = s.split('/')\n    absolute = len(parts) > 1 and not parts[0]\n    if parts[-1] == '':  # # Outcome of trailing /\n        parts = parts[:-1]  # discard\n    if len(parts) == 0:\n        directory = ''\n        pattern = ''\n    else:\n        directory = '/'.join(parts[:-1])\n        pattern = parts[-1]\n    if not is_pattern(directory): # Check for e.g. /abc/*/def\n        if is_pattern(pattern):\n            if not directory:\n                directory = '/' if absolute else '.'\n            return directory, pattern\n    return None, None", "response": "Parse a string such as foo. bar. py and return a directory and pattern."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_pattern(fn):\n    directory, pattern = parse_pattern(fn)\n    if directory is None:\n        print_err(\"Invalid pattern {}.\".format(fn))\n        return None, None\n    target = resolve_path(directory)\n    mode = auto(get_mode, target)\n    if not mode_exists(mode):\n        print_err(\"cannot access '{}': No such file or directory\".format(fn))\n        return None, None\n    if not mode_isdir(mode):\n        print_err(\"cannot access '{}': Not a directory\".format(fn))\n        return None, None\n    return target, pattern", "response": "Validate a pattern and return a absolute path and pattern."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_pattern(fn):\n    directory, pattern = validate_pattern(fn)\n    if directory is not None:\n        filenames = fnmatch.filter(auto(listdir, directory), pattern)\n        if filenames:\n            return [directory + '/' + sfn for sfn in filenames]\n        else:\n            print_err(\"cannot access '{}': No such file or directory\".format(fn))", "response": "Return a list of paths matching a pattern."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve_path(path):\n    if path[0] == '~':\n        # ~ or ~user\n        path = os.path.expanduser(path)\n    if path[0] != '/':\n        # Relative path\n        if cur_dir[-1] == '/':\n            path = cur_dir + path\n        else:\n            path = cur_dir + '/' + path\n    comps = path.split('/')\n    new_comps = []\n    for comp in comps:\n        # We strip out xxx/./xxx and xxx//xxx, except that we want to keep the\n        # leading / for absolute paths. This also removes the trailing slash\n        # that autocompletion adds to a directory.\n        if comp == '.' or (comp == '' and len(new_comps) > 0):\n            continue\n        if comp == '..':\n            if len(new_comps) > 1:\n                new_comps.pop()\n        else:\n            new_comps.append(comp)\n    if len(new_comps) == 1 and new_comps[0] == '':\n        return '/'\n    return '/'.join(new_comps)", "response": "Resolves path and converts it into an absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if a given file is located locally or remotely.", "response": "def get_dev_and_path(filename):\n    \"\"\"Determines if a given file is located locally or remotely. We assume\n       that any directories from the pyboard take precedence over local\n       directories of the same name. /flash and /sdcard are associated with\n       the default device. /dev_name/path where dev_name is the name of a\n       given device is also considered to be associated with the named device.\n\n       If the file is associated with a remote device, then this function\n       returns a tuple (dev, dev_filename) where dev is the device and\n       dev_filename is the portion of the filename relative to the device.\n\n       If the file is not associated with the remote device, then the dev\n       portion of the returned tuple will be None.\n    \"\"\"\n    if DEFAULT_DEV:\n        if DEFAULT_DEV.is_root_path(filename):\n            return (DEFAULT_DEV, filename)\n    test_filename = filename + '/'\n    with DEV_LOCK:\n        for dev in DEVS:\n            if test_filename.startswith(dev.name_path):\n                dev_filename = filename[len(dev.name_path)-1:]\n                if dev_filename == '':\n                    dev_filename = '/'\n                return (dev, dev_filename)\n    return (None, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_bytes(byte_str):\n    if isinstance(byte_str, str):\n        print(byte_str)\n    else:\n        print(str(byte_str, encoding='utf8'))", "response": "Prints a string or converts bytes to a string and then prints."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extra_funcs(*funcs):\n  def extra_funcs_decorator(real_func):\n    def wrapper(*args, **kwargs):\n      return real_func(*args, **kwargs)\n    wrapper.extra_funcs = list(funcs)\n    wrapper.source = inspect.getsource(real_func)\n    wrapper.name = real_func.__name__\n    return wrapper\n  return extra_funcs_decorator", "response": "Decorator which adds extra functions to be downloaded to the pyboard."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auto(func, filename, *args, **kwargs):\n    dev, dev_filename = get_dev_and_path(filename)\n    if dev is None:\n        if len(dev_filename) > 0 and dev_filename[0] == '~':\n            dev_filename = os.path.expanduser(dev_filename)\n        return func(dev_filename, *args, **kwargs)\n    return dev.remote_eval(func, dev_filename, *args, **kwargs)", "response": "Auto - calls func on the local file or locally on the remote board."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the boards name if available.", "response": "def board_name(default):\n    \"\"\"Returns the boards name (if available).\"\"\"\n    try:\n        import board\n        try:\n            name = board.name\n        except AttributeError:\n            # There was a board.py file, but it didn't have an name attribute\n            # We also ignore this as an error\n            name = default\n    except ImportError:\n        # No board.py file on the pyboard - not an error\n        name = default\n    except BaseException as err:\n        print('Error encountered executing board.py')\n        import sys\n        sys.print_exception(err)\n        name = default\n    return repr(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopies the contents of the indicated file to an already opened file.", "response": "def cat(src_filename, dst_file):\n    \"\"\"Copies the contents of the indicated file to an already opened file.\"\"\"\n    (dev, dev_filename) = get_dev_and_path(src_filename)\n    if dev is None:\n        with open(dev_filename, 'rb') as txtfile:\n            for line in txtfile:\n                dst_file.write(line)\n    else:\n        filesize = dev.remote_eval(get_filesize, dev_filename)\n        return dev.remote(send_file_to_host, dev_filename, dst_file, filesize,\n                          xfer_func=recv_file_from_remote)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy a file from one place to another.", "response": "def copy_file(src_filename, dst_filename):\n    \"\"\"Copies a file from one place to another. Both the source and destination\n       files must exist on the same machine.\n    \"\"\"\n    try:\n        with open(src_filename, 'rb') as src_file:\n            with open(dst_filename, 'wb') as dst_file:\n                while True:\n                    buf = src_file.read(BUFFER_SIZE)\n                    if len(buf) > 0:\n                        dst_file.write(buf)\n                    if len(buf) < BUFFER_SIZE:\n                        break\n        return True\n    except:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies one file to another.", "response": "def cp(src_filename, dst_filename):\n    \"\"\"Copies one file to another. The source file may be local or remote and\n       the destination file may be local or remote.\n    \"\"\"\n    src_dev, src_dev_filename = get_dev_and_path(src_filename)\n    dst_dev, dst_dev_filename = get_dev_and_path(dst_filename)\n    if src_dev is dst_dev:\n        # src and dst are either on the same remote, or both are on the host\n        return auto(copy_file, src_filename, dst_dev_filename)\n\n    filesize = auto(get_filesize, src_filename)\n\n    if dst_dev is None:\n        # Copying from remote to host\n        with open(dst_dev_filename, 'wb') as dst_file:\n            return src_dev.remote(send_file_to_host, src_dev_filename, dst_file,\n                                  filesize, xfer_func=recv_file_from_remote)\n    if src_dev is None:\n        # Copying from host to remote\n        with open(src_dev_filename, 'rb') as src_file:\n            return dst_dev.remote(recv_file_from_host, src_file, dst_dev_filename,\n                                  filesize, xfer_func=send_file_to_remote)\n\n    # Copying from remote A to remote B. We first copy the file\n    # from remote A to the host and then from the host to remote B\n    host_temp_file = tempfile.TemporaryFile()\n    if src_dev.remote(send_file_to_host, src_dev_filename, host_temp_file,\n                      filesize, xfer_func=recv_file_from_remote):\n        host_temp_file.seek(0)\n        return dst_dev.remote(recv_file_from_host, host_temp_file, dst_dev_filename,\n                              filesize, xfer_func=send_file_to_remote)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning os. stat for a given file adjusting the timestamps as appropriate.", "response": "def stat(filename):\n    \"\"\"Returns os.stat for a given file, adjusting the timestamps as appropriate.\"\"\"\n    import os\n    try:\n        # on the host, lstat won't try to follow symlinks\n        rstat = os.lstat(filename)\n    except:\n        rstat = os.stat(filename)\n    return rstat[:7] + tuple(tim + TIME_OFFSET for tim in rstat[7:])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef listdir_matches(match):\n    import os\n    last_slash = match.rfind('/')\n    if last_slash == -1:\n        dirname = '.'\n        match_prefix = match\n        result_prefix = ''\n    else:\n        match_prefix = match[last_slash + 1:]\n        if last_slash == 0:\n            dirname = '/'\n            result_prefix = '/'\n        else:\n            dirname = match[0:last_slash]\n            result_prefix = dirname + '/'\n    def add_suffix_if_dir(filename):\n        try:\n            if (os.stat(filename)[0] & 0x4000) != 0:\n                return filename + '/'\n        except FileNotFoundError:\n            # This can happen when a symlink points to a non-existant file.\n            pass\n        return filename\n    matches = [add_suffix_if_dir(result_prefix + filename)\n               for filename in os.listdir(dirname) if filename.startswith(match_prefix)]\n    return matches", "response": "Returns a list of filenames contained in the named directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of tuples for each file contained in the named directory.", "response": "def listdir_stat(dirname, show_hidden=True):\n    \"\"\"Returns a list of tuples for each file contained in the named\n       directory, or None if the directory does not exist. Each tuple\n       contains the filename, followed by the tuple returned by\n       calling os.stat on the filename.\n    \"\"\"\n    import os\n    try:\n        files = os.listdir(dirname)\n    except OSError:\n        return None\n    if dirname == '/':\n        return list((file, stat('/' + file)) for file in files if is_visible(file) or show_hidden)\n    return list((file, stat(dirname + '/' + file)) for file in files if is_visible(file) or show_hidden)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_file(filename, recursive=False, force=False):\n    import os\n    try:\n        mode = os.stat(filename)[0]\n        if mode & 0x4000 != 0:\n            # directory\n            if recursive:\n                for file in os.listdir(filename):\n                    success = remove_file(filename + '/' + file, recursive, force)\n                    if not success and not force:\n                        return False\n                os.rmdir(filename) # PGH Work like Unix: require recursive\n            else:\n                if not force:\n                    return False\n        else:\n            os.remove(filename)\n    except:\n        if not force:\n            return False\n    return True", "response": "Removes a file or directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rm(filename, recursive=False, force=False):\n    return auto(remove_file, filename, recursive, force)", "response": "Removes a file or directory tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_dir(dst_dir, dry_run, print_func, recursed):\n    parent = os.path.split(dst_dir.rstrip('/'))[0] # Check for nonexistent parent\n    parent_files = auto(listdir_stat, parent) if parent else True # Relative dir\n    if dry_run:\n        if recursed: # Assume success: parent not actually created yet\n            print_func(\"Creating directory {}\".format(dst_dir))\n        elif parent_files is None:\n            print_func(\"Unable to create {}\".format(dst_dir))\n        return True\n    if not mkdir(dst_dir):\n        print_err(\"Unable to create {}\".format(dst_dir))\n        return False\n    return True", "response": "Creates a directory. Produces information in case of dry run. Issues error where necessary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsynchronizing 2 directory trees.", "response": "def rsync(src_dir, dst_dir, mirror, dry_run, print_func, recursed, sync_hidden):\n    \"\"\"Synchronizes 2 directory trees.\"\"\"\n    # This test is a hack to avoid errors when accessing /flash. When the\n    # cache synchronisation issue is solved it should be removed\n    if not isinstance(src_dir, str) or not len(src_dir):\n        return\n\n    sstat = auto(get_stat, src_dir)\n    smode = stat_mode(sstat)\n    if mode_isfile(smode):\n        print_err('Source is a file not a directory.')\n        return\n\n    d_src = {}  # Look up stat tuple from name in current directory\n    src_files = auto(listdir_stat, src_dir, show_hidden=sync_hidden)\n    if src_files is None:\n        print_err('Source directory {} does not exist.'.format(src_dir))\n        return\n    for name, stat in src_files:\n        d_src[name] = stat\n\n    d_dst = {}\n    dst_files = auto(listdir_stat, dst_dir, show_hidden=sync_hidden)\n    if dst_files is None: # Directory does not exist\n        if not make_dir(dst_dir, dry_run, print_func, recursed):\n            return\n    else: # dest exists\n        for name, stat in dst_files:\n            d_dst[name] = stat\n\n    set_dst = set(d_dst.keys())\n    set_src = set(d_src.keys())\n    to_add = set_src - set_dst  # Files to copy to dest\n    to_del = set_dst - set_src  # To delete from dest\n    to_upd = set_dst.intersection(set_src) # In both: may need updating\n\n    for src_basename in to_add:  # Name in source but absent from destination\n        src_filename = src_dir + '/' + src_basename\n        dst_filename = dst_dir + '/' + src_basename\n        print_func(\"Adding %s\" % dst_filename)\n        src_stat = d_src[src_basename]\n        src_mode = stat_mode(src_stat)\n        if not dry_run:\n            if not mode_isdir(src_mode):\n                cp(src_filename, dst_filename)\n        if mode_isdir(src_mode):\n            rsync(src_filename, dst_filename, mirror=mirror, dry_run=dry_run,\n                  print_func=print_func, recursed=True, sync_hidden=sync_hidden)\n\n    if mirror:  # May delete\n        for dst_basename in to_del:  # In dest but not in source\n            dst_filename = dst_dir + '/' + dst_basename\n            print_func(\"Removing %s\" % dst_filename)\n            if not dry_run:\n                rm(dst_filename, recursive=True, force=True)\n\n    for src_basename in to_upd:  # Names are identical\n        src_stat = d_src[src_basename]\n        dst_stat = d_dst[src_basename]\n        src_filename = src_dir + '/' + src_basename\n        dst_filename = dst_dir + '/' + src_basename\n        src_mode = stat_mode(src_stat)\n        dst_mode = stat_mode(dst_stat)\n        if mode_isdir(src_mode):\n            if mode_isdir(dst_mode):\n                # src and dst are both directories - recurse\n                rsync(src_filename, dst_filename, mirror=mirror, dry_run=dry_run,\n                      print_func=print_func, recursed=True, sync_hidden=sync_hidden)\n            else:\n                msg = \"Source '{}' is a directory and destination \" \\\n                      \"'{}' is a file. Ignoring\"\n                print_err(msg.format(src_filename, dst_filename))\n        else:\n            if mode_isdir(dst_mode):\n                msg = \"Source '{}' is a file and destination \" \\\n                      \"'{}' is a directory. Ignoring\"\n                print_err(msg.format(src_filename, dst_filename))\n            else:\n                if stat_mtime(src_stat) > stat_mtime(dst_stat):\n                    msg = \"{} is newer than {} - copying\"\n                    print_func(msg.format(src_filename, dst_filename))\n                    if not dry_run:\n                        cp(src_filename, dst_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning which runs on the pyboard. Matches up with send_file_to_remote.", "response": "def recv_file_from_host(src_file, dst_filename, filesize, dst_mode='wb'):\n    \"\"\"Function which runs on the pyboard. Matches up with send_file_to_remote.\"\"\"\n    import sys\n    import ubinascii\n    if HAS_BUFFER:\n        try:\n            import pyb\n            usb = pyb.USB_VCP()\n        except:\n            try:\n                import machine\n                usb = machine.USB_VCP()\n            except:\n                usb = None\n        if usb and usb.isconnected():\n            # We don't want 0x03 bytes in the data to be interpreted as a Control-C\n            # This gets reset each time the REPL runs a line, so we don't need to\n            # worry about resetting it ourselves\n            usb.setinterrupt(-1)\n    try:\n        with open(dst_filename, dst_mode) as dst_file:\n            bytes_remaining = filesize\n            if not HAS_BUFFER:\n                bytes_remaining *= 2  # hexlify makes each byte into 2\n            buf_size = BUFFER_SIZE\n            write_buf = bytearray(buf_size)\n            read_buf = bytearray(buf_size)\n            while bytes_remaining > 0:\n                # Send back an ack as a form of flow control\n                sys.stdout.write('\\x06')\n                read_size = min(bytes_remaining, buf_size)\n                buf_remaining = read_size\n                buf_index = 0\n                while buf_remaining > 0:\n                    if HAS_BUFFER:\n                        bytes_read = sys.stdin.buffer.readinto(read_buf, read_size)\n                    else:\n                        bytes_read = sys.stdin.readinto(read_buf, read_size)\n                    if bytes_read > 0:\n                        write_buf[buf_index:bytes_read] = read_buf[0:bytes_read]\n                        buf_index += bytes_read\n                        buf_remaining -= bytes_read\n                if HAS_BUFFER:\n                    dst_file.write(write_buf[0:read_size])\n                else:\n                    dst_file.write(ubinascii.unhexlify(write_buf[0:read_size]))\n                bytes_remaining -= read_size\n        return True\n    except:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_file_to_remote(dev, src_file, dst_filename, filesize, dst_mode='wb'):\n    bytes_remaining = filesize\n    save_timeout = dev.timeout\n    dev.timeout = 1\n    while bytes_remaining > 0:\n        # Wait for ack so we don't get too far ahead of the remote\n        ack = dev.read(1)\n        if ack is None or ack != b'\\x06':\n            sys.stderr.write(\"timed out or error in transfer to remote\\n\")\n            sys.exit(2)\n\n        if HAS_BUFFER:\n            buf_size = BUFFER_SIZE\n        else:\n            buf_size = BUFFER_SIZE // 2\n        read_size = min(bytes_remaining, buf_size)\n        buf = src_file.read(read_size)\n        #sys.stdout.write('\\r%d/%d' % (filesize - bytes_remaining, filesize))\n        #sys.stdout.flush()\n        if HAS_BUFFER:\n            dev.write(buf)\n        else:\n            dev.write(binascii.hexlify(buf))\n        bytes_remaining -= read_size\n    #sys.stdout.write('\\r')\n    dev.timeout = save_timeout", "response": "Send a file to the remote."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nintend to be passed to the `remote` function as the xfer_func argument. Matches up with send_file_to_host.", "response": "def recv_file_from_remote(dev, src_filename, dst_file, filesize):\n    \"\"\"Intended to be passed to the `remote` function as the xfer_func argument.\n       Matches up with send_file_to_host.\n    \"\"\"\n    bytes_remaining = filesize\n    if not HAS_BUFFER:\n        bytes_remaining *= 2  # hexlify makes each byte into 2\n    buf_size = BUFFER_SIZE\n    write_buf = bytearray(buf_size)\n    while bytes_remaining > 0:\n        read_size = min(bytes_remaining, buf_size)\n        buf_remaining = read_size\n        buf_index = 0\n        while buf_remaining > 0:\n            read_buf = dev.read(buf_remaining)\n            bytes_read = len(read_buf)\n            if bytes_read:\n                write_buf[buf_index:bytes_read] = read_buf[0:bytes_read]\n                buf_index += bytes_read\n                buf_remaining -= bytes_read\n        if HAS_BUFFER:\n            dst_file.write(write_buf[0:read_size])\n        else:\n            dst_file.write(binascii.unhexlify(write_buf[0:read_size]))\n        # Send an ack to the remote as a form of flow control\n        dev.write(b'\\x06')   # ASCII ACK is 0x06\n        bytes_remaining -= read_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions which runs on the pyboard. Matches up with recv_file_from_remote.", "response": "def send_file_to_host(src_filename, dst_file, filesize):\n    \"\"\"Function which runs on the pyboard. Matches up with recv_file_from_remote.\"\"\"\n    import sys\n    import ubinascii\n    try:\n        with open(src_filename, 'rb') as src_file:\n            bytes_remaining = filesize\n            if HAS_BUFFER:\n                buf_size = BUFFER_SIZE\n            else:\n                buf_size = BUFFER_SIZE // 2\n            while bytes_remaining > 0:\n                read_size = min(bytes_remaining, buf_size)\n                buf = src_file.read(read_size)\n                if HAS_BUFFER:\n                    sys.stdout.buffer.write(buf)\n                else:\n                    sys.stdout.write(ubinascii.hexlify(buf))\n                bytes_remaining -= read_size\n                # Wait for an ack so we don't get ahead of the remote\n                while True:\n                    char = sys.stdin.read(1)\n                    if char:\n                        if char == '\\x06':\n                            break\n                        # This should only happen if an error occurs\n                        sys.stdout.write(char)\n        return True\n    except:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_cols(words, print_func, termwidth=79):\n    width = max([word_len(word) for word in words])\n    nwords = len(words)\n    ncols = max(1, (termwidth + 1) // (width + 1))\n    nrows = (nwords + ncols - 1) // ncols\n    for row in range(nrows):\n        for i in range(row, nwords, nrows):\n            word = words[i]\n            if word[0] == '\\x1b':\n                print_func('%-*s' % (width + 11, words[i]),\n                           end='\\n' if i + nrows >= nwords else ' ')\n            else:\n                print_func('%-*s' % (width, words[i]),\n                           end='\\n' if i + nrows >= nwords else ' ')", "response": "Takes a single column of words and prints it as multiple columns."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decorated_filename(filename, stat):\n    mode = stat[0]\n    if mode_isdir(mode):\n        return DIR_COLOR + filename + END_COLOR + '/'\n    if mode_issymlink(mode):\n        return filename + '@'\n    if filename.endswith('.py'):\n        return PY_COLOR + filename + END_COLOR\n    return filename", "response": "Takes a filename and the stat info and returns the decorated filename."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_long(filename, stat, print_func):\n    size = stat_size(stat)\n    mtime = stat_mtime(stat)\n    file_mtime = time.localtime(mtime)\n    curr_time = time.time()\n    if mtime > (curr_time + SIX_MONTHS) or mtime < (curr_time - SIX_MONTHS):\n        print_func('%6d %s %2d %04d  %s' % (size, MONTH[file_mtime[1]],\n                                            file_mtime[2], file_mtime[0],\n                                            decorated_filename(filename, stat)))\n    else:\n        print_func('%6d %s %2d %02d:%02d %s' % (size, MONTH[file_mtime[1]],\n                                                file_mtime[2], file_mtime[3], file_mtime[4],\n                                                decorated_filename(filename, stat)))", "response": "Prints detailed information about the file passed in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(port, baud=115200, user='micro', password='python', wait=0):\n    try:\n        ip_address = socket.gethostbyname(port)\n        #print('Connecting to ip', ip_address)\n        connect_telnet(port, ip_address, user=user, password=password)\n    except socket.gaierror:\n        # Doesn't look like a hostname or IP-address, assume its a serial port\n        #print('connecting to serial', port)\n        connect_serial(port, baud=baud, wait=wait)", "response": "Tries to connect automagically via network or serial."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to a MicroPython board via telnet.", "response": "def connect_telnet(name, ip_address=None, user='micro', password='python'):\n    \"\"\"Connect to a MicroPython board via telnet.\"\"\"\n    if ip_address is None:\n        try:\n            ip_address = socket.gethostbyname(name)\n        except socket.gaierror:\n            ip_address = name\n    if not QUIET:\n        if name == ip_address:\n            print('Connecting to (%s) ...' % ip_address)\n        else:\n            print('Connecting to %s (%s) ...' % (name, ip_address))\n    dev = DeviceNet(name, ip_address, user, password)\n    add_device(dev)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect_serial(port, baud=115200, wait=0):\n    if not QUIET:\n        print('Connecting to %s (buffer-size %d)...' % (port, BUFFER_SIZE))\n    try:\n        dev = DeviceSerial(port, baud, wait)\n    except DeviceError as err:\n        sys.stderr.write(str(err))\n        sys.stderr.write('\\n')\n        return False\n    add_device(dev)\n    return True", "response": "Connect to a MicroPython board via a serial port."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef real_main():\n    global RTS\n    global DTR\n    try:\n        default_baud = int(os.getenv('RSHELL_BAUD'))\n    except:\n        default_baud = 115200\n    default_port = os.getenv('RSHELL_PORT')\n    default_rts = os.getenv('RSHELL_RTS') or RTS\n    default_dtr = os.getenv('RSHELL_DTR') or DTR\n    default_user = os.getenv('RSHELL_USER') or 'micro'\n    default_password = os.getenv('RSHELL_PASSWORD') or 'python'\n    default_editor = os.getenv('RSHELL_EDITOR') or os.getenv('VISUAL') or os.getenv('EDITOR') or 'vi'\n    global BUFFER_SIZE\n    try:\n        default_buffer_size = int(os.getenv('RSHELL_BUFFER_SIZE'))\n    except:\n        default_buffer_size = BUFFER_SIZE\n    parser = argparse.ArgumentParser(\n        prog=\"rshell\",\n        usage=\"%(prog)s [options] [command]\",\n        description=\"Remote Shell for a MicroPython board.\",\n        epilog=(\"You can specify the default serial port using the \" +\n                \"RSHELL_PORT environment variable.\")\n    )\n    parser.add_argument(\n        \"-b\", \"--baud\",\n        dest=\"baud\",\n        action=\"store\",\n        type=int,\n        help=\"Set the baudrate used (default = %d)\" % default_baud,\n        default=default_baud\n    )\n    parser.add_argument(\n        \"--buffer-size\",\n        dest=\"buffer_size\",\n        action=\"store\",\n        type=int,\n        help=\"Set the buffer size used for transfers \"\n             \"(default = %d for USB, %d for UART)\" %\n             (USB_BUFFER_SIZE, UART_BUFFER_SIZE),\n    )\n    parser.add_argument(\n        \"-p\", \"--port\",\n        dest=\"port\",\n        help=\"Set the serial port to use (default '%s')\" % default_port,\n        default=default_port\n    )\n    parser.add_argument(\n        \"--rts\",\n        dest=\"rts\",\n        help=\"Set the RTS state (default '%s')\" % default_rts,\n        default=default_rts\n    )\n    parser.add_argument(\n        \"--dtr\",\n        dest=\"dtr\",\n        help=\"Set the DTR state (default '%s')\" % default_dtr,\n        default=default_dtr\n    )\n    parser.add_argument(\n        \"-u\", \"--user\",\n        dest=\"user\",\n        help=\"Set username to use (default '%s')\" % default_user,\n        default=default_user\n    )\n    parser.add_argument(\n        \"-w\", \"--password\",\n        dest=\"password\",\n        help=\"Set password to use (default '%s')\" % default_password,\n        default=default_password\n    )\n    parser.add_argument(\n        \"-e\", \"--editor\",\n        dest=\"editor\",\n        help=\"Set the editor to use (default '%s')\" % default_editor,\n        default=default_editor\n    )\n    parser.add_argument(\n        \"-f\", \"--file\",\n        dest=\"filename\",\n        help=\"Specifies a file of commands to process.\"\n    )\n    parser.add_argument(\n        \"-d\", \"--debug\",\n        dest=\"debug\",\n        action=\"store_true\",\n        help=\"Enable debug features\",\n        default=False\n    )\n    parser.add_argument(\n        \"-n\", \"--nocolor\",\n        dest=\"nocolor\",\n        action=\"store_true\",\n        help=\"Turn off colorized output\",\n        default=False\n    )\n    parser.add_argument(\n        \"-l\", \"--list\",\n        dest=\"list\",\n        action=\"store_true\",\n        help=\"Display serial ports\",\n        default=False\n    )\n    parser.add_argument(\n        \"-a\", \"--ascii\",\n        dest=\"ascii_xfer\",\n        action=\"store_true\",\n        help=\"ASCII encode binary files for transfer\",\n        default=False\n    )\n    parser.add_argument(\n        \"--wait\",\n        dest=\"wait\",\n        type=int,\n        action=\"store\",\n        help=\"Seconds to wait for serial port\",\n        default=0\n    )\n    parser.add_argument(\n        \"--timing\",\n        dest=\"timing\",\n        action=\"store_true\",\n        help=\"Print timing information about each command\",\n        default=False\n    )\n    parser.add_argument(\n        '-V', '--version',\n        dest='version',\n        action='store_true',\n        help='Reports the version and exits.',\n        default=False\n    )\n    parser.add_argument(\n        \"--quiet\",\n        dest=\"quiet\",\n        action=\"store_true\",\n        help=\"Turns off some output (useful for testing)\",\n        default=False\n    )\n    parser.add_argument(\n        \"cmd\",\n        nargs=argparse.REMAINDER,\n        help=\"Optional command to execute\"\n    )\n    args = parser.parse_args(sys.argv[1:])\n\n    if args.buffer_size is not None:\n        BUFFER_SIZE = args.buffer_size\n\n    if args.debug:\n        print(\"Debug = %s\" % args.debug)\n        print(\"Port = %s\" % args.port)\n        print(\"Baud = %d\" % args.baud)\n        print(\"User = %s\" % args.user)\n        print(\"Password = %s\" % args.password)\n        print(\"Wait = %d\" % args.wait)\n        print(\"List = %d\" % args.list)\n        print(\"nocolor = %d\" % args.nocolor)\n        print(\"ascii = %d\" % args.ascii_xfer)\n        print(\"Timing = %d\" % args.timing)\n        print(\"Quiet = %d\" % args.quiet)\n        print(\"BUFFER_SIZE = %d\" % BUFFER_SIZE)\n        print(\"Cmd = [%s]\" % ', '.join(args.cmd))\n\n    if args.version:\n        print(__version__)\n        return\n\n    global DEBUG\n    DEBUG = args.debug\n\n    global QUIET\n    QUIET = args.quiet\n\n    global EDITOR\n    EDITOR = args.editor\n\n    if args.nocolor:\n        global DIR_COLOR, PROMPT_COLOR, PY_COLOR, END_COLOR\n        DIR_COLOR = ''\n        PROMPT_COLOR = ''\n        PY_COLOR = ''\n        END_COLOR = ''\n    else:\n        if sys.platform == 'darwin':\n            # The readline that comes with OSX screws up colors in the prompt\n            global FAKE_INPUT_PROMPT\n            FAKE_INPUT_PROMPT = True\n\n    global ASCII_XFER\n    ASCII_XFER = args.ascii_xfer\n    RTS = args.rts\n    DTR = args.dtr\n\n    if args.list:\n        listports()\n        return\n\n    if args.port:\n        ASCII_XFER = True\n        if args.buffer_size is None:\n          if is_micropython_usb_port(args.port):\n              BUFFER_SIZE = USB_BUFFER_SIZE\n          else:\n              BUFFER_SIZE = UART_BUFFER_SIZE\n        QUIET or print('Using buffer-size of', BUFFER_SIZE)\n        try:\n            connect(args.port, baud=args.baud, wait=args.wait, user=args.user, password=args.password)\n        except DeviceError as err:\n            print(err)\n    else:\n        autoscan()\n    autoconnect()\n\n    if args.filename:\n        with open(args.filename) as cmd_file:\n            shell = Shell(stdin=cmd_file, filename=args.filename, timing=args.timing)\n            shell.cmdloop('')\n    else:\n        cmd_line = ' '.join(args.cmd)\n        if cmd_line == '':\n            print('Welcome to rshell.', EXIT_STR)\n        if num_devices() == 0:\n            print('')\n            print('No MicroPython boards connected - use the connect command to add one')\n            print('')\n        shell = Shell(timing=args.timing)\n        try:\n            shell.cmdloop(cmd_line)\n        except KeyboardInterrupt:\n            print('')", "response": "The main function for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self):\n        if self.pyb and self.pyb.serial:\n            self.pyb.serial.close()\n        self.pyb = None", "response": "Closes the serial port."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining if the given filename corresponds to a directory on this device.", "response": "def is_root_path(self, filename):\n        \"\"\"Determines if 'filename' corresponds to a directory on this device.\"\"\"\n        test_filename = filename + '/'\n        for root_dir in self.root_dirs:\n            if test_filename.startswith(root_dir):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, num_bytes):\n        self.check_pyb()\n        try:\n            return self.pyb.serial.read(num_bytes)\n        except (serial.serialutil.SerialException, TypeError):\n            # Write failed - assume that we got disconnected\n            self.close()\n            raise DeviceError('serial port %s closed' % self.dev_name_short)", "response": "Reads data from the pyboard over the serial port."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remote(self, func, *args, xfer_func=None, **kwargs):\n        global HAS_BUFFER\n        HAS_BUFFER = self.has_buffer\n        if hasattr(func, 'extra_funcs'):\n          func_name = func.name\n          func_lines = []\n          for extra_func in func.extra_funcs:\n            func_lines += inspect.getsource(extra_func).split('\\n')\n            func_lines += ['']\n          func_lines += filter(lambda line: line[:1] != '@', func.source.split('\\n'))\n          func_src = '\\n'.join(func_lines)\n        else:\n          func_name = func.__name__\n          func_src = inspect.getsource(func)\n        args_arr = [remote_repr(i) for i in args]\n        kwargs_arr = [\"{}={}\".format(k, remote_repr(v)) for k, v in kwargs.items()]\n        func_src += 'output = ' + func_name + '('\n        func_src += ', '.join(args_arr + kwargs_arr)\n        func_src += ')\\n'\n        func_src += 'if output is None:\\n'\n        func_src += '    print(\"None\")\\n'\n        func_src += 'else:\\n'\n        func_src += '    print(output)\\n'\n        time_offset = self.time_offset\n        if self.adjust_for_timezone:\n          time_offset -= time.localtime().tm_gmtoff\n        func_src = func_src.replace('TIME_OFFSET', '{}'.format(time_offset))\n        func_src = func_src.replace('HAS_BUFFER', '{}'.format(HAS_BUFFER))\n        func_src = func_src.replace('BUFFER_SIZE', '{}'.format(BUFFER_SIZE))\n        func_src = func_src.replace('IS_UPY', 'True')\n        if DEBUG:\n            print('----- About to send %d bytes of code to the pyboard -----' % len(func_src))\n            print(func_src)\n            print('-----')\n        self.check_pyb()\n        try:\n            self.pyb.enter_raw_repl()\n            self.check_pyb()\n            output = self.pyb.exec_raw_no_follow(func_src)\n            if xfer_func:\n                xfer_func(self, *args, **kwargs)\n            self.check_pyb()\n            output, _ = self.pyb.follow(timeout=20)\n            self.check_pyb()\n            self.pyb.exit_raw_repl()\n        except (serial.serialutil.SerialException, TypeError):\n            self.close()\n            raise DeviceError('serial port %s closed' % self.dev_name_short)\n        if DEBUG:\n            print('-----Response-----')\n            print(output)\n            print('-----')\n        return output", "response": "Calls func with the indicated args on the micropython board."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remote_eval(self, func, *args, **kwargs):\n        return eval(self.remote(func, *args, **kwargs))", "response": "Calls func with the indicated args on the micropython board and returns the result as python object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall func with the indicated args on the micropython board and returns the result as a python tuple.", "response": "def remote_eval_last(self, func, *args, **kwargs):\n        \"\"\"Calls func with the indicated args on the micropython board, and\n           converts the response back into python by using eval.\n        \"\"\"\n        result = self.remote(func, *args, **kwargs).split(b'\\r\\n')\n        messages = result[0:-2]\n        messages = b'\\n'.join(messages).decode('utf-8')\n        return (eval(result[-2]), messages)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the time on the pyboard to match the time on the host.", "response": "def sync_time(self):\n        \"\"\"Sets the time on the pyboard to match the time on the host.\"\"\"\n        now = time.localtime(time.time())\n        self.remote(set_time, (now.tm_year, now.tm_mon, now.tm_mday, now.tm_wday + 1,\n                               now.tm_hour, now.tm_min, now.tm_sec, 0))\n        return now"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting data to the pyboard over the serial port.", "response": "def write(self, buf):\n        \"\"\"Writes data to the pyboard over the serial port.\"\"\"\n        self.check_pyb()\n        try:\n            return self.pyb.serial.write(buf)\n        except (serial.serialutil.SerialException, BrokenPipeError, TypeError):\n            # Write failed - assume that we got disconnected\n            self.close()\n            raise DeviceError('{} closed'.format(self.dev_name_short))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the timeout associated with the serial port.", "response": "def timeout(self, value):\n        \"\"\"Sets the timeout associated with the serial port.\"\"\"\n        self.check_pyb()\n        try:\n            self.pyb.serial.timeout = value\n        except:\n            # timeout is a property so it calls code, and that can fail\n            # if the serial port is closed.\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef onecmd(self, line):\n        if DEBUG:\n            print('Executing \"%s\"' % line)\n        self.line_num += 1\n        if line == \"EOF\" or line == 'exit':\n            if cmd.Cmd.use_rawinput:\n                # This means that we printed a prompt, and we'll want to\n                # print a newline to pretty things up for the caller.\n                self.print('')\n            return True\n        # Strip comments\n        comment_idx = line.find(\"#\")\n        if comment_idx >= 0:\n            line = line[0:comment_idx]\n            line = line.strip()\n\n        # search multiple commands on the same line\n        lexer = shlex.shlex(line)\n        lexer.whitespace = ''\n\n        for issemicolon, group in itertools.groupby(lexer, lambda x: x == \";\"):\n            if not issemicolon:\n                self.onecmd_exec(\"\".join(group))", "response": "Override onecmd.\n\n        1 - So we don't have to have a do_EOF method.\n        2 - So we can strip comments\n        3 - So we can track line numbers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print(self, *args, end='\\n', file=None):\n        if file is None:\n            file = self.stdout\n        s = ' '.join(str(arg) for arg in args) + end\n        file.write(s)", "response": "Convenience function so you don t need to write the \\ n\n           at the end of the line."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps for catching exceptions since cmd seems to silently silently absorb them.", "response": "def filename_complete(self, text, line, begidx, endidx):\n        \"\"\"Wrapper for catching exceptions since cmd seems to silently\n           absorb them.\n        \"\"\"\n        try:\n            return self.real_filename_complete(text, line, begidx, endidx)\n        except:\n            traceback.print_exc()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef real_filename_complete(self, text, line, begidx, endidx):\n\n        # line contains the full command line that's been entered so far.\n        # text contains the portion of the line that readline is trying to complete\n        # text should correspond to line[begidx:endidx]\n        #\n        # The way the completer works text will start after one of the characters\n        # in DELIMS. So if the filename entered so far was \"embedded\\ sp\" then\n        # text will point to the s in sp.\n        #\n        # The following bit of logic backs up to find the real beginning of the\n        # filename.\n\n        if begidx >= len(line):\n            # This happens when you hit TAB on an empty filename\n            before_match = begidx\n        else:\n            for before_match in range(begidx, 0, -1):\n                if line[before_match] in DELIMS and before_match >= 1 and line[before_match - 1] != '\\\\':\n                    break\n\n        # We set fixed to be the portion of the filename which is before text\n        # and match is the full portion of the filename that's been entered so\n        # far (that's the part we use for matching files).\n        #\n        # When we return a list of completions, the bit that we return should\n        # just be the portion that we replace 'text' with.\n\n        fixed = unescape(line[before_match+1:begidx]) # fixed portion of the match\n        match = unescape(line[before_match+1:endidx]) # portion to match filenames against\n\n        # We do the following to cover the case that the current directory\n        # is / and the path being entered is relative.\n        strip = ''\n        if len(match) > 0 and match[0] == '/':\n            abs_match = match\n        elif cur_dir == '/':\n            abs_match = cur_dir + match\n            strip = cur_dir\n        else:\n            abs_match = cur_dir + '/' + match\n            strip = cur_dir + '/'\n\n        completions = []\n        prepend = ''\n        if abs_match.rfind('/') == 0:  # match is in the root directory\n            # This means that we're looking for matches in the root directory\n            # (i.e. abs_match is /foo and the user hit TAB).\n            # So we'll supply the matching board names as possible completions.\n            # Since they're all treated as directories we leave the trailing slash.\n            with DEV_LOCK:\n                if match[0] == '/':\n                    completions += [dev.name_path for dev in DEVS if dev.name_path.startswith(abs_match)]\n                else:\n                    completions += [dev.name_path[1:] for dev in DEVS if dev.name_path.startswith(abs_match)]\n            if DEFAULT_DEV:\n                # Add root directories of the default device (i.e. /flash/ and /sd/)\n                if match[0] == '/':\n                    completions += [root_dir for root_dir in DEFAULT_DEV.root_dirs if root_dir.startswith(match)]\n                else:\n                    completions += [root_dir[1:] for root_dir in DEFAULT_DEV.root_dirs if root_dir[1:].startswith(match)]\n        else:\n            # This means that there are at least 2 slashes in abs_match. If one\n            # of them matches a board name then we need to remove the board\n            # name from fixed. Since the results from listdir_matches won't\n            # contain the board name, we need to prepend each of the completions.\n            with DEV_LOCK:\n                for dev in DEVS:\n                    if abs_match.startswith(dev.name_path):\n                        prepend = dev.name_path[:-1]\n                        break\n\n        paths = sorted(auto(listdir_matches, abs_match))\n        for path in paths:\n            path = prepend + path\n            if path.startswith(strip):\n                path = path[len(strip):]\n            completions.append(escape(path.replace(fixed, '', 1)))\n        return completions", "response": "Figure out what filenames match the completion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef directory_complete(self, text, line, begidx, endidx):\n        return [filename for filename in self.filename_complete(text, line, begidx, endidx) if filename[-1] == '/']", "response": "Figure out what directories match the completion."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndebugs function for verifying argument parsing. This function just prints out each argument that it receives.", "response": "def do_args(self, line):\n        \"\"\"args [arguments...]\n\n           Debug function for verifying argument parsing. This function just\n           prints out each argument that it receives.\n        \"\"\"\n        args = self.line_to_args(line)\n        for idx in range(len(args)):\n            self.print(\"arg[%d] = '%s'\" % (idx, args[idx]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist the boards that rshell is currently connected to.", "response": "def do_boards(self, _):\n        \"\"\"boards\n\n           Lists the boards that rshell is currently connected to.\n        \"\"\"\n        rows = []\n        with DEV_LOCK:\n            for dev in DEVS:\n                if dev is DEFAULT_DEV:\n                    dirs = [dir[:-1] for dir in dev.root_dirs]\n                else:\n                    dirs = []\n                dirs += ['/{}{}'.format(dev.name, dir)[:-1] for dir in dev.root_dirs]\n                dirs = 'Dirs: ' + ' '.join(dirs)\n                epoch = 'Epoch: {}'.format(time.gmtime(dev.time_offset)[0])\n                rows.append((dev.name, '@ %s' % dev.dev_name_short, dev.status(), epoch, dirs))\n        if rows:\n            column_print('<<<< ', rows, self.print)\n        else:\n            print('No boards connected')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncatting FILENAME... Concatenates files and sends to stdout.", "response": "def do_cat(self, line):\n        \"\"\"cat FILENAME...\n\n           Concatenates files and sends to stdout.\n        \"\"\"\n        # note: when we get around to supporting cat from stdin, we'll need\n        #       to write stdin to a temp file, and then copy the file\n        #       since we need to know the filesize when copying to the pyboard.\n        args = self.line_to_args(line)\n        for filename in args:\n            filename = resolve_path(filename)\n            mode = auto(get_mode, filename)\n            if not mode_exists(mode):\n                print_err(\"Cannot access '%s': No such file\" % filename)\n                continue\n            if not mode_isfile(mode):\n                print_err(\"'%s': is not a file\" % filename)\n                continue\n            cat(filename, self.stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects a pyboard to rshell.", "response": "def do_connect(self, line):\n        \"\"\"connect TYPE TYPE_PARAMS\n           connect serial port [baud]\n           connect telnet ip-address-or-name\n\n           Connects a pyboard to rshell.\n        \"\"\"\n        args = self.line_to_args(line)\n        num_args = len(args)\n        if num_args < 1:\n            print_err('Missing connection TYPE')\n            return\n        connect_type = args[0]\n        if connect_type == 'serial':\n            if num_args < 2:\n                print_err('Missing serial port')\n                return\n            port = args[1]\n            if num_args < 3:\n                baud = 115200\n            else:\n                try:\n                    baud = int(args[2])\n                except ValueError:\n                    print_err(\"Expecting baud to be numeric. Found '{}'\".format(args[2]))\n                    return\n            connect_serial(port, baud)\n        elif connect_type == 'telnet':\n            if num_args < 2:\n                print_err('Missing hostname or ip-address')\n                return\n            name = args[1]\n            connect_telnet(name)\n        else:\n            print_err('Unrecognized connection TYPE: {}'.format(connect_type))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_cp(self, line):\n        args = self.line_to_args(line)\n        if len(args.filenames) < 2:\n            print_err('Missing destination file')\n            return\n        dst_dirname = resolve_path(args.filenames[-1])\n        dst_mode = auto(get_mode, dst_dirname)\n        d_dst = {}  # Destination directory: lookup stat by basename\n        if args.recursive:\n            dst_files = auto(listdir_stat, dst_dirname)\n            if dst_files is None:\n                err = \"cp: target {} is not a directory\"\n                print_err(err.format(dst_dirname))\n                return\n            for name, stat in dst_files:\n                d_dst[name] = stat\n\n        src_filenames = args.filenames[:-1]\n\n        # Process PATTERN\n        sfn = src_filenames[0]\n        if is_pattern(sfn):\n            if len(src_filenames) > 1:\n                print_err(\"Usage: cp [-r] PATTERN DIRECTORY\")\n                return\n            src_filenames = process_pattern(sfn)\n            if src_filenames is None:\n                return\n\n        for src_filename in src_filenames:\n            if is_pattern(src_filename):\n                print_err(\"Only one pattern permitted.\")\n                return\n            src_filename = resolve_path(src_filename)\n            src_mode = auto(get_mode, src_filename)\n            if not mode_exists(src_mode):\n                print_err(\"File '{}' doesn't exist\".format(src_filename))\n                return\n            if mode_isdir(src_mode):\n                if args.recursive: # Copying a directory\n                    src_basename = os.path.basename(src_filename)\n                    dst_filename = dst_dirname + '/' + src_basename\n                    if src_basename in d_dst:\n                        dst_stat = d_dst[src_basename]\n                        dst_mode = stat_mode(dst_stat)\n                        if not mode_isdir(dst_mode):\n                            err = \"Destination {} is not a directory\"\n                            print_err(err.format(dst_filename))\n                            return\n                    else:\n                        if not mkdir(dst_filename):\n                            err = \"Unable to create directory {}\"\n                            print_err(err.format(dst_filename))\n                            return\n\n                    rsync(src_filename, dst_filename, mirror=False, dry_run=False,\n                          print_func=lambda *args: None, recursed=False, sync_hidden=args.all)\n                else:\n                    print_err(\"Omitting directory {}\".format(src_filename))\n                continue\n            if mode_isdir(dst_mode):\n                dst_filename = dst_dirname + '/' + os.path.basename(src_filename)\n            else:\n                dst_filename = dst_dirname\n            if not cp(src_filename, dst_filename):\n                err = \"Unable to copy '{}' to '{}'\"\n                print_err(err.format(src_filename, dst_filename))\n                break", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m cp - cp - cp - r - pattern - pattern - pattern - file - filename - pattern - file - path to the source file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_echo(self, line):\n        args = self.line_to_args(line)\n        self.print(*args)", "response": "Echo a line of text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nedit the file locally launches an editor to edit the file locally.", "response": "def do_edit(self, line):\n        \"\"\"edit FILE\n\n           Copies the file locally, launches an editor to edit the file.\n           When the editor exits, if the file was modified then its copied\n           back.\n\n           You can specify the editor used with the --editor command line\n           option when you start rshell, or by using the VISUAL or EDITOR\n           environment variable. if none of those are set, then vi will be used.\n        \"\"\"\n        if len(line) == 0:\n            print_err(\"Must provide a filename\")\n            return\n        filename = resolve_path(line)\n        dev, dev_filename = get_dev_and_path(filename)\n        mode = auto(get_mode, filename)\n        if mode_exists(mode) and mode_isdir(mode):\n            print_err(\"Unable to edit directory '{}'\".format(filename))\n            return\n        if dev is None:\n            # File is local\n            os.system(\"{} '{}'\".format(EDITOR, filename))\n        else:\n            # File is remote\n            with tempfile.TemporaryDirectory() as temp_dir:\n                local_filename = os.path.join(temp_dir, os.path.basename(filename))\n                if mode_exists(mode):\n                    print('Retrieving {} ...'.format(filename))\n                    cp(filename, local_filename)\n                old_stat = get_stat(local_filename)\n                os.system(\"{} '{}'\".format(EDITOR, local_filename))\n                new_stat = get_stat(local_filename)\n                if old_stat != new_stat:\n                    self.print('Updating {} ...'.format(filename))\n                    cp(local_filename, filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_filetype(self, line):\n        if len(line) == 0:\n            print_err(\"Must provide a filename\")\n            return\n        filename = resolve_path(line)\n        mode = auto(get_mode, filename)\n        if mode_exists(mode):\n            if mode_isdir(mode):\n                self.print('dir')\n            elif mode_isfile(mode):\n                self.print('file')\n            else:\n                self.print('unknown')\n        else:\n            self.print('missing')", "response": "filetype FILE\n            Prints the type of file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhelp [ COMMAND] List available commands with no arguments or detailed help when a command is provided.", "response": "def do_help(self, line):\n        \"\"\"help [COMMAND]\n\n           List available commands with no arguments, or detailed help when\n           a command is provided.\n        \"\"\"\n        # We provide a help function so that we can trim the leading spaces\n        # from the docstrings. The builtin help function doesn't do that.\n        if not line:\n            cmd.Cmd.do_help(self, line)\n            self.print(EXIT_STR)\n            return\n        parser = self.create_argparser(line)\n        if parser:\n            parser.print_help()\n            return\n        try:\n            doc = getattr(self, 'do_' + line).__doc__\n            if doc:\n                self.print(\"%s\" % trim(doc))\n                return\n        except AttributeError:\n            pass\n        self.print(str(self.nohelp % (line,)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun as a thread which reads bytes from the serial port and writes them to stdout.", "response": "def repl_serial_to_stdout(self, dev):\n        \"\"\"Runs as a thread which has a sole purpose of readding bytes from\n           the serial port and writing them to stdout. Used by do_repl.\n        \"\"\"\n        with self.serial_reader_running:\n            try:\n                save_timeout = dev.timeout\n                # Set a timeout so that the read returns periodically with no data\n                # and allows us to check whether the main thread wants us to quit.\n                dev.timeout = 1\n                while not self.quit_serial_reader:\n                    try:\n                        char = dev.read(1)\n                    except serial.serialutil.SerialException:\n                        # This happens if the pyboard reboots, or a USB port\n                        # goes away.\n                        return\n                    except TypeError:\n                        # This is a bug in serialposix.py starting with python 3.3\n                        # which causes a TypeError during the handling of the\n                        # select.error. So we treat this the same as\n                        # serial.serialutil.SerialException:\n                        return\n                    except ConnectionResetError:\n                        # This happens over a telnet session, if it resets\n                        return\n                    if not char:\n                        # This means that the read timed out. We'll check the quit\n                        # flag and return if needed\n                        if self.quit_when_no_output:\n                            break\n                        continue\n                    self.stdout.write(char)\n                    self.stdout.flush()\n                dev.timeout = save_timeout\n            except DeviceError:\n                # The device is no longer present.\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_rm(self, line):\n        args = self.line_to_args(line)\n        filenames = args.filename\n        # Process PATTERN\n        sfn = filenames[0]\n        if is_pattern(sfn):\n            if len(filenames) > 1:\n                print_err(\"Usage: rm [-r] [-f] PATTERN\")\n                return\n            filenames = process_pattern(sfn)\n            if filenames is None:\n                return\n\n        for filename in filenames:\n            filename = resolve_path(filename)\n            if not rm(filename, recursive=args.recursive, force=args.force):\n                if not args.force:\n                    print_err(\"Unable to remove '{}'\".format(filename))\n                break", "response": "Remove one or more files or directories and directories and return a list of the ID s that were removed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the status of the ISO.", "response": "def set_status(self, value):\n        \"\"\"\n        Set the status of the motor to the specified value if not already set.\n        \"\"\"\n        if not self._status == value:\n            old = self._status\n            self._status = value\n            logger.info(\"{} changing status from {} to {}\".format(self, old.name, value.name))\n            self._statusChanged(old, value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self, *args, **kwargs):\n        if self.status in (Status.stopping, Status.stopped):\n            logger.debug(\"{} is already {}\".format(self, self.status.name))\n        else:\n            self.status = Status.stopping\n            self.onStopping(*args, **kwargs)\n            self.status = Status.stopped", "response": "Set the status to Status.stopping and also call `onStopping`\n        with the provided args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the name and corresponding instance name of the next node which is supposed to be a new Primary.", "response": "def next_primary_replica_name_for_master(self, node_reg, node_ids):\n        \"\"\"\n        Returns name and corresponding instance name of the next node which\n        is supposed to be a new Primary. In fact it is not round-robin on\n        this abstraction layer as currently the primary of master instance is\n        pointed directly depending on view number, instance id and total\n        number of nodes.\n        But since the view number is incremented by 1 before primary selection\n        then current approach may be treated as round robin.\n        \"\"\"\n        name = self._next_primary_node_name_for_master(node_reg, node_ids)\n        return name, Replica.generateName(nodeName=name, instId=0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef next_primary_replica_name_for_backup(self, instance_id, master_primary_rank,\n                                             primaries, node_reg, node_ids):\n        \"\"\"\n        Returns name and corresponding instance name of the next node which\n        is supposed to be a new Primary for backup instance in round-robin\n        fashion starting from primary of master instance.\n        \"\"\"\n        if node_reg is None:\n            node_reg = self.node.nodeReg\n        total_nodes = len(node_reg)\n        rank = (master_primary_rank + 1) % total_nodes\n        name = self.node.get_name_by_rank(rank, node_reg, node_ids)\n        while name in primaries:\n            rank = (rank + 1) % total_nodes\n            name = self.node.get_name_by_rank(rank, node_reg, node_ids)\n        return name, Replica.generateName(nodeName=name, instId=instance_id)", "response": "Returns the name and corresponding instance name of the next primary node which is supposed to be a new Primary for backup instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the selection of the current view_no_cluster and return the set of names of primaries that are used for the current view_no_cluster.", "response": "def process_selection(self, instance_count, node_reg, node_ids):\n        # Select primaries for current view_no\n        if instance_count == 0:\n            return []\n\n        '''\n        Build a set of names of primaries, it is needed to avoid\n        duplicates of primary nodes for different replicas.\n        '''\n\n        primaries = []\n        primary_rank = None\n\n        for i in range(instance_count):\n            if i == 0:\n                primary_name = self._next_primary_node_name_for_master(node_reg, node_ids)\n                primary_rank = self.node.get_rank_by_name(primary_name, node_reg, node_ids)\n                if primary_rank is None:\n                    raise LogicError('primary_rank must not be None')\n            else:\n                primary_name, _ = self.next_primary_replica_name_for_backup(\n                    i, primary_rank, primaries, node_reg, node_ids)\n\n            primaries.append(primary_name)\n            logger.display(\"{} selected primary {} for instance {} (view {})\"\n                           .format(PRIMARY_SELECTION_PREFIX,\n                                   primary_name, i, self.viewNo),\n                           extra={\"cli\": \"ANNOUNCE\",\n                                  \"tags\": [\"node-election\"]})\n        if len(primaries) != instance_count:\n            raise LogicError('instances inconsistency')\n\n        if len(primaries) != len(set(primaries)):\n            raise LogicError('repeating instances')\n\n        return primaries"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncounts the number of stewards added to the pool transaction store", "response": "def countStewards(self) -> int:\n        \"\"\"\n        Count the number of stewards added to the pool transaction store\n        Note: This is inefficient, a production use case of this function\n        should require an efficient storage mechanism\n        \"\"\"\n        # THIS SHOULD NOT BE DONE FOR PRODUCTION\n        return sum(1 for _, txn in self.ledger.getAllTxn() if\n                   (get_type(txn) == NYM) and (get_payload_data(txn).get(ROLE) == STEWARD))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a value for the given path in state trie.", "response": "def get_value_from_state(self, path, head_hash=None, with_proof=False, multi_sig=None):\n        '''\n        Get a value (and proof optionally)for the given path in state trie.\n        Does not return the proof is there is no aggregate signature for it.\n        :param path: the path generate a state proof for\n        :param head_hash: the root to create the proof against\n        :param get_value: whether to return the value\n        :return: a state proof or None\n        '''\n        if not multi_sig and with_proof:\n            root_hash = head_hash if head_hash else self.state.committedHeadHash\n            encoded_root_hash = state_roots_serializer.serialize(bytes(root_hash))\n\n            multi_sig = self.bls_store.get(encoded_root_hash)\n        return super().get_value_from_state(path, head_hash, with_proof, multi_sig)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake all Ordered messages from outbox out of turn.", "response": "def take_ordereds_out_of_turn(self) -> tuple:\n        \"\"\"\n        Takes all Ordered messages from outbox out of turn\n        \"\"\"\n        for replica in self._replicas.values():\n            yield replica.instId, replica._remove_ordered_from_queue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _new_replica(self, instance_id: int, is_master: bool, bls_bft: BlsBft) -> Replica:\n        return self._replica_class(self._node, instance_id, self._config, is_master, bls_bft, self._metrics)", "response": "Create a new replica with the specified parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrestoring removed replicas to requiredNumberOfInstances", "response": "def restore_replicas(self) -> None:\n        '''\n        Restore removed replicas to requiredNumberOfInstances\n        :return:\n        '''\n        self.backup_instances_faulty.clear()\n        for inst_id in range(self.node.requiredNumberOfInstances):\n            if inst_id not in self.node.replicas.keys():\n                self.node.replicas.add_replica(inst_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_backup_primary_disconnected(self, degraded_backups) -> None:\n        '''\n        The method for sending BackupInstanceFaulty messages\n        if backup primary disconnected\n        :param degraded_backups: list of backup instances\n        ids which performance were degraded\n        :return:\n        '''\n        self.__remove_replicas(degraded_backups,\n                               Suspicions.BACKUP_PRIMARY_DISCONNECTED,\n                               self.node.config.REPLICAS_REMOVING_WITH_PRIMARY_DISCONNECTED)", "response": "The method for sending BackupInstanceFaulty messages if backup primary disconnected."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sumSeries(a: float, b: float, steps: int) -> float:\n        return a * (exp(b * steps) - 1) / (exp(b) - 1)", "response": "Return the value of the following polynomial.\n          "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds a b - value that satisfies a total duration within a start time.", "response": "def goalDuration(start: float, steps: int, total: float) -> float:\n        \"\"\"\n        Finds a b-value (common ratio) that satisfies a total duration within\n        1 millisecond. Not terribly efficient, so using lru_cache. Don't know\n        a way to compute the common ratio when the sum of a finite geometric\n        series is known. Found myself needing to factor polynomials with an\n        arbitrarily\n        high degree.\n\n        :param start: a-value\n        :param steps: how many steps\n        :param total: total duration of the series of n-steps\n        :return: b value\n        \"\"\"\n        a = start\n        up = None\n        dn = None\n        b = 1.0\n        while True:\n            s = Ratchet._sumSeries(a, b, steps) - total\n            if abs(s) < .001:\n                break\n            elif s < 0:\n                dn = b\n                # halfway between b and upper if upper defined\n                b = (up + b) / 2 if up else b + 1\n            else:\n                up = b\n                b = (dn + b) / 2 if dn else b / 2\n        return b"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nacquiring a lock for action.", "response": "def acquire(self):\n        \"\"\"\n        Acquires lock for action.\n\n        :return: True and 0.0 if lock successfully acquired or False and number of seconds to wait before the next try\n        \"\"\"\n        now = self.get_current_time()\n        logger.debug(\"now: {}, len(actionsLog): {}\".format(\n            now, len(self.actionsLog)))\n        self._trimActionsLog(now)\n        logger.debug(\"after trim, len(actionsLog): {}\".format(\n            len(self.actionsLog)))\n\n        if len(self.actionsLog) == 0:\n            self.actionsLog.append(now)\n            logger.debug(\"len(actionsLog) was 0, after append, len(actionsLog):\"\n                         \" {}\".format(len(self.actionsLog)))\n            return True, 0.0\n        timeToWaitAfterPreviousTry = self.delayFunction(len(self.actionsLog))\n        timePassed = now - self.actionsLog[-1]\n        logger.debug(\"timeToWaitAfterPreviousTry: {}, timePassed: {}\".\n                     format(timeToWaitAfterPreviousTry, timePassed))\n        if timeToWaitAfterPreviousTry < timePassed:\n            self.actionsLog.append(now)\n            logger.debug(\n                \"timeToWaitAfterPreviousTry < timePassed was true, after \"\n                \"append, len(actionsLog): {}\".format(len(self.actionsLog)))\n            return True, 0.0\n        else:\n            logger.debug(\n                \"timeToWaitAfterPreviousTry < timePassed was false, \"\n                \"len(actionsLog): {}\".format(len(self.actionsLog)))\n            return False, timeToWaitAfterPreviousTry - timePassed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming a client request into a sequence of transactions.", "response": "def reqToTxn(req):\n    \"\"\"\n    Transform a client request such that it can be stored in the ledger.\n    Also this is what will be returned to the client in the reply\n    :param req:\n    :return:\n    \"\"\"\n    if isinstance(req, str):\n        req = json.loads(req)\n    if isinstance(req, dict):\n        kwargs = dict(\n            identifier=req.get(f.IDENTIFIER.nm, None),\n            reqId=req.get(f.REQ_ID.nm, None),\n            operation=req.get(OPERATION, None),\n            signature=req.get(f.SIG.nm, None),\n            signatures=req.get(f.SIGS.nm, None),\n            protocolVersion=req.get(f.PROTOCOL_VERSION.nm, None)\n        )\n        req = TxnUtilConfig.client_request_class(**kwargs)\n    if isinstance(req, Request):\n        req_data = req.as_dict\n        req_data[f.DIGEST.nm] = req.digest\n        req_data[f.PAYLOAD_DIGEST.nm] = req.payload_digest\n    else:\n        raise TypeError(\n            \"Expected dict or str as input, but got: {}\".format(type(req)))\n\n    req_data = deepcopy(req_data)\n    return do_req_to_txn(req_data=req_data,\n                         req_op=req_data[OPERATION])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connecteds(self) -> Set[str]:\n        return {r.name for r in self.remotes.values()\n                if self.isRemoteConnected(r)}", "response": "Return the names of the remote nodes this node is connected to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the remote by name or ha.", "response": "def getRemote(self, name: str = None, ha: HA = None):\n        \"\"\"\n        Find the remote by name or ha.\n\n        :param name: the name of the remote to find\n        :param ha: host address pair the remote to find\n        :raises: RemoteNotFound\n        \"\"\"\n        return self.findInRemotesByName(name) if name else \\\n            self.findInRemotesByHA(ha)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the remote by name.", "response": "def findInRemotesByName(self, name: str):\n        \"\"\"\n        Find the remote by name.\n\n        :param name: the name of the remote to find\n        :raises: RemoteNotFound\n        \"\"\"\n        remotes = [r for r in self.remotes.values()\n                   if r.name == name]\n        if len(remotes) > 1:\n            raise DuplicateRemotes(remotes)\n        if not remotes:\n            raise RemoteNotFound(name)\n        return remotes[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the remote by name.", "response": "def removeRemoteByName(self, name: str) -> int:\n        \"\"\"\n        Remove the remote by name.\n\n        :param name: the name of the remote to remove\n        :raises: RemoteNotFound\n        \"\"\"\n        remote = self.getRemote(name)\n        rid = remote.uid\n        self.removeRemote(remote)\n        return rid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether the two addresses correspond to the same address.", "response": "def sameAddr(self, ha, ha2) -> bool:\n        \"\"\"\n        Check whether the two arguments correspond to the same address\n        \"\"\"\n        if ha == ha2:\n            return True\n        if ha[1] != ha2[1]:\n            return False\n        return ha[0] in self.localips and ha2[0] in self.localips"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remotesByConnected(self):\n        conns, disconns = [], []\n        for r in self.remotes.values():\n            array = conns if self.isRemoteConnected(r) else disconns\n            array.append(r)\n        return conns, disconns", "response": "Returns a tuple of connected and disconnected remotes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def serviceQueues(self, limit=None) -> int:\n        return await self._inbox_router.handleAll(self._inbox, limit)", "response": "Service at most limit messages from the inBox."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a signer to the wallet.", "response": "def addIdentifier(self,\n                      identifier=None,\n                      seed=None,\n                      signer=None,\n                      alias=None,\n                      didMethodName=None):\n        \"\"\"\n        Adds signer to the wallet.\n        Requires complete signer, identifier or seed.\n\n        :param identifier: signer identifier or None to use random one\n        :param seed: signer key seed or None to use random one\n        :param signer: signer to add\n        :param alias: a friendly readable name for the signer\n        :param didMethodName: name of DID Method if not the default\n        :return:\n        \"\"\"\n\n        dm = self.didMethods.get(didMethodName)\n        signer = signer or dm.newSigner(identifier=identifier, seed=seed)\n        self.idsToSigners[signer.identifier] = signer\n        if self.defaultId is None:\n            # setting this signer as default signer to let use sign* methods\n            # without explicit specification of signer\n            self.defaultId = signer.identifier\n        if alias:\n            signer.alias = alias\n        if signer.alias:\n            self.aliasesToIds[signer.alias] = signer.identifier\n        return signer.identifier, signer"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the passed signer for an already present identifier.", "response": "def updateSigner(self, identifier, signer):\n        \"\"\"\n        Update signer for an already present identifier. The passed signer\n        should have the same identifier as `identifier` or an error is raised.\n        Also if the existing identifier has an alias in the wallet then the\n        passed signer is given the same alias\n        :param identifier: existing identifier in the wallet\n        :param signer: new signer to update too\n        :return:\n        \"\"\"\n        if identifier != signer.identifier:\n            raise ValueError(\"Passed signer has identifier {} but it should\"\n                             \" have been {}\".format(signer.identifier,\n                                                    identifier))\n        if identifier not in self.idsToSigners:\n            raise KeyError(\"Identifier {} not present in wallet\".\n                           format(identifier))\n\n        oldSigner = self.idsToSigners[identifier]\n        if oldSigner.alias and oldSigner.alias in self.aliasesToIds:\n            logger.debug('Changing alias of passed signer to {}'.\n                         format(oldSigner.alias))\n            signer.alias = oldSigner.alias\n\n        self.idsToSigners[identifier] = signer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether signer identifier specified or can be inferred from alias or can be default used instead of idr", "response": "def requiredIdr(self,\n                    idr: Identifier=None,\n                    alias: str=None):\n        \"\"\"\n        Checks whether signer identifier specified, or can it be\n        inferred from alias or can be default used instead\n\n        :param idr:\n        :param alias:\n        :param other:\n\n        :return: signer identifier\n        \"\"\"\n\n        # TODO Need to create a new Identifier type that supports DIDs and CIDs\n        if idr:\n            if ':' in idr:\n                idr = idr.split(':')[1]\n        else:\n            idr = self.aliasesToIds[alias] if alias else self.defaultId\n        if not idr:\n            raise EmptyIdentifier\n        return idr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signMsg(self,\n                msg: Dict,\n                identifier: Identifier=None,\n                otherIdentifier: Identifier=None):\n        \"\"\"\n        Creates signature for message using specified signer\n\n        :param msg: message to sign\n        :param identifier: signer identifier\n        :param otherIdentifier:\n        :return: signature that then can be assigned to request\n        \"\"\"\n        idr = self.requiredIdr(idr=identifier or otherIdentifier)\n        signer = self._signerById(idr)\n        signature = signer.sign(msg)\n        return signature", "response": "Creates a signature for a message using specified signer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef signRequest(self,\n                    req: Request,\n                    identifier: Identifier=None) -> Request:\n        \"\"\"\n        Signs request. Modifies reqId and signature. May modify identifier.\n\n        :param req: request\n        :param requestIdStore: request id generator\n        :param identifier: signer identifier\n        :return: signed request\n        \"\"\"\n\n        idr = self.requiredIdr(idr=identifier or req._identifier)\n        # idData = self._getIdData(idr)\n        req._identifier = idr\n        req.reqId = req.gen_req_id()\n        # req.digest = req.getDigest()\n        # QUESTION: `self.ids[idr]` would be overwritten if same identifier\n        # is used to send 2 requests, why is `IdData` persisted?\n        # self.ids[idr] = IdData(idData.signer, req.reqId)\n        req.signature = self.signMsg(msg=req.signingPayloadState(identifier=idr),\n                                     identifier=idr,\n                                     otherIdentifier=req.identifier)\n\n        return req", "response": "Signs a request. Modifies reqId and signature. May modify identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsign the message if a signer is configured and returns the signed Request object.", "response": "def signOp(self,\n               op: Dict,\n               identifier: Identifier=None) -> Request:\n        \"\"\"\n        Signs the message if a signer is configured\n\n        :param identifier: signing identifier; if not supplied the default for\n            the wallet is used.\n        :param op: Operation to be signed\n        :return: a signed Request object\n        \"\"\"\n        request = Request(operation=op,\n                          protocolVersion=CURRENT_PROTOCOL_VERSION)\n        return self.signRequest(request, identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of identifiers and aliases.", "response": "def listIds(self, exclude=list()):\n        \"\"\"\n        For each signer in this wallet, return its alias if present else\n        return its identifier.\n\n        :param exclude:\n        :return: List of identifiers/aliases.\n        \"\"\"\n        lst = list(self.aliasesToIds.keys())\n        others = set(self.idsToSigners.keys()) - \\\n            set(self.aliasesToIds.values())\n        lst.extend(list(others))\n        for x in exclude:\n            lst.remove(x)\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves a wallet into a file.", "response": "def saveWallet(self, wallet, fpath):\n        \"\"\"Save wallet into specified localtion.\n\n        Returns the canonical path for the ``fpath`` where ``wallet``\n        has been stored.\n\n        Error cases:\n            - ``fpath`` is not inside the keyrings base dir - ValueError raised\n            - directory part of ``fpath`` exists and it's not a directory -\n              NotADirectoryError raised\n            - ``fpath`` exists and it's a directory - IsADirectoryError raised\n\n        :param wallet: wallet to save\n        :param fpath: wallet file path, absolute or relative to\n            keyrings base dir\n        \"\"\"\n        if not fpath:\n            raise ValueError(\"empty path\")\n\n        _fpath = self._normalize(fpath)\n        _dpath = _fpath.parent\n\n        try:\n            _dpath.relative_to(self._baseDir)\n        except ValueError:\n            raise ValueError(\n                \"path {} is not is not relative to the keyrings {}\".format(\n                    fpath, self._baseDir))\n\n        self._createDirIfNotExists(_dpath)\n\n        # ensure permissions from the bottom of the directory hierarchy\n        while _dpath != self._baseDir:\n            self._ensurePermissions(_dpath, self.dmode)\n            _dpath = _dpath.parent\n\n        with _fpath.open(\"w\") as wf:\n            self._ensurePermissions(_fpath, self.fmode)\n            encodedWallet = self.encode(wallet)\n            wf.write(encodedWallet)\n            logger.debug(\"stored wallet '{}' in {}\".format(\n                wallet.name, _fpath))\n\n        return str(_fpath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads wallet from specified file path.", "response": "def loadWallet(self, fpath):\n        \"\"\"Load wallet from specified localtion.\n\n        Returns loaded wallet.\n\n        Error cases:\n            - ``fpath`` is not inside the keyrings base dir - ValueError raised\n            - ``fpath`` exists and it's a directory - IsADirectoryError raised\n\n        :param fpath: wallet file path, absolute or relative to\n            keyrings base dir\n        \"\"\"\n        if not fpath:\n            raise ValueError(\"empty path\")\n\n        _fpath = self._normalize(fpath)\n        _dpath = _fpath.parent\n\n        try:\n            _dpath.relative_to(self._baseDir)\n        except ValueError:\n            raise ValueError(\n                \"path {} is not is not relative to the wallets {}\".format(\n                    fpath, self._baseDir))\n\n        with _fpath.open() as wf:\n            wallet = self.decode(wf.read())\n\n        return wallet"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the specified PREPARE to this replica s list of received PREPAREs.", "response": "def addVote(self, prepare: Prepare, voter: str) -> None:\n        \"\"\"\n        Add the specified PREPARE to this replica's list of received\n        PREPAREs.\n\n        :param prepare: the PREPARE to add to the list\n        :param voter: the name of the node who sent the PREPARE\n        \"\"\"\n        self._add_msg(prepare, voter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addVote(self, commit: Commit, voter: str) -> None:\n        super()._add_msg(commit, voter)", "response": "Add the specified COMMIT to this replica s list of received\n        COMMITs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndiscard a message and log a reason using the specified logMethod.", "response": "def discard(self, msg, reason, logMethod=logging.error, cliOutput=False):\n        \"\"\"\n        Discard a message and log a reason using the specified `logMethod`.\n\n        :param msg: the message to discard\n        :param reason: the reason why this message is being discarded\n        :param logMethod: the logging function to be used\n        :param cliOutput: if truthy, informs a CLI that the logged msg should\n        be printed\n        \"\"\"\n        reason = \"\" if not reason else \" because {}\".format(reason)\n        logMethod(\"{} discarding message {}{}\".format(self, msg, reason),\n                  extra={\"cli\": cliOutput})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the message to a dictionary form of the message holding the key of the message.", "response": "def toDict(self, msg: Dict) -> Dict:\n        \"\"\"\n        Return a dictionary form of the message\n\n        :param msg: the message to be sent\n        :raises: ValueError if msg cannot be converted to an appropriate format\n            for transmission\n        \"\"\"\n\n        if isinstance(msg, Request):\n            tmsg = msg.as_dict\n        elif hasattr(msg, \"_asdict\"):\n            tmsg = dict(msg._asdict())\n        elif hasattr(msg, \"__dict__\"):\n            tmsg = dict(msg.__dict__)\n        elif self.allowDictOnly:\n            raise ValueError(\"Message cannot be converted to an appropriate \"\n                             \"format for transmission\")\n        else:\n            tmsg = msg\n        return tmsg"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the freshness of a specific entry in the cache for more than the given time.", "response": "def check_freshness(self, ts):\n        '''\n        Get all ledger IDs for which\n          A) not updated for more than Freshness Timeout\n          B) hasn't been attempted to update (returned from this method) for more than Freshness Timeout\n        Should be called whenever we need to decide if ledgers need to be updated.\n\n        :param ts: the current time check the freshness against\n        :return: an ordered dict of outdated ledgers sorted by the time from the last update (from oldest to newest)\n         and then by ledger ID (in case of equal update time)\n        '''\n        outdated_ledgers = {}\n        for ledger_id, freshness_state in self._ledger_freshness.items():\n            if ts - freshness_state.last_updated <= self.freshness_timeout:\n                continue\n            if ts - freshness_state.last_marked_as_outdated <= self.freshness_timeout:\n                continue\n\n            outdated_ledgers[ledger_id] = ts - freshness_state.last_updated\n            freshness_state.last_marked_as_outdated = ts\n\n        # sort by last update time and then by ledger_id\n        return OrderedDict(\n            sorted(\n                outdated_ledgers.items(),\n                key=lambda item: (-item[1], item[0])\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_freshness(self, ledger_id, ts):\n        '''\n        Updates the time at which the ledger was updated.\n        Should be called whenever a txn for the ledger is ordered.\n\n        :param ledger_id: the ID of the ledgers a txn was ordered for\n        :param ts: the current time\n        :return: None\n        '''\n        if ledger_id in self._ledger_freshness:\n            self._ledger_freshness[ledger_id].last_updated = ts", "response": "Updates the time at which the ledger was updated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_last_update_time(self):\n        '''\n        Gets the time at which each ledger was updated.\n        Can be called at any time to get this information.\n\n        :return: an ordered dict of outdated ledgers sorted by last update time (from old to new)\n        and then by ledger ID (in case of equal update time)\n        '''\n        last_updated = {ledger_id: freshness_state.last_updated\n                        for ledger_id, freshness_state in self._ledger_freshness.items()}\n        return OrderedDict(\n            sorted(\n                last_updated.items(),\n                key=lambda item: (item[1], item[0])\n            )\n        )", "response": "Gets the time at which each ledger was updated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serialize(self, obj, level=0, objname=None, topLevelKeysToIgnore=None,\n                  toBytes=True):\n        \"\"\"\n        Create a string representation of the given object.\n\n        Examples:\n        ::\n        >>> serialize(\"str\")\n        'str'\n        >>> serialize([1,2,3,4,5])\n        '1,2,3,4,5'\n        >>> signing.serlize({1:'a', 2:'b'})\n        '1:a|2:b'\n        >>> signing.serlize({1:'a', 2:'b', 3:[1,{2:'k'}]})\n        '1:a|2:b|3:1,2:k'\n\n        :param obj: the object to serlize\n        :param level: a parameter used internally for recursion to serialize nested\n         data structures\n         :param topLevelKeysToIgnore: the list of top level keys to ignore for\n         serialization\n        :return: a string representation of `obj`\n        \"\"\"\n        res = None\n        if not isinstance(obj, acceptableTypes):\n            error(\"invalid type found {}: {}\".format(objname, obj))\n        elif isinstance(obj, str):\n            res = obj\n        elif isinstance(obj, dict):\n            if level > 0:\n                keys = list(obj.keys())\n            else:\n                topLevelKeysToIgnore = topLevelKeysToIgnore or []\n                keys = [k for k in obj.keys() if k not in topLevelKeysToIgnore]\n            keys.sort()\n            strs = []\n            for k in keys:\n                onm = \".\".join([str(objname), str(k)]) if objname else k\n                strs.append(\n                    str(k) + \":\" + self.serialize(obj[k], level + 1, onm, toBytes=False))\n            res = \"|\".join(strs)\n        elif isinstance(obj, Iterable):\n            strs = []\n            for o in obj:\n                strs.append(self.serialize(\n                    o, level + 1, objname, toBytes=False))\n            res = \",\".join(strs)\n        elif obj is None:\n            res = \"\"\n        else:\n            res = str(obj)\n\n        # logger.trace(\"serialized msg {} into {}\".format(obj, res))\n\n        if not toBytes:\n            return res\n\n        return res.encode('utf-8')", "response": "This method creates a string representation of the given object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncommits the given number of uncommitted txns.", "response": "def commitTxns(self, count: int) -> Tuple[Tuple[int, int], List]:\n        \"\"\"\n        The number of txns from the beginning of `uncommittedTxns` to commit\n        :param count:\n        :return: a tuple of 2 seqNos indicating the start and end of sequence\n        numbers of the committed txns\n        \"\"\"\n        committedSize = self.size\n        committedTxns = []\n        for txn in self.uncommittedTxns[:count]:\n            txn.update(self.append(txn))\n            committedTxns.append(txn)\n        self.uncommittedTxns = self.uncommittedTxns[count:]\n        logger.debug('Committed {} txns, {} are uncommitted'.\n                     format(len(committedTxns), len(self.uncommittedTxns)))\n        if not self.uncommittedTxns:\n            self.uncommittedTree = None\n            self.uncommittedRootHash = None\n        # Do not change `uncommittedTree` or `uncommittedRootHash`\n        # if there are any `uncommittedTxns` since the ledger still has a\n        # valid uncommittedTree and a valid root hash which are\n        # different from the committed ones\n        if committedTxns:\n            return (committedSize + 1, committedSize + count), committedTxns\n        else:\n            return (committedSize, committedSize), committedTxns"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef discardTxns(self, count: int):\n        # TODO: This can be optimised if multiple discards are combined\n        # together since merkle root computation will be done only once.\n        if count == 0:\n            return\n        if count > len(self.uncommittedTxns):\n            raise LogicError(\"expected to revert {} txns while there are only {}\".\n                             format(count, len(self.uncommittedTxns)))\n        old_hash = self.uncommittedRootHash\n        self.uncommittedTxns = self.uncommittedTxns[:-count]\n        if not self.uncommittedTxns:\n            self.uncommittedTree = None\n            self.uncommittedRootHash = None\n        else:\n            self.uncommittedTree = self.treeWithAppliedTxns(\n                self.uncommittedTxns)\n            self.uncommittedRootHash = self.uncommittedTree.root_hash\n        logger.info('Discarding {} txns and root hash {} and new root hash is {}. {} are still uncommitted'.\n                    format(count, Ledger.hashToStr(old_hash), Ledger.hashToStr(self.uncommittedRootHash),\n                           len(self.uncommittedTxns)))", "response": "Discards the given number of uncommitted txns and returns the new version of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of the merkle tree after applying the txns", "response": "def treeWithAppliedTxns(self, txns: List, currentTree=None):\n        \"\"\"\n        Return a copy of merkle tree after applying the txns\n        :param txns:\n        :return:\n        \"\"\"\n        currentTree = currentTree or self.tree\n        # Copying the tree is not a problem since its a Compact Merkle Tree\n        # so the size of the tree would be 32*(lg n) bytes where n is the\n        # number of leaves (no. of txns)\n        tempTree = copy(currentTree)\n        for txn in txns:\n            s = self.serialize_for_tree(txn)\n            tempTree.append(s)\n        return tempTree"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets the values of all attributes of the transaction store.", "response": "def reset(self):\n        \"\"\"\n        Clear the values of all attributes of the transaction store.\n        \"\"\"\n        self.getsCounter = 0\n\n        # dictionary of processed requests for each client. Value for each\n        # client is a dictionary with request id as key and transaction id as\n        # value\n        self.processedRequests = {}  # type: Dict[str, Dict[int, str]]\n\n        # dictionary of responses to be sent for each client. Value for each\n        # client is an asyncio Queue\n        self.responses = {}  # type: Dict[str, asyncio.Queue]\n\n        # dictionary with key as transaction id and `Reply` as\n        # value\n        self.transactions = {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self, timeout: int = 5) -> None:\n        self.running = False\n        start = time.perf_counter()\n        while True:\n            if self.getsCounter == 0:\n                return True\n            elif time.perf_counter() <= start + timeout:\n                time.sleep(.1)\n            else:\n                raise StopTimeout(\"Stop timed out waiting for {} gets to \"\n                                  \"complete.\".format(self.getsCounter))", "response": "Stop the transaction store in the given timeout."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a client request to the transaction store s list of processed requests.", "response": "def addToProcessedTxns(self,\n                           identifier: str,\n                           txnId: str,\n                           reply: Reply) -> None:\n        \"\"\"\n        Add a client request to the transaction store's list of processed\n        requests.\n        \"\"\"\n        self.transactions[txnId] = reply\n        if identifier not in self.processedRequests:\n            self.processedRequests[identifier] = {}\n        self.processedRequests[identifier][reply.reqId] = txnId"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def append(self, reply: Reply) \\\n            -> None:\n        \"\"\"\n        Add the given Reply to this transaction store's list of responses.\n        Also add to processedRequests if not added previously.\n        \"\"\"\n        result = reply.result\n        identifier = result.get(f.IDENTIFIER.nm)\n        txnId = result.get(TXN_ID)\n        logger.debug(\"Reply being sent {}\".format(reply))\n        if self._isNewTxn(identifier, reply, txnId):\n            self.addToProcessedTxns(identifier, txnId, reply)\n        if identifier not in self.responses:\n            self.responses[identifier] = asyncio.Queue()\n        await self.responses[identifier].put(reply)", "response": "Add the given Reply to this transaction store s list of responses."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _isNewTxn(self, identifier, reply, txnId) -> bool:\n        return (identifier not in self.processedRequests or\n                reply.reqId not in self.processedRequests[identifier]) and \\\n            txnId is not None", "response": "Returns true if the reply is a new transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the specified request to this request store.", "response": "def add(self, req: Request):\n        \"\"\"\n        Add the specified request to this request store.\n        \"\"\"\n        key = req.key\n        if key not in self:\n            self[key] = ReqState(req)\n        return self[key]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ordered_by_replica(self, request_key):\n        state = self.get(request_key)\n        if not state:\n            return\n        state.unordered_by_replicas_num -= 1", "response": "Should be called by each replica when request is ordered."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmark the request as forwarded to the given replicas.", "response": "def mark_as_forwarded(self, req: Request, to: int):\n        \"\"\"\n        Works together with 'mark_as_executed' and 'free' methods.\n\n        It marks request as forwarded to 'to' replicas.\n        To let request be removed, it should be marked as executed and each of\n        'to' replicas should call 'free'.\n        \"\"\"\n        self[req.key].forwarded = True\n        self[req.key].forwardedTo = to\n        self[req.key].unordered_by_replicas_num = to"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the specified request to the list of PROPAGATEs.", "response": "def add_propagate(self, req: Request, sender: str):\n        \"\"\"\n        Add the specified request to the list of received\n        PROPAGATEs.\n\n        :param req: the REQUEST to add\n        :param sender: the name of the node sending the msg\n        \"\"\"\n        data = self.add(req)\n        data.propagates[sender] = req"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the number of propagates for a given reqId and identifier.", "response": "def votes(self, req) -> int:\n        \"\"\"\n        Get the number of propagates for a given reqId and identifier.\n        \"\"\"\n        try:\n            votes = len(self[req.key].propagates)\n        except KeyError:\n            votes = 0\n        return votes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mark_as_executed(self, req: Request):\n        state = self[req.key]\n        state.executed = True\n        self._clean(state)", "response": "Mark the request as executed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncleaning up the state of a request_key.", "response": "def free(self, request_key):\n        \"\"\"\n        Works together with 'mark_as_forwarded' and\n        'mark_as_executed' methods.\n\n        It makes request to be removed if all replicas request was\n        forwarded to freed it and if request executor marked it as executed.\n        \"\"\"\n        state = self.get(request_key)\n        if not state:\n            return\n        state.forwardedTo -= 1\n        self._clean(state)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking whether the request specified has already been propagated.", "response": "def has_propagated(self, req: Request, sender: str) -> bool:\n        \"\"\"\n        Check whether the request specified has already been propagated.\n        \"\"\"\n        return req.key in self and sender in self[req.key].propagates"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef propagate(self, request: Request, clientName):\n        if self.requests.has_propagated(request, self.name):\n            logger.trace(\"{} already propagated {}\".format(self, request))\n        else:\n            with self.metrics.measure_time(MetricsName.SEND_PROPAGATE_TIME):\n                self.requests.add_propagate(request, self.name)\n                propagate = self.createPropagate(request, clientName)\n                logger.debug(\"{} propagating request {} from client {}\".format(self, request.key, clientName),\n                             extra={\"cli\": True, \"tags\": [\"node-propagate\"]})\n                self.send(propagate)", "response": "Broadcast a PROPAGATE to all other nodes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a PROPAGATE for the given REQUEST.", "response": "def createPropagate(\n            request: Union[Request, dict], client_name) -> Propagate:\n        \"\"\"\n        Create a new PROPAGATE for the given REQUEST.\n\n        :param request: the client REQUEST\n        :return: a new PROPAGATE msg\n        \"\"\"\n        if not isinstance(request, (Request, dict)):\n            logger.error(\"{}Request not formatted properly to create propagate\"\n                         .format(THREE_PC_PREFIX))\n            return\n        logger.trace(\"Creating PROPAGATE for REQUEST {}\".format(request))\n        request = request.as_dict if isinstance(request, Request) else \\\n            request\n        if isinstance(client_name, bytes):\n            client_name = client_name.decode()\n        return Propagate(request, client_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef canForward(self, request: Request):\n\n        if self.requests.forwarded(request):\n            return 'already forwarded'\n\n        # If not enough Propagates, don't bother comparing\n        if not self.quorums.propagate.is_reached(self.requests.votes(request)):\n            return 'not finalised'\n\n        req = self.requests.req_with_acceptable_quorum(request,\n                                                       self.quorums.propagate)\n        if req:\n            self.requests.set_finalised(req)\n            return None\n        else:\n            return 'not finalised'", "response": "Determines whether the client REQUESTs can be forwarded to replicas based on the PROPAGATE messages received for the same node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nforwards the specified client REQUEST to the other replicas on this node.", "response": "def forward(self, request: Request):\n        \"\"\"\n        Forward the specified client REQUEST to the other replicas on this node\n\n        :param request: the REQUEST to propagate\n        \"\"\"\n        key = request.key\n        num_replicas = self.replicas.num_replicas\n        logger.debug('{} forwarding request {} to {} replicas'\n                     .format(self, key, num_replicas))\n        self.replicas.pass_message(ReqKey(key))\n        self.monitor.requestUnOrdered(key)\n        self.requests.mark_as_forwarded(request, num_replicas)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recordAndPropagate(self, request: Request, clientName):\n        self.requests.add(request)\n        self.propagate(request, clientName)\n        self.tryForwarding(request)", "response": "Record the request in the list of requests and propagate it to the clientName."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tryForwarding(self, request: Request):\n        cannot_reason_msg = self.canForward(request)\n        if cannot_reason_msg is None:\n            # If haven't got the client request(REQUEST) for the corresponding\n            # propagate request(PROPAGATE) but have enough propagate requests\n            # to move ahead\n            self.forward(request)\n        else:\n            logger.trace(\"{} not forwarding request {} to its replicas \"\n                         \"since {}\".format(self, request, cannot_reason_msg))", "response": "Try to forward the request to its replicas."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request_propagates(self, req_keys):\n        i = 0\n        for digest in req_keys:\n            if digest not in self.requested_propagates_for:\n                if digest not in self.requests:\n                    # Request from all nodes\n                    self.request_msg(PROPAGATE, {f.DIGEST.nm: digest})\n                else:\n                    # Request from nodes that didn't send\n                    send_to = [conn for conn in self.nodestack.connecteds if\n                               conn not in self.requests[digest].propagates.keys()]\n                    self.request_msg(PROPAGATE, {f.DIGEST.nm: digest}, frm=send_to)\n\n                self._add_to_recently_requested(digest)\n                i += 1\n            else:\n                logger.debug('{} already requested PROPAGATE recently for {}'.\n                             format(self, digest))\n        return i", "response": "Request PROPAGATEs for the given request keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a remote from the list of remote objects.", "response": "def removeRemote(self, remote: Remote, clear=True):\n        \"\"\"\n        Currently not using clear\n        \"\"\"\n        name = remote.name\n        pkey = remote.publicKey\n        vkey = remote.verKey\n        if name in self.remotes:\n            self.remotes.pop(name)\n            self.remotesByKeys.pop(pkey, None)\n            self.verifiers.pop(vkey, None)\n        else:\n            logger.info('No remote named {} present')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess the current service.", "response": "async def service(self, limit=None, quota: Optional[Quota] = None) -> int:\n        \"\"\"\n        Service `limit` number of received messages in this stack.\n\n        :param limit: the maximum number of messages to be processed. If None,\n        processes all of the messages in rxMsgs.\n        :return: the number of messages processed.\n        \"\"\"\n        if self.listener:\n            await self._serviceStack(self.age, quota)\n        else:\n            logger.info(\"{} is stopped\".format(self))\n\n        r = len(self.rxMsgs)\n        if r > 0:\n            pracLimit = limit if limit else sys.maxsize\n            return self.processReceived(pracLimit)\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreceives messages from listener and adds them to the queue.", "response": "def _receiveFromListener(self, quota: Quota) -> int:\n        \"\"\"\n        Receives messages from listener\n        :param quota: number of messages to receive\n        :return: number of received messages\n        \"\"\"\n        i = 0\n        incoming_size = 0\n        while i < quota.count and incoming_size < quota.size:\n            try:\n                ident, msg = self.listener.recv_multipart(flags=zmq.NOBLOCK)\n                if not msg:\n                    # Router probing sends empty message on connection\n                    continue\n                incoming_size += len(msg)\n                i += 1\n                self._verifyAndAppend(msg, ident)\n            except zmq.Again:\n                break\n        if i > 0:\n            logger.trace('{} got {} messages through listener'.\n                         format(self, i))\n        return i"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _receiveFromRemotes(self, quotaPerRemote) -> int:\n\n        assert quotaPerRemote\n        totalReceived = 0\n        for ident, remote in self.remotesByKeys.items():\n            if not remote.socket:\n                continue\n            i = 0\n            sock = remote.socket\n            while i < quotaPerRemote:\n                try:\n                    msg, = sock.recv_multipart(flags=zmq.NOBLOCK)\n                    if not msg:\n                        # Router probing sends empty message on connection\n                        continue\n                    i += 1\n                    self._verifyAndAppend(msg, ident)\n                except zmq.Again:\n                    break\n            if i > 0:\n                logger.trace('{} got {} messages through remote {}'.\n                             format(self, i, remote))\n            totalReceived += i\n        return totalReceived", "response": "Receives messages from all remotes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect(self,\n                name=None,\n                remoteId=None,\n                ha=None,\n                verKeyRaw=None,\n                publicKeyRaw=None):\n        \"\"\"\n        Connect to the node specified by name.\n        \"\"\"\n        if not name:\n            raise ValueError('Remote name should be specified')\n\n        publicKey = None\n        if name in self.remotes:\n            remote = self.remotes[name]\n        else:\n            publicKey = z85.encode(\n                publicKeyRaw) if publicKeyRaw else self.getPublicKey(name)\n            verKey = z85.encode(\n                verKeyRaw) if verKeyRaw else self.getVerKey(name)\n            if not ha or not publicKey or (self.isRestricted and not verKey):\n                raise ValueError('{} doesnt have enough info to connect. '\n                                 'Need ha, public key and verkey. {} {} {}'.\n                                 format(name, ha, verKey, publicKey))\n            remote = self.addRemote(name, ha, verKey, publicKey)\n\n        public, secret = self.selfEncKeys\n        remote.connect(self.ctx, public, secret)\n\n        logger.info(\"{}{} looking for {} at {}:{}\"\n                    .format(CONNECTION_PREFIX, self,\n                            name or remote.name, *remote.ha),\n                    extra={\"cli\": \"PLAIN\", \"tags\": [\"node-looking\"]})\n\n        # This should be scheduled as an async task\n\n        self.sendPingPong(remote, is_ping=True)\n\n        # re-send previously stashed pings/pongs from unknown remotes\n        logger.trace(\"{} stashed pongs: {}\".format(self.name, str(self._stashed_pongs)))\n        if publicKey in self._stashed_pongs:\n            logger.trace(\"{} sending stashed pongs to {}\".format(self.name, str(z85_to_friendly(publicKey))))\n            self._stashed_pongs.discard(publicKey)\n            self.sendPingPong(name, is_ping=False)\n\n        return remote.uid", "response": "Connect to the specified node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reconnectRemote(self, remote):\n        if not isinstance(remote, Remote):\n            raise PlenumTypeError('remote', remote, Remote)\n        logger.info('{} reconnecting to {}'.format(self, remote))\n        public, secret = self.selfEncKeys\n        remote.disconnect()\n        remote.connect(self.ctx, public, secret)\n        self.sendPingPong(remote, is_ping=True)", "response": "Disconnect remote and connect to it again"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads multiple hashes from the database.", "response": "def _readMultiple(self, start, end, db):\n        \"\"\"\n        Returns a list of hashes with serial numbers between start\n         and end, both inclusive.\n         \"\"\"\n        self._validatePos(start, end)\n        # Converting any bytearray to bytes\n        return [bytes(db.get(str(pos))) for pos in range(start, end + 1)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npack a list of nibbles into a binary sequence of NIBBLE_SIZE bytes", "response": "def pack_nibbles(nibbles):\n    \"\"\"pack nibbles to binary\n\n    :param nibbles: a nibbles sequence. may have a terminator\n    \"\"\"\n\n    if nibbles[-1] == NIBBLE_TERMINATOR:\n        flags = 2\n        nibbles = nibbles[:-1]\n    else:\n        flags = 0\n\n    oddlen = len(nibbles) % 2\n    flags |= oddlen   # set lowest bit if odd number of nibbles\n    if oddlen:\n        nibbles = [flags] + nibbles\n    else:\n        nibbles = [flags, 0] + nibbles\n    o = b''\n    for i in range(0, len(nibbles), 2):\n        o += ascii_chr(16 * nibbles[i] + nibbles[i + 1])\n    return o"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_last_node_for_prfx(self, node, key_prfx, seen_prfx):\n        node_type = self._get_node_type(node)\n\n        if node_type == NODE_TYPE_BLANK:\n            return BLANK_NODE\n\n        if node_type == NODE_TYPE_BRANCH:\n            # already reach the expected node\n            if not key_prfx:\n                return node\n            sub_node = self._decode_to_node(node[key_prfx[0]])\n            seen_prfx.append(key_prfx[0])\n            return self._get_last_node_for_prfx(sub_node, key_prfx[1:], seen_prfx)\n\n        # key value node\n        curr_key = key_nibbles_from_key_value_node(node)\n\n        if node_type == NODE_TYPE_LEAF:\n            # Return this node only if the complete prefix is part of the current key\n            if starts_with(curr_key, key_prfx):\n                # Do not update `seen_prefix` as node has the prefix\n                return node\n            else:\n                return BLANK_NODE\n\n        if node_type == NODE_TYPE_EXTENSION:\n            # traverse child nodes\n            if len(key_prfx) > len(curr_key):\n                if starts_with(key_prfx, curr_key):\n                    sub_node = self._get_inner_node_from_extension(node)\n                    seen_prfx.extend(curr_key)\n                    return self._get_last_node_for_prfx(sub_node,\n                                                        key_prfx[len(curr_key):],\n                                                        seen_prfx)\n                else:\n                    return BLANK_NODE\n            else:\n                if starts_with(curr_key, key_prfx):\n                    # Do not update `seen_prefix` as node has the prefix\n                    return node\n                else:\n                    return BLANK_NODE", "response": "get the last node for the given prefix"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over the branch of the tree.", "response": "def _iter_branch(self, node):\n        \"\"\"yield (key, value) stored in this and the descendant nodes\n        :param node: node in form of list, or BLANK_NODE\n\n        .. note::\n            Here key is in full form, rather than key of the individual node\n        \"\"\"\n        if node == BLANK_NODE:\n            raise StopIteration\n\n        node_type = self._get_node_type(node)\n\n        if is_key_value_type(node_type):\n            nibbles = key_nibbles_from_key_value_node(node)\n            key = b'+'.join([to_string(x) for x in nibbles])\n            if node_type == NODE_TYPE_EXTENSION:\n                sub_tree = self._iter_branch(self._get_inner_node_from_extension(node))\n            else:\n                sub_tree = [(to_string(NIBBLE_TERMINATOR), node[1])]\n\n            # prepend key of this node to the keys of children\n            for sub_key, sub_value in sub_tree:\n                full_key = (key + b'+' + sub_key).strip(b'+')\n                yield (full_key, sub_value)\n\n        elif node_type == NODE_TYPE_BRANCH:\n            for i in range(16):\n                sub_tree = self._iter_branch(self._decode_to_node(node[i]))\n                for sub_key, sub_value in sub_tree:\n                    full_key = (str_to_bytes(str(i)) +\n                                b'+' + sub_key).strip(b'+')\n                    yield (full_key, sub_value)\n            if node[16]:\n                yield (to_string(NIBBLE_TERMINATOR), node[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_at(self, root_node, key):\n        return self._get(root_node, bin_to_nibbles(to_string(key)))", "response": "Get a value of a key when the root node was root_node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate and return the metrics.", "response": "def metrics(self):\n        \"\"\"\n        Calculate and return the metrics.\n        \"\"\"\n        masterThrp, backupThrp = self.getThroughputs(self.instances.masterId)\n        r = self.instance_throughput_ratio(self.instances.masterId)\n        m = [\n            (\"{} Monitor metrics:\".format(self), None),\n            (\"Delta\", self.Delta),\n            (\"Lambda\", self.Lambda),\n            (\"Omega\", self.Omega),\n            (\"instances started\", self.instances.started),\n            (\"ordered request counts\",\n             {i: r[0] for i, r in self.numOrderedRequests.items()}),\n            (\"ordered request durations\",\n             {i: r[1] for i, r in self.numOrderedRequests.items()}),\n            (\"master request latencies\", self.masterReqLatencies),\n            (\"client avg request latencies\", {i: self.getLatency(i)\n                                              for i in self.instances.ids}),\n            (\"throughput\", {i: self.getThroughput(i)\n                            for i in self.instances.ids}),\n            (\"master throughput\", masterThrp),\n            (\"total requests\", self.totalRequests),\n            (\"avg backup throughput\", backupThrp),\n            (\"master throughput ratio\", r)]\n        return m"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset(self):\n        logger.debug(\"{}'s Monitor being reset\".format(self))\n        instances_ids = self.instances.started.keys()\n        self.numOrderedRequests = {inst_id: (0, 0) for inst_id in instances_ids}\n        self.requestTracker.reset()\n        self.masterReqLatencies = {}\n        self.masterReqLatencyTooHigh = False\n        self.totalViewChanges += 1\n        self.lastKnownTraffic = self.calculateTraffic()\n        if self.acc_monitor:\n            self.acc_monitor.reset()\n        for i in instances_ids:\n            rm = self.create_throughput_measurement(self.config)\n            self.throughputs[i] = rm\n            lm = self.latency_measurement_cls(self.config)\n            self.clientAvgReqLatencies[i] = lm", "response": "Reset the monitor. Sets all monitored values to defaults."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding one protocol instance for monitoring.", "response": "def addInstance(self, inst_id):\n        \"\"\"\n        Add one protocol instance for monitoring.\n        \"\"\"\n        self.instances.add(inst_id)\n        self.requestTracker.add_instance(inst_id)\n        self.numOrderedRequests[inst_id] = (0, 0)\n        rm = self.create_throughput_measurement(self.config)\n\n        self.throughputs[inst_id] = rm\n        lm = self.latency_measurement_cls(self.config)\n        self.clientAvgReqLatencies[inst_id] = lm\n        if self.acc_monitor:\n            self.acc_monitor.add_instance(inst_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requestOrdered(self, reqIdrs: List[str], instId: int,\n                       requests, byMaster: bool = False) -> Dict:\n        \"\"\"\n        Measure the time taken for ordering of a request and return it. Monitor\n        might have been reset due to view change due to which this method\n        returns None\n        \"\"\"\n        now = time.perf_counter()\n        if self.acc_monitor:\n            self.acc_monitor.update_time(now)\n        durations = {}\n        for key in reqIdrs:\n            if key not in self.requestTracker:\n                logger.debug(\"Got untracked ordered request with digest {}\".\n                             format(key))\n                continue\n            if self.acc_monitor:\n                self.acc_monitor.request_ordered(key, instId)\n            if key in self.requestTracker.handled_unordered():\n                started = self.requestTracker.started(key)\n                logger.info('Consensus for ReqId: {} was achieved by {}:{} in {} seconds.'\n                            .format(key, self.name, instId, now - started))\n            duration = self.requestTracker.order(instId, key, now)\n            self.throughputs[instId].add_request(now)\n\n            if key in requests:\n                identifier = requests[key].request.identifier\n                self.clientAvgReqLatencies[instId].add_duration(identifier, duration)\n\n            durations[key] = duration\n\n        reqs, tm = self.numOrderedRequests[instId]\n        orderedNow = len(durations)\n        self.numOrderedRequests[instId] = (reqs + orderedNow,\n                                           tm + sum(durations.values()))\n\n        # TODO: Inefficient, as on every request a minimum of a large list is\n        # calculated\n        if min(r[0] for r in self.numOrderedRequests.values()) == (reqs + orderedNow):\n            # If these requests is ordered by the last instance then increment\n            # total requests, but why is this important, why cant is ordering\n            # by master not enough?\n            self.totalRequests += orderedNow\n            self.postOnReqOrdered()\n            if 0 == reqs:\n                self.postOnNodeStarted(self.started)\n\n        return durations", "response": "This method is used to order a list of requests."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrecording the time at which the request ordering started.", "response": "def requestUnOrdered(self, key: str):\n        \"\"\"\n        Record the time at which request ordering started.\n        \"\"\"\n        now = time.perf_counter()\n        if self.acc_monitor:\n            self.acc_monitor.update_time(now)\n            self.acc_monitor.request_received(key)\n        self.requestTracker.start(key, now)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isMasterDegraded(self):\n        if self.acc_monitor:\n            self.acc_monitor.update_time(time.perf_counter())\n            return self.acc_monitor.is_master_degraded()\n        else:\n            return (self.instances.masterId is not None and\n                    (self.isMasterThroughputTooLow() or\n                     # TODO for now, view_change procedure can take more that 15 minutes\n                     # (5 minutes for catchup and 10 minutes for primary's answer).\n                     # Therefore, view_change triggering by max latency now is not indicative.\n                     # self.isMasterReqLatencyTooHigh() or\n                     self.isMasterAvgReqLatencyTooHigh()))", "response": "Return whether the master instance is degraded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of slow instance IDs that are marked as degraded.", "response": "def areBackupsDegraded(self):\n        \"\"\"\n        Return slow instance.\n        \"\"\"\n        slow_instances = []\n        if self.acc_monitor:\n            for instance in self.instances.backupIds:\n                if self.acc_monitor.is_instance_degraded(instance):\n                    slow_instances.append(instance)\n        else:\n            for instance in self.instances.backupIds:\n                if self.is_instance_throughput_too_low(instance):\n                    slow_instances.append(instance)\n        return slow_instances"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the relative throughput of an instance compared to the backup instances.", "response": "def instance_throughput_ratio(self, inst_id):\n        \"\"\"\n        The relative throughput of an instance compared to the backup\n        instances.\n        \"\"\"\n        inst_thrp, otherThrp = self.getThroughputs(inst_id)\n\n        # Backup throughput may be 0 so moving ahead only if it is not 0\n        r = inst_thrp / otherThrp if otherThrp and inst_thrp is not None \\\n            else None\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn whether the throughput of the master instance is greater than or equal to the acceptable threshold.", "response": "def is_instance_throughput_too_low(self, inst_id):\n        \"\"\"\n        Return whether the throughput of the master instance is greater than the\n        acceptable threshold\n        \"\"\"\n        r = self.instance_throughput_ratio(inst_id)\n        if r is None:\n            logger.debug(\"{} instance {} throughput is not \"\n                         \"measurable.\".format(self, inst_id))\n            return None\n        too_low = r < self.Delta\n        if too_low:\n            logger.display(\"{}{} instance {} throughput ratio {} is lower than Delta {}.\".\n                           format(MONITORING_PREFIX, self, inst_id, r, self.Delta))\n        else:\n            logger.trace(\"{} instance {} throughput ratio {} is acceptable.\".\n                         format(self, inst_id, r))\n        return too_low"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning whether the request latency of the master instance is greater than the acceptable threshold for all requests.", "response": "def isMasterReqLatencyTooHigh(self):\n        \"\"\"\n        Return whether the request latency of the master instance is greater\n        than the acceptable threshold\n        \"\"\"\n        # TODO for now, view_change procedure can take more that 15 minutes\n        # (5 minutes for catchup and 10 minutes for primary's answer).\n        # Therefore, view_change triggering by max latency is not indicative now.\n\n        r = self.masterReqLatencyTooHigh or \\\n            next(((key, lat) for key, lat in self.masterReqLatencies.items() if\n                  lat > self.Lambda), None)\n        if r:\n            logger.display(\"{}{} found master's latency {} to be higher than the threshold for request {}.\".\n                           format(MONITORING_PREFIX, self, r[1], r[0]))\n        else:\n            logger.trace(\"{} found master's latency to be lower than the \"\n                         \"threshold for all requests.\".format(self))\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn whether the average request latency of an instance is greater than the acceptable threshold.", "response": "def is_instance_avg_req_latency_too_high(self, inst_id):\n        \"\"\"\n        Return whether the average request latency of an instance is\n        greater than the acceptable threshold\n        \"\"\"\n        avg_lat, avg_lat_others = self.getLatencies()\n        if not avg_lat or not avg_lat_others:\n            return False\n\n        d = avg_lat - avg_lat_others\n        if d < self.Omega:\n            return False\n\n        if inst_id == self.instances.masterId:\n            logger.info(\"{}{} found difference between master's and \"\n                        \"backups's avg latency {} to be higher than the \"\n                        \"threshold\".format(MONITORING_PREFIX, self, d))\n            logger.trace(\n                \"{}'s master's avg request latency is {} and backup's \"\n                \"avg request latency is {}\".format(self, avg_lat, avg_lat_others))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getThroughputs(self, desired_inst_id: int):\n\n        instance_thrp = self.getThroughput(desired_inst_id)\n        totalReqs, totalTm = self.getInstanceMetrics(forAllExcept=desired_inst_id)\n        # Average backup replica's throughput\n        if len(self.throughputs) > 1:\n            thrs = []\n            for inst_id, thr_obj in self.throughputs.items():\n                if inst_id == desired_inst_id:\n                    continue\n                thr = self.getThroughput(inst_id)\n                if thr is not None:\n                    thrs.append(thr)\n            if thrs:\n                if desired_inst_id == self.instances.masterId:\n                    other_thrp = self.throughput_avg_strategy_cls.get_avg(thrs)\n                else:\n                    other_thrp = self.backup_throughput_avg_strategy_cls.get_avg(thrs)\n            else:\n                other_thrp = None\n        else:\n            other_thrp = None\n        if instance_thrp == 0:\n            if self.numOrderedRequests[desired_inst_id] == (0, 0):\n                avgReqsPerInst = (totalReqs or 0) / self.instances.count\n                if avgReqsPerInst <= 1:\n                    # too early to tell if we need an instance change\n                    instance_thrp = None\n        return instance_thrp, other_thrp", "response": "Returns a tuple of the throughput of the given instance and the average throughput of the remaining instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the throughput of the specified instance.", "response": "def getThroughput(self, instId: int) -> float:\n        \"\"\"\n        Return the throughput of the specified instance.\n\n        :param instId: the id of the protocol instance\n        \"\"\"\n        # We are using the instanceStarted time in the denominator instead of\n        # a time interval. This is alright for now as all the instances on a\n        # node are started at almost the same time.\n        if instId not in self.instances.ids:\n            return None\n        perf_time = time.perf_counter()\n        throughput = self.throughputs[instId].get_throughput(perf_time)\n        return throughput"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate and return the average throughput of all the instances except the one specified as forAllExcept.", "response": "def getInstanceMetrics(\n            self, forAllExcept: int) -> Tuple[Optional[int], Optional[float]]:\n        \"\"\"\n        Calculate and return the average throughput of all the instances except\n        the one specified as `forAllExcept`.\n        \"\"\"\n        m = [(reqs, tm) for i, (reqs, tm)\n             in self.numOrderedRequests.items()\n             if i != forAllExcept]\n        if m:\n            reqs, tm = zip(*m)\n            return sum(reqs), sum(tm)\n        else:\n            return None, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getLatency(self, instId: int) -> float:\n        if len(self.clientAvgReqLatencies) == 0:\n            return 0.0\n        return self.clientAvgReqLatencies[instId].get_avg_latency()", "response": "Returns the average latency of a client instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _enqueue(self, msg: Any, rid: int, signer: Signer) -> None:\n        if rid not in self.outBoxes:\n            self.outBoxes[rid] = deque()\n        self.outBoxes[rid].append(msg)", "response": "Enqueue the message into the remote s queue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self,\n             msg: Any, *\n             rids: Iterable[int],\n             signer: Signer = None,\n             message_splitter=None) -> None:\n        \"\"\"\n        Enqueue the given message into the outBoxes of the specified remotes\n        or into the outBoxes of all the remotes if rids is None\n\n        :param msg: the message to enqueue\n        :param rids: ids of the remotes to whose outBoxes\n            this message must be enqueued\n        :param message_splitter: callable that splits msg on\n            two smaller messages\n        \"\"\"\n        # Signing (if required) and serializing before enqueueing otherwise\n        # each call to `_enqueue` will have to sign it and `transmit` will try\n        # to serialize it which is waste of resources\n        message_parts, err_msg = \\\n            self.prepare_for_sending(msg, signer, message_splitter)\n\n        # TODO: returning breaks contract of super class\n        if err_msg is not None:\n            return False, err_msg\n\n        if rids:\n            for r in rids:\n                for part in message_parts:\n                    self._enqueue(part, r, signer)\n        else:\n            for part in message_parts:\n                self._enqueueIntoAllRemotes(part, signer)\n        return True, None", "response": "Sends the given message to the specified remotes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nflush the outBoxes and transmits them to the remotes.", "response": "def flushOutBoxes(self) -> None:\n        \"\"\"\n        Clear the outBoxes and transmit batched messages to remotes.\n        \"\"\"\n        removedRemotes = []\n        for rid, msgs in self.outBoxes.items():\n            try:\n                dest = self.remotes[rid].name\n            except KeyError:\n                removedRemotes.append(rid)\n                continue\n            if msgs:\n                if self._should_batch(msgs):\n                    logger.trace(\n                        \"{} batching {} msgs to {} into fewer transmissions\".\n                        format(self, len(msgs), dest))\n                    logger.trace(\"    messages: {}\".format(msgs))\n                    batches = split_messages_on_batches(list(msgs),\n                                                        self._make_batch,\n                                                        self._test_batch_len,\n                                                        )\n                    msgs.clear()\n                    if batches:\n                        for batch, size in batches:\n                            logger.trace(\"{} sending payload to {}: {}\".format(\n                                self, dest, batch))\n                            self.metrics.add_event(MetricsName.TRANSPORT_BATCH_SIZE, size)\n                            # Setting timeout to never expire\n                            self.transmit(\n                                batch,\n                                rid,\n                                timeout=self.messageTimeout,\n                                serialized=True)\n                    else:\n                        logger.error(\"{} cannot create batch(es) for {}\".format(self, dest))\n                else:\n                    while msgs:\n                        msg = msgs.popleft()\n                        logger.trace(\n                            \"{} sending msg {} to {}\".format(self, msg, dest))\n                        self.metrics.add_event(MetricsName.TRANSPORT_BATCH_SIZE, 1)\n                        # Setting timeout to never expire\n                        self.transmit(msg, rid, timeout=self.messageTimeout,\n                                      serialized=True)\n\n        for rid in removedRemotes:\n            logger.warning(\"{}{} has removed rid {}\"\n                           .format(CONNECTION_PREFIX, self,\n                                   z85_to_friendly(rid)),\n                           extra={\"cli\": False})\n            msgs = self.outBoxes[rid]\n            if msgs:\n                self.discard(msgs,\n                             \"{}rid {} no longer available\"\n                             .format(CONNECTION_PREFIX,\n                                     z85_to_friendly(rid)),\n                             logMethod=logger.debug)\n            del self.outBoxes[rid]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling prod once for each Prodable in this Looper", "response": "async def prodAllOnce(self):\n        \"\"\"\n        Call `prod` once for each Prodable in this Looper\n\n        :return: the sum of the number of events executed successfully\n        \"\"\"\n        # TODO: looks like limit is always None???\n        limit = None\n        s = 0\n        for n in self.prodables:\n            s += await n.prod(limit)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds one Prodable object to this Looper s list of Prodables xid", "response": "def add(self, prodable: Prodable) -> None:\n        \"\"\"\n        Add one Prodable object to this Looper's list of Prodables\n\n        :param prodable: the Prodable object to add\n        \"\"\"\n        if prodable.name in [p.name for p in self.prodables]:\n            raise ProdableAlreadyAdded(\"Prodable {} already added.\".\n                                       format(prodable.name))\n        self.prodables.append(prodable)\n        if self.autoStart:\n            prodable.start(self.loop)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the specified Prodable object from this Looper s list of Prodables .", "response": "def removeProdable(self, prodable: Prodable=None, name: str=None) -> Optional[Prodable]:\n        \"\"\"\n        Remove the specified Prodable object from this Looper's list of Prodables\n\n        :param prodable: the Prodable to remove\n        \"\"\"\n        if prodable:\n            self.prodables.remove(prodable)\n            return prodable\n        elif name:\n            for p in self.prodables:\n                if hasattr(p, \"name\") and getattr(p, \"name\") == name:\n                    prodable = p\n                    break\n            if prodable:\n                self.prodables.remove(prodable)\n                return prodable\n            else:\n                logger.warning(\"Trying to remove a prodable {} which is not present\"\n                               .format(prodable))\n        else:\n            logger.error(\"Provide a prodable object or a prodable name\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def runOnceNicely(self):\n        start = time.perf_counter()\n        msgsProcessed = await self.prodAllOnce()\n        if msgsProcessed == 0:\n            # if no let other stuff run\n            await asyncio.sleep(0.01, loop=self.loop)\n        dur = time.perf_counter() - start\n        if dur >= 15:\n            logger.info(\"it took {:.3f} seconds to run once nicely\".\n                        format(dur), extra={\"cli\": False})", "response": "Execute runOnce with a small tolerance of 0. 01 seconds so that the Prodables\n            can complete their other asynchronous tasks not running on the event - loop."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, *coros: CoroWrapper):\n        if not self.running:\n            raise RuntimeError(\"not running!\")\n\n        async def wrapper():\n            results = []\n            for coro in coros:\n                try:\n                    if inspect.isawaitable(coro):\n                        results.append(await coro)\n                    elif inspect.isfunction(coro):\n                        res = coro()\n                        if inspect.isawaitable(res):\n                            results.append(await res)\n                        else:\n                            results.append(res)\n                    else:\n                        raise RuntimeError(\n                            \"don't know how to run {}\".format(coro))\n                except Exception as ex:\n                    logger.error(\"Error while running coroutine {}: {}\".format(coro.__name__, ex.__repr__()))\n                    raise ex\n            if len(results) == 1:\n                return results[0]\n            return results\n        if coros:\n            what = wrapper()\n        else:\n            # if no coros supplied, then assume we run forever\n            what = self.runFut\n        return self.loop.run_until_complete(what)", "response": "Runs a list of coroutine functions and quits the loop until all coroutines are done."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def shutdown(self):\n        logger.display(\"Looper shutting down now...\", extra={\"cli\": False})\n        self.running = False\n        start = time.perf_counter()\n        if not self.runFut.done():\n            await self.runFut\n        self.stopall()\n        logger.display(\"Looper shut down in {:.3f} seconds.\".\n                       format(time.perf_counter() - start), extra={\"cli\": False})\n        # Unset signal handlers, bug: https://bugs.python.org/issue23548\n        for sig_name in self.signals:\n            logger.debug(\"Unsetting handler for {}\".format(sig_name))\n            sig_num = getattr(signal, sig_name)\n            self.loop.remove_signal_handler(sig_num)", "response": "Shut down this Looper."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a default BLS factory to instantiate BLS BFT classes.", "response": "def create_default_bls_bft_factory(node):\n    '''\n    Creates a default BLS factory to instantiate BLS BFT classes.\n\n    :param node: Node instance\n    :return: BLS factory instance\n    '''\n    bls_keys_dir = os.path.join(node.keys_dir, node.name)\n    bls_crypto_factory = create_default_bls_crypto_factory(bls_keys_dir)\n    return BlsFactoryBftPlenum(bls_crypto_factory, node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify the signature of a signed message.", "response": "def verify(self, smessage, signature=None, encoder=encoding.RawEncoder):\n        \"\"\"\n        Verifies the signature of a signed message, returning the message\n        if it has not been tampered with else raising\n        :class:`~ValueError`.\n\n        :param smessage: [:class:`bytes`] Either the original messaged or a\n            signature and message concated together.\n        :param signature: [:class:`bytes`] If an unsigned message is given for\n            smessage then the detached signature must be provded.\n        :param encoder: A class that is able to decode the secret message and\n            signature.\n        :rtype: :class:`bytes`\n        \"\"\"\n        if signature is not None:\n            # If we were given the message and signature separately, combine\n            #   them.\n            smessage = signature + smessage\n\n        # Decode the signed message\n        smessage = encoder.decode(smessage)\n\n        return libnacl.crypto_sign_open(smessage, self._key)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(cls):\n        return cls(\n            libnacl.randombytes(libnacl.crypto_sign_SEEDBYTES),\n            encoder=encoding.RawEncoder,\n        )", "response": "Generates a random signing key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sign(self, message, encoder=encoding.RawEncoder):\n        raw_signed = libnacl.crypto_sign(message, self._signing_key)\n\n        signature = encoder.encode(raw_signed[:libnacl.crypto_sign_BYTES])\n        message = encoder.encode(raw_signed[libnacl.crypto_sign_BYTES:])\n        signed = encoder.encode(raw_signed)\n\n        return SignedMessage._from_parts(signature, message, signed)", "response": "Signs a message using this key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies the message signature", "response": "def verify(self, signature, msg):\n        '''\n        Verify the message\n        '''\n        if not self.key:\n            return False\n        try:\n            self.key.verify(signature + msg)\n        except ValueError:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random object of the specified size.", "response": "def generate(cls):\n        \"\"\"\n        Generates a random :class:`~PrivateKey` object\n\n        :rtype: :class:`~PrivateKey`\n        \"\"\"\n        return cls(libnacl.randombytes(PrivateKey.SIZE), encoder=encoding.RawEncoder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encrypt(self, plaintext, nonce, encoder=encoding.RawEncoder):\n        if len(nonce) != self.NONCE_SIZE:\n            raise ValueError(\"The nonce must be exactly %s bytes long\" %\n                             self.NONCE_SIZE)\n\n        ciphertext = libnacl.crypto_box_afternm(\n            plaintext,\n            nonce,\n            self._shared_key,\n        )\n\n        encoded_nonce = encoder.encode(nonce)\n        encoded_ciphertext = encoder.encode(ciphertext)\n\n        return EncryptedMessage._from_parts(\n            encoded_nonce,\n            encoded_ciphertext,\n            encoder.encode(nonce + ciphertext),\n        )", "response": "Encrypts the given plaintext message using the given nonce and returns the ciphertext encoded with the encoder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypt(self, ciphertext, nonce=None, encoder=encoding.RawEncoder):\n        # Decode our ciphertext\n        ciphertext = encoder.decode(ciphertext)\n\n        if nonce is None:\n            # If we were given the nonce and ciphertext combined, split them.\n            nonce = ciphertext[:self.NONCE_SIZE]\n            ciphertext = ciphertext[self.NONCE_SIZE:]\n\n        if len(nonce) != self.NONCE_SIZE:\n            raise ValueError(\"The nonce must be exactly %s bytes long\" %\n                             self.NONCE_SIZE)\n\n        plaintext = libnacl.crypto_box_open_afternm(\n            ciphertext,\n            nonce,\n            self._shared_key,\n        )\n\n        return plaintext", "response": "Decrypts the ciphertext using the given nonce and returns the plaintext message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencrypting the message using the public key and return the encrypted message and the nonce", "response": "def encrypt(self, msg, pubkey, enhex=False):\n        '''\n        Return duple of (cyphertext, nonce) resulting from encrypting the message\n        using shared key generated from the .key and the pubkey\n        If pubkey is hex encoded it is converted first\n        If enhex is True then use HexEncoder otherwise use RawEncoder\n\n        Intended for the owner of the passed in public key\n\n        msg is string\n        pub is Publican instance\n        '''\n        if not isinstance(pubkey, PublicKey):\n            if len(pubkey) == 32:\n                pubkey = PublicKey(pubkey, encoding.RawEncoder)\n            else:\n                pubkey = PublicKey(pubkey, encoding.HexEncoder)\n        box = Box(self.key, pubkey)\n        nonce = self.nonce()\n        encoder = encoding.HexEncoder if enhex else encoding.RawEncoder\n        encrypted = box.encrypt(msg, nonce, encoder)\n        return (encrypted.ciphertext, encrypted.nonce)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns decrypted msg contained in cypher using nonce and shared key generated from .key and pubkey. If pubkey is hex encoded it is converted first If dehex is True then use HexEncoder otherwise use RawEncoder Intended for the owner of .key cypher is string nonce is string pub is Publican instance", "response": "def decrypt(self, cipher, nonce, pubkey, dehex=False):\n        '''\n        Return decrypted msg contained in cypher using nonce and shared key\n        generated from .key and pubkey.\n        If pubkey is hex encoded it is converted first\n        If dehex is True then use HexEncoder otherwise use RawEncoder\n\n        Intended for the owner of .key\n\n        cypher is string\n        nonce is string\n        pub is Publican instance\n        '''\n        if not isinstance(pubkey, PublicKey):\n            if len(pubkey) == 32:\n                pubkey = PublicKey(pubkey, encoding.RawEncoder)\n            else:\n                pubkey = PublicKey(pubkey, encoding.HexEncoder)\n        box = Box(self.key, pubkey)\n        decoder = encoding.HexEncoder if dehex else encoding.RawEncoder\n        if dehex and len(nonce) != box.NONCE_SIZE:\n            nonce = decoder.decode(nonce)\n        return box.decrypt(cipher, nonce, decoder)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, leaf):\n        # Serializing here to avoid serialisation in `_addToStore` and\n        # `_addToTree`\n        serz_leaf = self.serialize_for_txn_log(leaf)\n        self._addToStore(serz_leaf, serialized=True)\n\n        serz_leaf_for_tree = self.serialize_for_tree(leaf)\n        merkle_info = self._addToTree(serz_leaf_for_tree, serialized=True)\n\n        return merkle_info", "response": "Add the leaf to the log and the merkle tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of lines that are not empty", "response": "def cleanLines(source, lineSep=os.linesep):\n    \"\"\"\n    :param source: some iterable source (list, file, etc)\n    :param lineSep: string of separators (chars) that must be removed\n    :return: list of non empty lines with removed separators\n    \"\"\"\n    stripped = (line.strip(lineSep) for line in source)\n    return (line for line in stripped if len(line) != 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getInstalledConfig(installDir, configFile):\n    configPath = os.path.join(installDir, configFile)\n    if not os.path.exists(configPath):\n        raise FileNotFoundError(\"No file found at location {}\".\n                                format(configPath))\n    spec = spec_from_file_location(configFile, configPath)\n    config = module_from_spec(spec)\n    spec.loader.exec_module(config)\n    return config", "response": "Reads config from the installation directory of Plenum and returns it as a python object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _getConfig(general_config_dir: str = None):\n    stp_config = STPConfig()\n    plenum_config = import_module(\"plenum.config\")\n    config = stp_config\n    config.__dict__.update(plenum_config.__dict__)\n\n    if general_config_dir:\n        config.GENERAL_CONFIG_DIR = general_config_dir\n\n    if not config.GENERAL_CONFIG_DIR:\n        raise Exception('GENERAL_CONFIG_DIR must be set')\n\n    extend_with_external_config(config, (config.GENERAL_CONFIG_DIR,\n                                         config.GENERAL_CONFIG_FILE))\n\n    # \"unsafe\" is a set of attributes that can set certain behaviors that\n    # are not safe, for example, 'disable_view_change' disables view changes\n    # from happening. This might be useful in testing scenarios, but never\n    # in a live network.\n    if not hasattr(config, 'unsafe'):\n        setattr(config, 'unsafe', set())\n    return config", "response": "Reads a file called config. py in the project directory and returns a python object containing the configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getFunc(self, o: Any) -> Callable:\n        for cls, func in self.routes.items():\n            if isinstance(o, cls):\n                return func\n        logger.error(\"Unhandled msg {}, available handlers are:\".format(o))\n        for cls in self.routes.keys():\n            logger.error(\"   {}\".format(cls))\n        raise RuntimeError(\"unhandled msg: {}\".format(o))", "response": "Get the next function that can process o."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle a message from the server.", "response": "def handleSync(self, msg: Any) -> Any:\n        \"\"\"\n        Pass the message as an argument to the function defined in `routes`.\n        If the msg is a tuple, pass the values as multiple arguments to the function.\n\n        :param msg: tuple of object and callable\n        \"\"\"\n        # If a plain python tuple and not a named tuple, a better alternative\n        # would be to create a named entity with the 3 characteristics below\n        # TODO: non-obvious tuple, re-factor!\n        if isinstance(msg, tuple) and len(\n                msg) == 2 and not hasattr(msg, '_field_types'):\n            return self.getFunc(msg[0])(*msg)\n        else:\n            return self.getFunc(msg)(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle both sync and async functions.", "response": "async def handle(self, msg: Any) -> Any:\n        \"\"\"\n        Handle both sync and async functions.\n\n        :param msg: a message\n        :return: the result of execution of the function corresponding to this message's type\n        \"\"\"\n        res = self.handleSync(msg)\n        if isawaitable(res):\n            return await res\n        else:\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles all items in a deque. Can call asynchronous handlers.", "response": "async def handleAll(self, deq: deque, limit=None) -> int:\n        \"\"\"\n        Handle all items in a deque. Can call asynchronous handlers.\n\n        :param deq: a deque of items to be handled by this router\n        :param limit: the number of items in the deque to the handled\n        :return: the number of items handled successfully\n        \"\"\"\n        count = 0\n        while deq and (not limit or count < limit):\n            count += 1\n            item = deq.popleft()\n            await self.handle(item)\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handleAllSync(self, deq: deque, limit=None) -> int:\n        count = 0\n        while deq and (not limit or count < limit):\n            count += 1\n            msg = deq.popleft()\n            self.handleSync(msg)\n        return count", "response": "Synchronously handle all items in a deque."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload this tree from a dumb data object for serialisation.", "response": "def load(self, other: merkle_tree.MerkleTree):\n        \"\"\"Load this tree from a dumb data object for serialisation.\n\n        The object must have attributes tree_size:int and hashes:list.\n        \"\"\"\n        self._update(other.tree_size, other.hashes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave this tree into a dumb data object for serialisation.", "response": "def save(self, other: merkle_tree.MerkleTree):\n        \"\"\"Save this tree into a dumb data object for serialisation.\n\n        The object must have attributes tree_size:int and hashes:list.\n        \"\"\"\n        other.__tree_size = self.__tree_size\n        other.__hashes = self.__hashes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the root hash of this tree.", "response": "def root_hash(self):\n        \"\"\"Returns the root hash of this tree. (Only re-computed on change.)\"\"\"\n        if self.__root_hash is None:\n            self.__root_hash = (\n                self.__hasher._hash_fold(self.__hashes)\n                if self.__hashes else self.__hasher.hash_empty())\n        return self.__root_hash"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend a new leaf onto the end of the tree and return the audit path", "response": "def append(self, new_leaf: bytes) -> List[bytes]:\n        \"\"\"Append a new leaf onto the end of this tree and return the\n        audit path\"\"\"\n        auditPath = list(reversed(self.__hashes))\n        self._push_subtree([new_leaf])\n        return auditPath"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extend(self, new_leaves: List[bytes]):\n        size = len(new_leaves)\n        final_size = self.tree_size + size\n        idx = 0\n        while True:\n            # keep pushing subtrees until mintree_size > remaining\n            max_h = self.__mintree_height\n            max_size = 1 << (max_h - 1) if max_h > 0 else 0\n            if max_h > 0 and size - idx >= max_size:\n                self._push_subtree(new_leaves[idx:idx + max_size])\n                idx += max_size\n            else:\n                break\n        # fill in rest of tree in one go, now that we can\n        if idx < size:\n            root_hash, hashes = self.__hasher._hash_full(new_leaves, idx, size)\n            self._update(final_size, self.hashes + hashes)\n        assert self.tree_size == final_size", "response": "Extend this tree with new_leaves on the end."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extended(self, new_leaves: List[bytes]):\n        new_tree = self.__copy__()\n        new_tree.extend(new_leaves)\n        return new_tree", "response": "Returns a new tree equal to this tree extended with new_leaves."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify_consistency(self, expected_leaf_count) -> bool:\n        if expected_leaf_count != self.leafCount:\n            raise ConsistencyVerificationFailed()\n        if self.get_expected_node_count(self.leafCount) != self.nodeCount:\n            raise ConsistencyVerificationFailed()\n        return True", "response": "Verify that the tree has the same leaf count as expected and the number of nodes as expected."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns whether the given string represents a hex value or not", "response": "def isHex(val: str) -> bool:\n    \"\"\"\n    Return whether the given str represents a hex value or not\n\n    :param val: the string to check\n    :return: whether the given str represents a hex value\n    \"\"\"\n    if isinstance(val, bytes):\n        # only decodes utf-8 string\n        try:\n            val = val.decode()\n        except ValueError:\n            return False\n    return isinstance(val, str) and all(c in string.hexdigits for c in val)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating client and server CURVE certificates.", "response": "def generate_certificates(base_dir, *peer_names, pubKeyDir=None,\n                          secKeyDir=None, sigKeyDir=None,\n                          verkeyDir=None, clean=True):\n    ''' Generate client and server CURVE certificate files'''\n    pubKeyDir = pubKeyDir or 'public_keys'\n    secKeyDir = secKeyDir or 'private_keys'\n    verkeyDir = verkeyDir or 'verif_keys'\n    sigKeyDir = sigKeyDir or 'sig_keys'\n\n    # keys_dir = os.path.join(base_dir, 'certificates')\n    e_keys_dir = os.path.join(base_dir, '_enc')\n    s_keys_dir = os.path.join(base_dir, '_sig')\n\n    public_keys_dir = os.path.join(base_dir, pubKeyDir)\n    secret_keys_dir = os.path.join(base_dir, secKeyDir)\n    ver_keys_dir = os.path.join(base_dir, verkeyDir)\n    sig_keys_dir = os.path.join(base_dir, sigKeyDir)\n\n    # Create directories for certificates, remove old content if necessary\n    for d in [e_keys_dir, s_keys_dir, public_keys_dir, secret_keys_dir,\n              ver_keys_dir, sig_keys_dir]:\n        if clean and os.path.exists(d):\n            shutil.rmtree(d)\n        os.makedirs(d, exist_ok=True)\n\n    # create new keys in certificates dir\n    for peer_name in peer_names:\n        createEncAndSigKeys(e_keys_dir, s_keys_dir, peer_name)\n\n    # move public keys to appropriate directory\n    for keys_dir, pkdir, skdir in [\n        (e_keys_dir, public_keys_dir, secret_keys_dir),\n        (s_keys_dir, ver_keys_dir, sig_keys_dir)\n    ]:\n        moveKeyFilesToCorrectLocations(keys_dir, pkdir, skdir)\n\n    shutil.rmtree(e_keys_dir)\n    shutil.rmtree(s_keys_dir)\n\n    print('Public keys in {}'.format(public_keys_dir))\n    print('Private keys in {}'.format(secret_keys_dir))\n    print('Verification keys in {}'.format(ver_keys_dir))\n    print('Signing keys in {}'.format(sig_keys_dir))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lookup(self, path, is_committed=True, with_proof=False) -> (str, int):\n        assert path is not None\n        head_hash = self.state.committedHeadHash if is_committed else self.state.headHash\n        encoded, proof = self._get_value_from_state(path, head_hash, with_proof=with_proof)\n        if encoded:\n            value, last_seq_no, last_update_time = decode_state_value(encoded)\n            return value, last_seq_no, last_update_time, proof\n        return None, None, None, proof", "response": "Queries the state for a specific data entry in the state at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _accumulate(self, old_accum, next_val):\n        return old_accum * (1 - self.alpha) + next_val * self.alpha", "response": "Implement exponential moving average\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getNodePosition(cls, start, height=None) -> int:\n        pwr = highest_bit_set(start) - 1\n        height = height or pwr\n        if count_bits_set(start) == 1:\n            adj = height - pwr\n            return start - 1 + adj\n        else:\n            c = pow(2, pwr)\n            return cls.getNodePosition(c, pwr) + \\\n                cls.getNodePosition(start - c, height)", "response": "Calculates the node s position based on start and height."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the audit path of the leaf at the specified sequence number.", "response": "def getPath(cls, seqNo, offset=0):\n        \"\"\"\n        Get the audit path of the leaf at the position specified by serNo.\n\n        :param seqNo: sequence number of the leaf to calculate the path for\n        :param offset: the sequence number of the node from where the path\n         should begin.\n        :return: tuple of leafs and nodes\n        \"\"\"\n        if offset >= seqNo:\n            raise ValueError(\"Offset should be less than serial number\")\n        pwr = highest_bit_set(seqNo - 1 - offset) - 1\n        if pwr <= 0:\n            if seqNo % 2 == 0:\n                return [seqNo - 1], []\n            else:\n                return [], []\n        c = pow(2, pwr) + offset\n        leafs, nodes = cls.getPath(seqNo, c)\n        nodes.append(cls.getNodePosition(c, pwr))\n        return leafs, nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches the nodeHash based on start and height of the node in the tree.", "response": "def readNodeByTree(self, start, height=None):\n        \"\"\"\n        Fetches nodeHash based on start leaf and height of the node in the tree.\n\n        :return: the nodeHash\n        \"\"\"\n        pos = self.getNodePosition(start, height)\n        return self.readNode(pos)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_consistent(self) -> bool:\n        from ledger.compact_merkle_tree import CompactMerkleTree\n        return self.nodeCount == CompactMerkleTree.get_expected_node_count(\n            self.leafCount)", "response": "Returns True if number of nodes are consistent with number of leaves."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclosing current and start next chunk", "response": "def _startNextChunk(self) -> None:\n        \"\"\"\n        Close current and start next chunk\n        \"\"\"\n        if self.currentChunk is None:\n            self._useLatestChunk()\n        else:\n            self._useChunk(self.currentChunkIndex + self.chunkSize)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_key_location(self, key) -> (int, int):\n        key = int(key)\n        if key == 0:\n            return 1, 0\n        remainder = key % self.chunkSize\n        addend = ChunkedFileStore.firstChunkIndex\n        chunk_no = key - remainder + addend if remainder \\\n            else key - self.chunkSize + addend\n        offset = remainder or self.chunkSize\n        return chunk_no, offset", "response": "Return chunk no and offset of key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the value corresponding to the specified key.", "response": "def get(self, key) -> str:\n        \"\"\"\n        Determines the file to retrieve the data from and retrieves the data.\n\n        :return: value corresponding to specified key\n        \"\"\"\n        # TODO: get is creating files when a key is given which is more than\n        # the store size\n        chunk_no, offset = self._get_key_location(key)\n        with self._openChunk(chunk_no) as chunk:\n            return chunk.get(str(offset))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset(self) -> None:\n        self.close()\n        for f in os.listdir(self.dataDir):\n            os.remove(os.path.join(self.dataDir, f))\n        self._useLatestChunk()", "response": "Clear all data in file storage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding all the lines in a store", "response": "def _lines(self):\n        \"\"\"\n        Lines in a store (all chunks)\n\n        :return: lines\n        \"\"\"\n\n        chunkIndices = self._listChunks()\n        for chunkIndex in chunkIndices:\n            with self._openChunk(chunkIndex) as chunk:\n                yield from chunk._lines()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists stored chunks :return: sorted list of available chunk indices", "response": "def _listChunks(self):\n        \"\"\"\n        Lists stored chunks\n\n        :return: sorted list of available chunk indices\n        \"\"\"\n        chunks = []\n        for fileName in os.listdir(self.dataDir):\n            index = ChunkedFileStore._fileNameToChunkIndex(fileName)\n            if index is not None:\n                chunks.append(index)\n        return sorted(chunks)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filterMsgs(self, wrappedMsgs: deque) -> deque:\n        filtered = deque()\n        while wrappedMsgs:\n            wrappedMsg = wrappedMsgs.popleft()\n            msg, sender = wrappedMsg\n            if hasattr(msg, f.VIEW_NO.nm):\n                reqViewNo = getattr(msg, f.VIEW_NO.nm)\n                if reqViewNo == self.viewNo:\n                    filtered.append(wrappedMsg)\n                else:\n                    self.discard(wrappedMsg,\n                                 \"its view no {} is less than the elector's {}\"\n                                 .format(reqViewNo, self.viewNo),\n                                 logger.debug)\n            else:\n                filtered.append(wrappedMsg)\n\n        return filtered", "response": "Filter the given messages by view number so that only the messages that have the current view number are retained."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def serviceQueues(self, limit=None) -> int:\n\n        return await self.inBoxRouter.handleAll(self.filterMsgs(self.inBox),\n                                                limit)", "response": "Service at most limit messages from the inBox."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the view change has started.", "response": "def view_change_started(self, viewNo: int):\n        \"\"\"\n        Notifies primary decider about the fact that view changed to let it\n        prepare for election, which then will be started from outside by\n        calling decidePrimaries()\n        \"\"\"\n        if viewNo <= self.viewNo:\n            logger.warning(\"{}Provided view no {} is not greater\"\n                           \" than the current view no {}\"\n                           .format(VIEW_CHANGE_PREFIX, viewNo, self.viewNo))\n            return False\n        self.previous_master_primary = self.node.master_primary_name\n        for replica in self.replicas.values():\n            replica.primaryName = None\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, msg):\n        logger.debug(\"{}'s elector sending {}\".format(self.name, msg))\n        self.outBox.append(msg)", "response": "Send a message to the node on which this replica resides."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef authenticate(self, req_data, key=None):\n        identifiers = set()\n        typ = req_data.get(OPERATION, {}).get(TXN_TYPE)\n        if key and self._check_and_verify_existing_req(req_data, key):\n            return self._verified_reqs[key]['identifiers']\n\n        for authenticator in self._authenticators:\n            if authenticator.is_query(typ):\n                return set()\n            if not (authenticator.is_write(typ) or\n                    authenticator.is_action(typ)):\n                continue\n            rv = authenticator.authenticate(deepcopy(req_data)) or set()\n            identifiers.update(rv)\n\n        if not identifiers:\n            raise NoAuthenticatorFound\n        if key:\n            self._verified_reqs[key] = {'signature': req_data.get(f.SIG.nm)}\n            self._verified_reqs[key]['identifiers'] = identifiers\n        return identifiers", "response": "Authenticates a given request data by verifying signatures from any registered authenticators."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a plugin by name.", "response": "def get(self, name):\n        \"\"\"Retrieve a plugin by name.\"\"\"\n        try:\n            return self.plugins[name]\n        except KeyError:\n            raise RuntimeError(\"plugin {} does not exist\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nauthenticates the client s message with the signature provided.", "response": "def authenticate(self,\n                     msg: Dict,\n                     identifier: Optional[str] = None,\n                     signature: Optional[str] = None,\n                     threshold: Optional[int] = None,\n                     key: Optional[str] = None) -> str:\n        \"\"\"\n        Authenticate the client's message with the signature provided.\n\n        :param identifier: some unique identifier; if None, then try to use\n        msg['identifier'] as identifier\n        :param signature: a utf-8 and base58 encoded signature\n        :param msg: the message to authenticate\n        :param threshold: The number of successful signature verification\n        :param key: The key of request for storing in internal maps\n        required. By default all signatures are required to be verified.\n        :return: the identifier; an exception of type SigningException is\n            raised if the signature is not valid\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef authenticate_multi(self, msg: Dict, signatures: Dict[str, str],\n                           threshold: Optional[int] = None):\n        \"\"\"\n        :param msg:\n        :param signatures: A mapping from identifiers to signatures.\n        :param threshold: The number of successful signature verification\n        required. By default all signatures are required to be verified.\n        :return: returns the identifiers whose signature was matched and\n        correct; a SigningException is raised if threshold was not met\n        \"\"\"", "response": "Authenticate a message with multiple identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nauthenticate the data for the current user and return the unique ID.", "response": "def authenticate(self, req_data, identifier: Optional[str]=None,\n                     signature: Optional[str]=None, threshold: Optional[int] = None,\n                     verifier: Verifier=DidVerifier):\n        \"\"\"\n        Prepares the data to be serialised for signing and then verifies the\n        signature\n        :param req_data:\n        :param identifier:\n        :param signature:\n        :param verifier:\n        :return:\n        \"\"\"\n        to_serialize = {k: v for k, v in req_data.items()\n                        if k not in self.excluded_from_signing}\n        if req_data.get(f.SIG.nm) is None and \\\n                req_data.get(f.SIGS.nm) is None and \\\n                signature is None:\n            raise MissingSignature\n        if req_data.get(f.IDENTIFIER.nm) and (req_data.get(f.SIG.nm) or\n                                              signature):\n            try:\n                # if not identifier:\n                identifier = identifier or self._extract_identifier(req_data)\n\n                # if not signature:\n                signature = signature or self._extract_signature(req_data)\n\n                signatures = {identifier: signature}\n            except Exception as ex:\n                if ex in (MissingSignature, EmptySignature, MissingIdentifier,\n                          EmptyIdentifier):\n                    ex = ex(req_data.get(f.IDENTIFIER.nm), req_data.get(f.SIG.nm))\n                raise ex\n        else:\n            signatures = req_data.get(f.SIGS.nm, None)\n        return self.authenticate_multi(to_serialize, signatures=signatures,\n                                       threshold=threshold, verifier=verifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cmp(cls, v1: 'VersionBase', v2: 'VersionBase') -> int:\n        # TODO types checking\n        if v1._version > v2._version:\n            return 1\n        elif v1._version == v2._version:\n            return 0\n        else:\n            return -1", "response": "Compares two version objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks whether the registry contains some addresses", "response": "def reconcileNodeReg(self) -> set:\n        \"\"\"\n        Check whether registry contains some addresses\n        that were never connected to\n        :return:\n        \"\"\"\n\n        matches = set()\n        for name, remote in self.remotes.items():\n            if name not in self.registry:\n                continue\n            if self.sameAddr(remote.ha, self.registry[name]):\n                matches.add(name)\n                logger.debug(\"{} matched remote {} {}\".\n                             format(self, remote.uid, remote.ha))\n        return self.registry.keys() - matches - {self.name}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to the missing nodes", "response": "def connectToMissing(self) -> set:\n        \"\"\"\n        Try to connect to the missing nodes\n        \"\"\"\n\n        missing = self.reconcileNodeReg()\n        if not missing:\n            return missing\n\n        logger.info(\"{}{} found the following missing connections: {}\".\n                    format(CONNECTION_PREFIX, self, \", \".join(missing)))\n\n        for name in missing:\n            try:\n                self.connect(name, ha=self.registry[name])\n            except (ValueError, KeyError, PublicKeyNotFoundOnDisk, VerKeyNotFoundOnDisk) as ex:\n                logger.warning('{}{} cannot connect to {} due to {}'.\n                               format(CONNECTION_PREFIX, self, name, ex))\n        return missing"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npasses the log record back to the CLI for rendering", "response": "def emit(self, record):\n        \"\"\"\n        Passes the log record back to the CLI for rendering\n        \"\"\"\n        should_cb = None\n        attr_val = None\n        if hasattr(record, self.typestr):\n            attr_val = getattr(record, self.typestr)\n            should_cb = bool(attr_val)\n        if should_cb is None and record.levelno >= logging.INFO:\n            should_cb = True\n        if hasattr(record, 'tags'):\n            for t in record.tags:\n                if t in self.tags:\n                    if self.tags[t]:\n                        should_cb = True\n                        continue\n                    else:\n                        should_cb = False\n                        break\n        if should_cb:\n            self.callback(record, attr_val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the request object for the current version of the resource.", "response": "def validate(self, dct):\n        \"\"\"\n        Choose a schema for client request operation and validate\n        the operation field. If the schema is not found skips validation.\n        :param dct: an operation field from client request\n        :return: raises exception if invalid request\n        \"\"\"\n        if not isinstance(dct, dict):\n            # TODO this check should be in side of the validator not here\n            self._raise_invalid_fields('', dct, 'wrong type')\n        txn_type = dct.get(TXN_TYPE)\n        if txn_type is None:\n            self._raise_missed_fields(TXN_TYPE)\n        if txn_type in self.operations:\n            # check only if the schema is defined\n            op = self.operations[txn_type]\n            op.validate(dct)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef conns(self, value: Set[str]) -> None:\n        if not self._conns == value:\n            old = self._conns\n            self._conns = value\n            ins = value - old\n            outs = old - value\n            logger.display(\"{}'s connections changed from {} to {}\".format(self, old, value))\n            self._connsChanged(ins, outs)", "response": "Updates the number of connections of this node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _connsChanged(self, ins: Set[str], outs: Set[str]) -> None:\n        for o in outs:\n            logger.display(\"{}{} disconnected from {}\".format(CONNECTION_PREFIX, self, o),\n                           extra={\"cli\": \"IMPORTANT\", \"tags\": [\"connected\"]})\n        for i in ins:\n            logger.display(\"{}{} now connected to {}\".format(CONNECTION_PREFIX, self, i),\n                           extra={\"cli\": \"IMPORTANT\", \"tags\": [\"connected\"]})\n\n            # remove remotes for same ha when a connection is made\n            remote = self.getRemote(i)\n            others = [r for r in self.remotes.values()\n                      if r.ha == remote.ha and r.name != i]\n            for o in others:\n                logger.debug(\"{} removing other remote\".format(self))\n                self.removeRemote(o)\n\n        self.onConnsChanged(ins, outs)", "response": "Called by the connection count manager when a connection count has changed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of the remote by HA if found in the node registry else returns None", "response": "def findInNodeRegByHA(self, remoteHa):\n        \"\"\"\n        Returns the name of the remote by HA if found in the node registry, else\n        returns None\n        \"\"\"\n        regName = [nm for nm, ha in self.registry.items()\n                   if self.sameAddr(ha, remoteHa)]\n        if len(regName) > 1:\n            raise RuntimeError(\"more than one node registry entry with the \"\n                               \"same ha {}: {}\".format(remoteHa, regName))\n        if regName:\n            return regName[0]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of the remote object if found in node registry.", "response": "def getRemoteName(self, remote):\n        \"\"\"\n        Returns the name of the remote object if found in node registry.\n\n        :param remote: the remote object\n        \"\"\"\n        if remote.name not in self.registry:\n            find = [name for name, ha in self.registry.items()\n                    if ha == remote.ha]\n            assert len(find) == 1\n            return find[0]\n        return remote.name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef notConnectedNodes(self) -> Set[str]:\n        return set(self.registry.keys()) - self.conns", "response": "Returns the names of nodes that are NOT connected to the node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating and bind the ZAP socket", "response": "def start(self):\n        \"\"\"Create and bind the ZAP socket\"\"\"\n        self.zap_socket = self.context.socket(zmq.REP)\n        self.zap_socket.linger = 1\n        zapLoc = 'inproc://zeromq.zap.{}'.format(MultiZapAuthenticator.count)\n        self.zap_socket.bind(zapLoc)\n        self.log.debug('Starting ZAP at {}'.format(zapLoc))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclosing the ZAP socket and close the ZAP instance.", "response": "def stop(self):\n        \"\"\"Close the ZAP socket\"\"\"\n        if self.zap_socket:\n            self.log.debug(\n                'Stopping ZAP at {}'.format(self.zap_socket.LAST_ENDPOINT))\n            super().stop()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a random string in hex of the specified size", "response": "def randomString(size: int = 20) -> str:\n    \"\"\"\n    Generate a random string in hex of the specified size\n\n    DO NOT use python provided random class its a Pseudo Random Number Generator\n    and not secure enough for our needs\n\n    :param size: size of the random string to generate\n    :return: the hexadecimal random string\n    \"\"\"\n\n    def randomStr(size):\n        if not isinstance(size, int):\n            raise PlenumTypeError('size', size, int)\n        if not size > 0:\n            raise PlenumValueError('size', size, '> 0')\n        # Approach 1\n        rv = randombytes(size // 2).hex()\n\n        return rv if size % 2 == 0 else rv + hex(randombytes_uniform(15))[-1]\n\n        # Approach 2 this is faster than Approach 1, but lovesh had a doubt\n        # that part of a random may not be truly random, so until\n        # we have definite proof going to retain it commented\n        # rstr = randombytes(size).hex()\n        # return rstr[:size]\n\n    return randomStr(size)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef random_from_alphabet(size, alphabet):\n    import random\n    return list(random.choice(alphabet) for _ in range(size))", "response": "Takes size random elements from provided alphabet"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mostCommonElement(elements: Iterable[T], to_hashable_f: Callable=None):\n    class _Hashable(collections.abc.Hashable):\n        def __init__(self, orig):\n            self.orig = orig\n\n            if isinstance(orig, collections.Hashable):\n                self.hashable = orig\n            elif to_hashable_f is not None:\n                self.hashable = to_hashable_f(orig)\n            else:\n                self.hashable = json.dumps(orig, sort_keys=True)\n\n        def __eq__(self, other):\n            return self.hashable == other.hashable\n\n        def __hash__(self):\n            return hash(self.hashable)\n\n    _elements = (_Hashable(el) for el in elements)\n    most_common, counter = Counter(_elements).most_common(n=1)[0]\n    return most_common.orig, counter", "response": "Find the most frequent element of a collection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef objSearchReplace(obj: Any,\n                     toFrom: Dict[Any, Any],\n                     checked: Set[Any]=None,\n                     logMsg: str=None,\n                     deepLevel: int=None) -> None:\n    \"\"\"\n    Search for an attribute in an object and replace it with another.\n\n    :param obj: the object to search for the attribute\n    :param toFrom: dictionary of the attribute name before and after search and replace i.e. search for the key and replace with the value\n    :param checked: set of attributes of the object for recursion. optional. defaults to `set()`\n    :param logMsg: a custom log message\n    \"\"\"\n\n    if checked is None:\n        checked = set()\n\n    checked.add(id(obj))\n    pairs = [(i, getattr(obj, i)) for i in dir(obj) if not i.startswith(\"__\")]\n\n    if isinstance(obj, Mapping):\n        pairs += [x for x in iteritems(obj)]\n    elif isinstance(obj, (Sequence, Set)) and not isinstance(obj, string_types):\n        pairs += [x for x in enumerate(obj)]\n\n    for nm, o in pairs:\n        if id(o) not in checked:\n            mutated = False\n            for old, new in toFrom.items():\n                if id(o) == id(old):\n                    logging.debug(\n                        \"{}in object {}, attribute {} changed from {} to {}\". format(\n                            logMsg + \": \" if logMsg else \"\", obj, nm, old, new))\n                    if isinstance(obj, dict):\n                        obj[nm] = new\n                    else:\n                        setattr(obj, nm, new)\n                    mutated = True\n            if not mutated:\n                if deepLevel is not None and deepLevel == 0:\n                    continue\n                objSearchReplace(o, toFrom, checked, logMsg, deepLevel -\n                                 1 if deepLevel is not None else deepLevel)\n    checked.remove(id(obj))", "response": "Search for an attribute in an object and replace it with another."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning an array of coroutines", "response": "async def runall(corogen):\n    \"\"\"\n    Run an array of coroutines\n\n    :param corogen: a generator that generates coroutines\n    :return: list or returns of the coroutines\n    \"\"\"\n    results = []\n    for c in corogen:\n        result = await c\n        results.append(result)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prime_gen() -> int:\n    # credit to David Eppstein, Wolfgang Beneicke, Paul Hofstra\n    \"\"\"\n    A generator for prime numbers starting from 2.\n    \"\"\"\n    D = {}\n    yield 2\n    for q in itertools.islice(itertools.count(3), 0, None, 2):\n        p = D.pop(q, None)\n        if p is None:\n            D[q * q] = 2 * q\n            yield q\n        else:\n            x = p + q\n            while x in D:\n                x += p\n            D[x] = p", "response": "A generator for prime numbers starting from 2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def untilTrue(condition, *args, timeout=5) -> bool:\n    result = False\n    start = time.perf_counter()\n    elapsed = 0\n    while elapsed < timeout:\n        result = condition(*args)\n        if result:\n            break\n        await asyncio.sleep(.1)\n        elapsed = time.perf_counter() - start\n    return result", "response": "Keep checking the condition till it is true"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compareNamedTuple(tuple1: NamedTuple, tuple2: NamedTuple, *fields):\n    tuple1 = tuple1._asdict()\n    tuple2 = tuple2._asdict()\n    comp = []\n    for field in fields:\n        comp.append(tuple1[field] == tuple2[field])\n    return all(comp)", "response": "Compare provided fields of 2 named tuples for equality and returns true\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a pretty string of the difference between two dates.", "response": "def prettyDateDifference(startTime, finishTime=None):\n    \"\"\"\n    Get a datetime object or a int() Epoch timestamp and return a\n    pretty string like 'an hour ago', 'Yesterday', '3 months ago',\n    'just now', etc\n    \"\"\"\n    from datetime import datetime\n\n    if startTime is None:\n        return None\n\n    if not isinstance(startTime, (int, datetime)):\n        raise RuntimeError(\"Cannot parse time\")\n\n    endTime = finishTime or datetime.now()\n\n    if isinstance(startTime, int):\n        diff = endTime - datetime.fromtimestamp(startTime)\n    elif isinstance(startTime, datetime):\n        diff = endTime - startTime\n    else:\n        diff = endTime - endTime\n\n    second_diff = diff.seconds\n    day_diff = diff.days\n\n    if day_diff < 0:\n        return ''\n\n    if day_diff == 0:\n        if second_diff < 10:\n            return \"just now\"\n        if second_diff < 60:\n            return str(second_diff) + \" seconds ago\"\n        if second_diff < 120:\n            return \"a minute ago\"\n        if second_diff < 3600:\n            return str(int(second_diff / 60)) + \" minutes ago\"\n        if second_diff < 7200:\n            return \"an hour ago\"\n        if second_diff < 86400:\n            return str(int(second_diff / 3600)) + \" hours ago\"\n    if day_diff == 1:\n        return \"Yesterday\"\n    if day_diff < 7:\n        return str(day_diff) + \" days ago\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compare_3PC_keys(key1, key2) -> int:\n    if key1[0] == key2[0]:\n        return key2[1] - key1[1]\n    else:\n        return key2[0] - key1[0]", "response": "Compare two 3PC keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates and return a hashStore implementation based on configuration", "response": "def initHashStore(data_dir, name, config=None, read_only=False) -> HashStore:\n    \"\"\"\n    Create and return a hashStore implementation based on configuration\n    \"\"\"\n    config = config or getConfig()\n    hsConfig = config.hashStore['type'].lower()\n    if hsConfig == HS_FILE:\n        return FileHashStore(dataDir=data_dir,\n                             fileNamePrefix=name)\n    elif hsConfig == HS_LEVELDB or hsConfig == HS_ROCKSDB:\n        return DbHashStore(dataDir=data_dir,\n                           fileNamePrefix=name,\n                           db_type=hsConfig,\n                           read_only=read_only,\n                           config=config)\n    else:\n        return MemoryHashStore()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the object with the given name if it exists or raises DidMethodNotFound if it does not exist.", "response": "def get(self, didMethodName, required=True) -> DidMethod:\n        \"\"\"\n        :param didMethodName: name of DID Method\n        :param required: if not found and True, throws an exception, else None\n        :return: DID Method\n        \"\"\"\n        dm = self.d.get(didMethodName) if didMethodName else self.default\n        if not dm and required:\n            raise DidMethodNotFound\n        return dm"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transmitToClient(self, msg: Any, remoteName: str):\n        payload = self.prepForSending(msg)\n        try:\n            if isinstance(remoteName, str):\n                remoteName = remoteName.encode()\n            self.send(payload, remoteName)\n        except Exception as ex:\n            # TODO: This should not be an error since the client might not have\n            # sent the request to all nodes but only some nodes and other\n            # nodes might have got this request through PROPAGATE and thus\n            # might not have connection with the client.\n            logger.error(\n                \"{}{} unable to send message {} to client {}; Exception: {}\" .format(\n                    CONNECTION_PREFIX, self, msg, remoteName, ex.__repr__()))", "response": "Transmit the specified message to the remote client specified by remoteName."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges any newly received txns during catchup with already received txns", "response": "def _merge_catchup_txns(existing_txns, new_txns):\n        \"\"\"\n        Merge any newly received txns during catchup with already received txns\n        :param existing_txns:\n        :param new_txns:\n        :return:\n        \"\"\"\n        # TODO: Can we replace this with SortedDict and before merging substract existing transactions from new?\n        idx_to_remove = []\n        start_seq_no = new_txns[0][0]\n        end_seq_no = new_txns[-1][0]\n        for seq_no, _ in existing_txns:\n            if seq_no < start_seq_no:\n                continue\n            if seq_no > end_seq_no:\n                break\n            idx_to_remove.append(seq_no - start_seq_no)\n        for idx in reversed(idx_to_remove):\n            new_txns.pop(idx)\n\n        return list(merge(existing_txns, new_txns, key=lambda v: v[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _has_valid_catchup_replies(self, seq_no: int, txns_to_process: List[Tuple[int, Any]]) -> Tuple[bool, str, int]:\n\n        # TODO: Remove after stop passing seqNo here\n        assert seq_no == txns_to_process[0][0]\n\n        # Here seqNo has to be the seqNo of first transaction of\n        # `catchupReplies`\n\n        # Get the transactions in the catchup reply which has sequence\n        # number `seqNo`\n        node_name, catchup_rep = self._find_catchup_reply_for_seq_no(seq_no)\n        txns = catchup_rep.txns\n\n        # Add only those transaction in the temporary tree from the above\n        # batch which are not present in the ledger\n        # Integer keys being converted to strings when marshaled to JSON\n        txns = [self._provider.transform_txn_for_ledger(txn)\n                for s, txn in txns_to_process[:len(txns)]\n                if str(s) in txns]\n\n        # Creating a temporary tree which will be used to verify consistency\n        # proof, by inserting transactions. Duplicating a merkle tree is not\n        # expensive since we are using a compact merkle tree.\n        temp_tree = self._ledger.treeWithAppliedTxns(txns)\n\n        proof = catchup_rep.consProof\n        final_size = self._catchup_till.final_size\n        final_hash = self._catchup_till.final_hash\n        try:\n            logger.info(\"{} verifying proof for {}, {}, {}, {}, {}\".\n                        format(self, temp_tree.tree_size, final_size,\n                               temp_tree.root_hash, final_hash, proof))\n            verified = self._provider.verifier(self._ledger_id).verify_tree_consistency(\n                temp_tree.tree_size,\n                final_size,\n                temp_tree.root_hash,\n                Ledger.strToHash(final_hash),\n                [Ledger.strToHash(p) for p in proof]\n            )\n\n        except Exception as ex:\n            logger.info(\"{} could not verify catchup reply {} since {}\".format(self, catchup_rep, ex))\n            verified = False\n        return bool(verified), node_name, len(txns)", "response": "Checks if the given sequence number is valid for catchup replies."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parseLedgerForHaAndKeys(ledger, returnActive=True, ledger_size=None):\n        nodeReg = OrderedDict()\n        cliNodeReg = OrderedDict()\n        nodeKeys = {}\n        activeValidators = set()\n        try:\n            TxnStackManager._parse_pool_transaction_file(\n                ledger, nodeReg, cliNodeReg, nodeKeys, activeValidators,\n                ledger_size=ledger_size)\n        except ValueError:\n            errMsg = 'Pool transaction file corrupted. Rebuild pool transactions.'\n            logger.exception(errMsg)\n            exit(errMsg)\n\n        if returnActive:\n            allNodes = tuple(nodeReg.keys())\n            for nodeName in allNodes:\n                if nodeName not in activeValidators:\n                    nodeReg.pop(nodeName, None)\n                    cliNodeReg.pop(nodeName + CLIENT_STACK_SUFFIX, None)\n                    nodeKeys.pop(nodeName, None)\n\n            return nodeReg, cliNodeReg, nodeKeys\n        else:\n            return nodeReg, cliNodeReg, nodeKeys, activeValidators", "response": "Parses the ledger for a single host and key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the pool transaction file.", "response": "def _parse_pool_transaction_file(\n            ledger, nodeReg, cliNodeReg, nodeKeys, activeValidators,\n            ledger_size=None):\n        \"\"\"\n        helper function for parseLedgerForHaAndKeys\n        \"\"\"\n        for _, txn in ledger.getAllTxn(to=ledger_size):\n            if get_type(txn) == NODE:\n                txn_data = get_payload_data(txn)\n                nodeName = txn_data[DATA][ALIAS]\n                clientStackName = nodeName + CLIENT_STACK_SUFFIX\n                nHa = (txn_data[DATA][NODE_IP], txn_data[DATA][NODE_PORT]) \\\n                    if (NODE_IP in txn_data[DATA] and NODE_PORT in txn_data[DATA]) \\\n                    else None\n                cHa = (txn_data[DATA][CLIENT_IP], txn_data[DATA][CLIENT_PORT]) \\\n                    if (CLIENT_IP in txn_data[DATA] and CLIENT_PORT in txn_data[DATA]) \\\n                    else None\n                if nHa:\n                    nodeReg[nodeName] = HA(*nHa)\n                if cHa:\n                    cliNodeReg[clientStackName] = HA(*cHa)\n\n                try:\n                    # TODO: Need to handle abbreviated verkey\n                    key_type = 'verkey'\n                    verkey = cryptonymToHex(str(txn_data[TARGET_NYM]))\n                    key_type = 'identifier'\n                    cryptonymToHex(get_from(txn))\n                except ValueError:\n                    logger.exception(\n                        'Invalid {}. Rebuild pool transactions.'.format(key_type))\n                    exit('Invalid {}. Rebuild pool transactions.'.format(key_type))\n\n                nodeKeys[nodeName] = verkey\n\n                services = txn_data[DATA].get(SERVICES)\n                if isinstance(services, list):\n                    if VALIDATOR in services:\n                        activeValidators.add(nodeName)\n                    else:\n                        activeValidators.discard(nodeName)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform_txn_for_ledger(txn):\n        '''\n        Makes sure that we have integer as keys after possible deserialization from json\n        :param txn: txn to be transformed\n        :return: transformed txn\n        '''\n        txn_data = get_payload_data(txn)\n        txn_data[AUDIT_TXN_LEDGERS_SIZE] = {int(k): v for k, v in txn_data[AUDIT_TXN_LEDGERS_SIZE].items()}\n        txn_data[AUDIT_TXN_LEDGER_ROOT] = {int(k): v for k, v in txn_data[AUDIT_TXN_LEDGER_ROOT].items()}\n        txn_data[AUDIT_TXN_STATE_ROOT] = {int(k): v for k, v in txn_data[AUDIT_TXN_STATE_ROOT].items()}\n        return txn", "response": "Makes sure that we have integer as keys after possible deserialization from json\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncommits a batch of transactions.", "response": "def commit_batch(self, three_pc_batch, prev_handler_result=None):\n        \"\"\"\n        :param txn_count: The number of requests to commit (The actual requests\n        are picked up from the uncommitted list from the ledger)\n        :param state_root: The state trie root after the txns are committed\n        :param txn_root: The txn merkle root after the txns are committed\n\n        :return: list of committed transactions\n        \"\"\"\n\n        return self._commit(self.ledger, self.state, three_pc_batch)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreject the batch of items from the database.", "response": "def reject_batch(self):\n        \"\"\"\n        Return hash reverting for and calculate count of reverted txns\n        :return: root_hash, for reverting to (needed in revertToHead method) and count of reverted txns\n        \"\"\"\n        prev_size = 0\n        if len(self.un_committed) == 0:\n            raise LogicError(\"No items to return\")\n        if len(self.un_committed) > 0:\n            _, _, prev_size = self.un_committed.pop()\n        if len(self.un_committed) == 0:\n            committed_hash, committed_root, committed_size = self.last_committed\n            return committed_hash, committed_root, prev_size - committed_size\n        else:\n            lhash, ltxn_root, lsize = self.un_committed[-1]\n            return lhash, ltxn_root, prev_size - lsize"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize(self, data: Dict, fields=None, toBytes=True):\n        if isinstance(data, Dict):\n            data = self._sort_dict(data)\n        return msgpack.packb(data, use_bin_type=True)", "response": "Serializes a dict to bytes preserving the order"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncommit the given transaction count and return the list of committed transactions", "response": "def commit(self, txnCount, stateRoot, txnRoot, ppTime) -> List:\n        \"\"\"\n        :param txnCount: The number of requests to commit (The actual requests\n        are picked up from the uncommitted list from the ledger)\n        :param stateRoot: The state trie root after the txns are committed\n        :param txnRoot: The txn merkle root after the txns are committed\n\n        :return: list of committed transactions\n        \"\"\"\n\n        return self._commit(self.ledger, self.state, txnCount, stateRoot,\n                            txnRoot, ppTime, ts_store=self.ts_store)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_value_from_state(self, path, head_hash=None, with_proof=False, multi_sig=None):\n        '''\n        Get a value (and proof optionally)for the given path in state trie.\n        Does not return the proof is there is no aggregate signature for it.\n        :param path: the path generate a state proof for\n        :param head_hash: the root to create the proof against\n        :param get_value: whether to return the value\n        :return: a state proof or None\n        '''\n        root_hash = head_hash if head_hash else self.state.committedHeadHash\n        encoded_root_hash = state_roots_serializer.serialize(bytes(root_hash))\n\n        if not with_proof:\n            return self.state.get_for_root_hash(root_hash, path), None\n\n        if not multi_sig:\n            # Just return the value and not proof\n            try:\n                return self.state.get_for_root_hash(root_hash, path), None\n            except KeyError:\n                return None, None\n        else:\n            try:\n                proof, value = self.state.generate_state_proof(key=path,\n                                                               root=self.state.get_head_by_hash(root_hash),\n                                                               serialize=True,\n                                                               get_value=True)\n                value = self.state.get_decoded(value) if value else value\n                encoded_proof = proof_nodes_serializer.serialize(proof)\n                proof = {\n                    ROOT_HASH: encoded_root_hash,\n                    MULTI_SIGNATURE: multi_sig.as_dict(),\n                    PROOF_NODES: encoded_proof\n                }\n                return value, proof\n            except KeyError:\n                return None, None", "response": "Get a value for the given path in state trie."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify the consistency between two root hashes.", "response": "def verify_tree_consistency(self, old_tree_size: int, new_tree_size: int,\n                                old_root: bytes, new_root: bytes,\n                                proof: Sequence[bytes]):\n        \"\"\"Verify the consistency between two root hashes.\n\n        old_tree_size must be <= new_tree_size.\n\n        Args:\n            old_tree_size: size of the older tree.\n            new_tree_size: size of the newer_tree.\n            old_root: the root hash of the older tree.\n            new_root: the root hash of the newer tree.\n            proof: the consistency proof.\n\n        Returns:\n            True. The return value is enforced by a decorator and need not be\n                checked by the caller.\n\n        Raises:\n            ConsistencyError: the proof indicates an inconsistency\n                (this is usually really serious!).\n            ProofError: the proof is invalid.\n            ValueError: supplied tree sizes are invalid.\n        \"\"\"\n        old_size = old_tree_size\n        new_size = new_tree_size\n\n        if old_size < 0 or new_size < 0:\n            raise ValueError(\"Negative tree size\")\n\n        if old_size > new_size:\n            raise ValueError(\"Older tree has bigger size (%d vs %d), did \"\n                             \"you supply inputs in the wrong order?\" %\n                             (old_size, new_size))\n\n        if old_size == new_size:\n            if old_root == new_root:\n                if proof:\n                    logging.debug(\"Trees are identical, ignoring proof\")\n                return True\n            else:\n                raise error.ConsistencyError(\"Inconsistency: different root \"\n                                             \"hashes for the same tree size\")\n\n        if old_size == 0:\n            if proof:\n                # A consistency proof with an empty tree is an empty proof.\n                # Anything is consistent with an empty tree, so ignore whatever\n                # bogus proof was supplied. Note we do not verify here that the\n                # root hash is a valid hash for an empty tree.\n                logging.debug(\"Ignoring non-empty consistency proof for \"\n                              \"empty tree.\")\n            return True\n\n        # Now 0 < old_size < new_size\n        # A consistency proof is essentially an audit proof for the node with\n        # index old_size - 1 in the newer tree. The sole difference is that\n        # the path is already hashed together into a single hash up until the\n        # first audit node that occurs in the newer tree only.\n        node = old_size - 1\n        last_node = new_size - 1\n\n        # While we are the right child, everything is in both trees,\n        # so move one level up.\n        while node % 2:\n            node //= 2\n            last_node //= 2\n\n        p = iter(proof)\n        try:\n            if node:\n                # Compute the two root hashes in parallel.\n                new_hash = old_hash = next(p)\n            else:\n                # The old tree was balanced (2**k nodes), so we already have\n                # the first root hash.\n                new_hash = old_hash = old_root\n\n            while node:\n                if node % 2:\n                    # node is a right child: left sibling exists in both trees.\n                    next_node = next(p)\n                    old_hash = self.hasher.hash_children(next_node, old_hash)\n                    new_hash = self.hasher.hash_children(next_node, new_hash)\n                elif node < last_node:\n                    # node is a left child: right sibling only exists in the\n                    # newer tree.\n                    new_hash = self.hasher.hash_children(new_hash, next(p))\n                # else node == last_node: node is a left child with no sibling\n                # in either tree.\n                node //= 2\n                last_node //= 2\n\n            # Now old_hash is the hash of the first subtree. If the two trees\n            # have different height, continue the path until the new root.\n            while last_node:\n                n = next(p)\n                new_hash = self.hasher.hash_children(new_hash, n)\n                last_node //= 2\n\n            # If the second hash does not match, the proof is invalid for the\n            # given pair. If, on the other hand, the newer hash matches but the\n            # older one doesn't, then the proof (together with the signatures\n            # on the hashes) is proof of inconsistency.\n            # Continue to find out.\n            if new_hash != new_root:\n                raise error.ProofError(\"Bad Merkle proof: second root hash \"\n                                       \"does not match. Expected hash: %s \"\n                                       \", computed hash: %s\" %\n                                       (hexlify(new_root).strip(),\n                                        hexlify(new_hash).strip()))\n            elif old_hash != old_root:\n                raise error.ConsistencyError(\"Inconsistency: first root hash \"\n                                             \"does not match. Expected hash: \"\n                                             \"%s, computed hash: %s\" %\n                                             (hexlify(old_root).strip(),\n                                              hexlify(old_hash).strip())\n                                             )\n\n        except StopIteration:\n            raise error.ProofError(\"Merkle proof is too short\")\n\n        # We've already verified consistency, so accept the proof even if\n        # there's garbage left over (but log a warning).\n        try:\n            next(p)\n        except StopIteration:\n            pass\n        else:\n            logging.debug(\"Proof has extra nodes\")\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify_leaf_hash_inclusion(self, leaf_hash: bytes, leaf_index: int,\n                                   proof: List[bytes], sth: STH):\n        \"\"\"Verify a Merkle Audit Path.\n\n        See section 2.1.1 of RFC6962 for the exact path description.\n\n        Args:\n            leaf_hash: The hash of the leaf for which the proof was provided.\n            leaf_index: Index of the leaf in the tree.\n            proof: A list of SHA-256 hashes representing the  Merkle audit\n            path.\n            sth: STH with the same tree size as the one used to fetch the\n            proof.\n            The sha256_root_hash from this STH will be compared against the\n            root hash produced from the proof.\n\n        Returns:\n            True. The return value is enforced by a decorator and need not be\n                checked by the caller.\n\n        Raises:\n            ProofError: the proof is invalid.\n        \"\"\"\n        leaf_index = int(leaf_index)\n        tree_size = int(sth.tree_size)\n        # TODO(eranm): Verify signature over STH\n        if tree_size <= leaf_index:\n            raise ValueError(\"Provided STH is for a tree that is smaller \"\n                             \"than the leaf index. Tree size: %d Leaf \"\n                             \"index: %d\" % (tree_size, leaf_index))\n        if tree_size < 0 or leaf_index < 0:\n            raise ValueError(\"Negative tree size or leaf index: \"\n                             \"Tree size: %d Leaf index: %d\" %\n                             (tree_size, leaf_index))\n        calculated_root_hash = self._calculate_root_hash_from_audit_path(\n            leaf_hash, leaf_index, proof[:], tree_size)\n        if calculated_root_hash == sth.sha256_root_hash:\n            return True\n\n        raise error.ProofError(\"Constructed root hash differs from provided \"\n                               \"root hash. Constructed: %s Expected: %s\" %\n                               (hexlify(calculated_root_hash).strip(),\n                                hexlify(sth.sha256_root_hash).strip()))", "response": "Verify that the root hash of the given leaf hash is correct."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_leaf_inclusion(self, leaf: bytes, leaf_index: int,\n                              proof: List[bytes], sth: STH):\n        \"\"\"Verify a Merkle Audit Path.\n\n        See section 2.1.1 of RFC6962 for the exact path description.\n\n        Args:\n            leaf: The leaf for which the proof was provided.\n            leaf_index: Index of the leaf in the tree.\n            proof: A list of SHA-256 hashes representing the  Merkle audit\n            path.\n            sth: STH with the same tree size as the one used to fetch the\n            proof.\n            The sha256_root_hash from this STH will be compared against the\n            root hash produced from the proof.\n\n        Returns:\n            True. The return value is enforced by a decorator and need not be\n                checked by the caller.\n\n        Raises:\n            ProofError: the proof is invalid.\n        \"\"\"\n        leaf_hash = self.hasher.hash_leaf(leaf)\n        return self.verify_leaf_hash_inclusion(leaf_hash, leaf_index, proof,\n                                               sth)", "response": "Verify a Merkle Audit Path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nschedule an action to be executed after seconds.", "response": "def _schedule(self, action: Callable, seconds: int=0) -> int:\n        \"\"\"\n        Schedule an action to be executed after `seconds` seconds.\n\n        :param action: a callable to be scheduled\n        :param seconds: the time in seconds after which the action must be executed\n        \"\"\"\n        self.aid += 1\n        if seconds > 0:\n            nxt = time.perf_counter() + seconds\n            if nxt < self.aqNextCheck:\n                self.aqNextCheck = nxt\n            logger.trace(\"{} scheduling action {} with id {} to run in {} \"\n                         \"seconds\".format(self, get_func_name(action),\n                                          self.aid, seconds))\n            self.aqStash.append((nxt, (action, self.aid)))\n        else:\n            logger.trace(\"{} scheduling action {} with id {} to run now\".\n                         format(self, get_func_name(action), self.aid))\n            self.actionQueue.append((action, self.aid))\n\n        if action not in self.scheduled:\n            self.scheduled[action] = []\n        self.scheduled[action].append(self.aid)\n\n        return self.aid"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _cancel(self, action: Callable = None, aid: int = None):\n        if action is not None:\n            if action in self.scheduled:\n                logger.trace(\"{} cancelling all events for action {}, ids: {}\"\n                             \"\".format(self, action, self.scheduled[action]))\n                self.scheduled[action].clear()\n        elif aid is not None:\n            for action, aids in self.scheduled.items():\n                try:\n                    aids.remove(aid)\n                except ValueError:\n                    pass\n                else:\n                    logger.trace(\"{} cancelled action {} with id {}\".format(self, action, aid))\n                    break", "response": "Cancel scheduled events\n\n        :param action:  (optional) scheduled action. If specified, all\n                scheduled events for the action are cancelled.\n        :param aid:     (options) scheduled event id. If specified,\n                scheduled event with the aid is cancelled."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun all pending actions in the action queue.", "response": "def _serviceActions(self) -> int:\n        \"\"\"\n        Run all pending actions in the action queue.\n\n        :return: number of actions executed.\n        \"\"\"\n        if self.aqStash:\n            tm = time.perf_counter()\n            if tm > self.aqNextCheck:\n                earliest = float('inf')\n                for d in list(self.aqStash):\n                    nxt, action = d\n                    if tm > nxt:\n                        self.actionQueue.appendleft(action)\n                        self.aqStash.remove(d)\n                    if nxt < earliest:\n                        earliest = nxt\n                self.aqNextCheck = earliest\n        count = len(self.actionQueue)\n        while self.actionQueue:\n            action, aid = self.actionQueue.popleft()\n            assert action in self.scheduled\n            if aid in self.scheduled[action]:\n                self.scheduled[action].remove(aid)\n                logger.trace(\"{} running action {} with id {}\".\n                             format(self, get_func_name(action), aid))\n                action()\n            else:\n                logger.trace(\"{} not running cancelled action {} with id {}\".\n                             format(self, get_func_name(action), aid))\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_pool_txns(self, three_pc_batch) -> List:\n        committed_txns = self.default_executer(three_pc_batch)\n        for txn in committed_txns:\n            self.poolManager.onPoolMembershipChange(txn)\n        return committed_txns", "response": "Execute a transaction that involves consensus pool management like\n        adding a node or client or a steward."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_state_from_ledger(self, state: State, ledger: Ledger, reqHandler):\n        if state.isEmpty:\n            logger.info('{} found state to be empty, recreating from '\n                        'ledger'.format(self))\n            for seq_no, txn in ledger.getAllTxn():\n                txn = self.update_txn_with_extra_data(txn)\n                reqHandler.updateState([txn, ], isCommitted=True)\n                state.commit(rootHash=state.headHash)", "response": "Initialize the state from the given ledger."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_view_change_start(self):\n        self.view_changer.start_view_change_ts = self.utc_epoch()\n\n        for replica in self.replicas.values():\n            replica.on_view_change_start()\n        logger.info(\"{} resetting monitor stats at view change start\".format(self))\n        self.monitor.reset()\n        self.processStashedMsgsForView(self.viewNo)\n\n        self.backup_instance_faulty_processor.restore_replicas()\n        self.drop_primaries()\n\n        pop_keys(self.msgsForFutureViews, lambda x: x <= self.viewNo)\n        self.logNodeInfo()\n        # Keep on doing catchup until >(n-f) nodes LedgerStatus same on have a\n        # prepared certificate the first PRE-PREPARE of the new view\n        logger.info('{}{} changed to view {}, will start catchup now'.\n                    format(VIEW_CHANGE_PREFIX, self, self.viewNo))\n\n        self._cancel(self._check_view_change_completed)\n        self._schedule(action=self._check_view_change_completed,\n                       seconds=self._view_change_timeout)\n\n        # Set to 0 even when set to 0 in `on_view_change_complete` since\n        # catchup might be started due to several reasons.\n        self.catchup_rounds_without_txns = 0\n        self.last_sent_pp_store_helper.erase_last_sent_pp_seq_no()", "response": "Called when a view change is started"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_view_change_complete(self):\n\n        self.future_primaries_handler.set_node_state()\n\n        if not self.replicas.all_instances_have_primary:\n            raise LogicError(\n                \"{} Not all replicas have \"\n                \"primaries: {}\".format(self, self.replicas.primary_name_by_inst_id)\n            )\n\n        self._cancel(self._check_view_change_completed)\n\n        for replica in self.replicas.values():\n            replica.on_view_change_done()\n        self.view_changer.last_completed_view_no = self.view_changer.view_no\n        # Remove already ordered requests from requests list after view change\n        # If view change happen when one half of nodes ordered on master\n        # instance and backup but other only on master then we need to clear\n        # requests list.  We do this to stop transactions ordering  on backup\n        # replicas that have already been ordered on master.\n        # Test for this case in plenum/test/view_change/\n        # test_no_propagate_request_on_different_last_ordered_before_vc.py\n        for replica in self.replicas.values():\n            replica.clear_requests_and_fix_last_ordered()\n        self.monitor.reset()", "response": "Called by the view change manager when a view change is complete for a replica."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate and return a hashStore implementation based on configuration", "response": "def getHashStore(self, name) -> HashStore:\n        \"\"\"\n        Create and return a hashStore implementation based on configuration\n        \"\"\"\n        return initHashStore(self.dataLocation, name, self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef onStopping(self):\n        # Log stats should happen before any kind of reset or clearing\n        if self.config.STACK_COMPANION == 1:\n            add_stop_time(self.ledger_dir, self.utc_epoch())\n\n        self.logstats()\n        self.reset()\n\n        # Stop the ledgers\n        for ledger in self.ledgers:\n            try:\n                ledger.stop()\n            except Exception as ex:\n                logger.exception('{} got exception while stopping ledger: {}'.format(self, ex))\n\n        self.nodestack.stop()\n        self.clientstack.stop()\n\n        self.closeAllKVStores()\n\n        self._info_tool.stop()\n        self.mode = None\n        self.execute_hook(NodeHooks.POST_NODE_STOPPED)", "response": "Actions to be performed on stopping the node.\n\n        - Close the UDP socket of the nodestack"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess limit number of messages from the nodeInBox.", "response": "async def serviceNodeMsgs(self, limit: int) -> int:\n        \"\"\"\n        Process `limit` number of messages from the nodeInBox.\n\n        :param limit: the maximum number of messages to process\n        :return: the number of messages successfully processed\n        \"\"\"\n        with self.metrics.measure_time(MetricsName.SERVICE_NODE_STACK_TIME):\n            n = await self.nodestack.service(limit, self.quota_control.node_quota)\n\n        self.metrics.add_event(MetricsName.NODE_STACK_MESSAGES_PROCESSED, n)\n\n        await self.processNodeInBox()\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def serviceClientMsgs(self, limit: int) -> int:\n        c = await self.clientstack.service(limit, self.quota_control.client_quota)\n        self.metrics.add_event(MetricsName.CLIENT_STACK_MESSAGES_PROCESSED, c)\n\n        await self.processClientInBox()\n        return c", "response": "Process limit number of messages from the clientInBox."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def serviceViewChanger(self, limit) -> int:\n        if not self.isReady():\n            return 0\n        o = self.serviceViewChangerOutBox(limit)\n        i = await self.serviceViewChangerInbox(limit)\n        return o + i", "response": "Service the view_changer s inBox outBox and action queues."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nservices the observable s inBox and outBox and return the number of messages successfully serviced", "response": "async def service_observable(self, limit) -> int:\n        \"\"\"\n        Service the observable's inBox and outBox\n\n        :return: the number of messages successfully serviced\n        \"\"\"\n        if not self.isReady():\n            return 0\n        o = self._service_observable_out_box(limit)\n        i = await self._observable.serviceQueues(limit)\n        return o + i"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nservice at most limit number of messages from the observable s outBox.", "response": "def _service_observable_out_box(self, limit: int = None) -> int:\n        \"\"\"\n        Service at most `limit` number of messages from the observable's outBox.\n\n        :return: the number of messages successfully serviced.\n        \"\"\"\n        msg_count = 0\n        while True:\n            if limit and msg_count >= limit:\n                break\n\n            msg = self._observable.get_output()\n            if not msg:\n                break\n\n            msg_count += 1\n            msg, observer_ids = msg\n            # TODO: it's assumed that all Observers are connected the same way as Validators\n            self.sendToNodes(msg, observer_ids)\n        return msg_count"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def service_observer(self, limit) -> int:\n        if not self.isReady():\n            return 0\n        return await self._observer.serviceQueues(limit)", "response": "Service the inBox and outBox of the observer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef onConnsChanged(self, joined: Set[str], left: Set[str]):\n        _prev_status = self.status\n        if self.isGoing():\n            if self.connectedNodeCount == self.totalNodes:\n                self.status = Status.started\n            elif self.connectedNodeCount >= self.minimumNodes:\n                self.status = Status.started_hungry\n            else:\n                self.status = Status.starting\n        self.elector.nodeCount = self.connectedNodeCount\n\n        if self.master_primary_name in joined:\n            self.primaries_disconnection_times[self.master_replica.instId] = None\n        if self.master_primary_name in left:\n            logger.display('{} lost connection to primary of master'.format(self))\n            self.lost_master_primary()\n        elif _prev_status == Status.starting and self.status == Status.started_hungry \\\n                and self.primaries_disconnection_times[self.master_replica.instId] is not None \\\n                and self.master_primary_name is not None:\n            \"\"\"\n            Such situation may occur if the pool has come back to reachable consensus but\n            primary is still disconnected, so view change proposal makes sense now.\n            \"\"\"\n            self._schedule_view_change()\n\n        for inst_id, replica in self.replicas.items():\n            if not replica.isMaster and replica.primaryName is not None:\n                primary_node_name = replica.primaryName.split(':')[0]\n                if primary_node_name in joined:\n                    self.primaries_disconnection_times[inst_id] = None\n                elif primary_node_name in left:\n                    self.primaries_disconnection_times[inst_id] = time.perf_counter()\n                    self._schedule_replica_removal(inst_id)\n\n        if self.isReady():\n            self.checkInstances()\n        else:\n            logger.info(\"{} joined nodes {} but status is {}\".format(self, joined, self.status))\n        # Send ledger status whether ready (connected to enough nodes) or not\n        for node in joined:\n            self.send_ledger_status_to_newly_connected_node(node)\n\n        for node in left:\n            self.network_i3pc_watcher.disconnect(node)\n\n        for node in joined:\n            self.network_i3pc_watcher.connect(node)", "response": "Called by the system when the number of nodes in joined or left have changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ask_for_ledger_status(self, node_name: str, ledger_id):\n        self.request_msg(LEDGER_STATUS, {f.LEDGER_ID.nm: ledger_id},\n                         [node_name, ])\n        logger.info(\"{} asking {} for ledger status of ledger {}\".format(self, node_name, ledger_id))", "response": "Ask other node for ledger status"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if this node has the minimum required number of protocol instances.", "response": "def checkInstances(self) -> None:\n        # TODO: Is this method really needed?\n        \"\"\"\n        Check if this node has the minimum required number of protocol\n        instances, i.e. f+1. If not, add a replica. If no election is in\n        progress, this node will try to nominate one of its replicas as primary.\n        This method is called whenever a connection with a  new node is\n        established.\n        \"\"\"\n        logger.debug(\"{} choosing to start election on the basis of count {} and nodes {}\".\n                     format(self, self.connectedNodeCount, self.nodestack.conns))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef adjustReplicas(self,\n                       old_required_number_of_instances: int,\n                       new_required_number_of_instances: int):\n        \"\"\"\n        Add or remove replicas depending on `f`\n        \"\"\"\n        # TODO: refactor this\n        replica_num = old_required_number_of_instances\n        while replica_num < new_required_number_of_instances:\n            self.replicas.add_replica(replica_num)\n            self.processStashedMsgsForReplica(replica_num)\n            replica_num += 1\n\n        while replica_num > new_required_number_of_instances:\n            replica_num -= 1\n            self.replicas.remove_replica(replica_num)\n\n        pop_keys(self.msgsForFutureReplicas, lambda inst_id: inst_id < new_required_number_of_instances)\n\n        if len(self.primaries_disconnection_times) < new_required_number_of_instances:\n            self.primaries_disconnection_times.extend(\n                [None] * (new_required_number_of_instances - len(self.primaries_disconnection_times)))\n        elif len(self.primaries_disconnection_times) > new_required_number_of_instances:\n            self.primaries_disconnection_times = self.primaries_disconnection_times[:new_required_number_of_instances]", "response": "Adjusts the replicas of the current instance based on f."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether view change is completed.", "response": "def _check_view_change_completed(self):\n        \"\"\"\n        This thing checks whether new primary was elected.\n        If it was not - starts view change again\n        \"\"\"\n        logger.info('{} running the scheduled check for view change completion'.format(self))\n        if not self.view_changer.view_change_in_progress:\n            logger.info('{} already completion view change'.format(self))\n            return False\n\n        self.view_changer.on_view_change_not_completed_in_time()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef service_replicas_outbox(self, limit: int = None) -> int:\n        # TODO: rewrite this using Router\n\n        num_processed = 0\n        for message in self.replicas.get_output(limit):\n            num_processed += 1\n            if isinstance(message, (PrePrepare, Prepare, Commit, Checkpoint)):\n                self.send(message)\n            elif isinstance(message, Ordered):\n                self.try_processing_ordered(message)\n            elif isinstance(message, tuple) and isinstance(message[1], Reject):\n                with self.metrics.measure_time(MetricsName.NODE_SEND_REJECT_TIME):\n                    digest, reject = message\n                    result_reject = Reject(\n                        reject.identifier,\n                        reject.reqId,\n                        self.reasonForClientFromException(\n                            reject.reason))\n                    # TODO: What the case when reqKey will be not in requestSender dict\n                    if digest in self.requestSender:\n                        self.transmitToClient(result_reject, self.requestSender[digest])\n                        self.doneProcessingReq(digest)\n            elif isinstance(message, Exception):\n                self.processEscalatedException(message)\n            else:\n                # TODO: should not this raise exception?\n                logger.error(\"Received msg {} and don't \"\n                             \"know how to handle it\".format(message))\n        return num_processed", "response": "Process the messages from the replicas in the outbox."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nservices at most limit number of messages from the view_changer s outBox.", "response": "def serviceViewChangerOutBox(self, limit: int = None) -> int:\n        \"\"\"\n        Service at most `limit` number of messages from the view_changer's outBox.\n\n        :return: the number of messages successfully serviced.\n        \"\"\"\n        msgCount = 0\n        while self.view_changer.outBox and (not limit or msgCount < limit):\n            msgCount += 1\n            msg = self.view_changer.outBox.popleft()\n            if isinstance(msg, (InstanceChange, ViewChangeDone)):\n                self.send(msg)\n            else:\n                logger.error(\"Received msg {} and don't know how to handle it\".\n                             format(msg))\n        return msgCount"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def serviceViewChangerInbox(self, limit: int = None) -> int:\n        msgCount = 0\n        while self.msgsToViewChanger and (not limit or msgCount < limit):\n            msgCount += 1\n            msg = self.msgsToViewChanger.popleft()\n            self.view_changer.inBox.append(msg)\n        await self.view_changer.serviceQueues(limit)\n        return msgCount", "response": "Service at most limit number of messages from the view_changer s outBox."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of the primary node of the master instance.", "response": "def master_primary_name(self) -> Optional[str]:\n        \"\"\"\n        Return the name of the primary node of the master instance\n        \"\"\"\n\n        master_primary_name = self.master_replica.primaryName\n        if master_primary_name:\n            return self.master_replica.getNodeName(master_primary_name)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef msgHasAcceptableInstId(self, msg, frm) -> bool:\n        # TODO: refactor this! this should not do anything except checking!\n        instId = getattr(msg, f.INST_ID.nm, None)\n        if not (isinstance(instId, int) and instId >= 0):\n            return False\n        if instId >= self.requiredNumberOfInstances:\n            if instId not in self.msgsForFutureReplicas:\n                self.msgsForFutureReplicas[instId] = deque()\n            self.msgsForFutureReplicas[instId].append((msg, frm))\n            logger.debug(\"{} queueing message {} for future protocol instance {}\".format(self, msg, instId))\n            return False\n        return True", "response": "Returns true if the instance id of message corresponds to a correct\n        replica."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef msgHasAcceptableViewNo(self, msg, frm) -> bool:\n        # TODO: refactor this! this should not do anything except checking!\n        view_no = getattr(msg, f.VIEW_NO.nm, None)\n        if not (isinstance(view_no, int) and view_no >= 0):\n            return False\n        if self.viewNo - view_no > 1:\n            self.discard(msg, \"un-acceptable viewNo {}\"\n                         .format(view_no), logMethod=logger.warning)\n        if isinstance(msg, ViewChangeDone) and view_no < self.viewNo:\n            self.discard(msg, \"Proposed viewNo {} less, then current {}\"\n                         .format(view_no, self.viewNo), logMethod=logger.warning)\n        elif (view_no > self.viewNo) or self._is_initial_view_change_now():\n            if view_no not in self.msgsForFutureViews:\n                self.msgsForFutureViews[view_no] = deque()\n            logger.debug('{} stashing a message for a future view: {}'.format(self, msg))\n            self.msgsForFutureViews[view_no].append((msg, frm))\n            if isinstance(msg, ViewChangeDone):\n                future_vcd_msg = FutureViewChangeDone(vcd_msg=msg)\n                self.msgsToViewChanger.append((future_vcd_msg, frm))\n        else:\n            return True\n        return False", "response": "Return True if the view no of message corresponds to the current viewNo or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sendToReplica(self, msg, frm):\n        # TODO: discard or stash messages here instead of doing\n        # this in msgHas* methods!!!\n        if self.msgHasAcceptableInstId(msg, frm):\n            self.replicas.pass_message((msg, frm), msg.instId)", "response": "Send the message to the intended replica."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sendToViewChanger(self, msg, frm):\n        if (isinstance(msg, InstanceChange) or\n                self.msgHasAcceptableViewNo(msg, frm)):\n            logger.debug(\"{} sending message to view changer: {}\".\n                         format(self, (msg, frm)))\n            self.msgsToViewChanger.append((msg, frm))", "response": "Send the message to the intended view changer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending the message to the observer.", "response": "def send_to_observer(self, msg, frm):\n        \"\"\"\n        Send the message to the observer.\n\n        :param msg: the message to send\n        :param frm: the name of the node which sent this `msg`\n        \"\"\"\n        logger.debug(\"{} sending message to observer: {}\".\n                     format(self, (msg, frm)))\n        self._observer.append_input(msg, frm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates and process one message from a node.", "response": "def handleOneNodeMsg(self, wrappedMsg):\n        \"\"\"\n        Validate and process one message from a node.\n\n        :param wrappedMsg: Tuple of message and the name of the node that sent\n        the message\n        \"\"\"\n        try:\n            vmsg = self.validateNodeMsg(wrappedMsg)\n            if vmsg:\n                logger.trace(\"{} msg validated {}\".format(self, wrappedMsg),\n                             extra={\"tags\": [\"node-msg-validation\"]})\n                self.unpackNodeMsg(*vmsg)\n            else:\n                logger.debug(\"{} invalidated msg {}\".format(self, wrappedMsg),\n                             extra={\"tags\": [\"node-msg-validation\"]})\n        except SuspiciousNode as ex:\n            self.reportSuspiciousNodeEx(ex)\n        except Exception as ex:\n            msg, frm = wrappedMsg\n            self.discard(msg, ex, logger.info)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate another node s message sent to this node.", "response": "def validateNodeMsg(self, wrappedMsg):\n        \"\"\"\n        Validate another node's message sent to this node.\n\n        :param wrappedMsg: Tuple of message and the name of the node that sent\n        the message\n        :return: Tuple of message from node and name of the node\n        \"\"\"\n        msg, frm = wrappedMsg\n        if self.isNodeBlacklisted(frm):\n            self.discard(str(msg)[:256], \"received from blacklisted node {}\".format(frm), logger.display)\n            return None\n\n        with self.metrics.measure_time(MetricsName.INT_VALIDATE_NODE_MSG_TIME):\n            try:\n                message = node_message_factory.get_instance(**msg)\n            except (MissingNodeOp, InvalidNodeOp) as ex:\n                raise ex\n            except Exception as ex:\n                raise InvalidNodeMsg(str(ex))\n\n        try:\n            self.verifySignature(message)\n        except BaseExc as ex:\n            raise SuspiciousNode(frm, ex, message) from ex\n        logger.debug(\"{} received node message from {}: {}\".format(self, frm, message), extra={\"cli\": False})\n        return message, frm"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunpack a node message and adds it to the node s inbox.", "response": "def unpackNodeMsg(self, msg, frm) -> None:\n        \"\"\"\n        If the message is a batch message validate each message in the batch,\n        otherwise add the message to the node's inbox.\n\n        :param msg: a node message\n        :param frm: the name of the node that sent this `msg`\n        \"\"\"\n        # TODO: why do we unpack batches here? Batching is a feature of\n        # a transport, it should be encapsulated.\n\n        if isinstance(msg, Batch):\n            logger.trace(\"{} processing a batch {}\".format(self, msg))\n            with self.metrics.measure_time(MetricsName.UNPACK_BATCH_TIME):\n                for m in msg.messages:\n                    try:\n                        m = self.nodestack.deserializeMsg(m)\n                    except Exception as ex:\n                        logger.warning(\"Got error {} while processing {} message\".format(ex, m))\n                        continue\n                    self.handleOneNodeMsg((m, frm))\n        else:\n            self.postToNodeInBox(msg, frm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef postToNodeInBox(self, msg, frm):\n        logger.trace(\"{} appending to nodeInbox {}\".format(self, msg))\n        self.nodeInBox.append((msg, frm))", "response": "Append the message to the node inbox"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def processNodeInBox(self):\n        while self.nodeInBox:\n            m = self.nodeInBox.popleft()\n            await self.process_one_node_message(m)", "response": "Process the messages in the node inbox asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates and process a client message and unpack the message.", "response": "def handleOneClientMsg(self, wrappedMsg):\n        \"\"\"\n        Validate and process a client message\n\n        :param wrappedMsg: a message from a client\n        \"\"\"\n        try:\n            vmsg = self.validateClientMsg(wrappedMsg)\n            if vmsg:\n                self.unpackClientMsg(*vmsg)\n        except BlowUp:\n            raise\n        except Exception as ex:\n            msg, frm = wrappedMsg\n            friendly = friendlyEx(ex)\n            if isinstance(ex, SuspiciousClient):\n                self.reportSuspiciousClient(frm, friendly)\n\n            self.handleInvalidClientMsg(ex, wrappedMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validateClientMsg(self, wrappedMsg):\n        msg, frm = wrappedMsg\n        if self.isClientBlacklisted(frm):\n            self.discard(str(msg)[:256], \"received from blacklisted client {}\".format(frm), logger.display)\n            return None\n\n        needStaticValidation = False\n        if all([msg.get(OPERATION), msg.get(f.REQ_ID.nm),\n                idr_from_req_data(msg)]):\n            cls = self.client_request_class\n            needStaticValidation = True\n        elif OP_FIELD_NAME in msg:\n            op = msg[OP_FIELD_NAME]\n            cls = node_message_factory.get_type(op)\n            if cls not in (Batch, LedgerStatus, CatchupReq):\n                raise InvalidClientMsgType(cls, msg.get(f.REQ_ID.nm))\n        else:\n            raise InvalidClientRequest(msg.get(f.IDENTIFIER.nm),\n                                       msg.get(f.REQ_ID.nm))\n        try:\n            cMsg = cls(**msg)\n        except TypeError as ex:\n            raise InvalidClientRequest(msg.get(f.IDENTIFIER.nm),\n                                       msg.get(f.REQ_ID.nm),\n                                       str(ex))\n        except Exception as ex:\n            raise InvalidClientRequest(msg.get(f.IDENTIFIER.nm),\n                                       msg.get(f.REQ_ID.nm)) from ex\n\n        if needStaticValidation:\n            self.doStaticValidation(cMsg)\n\n        self.execute_hook(NodeHooks.PRE_SIG_VERIFICATION, cMsg)\n        self.verifySignature(cMsg)\n        self.execute_hook(NodeHooks.POST_SIG_VERIFICATION, cMsg)\n        # Suspicions should only be raised when lot of sig failures are\n        # observed\n        # try:\n        #     self.verifySignature(cMsg)\n        # except UnknownIdentifier as ex:\n        #     raise\n        # except Exception as ex:\n        #     raise SuspiciousClient from ex\n        logger.trace(\"{} received CLIENT message: {}\".\n                     format(self.clientstack.name, cMsg))\n        return cMsg, frm", "response": "Validate a client message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunpack a client message and returns the ID of the client that sent it.", "response": "def unpackClientMsg(self, msg, frm):\n        \"\"\"\n        If the message is a batch message validate each message in the batch,\n        otherwise add the message to the node's clientInBox.\n        But node return a Nack message if View Change in progress\n        :param msg: a client message\n        :param frm: the name of the client that sent this `msg`\n        \"\"\"\n\n        if isinstance(msg, Batch):\n            for m in msg.messages:\n                # This check is done since Client uses NodeStack (which can\n                # send and receive BATCH) to talk to nodes but Node uses\n                # ClientStack (which cannot send or receive BATCH).\n                # TODO: The solution is to have both kind of stacks be able to\n                # parse BATCH messages\n                if m in (ZStack.pingMessage, ZStack.pongMessage):\n                    continue\n                m = self.clientstack.deserializeMsg(m)\n                self.handleOneClientMsg((m, frm))\n        else:\n            msg_dict = msg.as_dict if isinstance(msg, Request) else msg\n            if isinstance(msg_dict, dict):\n                if self.view_changer.view_change_in_progress and self.is_request_need_quorum(msg_dict):\n                    self.discard(msg_dict,\n                                 reason=\"view change in progress\",\n                                 logMethod=logger.debug)\n                    self.send_nack_to_client((idr_from_req_data(msg_dict),\n                                              msg_dict.get(f.REQ_ID.nm, None)),\n                                             \"Client request is discarded since view \"\n                                             \"change is in progress\", frm)\n                    return\n            self.postToClientInBox(msg, frm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the messages in the node s clientInBox asynchronously.", "response": "async def processClientInBox(self):\n        \"\"\"\n        Process the messages in the node's clientInBox asynchronously.\n        All messages in the inBox have already been validated, including\n        signature check.\n        \"\"\"\n        while self.clientInBox:\n            m = self.clientInBox.popleft()\n            req, frm = m\n            logger.debug(\"{} processing {} request {}\".\n                         format(self.clientstack.name, frm, req),\n                         extra={\"cli\": True,\n                                \"tags\": [\"node-msg-processing\"]})\n\n            try:\n                await self.clientMsgRouter.handle(m)\n            except InvalidClientMessageException as ex:\n                self.handleInvalidClientMsg(ex, m)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_catchup_needed_during_view_change(self) -> bool:\n        if self.caught_up_for_current_view():\n            logger.info('{} is caught up for the current view {}'.format(self, self.viewNo))\n            return False\n        logger.info('{} is not caught up for the current view {}'.format(self, self.viewNo))\n\n        if self.num_txns_caught_up_in_last_catchup() == 0:\n            if self.has_ordered_till_last_prepared_certificate():\n                logger.info('{} ordered till last prepared certificate'.format(self))\n                return False\n\n        if self.is_catch_up_limit(self.config.MIN_TIMEOUT_CATCHUPS_DONE_DURING_VIEW_CHANGE):\n            # No more 3PC messages will be processed since maximum catchup\n            # rounds have been done\n            self.master_replica.last_prepared_before_view_change = None\n            return False\n\n        return True", "response": "Check if a quorum of view change done messages and if yes check if caught up till the last prepared certificate and if not check if catchup needed during view change"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef applyReq(self, request: Request, cons_time: int):\n        self.execute_hook(NodeHooks.PRE_REQUEST_APPLICATION, request=request,\n                          cons_time=cons_time)\n        req_handler = self.get_req_handler(txn_type=request.operation[TXN_TYPE])\n        seq_no, txn = req_handler.apply(request, cons_time)\n        ledger_id = self.ledger_id_for_request(request)\n        self.execute_hook(NodeHooks.POST_REQUEST_APPLICATION, request=request,\n                          cons_time=cons_time, ledger_id=ledger_id,\n                          seq_no=seq_no, txn=txn)", "response": "Applies the request to appropriate ledger and state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef processRequest(self, request: Request, frm: str):\n        logger.debug(\"{} received client request: {} from {}\".\n                     format(self.name, request, frm))\n        self.nodeRequestSpikeMonitorData['accum'] += 1\n\n        # TODO: What if client sends requests with same request id quickly so\n        # before reply for one is generated, the other comes. In that\n        # case we need to keep track of what requests ids node has seen\n        # in-memory and once request with a particular request id is processed,\n        # it should be removed from that in-memory DS.\n\n        # If request is already processed(there is a reply for the\n        # request in\n        # the node's transaction store then return the reply from the\n        # transaction store)\n        # TODO: What if the reply was a REQNACK? Its not gonna be found in the\n        # replies.\n\n        txn_type = request.operation[TXN_TYPE]\n\n        if self.is_action(txn_type):\n            self.process_action(request, frm)\n\n        elif txn_type == GET_TXN:\n            self.handle_get_txn_req(request, frm)\n            self.total_read_request_number += 1\n\n        elif self.is_query(txn_type):\n            self.process_query(request, frm)\n            self.total_read_request_number += 1\n\n        elif self.can_write_txn(txn_type):\n            reply = self.getReplyFromLedgerForRequest(request)\n            if reply:\n                logger.debug(\"{} returning reply from already processed \"\n                             \"REQUEST: {}\".format(self, request))\n                self.transmitToClient(reply, frm)\n                return\n\n            # If the node is not already processing the request\n            if not self.isProcessingReq(request.key):\n                self.startedProcessingReq(request.key, frm)\n                # forced request should be processed before consensus\n                self.handle_request_if_forced(request)\n\n            # If not already got the propagate request(PROPAGATE) for the\n            # corresponding client request(REQUEST)\n            self.recordAndPropagate(request, frm)\n            self.send_ack_to_client((request.identifier, request.reqId), frm)\n\n        else:\n            raise InvalidClientRequest(\n                request.identifier,\n                request.reqId,\n                'Pool is in readonly mode, try again in 60 seconds')", "response": "Process a REQUEST from the client and return the reply to the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef processPropagate(self, msg: Propagate, frm):\n        logger.debug(\"{} received propagated request: {}\".\n                     format(self.name, msg))\n\n        request = TxnUtilConfig.client_request_class(**msg.request)\n\n        clientName = msg.senderClient\n\n        if not self.isProcessingReq(request.key):\n            ledger_id, seq_no = self.seqNoDB.get_by_payload_digest(request.payload_digest)\n            if ledger_id is not None and seq_no is not None:\n                self._clean_req_from_verified(request)\n                logger.debug(\"{} ignoring propagated request {} \"\n                             \"since it has been already ordered\"\n                             .format(self.name, msg))\n                return\n\n            self.startedProcessingReq(request.key, clientName)\n            # forced request should be processed before consensus\n            self.handle_request_if_forced(request)\n\n        else:\n            if clientName is not None and \\\n                    not self.is_sender_known_for_req(request.key):\n                # Since some propagates might not include the client name\n                self.set_sender_for_req(request.key,\n                                        clientName)\n\n        self.requests.add_propagate(request, frm)\n\n        self.propagate(request, clientName)\n        self.tryForwarding(request)", "response": "Process one propagate request sent to this node asynchronously"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef processOrdered(self, ordered: Ordered):\n\n        if ordered.instId not in self.instances.ids:\n            logger.warning('{} got ordered request for instance {} which '\n                           'does not exist'.format(self, ordered.instId))\n            return False\n\n        if ordered.instId != self.instances.masterId:\n            # Requests from backup replicas are not executed\n            logger.trace(\"{} got ordered requests from backup replica {}\"\n                         .format(self, ordered.instId))\n            with self.metrics.measure_time(MetricsName.MONITOR_REQUEST_ORDERED_TIME):\n                self.monitor.requestOrdered(ordered.valid_reqIdr + ordered.invalid_reqIdr,\n                                            ordered.instId,\n                                            self.requests,\n                                            byMaster=False)\n            return False\n\n        logger.trace(\"{} got ordered requests from master replica\"\n                     .format(self))\n\n        logger.debug(\"{} executing Ordered batch {} {} of {} requests; state root {}; txn root {}\"\n                     .format(self.name,\n                             ordered.viewNo,\n                             ordered.ppSeqNo,\n                             len(ordered.valid_reqIdr),\n                             ordered.stateRootHash,\n                             ordered.txnRootHash))\n\n        three_pc_batch = ThreePcBatch.from_ordered(ordered)\n        if self.db_manager.ledgers[AUDIT_LEDGER_ID].uncommittedRootHash is None:\n            # if we order request during view change\n            # in between catchup rounds, then the 3PC batch will not be applied,\n            # since it was reverted before catchup started, and only COMMITs were\n            # processed in between catchup that led to this ORDERED msg\n            logger.info(\"{} applying stashed requests for batch {} {} of {} requests; state root {}; txn root {}\"\n                        .format(self.name,\n                                three_pc_batch.view_no,\n                                three_pc_batch.pp_seq_no,\n                                len(three_pc_batch.valid_digests),\n                                three_pc_batch.state_root,\n                                three_pc_batch.txn_root))\n\n            self.apply_stashed_reqs(three_pc_batch)\n\n        self.executeBatch(three_pc_batch,\n                          ordered.valid_reqIdr,\n                          ordered.invalid_reqIdr,\n                          ordered.auditTxnRootHash)\n\n        with self.metrics.measure_time(MetricsName.MONITOR_REQUEST_ORDERED_TIME):\n            self.monitor.requestOrdered(ordered.valid_reqIdr + ordered.invalid_reqIdr,\n                                        ordered.instId,\n                                        self.requests,\n                                        byMaster=True)\n\n        return True", "response": "Execute an ordered request and return the unique ID of the instance that was executed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef force_process_ordered(self):\n\n        for instance_id, messages in self.replicas.take_ordereds_out_of_turn():\n            num_processed = 0\n            for message in messages:\n                self.try_processing_ordered(message)\n                num_processed += 1\n            logger.info('{} processed {} Ordered batches for instance {} '\n                        'before starting catch up'\n                        .format(self, num_processed, instance_id))", "response": "For each message in replica that have been ordered and process them."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef processEscalatedException(self, ex):\n        if isinstance(ex, SuspiciousNode):\n            self.reportSuspiciousNodeEx(ex)\n        else:\n            raise RuntimeError(\"unhandled replica-escalated exception\") from ex", "response": "Process an exception escalated from a Replica\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if any requests have been ordered since last performance check Updates the performance check data store if needed.", "response": "def _update_new_ordered_reqs_count(self):\n        \"\"\"\n        Checks if any requests have been ordered since last performance check\n        and updates the performance check data store if needed.\n        :return: True if new ordered requests, False otherwise\n        \"\"\"\n        last_num_ordered = self._last_performance_check_data.get('num_ordered')\n        num_ordered = sum(num for num, _ in self.monitor.numOrderedRequests.values())\n        if num_ordered != last_num_ordered:\n            self._last_performance_check_data['num_ordered'] = num_ordered\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checkPerformance(self) -> Optional[bool]:\n        logger.trace(\"{} checking its performance\".format(self))\n\n        # Move ahead only if the node has synchronized its state with other\n        # nodes\n        if not self.isParticipating:\n            return\n\n        if self.view_change_in_progress:\n            return\n\n        if not self._update_new_ordered_reqs_count():\n            logger.trace(\"{} ordered no new requests\".format(self))\n            return\n\n        if self.instances.masterId is not None:\n            self.sendNodeRequestSpike()\n\n            master_throughput, backup_throughput = self.monitor.getThroughputs(0)\n            if master_throughput is not None:\n                self.metrics.add_event(MetricsName.MONITOR_AVG_THROUGHPUT, master_throughput)\n            if backup_throughput is not None:\n                self.metrics.add_event(MetricsName.BACKUP_MONITOR_AVG_THROUGHPUT, backup_throughput)\n\n            avg_lat_master, avg_lat_backup = self.monitor.getLatencies()\n            if avg_lat_master:\n                self.metrics.add_event(MetricsName.MONITOR_AVG_LATENCY, avg_lat_master)\n\n            if avg_lat_backup:\n                self.metrics.add_event(MetricsName.BACKUP_MONITOR_AVG_LATENCY, avg_lat_backup)\n\n            degraded_backups = self.monitor.areBackupsDegraded()\n            if degraded_backups:\n                logger.display('{} backup instances performance degraded'.format(degraded_backups))\n                self.backup_instance_faulty_processor.on_backup_degradation(degraded_backups)\n\n            if self.monitor.isMasterDegraded():\n                logger.display('{} master instance performance degraded'.format(self))\n                self.view_changer.on_master_degradation()\n                return False\n            else:\n                logger.trace(\"{}'s master has higher performance than backups\".\n                             format(self))\n        return True", "response": "Checks if master instance is slow and send an instance change request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nschedule a view change which can send a view change message", "response": "def lost_master_primary(self):\n        \"\"\"\n        Schedule an primary connection check which in turn can send a view\n        change message\n        \"\"\"\n        self.primaries_disconnection_times[self.master_replica.instId] = time.perf_counter()\n        self._schedule_view_change()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the signature of the message.", "response": "def verifySignature(self, msg):\n        \"\"\"\n        Validate the signature of the request\n        Note: Batch is whitelisted because the inner messages are checked\n\n        :param msg: a message requiring signature verification\n        :return: None; raises an exception if the signature is not valid\n        \"\"\"\n        if isinstance(msg, self.authnWhitelist):\n            return\n        if isinstance(msg, Propagate):\n            typ = 'propagate'\n            req = TxnUtilConfig.client_request_class(**msg.request)\n        else:\n            typ = ''\n            req = msg\n\n        key = None\n\n        if isinstance(req, Request):\n            key = req.key\n\n        if not isinstance(req, Mapping):\n            req = req.as_dict\n\n        with self.metrics.measure_time(MetricsName.VERIFY_SIGNATURE_TIME):\n            identifiers = self.authNr(req).authenticate(req, key=key)\n\n        logger.debug(\"{} authenticated {} signature on {} request {}\".\n                     format(self, identifiers, typ, req['reqId']),\n                     extra={\"cli\": True,\n                            \"tags\": [\"node-msg-processing\"]})"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the REQUEST sent to this Node", "response": "def executeBatch(self, three_pc_batch: ThreePcBatch,\n                     valid_reqs_keys: List, invalid_reqs_keys: List,\n                     audit_txn_root) -> None:\n        \"\"\"\n        Execute the REQUEST sent to this Node\n\n        :param view_no: the view number (See glossary)\n        :param pp_time: the time at which PRE-PREPARE was sent\n        :param valid_reqs: list of valid client requests keys\n        :param valid_reqs: list of invalid client requests keys\n        \"\"\"\n\n        # We need hashes in apply and str in commit\n        three_pc_batch.txn_root = Ledger.hashToStr(three_pc_batch.txn_root)\n        three_pc_batch.state_root = Ledger.hashToStr(three_pc_batch.state_root)\n\n        for req_key in valid_reqs_keys:\n            self.execute_hook(NodeHooks.PRE_REQUEST_COMMIT, req_key=req_key,\n                              pp_time=three_pc_batch.pp_time,\n                              state_root=three_pc_batch.state_root,\n                              txn_root=three_pc_batch.txn_root)\n\n        self.execute_hook(NodeHooks.PRE_BATCH_COMMITTED,\n                          ledger_id=three_pc_batch.ledger_id,\n                          pp_time=three_pc_batch.pp_time,\n                          reqs_keys=valid_reqs_keys,\n                          state_root=three_pc_batch.state_root,\n                          txn_root=three_pc_batch.txn_root)\n\n        try:\n            committedTxns = self.get_executer(three_pc_batch.ledger_id)(three_pc_batch)\n        except Exception as exc:\n            logger.error(\n                \"{} commit failed for batch request, error {}, view no {}, \"\n                \"ppSeqNo {}, ledger {}, state root {}, txn root {}, \"\n                \"requests: {}\".format(\n                    self, repr(exc), three_pc_batch.view_no, three_pc_batch.pp_seq_no,\n                    three_pc_batch.ledger_id, three_pc_batch.state_root,\n                    three_pc_batch.txn_root, [req_idr for req_idr in valid_reqs_keys]\n                )\n            )\n            raise\n\n        for req_key in valid_reqs_keys + invalid_reqs_keys:\n            if req_key in self.requests:\n                self.mark_request_as_executed(self.requests[req_key].request)\n            else:\n                # Means that this request is dropped from the main requests queue due to timeout,\n                # but anyway it is ordered and executed normally\n                logger.debug('{} normally executed request {} which object has been dropped '\n                             'from the requests queue'.format(self, req_key))\n                pass\n\n        # TODO is it possible to get len(committedTxns) != len(valid_reqs)\n        # someday\n        if not committedTxns:\n            return\n\n        logger.debug(\"{} committed batch request, view no {}, ppSeqNo {}, \"\n                     \"ledger {}, state root {}, txn root {}, requests: {}\".\n                     format(self, three_pc_batch.view_no, three_pc_batch.pp_seq_no,\n                            three_pc_batch.ledger_id, three_pc_batch.state_root,\n                            three_pc_batch.txn_root, [key for key in valid_reqs_keys]))\n\n        for txn in committedTxns:\n            self.execute_hook(NodeHooks.POST_REQUEST_COMMIT, txn=txn,\n                              pp_time=three_pc_batch.pp_time, state_root=three_pc_batch.state_root,\n                              txn_root=three_pc_batch.txn_root)\n\n        first_txn_seq_no = get_seq_no(committedTxns[0])\n        last_txn_seq_no = get_seq_no(committedTxns[-1])\n\n        reqs = []\n        reqs_list_built = True\n        for req_key in valid_reqs_keys:\n            if req_key in self.requests:\n                reqs.append(self.requests[req_key].request.as_dict)\n            else:\n                logger.warning(\"Could not build requests list for observers due to non-existent requests\")\n                reqs_list_built = False\n                break\n\n        if reqs_list_built:\n            batch_committed_msg = BatchCommitted(reqs,\n                                                 three_pc_batch.ledger_id,\n                                                 0,\n                                                 three_pc_batch.view_no,\n                                                 three_pc_batch.pp_seq_no,\n                                                 three_pc_batch.pp_time,\n                                                 three_pc_batch.state_root,\n                                                 three_pc_batch.txn_root,\n                                                 first_txn_seq_no,\n                                                 last_txn_seq_no,\n                                                 audit_txn_root,\n                                                 three_pc_batch.primaries)\n            self._observable.append_input(batch_committed_msg, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls when a batch has been created and has been applied to the ledger and state root.", "response": "def onBatchCreated(self, three_pc_batch: ThreePcBatch):\n        \"\"\"\n        A batch of requests has been created and has been applied but\n        committed to ledger and state.\n        :param ledger_id:\n        :param state_root: state root after the batch creation\n        :return:\n        \"\"\"\n        ledger_id = three_pc_batch.ledger_id\n        if ledger_id == POOL_LEDGER_ID:\n            if isinstance(self.poolManager, TxnPoolManager):\n                self.get_req_handler(POOL_LEDGER_ID).onBatchCreated(three_pc_batch.state_root, three_pc_batch.pp_time)\n        elif self.get_req_handler(ledger_id):\n            self.get_req_handler(ledger_id).onBatchCreated(three_pc_batch.state_root, three_pc_batch.pp_time)\n        else:\n            logger.debug('{} did not know how to handle for ledger {}'.format(self, ledger_id))\n\n        if ledger_id == POOL_LEDGER_ID:\n            three_pc_batch.primaries = self.future_primaries_handler.post_batch_applied(three_pc_batch)\n        elif not three_pc_batch.primaries:\n            three_pc_batch.primaries = self.future_primaries_handler.get_last_primaries() or self.primaries\n        self.audit_handler.post_batch_applied(three_pc_batch)\n\n        self.execute_hook(NodeHooks.POST_BATCH_CREATED, ledger_id, three_pc_batch.state_root)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef onBatchRejected(self, ledger_id):\n        if ledger_id == POOL_LEDGER_ID:\n            if isinstance(self.poolManager, TxnPoolManager):\n                self.get_req_handler(POOL_LEDGER_ID).onBatchRejected()\n        elif self.get_req_handler(ledger_id):\n            self.get_req_handler(ledger_id).onBatchRejected()\n        else:\n            logger.debug('{} did not know how to handle for ledger {}'.format(self, ledger_id))\n\n        self.audit_handler.post_batch_rejected(ledger_id)\n\n        self.execute_hook(NodeHooks.POST_BATCH_REJECTED, ledger_id)", "response": "Called by the ledger when a batch of requests has been rejected."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addNewRole(self, txn):\n        # If the client authenticator is a simple authenticator then add verkey.\n        #  For a custom authenticator, handle appropriately.\n        # NOTE: The following code should not be used in production\n        if isinstance(self.clientAuthNr.core_authenticator, SimpleAuthNr):\n            txn_data = get_payload_data(txn)\n            identifier = txn_data[TARGET_NYM]\n            verkey = txn_data.get(VERKEY)\n            v = DidVerifier(verkey, identifier=identifier)\n            if identifier not in self.clientAuthNr.core_authenticator.clients:\n                role = txn_data.get(ROLE)\n                if role not in (STEWARD, TRUSTEE, None):\n                    logger.debug(\"Role if present must be {} and not {}\".\n                                 format(Roles.STEWARD.name, role))\n                    return\n                self.clientAuthNr.core_authenticator.addIdr(identifier,\n                                                            verkey=v.verkey,\n                                                            role=role)", "response": "Add a new role to this node based on transaction type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure that the keys are setup in the local STP keep. Raises KeysNotFoundException if not found.", "response": "def ensureKeysAreSetup(self):\n        \"\"\"\n        Check whether the keys are setup in the local STP keep.\n        Raises KeysNotFoundException if not found.\n        \"\"\"\n        if not areKeysSetup(self.name, self.keys_dir):\n            raise REx(REx.reason.format(self.name) + self.keygenScript)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reportSuspiciousNodeEx(self, ex: SuspiciousNode):\n        self.reportSuspiciousNode(ex.node, ex.reason, ex.code, ex.offendingMsg)", "response": "Report suspicion on a node on the basis of an exception."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reportSuspiciousNode(self,\n                             nodeName: str,\n                             reason=None,\n                             code: int = None,\n                             offendingMsg=None):\n        \"\"\"\n        Report suspicion on a node and add it to this node's blacklist.\n\n        :param nodeName: name of the node to report suspicion on\n        :param reason: the reason for suspicion\n        \"\"\"\n        logger.warning(\"{} raised suspicion on node {} for {}; suspicion code \"\n                       \"is {}\".format(self, nodeName, reason, code))\n        # TODO need a more general solution here\n\n        # TODO: Should not blacklist client on a single InvalidSignature.\n        # Should track if a lot of requests with incorrect signatures have been\n        # made in a short amount of time, only then blacklist client.\n        # if code == InvalidSignature.code:\n        #     self.blacklistNode(nodeName,\n        #                        reason=InvalidSignature.reason,\n        #                        code=InvalidSignature.code)\n\n        # TODO: Consider blacklisting nodes again.\n        # if code in self.suspicions:\n        #     self.blacklistNode(nodeName,\n        #                        reason=self.suspicions[code],\n        #                        code=code)\n\n        if code in (s.code for s in (Suspicions.PPR_DIGEST_WRONG,\n                                     Suspicions.PPR_REJECT_WRONG,\n                                     Suspicions.PPR_TXN_WRONG,\n                                     Suspicions.PPR_STATE_WRONG,\n                                     Suspicions.PPR_PLUGIN_EXCEPTION,\n                                     Suspicions.PPR_SUB_SEQ_NO_WRONG,\n                                     Suspicions.PPR_NOT_FINAL,\n                                     Suspicions.PPR_WITH_ORDERED_REQUEST,\n                                     Suspicions.PPR_AUDIT_TXN_ROOT_HASH_WRONG,\n                                     Suspicions.PPR_BLS_MULTISIG_WRONG,\n                                     Suspicions.PPR_TIME_WRONG,\n                                     )):\n            logger.display('{}{} got one of primary suspicions codes {}'.format(VIEW_CHANGE_PREFIX, self, code))\n            self.view_changer.on_suspicious_primary(Suspicions.get_by_code(code))\n\n        if offendingMsg:\n            self.discard(offendingMsg, reason, logger.debug)", "response": "Report suspicion on a node and add it to the blacklist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reportSuspiciousClient(self, clientName: str, reason):\n        logger.warning(\"{} raised suspicion on client {} for {}\"\n                       .format(self, clientName, reason))\n        self.blacklistClient(clientName)", "response": "Report suspicion on a client and add it to this node s blacklist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the client specified by clientName to this node s blacklist.", "response": "def blacklistClient(self, clientName: str,\n                        reason: str = None, code: int = None):\n        \"\"\"\n        Add the client specified by `clientName` to this node's blacklist\n        \"\"\"\n        msg = \"{} blacklisting client {}\".format(self, clientName)\n        if reason:\n            msg += \" for reason {}\".format(reason)\n        logger.display(msg)\n        self.clientBlacklister.blacklist(clientName)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds the node specified by nodeName to this node s blacklist", "response": "def blacklistNode(self, nodeName: str, reason: str = None, code: int = None):\n        \"\"\"\n        Add the node specified by `nodeName` to this node's blacklist\n        \"\"\"\n        msg = \"{} blacklisting node {}\".format(self, nodeName)\n        if reason:\n            msg += \" for reason {}\".format(reason)\n        if code:\n            msg += \" for code {}\".format(code)\n        logger.display(msg)\n        self.nodeBlacklister.blacklist(nodeName)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the node s current statistics to log.", "response": "def logstats(self):\n        \"\"\"\n        Print the node's current statistics to log.\n        \"\"\"\n        lines = [\n            \"node {} current stats\".format(self),\n            \"--------------------------------------------------------\",\n            \"node inbox size         : {}\".format(len(self.nodeInBox)),\n            \"client inbox size       : {}\".format(len(self.clientInBox)),\n            \"age (seconds)           : {}\".format(time.time() - self.created),\n            \"next check for reconnect: {}\".format(time.perf_counter() -\n                                                  self.nodestack.nextCheck),\n            \"node connections        : {}\".format(self.nodestack.conns),\n            \"f                       : {}\".format(self.f),\n            \"master instance         : {}\".format(self.instances.masterId),\n            \"replicas                : {}\".format(len(self.replicas)),\n            \"view no                 : {}\".format(self.viewNo),\n            \"rank                    : {}\".format(self.rank),\n            \"msgs to replicas        : {}\".format(self.replicas.sum_inbox_len),\n            \"msgs to view changer    : {}\".format(len(self.msgsToViewChanger)),\n            \"action queue            : {} {}\".format(len(self.actionQueue),\n                                                     id(self.actionQueue)),\n            \"action queue stash      : {} {}\".format(len(self.aqStash),\n                                                     id(self.aqStash)),\n        ]\n\n        logger.info(\"\\n\".join(lines), extra={\"cli\": False})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints the node s info to log for the REST backend to read.", "response": "def logNodeInfo(self):\n        \"\"\"\n        Print the node's info to log for the REST backend to read.\n        \"\"\"\n        self.nodeInfo['data'] = self.collectNodeInfo()\n\n        with closing(open(os.path.join(self.ledger_dir, 'node_info'), 'w')) \\\n                as logNodeInfoFile:\n            logNodeInfoFile.write(json.dumps(self.nodeInfo['data']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_collection_sizes(obj, collections: Optional[Tuple]=None,\n                         get_only_non_empty=False):\n    \"\"\"\n    Iterates over `collections` of the gives object and gives its byte size\n    and number of items in collection\n    \"\"\"\n    from pympler import asizeof\n    collections = collections or (list, dict, set, deque, abc.Sized)\n    if not isinstance(collections, tuple):\n        collections = tuple(collections)\n\n    result = []\n    for attr_name in dir(obj):\n        attr = getattr(obj, attr_name)\n        if isinstance(attr, collections) and (\n                not get_only_non_empty or len(attr) > 0):\n            result.append(\n                (attr_name, len(attr), asizeof.asizeof(attr, detail=1)))\n    return result", "response": "Returns a list of bytes sizes of all the items in the given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef backupIds(self) -> Sequence[int]:\n        return [id for id in self.started.keys() if id != 0]", "response": "Return the list of replicas that don t belong to the master protocol\n        instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck whether n - f nodes completed view change and whether one of them has a view change quorum.", "response": "def _hasViewChangeQuorum(self):\n        # This method should just be present for master instance.\n        \"\"\"\n        Checks whether n-f nodes completed view change and whether one\n        of them is the next primary\n        \"\"\"\n        num_of_ready_nodes = len(self._view_change_done)\n        diff = self.quorum - num_of_ready_nodes\n        if diff > 0:\n            logger.info('{} needs {} ViewChangeDone messages'.format(self, diff))\n            return False\n\n        logger.info(\"{} got view change quorum ({} >= {})\".\n                    format(self.name, num_of_ready_nodes, self.quorum))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating and process an instance change request.", "response": "def process_instance_change_msg(self, instChg: InstanceChange, frm: str) -> None:\n        \"\"\"\n        Validate and process an instance change request.\n\n        :param instChg: the instance change request\n        :param frm: the name of the node that sent this `msg`\n        \"\"\"\n        if frm not in self.provider.connected_nodes():\n            self.provider.discard(\n                instChg,\n                \"received instance change request: {} from {} \"\n                \"which is not in connected list: {}\".format(\n                    instChg, frm, self.provider.connected_nodes()), logger.info)\n            return\n\n        logger.info(\"{} received instance change request: {} from {}\".format(self, instChg, frm))\n\n        # TODO: add sender to blacklist?\n        if not isinstance(instChg.viewNo, int):\n            self.provider.discard(\n                instChg, \"{}field view_no has incorrect type: {}\".format(\n                    VIEW_CHANGE_PREFIX, type(instChg.viewNo)))\n        elif instChg.viewNo <= self.view_no:\n            self.provider.discard(\n                instChg,\n                \"Received instance change request with view no {} \"\n                \"which is not more than its view no {}\".format(\n                    instChg.viewNo, self.view_no), logger.info)\n        else:\n            # Record instance changes for views but send instance change\n            # only when found master to be degraded. if quorum of view changes\n            #  found then change view even if master not degraded\n            self._on_verified_instance_change_msg(instChg, frm)\n\n            if self.instance_changes.has_inst_chng_from(instChg.viewNo, self.name):\n                logger.info(\"{} received instance change message {} but has already \"\n                            \"sent an instance change message\".format(self, instChg))\n            elif not self.provider.is_master_degraded():\n                logger.info(\"{} received instance change message {} but did not \"\n                            \"find the master to be slow\".format(self, instChg))\n            else:\n                logger.display(\"{}{} found master degraded after receiving instance change\"\n                               \" message from {}\".format(VIEW_CHANGE_PREFIX, self, frm))\n                self.sendInstanceChange(instChg.viewNo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_vchd_msg(self, msg: ViewChangeDone, sender: str) -> bool:\n        logger.info(\"{}'s primary selector started processing of ViewChangeDone msg from {} : {}\".\n                    format(self.name, sender, msg))\n        view_no = msg.viewNo\n        if self.view_no != view_no:\n            self.provider.discard(msg, '{} got Primary from {} for view no {} '\n                                       'whereas current view no is {}'.\n                                  format(self, sender, view_no, self.view_no),\n                                  logMethod=logger.info)\n            return False\n\n        new_primary_name = msg.name\n        if new_primary_name == self.previous_master_primary:\n            self.provider.discard(msg, '{} got Primary from {} for {} who was primary of '\n                                       'master in previous view too'.\n                                  format(self, sender, new_primary_name),\n                                  logMethod=logger.info)\n            return False\n\n        # Since a node can send ViewChangeDone more than one time\n        self._on_verified_view_change_done_msg(msg, sender)\n        # TODO why do we check that after the message tracking\n        if self.provider.has_primary():\n            self.provider.discard(msg, \"it already decided primary which is {}\".\n                                  format(self.provider.current_primary_name()), logger.info)\n            return False\n\n        self._start_selection()", "response": "Processes ViewChangeDone messages. Once n-f messages have been\n        received, decides on a primary for specific replica.\n\n        :param msg: ViewChangeDone message\n        :param sender: the name of the node from which this message was sent"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nservice at most limit messages from the inBox.", "response": "async def serviceQueues(self, limit=None) -> int:\n        \"\"\"\n        Service at most `limit` messages from the inBox.\n\n        :param limit: the maximum number of messages to service\n        :return: the number of messages successfully processed\n        \"\"\"\n        # do not start any view changes until catch-up is finished!\n        if not Mode.is_done_syncing(self.provider.node_mode()):\n            return 0\n        return await self.inBoxRouter.handleAll(self.inBox, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sendInstanceChange(self, view_no: int,\n                           suspicion=Suspicions.PRIMARY_DEGRADED):\n        \"\"\"\n        Broadcast an instance change request to all the remaining nodes\n\n        :param view_no: the view number when the instance change is requested\n        \"\"\"\n\n        # If not found any sent instance change messages in last\n        # `ViewChangeWindowSize` seconds or the last sent instance change\n        # message was sent long enough ago then instance change message can be\n        # sent otherwise no.\n        canSendInsChange, cooldown = self.insChngThrottler.acquire()\n        if canSendInsChange:\n            logger.info(\n                \"{}{} sending an instance change with view_no {}\"\n                \" since {}\".format(\n                    VIEW_CHANGE_PREFIX,\n                    self,\n                    view_no,\n                    suspicion.reason))\n            logger.info(\"{}{} metrics for monitor: {}\"\n                        .format(MONITORING_PREFIX, self,\n                                self.provider.pretty_metrics()))\n            msg = self._create_instance_change_msg(view_no, suspicion.code)\n            self.send(msg)\n            # record instance change vote for self and try to change the view\n            # if quorum is reached\n            self._on_verified_instance_change_msg(msg, self.name)\n        else:\n            logger.info(\"{} cannot send instance change sooner then {} seconds\".format(self, cooldown))", "response": "Send an instance change request to all the remaining nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _canViewChange(self, proposedViewNo: int) -> (bool, str):\n        msg = None\n        quorum = self.quorums.view_change.value\n        if not self.instance_changes.has_quorum(proposedViewNo, quorum):\n            msg = '{} has no quorum for view {}'.format(self, proposedViewNo)\n        elif not proposedViewNo > self.view_no:\n            msg = '{} is in higher view more than {}'.format(\n                self, proposedViewNo)\n\n        return not bool(msg), msg", "response": "Return whether the view change for the proposed view number and its view is less than or equal to the proposed view number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the view change process.", "response": "def start_view_change(self, proposed_view_no: int, continue_vc=False):\n        \"\"\"\n        Trigger the view change process.\n\n        :param proposed_view_no: the new view number after view change.\n        \"\"\"\n        # TODO: consider moving this to pool manager\n        # TODO: view change is a special case, which can have different\n        # implementations - we need to make this logic pluggable\n\n        if self.pre_vc_strategy and (not continue_vc):\n            self.pre_view_change_in_progress = True\n            self.pre_vc_strategy.prepare_view_change(proposed_view_no)\n            return\n        elif self.pre_vc_strategy:\n            self.pre_vc_strategy.on_strategy_complete()\n\n        self.previous_view_no = self.view_no\n        self.view_no = proposed_view_no\n        self.pre_view_change_in_progress = False\n        self.view_change_in_progress = True\n        self.previous_master_primary = self.provider.current_primary_name()\n        self.set_defaults()\n        self._process_vcd_for_future_view()\n\n        self.initInsChngThrottling()\n\n        self.provider.notify_view_change_start()\n        self.provider.start_catchup()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _verify_primary(self, new_primary, ledger_info):\n        expected_primary = self.provider.next_primary_name()\n        if new_primary != expected_primary:\n            logger.error(\"{}{} expected next primary to be {}, but majority \"\n                         \"declared {} instead for view {}\"\n                         .format(PRIMARY_SELECTION_PREFIX, self.name,\n                                 expected_primary, new_primary, self.view_no))\n            return False\n\n        self._primary_verified = True\n        return True", "response": "This method is called when sufficient number of ViewChangeDone\n        received and makes steps to switch to the new primary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a ViewChangeDone message to other protocol participants", "response": "def _send_view_change_done_message(self):\n        \"\"\"\n        Sends ViewChangeDone message to other protocol participants\n        \"\"\"\n        new_primary_name = self.provider.next_primary_name()\n        ledger_summary = self.provider.ledger_summary()\n        message = ViewChangeDone(self.view_no,\n                                 new_primary_name,\n                                 ledger_summary)\n\n        logger.info(\"{} is sending ViewChangeDone msg to all : {}\".format(self, message))\n\n        self.send(message)\n        self._on_verified_view_change_done_msg(message, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_msgs_for_lagged_nodes(self) -> List[ViewChangeDone]:\n        # Should not return a list, only done for compatibility with interface\n        \"\"\"\n        Returns the last accepted `ViewChangeDone` message.\n        If no view change has happened returns ViewChangeDone\n        with view no 0 to a newly joined node\n        \"\"\"\n        # TODO: Consider a case where more than one node joins immediately,\n        # then one of the node might not have an accepted\n        # ViewChangeDone message\n        messages = []\n        accepted = self._accepted_view_change_done_message\n        if accepted:\n            messages.append(ViewChangeDone(self.last_completed_view_no, *accepted))\n        elif self.name in self._view_change_done:\n            messages.append(ViewChangeDone(self.last_completed_view_no,\n                                           *self._view_change_done[self.name]))\n        else:\n            logger.info('{} has no ViewChangeDone message to send for view {}'.\n                        format(self, self.view_no))\n        return messages", "response": "Returns the list of ViewChangeDone messages for lagged nodes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self, val):\n\n        if self.nullable and val is None:\n            return\n        type_er = self.__type_check(val)\n        if type_er:\n            return type_er\n\n        spec_err = self._specific_validation(val)\n        if spec_err:\n            return spec_err", "response": "Validates the value for the key - value pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sign(self, msg: Dict) -> Dict:\n        ser = serialize_msg_for_signing(msg, topLevelKeysToIgnore=[f.SIG.nm])\n        bsig = self.naclSigner.signature(ser)\n        sig = base58.b58encode(bsig).decode(\"utf-8\")\n        return sig", "response": "Return a signature for the given message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lastPrePrepareSeqNo(self, n):\n        if n > self._lastPrePrepareSeqNo:\n            self._lastPrePrepareSeqNo = n\n        else:\n            self.logger.debug(\n                '{} cannot set lastPrePrepareSeqNo to {} as its '\n                'already {}'.format(\n                    self, n, self._lastPrePrepareSeqNo))", "response": "Sets the sequence number of the last pre - prepare sequence for this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generateName(nodeName: str, instId: int):\n\n        if isinstance(nodeName, str):\n            # Because sometimes it is bytes (why?)\n            if \":\" in nodeName:\n                # Because in some cases (for requested messages) it\n                # already has ':'. This should be fixed.\n                return nodeName\n        return \"{}:{}\".format(nodeName, instId)", "response": "Create and return the name for a replica using its nodeName and instanceId."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef primaryName(self, value: Optional[str]) -> None:\n        if value is not None:\n            self.warned_no_primary = False\n        self.primaryNames[self.viewNo] = value\n        self.compact_primary_names()\n        if value != self._primaryName:\n            self._primaryName = value\n            self.logger.info(\"{} setting primaryName for view no {} to: {}\".\n                             format(self, self.viewNo, value))\n            if value is None:\n                # Since the GC needs to happen after a primary has been\n                # decided.\n                return\n            self._gc_before_new_view()\n            if self.__should_reset_watermarks_before_new_view():\n                self._reset_watermarks_before_new_view()", "response": "Sets the value of isPrimary to value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_lowest_probable_prepared_certificate_in_view(\n            self, view_no) -> Optional[int]:\n        \"\"\"\n        Return lowest pp_seq_no of the view for which can be prepared but\n        choose from unprocessed PRE-PREPAREs and PREPAREs.\n        \"\"\"\n        # TODO: Naive implementation, dont need to iterate over the complete\n        # data structures, fix this later\n        seq_no_pp = SortedList()  # pp_seq_no of PRE-PREPAREs\n        # pp_seq_no of PREPAREs with count of PREPAREs for each\n        seq_no_p = set()\n\n        for (v, p) in self.prePreparesPendingPrevPP:\n            if v == view_no:\n                seq_no_pp.add(p)\n            if v > view_no:\n                break\n\n        for (v, p), pr in self.preparesWaitingForPrePrepare.items():\n            if v == view_no and len(pr) >= self.quorums.prepare.value:\n                seq_no_p.add(p)\n\n        for n in seq_no_pp:\n            if n in seq_no_p:\n                return n\n        return None", "response": "Return the lowest probable PRE - PREPARE certificate in the given view."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_last_ordered_for_non_master(self):\n        if not self.isMaster and self.first_batch_after_catchup and \\\n                not self.isPrimary:\n            # If not master instance choose last ordered seq no to be 1 less\n            # the lowest prepared certificate in this view\n            lowest_prepared = self.get_lowest_probable_prepared_certificate_in_view(\n                self.viewNo)\n            if lowest_prepared is not None:\n                # now after catch up we have in last_ordered_3pc[1] value 0\n                # it value should change last_ordered_3pc to lowest_prepared - 1\n                self.logger.info('{} Setting last ordered for non-master as {}'.\n                                 format(self, self.last_ordered_3pc))\n                self.last_ordered_3pc = (self.viewNo, lowest_prepared - 1)\n                self.update_watermark_from_3pc()\n                self.first_batch_after_catchup = False", "response": "Setup the last ordered for non - master instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_primary_in_view(self, viewNo: int) -> Optional[bool]:\n        if viewNo not in self.primaryNames:\n            return False\n        return self.primaryNames[viewNo] == self.name", "response": "Return whether this replica was primary in the given view."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isPrimaryForMsg(self, msg) -> Optional[bool]:\n        return self.isPrimary if self.isMsgForCurrentView(msg) \\\n            else self.is_primary_in_view(msg.viewNo)", "response": "Returns whether this replica is primary for the given message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn whether this message was from primary replica", "response": "def isMsgFromPrimary(self, msg, sender: str) -> bool:\n        \"\"\"\n        Return whether this message was from primary replica\n        :param msg:\n        :param sender:\n        :return:\n        \"\"\"\n        if self.isMsgForCurrentView(msg):\n            return self.primaryName == sender\n        try:\n            return self.primaryNames[msg.viewNo] == sender\n        except KeyError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef processReqDuringBatch(\n            self,\n            req: Request,\n            cons_time: int):\n        \"\"\"\n        This method will do dynamic validation and apply requests.\n        If there is any errors during validation it would be raised\n        \"\"\"\n        if self.isMaster:\n            self.node.doDynamicValidation(req)\n            self.node.applyReq(req, cons_time)", "response": "This method will do dynamic validation and apply requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a 3 - PC batch for the given ledger.", "response": "def create_3pc_batch(self, ledger_id):\n        pp_seq_no = self.lastPrePrepareSeqNo + 1\n        pool_state_root_hash = self.stateRootHash(POOL_LEDGER_ID)\n        self.logger.debug(\"{} creating batch {} for ledger {} with state root {}\".format(\n            self, pp_seq_no, ledger_id,\n            self.stateRootHash(ledger_id, to_str=False)))\n\n        if self.last_accepted_pre_prepare_time is None:\n            last_ordered_ts = self._get_last_timestamp_from_state(ledger_id)\n            if last_ordered_ts:\n                self.last_accepted_pre_prepare_time = last_ordered_ts\n\n        # DO NOT REMOVE `view_no` argument, used while replay\n        # tm = self.utc_epoch\n        tm = self.get_utc_epoch_for_preprepare(self.instId, self.viewNo,\n                                               pp_seq_no)\n\n        reqs, invalid_indices, rejects = self.consume_req_queue_for_pre_prepare(\n            ledger_id, tm, self.viewNo, pp_seq_no)\n        if self.isMaster:\n            three_pc_batch = ThreePcBatch(ledger_id=ledger_id,\n                                          inst_id=self.instId,\n                                          view_no=self.viewNo,\n                                          pp_seq_no=pp_seq_no,\n                                          pp_time=tm,\n                                          state_root=self.stateRootHash(ledger_id, to_str=False),\n                                          txn_root=self.txnRootHash(ledger_id, to_str=False),\n                                          primaries=[],\n                                          valid_digests=self.get_valid_req_ids_from_all_requests(\n                                              reqs, invalid_indices))\n            self.node.onBatchCreated(three_pc_batch)\n\n        digest = self.batchDigest(reqs)\n        state_root_hash = self.stateRootHash(ledger_id)\n        audit_txn_root_hash = self.txnRootHash(AUDIT_LEDGER_ID)\n\n        \"\"\"TODO: for now default value for fields sub_seq_no is 0 and for final is True\"\"\"\n        params = [\n            self.instId,\n            self.viewNo,\n            pp_seq_no,\n            tm,\n            [req.digest for req in reqs],\n            invalid_index_serializer.serialize(invalid_indices, toBytes=False),\n            digest,\n            ledger_id,\n            state_root_hash,\n            self.txnRootHash(ledger_id),\n            0,\n            True,\n            pool_state_root_hash,\n            audit_txn_root_hash\n        ]\n\n        # BLS multi-sig:\n        params = self._bls_bft_replica.update_pre_prepare(params, ledger_id)\n\n        pre_prepare = PrePrepare(*params)\n        if self.isMaster:\n            rv = self.execute_hook(ReplicaHooks.CREATE_PPR, pre_prepare)\n            pre_prepare = rv if rv is not None else pre_prepare\n\n        self.logger.trace('{} created a PRE-PREPARE with {} requests for ledger {}'.format(\n            self, len(reqs), ledger_id))\n        self.lastPrePrepareSeqNo = pp_seq_no\n        self.last_accepted_pre_prepare_time = tm\n        if self.isMaster:\n            self.outBox.extend(rejects)\n        return pre_prepare"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses limit number of messages in the inBox and send them to the service actions.", "response": "def serviceQueues(self, limit=None):\n        \"\"\"\n        Process `limit` number of messages in the inBox.\n\n        :param limit: the maximum number of messages to process\n        :return: the number of messages successfully processed\n        \"\"\"\n        # TODO should handle SuspiciousNode here\n        r = self.dequeue_pre_prepares()\n        r += self.inBoxRouter.handleAllSync(self.inBox, limit)\n        r += self.send_3pc_batch()\n        r += self._serviceActions()\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess a 3 - phase message.", "response": "def process_three_phase_msg(self, msg: ThreePhaseMsg, sender: str):\n        \"\"\"\n        Process a 3-phase (pre-prepare, prepare and commit) request.\n        Dispatch the request only if primary has already been decided, otherwise\n        stash it.\n\n        :param msg: the Three Phase message, one of PRE-PREPARE, PREPARE,\n            COMMIT\n        :param sender: name of the node that sent this message\n        \"\"\"\n        sender = self.generateName(sender, self.instId)\n\n        pp_key = ((msg.viewNo, msg.ppSeqNo) if\n                  isinstance(msg, PrePrepare) else None)\n\n        # the same PrePrepare might come here multiple times\n        if (pp_key and (msg, sender) not in self.pre_prepare_tss[pp_key]):\n            # TODO more clean solution would be to set timestamps\n            # earlier (e.g. in zstack)\n            self.pre_prepare_tss[pp_key][msg, sender] = self.get_time_for_3pc_batch()\n\n        result, reason = self.validator.validate_3pc_msg(msg)\n        if result == DISCARD:\n            self.discard(msg, \"{} discard message {} from {} \"\n                              \"with the reason: {}\".format(self, msg, sender, reason),\n                         self.logger.trace)\n        elif result == PROCESS:\n            self.threePhaseRouter.handleSync((msg, sender))\n        else:\n            self.logger.debug(\"{} stashing 3 phase message {} with \"\n                              \"the reason: {}\".format(self, msg, reason))\n            self.stasher.stash((msg, sender), result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate and process a PRE - PREPARE message and create and broadcast PREPARE message for it.", "response": "def processPrePrepare(self, pre_prepare: PrePrepare, sender: str):\n        \"\"\"\n        Validate and process provided PRE-PREPARE, create and\n        broadcast PREPARE for it.\n\n        :param pre_prepare: message\n        :param sender: name of the node that sent this message\n        \"\"\"\n        key = (pre_prepare.viewNo, pre_prepare.ppSeqNo)\n        self.logger.debug(\"{} received PRE-PREPARE{} from {}\".format(self, key, sender))\n\n        # TODO: should we still do it?\n        # Converting each req_idrs from list to tuple\n        req_idrs = {f.REQ_IDR.nm: [key for key in pre_prepare.reqIdr]}\n        pre_prepare = updateNamedTuple(pre_prepare, **req_idrs)\n\n        def report_suspicious(reason):\n            ex = SuspiciousNode(sender, reason, pre_prepare)\n            self.report_suspicious_node(ex)\n\n        why_not = self._can_process_pre_prepare(pre_prepare, sender)\n        if why_not is None:\n            why_not_applied = \\\n                self._process_valid_preprepare(pre_prepare, sender)\n            if why_not_applied is not None:\n                if why_not_applied == PP_APPLY_REJECT_WRONG:\n                    report_suspicious(Suspicions.PPR_REJECT_WRONG)\n                elif why_not_applied == PP_APPLY_WRONG_DIGEST:\n                    report_suspicious(Suspicions.PPR_DIGEST_WRONG)\n                elif why_not_applied == PP_APPLY_WRONG_STATE:\n                    report_suspicious(Suspicions.PPR_STATE_WRONG)\n                elif why_not_applied == PP_APPLY_ROOT_HASH_MISMATCH:\n                    report_suspicious(Suspicions.PPR_TXN_WRONG)\n                elif why_not_applied == PP_APPLY_HOOK_ERROR:\n                    report_suspicious(Suspicions.PPR_PLUGIN_EXCEPTION)\n                elif why_not_applied == PP_SUB_SEQ_NO_WRONG:\n                    report_suspicious(Suspicions.PPR_SUB_SEQ_NO_WRONG)\n                elif why_not_applied == PP_NOT_FINAL:\n                    # this is fine, just wait for another\n                    return\n                elif why_not_applied == PP_APPLY_AUDIT_HASH_MISMATCH:\n                    report_suspicious(Suspicions.PPR_AUDIT_TXN_ROOT_HASH_WRONG)\n                elif why_not_applied == PP_REQUEST_ALREADY_ORDERED:\n                    report_suspicious(Suspicions.PPR_WITH_ORDERED_REQUEST)\n        elif why_not == PP_CHECK_NOT_FROM_PRIMARY:\n            report_suspicious(Suspicions.PPR_FRM_NON_PRIMARY)\n        elif why_not == PP_CHECK_TO_PRIMARY:\n            report_suspicious(Suspicions.PPR_TO_PRIMARY)\n        elif why_not == PP_CHECK_DUPLICATE:\n            report_suspicious(Suspicions.DUPLICATE_PPR_SENT)\n        elif why_not == PP_CHECK_INCORRECT_POOL_STATE_ROOT:\n            report_suspicious(Suspicions.PPR_POOL_STATE_ROOT_HASH_WRONG)\n        elif why_not == PP_CHECK_OLD:\n            self.logger.info(\"PRE-PREPARE {} has ppSeqNo lower \"\n                             \"then the latest one - ignoring it\".format(key))\n        elif why_not == PP_CHECK_REQUEST_NOT_FINALIZED:\n            absents = set()\n            non_fin = set()\n            non_fin_payload = set()\n            for key in pre_prepare.reqIdr:\n                req = self.requests.get(key)\n                if req is None:\n                    absents.add(key)\n                elif not req.finalised:\n                    non_fin.add(key)\n                    non_fin_payload.add(req.request.payload_digest)\n            absent_str = ', '.join(str(key) for key in absents)\n            non_fin_str = ', '.join(\n                '{} ({} : {})'.format(str(key),\n                                      str(len(self.requests[key].propagates)),\n                                      ', '.join(self.requests[key].propagates.keys())) for key in non_fin)\n            self.logger.warning(\n                \"{} found requests in the incoming pp, of {} ledger, that are not finalized. \"\n                \"{} of them don't have propagates: {}.\"\n                \"{} of them don't have enough propagates: {}.\".format(self, pre_prepare.ledgerId,\n                                                                      len(absents), absent_str,\n                                                                      len(non_fin), non_fin_str))\n\n            def signal_suspicious(req):\n                self.logger.info(\"Request digest {} already ordered. Discard {} \"\n                                 \"from {}\".format(req, pre_prepare, sender))\n                report_suspicious(Suspicions.PPR_WITH_ORDERED_REQUEST)\n\n            # checking for payload digest is more effective\n            for payload_key in non_fin_payload:\n                if self.node.seqNoDB.get_by_payload_digest(payload_key) != (None, None):\n                    signal_suspicious(payload_key)\n                    return\n\n            # for absents we can only check full digest\n            for full_key in absents:\n                if self.node.seqNoDB.get_by_full_digest(full_key) is not None:\n                    signal_suspicious(full_key)\n                    return\n\n            bad_reqs = absents | non_fin\n            self.enqueue_pre_prepare(pre_prepare, sender, bad_reqs)\n            # TODO: An optimisation might be to not request PROPAGATEs\n            # if some PROPAGATEs are present or a client request is\n            # present and sufficient PREPAREs and PRE-PREPARE are present,\n            # then the digest can be compared but this is expensive as the\n            # PREPARE and PRE-PREPARE contain a combined digest\n            self._schedule(partial(self.request_propagates_if_needed, bad_reqs, pre_prepare),\n                           self.config.PROPAGATE_REQUEST_DELAY)\n        elif why_not == PP_CHECK_NOT_NEXT:\n            pp_view_no = pre_prepare.viewNo\n            pp_seq_no = pre_prepare.ppSeqNo\n            last_pp_view_no, last_pp_seq_no = self.__last_pp_3pc\n            if pp_view_no >= last_pp_view_no and (\n                    self.isMaster or self.last_ordered_3pc[1] != 0):\n                seq_frm = last_pp_seq_no + 1 if pp_view_no == last_pp_view_no else 1\n                seq_to = pp_seq_no - 1\n                if seq_to >= seq_frm >= pp_seq_no - CHK_FREQ + 1:\n                    self.logger.warning(\n                        \"{} missing PRE-PREPAREs from {} to {}, \"\n                        \"going to request\".format(self, seq_frm, seq_to))\n                    self._request_missing_three_phase_messages(\n                        pp_view_no, seq_frm, seq_to)\n            self.enqueue_pre_prepare(pre_prepare, sender)\n            self._setup_last_ordered_for_non_master()\n        elif why_not == PP_CHECK_WRONG_TIME:\n            key = (pre_prepare.viewNo, pre_prepare.ppSeqNo)\n            item = (pre_prepare, sender, False)\n            self.pre_prepares_stashed_for_incorrect_time[key] = item\n            report_suspicious(Suspicions.PPR_TIME_WRONG)\n        elif why_not == BlsBftReplica.PPR_BLS_MULTISIG_WRONG:\n            report_suspicious(Suspicions.PPR_BLS_MULTISIG_WRONG)\n        else:\n            self.logger.warning(\"Unknown PRE-PREPARE check status: {}\".format(why_not))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to send the PREPARE message.", "response": "def tryPrepare(self, pp: PrePrepare):\n        \"\"\"\n        Try to send the Prepare message if the PrePrepare message is ready to\n        be passed into the Prepare phase.\n        \"\"\"\n        rv, msg = self.canPrepare(pp)\n        if rv:\n            self.doPrepare(pp)\n        else:\n            self.logger.debug(\"{} cannot send PREPARE since {}\".format(self, msg))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef processPrepare(self, prepare: Prepare, sender: str) -> None:\n        key = (prepare.viewNo, prepare.ppSeqNo)\n        self.logger.debug(\"{} received PREPARE{} from {}\".format(self, key, sender))\n\n        # TODO move this try/except up higher\n        try:\n            if self.validatePrepare(prepare, sender):\n                self.addToPrepares(prepare, sender)\n                self.stats.inc(TPCStat.PrepareRcvd)\n                self.logger.debug(\"{} processed incoming PREPARE {}\".format(\n                    self, (prepare.viewNo, prepare.ppSeqNo)))\n            else:\n                # TODO let's have isValidPrepare throw an exception that gets\n                # handled and possibly logged higher\n                self.logger.trace(\"{} cannot process incoming PREPARE\".format(self))\n        except SuspiciousNode as ex:\n            self.report_suspicious_node(ex)", "response": "Validate and process the PREPARE message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate and process the COMMIT message.", "response": "def processCommit(self, commit: Commit, sender: str) -> None:\n        \"\"\"\n        Validate and process the COMMIT specified.\n        If validation is successful, return the message to the node.\n\n        :param commit: an incoming COMMIT message\n        :param sender: name of the node that sent the COMMIT\n        \"\"\"\n        self.logger.debug(\"{} received COMMIT{} from {}\".format(\n            self, (commit.viewNo, commit.ppSeqNo), sender))\n\n        if self.validateCommit(commit, sender):\n            self.stats.inc(TPCStat.CommitRcvd)\n            self.addToCommits(commit, sender)\n            self.logger.debug(\"{} processed incoming COMMIT{}\".format(\n                self, (commit.viewNo, commit.ppSeqNo)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tryCommit(self, prepare: Prepare):\n        rv, reason = self.canCommit(prepare)\n        if rv:\n            self.doCommit(prepare)\n        else:\n            self.logger.debug(\"{} cannot send COMMIT since {}\".format(self, reason))", "response": "Try to commit if the prepare message is ready to be passed into the the\n        commit phase."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tryOrder(self, commit: Commit):\n        canOrder, reason = self.canOrder(commit)\n        if canOrder:\n            self.logger.trace(\"{} returning request to node\".format(self))\n            self.doOrder(commit)\n        else:\n            self.logger.debug(\"{} cannot return request to node: {}\".format(self, reason))\n        return canOrder", "response": "Try to order if the Commit message is ready to be ordered."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef doCommit(self, p: Prepare):\n        key_3pc = (p.viewNo, p.ppSeqNo)\n        self.logger.debug(\"{} Sending COMMIT{} at {}\".format(self, key_3pc, self.get_current_time()))\n\n        params = [\n            self.instId, p.viewNo, p.ppSeqNo\n        ]\n\n        pre_prepare = self.getPrePrepare(*key_3pc)\n\n        # BLS multi-sig:\n        if p.stateRootHash is not None:\n            pre_prepare = self.getPrePrepare(*key_3pc)\n            params = self._bls_bft_replica.update_commit(params, pre_prepare)\n\n        commit = Commit(*params)\n        if self.isMaster:\n            rv = self.execute_hook(ReplicaHooks.CREATE_CM, commit)\n            commit = rv if rv is not None else commit\n\n        self.send(commit, TPCStat.CommitSent)\n        self.addToCommits(commit, self.name)", "response": "Create a commit message from the given Prepare message and trigger the commit phase\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nonFinalisedReqs(self, reqKeys: List[Tuple[str, int]]):\n        return {key for key in reqKeys if not self.requests.is_finalised(key)}", "response": "Check if there are any requests which are not finalised i. e. for\n        which there are not enough PROPAGATEs\n        which are not enough PROPAGATEs\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply the pre - prepared requests of the state and state store to the ledger and state store.", "response": "def _apply_pre_prepare(self, pre_prepare: PrePrepare):\n        \"\"\"\n        Applies (but not commits) requests of the PrePrepare\n        to the ledger and state\n        \"\"\"\n\n        reqs = []\n        idx = 0\n        rejects = []\n        invalid_indices = []\n        suspicious = False\n\n        # 1. apply each request\n        for req_key in pre_prepare.reqIdr:\n            req = self.requests[req_key].finalised\n            try:\n                self.processReqDuringBatch(req,\n                                           pre_prepare.ppTime)\n            except (InvalidClientMessageException, UnknownIdentifier, SuspiciousPrePrepare) as ex:\n                self.logger.warning('{} encountered exception {} while processing {}, '\n                                    'will reject'.format(self, ex, req))\n                rejects.append((req.key, Reject(req.identifier, req.reqId, ex)))\n                invalid_indices.append(idx)\n                if isinstance(ex, SuspiciousPrePrepare):\n                    suspicious = True\n            finally:\n                reqs.append(req)\n            idx += 1\n\n        # 2. call callback for the applied batch\n        if self.isMaster:\n            three_pc_batch = ThreePcBatch.from_pre_prepare(pre_prepare,\n                                                           state_root=self.stateRootHash(pre_prepare.ledgerId,\n                                                                                         to_str=False),\n                                                           txn_root=self.txnRootHash(pre_prepare.ledgerId,\n                                                                                     to_str=False),\n                                                           primaries=[],\n                                                           valid_digests=self.get_valid_req_ids_from_all_requests(\n                                                               reqs, invalid_indices))\n            self.node.onBatchCreated(three_pc_batch)\n\n        return reqs, invalid_indices, rejects, suspicious"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning whether this replica can process a PRE - PREPARE.", "response": "def _can_process_pre_prepare(self, pre_prepare: PrePrepare, sender: str) -> Optional[int]:\n        \"\"\"\n        Decide whether this replica is eligible to process a PRE-PREPARE.\n\n        :param pre_prepare: a PRE-PREPARE msg to process\n        :param sender: the name of the node that sent the PRE-PREPARE msg\n        \"\"\"\n        # TODO: Check whether it is rejecting PRE-PREPARE from previous view\n\n        # PRE-PREPARE should not be sent from non primary\n        if not self.isMsgFromPrimary(pre_prepare, sender):\n            return PP_CHECK_NOT_FROM_PRIMARY\n\n        # Already has a PRE-PREPARE with same 3 phase key\n        if (pre_prepare.viewNo, pre_prepare.ppSeqNo) in self.prePrepares:\n            return PP_CHECK_DUPLICATE\n\n        if not self.is_pre_prepare_time_acceptable(pre_prepare, sender):\n            return PP_CHECK_WRONG_TIME\n\n        if compare_3PC_keys((pre_prepare.viewNo, pre_prepare.ppSeqNo),\n                            self.__last_pp_3pc) > 0:\n            return PP_CHECK_OLD  # ignore old pre-prepare\n\n        if self.nonFinalisedReqs(pre_prepare.reqIdr):\n            return PP_CHECK_REQUEST_NOT_FINALIZED\n\n        if not self.__is_next_pre_prepare(pre_prepare.viewNo,\n                                          pre_prepare.ppSeqNo):\n            return PP_CHECK_NOT_NEXT\n\n        if f.POOL_STATE_ROOT_HASH.nm in pre_prepare and \\\n                pre_prepare.poolStateRootHash != self.stateRootHash(POOL_LEDGER_ID):\n            return PP_CHECK_INCORRECT_POOL_STATE_ROOT\n\n        # BLS multi-sig:\n        status = self._bls_bft_replica.validate_pre_prepare(pre_prepare,\n                                                            sender)\n        if status is not None:\n            return status\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the specified PRE - PREPARE to this replica s list of received PRE - PREPAREs and try sending PREPAREs.", "response": "def addToPrePrepares(self, pp: PrePrepare) -> None:\n        \"\"\"\n        Add the specified PRE-PREPARE to this replica's list of received\n        PRE-PREPAREs and try sending PREPARE\n\n        :param pp: the PRE-PREPARE to add to the list\n        \"\"\"\n        key = (pp.viewNo, pp.ppSeqNo)\n        self.prePrepares[key] = pp\n        self.lastPrePrepareSeqNo = pp.ppSeqNo\n        self.last_accepted_pre_prepare_time = pp.ppTime\n        self.dequeue_prepares(*key)\n        self.dequeue_commits(*key)\n        self.stats.inc(TPCStat.PrePrepareRcvd)\n        self.tryPrepare(pp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns whether the PREPARE step can proceed to the PREPARE step.", "response": "def canPrepare(self, ppReq) -> (bool, str):\n        \"\"\"\n        Return whether the batch of requests in the PRE-PREPARE can\n        proceed to the PREPARE step.\n\n        :param ppReq: any object with identifier and requestId attributes\n        \"\"\"\n        if self.has_sent_prepare(ppReq):\n            return False, 'has already sent PREPARE for {}'.format(ppReq)\n        return True, ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validatePrepare(self, prepare: Prepare, sender: str) -> bool:\n        key = (prepare.viewNo, prepare.ppSeqNo)\n        primaryStatus = self.isPrimaryForMsg(prepare)\n\n        ppReq = self.getPrePrepare(*key)\n\n        # If a non primary replica and receiving a PREPARE request before a\n        # PRE-PREPARE request, then proceed\n\n        # PREPARE should not be sent from primary\n        if self.isMsgFromPrimary(prepare, sender):\n            raise SuspiciousNode(sender, Suspicions.PR_FRM_PRIMARY, prepare)\n\n        # If non primary replica\n        if primaryStatus is False:\n            if self.prepares.hasPrepareFrom(prepare, sender):\n                raise SuspiciousNode(\n                    sender, Suspicions.DUPLICATE_PR_SENT, prepare)\n            # If PRE-PREPARE not received for the PREPARE, might be slow\n            # network\n            if not ppReq:\n                self.enqueue_prepare(prepare, sender)\n                self._setup_last_ordered_for_non_master()\n                return False\n        # If primary replica\n        if primaryStatus is True:\n            if self.prepares.hasPrepareFrom(prepare, sender):\n                raise SuspiciousNode(\n                    sender, Suspicions.DUPLICATE_PR_SENT, prepare)\n            # If PRE-PREPARE was not sent for this PREPARE, certainly\n            # malicious behavior\n            elif not ppReq:\n                raise SuspiciousNode(\n                    sender, Suspicions.UNKNOWN_PR_SENT, prepare)\n\n        if primaryStatus is None and not ppReq:\n            self.enqueue_prepare(prepare, sender)\n            self._setup_last_ordered_for_non_master()\n            return False\n\n        if prepare.digest != ppReq.digest:\n            raise SuspiciousNode(sender, Suspicions.PR_DIGEST_WRONG, prepare)\n        elif prepare.stateRootHash != ppReq.stateRootHash:\n            raise SuspiciousNode(sender, Suspicions.PR_STATE_WRONG,\n                                 prepare)\n        elif prepare.txnRootHash != ppReq.txnRootHash:\n            raise SuspiciousNode(sender, Suspicions.PR_TXN_WRONG,\n                                 prepare)\n        elif prepare.auditTxnRootHash != ppReq.auditTxnRootHash:\n            raise SuspiciousNode(sender, Suspicions.PR_AUDIT_TXN_ROOT_HASH_WRONG,\n                                 prepare)\n\n        try:\n            self.execute_hook(ReplicaHooks.VALIDATE_PR, prepare, ppReq)\n        except Exception as ex:\n            self.logger.warning('{} encountered exception in replica '\n                                'hook {} : {}'.\n                                format(self, ReplicaHooks.VALIDATE_PR, ex))\n            raise SuspiciousNode(sender, Suspicions.PR_PLUGIN_EXCEPTION,\n                                 prepare)\n\n        # BLS multi-sig:\n        self._bls_bft_replica.validate_prepare(prepare, sender)\n\n        return True", "response": "Validate the PREPARE request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addToPrepares(self, prepare: Prepare, sender: str):\n        # BLS multi-sig:\n        self._bls_bft_replica.process_prepare(prepare, sender)\n\n        self.prepares.addVote(prepare, sender)\n        self.dequeue_commits(prepare.viewNo, prepare.ppSeqNo)\n        self.tryCommit(prepare)", "response": "Add the specified PREPARE to this replica s list of received\n        PREPAREs and try sending COMMITs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning whether the PREPARE can proceed to the Commit step.", "response": "def canCommit(self, prepare: Prepare) -> (bool, str):\n        \"\"\"\n        Return whether the specified PREPARE can proceed to the Commit\n        step.\n\n        Decision criteria:\n\n        - If this replica has got just n-f-1 PREPARE requests then commit request.\n        - If less than n-f-1 PREPARE requests then probably there's no consensus on\n            the request; don't commit\n        - If more than n-f-1 then already sent COMMIT; don't commit\n\n        :param prepare: the PREPARE\n        \"\"\"\n        quorum = self.quorums.prepare.value\n        if not self.prepares.hasQuorum(prepare, quorum):\n            return False, 'does not have prepare quorum for {}'.format(prepare)\n        if self.hasCommitted(prepare):\n            return False, 'has already sent COMMIT for {}'.format(prepare)\n        return True, ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validateCommit(self, commit: Commit, sender: str) -> bool:\n        key = (commit.viewNo, commit.ppSeqNo)\n        if not self.has_prepared(key):\n            self.enqueue_commit(commit, sender)\n            return False\n\n        if self.commits.hasCommitFrom(commit, sender):\n            raise SuspiciousNode(sender, Suspicions.DUPLICATE_CM_SENT, commit)\n\n        # BLS multi-sig:\n        pre_prepare = self.getPrePrepare(commit.viewNo, commit.ppSeqNo)\n        why_not = self._bls_bft_replica.validate_commit(commit, sender, pre_prepare)\n\n        if why_not == BlsBftReplica.CM_BLS_SIG_WRONG:\n            self.logger.warning(\"{} discard Commit message from \"\n                                \"{}:{}\".format(self, sender, commit))\n            raise SuspiciousNode(sender,\n                                 Suspicions.CM_BLS_SIG_WRONG,\n                                 commit)\n        elif why_not is not None:\n            self.logger.warning(\"Unknown error code returned for bls commit \"\n                                \"validation {}\".format(why_not))\n\n        return True", "response": "Validate the COMMIT message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the specified COMMIT to this replica s list of received commits.", "response": "def addToCommits(self, commit: Commit, sender: str):\n        \"\"\"\n        Add the specified COMMIT to this replica's list of received\n        commit requests.\n\n        :param commit: the COMMIT to add to the list\n        :param sender: the name of the node that sent the COMMIT\n        \"\"\"\n        # BLS multi-sig:\n        self._bls_bft_replica.process_commit(commit, sender)\n\n        self.commits.addVote(commit, sender)\n        self.tryOrder(commit)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef canOrder(self, commit: Commit) -> Tuple[bool, Optional[str]]:\n        quorum = self.quorums.commit.value\n        if not self.commits.hasQuorum(commit, quorum):\n            return False, \"no quorum ({}): {} commits where f is {}\". \\\n                format(quorum, commit, self.f)\n\n        key = (commit.viewNo, commit.ppSeqNo)\n        if self.has_already_ordered(*key):\n            return False, \"already ordered\"\n\n        if commit.ppSeqNo > 1 and not self.all_prev_ordered(commit):\n            viewNo, ppSeqNo = commit.viewNo, commit.ppSeqNo\n            if viewNo not in self.stashed_out_of_order_commits:\n                self.stashed_out_of_order_commits[viewNo] = {}\n            self.stashed_out_of_order_commits[viewNo][ppSeqNo] = commit\n            self.startRepeating(self.process_stashed_out_of_order_commits,\n                                self.config.PROCESS_STASHED_OUT_OF_ORDER_COMMITS_INTERVAL)\n            return False, \"stashing {} since out of order\". \\\n                format(commit)\n\n        return True, None", "response": "Return whether the specified commitRequest can be returned to the node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_prev_ordered(self, commit: Commit):\n        # TODO: This method does a lot of work, choose correct data\n        # structures to make it efficient.\n\n        viewNo, ppSeqNo = commit.viewNo, commit.ppSeqNo\n\n        if self.last_ordered_3pc == (viewNo, ppSeqNo - 1):\n            # Last ordered was in same view as this COMMIT\n            return True\n\n        # if some PREPAREs/COMMITs were completely missed in the same view\n        toCheck = set()\n        toCheck.update(set(self.sentPrePrepares.keys()))\n        toCheck.update(set(self.prePrepares.keys()))\n        toCheck.update(set(self.prepares.keys()))\n        toCheck.update(set(self.commits.keys()))\n        for (v, p) in toCheck:\n            if v < viewNo and (v, p) not in self.ordered:\n                # Have commits from previous view that are unordered.\n                return False\n            if v == viewNo and p < ppSeqNo and (v, p) not in self.ordered:\n                # If unordered commits are found with lower ppSeqNo then this\n                # cannot be ordered.\n                return False\n\n        return True", "response": "Return True if all previous COMMITs have been ordered."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a checkpoint message.", "response": "def process_checkpoint(self, msg: Checkpoint, sender: str) -> bool:\n        \"\"\"\n        Process checkpoint messages\n\n        :return: whether processed (True) or stashed (False)\n        \"\"\"\n        self.logger.info('{} processing checkpoint {} from {}'.format(self, msg, sender))\n        result, reason = self.validator.validate_checkpoint_msg(msg)\n        if result == DISCARD:\n            self.discard(msg, \"{} discard message {} from {} \"\n                              \"with the reason: {}\".format(self, msg, sender, reason),\n                         self.logger.trace)\n        elif result == PROCESS:\n            self._do_process_checkpoint(msg, sender)\n        else:\n            self.logger.debug(\"{} stashing checkpoint message {} with \"\n                              \"the reason: {}\".format(self, msg, reason))\n            self.stasher.stash((msg, sender), result)\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the given checkpoint is stable and if so returns True otherwise.", "response": "def is_pp_seq_no_stable(self, msg: Checkpoint):\n        \"\"\"\n        :param ppSeqNo:\n        :return: True if ppSeqNo is less than or equal to last stable\n        checkpoint, false otherwise\n        \"\"\"\n        pp_seq_no = msg.seqNoEnd\n        ck = self.firstCheckPoint\n        if ck:\n            _, ckState = ck\n            return ckState.isStable and ckState.seqNo >= pp_seq_no\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef can_pp_seq_no_be_in_view(self, view_no, pp_seq_no):\n        if view_no > self.viewNo:\n            raise PlenumValueError(\n                'view_no', view_no,\n                \"<= current view_no {}\".format(self.viewNo),\n                prefix=self\n            )\n\n        return view_no == self.viewNo or (\n            view_no < self.viewNo and self.last_prepared_before_view_change and compare_3PC_keys(\n                (view_no, pp_seq_no), self.last_prepared_before_view_change) >= 0)", "response": "Checks if the pp_seq_no can be in view."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _request_pre_prepare(self, three_pc_key: Tuple[int, int],\n                             stash_data: Optional[Tuple[str, str, str]] = None) -> bool:\n        \"\"\"\n        Request preprepare\n        \"\"\"\n        recipients = self.primaryName\n        return self._request_three_phase_msg(three_pc_key,\n                                             self.requested_pre_prepares,\n                                             PREPREPARE,\n                                             recipients,\n                                             stash_data)", "response": "Request pre - prepare message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _request_commit(self, three_pc_key: Tuple[int, int],\n                        recipients: List[str] = None) -> bool:\n        \"\"\"\n        Request commit\n        \"\"\"\n        return self._request_three_phase_msg(three_pc_key, self.requested_commits, COMMIT, recipients)", "response": "Request a COMMIT message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _request_pre_prepare_for_prepare(self, three_pc_key) -> bool:\n\n        if three_pc_key in self.prePreparesPendingPrevPP:\n            self.logger.debug('{} not requesting a PRE-PREPARE since already found '\n                              'stashed for {}'.format(self, three_pc_key))\n            return False\n\n        if len(\n                self.preparesWaitingForPrePrepare[three_pc_key]) < self.quorums.prepare.value:\n            self.logger.debug(\n                '{} not requesting a PRE-PREPARE because does not have'\n                ' sufficient PREPAREs for {}'.format(\n                    self, three_pc_key))\n            return False\n\n        digest, state_root, txn_root, _ = \\\n            self.get_acceptable_stashed_prepare_state(three_pc_key)\n\n        # Choose a better data structure for `prePreparesPendingFinReqs`\n        pre_prepares = [pp for pp, _, _ in self.prePreparesPendingFinReqs\n                        if (pp.viewNo, pp.ppSeqNo) == three_pc_key]\n        if pre_prepares:\n            if [pp for pp in pre_prepares if (\n                pp.digest, pp.stateRootHash, pp.txnRootHash) == (\n                    digest, state_root, txn_root)]:\n                self.logger.debug('{} not requesting a PRE-PREPARE since already '\n                                  'found stashed for {}'.format(self, three_pc_key))\n                return False\n\n        self._request_pre_prepare(three_pc_key,\n                                  stash_data=(digest, state_root, txn_root))\n        return True", "response": "Request PRE - PREPARE for the given three - PC key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_pre_prepare_time_correct(self, pp: PrePrepare, sender: str) -> bool:\n        tpcKey = (pp.viewNo, pp.ppSeqNo)\n\n        if (self.last_accepted_pre_prepare_time and\n                pp.ppTime < self.last_accepted_pre_prepare_time):\n            return False\n        elif ((tpcKey not in self.pre_prepare_tss) or\n                ((pp, sender) not in self.pre_prepare_tss[tpcKey])):\n            return False\n        else:\n            return (\n                abs(pp.ppTime - self.pre_prepare_tss[tpcKey][pp, sender]) <=\n                self.config.ACCEPTABLE_DEVIATION_PREPREPARE_SECS\n            )", "response": "Check if this PRE - PREPARE is older than the last PRE - PREPARE and in a sufficient range of UTC time."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_pre_prepare_time_acceptable(self, pp: PrePrepare, sender: str) -> bool:\n        key = (pp.viewNo, pp.ppSeqNo)\n        if key in self.requested_pre_prepares:\n            # Special case for requested PrePrepares\n            return True\n        correct = self.is_pre_prepare_time_correct(pp, sender)\n        if not correct:\n            if key in self.pre_prepares_stashed_for_incorrect_time and \\\n                    self.pre_prepares_stashed_for_incorrect_time[key][-1]:\n                self.logger.debug('{} marking time as correct for {}'.format(self, pp))\n                correct = True\n            else:\n                self.logger.warning('{} found {} to have incorrect time.'.format(self, pp))\n        return correct", "response": "Returns True if the time in PRE - PREPARE is acceptable or False depending on the whether the time in PRE - PREPARE is acceptable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, msg, stat=None) -> None:\n        self.logger.trace(\"{} sending {}\".format(self, msg.__class__.__name__),\n                          extra={\"cli\": True, \"tags\": ['sending']})\n        self.logger.trace(\"{} sending {}\".format(self, msg))\n        if stat:\n            self.stats.inc(stat)\n        self.outBox.append(msg)", "response": "Send a message to the node on which this replica resides."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef revert_unordered_batches(self):\n        i = 0\n        for key in sorted(self.batches.keys(), reverse=True):\n            if compare_3PC_keys(self.last_ordered_3pc, key) > 0:\n                ledger_id, discarded, _, prevStateRoot, len_reqIdr = self.batches.pop(key)\n                discarded = invalid_index_serializer.deserialize(discarded)\n                self.logger.debug('{} reverting 3PC key {}'.format(self, key))\n                self.revert(ledger_id, prevStateRoot, len_reqIdr - len(discarded))\n                i += 1\n            else:\n                break\n        return i", "response": "Revert unordered batches to ledger and state made by any requests\n        that have not been ordered."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves any 3 phase messages till the last ordered key and also remove any corresponding request keys that are still in the order.", "response": "def _remove_till_caught_up_3pc(self, last_caught_up_3PC):\n        \"\"\"\n        Remove any 3 phase messages till the last ordered key and also remove\n        any corresponding request keys\n        \"\"\"\n        outdated_pre_prepares = {}\n        for key, pp in self.prePrepares.items():\n            if compare_3PC_keys(key, last_caught_up_3PC) >= 0:\n                outdated_pre_prepares[key] = pp\n        for key, pp in self.sentPrePrepares.items():\n            if compare_3PC_keys(key, last_caught_up_3PC) >= 0:\n                outdated_pre_prepares[key] = pp\n\n        self.logger.trace('{} going to remove messages for {} 3PC keys'.format(\n            self, len(outdated_pre_prepares)))\n\n        for key, pp in outdated_pre_prepares.items():\n            self.batches.pop(key, None)\n            self.sentPrePrepares.pop(key, None)\n            self.prePrepares.pop(key, None)\n            self.prepares.pop(key, None)\n            self.commits.pop(key, None)\n            self._discard_ordered_req_keys(pp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove any Ordered messages from the queue.", "response": "def _remove_ordered_from_queue(self, last_caught_up_3PC=None):\n        \"\"\"\n        Remove any Ordered that the replica might be sending to node which is\n        less than or equal to `last_caught_up_3PC` if `last_caught_up_3PC` is\n        passed else remove all ordered, needed in catchup\n        \"\"\"\n        to_remove = []\n        for i, msg in enumerate(self.outBox):\n            if isinstance(msg, Ordered) and \\\n                    (not last_caught_up_3PC or\n                     compare_3PC_keys((msg.viewNo, msg.ppSeqNo), last_caught_up_3PC) >= 0):\n                to_remove.append(i)\n\n        self.logger.trace('{} going to remove {} Ordered messages from outbox'.format(self, len(to_remove)))\n\n        # Removing Ordered from queue but returning `Ordered` in order that\n        # they should be processed.\n        removed = []\n        for i in reversed(to_remove):\n            removed.insert(0, self.outBox[i])\n            del self.outBox[i]\n        return removed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _remove_stashed_checkpoints(self, till_3pc_key=None):\n        if till_3pc_key is None:\n            self.stashedRecvdCheckpoints.clear()\n            self.logger.info('{} removing all stashed checkpoints'.format(self))\n            return\n\n        for view_no in list(self.stashedRecvdCheckpoints.keys()):\n\n            if view_no < till_3pc_key[0]:\n                self.logger.info('{} removing stashed checkpoints for view {}'.format(self, view_no))\n                del self.stashedRecvdCheckpoints[view_no]\n\n            elif view_no == till_3pc_key[0]:\n                for (s, e) in list(self.stashedRecvdCheckpoints[view_no].keys()):\n                    if e <= till_3pc_key[1]:\n                        self.logger.info('{} removing stashed checkpoints: '\n                                         'viewNo={}, seqNoStart={}, seqNoEnd={}'.\n                                         format(self, view_no, s, e))\n                        del self.stashedRecvdCheckpoints[view_no][(s, e)]\n                if len(self.stashedRecvdCheckpoints[view_no]) == 0:\n                    del self.stashedRecvdCheckpoints[view_no]", "response": "Remove stashed received checkpoints up to till_3pc_key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether the given port is available for the given adapter.", "response": "def checkPortAvailable(ha):\n    \"\"\"Checks whether the given port is available\"\"\"\n    # Not sure why OS would allow binding to one type and not other.\n    # Checking for port available for TCP and UDP.\n    sockTypes = (socket.SOCK_DGRAM, socket.SOCK_STREAM)\n    for typ in sockTypes:\n        sock = socket.socket(socket.AF_INET, typ)\n        try:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            sock.bind(ha)\n            if typ == socket.SOCK_STREAM:\n                l_onoff = 1\n                l_linger = 0\n                sock.setsockopt(socket.SOL_SOCKET, socket.SO_LINGER,\n                                struct.pack('ii', l_onoff, l_linger))\n        except OSError as exc:\n            if exc.errno in [\n                errno.EADDRINUSE, errno.EADDRNOTAVAIL,\n                WS_SOCKET_BIND_ERROR_ALREADY_IN_USE,\n                WS_SOCKET_BIND_ERROR_NOT_AVAILABLE\n            ]:\n                raise PortNotAvailable(ha)\n            else:\n                raise exc\n        finally:\n            sock.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef distributedConnectionMap(names: List[str]) -> OrderedDict:\n    names.sort()\n    combos = list(itertools.combinations(names, 2))\n    maxPer = math.ceil(len(list(combos)) / len(names))\n    # maxconns = math.ceil(len(names) / 2)\n    connmap = OrderedDict((n, []) for n in names)\n    for a, b in combos:\n        if len(connmap[a]) < maxPer:\n            connmap[a].append(b)\n        else:\n            connmap[b].append(a)\n    return connmap", "response": "Create a map where every node is connected every other node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef band_width(high_data, low_data, period):\n    catch_errors.check_for_input_len_diff(high_data, low_data)\n    diff = np.array(high_data) - np.array(low_data)\n    bw = sma(diff, period)\n    return bw", "response": "A wrapper around the bandwidth function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the center band formula.", "response": "def center_band(close_data, high_data, low_data, period):\n    \"\"\"\n    Center Band.\n\n    Formula:\n    CB = SMA(TP)\n    \"\"\"\n    tp = typical_price(close_data, high_data, low_data)\n    cb = sma(tp, period)\n    return cb"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef upper_band(close_data, high_data, low_data, period):\n    cb = center_band(close_data, high_data, low_data, period)\n    bw = band_width(high_data, low_data, period)\n    ub = cb + bw\n    return ub", "response": "This function calculates the upper band of the next close."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lower_band(close_data, high_data, low_data, period):\n    cb = center_band(close_data, high_data, low_data, period)\n    bw = band_width(high_data, low_data, period)\n    lb = cb - bw\n    return lb", "response": "Lower Band.\n\n    Formula:\n    LB = CB - BW"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef simple_moving_average(data, period):\n    catch_errors.check_for_period_error(data, period)\n    # Mean of Empty Slice RuntimeWarning doesn't affect output so it is\n    # supressed\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        sma = [np.mean(data[idx-(period-1):idx+1]) for idx in range(0, len(data))]\n    sma = fill_for_noncomputable_vals(data, sma)\n    return sma", "response": "Simple Moving Average.\n\n    Formula:\n    SUM(data / N)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naveraging True Range Percent.", "response": "def average_true_range_percent(close_data, period):\n    \"\"\"\n    Average True Range Percent.\n\n    Formula:\n    ATRP = (ATR / CLOSE) * 100\n    \"\"\"\n    catch_errors.check_for_period_error(close_data, period)\n    atrp = (atr(close_data, period) / np.array(close_data)) * 100\n    return atrp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_balance_volume(close_data, volume):\n    catch_errors.check_for_input_len_diff(close_data, volume)\n    obv = np.zeros(len(volume))\n    obv[0] = 1\n    for idx in range(1, len(obv)):\n        if close_data[idx] > close_data[idx-1]:\n            obv[idx] = obv[idx-1] + volume[idx]\n        elif close_data[idx] < close_data[idx-1]:\n            obv[idx] = obv[idx-1] - volume[idx]\n        elif close_data[idx] == close_data[idx-1]:\n            obv[idx] = obv[idx-1]\n    return obv", "response": "On Balance Volume.\n\n    Formula:\n    start = 1\n    if CLOSEt > CLOSEt-1\n        obv = obvt-1 + volumet\n    elif CLOSEt < CLOSEt-1\n        obv = obvt-1 - volumet\n    elif CLOSEt == CLOSTt-1\n        obv = obvt-1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrating of Change. Formula: (Close - Close n periods ago) / (Close n periods ago) * 100", "response": "def rate_of_change(data, period):\n    \"\"\"\n    Rate of Change.\n\n    Formula:\n    (Close - Close n periods ago) / (Close n periods ago) * 100\n    \"\"\"\n    catch_errors.check_for_period_error(data, period)\n\n    rocs = [((data[idx] - data[idx - (period - 1)]) /\n         data[idx - (period - 1)]) * 100 for idx in range(period - 1, len(data))]\n    rocs = fill_for_noncomputable_vals(data, rocs)\n    return rocs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef average_true_range(close_data, period):\n    tr = true_range(close_data, period)\n    atr = smoothed_moving_average(tr, period)\n    atr[0:period-1] = tr[0:period-1]\n    return atr", "response": "Average True Range.\n\n    Formula:\n    ATRt = ATRt-1 * (n - 1) + TRt / n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef accumulation_distribution(close_data, high_data, low_data, volume):\n    catch_errors.check_for_input_len_diff(\n        close_data, high_data, low_data, volume\n        )\n\n    ad = np.zeros(len(close_data))\n    for idx in range(1, len(close_data)):\n        ad[idx] = (\n            (((close_data[idx] - low_data[idx]) -\n                (high_data[idx] - close_data[idx])) /\n                (high_data[idx] - low_data[idx]) *\n                volume[idx]) +\n            ad[idx-1]\n            )\n    return ad", "response": "Accumulation/Distribution.\n\n    Formula:\n    A/D = (Ct - Lt) - (Ht - Ct) / (Ht - Lt) * Vt + A/Dt-1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef relative_strength_index(data, period):\n    catch_errors.check_for_period_error(data, period)\n\n    period = int(period)\n    changes = [data_tup[1] - data_tup[0] for data_tup in zip(data[::1], data[1::1])]\n\n    filtered_gain = [val < 0 for val in changes]\n    gains = [0 if filtered_gain[idx] is True else changes[idx] for idx in range(0, len(filtered_gain))]\n\n    filtered_loss = [val > 0 for val in changes]\n    losses = [0 if filtered_loss[idx] is True else abs(changes[idx]) for idx in range(0, len(filtered_loss))]\n\n    avg_gain = np.mean(gains[:period])\n    avg_loss = np.mean(losses[:period])\n\n    rsi = []\n    if avg_loss == 0:\n        rsi.append(100)\n    else:\n        rs = avg_gain / avg_loss\n        rsi.append(100 - (100 / (1 + rs)))\n\n    for idx in range(1, len(data) - period):\n        avg_gain = ((avg_gain * (period - 1) +\n                    gains[idx + (period - 1)]) / period)\n        avg_loss = ((avg_loss * (period - 1) +\n                    losses[idx + (period - 1)]) / period)\n\n        if avg_loss == 0:\n            rsi.append(100)\n        else:\n            rs = avg_gain / avg_loss\n            rsi.append(100 - (100 / (1 + rs)))\n\n    rsi = fill_for_noncomputable_vals(data, rsi)\n\n    return rsi", "response": "Relative Strength Index.\n\n    Formula:\n    RSI = 100 - (100 / 1 + (prevGain/prevLoss))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef vertical_horizontal_filter(data, period):\n    catch_errors.check_for_period_error(data, period)\n\n    vhf = [abs(np.max(data[idx+1-period:idx+1]) -\n            np.min(data[idx+1-period:idx+1])) /\n        sum([abs(data[idx+1-period:idx+1][i] - data[idx+1-period:idx+1][i-1]) for i in range(0, len(data[idx+1-period:idx+1]))]) for idx in range(period - 1, len(data))]\n\n    vhf = fill_for_noncomputable_vals(data, vhf)\n    return vhf", "response": "Vertical Horizontal Filter.\n\n    Formula:\n    ABS(pHIGH - pLOW) / SUM(ABS(Pi - Pi-1))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef buying_pressure(close_data, low_data):\n    catch_errors.check_for_input_len_diff(close_data, low_data)\n    bp = [close_data[idx] - np.min([low_data[idx], close_data[idx-1]]) for idx in range(1, len(close_data))]\n    bp = fill_for_noncomputable_vals(close_data, bp)\n    return bp", "response": "Buying Pressure.\n\n    Formula:\n    BP = current close - min()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef aroon_down(data, period):\n    catch_errors.check_for_period_error(data, period)\n    period = int(period)\n\n    a_down = [((period -\n            list(reversed(data[idx+1-period:idx+1])).index(np.min(data[idx+1-period:idx+1]))) /\n            float(period)) * 100 for idx in range(period-1, len(data))]\n    a_down = fill_for_noncomputable_vals(data, a_down)\n    return a_down", "response": "Aroon Down.\n\n    Formula:\n    AROONDWN = (((PERIOD) - (PERIODS SINCE PERIOD LOW)) / (PERIOD)) * 100"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef momentum(data, period):\n    catch_errors.check_for_period_error(data, period)\n\n    momentum = [data[idx] - data[idx+1-period] for idx in range(period-1, len(data))]\n    momentum = fill_for_noncomputable_vals(data, momentum)\n    return momentum", "response": "Momentum.\n\n    Formula:\n    DATA[i] - DATA[i - period]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlowers Price Channel. Formula: lpc = EMA(t) * (1 - lower_percent / 100)", "response": "def lower_price_channel(data, period, lower_percent):\n    \"\"\"\n    Lower Price Channel.\n\n    Formula:\n    lpc = EMA(t) * (1 - lower_percent / 100)\n    \"\"\"\n    catch_errors.check_for_period_error(data, period)\n\n    emas = ema(data, period)\n    lower_channel = [val * (1-float(lower_percent)/100) for val in emas]\n    return lower_channel"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef moving_average_convergence_divergence(data, short_period, long_period):\n    catch_errors.check_for_period_error(data, short_period)\n    catch_errors.check_for_period_error(data, long_period)\n\n    macd = ema(data, short_period) - ema(data, long_period)\n    return macd", "response": "Moving Average Convergence Divergence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef money_flow_index(close_data, high_data, low_data, volume, period):\n    catch_errors.check_for_input_len_diff(\n        close_data, high_data, low_data, volume\n        )\n    catch_errors.check_for_period_error(close_data, period)\n\n    mf = money_flow(close_data, high_data, low_data, volume)\n    tp = typical_price(close_data, high_data, low_data)\n\n    flow = [tp[idx] > tp[idx-1] for idx in range(1, len(tp))]\n    pf = [mf[idx] if flow[idx] else 0 for idx in range(0, len(flow))]\n    nf = [mf[idx] if not flow[idx] else 0 for idx in range(0, len(flow))]\n\n    pmf = [sum(pf[idx+1-period:idx+1]) for idx in range(period-1, len(pf))]\n    nmf = [sum(nf[idx+1-period:idx+1]) for idx in range(period-1, len(nf))]\n\n    # Dividing by 0 is not an issue, it turns the value into NaN which we would\n    # want in that case\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n        money_ratio = np.array(pmf) / np.array(nmf)\n\n    mfi = 100 - (100 / (1 + money_ratio))\n\n    mfi = fill_for_noncomputable_vals(close_data, mfi)\n\n    return mfi", "response": "Money Flow Index.\n\n    Formula:\n    MFI = 100 - (100 / (1 + PMF / NMF))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef true_range(close_data, period):\n    catch_errors.check_for_period_error(close_data, period)\n\n    tr = [np.max([np.max(close_data[idx+1-period:idx+1]) -\n                np.min(close_data[idx+1-period:idx+1]),\n                abs(np.max(close_data[idx+1-period:idx+1]) -\n                close_data[idx-1]),\n                abs(np.min(close_data[idx+1-period:idx+1]) -\n                close_data[idx-1])]) for idx in range(period-1, len(close_data))]\n    tr = fill_for_noncomputable_vals(close_data, tr)\n    return tr", "response": "True Range.\n\n    Formula:\n    TRt = MAX(abs(Ht - Lt), abs(Ht - Ct-1), abs(Lt - Ct-1))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoubling Smoothed Stochastic. Formula: dss = 100 * EMA(Close - Lowest Low) / EMA(Highest High - Lowest Low)", "response": "def double_smoothed_stochastic(data, period):\n    \"\"\"\n    Double Smoothed Stochastic.\n\n    Formula:\n    dss = 100 *  EMA(Close - Lowest Low) / EMA(Highest High - Lowest Low)\n    \"\"\"\n    catch_errors.check_for_period_error(data, period)\n    lows = [data[idx] - np.min(data[idx+1-period:idx+1]) for idx in range(period-1, len(data))]\n    sm_lows = ema(ema(lows, period), period)\n    highs = [np.max(data[idx+1-period:idx+1]) - np.min(data[idx+1-period:idx+1]) for idx in range(period-1, len(data))]\n    sm_highs = ema(ema(highs, period), period)\n    dss = (sm_lows / sm_highs) * 100\n\n    dss = fill_for_noncomputable_vals(data, dss)\n    return dss"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvoluming Adjusted Moving Average.", "response": "def volume_adjusted_moving_average(close_data, volume, period):\n    \"\"\"\n    Volume Adjusted Moving Average.\n\n    Formula:\n    VAMA = SUM(CLOSE * VolumeRatio) / period\n    \"\"\"\n    catch_errors.check_for_input_len_diff(close_data, volume)\n    catch_errors.check_for_period_error(close_data, period)\n\n    avg_vol = np.mean(volume)\n    vol_incr = avg_vol * 0.67\n    vol_ratio = [val / vol_incr for val in volume]\n    close_vol = np.array(close_data) * vol_ratio\n    vama = [sum(close_vol[idx+1-period:idx+1]) / period for idx in range(period-1, len(close_data))]\n    vama = fill_for_noncomputable_vals(close_data, vama)\n    return vama"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef double_exponential_moving_average(data, period):\n    catch_errors.check_for_period_error(data, period)\n\n    dema = (2 * ema(data, period)) - ema(ema(data, period), period)\n    return dema", "response": "Double Exponential Moving Average."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nweighting Moving Average. Formula: (P1 + 2 P2 + 3 P3 + ... + n Pn) / K where K = (1+2+...+n) = n(n+1)/2 and Pn is the most recent price", "response": "def weighted_moving_average(data, period):\n    \"\"\"\n    Weighted Moving Average.\n\n    Formula:\n    (P1 + 2 P2 + 3 P3 + ... + n Pn) / K\n    where K = (1+2+...+n) = n(n+1)/2 and Pn is the most recent price\n    \"\"\"\n    catch_errors.check_for_period_error(data, period)\n    k = (period * (period + 1)) / 2.0\n\n    wmas = []\n    for idx in range(0, len(data)-period+1):\n        product = [data[idx + period_idx] * (period_idx + 1) for period_idx in range(0, period)]\n        wma = sum(product) / k\n        wmas.append(wma)\n    wmas = fill_for_noncomputable_vals(data, wmas)\n\n    return wmas"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef senkou_b(data, period=52):\n    sb = conversion_base_line_helper(data, period)\n    shift_by = np.repeat(np.nan, 26)\n    sb = np.append(shift_by, sb)\n    return sb", "response": "Senkou B (Leading Span B)\n\n    Formula:\n    (H + L) / 2  :: default period=52 :: shifted forward 26 bars"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef volatility(data, period):\n    volatility = sd(data, period) / sv(data, period)\n    return volatility", "response": "Computes the volatility of a given data period."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprices Oscillator. Formula: (short EMA - long EMA / long EMA) * 100", "response": "def price_oscillator(data, short_period, long_period):\n    \"\"\"\n    Price Oscillator.\n\n    Formula:\n    (short EMA - long EMA / long EMA) * 100\n    \"\"\"\n    catch_errors.check_for_period_error(data, short_period)\n    catch_errors.check_for_period_error(data, long_period)\n\n    ema_short = ema(data, short_period)\n    ema_long = ema(data, long_period)\n\n    po = ((ema_short - ema_long) / ema_long) * 100\n    return po"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_for_period_error(data, period):\n    period = int(period)\n    data_len = len(data)\n    if data_len < period:\n        raise Exception(\"Error: data_len < period\")", "response": "Check for Period Error."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking for Input Length Difference.", "response": "def check_for_input_len_diff(*args):\n    \"\"\"\n    Check for Input Length Difference.\n\n    This method checks if multiple data sets that are inputted are all the same\n    size. If they are not the same length an error is raised with a custom\n    message that informs the developer that the data set's lengths are not the\n    same.\n    \"\"\"\n    arrays_len = [len(arr) for arr in args]\n    if not all(a == arrays_len[0] for a in arrays_len):\n        err_msg = (\"Error: mismatched data lengths, check to ensure that all \"\n                   \"input data is the same length and valid\")\n        raise Exception(err_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stochrsi(data, period):\n    rsi = relative_strength_index(data, period)[period:]\n    stochrsi = [100 * ((rsi[idx] - np.min(rsi[idx+1-period:idx+1])) / (np.max(rsi[idx+1-period:idx+1]) - np.min(rsi[idx+1-period:idx+1]))) for idx in range(period-1, len(rsi))]\n    stochrsi = fill_for_noncomputable_vals(data, stochrsi)\n    return stochrsi", "response": "StochRSI formula for the given period of the data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upper_bollinger_band(data, period, std_mult=2.0):\n    catch_errors.check_for_period_error(data, period)\n\n    period = int(period)\n    simple_ma = sma(data, period)[period-1:]\n\n    upper_bb = []\n    for idx in range(len(data) - period + 1):\n        std_dev = np.std(data[idx:idx + period])\n        upper_bb.append(simple_ma[idx] + std_dev * std_mult)\n    upper_bb = fill_for_noncomputable_vals(data, upper_bb)\n\n    return np.array(upper_bb)", "response": "Upper Bollinger Band.\n\n    Formula:\n    u_bb = SMA(t) + STD(SMA(t-n:t)) * std_mult"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmiddling Bollinger Band. Formula: m_bb = sma()", "response": "def middle_bollinger_band(data, period, std=2.0):\n    \"\"\"\n    Middle Bollinger Band.\n\n    Formula:\n    m_bb = sma()\n    \"\"\"\n    catch_errors.check_for_period_error(data, period)\n\n    period = int(period)\n    mid_bb = sma(data, period)\n\n    return mid_bb"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlower Bollinger Band. Formula: u_bb = SMA(t) - STD(SMA(t-n:t)) * std_mult", "response": "def lower_bollinger_band(data, period, std=2.0):\n    \"\"\"\n    Lower Bollinger Band.\n\n    Formula:\n    u_bb = SMA(t) - STD(SMA(t-n:t)) * std_mult\n    \"\"\"\n    catch_errors.check_for_period_error(data, period)\n\n    period = int(period)\n    simple_ma = sma(data, period)[period-1:]\n\n    lower_bb = []\n    for idx in range(len(data) - period + 1):\n        std_dev = np.std(data[idx:idx + period])\n        lower_bb.append(simple_ma[idx] - std_dev * std)\n    lower_bb = fill_for_noncomputable_vals(data, lower_bb)\n\n    return np.array(lower_bb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bb_range(data, period, std=2.0):\n    catch_errors.check_for_period_error(data, period)\n\n    period = int(period)\n    bb_range = (upper_bollinger_band(data, period, std) -\n                lower_bollinger_band(data, period, std)\n                )\n    return bb_range", "response": "Range.\n\n    Formula:\n    bb_range = u_bb - l_bb"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef percent_b(data, period, upper_bb_std=2.0, lower_bb_std=2.0):\n    lb = lower_bollinger_band(data, period, lower_bb_std)\n    ub = upper_bollinger_band(data, period, upper_bb_std)\n    percent_b = ((np.array(data) - lb) / (ub - lb)) * 100\n    return percent_b", "response": "%B.\n\n    Formula:\n    %B = ((data - lb) / (ub - lb)) * 100"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlower Band. Formula: lb = cb * (1 - env_percentage)", "response": "def lower_band(data, period, env_percentage):\n    \"\"\"\n    Lower Band.\n\n    Formula:\n    lb = cb * (1 - env_percentage)\n    \"\"\"\n    cb = center_band(data, period)\n    lb = [val * (1 - float(env_percentage)) for val in cb]\n    return lb"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef smoothed_moving_average(data, period):\n    catch_errors.check_for_period_error(data, period)\n    series = pd.Series(data)\n    return series.ewm(alpha = 1.0/period).mean().values.flatten()", "response": "Smoothed Moving Average.\n\n    Formula:\n    smma = avg(data(n)) - avg(data(n)/n) + data(t)/n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef percent_k(data, period):\n    catch_errors.check_for_period_error(data, period)\n    percent_k = [((data[idx] - np.min(data[idx+1-period:idx+1])) /\n         (np.max(data[idx+1-period:idx+1]) -\n          np.min(data[idx+1-period:idx+1]))) for idx in range(period-1, len(data))]\n    percent_k = fill_for_noncomputable_vals(data, percent_k)\n\n    return percent_k", "response": "%K.\n\n    Formula:\n    %k = data(t) - low(n) / (high(n) - low(n))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef percent_d(data, period):\n    p_k = percent_k(data, period)\n    percent_d = sma(p_k, 3)\n    return percent_d", "response": "Percent of divergence for a single chunk."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hull_moving_average(data, period):\n    catch_errors.check_for_period_error(data, period)\n    hma = wma(\n        2 * wma(data, int(period/2)) - wma(data, period), int(np.sqrt(period))\n        )\n    return hma", "response": "Hull Moving Average.\n\n    Formula:\n    HMA = WMA(2*WMA(n/2) - WMA(n)), sqrt(n)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate_up_moves(high_data):\n    up_moves = [high_data[idx] - high_data[idx-1] for idx in range(1, len(high_data))]\n    return [np.nan] + up_moves", "response": "Calculate the up moves of the high data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the down moves of the given low data.", "response": "def calculate_down_moves(low_data):\n    \"\"\"\n    Down Move.\n\n    Formula:\n    DWNMOVE = Lt-1 - Lt\n    \"\"\"\n    down_moves = [low_data[idx-1] - low_data[idx] for idx in range(1, len(low_data))]\n    return [np.nan] + down_moves"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef negative_directional_movement(high_data, low_data):\n    catch_errors.check_for_input_len_diff(high_data, low_data)\n    up_moves = calculate_up_moves(high_data)\n    down_moves = calculate_down_moves(low_data)\n\n    ndm = []\n    for idx in range(0, len(down_moves)):\n        if down_moves[idx] > up_moves[idx] and down_moves[idx] > 0:\n            ndm.append(down_moves[idx])\n        else:\n            ndm.append(0)\n\n    return ndm", "response": "Negative Directional Movement (-DM).\n\n\n    -DM: if DWNMOVE > UPMOVE and DWNMOVE > 0 then -DM = DWNMOVE else -Dm = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef positive_directional_index(close_data, high_data, low_data, period):\n    catch_errors.check_for_input_len_diff(close_data, high_data, low_data)\n    pdi = (100 *\n           smma(positive_directional_movement(high_data, low_data), period) /\n           atr(close_data, period)\n           )\n    return pdi", "response": "Positive Directional Index (+DI).\n\n    Formula:\n    +DI = 100 * SMMA(+DM) / ATR"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef negative_directional_index(close_data, high_data, low_data, period):\n    catch_errors.check_for_input_len_diff(close_data, high_data, low_data)\n    ndi = (100 *\n           smma(negative_directional_movement(high_data, low_data), period) /\n           atr(close_data, period)\n           )\n    return ndi", "response": "Negative Directional Index (-DI).\n\n    Formula:\n    -DI = 100 * SMMA(-DM) / ATR"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naveraging Directional Index. Formula: ADX = 100 * SMMA(abs((+DI - -DI) / (+DI + -DI)))", "response": "def average_directional_index(close_data, high_data, low_data, period):\n    \"\"\"\n    Average Directional Index.\n\n    Formula:\n    ADX = 100 * SMMA(abs((+DI - -DI) / (+DI + -DI)))\n    \"\"\"\n    avg_di = (abs(\n              (positive_directional_index(\n                close_data, high_data, low_data, period) -\n              negative_directional_index(\n                close_data, high_data, low_data, period)) /\n              (positive_directional_index(\n                close_data, high_data, low_data, period) +\n               negative_directional_index(\n                close_data, high_data, low_data, period)))\n              )\n    adx = 100 * smma(avg_di, period)\n    return adx"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef volume_oscillator(volume, short_period, long_period):\n    catch_errors.check_for_period_error(volume, short_period)\n    catch_errors.check_for_period_error(volume, long_period)\n\n    vo = (100 * ((sma(volume, short_period) - sma(volume, long_period)) /\n          sma(volume, long_period)))\n    return vo", "response": "Volume Oscillator.\n\n    Formula:\n    vo = 100 * (SMA(vol, short) - SMA(vol, long) / SMA(vol, long))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntripling Exponential Moving Average.", "response": "def triple_exponential_moving_average(data, period):\n    \"\"\"\n    Triple Exponential Moving Average.\n\n    Formula:\n    TEMA = (3*EMA - 3*EMA(EMA)) + EMA(EMA(EMA))\n    \"\"\"\n    catch_errors.check_for_period_error(data, period)\n\n    tema = ((3 * ema(data, period) - (3 * ema(ema(data, period), period))) +\n            ema(ema(ema(data, period), period), period)\n            )\n    return tema"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnegativing Volume Index (NVI). Formula: NVI0 = 1 IF Vt < Vt-1 NVIt = NVIt-1 + (CLOSEt - CLOSEt-1 / CLOSEt-1 * NVIt-1) ELSE: NVIt = NVIt-1", "response": "def negative_volume_index(close_data, volume):\n    \"\"\"\n    Negative Volume Index (NVI).\n\n    Formula:\n    NVI0 = 1\n    IF Vt < Vt-1\n        NVIt = NVIt-1 + (CLOSEt - CLOSEt-1 / CLOSEt-1 * NVIt-1)\n    ELSE:\n        NVIt = NVIt-1\n    \"\"\"\n    catch_errors.check_for_input_len_diff(close_data, volume)\n    nvi = np.zeros(len(volume))\n    nvi[0] = 1\n    for idx in range(1, len(volume)):\n        if volume[idx] < volume[idx-1]:\n            nvi[idx] = volume_index_helper(nvi, idx, close_data)\n        else:\n            nvi[idx] = nvi[idx-1]\n    return nvi"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging out and quits the current web driver and selenium session.", "response": "def close(self):\n        \"\"\"Logs out and quits the current web driver/selenium session.\"\"\"\n        if not self.driver:\n            return\n\n        try:\n            self.driver.implicitly_wait(1)\n            self.driver.find_element_by_id('link-logout').click()\n        except NoSuchElementException:\n            pass\n\n        self.driver.quit()\n        self.driver = None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef request_and_check(self, url, method='get',\n                          expected_content_type=None, **kwargs):\n        \"\"\"Performs a request, and checks that the status is OK, and that the\n        content-type matches expectations.\n\n        Args:\n          url: URL to request\n          method: either 'get' or 'post'\n          expected_content_type: prefix to match response content-type against\n          **kwargs: passed to the request method directly.\n\n        Raises:\n          RuntimeError if status_code does not match.\n        \"\"\"\n        assert method in ['get', 'post']\n        result = self.driver.request(method, url, **kwargs)\n        if result.status_code != requests.codes.ok:\n            raise RuntimeError('Error requesting %r, status = %d' %\n                               (url, result.status_code))\n        if expected_content_type is not None:\n            content_type = result.headers.get('content-type', '')\n            if not re.match(expected_content_type, content_type):\n                raise RuntimeError(\n                    'Error requesting %r, content type %r does not match %r' %\n                    (url, content_type, expected_content_type))\n        return result", "response": "Performs a request to the specified URL and checks that the status code is OK and that the content - type matches the expected content - type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_transactions_json(self, include_investment=False,\n                              skip_duplicates=False, start_date=None, id=0):\n        \"\"\"Returns the raw JSON transaction data as downloaded from Mint.  The JSON\n        transaction data includes some additional information missing from the\n        CSV data, such as whether the transaction is pending or completed, but\n        leaves off the year for current year transactions.\n\n        Warning: In order to reliably include or exclude duplicates, it is\n        necessary to change the user account property 'hide_duplicates' to the\n        appropriate value.  This affects what is displayed in the web\n        interface.  Note that the CSV transactions never exclude duplicates.\n        \"\"\"\n\n        # Warning: This is a global property for the user that we are changing.\n        self.set_user_property(\n            'hide_duplicates', 'T' if skip_duplicates else 'F')\n\n        # Converts the start date into datetime format - must be mm/dd/yy\n        try:\n            start_date = datetime.strptime(start_date, '%m/%d/%y')\n        except (TypeError, ValueError):\n            start_date = None\n        all_txns = []\n        offset = 0\n        # Mint only returns some of the transactions at once.  To get all of\n        # them, we have to keep asking for more until we reach the end.\n        while 1:\n            url = MINT_ROOT_URL + '/getJsonData.xevent'\n            params = {\n                'queryNew': '',\n                'offset': offset,\n                'comparableType': '8',\n                'rnd': Mint.get_rnd(),\n            }\n            # Specifying accountId=0 causes Mint to return investment\n            # transactions as well.  Otherwise they are skipped by\n            # default.\n            if id > 0 or include_investment:\n                params['id'] = id\n            if include_investment:\n                params['task'] = 'transactions'\n            else:\n                params['task'] = 'transactions,txnfilters'\n                params['filterType'] = 'cash'\n            result = self.request_and_check(\n                url, headers=JSON_HEADER, params=params,\n                expected_content_type='text/json|application/json')\n            data = json.loads(result.text)\n            txns = data['set'][0].get('data', [])\n            if not txns:\n                break\n            if start_date:\n                last_dt = json_date_to_datetime(txns[-1]['odate'])\n                if last_dt < start_date:\n                    keep_txns = [\n                        t for t in txns\n                        if json_date_to_datetime(t['odate']) >= start_date]\n                    all_txns.extend(keep_txns)\n                    break\n            all_txns.extend(txns)\n            offset += len(txns)\n        return all_txns", "response": "Returns the raw JSON transaction data as downloaded from Mint."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the JSON transaction data as a DataFrame and converts the dates prior year dates into consistent datetime.", "response": "def get_detailed_transactions(self, include_investment=False,\n                                  skip_duplicates=False,\n                                  remove_pending=True,\n                                  start_date=None):\n        \"\"\"Returns the JSON transaction data as a DataFrame, and converts\n        current year dates and prior year dates into consistent datetime\n        format, and reverses credit activity.\n\n        Note: start_date must be in format mm/dd/yy. If pulls take too long,\n        use a more recent start date. See json explanations of\n        include_investment and skip_duplicates.\n\n        Also note: Mint includes pending transactions, however these sometimes\n        change dates/amounts after the transactions post. They have been\n        removed by default in this pull, but can be included by changing\n        remove_pending to False\n\n        \"\"\"\n        assert_pd()\n\n        result = self.get_transactions_json(include_investment,\n                                            skip_duplicates, start_date)\n        df = pd.DataFrame(result)\n        df['odate'] = df['odate'].apply(json_date_to_datetime)\n\n        if remove_pending:\n            df = df[~df.isPending]\n            df.reset_index(drop=True, inplace=True)\n\n        df.amount = df.apply(reverse_credit_amount, axis=1)\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the raw CSV transaction data as downloaded from Mint.", "response": "def get_transactions_csv(self, include_investment=False, acct=0):\n        \"\"\"Returns the raw CSV transaction data as downloaded from Mint.\n\n        If include_investment == True, also includes transactions that Mint\n        classifies as investment-related.  You may find that the investment\n        transaction data is not sufficiently detailed to actually be useful,\n        however.\n        \"\"\"\n\n        # Specifying accountId=0 causes Mint to return investment\n        # transactions as well.  Otherwise they are skipped by\n        # default.\n        params = None\n        if include_investment or acct > 0:\n            params = {'accountId': acct}\n        result = self.request_and_check(\n            '{}/transactionDownload.event'.format(MINT_ROOT_URL),\n            params=params,\n            expected_content_type='text/csv')\n        return result.content"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the transaction data as a Pandas DataFrame.", "response": "def get_transactions(self, include_investment=False):\n        \"\"\"Returns the transaction data as a Pandas DataFrame.\"\"\"\n        assert_pd()\n        s = StringIO(self.get_transactions_csv(\n            include_investment=include_investment))\n        s.seek(0)\n        df = pd.read_csv(s, parse_dates=['Date'])\n        df.columns = [c.lower().replace(' ', '_') for c in df.columns]\n        df.category = (df.category.str.lower()\n                       .replace('uncategorized', pd.np.nan))\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self):\n\n        acc = self.horizon.account(self.address)\n        self.sequence = acc.get('sequence')\n        self.balances = acc.get('balances')\n        self.paging_token = acc.get('paging_token')\n        self.thresholds = acc.get('thresholds')\n        self.flags = acc.get('flags')\n        self.signers = acc.get('signers')\n        self.data = acc.get('data')\n        self.inflation_destination = acc.get('inflation_destination')\n        self.subentry_count = acc.get('subentry_count')", "response": "Retrieve the account data that corresponds to this address."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef payments(self, cursor=None, order='asc', limit=10, sse=False):\n        return self.horizon.account_payments(address=self.address, cursor=cursor, order=order, limit=limit, sse=sse)", "response": "Retrieve the payments JSON response for the account associated with this instance s Address."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the offers JSON response for the account associated with this instance s Address.", "response": "def offers(self, cursor=None, order='asc', limit=10, sse=False):\n        \"\"\"Retrieve the offers JSON from this instance's Horizon server.\n\n        Retrieve the offers JSON response for the account associated with\n        this :class:`Address`.\n\n        :param cursor: A paging token, specifying where to start returning records from.\n            When streaming this can be set to \"now\" to stream object created since your request time.\n        :type cursor: int, str\n        :param str order: The order in which to return rows, \"asc\" or \"desc\".\n        :param int limit: Maximum number of records to return.\n        :param bool sse: Use server side events for streaming responses.\n\n        \"\"\"\n        return self.horizon.account_offers(self.address, cursor=cursor, order=order, limit=limit, sse=sse)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the transactions JSON response for the account associated with this instance s Address.", "response": "def transactions(self, cursor=None, order='asc', limit=10, sse=False):\n        \"\"\"Retrieve the transactions JSON from this instance's Horizon server.\n\n        Retrieve the transactions JSON response for the account associated with\n        this :class:`Address`.\n\n        :param cursor: A paging token, specifying where to start returning records from.\n            When streaming this can be set to \"now\" to stream object created since your request time.\n        :type cursor: int, str\n        :param str order: The order in which to return rows, \"asc\" or \"desc\".\n        :param int limit: Maximum number of records to return.\n        :param bool sse: Use server side events for streaming responses.\n        \"\"\"\n        return self.horizon.account_transactions(\n            self.address, cursor=cursor, order=order, limit=limit, sse=sse)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the operations JSON from this instance s Horizon server.", "response": "def operations(self, cursor=None, order='asc', limit=10, sse=False):\n        \"\"\"Retrieve the operations JSON from this instance's Horizon server.\n\n        Retrieve the operations JSON response for the account associated with\n        this :class:`Address`.\n\n        :param cursor: A paging token, specifying where to start returning records from.\n            When streaming this can be set to \"now\" to stream object created since your request time.\n        :type cursor: int, str\n        :param str order: The order in which to return rows, \"asc\" or \"desc\".\n        :param int limit: Maximum number of records to return.\n        :param bool sse: Use the SSE client for connecting to Horizon.\n\n        \"\"\"\n        return self.horizon.account_operations(\n            self.address, cursor=cursor, order=order, limit=limit, sse=sse)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trades(self, cursor=None, order='asc', limit=10, sse=False):\n        return self.horizon.account_trades(\n            self.address, cursor=cursor, order=order, limit=limit, sse=sse)", "response": "Retrieve the trades JSON response for the account associated with this instance s address."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the effects JSON response for the account associated with this instance s address.", "response": "def effects(self, cursor=None, order='asc', limit=10, sse=False):\n        \"\"\"Retrieve the effects JSON from this instance's Horizon server.\n\n        Retrieve the effects JSON response for the account associated with\n        this :class:`Address`.\n\n        :param cursor: A paging token, specifying where to start returning records from.\n            When streaming this can be set to \"now\" to stream object created since your request time.\n        :type cursor: int, str\n        :param str order: The order in which to return rows, \"asc\" or \"desc\".\n        :param int limit: Maximum number of records to return.\n        :param bool sse: Use the SSE client for connecting to Horizon.\n\n        \"\"\"\n        return self.horizon.account_effects(\n            self.address, cursor=cursor, order=order, limit=limit, sse=sse)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef submit(self, te):\n        params = {'tx': te}\n        url = urljoin(self.horizon_uri, 'transactions/')\n\n        # POST is not included in Retry's method_whitelist for a good reason.\n        # our custom retry mechanism follows\n        reply = None\n        retry_count = self.num_retries\n        while True:\n            try:\n                reply = self._session.post(\n                    url, data=params, timeout=self.request_timeout)\n                return check_horizon_reply(reply.json())\n            except (RequestException, NewConnectionError, ValueError) as e:\n                if reply is not None:\n                    msg = 'Horizon submit exception: {}, reply: [{}] {}'.format(\n                        str(e), reply.status_code, reply.text)\n                else:\n                    msg = 'Horizon submit exception: {}'.format(str(e))\n                logging.warning(msg)\n\n                if (reply is not None and reply.status_code not in self.status_forcelist) or retry_count <= 0:\n                    if reply is None:\n                        raise HorizonRequestError(e)\n                    raise HorizonError('Invalid horizon reply: [{}] {}'.format(\n                        reply.status_code, reply.text), reply.status_code)\n                retry_count -= 1\n                logging.warning('Submit retry attempt {}'.format(retry_count))\n                sleep(self.backoff_factor)", "response": "Submit a new transaction using a pooled connection and retry on failure."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef account(self, address):\n        endpoint = '/accounts/{account_id}'.format(account_id=address)\n        return self.query(endpoint)", "response": "Returns information and links relating to a single account."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef account_effects(self, address, cursor=None, order='asc', limit=10, sse=False):\n        endpoint = '/accounts/{account_id}/effects'.format(account_id=address)\n        params = self.__query_params(cursor=cursor, order=order, limit=limit)\n        return self.query(endpoint, params, sse)", "response": "This endpoint represents all effects that changed a given account."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assets(self, asset_code=None, asset_issuer=None, cursor=None, order='asc', limit=10):\n        endpoint = '/assets'\n        params = self.__query_params(asset_code=asset_code, asset_issuer=asset_issuer, cursor=cursor, order=order,\n                                     limit=limit)\n        return self.query(endpoint, params)", "response": "This endpoint represents all the assets. It will give you all the assets in the system along with various statistics about each asset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transaction(self, tx_hash):\n        endpoint = '/transactions/{tx_hash}'.format(tx_hash=tx_hash)\n        return self.query(endpoint)", "response": "The transaction details endpoint provides information on a single transaction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn for each orderbook a summary of the orderbook and the bids and asks associated with that orderbook.", "response": "def order_book(self, selling_asset_code, buying_asset_code, selling_asset_issuer=None, buying_asset_issuer=None,\n                   limit=10):\n        \"\"\"Return, for each orderbook, a summary of the orderbook and the bids\n        and asks associated with that orderbook.\n\n        See the external docs below for information on the arguments required.\n\n        `GET /order_book\n        <https://www.stellar.org/developers/horizon/reference/endpoints/orderbook-details.html>`_\n\n        :param str selling_asset_code: Code of the Asset being sold.\n        :param str buying_asset_code: Type of the Asset being bought.\n        :param str selling_asset_issuer: Account ID of the issuer of the Asset being sold,\n            if it is a native asset, let it be `None`.\n        :param str buying_asset_issuer: Account ID of the issuer of the Asset being bought,\n            if it is a native asset, let it be `None`.\n        :param int limit: Limit the number of items returned.\n        :return: A list of orderbook summaries as a JSON object.\n        :rtype: dict\n\n        \"\"\"\n        selling_asset = Asset(selling_asset_code, selling_asset_issuer)\n        buying_asset = Asset(buying_asset_code, buying_asset_issuer)\n        asset_params = {\n            'selling_asset_type': selling_asset.type,\n            'selling_asset_code': None if selling_asset.is_native() else selling_asset.code,\n            'selling_asset_issuer': selling_asset.issuer,\n            'buying_asset_type': buying_asset.type,\n            'buying_asset_code': None if buying_asset.is_native() else buying_asset.code,\n            'buying_asset_issuer': buying_asset.issuer,\n        }\n        endpoint = '/order_book'\n        params = self.__query_params(limit=limit, **asset_params)\n        return self.query(endpoint, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ledger(self, ledger_id):\n        endpoint = '/ledgers/{ledger_id}'.format(ledger_id=ledger_id)\n        return self.query(endpoint)", "response": "The ledger details endpoint provides information on a single ledger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ledger_effects(self, ledger_id, cursor=None, order='asc', limit=10):\n        endpoint = '/ledgers/{ledger_id}/effects'.format(ledger_id=ledger_id)\n        params = self.__query_params(cursor=cursor, order=order, limit=limit)\n        return self.query(endpoint, params)", "response": "This endpoint represents all effects that occurred in the given ledger."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef effects(self, cursor=None, order='asc', limit=10, sse=False):\n        endpoint = '/effects'\n        params = self.__query_params(cursor=cursor, order=order, limit=limit)\n        return self.query(endpoint, params, sse)", "response": "This endpoint represents all effects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef operations(self, cursor=None, order='asc', limit=10, include_failed=False, sse=False):\n        endpoint = '/operations'\n        params = self.__query_params(cursor=cursor, order=order, limit=limit, include_failed=include_failed)\n        return self.query(endpoint, params, sse)", "response": "This endpoint represents all operations that are part of validated\n        transactions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a list of assets available to the source account id and find any payment paths from those source assets to the desired destination asset. See the below docs for more information on required and optional parameters for further specifying your search. `GET /paths <https://www.stellar.org/developers/horizon/reference/endpoints/path-finding.html>`_ :param str destination_account: The destination account that any returned path should use. :param str destination_amount: The amount, denominated in the destination asset, that any returned path should be able to satisfy. :param str source_account: The sender's account id. Any returned path must use a source that the sender can hold. :param str destination_asset_code: The asset code for the destination. :param destination_asset_issuer: The asset issuer for the destination, if it is a native asset, let it be `None`. :type destination_asset_issuer: str, None :return: A list of paths that can be used to complete a payment based on a given query. :rtype: dict", "response": "def paths(self, destination_account, destination_amount, source_account, destination_asset_code,\n              destination_asset_issuer=None):\n        \"\"\"Load a list of assets available to the source account id and find\n        any payment paths from those source assets to the desired\n        destination asset.\n\n        See the below docs for more information on required and optional\n        parameters for further specifying your search.\n\n        `GET /paths\n        <https://www.stellar.org/developers/horizon/reference/endpoints/path-finding.html>`_\n\n        :param str destination_account: The destination account that any returned path should use.\n        :param str destination_amount: The amount, denominated in the destination asset,\n            that any returned path should be able to satisfy.\n        :param str source_account: The sender's account id. Any returned path must use a source that the sender can hold.\n        :param str destination_asset_code: The asset code for the destination.\n        :param destination_asset_issuer: The asset issuer for the destination, if it is a native asset, let it be `None`.\n        :type destination_asset_issuer: str, None\n\n\n        :return: A list of paths that can be used to complete a payment based\n            on a given query.\n        :rtype: dict\n\n        \"\"\"\n        destination_asset = Asset(destination_asset_code, destination_asset_issuer)\n        destination_asset_params = {\n            'destination_asset_type': destination_asset.type,\n            'destination_asset_code': None if destination_asset.is_native() else destination_asset.code,\n            'destination_asset_issuer': destination_asset.issuer\n        }\n        endpoint = '/paths'\n        params = self.__query_params(destination_account=destination_account,\n                                     source_account=source_account,\n                                     destination_amount=destination_amount,\n                                     **destination_asset_params\n                                     )\n        return self.query(endpoint, params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a list of trades optionally filtered by an orderbook.", "response": "def trades(self, base_asset_code=None, counter_asset_code=None, base_asset_issuer=None, counter_asset_issuer=None,\n               offer_id=None, cursor=None, order='asc', limit=10):\n        \"\"\"Load a list of trades, optionally filtered by an orderbook.\n\n        See the below docs for more information on required and optional\n        parameters for further specifying your search.\n\n        `GET /trades\n        <https://www.stellar.org/developers/horizon/reference/endpoints/trades.html>`_\n\n        :param str base_asset_code: Code of base asset.\n        :param str base_asset_issuer: Issuer of base asset, if it is a native asset, let it be `None`.\n        :param str counter_asset_code: Code of counter asset.\n        :param str counter_asset_issuer: Issuer of counter asset, if it is a native asset, let it be `None`.\n        :param int offer_id: Filter for by a specific offer id.\n        :param int cursor: A paging token, specifying where to start returning records from.\n        :param str order: The order in which to return rows, \"asc\" or \"desc\".\n        :param int limit: Maximum number of records to return.\n        :return: A list of trades filtered by a given query.\n        :rtype: dict\n\n        \"\"\"\n        base_asset = Asset(base_asset_code, base_asset_issuer)\n        counter_asset = Asset(counter_asset_code, counter_asset_issuer)\n        asset_params = {\n            'base_asset_type': base_asset.type,\n            'base_asset_code': None if base_asset.is_native() else base_asset.code,\n            'base_asset_issuer': base_asset.issuer,\n            'counter_asset_type': counter_asset.type,\n            'counter_asset_code': None if counter_asset.is_native() else counter_asset.code,\n            'counter_asset_issuer': counter_asset.issuer\n        }\n        endpoint = '/trades'\n        params = self.__query_params(offer_id=offer_id, cursor=cursor, order=order, limit=limit, **asset_params)\n        return self.query(endpoint, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a list of aggregated historical trade data optionally filtered by an orderbook.", "response": "def trade_aggregations(self, resolution, base_asset_code, counter_asset_code,\n                           base_asset_issuer=None, counter_asset_issuer=None, start_time=None,\n                           end_time=None, order='asc', limit=10, offset=0):\n        \"\"\"Load a list of aggregated historical trade data, optionally filtered\n        by an orderbook.\n\n        `GET /trade_aggregations\n        <https://www.stellar.org/developers/horizon/reference/endpoints/trade_aggregations.html>`_\n\n        :param int start_time: Lower time boundary represented as millis since epoch.\n        :param int end_time: Upper time boundary represented as millis since epoch.\n        :param int resolution: Segment duration as millis since epoch. Supported values\n            are 1 minute (60000), 5 minutes (300000), 15 minutes (900000), 1 hour (3600000),\n            1 day (86400000) and 1 week (604800000).\n        :param str base_asset_code: Code of base asset.\n        :param str base_asset_issuer: Issuer of base asset, if it is a native asset, let it be `None`.\n        :param str counter_asset_code: Code of counter asset.\n        :param str counter_asset_issuer: Issuer of counter asset, if it is a native asset, let it be `None`.\n        :param str order: The order in which to return rows, \"asc\" or \"desc\".\n        :param int limit: Maximum number of records to return.\n        :param int offset: segments can be offset using this parameter.\n            Expressed in milliseconds. *Can only be used if the resolution is greater than 1 hour.\n            Value must be in whole hours, less than the provided resolution, and less than 24 hours.\n        :return: A list of collected trade aggregations.\n        :rtype: dict\n\n        \"\"\"\n        allowed_resolutions = (60000, 300000, 900000, 3600000, 86400000, 604800000)\n        if resolution not in allowed_resolutions:\n            raise NotValidParamError(\"resolution is invalid\")\n\n        if offset > resolution or offset >= 24 * 3600000 or offset % 3600000 != 0:\n            raise NotValidParamError(\"offset is invalid\")\n\n        base_asset = Asset(base_asset_code, base_asset_issuer)\n        counter_asset = Asset(counter_asset_code, counter_asset_issuer)\n        asset_params = {\n            'base_asset_type': base_asset.type,\n            'base_asset_code': None if base_asset.is_native() else base_asset.code,\n            'base_asset_issuer': base_asset.issuer,\n            'counter_asset_type': counter_asset.type,\n            'counter_asset_code': None if counter_asset.is_native() else counter_asset.code,\n            'counter_asset_issuer': counter_asset.issuer\n        }\n        endpoint = '/trade_aggregations'\n        params = self.__query_params(start_time=start_time, end_time=end_time, resolution=resolution, order=order,\n                                     limit=limit, offset=offset, **asset_params)\n        return self.query(endpoint, params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef offer_trades(self, offer_id, cursor=None, order='asc', limit=10):\n        endpoint = '/offers/{offer_id}/trades'.format(offer_id=offer_id)\n        params = self.__query_params(cursor=cursor, order=order, limit=limit)\n        return self.query(endpoint, params)", "response": "This endpoint represents all trades for an offer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef base_fee(self):\n        latest_ledger = self.ledgers(order='desc', limit=1)\n        try:\n            base_fee = latest_ledger['_embedded']['records'][0]['base_fee_in_stroops']\n        except (KeyError, IndexError):\n            base_fee = 100\n        return base_fee", "response": "Fetch the base fee from the latest ledger."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sign(self, keypair):\n        assert isinstance(keypair, Keypair)\n        tx_hash = self.hash_meta()\n        sig = keypair.sign_decorated(tx_hash)\n        sig_dict = [signature.__dict__ for signature in self.signatures]\n        if sig.__dict__ in sig_dict:\n            raise SignatureExistError('The keypair has already signed')\n        else:\n            self.signatures.append(sig)", "response": "Sign this transaction with a given keypair."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sign_hashX(self, preimage):\n        # if len(preimage) > 64:\n        #     raise PreimageLengthError('preimage must <= 64 bytes')\n        preimage = convert_hex_to_bytes(preimage)\n        sig = hashX_sign_decorated(preimage)\n        sig_dict = [signature.__dict__ for signature in self.signatures]\n        if sig.__dict__ in sig_dict:\n            raise SignatureExistError('The preimage has already signed.')\n        else:\n            self.signatures.append(sig)", "response": "Sign this transaction envelope with a HashX signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the signature base of this transaction envelope.", "response": "def signature_base(self):\n        \"\"\"Get the signature base of this transaction envelope.\n\n        Return the \"signature base\" of this transaction, which is the value\n        that, when hashed, should be signed to create a signature that\n        validators on the Stellar Network will accept.\n\n        It is composed of a 4 prefix bytes followed by the xdr-encoded form of\n        this transaction.\n\n        :return: The signature base of this transaction envelope.\n\n        \"\"\"\n        network_id = self.network_id\n        tx_type = Xdr.StellarXDRPacker()\n        tx_type.pack_EnvelopeType(Xdr.const.ENVELOPE_TYPE_TX)\n        tx_type = tx_type.get_buffer()\n\n        tx = Xdr.StellarXDRPacker()\n        tx.pack_Transaction(self.tx.to_xdr_object())\n        tx = tx.get_buffer()\n        return network_id + tx_type + tx"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_xdr_object(self):\n        tx = self.tx.to_xdr_object()\n        return Xdr.types.TransactionEnvelope(tx, self.signatures)", "response": "Get an XDR object representation of this\n       ."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the base64 encoded XDR string representing this .", "response": "def xdr(self):\n        \"\"\"Get the base64 encoded XDR string representing this\n        :class:`TransactionEnvelope`.\n\n        \"\"\"\n        te = Xdr.StellarXDRPacker()\n        te.pack_TransactionEnvelope(self.to_xdr_object())\n        te = base64.b64encode(te.get_buffer())\n        return te"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new TransactionEnvelope object from an XDR string.", "response": "def from_xdr(cls, xdr):\n        \"\"\"Create a new :class:`TransactionEnvelope` from an XDR string.\n\n        :param xdr: The XDR string that represents a transaction\n            envelope.\n        :type xdr: bytes, str\n\n        \"\"\"\n        xdr_decoded = base64.b64decode(xdr)\n        te = Xdr.StellarXDRUnpacker(xdr_decoded)\n        te_xdr_object = te.unpack_TransactionEnvelope()\n        signatures = te_xdr_object.signatures\n        tx_xdr_object = te_xdr_object.tx\n        tx = Transaction.from_xdr_object(tx_xdr_object)\n        te = TransactionEnvelope(tx, signatures=signatures)\n        # te = TransactionEnvelope(\n        #     tx, {'signatures': signatures, 'network_id': 'PUBLIC'})\n        return te"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _crc16(data, crc, table):\n    bytes_to_int = lambda x: ord(x) if sys.version_info.major == 2 else x\n    for byte in data:\n        crc = ((crc << 8) & 0xff00) ^ table[((crc >> 8) & 0xff) ^ bytes_to_int(byte)]\n    return crc & 0xffff", "response": "Calculates the CRC of the given data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef federation(address_or_id, fed_type='name', domain=None, allow_http=False):\n    if fed_type == 'name':\n        if '*' not in address_or_id:\n            raise FederationError('Not a valid federation address.')\n\n        param, domain = address_or_id.rsplit('*', 1)\n        if param == '' or domain == '':\n            raise FederationError('Not a valid federation address.')\n    elif fed_type == 'id':\n        try:\n            assert is_valid_address(address_or_id)\n        except StellarAddressInvalidError:\n            raise FederationError('{} is not a valid account id.'.format(address_or_id))\n    else:\n        raise FederationError('Not a valid fed_type.')\n\n    if '.' not in domain:\n        raise FederationError('Not a valid domain name.')\n    fed_service = get_federation_service(domain, allow_http)\n    if not fed_service:\n        raise FederationError('Not a valid federation server.')\n\n    return _get_federation_info(address_or_id, fed_service, fed_type)", "response": "Send a federation query to a Stellar Federation service."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_federation_info(address_or_id, federation_service, fed_type='name'):\n    params = {'q': address_or_id, 'type': fed_type}\n    r = requests.get(federation_service, params=params)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return None", "response": "Send a federation query to a stellar federation service."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the FEDERATION_SERVER config from a domain s stellar. toml file.", "response": "def get_federation_service(domain, allow_http=False):\n    \"\"\"Retrieve the FEDERATION_SERVER config from a domain's stellar.toml.\n\n    :param str domain: The domain the .toml file is hosted at.\n    :param bool allow_http: Specifies whether the request should go over plain\n        HTTP vs HTTPS. Note it is recommend that you *always* use HTTPS.\n    :return str: The FEDERATION_SERVER url.\n\n    \"\"\"\n    st = get_stellar_toml(domain, allow_http)\n    if not st:\n        return None\n    return st.get('FEDERATION_SERVER')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_auth_server(domain, allow_http=False):\n    st = get_stellar_toml(domain, allow_http)\n    if not st:\n        return None\n    return st.get('AUTH_SERVER')", "response": "Retrieve the AUTH_SERVER config from a domain s stellar. toml file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_stellar_toml(domain, allow_http=False):\n    toml_link = '/.well-known/stellar.toml'\n    if allow_http:\n        protocol = 'http://'\n    else:\n        protocol = 'https://'\n    url_list = ['', 'www.', 'stellar.']\n    url_list = [protocol + url + domain + toml_link for url in url_list]\n\n    for url in url_list:\n        r = requests.get(url)\n        if r.status_code == 200:\n            return toml.loads(r.text)\n\n    return None", "response": "Retrieve the stellar. toml file from a given domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_operation(self, operation):\n        if operation not in self.operations:\n            self.operations.append(operation)", "response": "Add an operation to the list of operations that this transaction should be unique."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an XDR Transaction object that represents this .", "response": "def to_xdr_object(self):\n        \"\"\"Creates an XDR Transaction object that represents this\n        :class:`Transaction`.\n\n        \"\"\"\n        source_account = account_xdr_object(self.source)\n        memo = self.memo.to_xdr_object()\n        operations = [o.to_xdr_object() for o in self.operations]\n        ext = Xdr.nullclass()\n        ext.v = 0\n        return Xdr.types.Transaction(source_account, self.fee, self.sequence,\n                                     self.time_bounds, memo, operations, ext)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npacks and base64 encodes this : class : Transaction as an XDR string.", "response": "def xdr(self):\n        \"\"\"Packs and base64 encodes this :class:`Transaction` as an XDR\n        string.\n\n        \"\"\"\n        tx = Xdr.StellarXDRPacker()\n        tx.pack_Transaction(self.to_xdr_object())\n        return base64.b64encode(tx.get_buffer())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_xdr_object(cls, tx_xdr_object):\n        source = encode_check('account', tx_xdr_object.sourceAccount.ed25519)\n        sequence = tx_xdr_object.seqNum - 1\n        time_bounds_in_xdr = tx_xdr_object.timeBounds  # TODO test\n        if time_bounds_in_xdr:\n            time_bounds = {\n                'maxTime': time_bounds_in_xdr[0].maxTime,\n                'minTime': time_bounds_in_xdr[0].minTime\n            }\n        else:\n            time_bounds = None\n\n        memo = xdr_to_memo(tx_xdr_object.memo)\n\n        operations = list(map(\n            Operation.from_xdr_object, tx_xdr_object.operations\n        ))\n        return cls(\n            source=source,\n            sequence=sequence,\n            time_bounds=time_bounds,\n            memo=memo,\n            fee=tx_xdr_object.fee,\n            operations=operations)", "response": "Create a : class : Transaction object from a Transaction XDR object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a new keypair from a mnemonic using a deterministic version of the mnemonic.", "response": "def deterministic(cls, mnemonic, passphrase='', lang='english', index=0):\n        \"\"\"Generate a :class:`Keypair` object via a deterministic\n        phrase.\n\n        Using a mnemonic, such as one generated from :class:`StellarMnemonic`,\n        generate a new keypair deterministically. Uses :class:`StellarMnemonic`\n        internally to generate the seed from the mnemonic, using PBKDF2.\n\n        :param str mnemonic: A unique string used to deterministically generate\n            keypairs.\n        :param str passphrase: An optional passphrase used as part of the salt\n            during PBKDF2 rounds when generating the seed from the mnemonic.\n        :param str lang: The language of the mnemonic, defaults to english.\n        :param int index: The index of the keypair generated by the mnemonic.\n            This allows for multiple Keypairs to be derived from the same\n            mnemonic, such as::\n\n                >>> from stellar_base.keypair import Keypair\n                >>> m = 'update hello cry airport drive chunk elite boat shaft sea describe number'  # Don't use this mnemonic in practice.\n                >>> kp1 = Keypair.deterministic(m, lang='english', index=0)\n                >>> kp2 = Keypair.deterministic(m, lang='english', index=1)\n                >>> kp3 = Keypair.deterministic(m, lang='english', index=2)\n\n        :return: A new :class:`Keypair` instance derived from the mnemonic.\n\n        \"\"\"\n        sm = StellarMnemonic(lang)\n        seed = sm.to_seed(mnemonic, passphrase=passphrase, index=index)\n        return cls.from_raw_seed(seed)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_raw_seed(cls, raw_seed):\n        signing_key = ed25519.SigningKey(raw_seed)\n        verifying_key = signing_key.get_verifying_key()\n        return cls(verifying_key, signing_key)", "response": "Generate a new keypair from a raw secret seed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a new keypair object from a base58 encoded secret seed.", "response": "def from_base58_seed(cls, base58_seed):\n        \"\"\"Generate a :class:`Keypair` object via Base58 encoded seed.\n\n        .. deprecated:: 0.1.7\n           Base58 address encoding is DEPRECATED! Use this method only for\n           transition to strkey encoding.\n\n        :param str base58_seed: A base58 encoded encoded secret seed.\n        :return: A new :class:`Keypair` derived from the secret seed.\n\n        \"\"\"\n        warnings.warn(\n            \"Base58 address encoding is DEPRECATED! Use this method only for \"\n            \"transition to strkey encoding.\", DeprecationWarning)\n        raw_seed = b58decode_check(base58_seed)[1:]\n        return cls.from_raw_seed(raw_seed)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_address(cls, address):\n        public_key = is_valid_address(address)\n        verifying_key = ed25519.VerifyingKey(public_key)\n        return cls(verifying_key)", "response": "Generate a new keypair object from an address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate PublicKey XDR object via public key bytes.", "response": "def account_xdr_object(self):\n        \"\"\"Create PublicKey XDR object via public key bytes.\n\n        :return: Serialized XDR of PublicKey type.\n        \"\"\"\n        return Xdr.types.PublicKey(Xdr.const.KEY_TYPE_ED25519,\n                                   self.verifying_key.to_bytes())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate base64 encoded XDR PublicKey object.", "response": "def xdr(self):\n        \"\"\"Generate base64 encoded XDR PublicKey object.\n\n        Return a base64 encoded PublicKey XDR object, for sending over the wire\n        when interacting with stellar.\n\n        :return: The base64 encoded PublicKey XDR structure.\n        \"\"\"\n        kp = Xdr.StellarXDRPacker()\n        kp.pack_PublicKey(self.account_xdr_object())\n        return base64.b64encode(kp.get_buffer())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sign(self, data):\n        if self.signing_key is None:\n            raise MissingSigningKeyError(\"KeyPair does not contain secret key. \"\n                                         \"Use Keypair.from_seed method to create a new keypair with a secret key.\")\n        return self.signing_key.sign(data)", "response": "Sign a bytes - like object using the signing key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify the signature of a sequence of bytes using the verifying_key and the corresponding data.", "response": "def verify(self, data, signature):\n        \"\"\"Verify the signature of a sequence of bytes.\n\n        Verify the signature of a sequence of bytes using the verifying\n        (public) key and the data that was originally signed, otherwise throws\n        an exception.\n\n        :param bytes data: A sequence of bytes that were previously signed by\n            the private key associated with this verifying key.\n        :param bytes signature: A sequence of bytes that comprised the\n            signature for the corresponding data.\n        \"\"\"\n        try:\n            return self.verifying_key.verify(signature, data)\n        except ed25519.BadSignatureError:\n            raise BadSignatureError(\"Signature verification failed.\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sign_decorated(self, data):\n        signature = self.sign(data)\n        hint = self.signature_hint()\n        return Xdr.types.DecoratedSignature(hint, signature)", "response": "Sign a bytes - like object and return the decorated signature."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy from base64. _bytes_from_decode_data", "response": "def bytes_from_decode_data(s):\n    \"\"\"copy from base64._bytes_from_decode_data\n    \"\"\"\n    if isinstance(s, (str, unicode)):\n        try:\n            return s.encode('ascii')\n        except UnicodeEncodeError:\n            raise NotValidParamError(\n                'String argument should contain only ASCII characters')\n    if isinstance(s, bytes_types):\n        return s\n    try:\n        return memoryview(s).tobytes()\n    except TypeError:\n        raise suppress_context(\n            TypeError(\n                'Argument should be a bytes-like object or ASCII string, not '\n                '{!r}'.format(s.__class__.__name__)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an XDR Operation object that represents this .", "response": "def to_xdr_object(self):\n        \"\"\"Creates an XDR Operation object that represents this\n        :class:`Operation`.\n\n        \"\"\"\n        try:\n            source_account = [account_xdr_object(self.source)]\n        except StellarAddressInvalidError:\n            source_account = []\n        return Xdr.types.Operation(source_account, self.body)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npacks and base64 encodes this : class : Operation as an XDR string.", "response": "def xdr(self):\n        \"\"\"Packs and base64 encodes this :class:`Operation` as an XDR string.\n\n        \"\"\"\n        op = Xdr.StellarXDRPacker()\n        op.pack_Operation(self.to_xdr_object())\n        return base64.b64encode(op.get_buffer())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_xdr_amount(value):\n        if not isinstance(value, str):\n            raise NotValidParamError(\"Value of type '{}' must be of type String, but got {}\".format(value, type(value)))\n\n        # throw exception if value * ONE has decimal places (it can't be\n        # represented as int64)\n        try:\n            amount = int((Decimal(value) * ONE).to_integral_exact(context=Context(traps=[Inexact])))\n        except decimal.Inexact:\n            raise NotValidParamError(\"Value of '{}' must have at most 7 digits after the decimal.\".format(value))\n        except decimal.InvalidOperation:\n            raise NotValidParamError(\"Value of '{}' must represent a positive number.\".format(value))\n        return amount", "response": "Converts an amount to an appropriate value to send over the XDR object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an instance of the class cls from an XDR base64 encoded string and return it.", "response": "def from_xdr(cls, xdr):\n        \"\"\"Create the appropriate :class:`Operation` subclass from the XDR\n        structure.\n\n        Decode an XDR base64 encoded string and create the appropriate\n        :class:`Operation` object.\n\n        :param str xdr: The XDR object to create an :class:`Operation` (or\n            subclass) instance from.\n\n        \"\"\"\n        xdr_decode = base64.b64decode(xdr)\n        op = Xdr.StellarXDRUnpacker(xdr_decode)\n        op = op.unpack_Operation()\n        return cls.from_xdr_object(op)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_xdr_object(self):\n        destination = account_xdr_object(self.destination)\n\n        create_account_op = Xdr.types.CreateAccountOp(\n            destination, Operation.to_xdr_amount(self.starting_balance))\n        self.body.type = Xdr.const.CREATE_ACCOUNT\n        self.body.createAccountOp = create_account_op\n        return super(CreateAccount, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents this\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_xdr_object(cls, op_xdr_object):\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        destination = encode_check(\n            'account',\n            op_xdr_object.body.createAccountOp.destination.ed25519).decode()\n        starting_balance = Operation.from_xdr_amount(\n            op_xdr_object.body.createAccountOp.startingBalance)\n\n        return cls(\n            source=source,\n            destination=destination,\n            starting_balance=starting_balance,\n        )", "response": "Creates a : class : CreateAccount object from an XDR Operation\n            object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_xdr_object(self):\n        asset = self.asset.to_xdr_object()\n        destination = account_xdr_object(self.destination)\n\n        amount = Operation.to_xdr_amount(self.amount)\n\n        payment_op = Xdr.types.PaymentOp(destination, asset, amount)\n        self.body.type = Xdr.const.PAYMENT\n        self.body.paymentOp = payment_op\n        return super(Payment, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents this\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a : class : Payment object from an XDR Operation object.", "response": "def from_xdr_object(cls, op_xdr_object):\n        \"\"\"Creates a :class:`Payment` object from an XDR Operation\n        object.\n\n        \"\"\"\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        destination = encode_check(\n            'account',\n            op_xdr_object.body.paymentOp.destination.ed25519).decode()\n        asset = Asset.from_xdr_object(op_xdr_object.body.paymentOp.asset)\n        amount = Operation.from_xdr_amount(op_xdr_object.body.paymentOp.amount)\n\n        return cls(\n            source=source,\n            destination=destination,\n            asset=asset,\n            amount=amount,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_xdr_object(self):\n        destination = account_xdr_object(self.destination)\n        send_asset = self.send_asset.to_xdr_object()\n        dest_asset = self.dest_asset.to_xdr_object()\n        path = [asset.to_xdr_object() for asset in self.path]\n\n        path_payment = Xdr.types.PathPaymentOp(\n            send_asset, Operation.to_xdr_amount(self.send_max), destination,\n            dest_asset, Operation.to_xdr_amount(self.dest_amount), path)\n        self.body.type = Xdr.const.PATH_PAYMENT\n        self.body.pathPaymentOp = path_payment\n        return super(PathPayment, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents this\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_xdr_object(cls, op_xdr_object):\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        destination = encode_check(\n            'account',\n            op_xdr_object.body.pathPaymentOp.destination.ed25519).decode()\n        send_asset = Asset.from_xdr_object(\n            op_xdr_object.body.pathPaymentOp.sendAsset)\n        dest_asset = Asset.from_xdr_object(\n            op_xdr_object.body.pathPaymentOp.destAsset)\n        send_max = Operation.from_xdr_amount(\n            op_xdr_object.body.pathPaymentOp.sendMax)\n        dest_amount = Operation.from_xdr_amount(\n            op_xdr_object.body.pathPaymentOp.destAmount)\n\n        path = []\n        if op_xdr_object.body.pathPaymentOp.path:\n            for x in op_xdr_object.body.pathPaymentOp.path:\n                path.append(Asset.from_xdr_object(x))\n\n        return cls(\n            source=source,\n            destination=destination,\n            send_asset=send_asset,\n            send_max=send_max,\n            dest_asset=dest_asset,\n            dest_amount=dest_amount,\n            path=path)", "response": "Creates a : class:`PathPayment` object from an XDR Operation\n            object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_xdr_object(self):\n        line = self.line.to_xdr_object()\n        limit = Operation.to_xdr_amount(self.limit)\n\n        change_trust_op = Xdr.types.ChangeTrustOp(line, limit)\n        self.body.type = Xdr.const.CHANGE_TRUST\n        self.body.changeTrustOp = change_trust_op\n        return super(ChangeTrust, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents this change trust."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a : class : ChangeTrust object from an XDR Operation object.", "response": "def from_xdr_object(cls, op_xdr_object):\n        \"\"\"Creates a :class:`ChangeTrust` object from an XDR Operation\n        object.\n\n        \"\"\"\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        line = Asset.from_xdr_object(op_xdr_object.body.changeTrustOp.line)\n        limit = Operation.from_xdr_amount(\n            op_xdr_object.body.changeTrustOp.limit)\n\n        return cls(source=source, asset=line, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_xdr_object(self):\n        trustor = account_xdr_object(self.trustor)\n        length = len(self.asset_code)\n        assert length <= 12\n        pad_length = 4 - length if length <= 4 else 12 - length\n        # asset_code = self.asset_code + '\\x00' * pad_length\n        # asset_code = bytearray(asset_code, encoding='utf-8')\n        asset_code = bytearray(self.asset_code, 'ascii') + b'\\x00' * pad_length\n        asset = Xdr.nullclass()\n        if len(asset_code) == 4:\n            asset.type = Xdr.const.ASSET_TYPE_CREDIT_ALPHANUM4\n            asset.assetCode4 = asset_code\n        else:\n            asset.type = Xdr.const.ASSET_TYPE_CREDIT_ALPHANUM12\n            asset.assetCode12 = asset_code\n\n        allow_trust_op = Xdr.types.AllowTrustOp(trustor, asset, self.authorize)\n        self.body.type = Xdr.const.ALLOW_TRUST\n        self.body.allowTrustOp = allow_trust_op\n        return super(AllowTrust, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents thisAllowTrust."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_xdr_object(cls, op_xdr_object):\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n        trustor = encode_check(\n            'account',\n            op_xdr_object.body.allowTrustOp.trustor.ed25519).decode()\n        authorize = op_xdr_object.body.allowTrustOp.authorize\n\n        asset_type = op_xdr_object.body.allowTrustOp.asset.type\n        if asset_type == Xdr.const.ASSET_TYPE_CREDIT_ALPHANUM4:\n            asset_code = (\n                op_xdr_object.body.allowTrustOp.asset.assetCode4.decode())\n        elif asset_type == Xdr.const.ASSET_TYPE_CREDIT_ALPHANUM12:\n            asset_code = (\n                op_xdr_object.body.allowTrustOp.asset.assetCode12.decode())\n        else:\n            raise NotImplementedError(\n                \"Operation of asset_type={} is not implemented\"\n                \".\".format(asset_type.type))\n\n        return cls(\n            source=source,\n            trustor=trustor,\n            authorize=authorize,\n            asset_code=asset_code)", "response": "Creates a : class : AllowTrust object from an XDR Operation\n            object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an XDR Operation object that represents this SetOptions.", "response": "def to_xdr_object(self):\n        \"\"\"Creates an XDR Operation object that represents this\n        :class:`SetOptions`.\n\n        \"\"\"\n\n        def assert_option_array(x):\n            if x is None:\n                return []\n            if not isinstance(x, list):\n                return [x]\n            return x\n\n        if self.inflation_dest is not None:\n            inflation_dest = [account_xdr_object(self.inflation_dest)]\n        else:\n            inflation_dest = []\n\n        self.clear_flags = assert_option_array(self.clear_flags)\n        self.set_flags = assert_option_array(self.set_flags)\n        self.master_weight = assert_option_array(self.master_weight)\n        self.low_threshold = assert_option_array(self.low_threshold)\n        self.med_threshold = assert_option_array(self.med_threshold)\n        self.high_threshold = assert_option_array(self.high_threshold)\n        self.home_domain = assert_option_array(self.home_domain)\n\n        req_signer_fields = (self.signer_address, self.signer_type,\n                             self.signer_weight)\n\n        if all(signer_field is not None for signer_field in req_signer_fields):\n            signer = [\n                Xdr.types.Signer(\n                    signer_key_xdr_object(self.signer_type,\n                                          self.signer_address),\n                    self.signer_weight)\n            ]\n        else:\n            signer = []\n\n        set_options_op = Xdr.types.SetOptionsOp(\n            inflation_dest, self.clear_flags, self.set_flags,\n            self.master_weight, self.low_threshold, self.med_threshold,\n            self.high_threshold, self.home_domain, signer)\n        self.body.type = Xdr.const.SET_OPTIONS\n        self.body.setOptionsOp = set_options_op\n        return super(SetOptions, self).to_xdr_object()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_xdr_object(cls, op_xdr_object):\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        if not op_xdr_object.body.setOptionsOp.inflationDest:\n            inflation_dest = None\n        else:\n            inflation_dest = encode_check(\n                'account', op_xdr_object.body.setOptionsOp.inflationDest[0]\n                    .ed25519).decode()\n\n        clear_flags = op_xdr_object.body.setOptionsOp.clearFlags  # list\n        set_flags = op_xdr_object.body.setOptionsOp.setFlags\n        master_weight = op_xdr_object.body.setOptionsOp.masterWeight\n        low_threshold = op_xdr_object.body.setOptionsOp.lowThreshold\n        med_threshold = op_xdr_object.body.setOptionsOp.medThreshold\n        high_threshold = op_xdr_object.body.setOptionsOp.highThreshold\n        home_domain = op_xdr_object.body.setOptionsOp.homeDomain\n\n        if op_xdr_object.body.setOptionsOp.signer:\n            key = op_xdr_object.body.setOptionsOp.signer[0].key\n            if key.type == Xdr.const.SIGNER_KEY_TYPE_ED25519:\n                signer_address = encode_check('account', key.ed25519).decode()\n                signer_type = 'ed25519PublicKey'\n            if key.type == Xdr.const.SIGNER_KEY_TYPE_PRE_AUTH_TX:\n                signer_address = key.preAuthTx\n                signer_type = 'preAuthTx'\n            if key.type == Xdr.const.SIGNER_KEY_TYPE_HASH_X:\n                signer_address = key.hashX\n                signer_type = 'hashX'\n\n            signer_weight = op_xdr_object.body.setOptionsOp.signer[0].weight\n        else:\n            signer_address = None\n            signer_type = None\n            signer_weight = None\n\n        return cls(\n            source=source,\n            inflation_dest=inflation_dest,\n            clear_flags=clear_flags,\n            set_flags=set_flags,\n            master_weight=master_weight,\n            low_threshold=low_threshold,\n            med_threshold=med_threshold,\n            high_threshold=high_threshold,\n            home_domain=home_domain,\n            signer_address=signer_address,\n            signer_type=signer_type,\n            signer_weight=signer_weight)", "response": "Creates a : class : SetOptions object from an XDR Operation object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an XDR Operation object that represents thisManageOffer.", "response": "def to_xdr_object(self):\n        \"\"\"Creates an XDR Operation object that represents this\n        :class:`ManageOffer`.\n\n        \"\"\"\n        selling = self.selling.to_xdr_object()\n        buying = self.buying.to_xdr_object()\n        price = Operation.to_xdr_price(self.price)\n        price = Xdr.types.Price(price['n'], price['d'])\n\n        amount = Operation.to_xdr_amount(self.amount)\n\n        manage_offer_op = Xdr.types.ManageOfferOp(selling, buying, amount,\n                                                  price, self.offer_id)\n        self.body.type = Xdr.const.MANAGE_OFFER\n        self.body.manageOfferOp = manage_offer_op\n        return super(ManageOffer, self).to_xdr_object()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_xdr_object(self):\n        selling = self.selling.to_xdr_object()\n        buying = self.buying.to_xdr_object()\n\n        price = Operation.to_xdr_price(self.price)\n        price = Xdr.types.Price(price['n'], price['d'])\n\n        amount = Operation.to_xdr_amount(self.amount)\n\n        create_passive_offer_op = Xdr.types.CreatePassiveOfferOp(\n            selling, buying, amount, price)\n        self.body.type = Xdr.const.CREATE_PASSIVE_OFFER\n        self.body.createPassiveOfferOp = create_passive_offer_op\n        return super(CreatePassiveOffer, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents this\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_xdr_object(cls, op_xdr_object):\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        selling = Asset.from_xdr_object(\n            op_xdr_object.body.createPassiveOfferOp.selling)\n        buying = Asset.from_xdr_object(\n            op_xdr_object.body.createPassiveOfferOp.buying)\n        amount = Operation.from_xdr_amount(\n            op_xdr_object.body.createPassiveOfferOp.amount)\n\n        n = op_xdr_object.body.createPassiveOfferOp.price.n\n        d = op_xdr_object.body.createPassiveOfferOp.price.d\n        price = division(n, d)\n        return cls(\n            source=source,\n            selling=selling,\n            buying=buying,\n            amount=amount,\n            price=price)", "response": "Creates a : class : CreatePassiveOffer object from an XDR Operation\n            object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an XDR Operation object that represents this .", "response": "def to_xdr_object(self):\n        \"\"\"Creates an XDR Operation object that represents this\n        :class:`AccountMerge`.\n\n        \"\"\"\n        destination = account_xdr_object(self.destination)\n\n        self.body.type = Xdr.const.ACCOUNT_MERGE\n        self.body.destination = destination\n        return super(AccountMerge, self).to_xdr_object()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a : class : AccountMerge object from an XDR Operation object.", "response": "def from_xdr_object(cls, op_xdr_object):\n        \"\"\"Creates a :class:`AccountMerge` object from an XDR Operation\n        object.\n\n        \"\"\"\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        destination = encode_check(\n            'account', op_xdr_object.body.destination.ed25519).decode()\n\n        return cls(source=source, destination=destination)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_xdr_object(self):\n        self.body.type = Xdr.const.INFLATION\n        return super(Inflation, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents this\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a : class : Inflation object from an XDR Operation object.", "response": "def from_xdr_object(cls, op_xdr_object):\n        \"\"\"Creates a :class:`Inflation` object from an XDR Operation\n        object.\n\n        \"\"\"\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n        return cls(source=source)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_xdr_object(self):\n        data_name = bytearray(self.data_name, encoding='utf-8')\n\n        if self.data_value is not None:\n            if isinstance(self.data_value, bytes):\n                data_value = [bytearray(self.data_value)]\n            else:\n                data_value = [bytearray(self.data_value, 'utf-8')]\n        else:\n            data_value = []\n        manage_data_op = Xdr.types.ManageDataOp(data_name, data_value)\n        self.body.type = Xdr.const.MANAGE_DATA\n        self.body.manageDataOp = manage_data_op\n        return super(ManageData, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents this\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_xdr_object(cls, op_xdr_object):\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        data_name = op_xdr_object.body.manageDataOp.dataName.decode()\n\n        if op_xdr_object.body.manageDataOp.dataValue:\n            data_value = op_xdr_object.body.manageDataOp.dataValue[0]\n        else:\n            data_value = None\n        return cls(source=source, data_name=data_name, data_value=data_value)", "response": "Creates a : class : ManageData object from an XDR Operation\n            object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_xdr_object(self):\n        bump_sequence_op = Xdr.types.BumpSequenceOp(self.bump_to)\n        self.body.type = Xdr.const.BUMP_SEQUENCE\n        self.body.bumpSequenceOp = bump_sequence_op\n        return super(BumpSequence, self).to_xdr_object()", "response": "Creates an XDR Operation object that represents this\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a BumpSequence object from an XDR Operation object.", "response": "def from_xdr_object(cls, op_xdr_object):\n        \"\"\"Creates a :class:`BumpSequence` object from an XDR Operation\n        object.\n\n        \"\"\"\n        if not op_xdr_object.sourceAccount:\n            source = None\n        else:\n            source = encode_check(\n                'account', op_xdr_object.sourceAccount[0].ed25519).decode()\n\n        bump_to = op_xdr_object.body.bumpSequenceOp.bumpTo\n        return cls(source=source, bump_to=bump_to)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an XDR Memo object for a transaction with MEMO_TEXT.", "response": "def to_xdr_object(self):\n        \"\"\"Creates an XDR Memo object for a transaction with MEMO_TEXT.\"\"\"\n        return Xdr.types.Memo(type=Xdr.const.MEMO_TEXT, text=self.text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_xdr_object(self):\n        return Xdr.types.Memo(type=Xdr.const.MEMO_ID, id=self.memo_id)", "response": "Creates an XDR Memo object for a transaction with MEMO_ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_xdr_object(self):\n        return Xdr.types.Memo(type=Xdr.const.MEMO_HASH, hash=self.memo_hash)", "response": "Creates an XDR Memo object for a transaction with MEMO_HASH."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an XDR Memo object for a transaction with MEMO_RETURN.", "response": "def to_xdr_object(self):\n        \"\"\"Creates an XDR Memo object for a transaction with MEMO_RETURN.\"\"\"\n        return Xdr.types.Memo(\n            type=Xdr.const.MEMO_RETURN, retHash=self.memo_return)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef append_op(self, operation):\n        if operation not in self.ops:\n            self.ops.append(operation)\n        return self", "response": "Append an operation to the list of operations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_create_account_op(self,\n                                 destination,\n                                 starting_balance,\n                                 source=None):\n        \"\"\"Append a :class:`CreateAccount\n        <stellar_base.operation.CreateAccount>` operation to the list of\n        operations.\n\n        :param str destination: Account address that is created and funded.\n        :param str starting_balance: Amount of XLM to send to the newly created\n            account. This XLM comes from the source account.\n        :param str source: The source address to deduct funds from to fund the\n            new account.\n        :return: This builder instance.\n\n        \"\"\"\n        op = operation.CreateAccount(destination, starting_balance, source)\n        return self.append_op(op)", "response": "Appends a CreateAccount operation to the list of operations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_trust_op(self, destination, code, limit=None, source=None):  # pragma: no cover\n        warnings.warn(\n            \"append_trust_op will be deprecated in the future, use append_change_trust_op instead.\",\n            PendingDeprecationWarning\n        )  # pragma: no cover\n\n        return self.append_change_trust_op(asset_code=code, asset_issuer=destination, limit=limit,\n                                           source=source)", "response": "Append a change trust operation to the list of operations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nappending a change trust operation to the list of operations.", "response": "def append_change_trust_op(self, asset_code, asset_issuer, limit=None, source=None):\n        \"\"\"Append a :class:`ChangeTrust <stellar_base.operation.ChangeTrust>`\n        operation to the list of operations.\n\n        :param str asset_issuer: The issuer address for the asset.\n        :param str asset_code: The asset code for the asset.\n        :param str limit: The limit of the new trustline.\n        :param str source: The source address to add the trustline to.\n        :return: This builder instance.\n\n        \"\"\"\n        asset = Asset(asset_code, asset_issuer)\n        op = operation.ChangeTrust(asset, limit, source)\n        return self.append_op(op)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append_payment_op(self,\n                          destination,\n                          amount,\n                          asset_code='XLM',\n                          asset_issuer=None,\n                          source=None):\n        \"\"\"Append a :class:`Payment <stellar_base.operation.Payment>` operation\n        to the list of operations.\n\n        :param str destination: Account address that receives the payment.\n        :param str amount: The amount of the currency to send in the payment.\n        :param str asset_code: The asset code for the asset to send.\n        :param asset_issuer: The address of the issuer of the asset.\n        :type asset_issuer: str, None\n        :param str source: The source address of the payment.\n        :return: This builder instance.\n\n        \"\"\"\n        asset = Asset(code=asset_code, issuer=asset_issuer)\n        op = operation.Payment(destination, asset, amount, source)\n        return self.append_op(op)", "response": "Appends a payment operation to the list of operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends a PathPayment operation to the list of operations that can be applied to the destination account.", "response": "def append_path_payment_op(self,\n                               destination,\n                               send_code,\n                               send_issuer,\n                               send_max,\n                               dest_code,\n                               dest_issuer,\n                               dest_amount,\n                               path,\n                               source=None):\n        \"\"\"Append a :class:`PathPayment <stellar_base.operation.PathPayment>`\n        operation to the list of operations.\n\n        :param str destination: The destination address (Account ID) for the\n            payment.\n        :param str send_code: The asset code for the source asset deducted from\n            the source account.\n        :param send_issuer: The address of the issuer of the source asset.\n        :type send_issuer: str, None\n        :param str send_max: The maximum amount of send asset to deduct\n            (excluding fees).\n        :param str dest_code: The asset code for the final destination asset\n            sent to the recipient.\n        :param dest_issuer: Account address that receives the payment.\n        :type dest_issuer: str, None\n        :param str dest_amount: The amount of destination asset the destination\n            account receives.\n        :param list path: A list of asset tuples, each tuple containing a\n            (asset_code, asset_issuer) for each asset in the path. For the native\n            asset, `None` is used for the asset_issuer.\n        :param str source: The source address of the path payment.\n        :return: This builder instance.\n\n        \"\"\"\n        # path: a list of asset tuple which contains asset_code and asset_issuer,\n        # [(asset_code, asset_issuer), (asset_code, asset_issuer)] for native asset you can deliver\n        # ('XLM', None)\n\n        send_asset = Asset(send_code, send_issuer)\n        dest_asset = Asset(dest_code, dest_issuer)\n\n        assets = []\n        for p in path:\n            assets.append(Asset(p[0], p[1]))\n        op = operation.PathPayment(destination, send_asset, send_max,\n                                   dest_asset, dest_amount, assets, source)\n        return self.append_op(op)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nappending an allow trust operation to the list of operations.", "response": "def append_allow_trust_op(self,\n                              trustor,\n                              asset_code,\n                              authorize,\n                              source=None):\n        \"\"\"Append an :class:`AllowTrust <stellar_base.operation.AllowTrust>`\n        operation to the list of operations.\n\n        :param str trustor: The account of the recipient of the trustline.\n        :param str asset_code:  The asset of the trustline the source account\n            is authorizing. For example, if an anchor wants to allow another\n            account to hold its USD credit, the type is USD:anchor.\n        :param bool authorize: Flag indicating whether the trustline is\n            authorized.\n        :param str source: The source address that is establishing the trust in\n            the allow trust operation.\n        :return: This builder instance.\n\n        \"\"\"\n        op = operation.AllowTrust(trustor, asset_code, authorize, source)\n        return self.append_op(op)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef append_set_options_op(self,\n                              inflation_dest=None,\n                              clear_flags=None,\n                              set_flags=None,\n                              master_weight=None,\n                              low_threshold=None,\n                              med_threshold=None,\n                              high_threshold=None,\n                              home_domain=None,\n                              signer_address=None,\n                              signer_type=None,\n                              signer_weight=None,\n                              source=None):\n        \"\"\"Append a :class:`SetOptions <stellar_base.operation.SetOptions>`\n        operation to the list of operations.\n\n        .. _Accounts:\n            https://www.stellar.org/developers/guides/concepts/accounts.html\n\n        :param str inflation_dest: The address in which to send inflation to on\n            an :class:`Inflation <stellar_base.operation.Inflation>` operation.\n        :param int clear_flags: Indicates which flags to clear. For details\n            about the flags, please refer to Stellar's documentation on\n            `Accounts`_. The bit mask integer subtracts from the existing flags\n            of the account. This allows for setting specific bits without\n            knowledge of existing flags.\n        :param int set_flags: Indicates which flags to set. For details about\n            the flags, please refer to Stellar's documentation on `Accounts`_.\n            The bit mask integer adds onto the existing flags of the account.\n            This allows for setting specific bits without knowledge of existing\n            flags.\n        :param int master_weight: Weight of the master key. This account may\n            also add other keys with which to sign transactions using the\n            signer param.\n        :param int low_threshold: A number from 0-255 representing the\n            threshold this account sets on all operations it performs that have\n            a `low threshold\n            <https://www.stellar.org/developers/guides/concepts/multi-sig.html>`_.\n        :param int med_threshold: A number from 0-255 representing the\n            threshold this account sets on all operations it performs that have\n            a `medium threshold\n            <https://www.stellar.org/developers/guides/concepts/multi-sig.html>`_.\n        :param int high_threshold: A number from 0-255 representing the\n            threshold this account sets on all operations it performs that have\n            a `high threshold\n            <https://www.stellar.org/developers/guides/concepts/multi-sig.html>`_.\n        :param str home_domain: Sets the home domain of an account. See\n            Stellar's documentation on `Federation\n            <https://www.stellar.org/developers/guides/concepts/federation.html>`_.\n        :param signer_address: The address of the new signer to add to the\n            source account.\n        :type signer_address: str, bytes\n        :param str signer_type: The type of signer to add to the account. Must\n            be in ('ed25519PublicKey', 'hashX', 'preAuthTx'). See Stellar's\n            documentation for `Multi-Sign\n            <https://www.stellar.org/developers/guides/concepts/multi-sig.html>`_\n            for more information.\n        :param int signer_weight: The weight of the signer. If the weight is 0,\n            the signer will be deleted.\n        :param str source: The source address for which options are being set.\n        :return: This builder instance.\n\n        \"\"\"\n\n        op = operation.SetOptions(inflation_dest, clear_flags, set_flags,\n                                  master_weight, low_threshold, med_threshold,\n                                  high_threshold, home_domain, signer_address,\n                                  signer_type, signer_weight, source)\n        return self.append_op(op)", "response": "Append a SetOptions operation to the list of operations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a HashX signer to an account. Add a HashX signer to an account via a :class:`SetOptions <stellar_base.operation.SetOptions` operation. This is a helper function for :meth:`append_set_options_op`. :param hashx: The address of the new hashX signer. :type hashx: str, bytes :param int signer_weight: The weight of the new signer. :param str source: The source account that is adding a signer to its list of signers. :return: This builder instance.", "response": "def append_hashx_signer(self, hashx, signer_weight, source=None):\n        \"\"\"Add a HashX signer to an account.\n\n        Add a HashX signer to an account via a :class:`SetOptions\n        <stellar_base.operation.SetOptions` operation. This is a helper\n        function for :meth:`append_set_options_op`.\n\n        :param hashx: The address of the new hashX signer.\n        :type hashx: str, bytes\n        :param int signer_weight: The weight of the new signer.\n        :param str source: The source account that is adding a signer to its\n            list of signers.\n        :return: This builder instance.\n\n        \"\"\"\n        return self.append_set_options_op(\n            signer_address=hashx,\n            signer_type='hashX',\n            signer_weight=signer_weight,\n            source=source)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append_pre_auth_tx_signer(self,\n                                  pre_auth_tx,\n                                  signer_weight,\n                                  source=None):\n        \"\"\"Add a PreAuthTx signer to an account.\n\n        Add a PreAuthTx signer to an account via a :class:`SetOptions\n        <stellar_base.operation.SetOptions` operation. This is a helper\n        function for :meth:`append_set_options_op`.\n\n        :param pre_auth_tx: The address of the new preAuthTx signer - obtained by calling `hash_meta` on the TransactionEnvelope.\n        :type pre_auth_tx: str, bytes\n        :param int signer_weight: The weight of the new signer.\n        :param str source: The source account that is adding a signer to its\n            list of signers.\n        :return: This builder instance.\n\n        \"\"\"\n        return self.append_set_options_op(\n            signer_address=pre_auth_tx,\n            signer_type='preAuthTx',\n            signer_weight=signer_weight,\n            source=source)", "response": "Add a PreAuthTx signer to an account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend a manage offer operation to the list of operations.", "response": "def append_manage_offer_op(self,\n                               selling_code,\n                               selling_issuer,\n                               buying_code,\n                               buying_issuer,\n                               amount,\n                               price,\n                               offer_id=0,\n                               source=None):\n        \"\"\"Append a :class:`ManageOffer <stellar_base.operation.ManageOffer>`\n        operation to the list of operations.\n\n        :param str selling_code: The asset code for the asset the offer creator\n            is selling.\n        :param selling_issuer: The issuing address for the asset the offer\n            creator is selling.\n        :type selling_issuer: str, None\n        :param str buying_code: The asset code for the asset the offer creator\n            is buying.\n        :param buying_issuer: The issuing address for the asset the offer\n            creator is selling.\n        :type buying_issuer: str, None\n        :param str amount: Amount of the asset being sold. Set to 0 if you want\n            to delete an existing offer.\n        :param price: Price of 1 unit of selling in terms of buying. You can pass\n            in a number as a string or a dict like `{n: numerator, d: denominator}`\n        :type price: str, dict\n        :param int offer_id: The ID of the offer. 0 for new offer. Set to\n            existing offer ID to update or delete.\n        :param str source: The source address that is managing an offer on\n            Stellar's distributed exchange.\n        :return: This builder instance.\n\n        \"\"\"\n        selling = Asset(selling_code, selling_issuer)\n        buying = Asset(buying_code, buying_issuer)\n        op = operation.ManageOffer(selling, buying, amount, price, offer_id,\n                                   source)\n        return self.append_op(op)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends a CreatePassiveOffer operation to the list of operations.", "response": "def append_create_passive_offer_op(self,\n                                       selling_code,\n                                       selling_issuer,\n                                       buying_code,\n                                       buying_issuer,\n                                       amount,\n                                       price,\n                                       source=None):\n        \"\"\"Append a :class:`CreatePassiveOffer\n        <stellar_base.operation.CreatePassiveOffer>` operation to the list of\n        operations.\n\n        :param str selling_code: The asset code for the asset the offer creator\n            is selling.\n        :param selling_issuer: The issuing address for the asset the offer\n            creator is selling.\n        :type selling_issuer: str, None\n        :param str buying_code: The asset code for the asset the offer creator\n            is buying.\n        :param buying_issuer: The issuing address for the asset the offer\n            creator is selling.\n        :type buying_issuer: str, None\n        :param str amount: Amount of the asset being sold. Set to 0 if you want\n            to delete an existing offer.\n        :param price: Price of 1 unit of selling in terms of buying. You can pass\n            in a number as a string or a dict like `{n: numerator, d: denominator}`\n        :type price: str, dict\n        :param str source: The source address that is creating a passive offer\n            on Stellar's distributed exchange.\n        :return: This builder instance.\n\n        \"\"\"\n        selling = Asset(selling_code, selling_issuer)\n        buying = Asset(buying_code, buying_issuer)\n        op = operation.CreatePassiveOffer(selling, buying, amount, price,\n                                          source)\n        return self.append_op(op)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append_account_merge_op(self, destination, source=None):\n        op = operation.AccountMerge(destination, source)\n        return self.append_op(op)", "response": "Appends a AccountMerge operation to the list of operations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_inflation_op(self, source=None):\n        op = operation.Inflation(source)\n        return self.append_op(op)", "response": "Appends a new inflation operation to the list of operations."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends a ManageData operation to the list of operations.", "response": "def append_manage_data_op(self, data_name, data_value, source=None):\n        \"\"\"Append a :class:`ManageData <stellar_base.operation.ManageData>`\n        operation to the list of operations.\n\n        :param str data_name: String up to 64 bytes long. If this is a new Name\n            it will add the given name/value pair to the account. If this Name\n            is already present then the associated value will be modified.\n        :param data_value: If not present then the existing\n            Name will be deleted. If present then this value will be set in the\n            DataEntry. Up to 64 bytes long.\n        :type data_value: str, bytes, None\n        :param str source: The source account on which data is being managed.\n            operation.\n        :return: This builder instance.\n\n        \"\"\"\n        op = operation.ManageData(data_name, data_value, source)\n        return self.append_op(op)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends a bump sequence operation to the list of operations.", "response": "def append_bump_sequence_op(self, bump_to, source=None):\n        \"\"\"Append a :class:`BumpSequence <stellar_base.operation.BumpSequence>`\n        operation to the list of operations.\n\n        Only available in protocol version 10 and above\n\n        :param int bump_to: Sequence number to bump to.\n        :param str source: The source address that is running the inflation\n            operation.\n        :return: This builder instance.\n\n        \"\"\"\n        op = operation.BumpSequence(bump_to, source)\n        return self.append_op(op)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a memo for the transaction to a new : class : TextMemo containing the memo_text.", "response": "def add_text_memo(self, memo_text):\n        \"\"\"Set the memo for the transaction to a new :class:`TextMemo\n        <stellar_base.memo.TextMemo>`.\n\n        :param memo_text: The text for the memo to add.\n        :type memo_text: str, bytes\n        :return: This builder instance.\n\n        \"\"\"\n        memo_text = memo.TextMemo(memo_text)\n        return self.add_memo(memo_text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_id_memo(self, memo_id):\n        memo_id = memo.IdMemo(memo_id)\n        return self.add_memo(memo_id)", "response": "Add a memo for the transaction to a new : class : IdMemo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a memo for the transaction to a new : class : HashMemo <stellar_base. memo. HashMemo >.", "response": "def add_hash_memo(self, memo_hash):\n        \"\"\"Set the memo for the transaction to a new :class:`HashMemo\n        <stellar_base.memo.HashMemo>`.\n\n        :param memo_hash: A 32 byte hash or hex encoded string to use as the memo.\n        :type memo_hash: bytes, str\n        :return: This builder instance.\n\n        \"\"\"\n        memo_hash = memo.HashMemo(memo_hash)\n        return self.add_memo(memo_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a memo for the transaction to a new : class : RetHashMemo that is used to generate the hash of the transaction.", "response": "def add_ret_hash_memo(self, memo_return):\n        \"\"\"Set the memo for the transaction to a new :class:`RetHashMemo\n        <stellar_base.memo.RetHashMemo>`.\n\n        :param bytes memo_return: A 32 byte hash or hex encoded string intended to be interpreted as\n            the hash of the transaction the sender is refunding.\n        :type memo_return: bytes, str\n        :return: This builder instance.\n\n        \"\"\"\n        memo_return = memo.RetHashMemo(memo_return)\n        return self.add_memo(memo_return)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef federation_payment(self,\n                           fed_address,\n                           amount,\n                           asset_code='XLM',\n                           asset_issuer=None,\n                           source=None,\n                           allow_http=False):\n        \"\"\"Append a :class:`Payment <stellar_base.operation.Payment>` operation\n        to the list of operations using federation on the destination address.\n\n        Translates the destination stellar address to an account ID via\n        :func:`federation <stellar_base.federation.federation>`, before\n        creating a new payment operation via :meth:`append_payment_op`.\n\n        :param str fed_address: A Stellar Address that needs to be translated\n            into a valid account ID via federation.\n        :param str amount: The amount of the currency to send in the payment.\n        :param str asset_code: The asset code for the asset to send.\n        :param str asset_issuer: The address of the issuer of the asset.\n        :param str source: The source address of the payment.\n        :param bool allow_http: When set to `True`, connections to insecure http protocol federation servers\n            will be allowed. Must be set to `False` in production. Default: `False`.\n        :return: This builder instance.\n\n        \"\"\"\n        fed_info = federation(\n            address_or_id=fed_address, fed_type='name', allow_http=allow_http)\n        if not fed_info or not fed_info.get('account_id'):\n            raise FederationError(\n                'Cannot determine Stellar Address to Account ID translation '\n                'via Federation server.')\n        self.append_payment_op(fed_info['account_id'], amount, asset_code,\n                               asset_issuer, source)\n        memo_type = fed_info.get('memo_type')\n        if memo_type is not None and memo_type in ('text', 'id', 'hash'):\n            getattr(self, 'add_' + memo_type.lower() + '_memo')(fed_info['memo'])", "response": "This method creates a new payment operation for a given destination account ID and amount."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a Transaction object from the list of operations contained within this object.", "response": "def gen_tx(self):\n        \"\"\"Generate a :class:`Transaction\n        <stellar_base.transaction.Transaction>` object from the list of\n        operations contained within this object.\n\n        :return: A transaction representing all of the operations that have\n            been appended to this builder.\n        :rtype: :class:`Transaction <stellar_base.transaction.Transaction>`\n\n        \"\"\"\n        if not self.address:\n            raise StellarAddressInvalidError('Transaction does not have any source address.')\n        if self.sequence is None:\n            raise SequenceError('No sequence is present, maybe not funded?')\n        tx = Transaction(\n            source=self.address,\n            sequence=self.sequence,\n            time_bounds=self.time_bounds,\n            memo=self.memo,\n            fee=self.fee * len(self.ops),\n            operations=self.ops)\n        self.tx = tx\n        return tx"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a : class:`TransactionEnvelope <stellar_base. transaction_envelope. TransactionEnvelope > around the generated Transaction via the list of operations in this instance.", "response": "def gen_te(self):\n        \"\"\"Generate a :class:`TransactionEnvelope\n        <stellar_base.transaction_envelope.TransactionEnvelope>` around the\n        generated Transaction via the list of operations in this instance.\n\n        :return: A transaction envelope ready to send over the network.\n        :rtype: :class:`TransactionEnvelope\n            <stellar_base.transaction_envelope.TransactionEnvelope>`\n\n        \"\"\"\n        if self.tx is None:\n            self.gen_tx()\n        te = Te(self.tx, network_id=self.network)\n        if self.te:\n            te.signatures = self.te.signatures\n        self.te = te\n        return te"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gen_compliance_xdr(self):\n        sequence = self.sequence\n        self.sequence = -1\n        tx_xdr = self.gen_tx().xdr()\n        self.sequence = sequence\n        return tx_xdr", "response": "Generate an XDR object representing this builder s transaction to be\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_from_xdr(self, xdr):\n        te = Te.from_xdr(xdr)\n        if self.network.upper() in NETWORKS:\n            te.network_id = Network(NETWORKS[self.network]).network_id()\n        else:\n            te.network_id = Network(self.network).network_id()\n        self.te = te\n        self.tx = te.tx  # with a different source or not .\n        self.ops = te.tx.operations\n        self.address = te.tx.source\n        self.sequence = te.tx.sequence - 1\n        time_bounds_in_xdr = te.tx.time_bounds\n        if time_bounds_in_xdr:\n            self.time_bounds = {\n                'maxTime': time_bounds_in_xdr[0].maxTime,\n                'minTime': time_bounds_in_xdr[0].minTime\n            }\n        else:\n            self.time_bounds = None\n        self.memo = te.tx.memo\n        return self", "response": "Imports the contents of the object from the given XDR object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsigns the generated TransactionEnvelope with the keypair provided.", "response": "def sign(self, secret=None):\n        \"\"\"Sign the generated :class:`TransactionEnvelope\n        <stellar_base.transaction_envelope.TransactionEnvelope>` from the list\n        of this builder's operations.\n\n        :param str secret: The secret seed to use if a key pair or secret was\n            not provided when this class was originaly instantiated, or if\n            another key is being utilized to sign the transaction envelope.\n\n        \"\"\"\n        keypair = self.keypair if not secret else Keypair.from_seed(secret)\n        self.gen_te()\n        self.te.sign(keypair)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsigning the generated transaction envelope using a Hash ( x signature on the the transaction envelope.", "response": "def sign_preimage(self, preimage):\n        \"\"\"Sign the generated transaction envelope using a Hash(x) signature.\n\n        :param preimage: The value to be hashed and used as a signer on the\n            transaction envelope.\n        :type preimage: str, bytes\n\n        \"\"\"\n        if self.te is None:\n            self.gen_te()\n        self.te.sign_hashX(preimage)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new Builder based off of this one with its sequence number incremented.", "response": "def next_builder(self):\n        \"\"\"Create a new builder based off of this one with its sequence number\n        incremented.\n\n        :return: A new Builder instance\n        :rtype: :class:`Builder`\n\n        \"\"\"\n        sequence = self.sequence + 1\n        next_builder = Builder(\n            horizon_uri=self.horizon.horizon_uri,\n            address=self.address,\n            network=self.network,\n            sequence=sequence,\n            fee=self.fee)\n        next_builder.keypair = self.keypair\n        return next_builder"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sequence(self):\n        if not self.address:\n            raise StellarAddressInvalidError('No address provided.')\n\n        address = self.horizon.account(self.address)\n        return int(address.get('sequence'))", "response": "Get the current sequence number for a given account via Horizon."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_dict(self):\n        rv = {'code': self.code}\n        if not self.is_native():\n            rv['issuer'] = self.issuer\n            rv['type'] = self.type\n        else:\n            rv['type'] = 'native'\n        return rv", "response": "Generate a dict representing this object s attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an XDR object for this Asset.", "response": "def to_xdr_object(self):\n        \"\"\"Create an XDR object for this :class:`Asset`.\n\n        :return: An XDR Asset object\n        \"\"\"\n        if self.is_native():\n            xdr_type = Xdr.const.ASSET_TYPE_NATIVE\n            return Xdr.types.Asset(type=xdr_type)\n        else:\n            x = Xdr.nullclass()\n            length = len(self.code)\n            pad_length = 4 - length if length <= 4 else 12 - length\n            x.assetCode = bytearray(self.code, 'ascii') + b'\\x00' * pad_length\n            x.issuer = account_xdr_object(self.issuer)\n        if length <= 4:\n            xdr_type = Xdr.const.ASSET_TYPE_CREDIT_ALPHANUM4\n            return Xdr.types.Asset(type=xdr_type, alphaNum4=x)\n        else:\n            xdr_type = Xdr.const.ASSET_TYPE_CREDIT_ALPHANUM12\n            return Xdr.types.Asset(type=xdr_type, alphaNum12=x)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an base64 encoded XDR string for this asset.", "response": "def xdr(self):\n        \"\"\"Create an base64 encoded XDR string for this :class:`Asset`.\n\n        :return str: A base64 encoded XDR object representing this\n            :class:`Asset`.\n\n        \"\"\"\n        asset = Xdr.StellarXDRPacker()\n        asset.pack_Asset(self.to_xdr_object())\n        return base64.b64encode(asset.get_buffer())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_xdr_object(cls, asset_xdr_object):\n        if asset_xdr_object.type == Xdr.const.ASSET_TYPE_NATIVE:\n            return Asset.native()\n        elif asset_xdr_object.type == Xdr.const.ASSET_TYPE_CREDIT_ALPHANUM4:\n            issuer = encode_check(\n                'account', asset_xdr_object.alphaNum4.issuer.ed25519).decode()\n            code = asset_xdr_object.alphaNum4.assetCode.decode().rstrip('\\x00')\n        else:\n            issuer = encode_check(\n                'account',\n                asset_xdr_object.alphaNum12.issuer.ed25519).decode()\n            code = (\n                asset_xdr_object.alphaNum12.assetCode.decode().rstrip('\\x00'))\n        return cls(code, issuer)", "response": "Create a Asset object from an XDR Asset object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_xdr(cls, xdr):\n        xdr_decoded = base64.b64decode(xdr)\n        asset = Xdr.StellarXDRUnpacker(xdr_decoded)\n        asset_xdr_object = asset.unpack_Asset()\n        asset = Asset.from_xdr_object(asset_xdr_object)\n        return asset", "response": "Create an Asset object from its base64 encoded XDR representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_ID(t):\n    r'[A-Za-z][A-Za-z0-9_]*'\n    if t.value in keywords:\n        t.type = t.value.upper()\n    return t", "response": "r ID is a special character in the URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_constant_def(t):\n    global name_dict\n    id = t[2]\n    value = t[4]\n    lineno = t.lineno(1)\n    if id_unique(id, 'constant', lineno):\n        name_dict[id] = const_info(id, value, lineno)", "response": "A constant definition is a simple statement."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_optional_value(t):\n    # return value or None.\n    t[0] = t[1]\n    # Note this must be unsigned\n    value = t[0]\n    if value is None or value[0].isdigit():\n        return\n    msg = ''\n    if value[0] == '-':\n        msg = \"Can't use negative index %s\" % value\n    elif value not in name_dict:\n        msg = \"Can't derefence index %s\" % value\n    else:\n        data = name_dict[value]\n        if data.type != 'const':\n            msg = \"Can't use non-constant %s %s as index\" % (data.type, value)\n        elif not data.positive:\n            msg = \"Can't use negative index %s\" % value\n    if msg:\n        global error_occurred\n        error_occurred = True\n        print(u\"ERROR - {0:s} near line {1:d}\".format(msg, t.lineno(1)))", "response": "p_optional_value - Print an error message if the optional value is not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_type_def_1(t):\n    # declarations is a type_info\n    d = t[2]\n    lineno = t.lineno(1)\n    sortno = t.lineno(3) + 0.5\n    if d.type == 'void':\n        global error_occurred\n        error_occurred = True\n        print(\n            u\"ERROR - can't use void in typedef at line {0:d}\".format(lineno))\n        return\n    d.lineno = lineno\n    if id_unique(d.id, d.type, lineno):\n        if d.type == 'enum':\n            info = d.create_enum(lineno, sortno)\n        elif d.type == 'struct':\n            info = d.create_struct(lineno, sortno)\n        elif d.type == 'union':\n            info = d.create_union(lineno, sortno)\n        else:\n            info = d\n        name_dict[d.id] = info", "response": "type_def : TYPEDEF declaration SEMI"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_type_def_3(t):\n    id = t[2]\n    body = t[3]\n    lineno = t.lineno(1)\n    if id_unique(id, 'struct', lineno):\n        name_dict[id] = struct_info(id, body, lineno)", "response": "type_def : STRUCT ID struct_body SEMI"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_type_def_4(t):\n    id = t[2]\n    body = t[3]\n    lineno = t.lineno(1)\n    if id_unique(id, 'union', lineno):\n        name_dict[id] = union_info(id, body, lineno)", "response": "type_def : UNION ID union_body SEMI"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntype specifier for 2. 1. 2.", "response": "def p_type_specifier_2(t):\n    \"\"\"type_specifier : INT\n                      | HYPER\n                      | FLOAT\n                      | DOUBLE\n                      | QUADRUPLE\n                      | BOOL\n                      | ID\n                      | UNSIGNED\n                      | enum_type_spec\n                      | struct_type_spec\n                      | union_type_spec\"\"\"\n    # FRED - Note UNSIGNED is not in spec\n    if isinstance(t[1], type_info):\n        t[0] = t[1]\n    else:\n        t[0] = type_info(t[1], t.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_program_def(t):\n    print(\"Ignoring program {0:s} = {1:s}\".format(t[2], t[8]))\n    global name_dict\n    id = t[2]\n    value = t[8]\n    lineno = t.lineno(1)\n    if id_unique(id, 'program', lineno):\n        name_dict[id] = const_info(id, value, lineno)", "response": "P - PROGRAM DEFINE"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_version_def(t):\n    global name_dict\n    id = t[2]\n    value = t[8]\n    lineno = t.lineno(1)\n    if id_unique(id, 'version', lineno):\n        name_dict[id] = const_info(id, value, lineno)", "response": "version_def :  VERSION ID LBRACE procedure_def procedure_def_list RBRACE EQUALS constant SEMI"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_procedure_def(t):\n    global name_dict\n    tid = t[2]\n    value = t[8]\n    lineno = t.lineno(1)\n    if id_unique(tid, 'procedure', lineno):\n        name_dict[tid] = const_info(tid, value, lineno)", "response": "A procedure definition is a block of code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if dict_id not already used. Otherwise invokes error", "response": "def id_unique(dict_id, name, lineno):\n    \"\"\"Returns True if dict_id not already used.  Otherwise, invokes error\"\"\"\n    if dict_id in name_dict:\n        global error_occurred\n        error_occurred = True\n        print(\n            \"ERROR - {0:s} definition {1:s} at line {2:d} conflicts with {3:s}\"\n            .format(name, dict_id, lineno, name_dict[dict_id]))\n        return False\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xdrbody(self, prefix=''):\n        body = ''\n        prefix += indent\n        if self.type == 'enum':\n            body = ''.join(\n                [\"%s,\\n\" % l.xdrout(prefix) for l in self.body[:-1]])\n            body += \"%s\\n\" % self.body[-1].xdrout(prefix)\n        elif self.type == 'struct':\n            body = ''.join([\"%s\\n\" % l.xdrout(prefix) for l in self.body])\n        elif self.type == 'union':\n            for l in self.body[1:-1]:\n                body += ''.join([\"%scase %s:\\n\" % (prefix, case) \\\n                                 for case in l.cases])\n                body += ''.join([\n                    \"%s\\n\" % d.xdrout(prefix + indent) for d in l.declarations\n                ])\n            if self.body[-1].declarations:\n                body += \"%sdefault:\\n\" % prefix + \\\n                        ''.join([\"%s\\n\" % d.xdrout(prefix + indent)\n                                 for d in self.body[-1].declarations])\n        return body", "response": "Return the xdr code for the body of the class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding a string using Base58 with a 4 character checksum", "response": "def b58encode_check(v):\n    \"\"\"Encode a string using Base58 with a 4 character checksum\"\"\"\n\n    digest = sha256(sha256(v).digest()).digest()\n    return b58encode(v + digest[:4])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    '''Base58 encode or decode FILE, or standard input, to standard output.'''\n\n    import sys\n    import argparse\n\n    stdout = buffer(sys.stdout)\n\n    parser = argparse.ArgumentParser(description=main.__doc__)\n    parser.add_argument(\n        'file',\n        metavar='FILE',\n        nargs='?',\n        type=argparse.FileType('r'),\n        default='-')\n    parser.add_argument(\n        '-d', '--decode', action='store_true', help='decode data')\n    parser.add_argument(\n        '-c',\n        '--check',\n        action='store_true',\n        help='append a checksum before encoding')\n\n    args = parser.parse_args()\n    fun = {\n        (False, False): b58encode,\n        (False, True): b58encode_check,\n        (True, False): b58decode,\n        (True, True): b58decode_check\n    }[(args.decode, args.check)]\n\n    data = buffer(args.file).read().rstrip(b'\\n')\n\n    try:\n        result = fun(data)\n    except Exception as e:\n        sys.exit(e)\n\n    if not isinstance(result, bytes):\n        result = result.encode('ascii')\n\n    stdout.write(result)", "response": "Base58 encode or decode FILE or standard input to standard output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef EnableNetworkInterfaces(\n      self, interfaces, logger, dhclient_script=None):\n    \"\"\"Enable the list of network interfaces.\n\n    Args:\n      interfaces: list of string, the output device names to enable.\n      logger: logger object, used to write to SysLog and serial port.\n      dhclient_script: string, the path to a dhclient script used by dhclient.\n    \"\"\"\n    interfaces_to_up = [i for i in interfaces if i != 'eth0']\n    if interfaces_to_up:\n      logger.info('Enabling the Ethernet interfaces %s.', interfaces_to_up)\n      self._Dhcpcd(interfaces_to_up, logger)", "response": "Enable the list of network interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing dhcpcd to activate the interfaces.", "response": "def _Dhcpcd(self, interfaces, logger):\n    \"\"\"Use dhcpcd to activate the interfaces.\n\n    Args:\n      interfaces: list of string, the output device names to enable.\n      logger: logger object, used to write to SysLog and serial port.\n    \"\"\"\n    for interface in interfaces:\n      dhcpcd = ['/sbin/dhcpcd']\n      try:\n        subprocess.check_call(dhcpcd + ['-x', interface])\n      except subprocess.CalledProcessError:\n        # Dhcpcd not yet running for this device.\n        logger.info('Dhcpcd not yet running for interface %s.', interface)\n      try:\n        subprocess.check_call(dhcpcd + [interface])\n      except subprocess.CalledProcessError:\n        # The interface is already active.\n        logger.warning('Could not activate interface %s.', interface)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _CreateInterfaceMapSysfs(self):\n    interfaces = {}\n    for interface in os.listdir('/sys/class/net'):\n      try:\n        mac_address = open(\n            '/sys/class/net/%s/address' % interface).read().strip()\n      except (IOError, OSError) as e:\n        message = 'Unable to determine MAC address for %s. %s.'\n        self.logger.warning(message, interface, str(e))\n      else:\n        interfaces[mac_address] = interface\n    return interfaces", "response": "Create a dictionary mapping MAC addresses to Ethernet interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a dictionary mapping MAC addresses to Ethernet interfaces.", "response": "def _CreateInterfaceMapNetifaces(self):\n    \"\"\"Generate a dictionary mapping MAC address to Ethernet interfaces.\n\n    Returns:\n      dict, string MAC addresses mapped to the string network interface name.\n    \"\"\"\n\n    interfaces = {}\n    for interface in netifaces.interfaces():\n      af_link = netifaces.ifaddresses(interface).get(netifaces.AF_LINK, [])\n      mac_address = next(iter(af_link), {}).get('addr', '')\n      # In some systems this field can come with an empty string or with the\n      # name of the interface when there is no MAC address associated with it.\n      # Check the regex to be sure.\n      if MAC_REGEX.match(mac_address):\n        interfaces[mac_address] = interface\n      else:\n        message = 'Unable to determine MAC address for %s.'\n        self.logger.warning(message, interface)\n    return interfaces"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _RunScripts(self, run_dir=None):\n    with _CreateTempDir(self.script_type, run_dir=run_dir) as dest_dir:\n      try:\n        self.logger.info('Starting %s scripts.', self.script_type)\n        script_dict = self.retriever.GetScripts(dest_dir)\n        self.executor.RunScripts(script_dict)\n      finally:\n        self.logger.info('Finished running %s scripts.', self.script_type)", "response": "Retrieve and execute metadata scripts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetInstanceConfig(self):\n    try:\n      instance_data = self.metadata_dict['instance']['attributes']\n    except KeyError:\n      instance_data = {}\n      self.logger.warning('Instance attributes were not found.')\n\n    try:\n      project_data = self.metadata_dict['project']['attributes']\n    except KeyError:\n      project_data = {}\n      self.logger.warning('Project attributes were not found.')\n\n    return (instance_data.get('google-instance-configs')\n            or project_data.get('google-instance-configs'))", "response": "Get the instance configuration specified in metadata.\n    Returns the instance configuration data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _RunScript(self, script):\n    process = subprocess.Popen(\n        script, shell=True, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)\n    while True:\n      for line in iter(process.stdout.readline, b''):\n        self.logger.info(line.decode('utf-8').rstrip('\\n'))\n      if process.poll() is not None:\n        break", "response": "Runs a script and logs the output of the script."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _GenerateSshKey(self, key_type, key_dest):\n    # Create a temporary file to save the created RSA keys.\n    with tempfile.NamedTemporaryFile(prefix=key_type, delete=True) as temp:\n      temp_key = temp.name\n\n    command = ['ssh-keygen', '-t', key_type, '-f', temp_key, '-N', '', '-q']\n    try:\n      self.logger.info('Generating SSH key %s.', key_dest)\n      subprocess.check_call(command)\n    except subprocess.CalledProcessError:\n      self.logger.warning('Could not create SSH key %s.', key_dest)\n      return\n\n    shutil.move(temp_key, key_dest)\n    shutil.move('%s.pub' % temp_key, '%s.pub' % key_dest)\n\n    file_utils.SetPermissions(key_dest, mode=0o600)\n    file_utils.SetPermissions('%s.pub' % key_dest, mode=0o644)", "response": "Generate a new SSH key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the SSH daemon.", "response": "def _StartSshd(self):\n    \"\"\"Initialize the SSH daemon.\"\"\"\n    # Exit as early as possible.\n    # Instance setup systemd scripts block sshd from starting.\n    if os.path.exists(constants.LOCALBASE + '/bin/systemctl'):\n      return\n    elif (os.path.exists('/etc/init.d/ssh')\n          or os.path.exists('/etc/init/ssh.conf')):\n      subprocess.call(['service', 'ssh', 'start'])\n      subprocess.call(['service', 'ssh', 'reload'])\n    elif (os.path.exists('/etc/init.d/sshd')\n          or os.path.exists('/etc/init/sshd.conf')):\n      subprocess.call(['service', 'sshd', 'start'])\n      subprocess.call(['service', 'sshd', 'reload'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _SetSshHostKeys(self, host_key_types=None):\n    section = 'Instance'\n    instance_id = self._GetInstanceId()\n    if instance_id != self.instance_config.GetOptionString(\n        section, 'instance_id'):\n      self.logger.info('Generating SSH host keys for instance %s.', instance_id)\n      file_regex = re.compile(r'ssh_host_(?P<type>[a-z0-9]*)_key\\Z')\n      key_dir = '/etc/ssh'\n      key_files = [f for f in os.listdir(key_dir) if file_regex.match(f)]\n      key_types = host_key_types.split(',') if host_key_types else []\n      key_types_files = ['ssh_host_%s_key' % key_type for key_type in key_types]\n      for key_file in set(key_files) | set(key_types_files):\n        key_type = file_regex.match(key_file).group('type')\n        key_dest = os.path.join(key_dir, key_file)\n        self._GenerateSshKey(key_type, key_dest)\n      self._StartSshd()\n      self.instance_config.SetOption(section, 'instance_id', str(instance_id))", "response": "Regenerates SSH host keys when the VM is restarted."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the boto config so GSUtil works with provisioned service accounts.", "response": "def _SetupBotoConfig(self):\n    \"\"\"Set the boto config so GSUtil works with provisioned service accounts.\"\"\"\n    project_id = self._GetNumericProjectId()\n    try:\n      boto_config.BotoConfig(project_id, debug=self.debug)\n    except (IOError, OSError) as e:\n      self.logger.warning(str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads a Google Storage URL using an authentication token.", "response": "def _DownloadAuthUrl(self, url, dest_dir):\n    \"\"\"Download a Google Storage URL using an authentication token.\n\n    If the token cannot be fetched, fallback to unauthenticated download.\n\n    Args:\n      url: string, the URL to download.\n      dest_dir: string, the path to a directory for storing metadata scripts.\n\n    Returns:\n      string, the path to the file storing the metadata script.\n    \"\"\"\n    dest_file = tempfile.NamedTemporaryFile(dir=dest_dir, delete=False)\n    dest_file.close()\n    dest = dest_file.name\n\n    self.logger.info(\n        'Downloading url from %s to %s using authentication token.', url, dest)\n\n    if not self.token:\n      response = self.watcher.GetMetadata(\n          self.token_metadata_key, recursive=False, retry=False)\n\n      if not response:\n        self.logger.info(\n            'Authentication token not found. Attempting unauthenticated '\n            'download.')\n        return self._DownloadUrl(url, dest_dir)\n\n      self.token = '%s %s' % (\n          response.get('token_type', ''), response.get('access_token', ''))\n\n    try:\n      request = urlrequest.Request(url)\n      request.add_unredirected_header('Metadata-Flavor', 'Google')\n      request.add_unredirected_header('Authorization', self.token)\n      content = urlrequest.urlopen(request).read().decode('utf-8')\n    except (httpclient.HTTPException, socket.error, urlerror.URLError) as e:\n      self.logger.warning('Could not download %s. %s.', url, str(e))\n      return None\n\n    with open(dest, 'wb') as f:\n      f.write(content)\n\n    return dest"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _DownloadUrl(self, url, dest_dir):\n    dest_file = tempfile.NamedTemporaryFile(dir=dest_dir, delete=False)\n    dest_file.close()\n    dest = dest_file.name\n\n    self.logger.info('Downloading url from %s to %s.', url, dest)\n    try:\n      urlretrieve.urlretrieve(url, dest)\n      return dest\n    except (httpclient.HTTPException, socket.error, urlerror.URLError) as e:\n      self.logger.warning('Could not download %s. %s.', url, str(e))\n    except Exception as e:\n      self.logger.warning('Exception downloading %s. %s.', url, str(e))\n    return None", "response": "Download a script from a given URL."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _DownloadScript(self, url, dest_dir):\n    # Check for the preferred Google Storage URL format:\n    # gs://<bucket>/<object>\n    if url.startswith(r'gs://'):\n      # Convert the string into a standard URL.\n      url = re.sub('^gs://', 'https://storage.googleapis.com/', url)\n      return self._DownloadAuthUrl(url, dest_dir)\n\n    header = r'http[s]?://'\n    domain = r'storage\\.googleapis\\.com'\n\n    # Many of the Google Storage URLs are supported below.\n    # It is prefered that customers specify their object using\n    # its gs://<bucket>/<object> url.\n    bucket = r'(?P<bucket>[a-z0-9][-_.a-z0-9]*[a-z0-9])'\n\n    # Accept any non-empty string that doesn't contain a wildcard character\n    obj = r'(?P<obj>[^\\*\\?]+)'\n\n    # Check for the Google Storage URLs:\n    # http://<bucket>.storage.googleapis.com/<object>\n    # https://<bucket>.storage.googleapis.com/<object>\n    gs_regex = re.compile(r'\\A%s%s\\.%s/%s\\Z' % (header, bucket, domain, obj))\n    match = gs_regex.match(url)\n    if match:\n      return self._DownloadAuthUrl(url, dest_dir)\n\n    # Check for the other possible Google Storage URLs:\n    # http://storage.googleapis.com/<bucket>/<object>\n    # https://storage.googleapis.com/<bucket>/<object>\n    #\n    # The following are deprecated but checked:\n    # http://commondatastorage.googleapis.com/<bucket>/<object>\n    # https://commondatastorage.googleapis.com/<bucket>/<object>\n    gs_regex = re.compile(\n        r'\\A%s(commondata)?%s/%s/%s\\Z' % (header, domain, bucket, obj))\n    match = gs_regex.match(url)\n    if match:\n      return self._DownloadAuthUrl(url, dest_dir)\n\n    # Unauthenticated download of the object.\n    return self._DownloadUrl(url, dest_dir)", "response": "Download the contents of the URL to the destination."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the scripts from the attribute metadata.", "response": "def _GetAttributeScripts(self, attribute_data, dest_dir):\n    \"\"\"Retrieve the scripts from attribute metadata.\n\n    Args:\n      attribute_data: dict, the contents of the attributes metadata.\n      dest_dir: string, the path to a directory for storing metadata scripts.\n\n    Returns:\n      dict, a dictionary mapping metadata keys to files storing scripts.\n    \"\"\"\n    script_dict = {}\n    attribute_data = attribute_data or {}\n    metadata_key = '%s-script' % self.script_type\n    metadata_value = attribute_data.get(metadata_key)\n    if metadata_value:\n      self.logger.info('Found %s in metadata.', metadata_key)\n      with tempfile.NamedTemporaryFile(\n          mode='w', dir=dest_dir, delete=False) as dest:\n        dest.write(metadata_value.lstrip())\n        script_dict[metadata_key] = dest.name\n\n    metadata_key = '%s-script-url' % self.script_type\n    metadata_value = attribute_data.get(metadata_key)\n    if metadata_value:\n      self.logger.info('Found %s in metadata.', metadata_key)\n      script_dict[metadata_key] = self._DownloadScript(\n          metadata_value, dest_dir)\n\n    return script_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the scripts to execute.", "response": "def GetScripts(self, dest_dir):\n    \"\"\"Retrieve the scripts to execute.\n\n    Args:\n      dest_dir: string, the path to a directory for storing metadata scripts.\n\n    Returns:\n      dict, a dictionary mapping set metadata keys with associated scripts.\n    \"\"\"\n    metadata_dict = self.watcher.GetMetadata() or {}\n\n    try:\n      instance_data = metadata_dict['instance']['attributes']\n    except KeyError:\n      instance_data = None\n      self.logger.warning('Instance attributes were not found.')\n\n    try:\n      project_data = metadata_dict['project']['attributes']\n    except KeyError:\n      project_data = None\n      self.logger.warning('Project attributes were not found.')\n\n    return (self._GetAttributeScripts(instance_data, dest_dir)\n            or self._GetAttributeScripts(project_data, dest_dir))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _MakeExecutable(self, metadata_script):\n    mode = os.stat(metadata_script).st_mode\n    os.chmod(metadata_script, mode | stat.S_IEXEC)", "response": "Add executable permissions to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _RunScript(self, metadata_key, metadata_script):\n    process = subprocess.Popen(\n        metadata_script, shell=True,\n        executable=self.default_shell,\n        stderr=subprocess.STDOUT, stdout=subprocess.PIPE)\n    while True:\n      for line in iter(process.stdout.readline, b''):\n        message = line.decode('utf-8', 'replace').rstrip('\\n')\n        if message:\n          self.logger.info('%s: %s', metadata_key, message)\n      if process.poll() is not None:\n        break\n    self.logger.info('%s: Return code %s.', metadata_key, process.returncode)", "response": "Runs a script and logs the output."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RunScripts(self, script_dict):\n    metadata_types = ['%s-script-url', '%s-script']\n    metadata_keys = [key % self.script_type for key in metadata_types]\n    metadata_keys = [key for key in metadata_keys if script_dict.get(key)]\n    if not metadata_keys:\n      self.logger.info('No %s scripts found in metadata.', self.script_type)\n    for metadata_key in metadata_keys:\n      metadata_script = script_dict.get(metadata_key)\n      self._MakeExecutable(metadata_script)\n      self._RunScript(metadata_key, metadata_script)", "response": "Runs the scripts in the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a file header in the config.", "response": "def _AddHeader(self, fp):\n    \"\"\"Create a file header in the config.\n\n    Args:\n      fp: int, a file pointer for writing the header.\n    \"\"\"\n    text = textwrap.wrap(\n        textwrap.dedent(self.config_header), break_on_hyphens=False)\n    fp.write('\\n'.join(['# ' + line for line in text]))\n    fp.write('\\n\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the value of an option in the config file.", "response": "def GetOptionString(self, section, option):\n    \"\"\"Get the value of an option in the config file.\n\n    Args:\n      section: string, the section of the config file to check.\n      option: string, the option to retrieve the value of.\n\n    Returns:\n      string, the value of the option or None if the option doesn't exist.\n    \"\"\"\n    if self.config.has_option(section, option):\n      return self.config.get(section, option)\n    else:\n      return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetOptionBool(self, section, option):\n    return (not self.config.has_option(section, option)\n            or self.config.getboolean(section, option))", "response": "Retrieves the value of an option in the config file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SetOption(self, section, option, value, overwrite=True):\n    if not overwrite and self.config.has_option(section, option):\n      return\n    if not self.config.has_section(section):\n      self.config.add_section(section)\n    self.config.set(section, option, str(value))", "response": "Sets the value of an option in the config file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the config values to a given file.", "response": "def WriteConfig(self, config_file=None):\n    \"\"\"Write the config values to a given file.\n\n    Args:\n      config_file: string, the file location of the config file to write.\n    \"\"\"\n    config_file = config_file or self.config_file\n    config_name = os.path.splitext(os.path.basename(config_file))[0]\n    config_lock = (\n        '%s/lock/google_%s.lock' % (constants.LOCALSTATEDIR, config_name))\n    with file_utils.LockFile(config_lock):\n      with open(config_file, 'w') as config_fp:\n        if self.config_header:\n          self._AddHeader(config_fp)\n        self.config.write(config_fp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a logging object with handlers for sending logs to SysLog.", "response": "def Logger(name, debug=False, facility=None):\n  \"\"\"Get a logging object with handlers for sending logs to SysLog.\n\n  Args:\n    name: string, the name of the logger which will be added to log entries.\n    debug: bool, True if debug output should write to the console.\n    facility: int, an encoding of the SysLog handler's facility and priority.\n\n  Returns:\n    logging object, an object for logging entries.\n  \"\"\"\n  logger = logging.getLogger(name)\n  logger.handlers = []\n  logger.addHandler(logging.NullHandler())\n  logger.propagate = False\n  logger.setLevel(logging.DEBUG)\n  formatter = logging.Formatter(name + ': %(levelname)s %(message)s')\n\n  if debug:\n    # Create a handler for console logging.\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.DEBUG)\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n\n  if facility:\n    # Create a handler for sending logs to SysLog.\n    syslog_handler = logging.handlers.SysLogHandler(\n        address=constants.SYSLOG_SOCKET, facility=facility)\n    syslog_handler.setLevel(logging.INFO)\n    syslog_handler.setFormatter(formatter)\n    logger.addHandler(syslog_handler)\n\n  return logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _CreateSudoersGroup(self):\n    if not self._GetGroup(self.google_sudoers_group):\n      try:\n        command = self.groupadd_cmd.format(group=self.google_sudoers_group)\n        subprocess.check_call(command.split(' '))\n      except subprocess.CalledProcessError as e:\n        self.logger.warning('Could not create the sudoers group. %s.', str(e))\n\n    if not os.path.exists(self.google_sudoers_file):\n      try:\n        with open(self.google_sudoers_file, 'w') as group:\n          message = '%{0} ALL=(ALL:ALL) NOPASSWD:ALL'.format(\n              self.google_sudoers_group)\n          group.write(message)\n      except IOError as e:\n        self.logger.error(\n            'Could not write sudoers file. %s. %s',\n            self.google_sudoers_file, str(e))\n        return\n\n    file_utils.SetPermissions(\n        self.google_sudoers_file, mode=0o440, uid=0, gid=0)", "response": "Create a Linux group for Google added sudo user accounts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _AddUser(self, user):\n    self.logger.info('Creating a new user account for %s.', user)\n\n    command = self.useradd_cmd.format(user=user)\n    try:\n      subprocess.check_call(command.split(' '))\n    except subprocess.CalledProcessError as e:\n      self.logger.warning('Could not create user %s. %s.', user, str(e))\n      return False\n    else:\n      self.logger.info('Created user account %s.', user)\n      return True", "response": "Configure a Linux user account."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the group membership for a Linux user account.", "response": "def _UpdateUserGroups(self, user, groups):\n    \"\"\"Update group membership for a Linux user.\n\n    Args:\n      user: string, the name of the Linux user account.\n      groups: list, the group names to add the user as a member.\n\n    Returns:\n      bool, True if user update succeeded.\n    \"\"\"\n    groups = ','.join(groups)\n    self.logger.debug('Updating user %s with groups %s.', user, groups)\n    command = self.usermod_cmd.format(user=user, groups=groups)\n    try:\n      subprocess.check_call(command.split(' '))\n    except subprocess.CalledProcessError as e:\n      self.logger.warning('Could not update user %s. %s.', user, str(e))\n      return False\n    else:\n      self.logger.debug('Updated user account %s.', user)\n      return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _UpdateAuthorizedKeys(self, user, ssh_keys):\n    pw_entry = self._GetUser(user)\n    if not pw_entry:\n      return\n\n    uid = pw_entry.pw_uid\n    gid = pw_entry.pw_gid\n    home_dir = pw_entry.pw_dir\n    ssh_dir = os.path.join(home_dir, '.ssh')\n\n    # Not all sshd's support multiple authorized_keys files so we have to\n    # share one with the user. We add each of our entries as follows:\n    #  # Added by Google\n    #  authorized_key_entry\n    authorized_keys_file = os.path.join(ssh_dir, 'authorized_keys')\n\n    # Do not write to the authorized keys file if it is a symlink.\n    if os.path.islink(ssh_dir) or os.path.islink(authorized_keys_file):\n      self.logger.warning(\n          'Not updating authorized keys for user %s. File is a symlink.', user)\n      return\n\n    # Create home directory if it does not exist. This can happen if _GetUser\n    # (getpwnam) returns non-local user info (e.g., from LDAP).\n    if not os.path.exists(home_dir):\n        file_utils.SetPermissions(home_dir, mode=0o755, uid=uid, gid=gid,\n            mkdir=True)\n\n    # Create ssh directory if it does not exist.\n    file_utils.SetPermissions(ssh_dir, mode=0o700, uid=uid, gid=gid, mkdir=True)\n\n    # Create entry in the authorized keys file.\n    prefix = self.logger.name + '-'\n    with tempfile.NamedTemporaryFile(\n        mode='w', prefix=prefix, delete=True) as updated_keys:\n      updated_keys_file = updated_keys.name\n      if os.path.exists(authorized_keys_file):\n        lines = open(authorized_keys_file).readlines()\n      else:\n        lines = []\n\n      google_lines = set()\n      for i, line in enumerate(lines):\n        if line.startswith(self.google_comment):\n          google_lines.update([i, i+1])\n\n      # Write user's authorized key entries.\n      for i, line in enumerate(lines):\n        if i not in google_lines and line:\n          line += '\\n' if not line.endswith('\\n') else ''\n          updated_keys.write(line)\n\n      # Write the Google authorized key entries at the end of the file.\n      # Each entry is preceded by '# Added by Google'.\n      for ssh_key in ssh_keys:\n        ssh_key += '\\n' if not ssh_key.endswith('\\n') else ''\n        updated_keys.write('%s\\n' % self.google_comment)\n        updated_keys.write(ssh_key)\n\n      # Write buffered data to the updated keys file without closing it and\n      # update the Linux user's authorized keys file.\n      updated_keys.flush()\n      shutil.copy(updated_keys_file, authorized_keys_file)\n\n    file_utils.SetPermissions(\n        authorized_keys_file, mode=0o600, uid=uid, gid=gid)", "response": "Update the authorized keys file for a Linux user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the sudoer group membership for a Linux user account.", "response": "def _UpdateSudoer(self, user, sudoer=False):\n    \"\"\"Update sudoer group membership for a Linux user account.\n\n    Args:\n      user: string, the name of the Linux user account.\n      sudoer: bool, True if the user should be a sudoer.\n\n    Returns:\n      bool, True if user update succeeded.\n    \"\"\"\n    if sudoer:\n      self.logger.info('Adding user %s to the Google sudoers group.', user)\n      command = self.gpasswd_add_cmd.format(\n          user=user, group=self.google_sudoers_group)\n    else:\n      self.logger.info('Removing user %s from the Google sudoers group.', user)\n      command = self.gpasswd_remove_cmd.format(\n          user=user, group=self.google_sudoers_group)\n\n    try:\n      subprocess.check_call(command.split(' '))\n    except subprocess.CalledProcessError as e:\n      self.logger.warning('Could not update user %s. %s.', user, str(e))\n      return False\n    else:\n      self.logger.debug('Removed user %s from the Google sudoers group.', user)\n      return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an authorized keys file to prevent login.", "response": "def _RemoveAuthorizedKeys(self, user):\n    \"\"\"Remove a Linux user account's authorized keys file to prevent login.\n\n    Args:\n      user: string, the Linux user account to remove access.\n    \"\"\"\n    pw_entry = self._GetUser(user)\n    if not pw_entry:\n      return\n\n    home_dir = pw_entry.pw_dir\n    authorized_keys_file = os.path.join(home_dir, '.ssh', 'authorized_keys')\n    if os.path.exists(authorized_keys_file):\n      try:\n        os.remove(authorized_keys_file)\n      except OSError as e:\n        message = 'Could not remove authorized keys for user %s. %s.'\n        self.logger.warning(message, user, str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the list of configured Google user accounts.", "response": "def GetConfiguredUsers(self):\n    \"\"\"Retrieve the list of configured Google user accounts.\n\n    Returns:\n      list, the username strings of users congfigured by Google.\n    \"\"\"\n    if os.path.exists(self.google_users_file):\n      users = open(self.google_users_file).readlines()\n    else:\n      users = []\n    return [user.strip() for user in users]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SetConfiguredUsers(self, users):\n    prefix = self.logger.name + '-'\n    with tempfile.NamedTemporaryFile(\n        mode='w', prefix=prefix, delete=True) as updated_users:\n      updated_users_file = updated_users.name\n      for user in users:\n        updated_users.write(user + '\\n')\n      updated_users.flush()\n      if not os.path.exists(self.google_users_dir):\n        os.makedirs(self.google_users_dir)\n      shutil.copy(updated_users_file, self.google_users_file)\n\n    file_utils.SetPermissions(self.google_users_file, mode=0o600, uid=0, gid=0)", "response": "Sets the list of configured Google user accounts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef UpdateUser(self, user, ssh_keys):\n    if not bool(USER_REGEX.match(user)):\n      self.logger.warning('Invalid user account name %s.', user)\n      return False\n    if not self._GetUser(user):\n      # User does not exist. Attempt to create the user and add them to the\n      # appropriate user groups.\n      if not (self._AddUser(user)\n              and self._UpdateUserGroups(user, self.groups)):\n        return False\n    # Add the user to the google sudoers group.\n    if not self._UpdateSudoer(user, sudoer=True):\n      return False\n\n    # Don't try to manage account SSH keys with a shell set to disable\n    # logins. This helps avoid problems caused by operator and root sharing\n    # a home directory in CentOS and RHEL.\n    pw_entry = self._GetUser(user)\n    if pw_entry and os.path.basename(pw_entry.pw_shell) == 'nologin':\n      message = 'Not updating user %s. User set `nologin` as login shell.'\n      self.logger.debug(message, user)\n      return True\n\n    try:\n      self._UpdateAuthorizedKeys(user, ssh_keys)\n    except (IOError, OSError) as e:\n      message = 'Could not update the authorized keys file for user %s. %s.'\n      self.logger.warning(message, user, str(e))\n      return False\n    else:\n      return True", "response": "Updates a Linux user account with authorized SSH keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a Linux user account.", "response": "def RemoveUser(self, user):\n    \"\"\"Remove a Linux user account.\n\n    Args:\n      user: string, the Linux user account to remove.\n    \"\"\"\n    self.logger.info('Removing user %s.', user)\n    if self.remove:\n      command = self.userdel_cmd.format(user=user)\n      try:\n        subprocess.check_call(command.split(' '))\n      except subprocess.CalledProcessError as e:\n        self.logger.warning('Could not remove user %s. %s.', user, str(e))\n      else:\n        self.logger.info('Removed user account %s.', user)\n    self._RemoveAuthorizedKeys(user)\n    self._UpdateSudoer(user, sudoer=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _RunOsLoginControl(self, params):\n    try:\n      return subprocess.call([constants.OSLOGIN_CONTROL_SCRIPT] + params)\n    except OSError as e:\n      if e.errno == errno.ENOENT:\n        return None\n      else:\n        raise", "response": "Runs the OS Login control script."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether OS Login is installed.", "response": "def _GetStatus(self, two_factor=False):\n    \"\"\"Check whether OS Login is installed.\n\n    Args:\n      two_factor: bool, True if two factor should be enabled.\n\n    Returns:\n      bool, True if OS Login is installed.\n    \"\"\"\n    params = ['status']\n    if two_factor:\n      params += ['--twofactor']\n    retcode = self._RunOsLoginControl(params)\n    if retcode is None:\n      if self.oslogin_installed:\n        self.logger.warning('OS Login not installed.')\n        self.oslogin_installed = False\n      return None\n\n    # Prevent log spam when OS Login is not installed.\n    self.oslogin_installed = True\n    if not os.path.exists(constants.OSLOGIN_NSS_CACHE):\n      return False\n    return not retcode"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the OS Login NSS cache binary.", "response": "def _RunOsLoginNssCache(self):\n    \"\"\"Run the OS Login NSS cache binary.\n\n    Returns:\n      int, the return code from the call, or None if the script is not found.\n    \"\"\"\n    try:\n      return subprocess.call([constants.OSLOGIN_NSS_CACHE_SCRIPT])\n    except OSError as e:\n      if e.errno == errno.ENOENT:\n        return None\n      else:\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _RemoveOsLoginNssCache(self):\n    if os.path.exists(constants.OSLOGIN_NSS_CACHE):\n      try:\n        os.remove(constants.OSLOGIN_NSS_CACHE)\n      except OSError as e:\n        if e.errno != errno.ENOENT:\n          raise", "response": "Removes the OS Login NSS cache file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef UpdateOsLogin(self, oslogin_desired, two_factor_desired=False):\n    oslogin_configured = self._GetStatus(two_factor=False)\n    if oslogin_configured is None:\n      return None\n    two_factor_configured = self._GetStatus(two_factor=True)\n    # Two factor can only be enabled when OS Login is enabled.\n    two_factor_desired = two_factor_desired and oslogin_desired\n\n    if oslogin_desired:\n      params = ['activate']\n      if two_factor_desired:\n        params += ['--twofactor']\n      # OS Login is desired and not enabled.\n      if not oslogin_configured:\n        self.logger.info('Activating OS Login.')\n        return self._RunOsLoginControl(params) or self._RunOsLoginNssCache()\n      # Enable two factor authentication.\n      if two_factor_desired and not two_factor_configured:\n        self.logger.info('Activating OS Login two factor authentication.')\n        return self._RunOsLoginControl(params) or self._RunOsLoginNssCache()\n      # Deactivate two factor authentication.\n      if two_factor_configured and not two_factor_desired:\n        self.logger.info('Reactivating OS Login with two factor disabled.')\n        return (self._RunOsLoginControl(['deactivate'])\n                or self._RunOsLoginControl(params))\n      # OS Login features are already enabled. Update the cache if appropriate.\n      current_time = time.time()\n      if current_time - self.update_time > NSS_CACHE_DURATION_SEC:\n        self.update_time = current_time\n        return self._RunOsLoginNssCache()\n\n    elif oslogin_configured:\n      self.logger.info('Deactivating OS Login.')\n      return (self._RunOsLoginControl(['deactivate'])\n              or self._RemoveOsLoginNssCache())\n\n    # No action was needed.\n    return 0", "response": "Updates the OS Login features and NSS cache if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef CallDhclient(\n    interfaces, logger, dhclient_script=None):\n  \"\"\"Configure the network interfaces using dhclient.\n\n  Args:\n    interfaces: list of string, the output device names to enable.\n    logger: logger object, used to write to SysLog and serial port.\n    dhclient_script: string, the path to a dhclient script used by dhclient.\n  \"\"\"\n  logger.info('Enabling the Ethernet interfaces %s.', interfaces)\n\n  dhclient_command = ['dhclient']\n\n  if dhclient_script and os.path.exists(dhclient_script):\n    dhclient_command += ['-sf', dhclient_script]\n\n  try:\n    subprocess.check_call(dhclient_command + ['-x'] + interfaces)\n    subprocess.check_call(dhclient_command + interfaces)\n  except subprocess.CalledProcessError:\n    logger.warning('Could not enable interfaces %s.', interfaces)", "response": "Configure the network interfaces using dhclient."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef CallNtpdate(logger):\n  ntpd_inactive = subprocess.call(['service', 'ntpd', 'status'])\n  try:\n    if not ntpd_inactive:\n      subprocess.check_call(['service', 'ntpd', 'stop'])\n    subprocess.check_call(\n        'ntpdate `awk \\'$1==\"server\" {print $2}\\' /etc/ntp.conf`', shell=True)\n    if not ntpd_inactive:\n      subprocess.check_call(['service', 'ntpd', 'start'])\n  except subprocess.CalledProcessError:\n    logger.warning('Failed to sync system time with ntp server.')\n  else:\n    logger.info('Synced system time with ntp server.')", "response": "Syncs the system time using ntpdate."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef EnableNetworkInterfaces(self, interfaces):\n    # The default Ethernet interface is enabled by default. Do not attempt to\n    # enable interfaces if only one interface is specified in metadata.\n    if not interfaces or set(interfaces) == self.interfaces:\n      return\n\n    self.logger.info('Ethernet interfaces: %s.', interfaces)\n    self.interfaces = set(interfaces)\n\n    if self.dhcp_command:\n      try:\n        subprocess.check_call([self.dhcp_command])\n      except subprocess.CalledProcessError:\n        self.logger.warning('Could not enable Ethernet interfaces.')\n      return\n\n    # Distro-specific setup for network interfaces.\n    self.distro_utils.EnableNetworkInterfaces(\n        interfaces, self.logger, dhclient_script=self.dhclient_script)", "response": "Enable the list of network interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef EnableNetworkInterfaces(\n      self, interfaces, logger, dhclient_script=None):\n    \"\"\"Enable the list of network interfaces.\n\n    Args:\n      interfaces: list of string, the output device names to enable.\n      logger: logger object, used to write to SysLog and serial port.\n      dhclient_script: string, the path to a dhclient script used by dhclient.\n    \"\"\"\n    helpers.CallDhclient(interfaces, logger, dhclient_script=dhclient_script)", "response": "Enable the list of network interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _GetNumericProjectId(self):\n    project_id = 'project/numeric-project-id'\n    return self.watcher.GetMetadata(metadata_key=project_id, recursive=False)", "response": "Get the numeric project ID for this VM."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the boto config file to support standalone GSUtil.", "response": "def _CreateConfig(self, project_id):\n    \"\"\"Create the boto config to support standalone GSUtil.\n\n    Args:\n      project_id: string, the project ID to use in the config file.\n    \"\"\"\n    project_id = project_id or self._GetNumericProjectId()\n\n    # Our project doesn't support service accounts.\n    if not project_id:\n      return\n\n    self.boto_config_header %= (\n        self.boto_config_script, self.boto_config_template)\n    config = config_manager.ConfigManager(\n        config_file=self.boto_config_template,\n        config_header=self.boto_config_header)\n    boto_dir = os.path.dirname(self.boto_config_script)\n\n    config.SetOption('GSUtil', 'default_project_id', project_id)\n    config.SetOption('GSUtil', 'default_api_version', '2')\n    config.SetOption('GoogleCompute', 'service_account', 'default')\n    config.SetOption('Plugin', 'plugin_directory', boto_dir)\n    config.WriteConfig(config_file=self.boto_config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _CreateRouteOptions(self, **kwargs):\n    options = {\n        'proto': self.proto_id,\n        'scope': 'host',\n    }\n    options.update(kwargs)\n    return options", "response": "Create a dictionary of parameters to append to the ip route command."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _RunIpRoute(self, args=None, options=None):\n    args = args or []\n    options = options or {}\n    command = ['ip', 'route']\n    command.extend(args)\n    for item in options.items():\n      command.extend(item)\n    try:\n      process = subprocess.Popen(\n          command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n      stdout, stderr = process.communicate()\n    except OSError as e:\n      self.logger.warning('Exception running %s. %s.', command, str(e))\n    else:\n      if process.returncode:\n        message = 'Non-zero exit status running %s. %s.'\n        self.logger.warning(message, command, stderr.strip())\n      else:\n        return stdout.decode('utf-8', 'replace')\n    return ''", "response": "Runs a command with ip route and return the standard output."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ParseForwardedIps(self, forwarded_ips):\n    addresses = []\n    forwarded_ips = forwarded_ips or []\n    for ip in forwarded_ips:\n      if ip and (IP_REGEX.match(ip) or IP_ALIAS_REGEX.match(ip)):\n        addresses.append(ip[:-3] if ip.endswith('/32') else ip)\n      else:\n        self.logger.warning('Could not parse IP address: \"%s\".', ip)\n    return addresses", "response": "Parses and validates the forwarded IP addresses."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetForwardedIps(self, interface, interface_ip=None):\n    args = ['ls', 'table', 'local', 'type', 'local']\n    options = self._CreateRouteOptions(dev=interface)\n    result = self._RunIpRoute(args=args, options=options)\n    result = re.sub(r'local\\s', r'', result)\n    return self.ParseForwardedIps(result.split())", "response": "Retrieves the list of configured forwarded IP addresses."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new IP address to the network interface.", "response": "def AddForwardedIp(self, address, interface):\n    \"\"\"Configure a new IP address on the network interface.\n\n    Args:\n      address: string, the IP address to configure.\n      interface: string, the output device to use.\n    \"\"\"\n    address = address if IP_ALIAS_REGEX.match(address) else '%s/32' % address\n    args = ['add', 'to', 'local', address]\n    options = self._CreateRouteOptions(dev=interface)\n    self._RunIpRoute(args=args, options=options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ParseForwardedIps(self, forwarded_ips):\n    addresses = []\n    forwarded_ips = forwarded_ips or []\n    for ip in forwarded_ips:\n      if ip and (IP_REGEX.match(ip) or IP_ALIAS_REGEX.match(ip)):\n        addresses.extend([str(addr) for addr in list(netaddr.IPNetwork(ip))])\n      else:\n        self.logger.warning('Could not parse IP address: \"%s\".', ip)\n    return addresses", "response": "Parse and validate forwarded IP addresses."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the list of forwarded IP addresses for the given interface.", "response": "def GetForwardedIps(self, interface, interface_ip=None):\n    \"\"\"Retrieve the list of configured forwarded IP addresses.\n\n    Args:\n      interface: string, the output device to query.\n      interface_ip: string, current interface ip address.\n\n    Returns:\n      list, the IP address strings.\n    \"\"\"\n    try:\n      ips = netifaces.ifaddresses(interface)\n      ips = ips[netifaces.AF_INET]\n    except (ValueError, IndexError):\n      return []\n    forwarded_ips = []\n    for ip in ips:\n      if ip['addr'] != interface_ip:\n        full_addr = '%s/%d' % (ip['addr'], netaddr.IPAddress(ip['netmask']).netmask_bits())\n        forwarded_ips.append(full_addr)\n    return self.ParseForwardedIps(forwarded_ips)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AddForwardedIp(self, address, interface):\n    for ip in list(netaddr.IPNetwork(address)):\n      self._RunIfconfig(args=[interface, 'alias', '%s/32' % str(ip)])", "response": "Adds a new IP address on the network interface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RemoveForwardedIp(self, address, interface):\n    ip = netaddr.IPNetwork(address)\n    self._RunIfconfig(args=[interface, '-alias', str(ip.ip)])", "response": "Removes an IP address on the network interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _GetGsScopes(self):\n    service_accounts = self.watcher.GetMetadata(metadata_key=self.metadata_key)\n    try:\n      scopes = service_accounts[self.service_account]['scopes']\n      return list(GS_SCOPES.intersection(set(scopes))) if scopes else None\n    except KeyError:\n      return None", "response": "Returns all Google Storage scopes available on this VM."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _GetAccessToken(self):\n    service_accounts = self.watcher.GetMetadata(metadata_key=self.metadata_key)\n    try:\n      return service_accounts[self.service_account]['token']['access_token']\n    except KeyError:\n      return None", "response": "Return an OAuth 2. 0 access token for Google Storage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when clock drift token has changed.", "response": "def HandleClockSync(self, response):\n    \"\"\"Called when clock drift token changes.\n\n    Args:\n      response: string, the metadata response with the new drift token value.\n    \"\"\"\n    self.logger.info('Clock drift token has changed: %s.', response)\n    self.distro_utils.HandleClockSync(self.logger)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef EnableNetworkInterfaces(\n      self, interfaces, logger, dhclient_script=None):\n    \"\"\"Enable the list of network interfaces.\n\n    Args:\n      interfaces: list of string, the output device names to enable.\n      logger: logger object, used to write to SysLog and serial port.\n      dhclient_script: string, the path to a dhclient script used by dhclient.\n    \"\"\"\n    # Should always exist in EL 7.\n    if os.path.exists(self.network_path):\n      self._DisableNetworkManager(interfaces, logger)\n    helpers.CallDhclient(interfaces, logger)", "response": "Enable the list of network interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisabling network manager management on a list of network interfaces.", "response": "def _DisableNetworkManager(self, interfaces, logger):\n    \"\"\"Disable network manager management on a list of network interfaces.\n\n    Args:\n      interfaces: list of string, the output device names enable.\n      logger: logger object, used to write to SysLog and serial port.\n    \"\"\"\n    for interface in interfaces:\n      interface_config = os.path.join(\n          self.network_path, 'ifcfg-%s' % interface)\n      if os.path.exists(interface_config):\n        self._ModifyInterface(\n            interface_config, 'DEVICE', interface, replace=False)\n        self._ModifyInterface(\n            interface_config, 'NM_CONTROLLED', 'no', replace=True)\n      else:\n        with open(interface_config, 'w') as interface_file:\n          interface_content = [\n              '# Added by Google.',\n              'BOOTPROTO=none',\n              'DEFROUTE=no',\n              'DEVICE=%s' % interface,\n              'IPV6INIT=no',\n              'NM_CONTROLLED=no',\n              'NOZEROCONF=yes',\n              '',\n          ]\n          interface_file.write('\\n'.join(interface_content))\n        logger.info('Created config file for interface %s.', interface)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ModifyInterface(\n      self, interface_config, config_key, config_value, replace=False):\n    \"\"\"Write a value to a config file if not already present.\n\n    Args:\n      interface_config: string, the path to a config file.\n      config_key: string, the configuration key to set.\n      config_value: string, the value to set for the configuration key.\n      replace: bool, replace the configuration option if already present.\n    \"\"\"\n    config_entry = '%s=%s' % (config_key, config_value)\n    if not open(interface_config).read().count(config_key):\n      with open(interface_config, 'a') as config:\n        config.write('%s\\n' % config_entry)\n    elif replace:\n      for line in fileinput.input(interface_config, inplace=True):\n        print(re.sub(r'%s=.*' % config_key, config_entry, line.rstrip()))", "response": "Modify a value in a config file if not already present."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _HasExpired(self, key):\n    self.logger.debug('Processing key: %s.', key)\n\n    try:\n      schema, json_str = key.split(None, 3)[2:]\n    except (ValueError, AttributeError):\n      self.logger.debug('No schema identifier. Not expiring key.')\n      return False\n\n    if schema != 'google-ssh':\n      self.logger.debug('Invalid schema %s. Not expiring key.', schema)\n      return False\n\n    try:\n      json_obj = json.loads(json_str)\n    except ValueError:\n      self.logger.debug('Invalid JSON %s. Not expiring key.', json_str)\n      return False\n\n    if 'expireOn' not in json_obj:\n      self.logger.debug('No expiration timestamp. Not expiring key.')\n      return False\n\n    expire_str = json_obj['expireOn']\n    format_str = '%Y-%m-%dT%H:%M:%S+0000'\n    try:\n      expire_time = datetime.datetime.strptime(expire_str, format_str)\n    except ValueError:\n      self.logger.warning(\n          'Expiration timestamp \"%s\" not in format %s. Not expiring key.',\n          expire_str, format_str)\n      return False\n\n    # Expire the key if and only if we have exceeded the expiration timestamp.\n    return datetime.datetime.utcnow() > expire_time", "response": "Checks whether a key has expired."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the SSH key data into a user map.", "response": "def _ParseAccountsData(self, account_data):\n    \"\"\"Parse the SSH key data into a user map.\n\n    Args:\n      account_data: string, the metadata server SSH key attributes data.\n\n    Returns:\n      dict, a mapping of the form: {'username': ['sshkey1, 'sshkey2', ...]}.\n    \"\"\"\n    if not account_data:\n      return {}\n    lines = [line for line in account_data.splitlines() if line]\n    user_map = {}\n    for line in lines:\n      if not all(ord(c) < 128 for c in line):\n        self.logger.info('SSH key contains non-ascii character: %s.', line)\n        continue\n      split_line = line.split(':', 1)\n      if len(split_line) != 2:\n        self.logger.info('SSH key is not a complete entry: %s.', split_line)\n        continue\n      user, key = split_line\n      if self._HasExpired(key):\n        self.logger.debug('Expired SSH key for user %s: %s.', user, key)\n        continue\n      if user not in user_map:\n        user_map[user] = []\n      user_map[user].append(key)\n    logging.debug('User accounts: %s.', user_map)\n    return user_map"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting dictionaries for instance and project attributes.", "response": "def _GetInstanceAndProjectAttributes(self, metadata_dict):\n    \"\"\"Get dictionaries for instance and project attributes.\n\n    Args:\n      metadata_dict: json, the deserialized contents of the metadata server.\n\n    Returns:\n      tuple, two dictionaries for instance and project attributes.\n    \"\"\"\n    metadata_dict = metadata_dict or {}\n\n    try:\n      instance_data = metadata_dict['instance']['attributes']\n    except KeyError:\n      instance_data = {}\n      self.logger.warning('Instance attributes were not found.')\n\n    try:\n      project_data = metadata_dict['project']['attributes']\n    except KeyError:\n      project_data = {}\n      self.logger.warning('Project attributes were not found.')\n\n    return instance_data, project_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GetAccountsData(self, metadata_dict):\n    instance_data, project_data = self._GetInstanceAndProjectAttributes(\n        metadata_dict)\n    valid_keys = [instance_data.get('sshKeys'), instance_data.get('ssh-keys')]\n    block_project = instance_data.get('block-project-ssh-keys', '').lower()\n    if block_project != 'true' and not instance_data.get('sshKeys'):\n      valid_keys.append(project_data.get('ssh-keys'))\n      valid_keys.append(project_data.get('sshKeys'))\n    accounts_data = '\\n'.join([key for key in valid_keys if key])\n    return self._ParseAccountsData(accounts_data)", "response": "Get the user accounts specified in metadata server contents."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprovision and update Linux user accounts based on account metadata.", "response": "def _UpdateUsers(self, update_users):\n    \"\"\"Provision and update Linux user accounts based on account metadata.\n\n    Args:\n      update_users: dict, authorized users mapped to their public SSH keys.\n    \"\"\"\n    for user, ssh_keys in update_users.items():\n      if not user or user in self.invalid_users:\n        continue\n      configured_keys = self.user_ssh_keys.get(user, [])\n      if set(ssh_keys) != set(configured_keys):\n        if not self.utils.UpdateUser(user, ssh_keys):\n          self.invalid_users.add(user)\n        else:\n          self.user_ssh_keys[user] = ssh_keys[:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the value of the enable - oslogin metadata key.", "response": "def _GetEnableOsLoginValue(self, metadata_dict):\n    \"\"\"Get the value of the enable-oslogin metadata key.\n\n    Args:\n      metadata_dict: json, the deserialized contents of the metadata server.\n\n    Returns:\n      bool, True if OS Login is enabled for VM access.\n    \"\"\"\n    instance_data, project_data = self._GetInstanceAndProjectAttributes(\n        metadata_dict)\n    instance_value = instance_data.get('enable-oslogin')\n    project_value = project_data.get('enable-oslogin')\n    value = instance_value or project_value or ''\n\n    return value.lower() == 'true'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef HandleAccounts(self, result):\n    self.logger.debug('Checking for changes to user accounts.')\n    configured_users = self.utils.GetConfiguredUsers()\n    enable_oslogin = self._GetEnableOsLoginValue(result)\n    enable_two_factor = self._GetEnableTwoFactorValue(result)\n    if enable_oslogin:\n      desired_users = {}\n      self.oslogin.UpdateOsLogin(True, two_factor_desired=enable_two_factor)\n    else:\n      desired_users = self._GetAccountsData(result)\n      self.oslogin.UpdateOsLogin(False)\n    remove_users = sorted(set(configured_users) - set(desired_users.keys()))\n    self._UpdateUsers(desired_users)\n    self._RemoveUsers(remove_users)\n    self.utils.SetConfiguredUsers(desired_users.keys())", "response": "Called when there are changes to the contents of the metadata server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _SetSELinuxContext(path):\n  restorecon = '/sbin/restorecon'\n  if os.path.isfile(restorecon) and os.access(restorecon, os.X_OK):\n    subprocess.call([restorecon, path])", "response": "Set the appropriate SELinux context if SELinux tools are installed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SetPermissions(path, mode=None, uid=None, gid=None, mkdir=False):\n  if mkdir and not os.path.exists(path):\n    os.mkdir(path, mode or 0o777)\n  elif mode:\n    os.chmod(path, mode)\n  if uid and gid:\n    os.chown(path, uid, gid)\n  _SetSELinuxContext(path)", "response": "Sets the permissions and ownership of a path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlock the provided file descriptor.", "response": "def Lock(fd, path, blocking):\n  \"\"\"Lock the provided file descriptor.\n\n  Args:\n    fd: int, the file descriptor of the file to lock.\n    path: string, the name of the file to lock.\n    blocking: bool, whether the function should return immediately.\n\n  Raises:\n    IOError, raised from flock while attempting to lock a file.\n  \"\"\"\n  operation = fcntl.LOCK_EX if blocking else fcntl.LOCK_EX | fcntl.LOCK_NB\n  try:\n    fcntl.flock(fd, operation)\n  except IOError as e:\n    if e.errno == errno.EWOULDBLOCK:\n      raise IOError('Exception locking %s. File already locked.' % path)\n    else:\n      raise IOError('Exception locking %s. %s.' % (path, str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrelease the lock on the file. Args: fd: int, the file descriptor of the file to unlock. path: string, the name of the file to lock. Raises: IOError, raised from flock while attempting to release a file lock.", "response": "def Unlock(fd, path):\n  \"\"\"Release the lock on the file.\n\n  Args:\n    fd: int, the file descriptor of the file to unlock.\n    path: string, the name of the file to lock.\n\n  Raises:\n    IOError, raised from flock while attempting to release a file lock.\n  \"\"\"\n  try:\n    fcntl.flock(fd, fcntl.LOCK_UN | fcntl.LOCK_NB)\n  except IOError as e:\n    if e.errno == errno.EWOULDBLOCK:\n      raise IOError('Exception unlocking %s. Locked by another process.' % path)\n    else:\n      raise IOError('Exception unlocking %s. %s.' % (path, str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninterfaces to flock - based file locking.", "response": "def LockFile(path, blocking=False):\n  \"\"\"Interface to flock-based file locking to prevent concurrent executions.\n\n  Args:\n    path: string, the name of the file to lock.\n    blocking: bool, whether the function should return immediately.\n\n  Yields:\n    None, yields when a lock on the file is obtained.\n\n  Raises:\n    IOError, raised from flock locking operations on a file.\n    OSError, raised from file operations.\n  \"\"\"\n  fd = os.open(path, os.O_CREAT)\n  try:\n    Lock(fd, path, blocking)\n    yield\n  finally:\n    try:\n      Unlock(fd, path)\n    finally:\n      os.close(fd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef RetryOnUnavailable(func):\n\n  @functools.wraps(func)\n  def Wrapper(*args, **kwargs):\n    while True:\n      try:\n        response = func(*args, **kwargs)\n      except (httpclient.HTTPException, socket.error, urlerror.URLError) as e:\n        time.sleep(5)\n        if (isinstance(e, urlerror.HTTPError)\n            and e.getcode() == httpclient.SERVICE_UNAVAILABLE):\n          continue\n        elif isinstance(e, socket.timeout):\n          continue\n        raise\n      else:\n        if response.getcode() == httpclient.OK:\n          return response\n        else:\n          raise StatusException(response)\n  return Wrapper", "response": "Decorator to retry on a service unavailable exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _GetMetadataRequest(self, metadata_url, params=None, timeout=None):\n    headers = {'Metadata-Flavor': 'Google'}\n    params = urlparse.urlencode(params or {})\n    url = '%s?%s' % (metadata_url, params)\n    request = urlrequest.Request(url, headers=headers)\n    request_opener = urlrequest.build_opener(urlrequest.ProxyHandler({}))\n    timeout = timeout or self.timeout\n    return request_opener.open(request, timeout=timeout*1.1)", "response": "Perform a GET request on the specified URL."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the etag in the response header.", "response": "def _UpdateEtag(self, response):\n    \"\"\"Update the etag from an API response.\n\n    Args:\n      response: HTTP response with a header field.\n\n    Returns:\n      bool, True if the etag in the response header updated.\n    \"\"\"\n    etag = response.headers.get('etag', self.etag)\n    etag_updated = self.etag != etag\n    self.etag = etag\n    return etag_updated"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GetMetadataUpdate(\n      self, metadata_key='', recursive=True, wait=True, timeout=None):\n    \"\"\"Request the contents of metadata server and deserialize the response.\n\n    Args:\n      metadata_key: string, the metadata key to watch for changes.\n      recursive: bool, True if we should recursively watch for metadata changes.\n      wait: bool, True if we should wait for a metadata change.\n      timeout: int, timeout in seconds for returning metadata output.\n\n    Returns:\n      json, the deserialized contents of the metadata server.\n    \"\"\"\n    metadata_key = os.path.join(metadata_key, '') if recursive else metadata_key\n    metadata_url = os.path.join(METADATA_SERVER, metadata_key)\n    params = {\n        'alt': 'json',\n        'last_etag': self.etag,\n        'recursive': recursive,\n        'timeout_sec': timeout or self.timeout,\n        'wait_for_change': wait,\n    }\n    while True:\n      response = self._GetMetadataRequest(\n          metadata_url, params=params, timeout=timeout)\n      etag_updated = self._UpdateEtag(response)\n      if wait and not etag_updated and not timeout:\n        # Retry until the etag is updated.\n        continue\n      else:\n        # One of the following are true:\n        # - Waiting for change is not required.\n        # - The etag is updated.\n        # - The user specified a request timeout.\n        break\n    return json.loads(response.read().decode('utf-8'))", "response": "Request the contents of the metadata server and deserialize the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the metadata update request.", "response": "def _HandleMetadataUpdate(\n      self, metadata_key='', recursive=True, wait=True, timeout=None,\n      retry=True):\n    \"\"\"Wait for a successful metadata response.\n\n    Args:\n      metadata_key: string, the metadata key to watch for changes.\n      recursive: bool, True if we should recursively watch for metadata changes.\n      wait: bool, True if we should wait for a metadata change.\n      timeout: int, timeout in seconds for returning metadata output.\n      retry: bool, True if we should retry on failure.\n\n    Returns:\n      json, the deserialized contents of the metadata server.\n    \"\"\"\n    exception = None\n    while True:\n      try:\n        return self._GetMetadataUpdate(\n            metadata_key=metadata_key, recursive=recursive, wait=wait,\n            timeout=timeout)\n      except (httpclient.HTTPException, socket.error, urlerror.URLError) as e:\n        if not isinstance(e, type(exception)):\n          exception = e\n          self.logger.error('GET request error retrieving metadata. %s.', e)\n        if retry:\n          continue\n        else:\n          break"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwatch for changes to the contents of the metadata server.", "response": "def WatchMetadata(\n      self, handler, metadata_key='', recursive=True, timeout=None):\n    \"\"\"Watch for changes to the contents of the metadata server.\n\n    Args:\n      handler: callable, a function to call with the updated metadata contents.\n      metadata_key: string, the metadata key to watch for changes.\n      recursive: bool, True if we should recursively watch for metadata changes.\n      timeout: int, timeout in seconds for returning metadata output.\n    \"\"\"\n    while True:\n      response = self._HandleMetadataUpdate(\n          metadata_key=metadata_key, recursive=recursive, wait=True,\n          timeout=timeout)\n      try:\n        handler(response)\n      except Exception as e:\n        self.logger.exception('Exception calling the response handler. %s.', e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetMetadata(\n      self, metadata_key='', recursive=True, timeout=None, retry=True):\n    \"\"\"Retrieve the contents of metadata server for a metadata key.\n\n    Args:\n      metadata_key: string, the metadata key to watch for changes.\n      recursive: bool, True if we should recursively watch for metadata changes.\n      timeout: int, timeout in seconds for returning metadata output.\n      retry: bool, True if we should retry on failure.\n\n    Returns:\n      json, the deserialized contents of the metadata server or None if error.\n    \"\"\"\n    return self._HandleMetadataUpdate(\n        metadata_key=metadata_key, recursive=recursive, wait=False,\n        timeout=timeout, retry=retry)", "response": "Retrieves the contents of the metadata server for a metadata key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog the forwarded IP addresses.", "response": "def _LogForwardedIpChanges(\n      self, configured, desired, to_add, to_remove, interface):\n    \"\"\"Log the planned IP address changes.\n\n    Args:\n      configured: list, the IP address strings already configured.\n      desired: list, the IP address strings that will be configured.\n      to_add: list, the forwarded IP address strings to configure.\n      to_remove: list, the forwarded IP address strings to delete.\n      interface: string, the output device to modify.\n    \"\"\"\n    if not to_add and not to_remove:\n      return\n    self.logger.info(\n        'Changing %s IPs from %s to %s by adding %s and removing %s.',\n        interface, configured or None, desired or None, to_add or None,\n        to_remove or None)"}
