{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef substitute_vids(library, statement):\n    from ambry.identity import ObjectNumber, TableNumber, NotObjectNumberError\n    from ambry.orm.exc import NotFoundError\n\n    try:\n        stmt_str = statement.to_unicode()\n    except AttributeError:\n        stmt_str = statement\n\n    parts = stmt_str.strip(';').split()\n\n    new_parts = []\n\n    tables = set()\n    partitions = set()\n\n    while parts:\n        token = parts.pop(0).strip()\n        if token.lower() in ('from', 'join', 'materialize', 'install'):\n            ident = parts.pop(0).strip(';')\n            new_parts.append(token)\n\n            try:\n                obj_number = ObjectNumber.parse(token)\n                if isinstance(obj_number, TableNumber):\n                    table = library.table(ident)\n                    tables.add(table.vid)\n                    new_parts.append(table.vid)\n                else:\n                    # Do not care about other object numbers. Assume partition.\n                    raise NotObjectNumberError\n\n            except NotObjectNumberError:\n                # assume partition\n                try:\n                    partition = library.partition(ident)\n                    partitions.add(partition.vid)\n                    new_parts.append(partition.vid)\n                except NotFoundError:\n                    # Ok, maybe it is just a normal identifier...\n                    new_parts.append(ident)\n        else:\n            new_parts.append(token)\n\n    return ' '.join(new_parts).strip(), tables, partitions", "response": "Replace all of the references to tables and partitions with their vids."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a statement and return a FIMRecord that can be used to create or install indexes for partitions .", "response": "def find_indexable_materializable(sql, library):\n    \"\"\"\n    Parse a statement, then call functions to install, materialize or create indexes for partitions\n    referenced in the statement.\n\n    :param sql:\n    :param materialize_f:\n    :param install_f:\n    :param index_f:\n    :return:\n    \"\"\"\n\n    derefed, tables, partitions = substitute_vids(library, sql)\n\n    if derefed.lower().startswith('create index') or derefed.lower().startswith('index'):\n        parsed = parse_index(derefed)\n        return FIMRecord(statement=derefed, indexes=[(parsed.source, tuple(parsed.columns))])\n\n    elif derefed.lower().startswith('materialize'):\n        _, vid = derefed.split()\n        return FIMRecord(statement=derefed, materialize=set([vid]))\n\n    elif derefed.lower().startswith('install'):\n        _, vid = derefed.split()\n        return FIMRecord(statement=derefed, install=set([vid]))\n\n    elif derefed.lower().startswith('select'):\n        rec = FIMRecord(statement=derefed)\n        parsed = parse_select(derefed)\n\n    elif derefed.lower().startswith('drop'):\n        return FIMRecord(statement=derefed, drop=derefed)\n\n    elif derefed.lower().startswith('create table'):\n        parsed = parse_view(derefed)\n        rec = FIMRecord(statement=derefed, drop='DROP TABLE IF EXISTS {};'.format(parsed.name), views=1)\n\n    elif derefed.lower().startswith('create view'):\n        parsed = parse_view(derefed)\n        rec = FIMRecord(statement=derefed, drop='DROP VIEW IF EXISTS {};'.format(parsed.name), views=1)\n    else:\n        return FIMRecord(statement=derefed, tables=set(tables), install=set(partitions))\n\n    def partition_aliases(parsed):\n        d = {}\n\n        for source in parsed.sources:\n            if source.alias:\n                d[source.alias] = source.name\n\n        for j in parsed.joins:\n            if j.source.alias:\n                d[j.source.alias] = j.source.name\n\n        return d\n\n    def indexable_columns(aliases, parsed):\n\n        indexes = []\n\n        for j in parsed.joins:\n            if j and j.join_cols:\n                for col in j.join_cols:\n                    if '.' in col:\n                        try:\n                            alias, col = col.split('.')\n                            if alias:\n                                indexes.append((aliases[alias], (col,)))\n                        except KeyError:\n                            pass\n\n        return indexes\n\n    aliases = partition_aliases(parsed)\n\n    indexes = indexable_columns(aliases, parsed)\n\n    rec.joins = len(parsed.joins)\n\n    install = set(partitions)\n\n    rec.update(tables=tables, install=install, indexes=indexes)\n\n    return rec"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the current record.", "response": "def update(self, rec=None, drop=None, tables=None, install=None, materialize=None,\n               indexes=None, joins=0, views=0):\n        \"\"\" Updates current record.\n\n        Args:\n            rec (FIMRecord):\n        \"\"\"\n        if not drop:\n            drop = []\n\n        if not tables:\n            tables = set()\n\n        if not install:\n            install = set()\n\n        if not materialize:\n            materialize = set()\n\n        if not indexes:\n            indexes = set()\n\n        if rec:\n            self.update(\n                drop=rec.drop, tables=rec.tables, install=rec.install, materialize=rec.materialize,\n                indexes=rec.indexes, joins=rec.joins\n            )\n\n        self.drop += drop\n        self.tables |= set(tables)\n        self.install |= set(install)\n        self.materialize |= set(materialize)\n        self.indexes |= set(indexes)\n\n        self.joins += joins\n        self.views += views\n\n        # Joins or views promote installed partitions to materialized partitions\n        if self.joins > 0 or self.views > 0:\n            self.materialize |= self.install\n            self.install = set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef support_level(self, support_level):\n        allowed_values = [\"UNRELEASED\", \"EARLYACCESS\", \"SUPPORTED\", \"EXTENDED_SUPPORT\", \"EOL\"]\n        if support_level not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `support_level` ({0}), must be one of {1}\"\n                .format(support_level, allowed_values)\n            )\n\n        self._support_level = support_level", "response": "Sets the support_level of this ProductReleaseRest."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new DelayedCall to the list of scheduled calls.", "response": "def callLater(self, when, what, *a, **kw):\n    \"\"\"\n    Copied from twisted.internet.task.Clock, r20480.  Fixes the bug\n    where the wrong DelayedCall would sometimes be returned.\n    \"\"\"\n    dc =  base.DelayedCall(self.seconds() + when,\n                           what, a, kw,\n                           self.calls.remove,\n                           lambda c: None,\n                           self.seconds)\n    self.calls.append(dc)\n    self.calls.sort(lambda a, b: cmp(a.getTime(), b.getTime()))\n    return dc"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns whether the Clock has the bug that returns the wrong DelayedCall or not.", "response": "def clockIsBroken():\n    \"\"\"\n    Returns whether twisted.internet.task.Clock has the bug that\n    returns the wrong DelayedCall or not.\n    \"\"\"\n    clock = Clock()\n    dc1 = clock.callLater(10, lambda: None)\n    dc2 = clock.callLater(1, lambda: None)\n    if dc1 is dc2:\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_scm_status(config, read_modules=False, repo_url=None, mvn_repo_local=None, additional_params=None):\n    global scm_status_cache\n    if config.artifact in scm_status_cache.keys():\n        result = scm_status_cache[config.artifact]\n    elif not read_modules and ((\"%s|False\" % config.artifact) in scm_status_cache.keys()):\n        result = scm_status_cache[\"%s|False\" % config.artifact]\n    else:\n        result = _get_scm_status(config, read_modules, repo_url, mvn_repo_local, additional_params)\n        if read_modules:\n            scm_status_cache[config.artifact] = result\n            if (\"%s|False\" % config.artifact) in scm_status_cache.keys():\n                del(scm_status_cache[\"%s|False\" % config.artifact])\n        else:\n            scm_status_cache[\"%s|False\" % config.artifact] = result\n    return result", "response": "Gets the artifact status from SCM defined by config."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shrink_patch(patch_path, target_file):\n    logging.debug(\"Shrinking patch file %s to keep only %s changes.\", patch_path, target_file)\n    shrinked_lines = []\n    patch_file = None\n    try:\n        patch_file = open(patch_path)\n        adding = False\n        search_line = \"diff --git a/%s b/%s\" % (target_file, target_file)\n        for line in patch_file.read().split(\"\\n\"):\n            if adding and line.startswith(\"diff --git a/\") and line != search_line:\n                adding = False\n            elif line == search_line:\n                adding = True\n            if adding:\n                shrinked_lines.append(line)\n    finally:\n        if patch_file:\n            patch_file.close()\n\n    if len(shrinked_lines):\n        patch_file = None\n        try:\n            patch_file = open(patch_path, \"w\")\n            content = \"\\n\".join(shrinked_lines)\n            if not content.endswith(\"\\n\"):\n                content = content + \"\\n\"\n            patch_file.write(content)\n        finally:\n            if patch_file:\n                patch_file.close()\n        return True\n    else:\n        return False", "response": "Shrinks a patch file to contain only changes for target_file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads SCM info from the given directory.", "response": "def get_scm_info(directory, branch_id=False, read_only=False, filePath=None):\n    \"\"\"\n    Reads SCM info from the given directory. It can fill real commit ID into commit_id field or branch name.\n\n    @param directory: directory name\n    @param branch_id: reads commit ID if False (default) or branch name if True\n    @param read_only: if True it replaces the actual scheme to the read-only for known hosts, e.g. git+ssh to git for\n                      git.app.eng.bos.redhat.com, otherwise it just reads it (default)\n    @return: an ScmInfo instance\n    \"\"\"\n    #TODO use a commit id instead of branch if in detached state\n\n    if (directory, branch_id, read_only, filePath) in scm_info_path_cache:\n        return copy.copy(scm_info_path_cache[(directory, branch_id, read_only, filePath)])\n\n    if os.path.exists(os.path.join(directory, \".git\")):\n        logging.debug(\"Getting git info for %s\", directory)\n        if filePath != None:\n            args = [\"git\", \"--git-dir\", directory + \"/.git\", \"log\", \"-z\", \"-n\", \"2\", \"--pretty=format:* dummy-branch  %H  %s%n\", \"--\", filePath]\n        else:\n            args = [\"git\", \"--git-dir\", directory + \"/.git\", \"branch\", \"-v\", \"--no-abbrev\"]\n\n        command = Popen(args, stdout=PIPE, stderr=STDOUT)\n        stdout = command.communicate()[0]\n        if command.returncode:\n            raise ScmException(\"Reading Git branch name and commit ID from %s failed. Output: %s\" % (directory, stdout))\n\n        branch_name = None\n        commit_id = None\n\n        for line in stdout.split(\"\\n\"):\n            if line.startswith(\"* \"):\n                pattern = \"\\* +(.*) +([a-f0-9]{40}) .*\"\n                m = re.match(pattern, line)\n                if m:\n                    branch_name = m.group(1).strip()\n                    commit_id = m.group(2).strip()\n                    break\n                else:\n                    raise ScmException(\"Cannot parse commit ID and branch name from result line:\\n%s\" % line)\n\n        logging.info (\"Retrieved branch_name %s and commit_id %s\", branch_name, commit_id)\n\n        args = [\"git\", \"--git-dir\", directory + \"/.git\", \"remote\", \"-v\"]\n        command = Popen(args, stdout=PIPE, stderr=STDOUT)\n        stdout = command.communicate()[0]\n        if command.returncode:\n            raise ScmException(\"Reading Git remote from %s failed. Output: %s\" % (directory, stdout))\n\n        origin_url = None\n        for line in stdout.split(\"\\n\"):\n            if line.startswith(\"origin\" + chr(9)) and line.endswith(\" (fetch)\"):\n                parts = re.split(\"[\\s]+\", line, 3)\n                origin_url = parts[1]\n                break\n\n        if branch_id:\n            scminfo = ScmInfo(\"%s#%s\" % (origin_url, branch_name))\n        else:\n            scminfo = ScmInfo(\"%s#%s\" % (origin_url, commit_id))\n\n        if read_only:\n            if scminfo.get_scm_url().startswith(\"git+ssh://git.app.eng.bos.redhat.com/srv/git/\"):\n                scminfo.scheme = \"git\"\n                scminfo.path = scminfo.path.replace(\"/srv/git/\", \"/\")\n            elif scminfo.get_scm_url().startswith(\"git+ssh://code.engineering.redhat.com/\"):\n                scminfo.scheme = \"git+https\"\n                scminfo.path = (\"%s%s\" % (\"/gerrit/\", scminfo.path)).replace(\"gerrit//\", \"gerrit/\")\n\n        scm_info_path_cache[(directory, branch_id, read_only, filePath)] = scminfo\n        return scminfo\n    elif os.path.exists(directory):\n        #Special case for the integration-platform-tests which test tooling\n        #inplace and use the file:// in the test.cfg\n        scminfo = ScmInfo(\"file://%s#%s\" % (directory, \"xx\"))\n        scm_info_path_cache[(directory, branch_id, read_only, filePath)] = scminfo\n        return scminfo\n    else:\n        raise ScmException(\"Unknown SCM type while reading SCM info from %s\" % directory)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new_status(self, new_status):\n        allowed_values = [\"NEW\", \"DONE\", \"REJECTED\"]\n        if new_status not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `new_status` ({0}), must be one of {1}\"\n                .format(new_status, allowed_values)\n            )\n\n        self._new_status = new_status", "response": "Sets the new_status of this BuildSetStatusChangedEvent."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the old_status of this BuildSetStatusChangedEvent.", "response": "def old_status(self, old_status):\n        \"\"\"\n        Sets the old_status of this BuildSetStatusChangedEvent.\n\n        :param old_status: The old_status of this BuildSetStatusChangedEvent.\n        :type: str\n        \"\"\"\n        allowed_values = [\"NEW\", \"DONE\", \"REJECTED\"]\n        if old_status not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `old_status` ({0}), must be one of {1}\"\n                .format(old_status, allowed_values)\n            )\n\n        self._old_status = old_status"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns development server with automated reload on code change.", "response": "def command_serve(self, host='', port='8000', level='debug'):\n        '''\n        Run development server with automated reload on code change::\n\n            ./manage.py app:serve [host] [port] [level]\n        '''\n        logging.basicConfig(level=getattr(logging, level.upper()), format=self.format)\n        if self.bootstrap:\n            logger.info('Bootstraping...')\n            self.bootstrap()\n        try:\n            server_thread = DevServerThread(host, port, self.app)\n            server_thread.start()\n\n            wait_for_code_change(extra_files=self.extra_files)\n            server_thread.running = False\n            server_thread.join()\n            logger.info('Reloading...')\n            flush_fds()\n            pid = os.fork()\n            # We need to fork before `execvp` to perform code reload\n            # correctly, because we need to complete python destructors and\n            # `atexit`.\n            # This will save us from problems of incorrect exit, such as:\n            # - unsaved data in data storage, which does not write data\n            # on hard drive immediatly\n            # - code, that can't be measured with coverage tool, because it uses\n            # `atexit` handler to save coverage data\n            # NOTE: we using untipical fork-exec scheme with replacing\n            # the parent process(not the child) to preserve PID of proccess\n            # we use `pragma: no cover` here, because parent process cannot be\n            # measured with coverage since it is ends with `execvp`\n            if pid: # pragma: no cover\n                os.closerange(3, MAXFD)\n                os.waitpid(pid, 0)\n                # reloading the code in parent process\n                os.execvp(sys.executable, [sys.executable] + sys.argv)\n            else:\n                # we closing our recources, including file descriptors\n                # and performing `atexit`.\n                sys.exit()\n        except KeyboardInterrupt:\n            logger.info('Stoping dev-server...')\n            server_thread.running = False\n            server_thread.join()\n            sys.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef command_shell(self):\n        '''\n        Shell command::\n\n            ./manage.py app:shell\n\n        Executed with `self.shell_namespace` as local variables namespace.\n        '''\n        from code import interact\n        interact('Namespace {!r}'.format(self.shell_namespace),\n                 local=self.shell_namespace)", "response": "Command line interface for the neccesary shell."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef declared_mixin(*bases):\n    '''Create mix-in class with all assignments turned into methods decorated\n    with declared_attr. Usage:\n\n        @declared_mixin\n        def FactoryFunction():\n\n    or with base mix-in class[es]:\n\n        @declared_mixin(BaseMixIn1, BaseMixIn2)\n        def FactoryFunction():\n\n    For example:\n\n        @declared_mixin\n        def WithParent():\n            parent_id = Column(ForeignKey(Parent.id))\n            parent = relationship(Parent)\n\n    is equivalent to\n\n        class WithParent(object):\n            @declared_attr\n            def parent_id(cls):\n                return Column(ForeignKey(Parent.id))\n            @declared_attr\n            def parent(cls):\n                return relationship(Parent)\n    '''\n\n    def wrapper(func):\n        attrs = weakref.WeakKeyDictionary()\n        def create_descriptor(name):\n            def get_attr(cls):\n                if cls not in attrs:\n                    # Call func only once per class\n                    attrs[cls] = return_locals(func)()\n                return attrs[cls][name]\n            get_attr.__name__ = name\n            return declared_attr(get_attr)\n        dict_ = {name: create_descriptor(name)\n                 for name in six.get_function_code(func).co_varnames}\n        dict_['__doc__'] = func.__doc__\n        return type(func.__name__, bases, dict_)\n\n    if len(bases)==1 and not isinstance(bases[0], type):\n        # Short form (without bases) is used\n        func = bases[0]\n        bases = ()\n        return wrapper(func)\n    else:\n        return wrapper", "response": "Create mix - in class with all assignments turned into methods decorated\n    with declared_attr."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef elfhash(s):\n    hash = 0\n    x = 0\n    for c in s:\n        hash = (hash << 4) + c\n        x = hash & 0xF0000000\n        if x:\n            hash ^= (x >> 24)\n            hash &= ~x\n    return (hash & 0x7FFFFFFF)", "response": "hash a bytes object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind previous element in a sorted list", "response": "def find_previous(element, l):\n    \"\"\"\n    find previous element in a sorted list\n\n    >>> find_previous(0, [0])\n    0\n    >>> find_previous(2, [1, 1, 3])\n    1\n    >>> find_previous(0, [1, 2])\n    >>> find_previous(1.5, [1, 2])\n    1\n    >>> find_previous(3, [1, 2])\n    2\n    \"\"\"\n    length = len(l)\n    for index, current in enumerate(l):\n        # current is the last element\n        if length - 1 == index:\n            return current\n\n        # current is the first element\n        if index == 0:\n            if element < current:\n                return None\n\n        if current <= element < l[index+1]:\n            return current"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npatches ssl. match_hostname so that the SSL certificate matches the one we expect.", "response": "def patch_match_hostname():\n    \"\"\"Fixes https://github.com/boto/boto/issues/2836\"\"\"\n\n\n    _old_match_hostname = ssl.match_hostname\n\n    def _new_match_hostname(cert, hostname):\n        if hostname.endswith('.s3.amazonaws.com'):\n            pos = hostname.find('.s3.amazonaws.com')\n            hostname = hostname[:pos].replace('.', '') + hostname[pos:]\n        return _old_match_hostname(cert, hostname)\n\n    ssl.match_hostname = _new_match_hostname"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dict(self):\n        from collections import OrderedDict\n\n        d = OrderedDict(\n            [(p.key, getattr(self, p.key)) for p in self.__mapper__.attrs if p.key not in ('data',)])\n\n        if 'list' in self.data:\n            d['bundle_count'] = len(self.data['list'])\n        else:\n            d['bundle_count'] = None\n\n        if self.data:\n            for k, v in self.data.items():\n                d[k] = v\n\n        return d", "response": "A dict that holds all of the properties in the the\n            object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncaches the list into the data section of the record", "response": "def update(self):\n        \"\"\"Cache the list into the data section of the record\"\"\"\n\n        from ambry.orm.exc import NotFoundError\n        from requests.exceptions import ConnectionError, HTTPError\n        from boto.exception import S3ResponseError\n\n        d = {}\n\n        try:\n            for k, v in self.list(full=True):\n                if not v:\n                    continue\n\n                d[v['vid']] = {\n                    'vid': v['vid'],\n                    'vname': v.get('vname'),\n                    'id': v.get('id'),\n                    'name': v.get('name')\n                }\n\n            self.data['list'] = d\n        except (NotFoundError, ConnectionError, S3ResponseError, HTTPError) as e:\n            raise RemoteAccessError(\"Failed to update {}: {}\".format(self.short_name, e))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist all of the bundles in the remote", "response": "def list(self, full=False):\n        \"\"\"List all of the bundles in the remote\"\"\"\n\n        if self.is_api:\n            return self._list_api(full=full)\n        else:\n            return self._list_fs(full=full)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_fs_list(self):\n        from json import dumps\n\n        full_list = [ e[1] for e in self._list_fs(full=True) ]\n\n        remote = self._fs_remote(self.url)\n\n        remote.setcontents(os.path.join('_meta', 'list.json'), dumps(full_list, indent = 4))", "response": "Cache the full list for http access"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks in a bundle package to the remote.", "response": "def checkin(self, package, no_partitions=False, force=False,  cb=None):\n        \"\"\"\n        Check in a bundle package to the remote.\n\n        :param package: A Database, referencing a sqlite database holding the bundle\n        :param cb: a two argument progress callback: cb(message, num_records)\n        :return:\n        \"\"\"\n        from ambry.orm.exc import NotFoundError\n\n        if not os.path.exists(package.path):\n            raise NotFoundError(\"Package path does not exist: '{}' \".format(package.path))\n\n        if self.is_api:\n            return self._checkin_api(package, no_partitions=no_partitions, force=force, cb=cb)\n        else:\n            return self._checkin_fs(package, no_partitions=no_partitions, force=force, cb=cb)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _put_metadata(self, fs_remote, ds):\n\n        from six import text_type\n        from fs.errors import ResourceNotFoundError\n\n\n        identity = ds.identity\n        d = identity.dict\n\n        d['summary'] = ds.config.metadata.about.summary\n        d['title'] = ds.config.metadata.about.title\n\n        meta_stack = self._meta_infos(ds)\n\n        def do_metadata():\n            for path, ident in meta_stack:\n                fs_remote.setcontents(path, ident)\n\n\n        try:\n            # Assume the directories already exist\n            do_metadata()\n        except ResourceNotFoundError:\n            # Nope, make them and try again.\n            parts = ['vid', 'id', 'vname', 'name']\n            for p in parts:\n                dirname = os.path.join('_meta', p)\n                fs_remote.makedir(dirname, allow_recreate=True, recursive=True)\n\n            do_metadata()", "response": "Store metadata on a pyfs remote"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef checkout(self, ref, cb=None):\n        if self.is_api:\n            return self._checkout_api(ref, cb=cb)\n        else:\n            return self._checkout_fs(ref, cb=cb)", "response": "Checkout a bundle from the remote. Returns a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self, ref, cb=None):\n\n        if self.is_api:\n            return self._remove_api(ref, cb)\n        else:\n            return self._remove_fs(ref, cb)", "response": "Remove a single entry from the bundle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef s3(self, url, account_acessor=None, access=None, secret=None):\n        from ambry.util.ambrys3 import AmbryS3FS\n        from ambry.util import parse_url_to_dict\n        import ssl\n\n        pd = parse_url_to_dict(url)\n\n        if account_acessor:\n            account = account_acessor(pd['hostname'])\n\n            assert account['account_id'] == pd['hostname']\n            aws_access_key = account['access_key'],\n            aws_secret_key = account['secret']\n        else:\n            aws_access_key = access\n            aws_secret_key = secret\n\n        assert access, url\n        assert secret, url\n\n        s3 = AmbryS3FS(\n            bucket=pd['netloc'],\n            prefix=pd['path'].strip('/')+'/',\n            aws_access_key=aws_access_key,\n            aws_secret_key=aws_secret_key,\n\n        )\n\n        return s3", "response": "Setup an S3 pyfs object with account credentials fixing an ssl matching problem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a WithDictNode for the given context dict.", "response": "def withdict(parser, token):\n    \"\"\"\n    Take a complete context dict as extra layer.\n    \"\"\"\n    bits = token.split_contents()\n    if len(bits) != 2:\n        raise TemplateSyntaxError(\"{% withdict %} expects one argument\")\n\n    nodelist = parser.parse(('endwithdict',))\n    parser.delete_first_token()\n\n    return WithDictNode(\n        nodelist=nodelist,\n        context_expr=parser.compile_filter(bits[1])\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render(self, context):\n        extra_context = self.context_expr.resolve(context)\n        if not isinstance(extra_context, dict):\n            raise TemplateSyntaxError(\"{% withdict %} expects the argument to be a dictionary.\")\n\n        with context.push(**extra_context):\n            return self.nodelist.render(context)", "response": "Render the tag with extra context layer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filesessionmaker(sessionmaker, file_manager, file_managers=None):\n    u'''Wrapper of session maker adding link to a FileManager instance\n    to session.::\n\n        file_manager = FileManager(cfg.TRANSIENT_ROOT,\n                                   cfg.PERSISTENT_ROOT)\n        filesessionmaker(sessionmaker(...), file_manager)\n    '''\n\n    registry = WeakKeyDictionary()\n\n    if file_managers:\n        for k, v in six.iteritems(file_managers):\n            if isinstance(k, FileAttribute):\n                raise NotImplementedError()\n            registry[k] = v\n\n    def find_file_manager(self, target):\n        if isinstance(target, FileAttribute):\n            assert hasattr(target, 'class_')\n            target = target.class_\n        else:\n            if not inspect.isclass(target):\n                target = type(target)\n\n        assert hasattr(target, 'metadata')\n        assert class_mapper(target) is not None\n        if target in registry:\n            return registry[target]\n        if target.metadata in registry:\n            return registry[target.metadata]\n        return file_manager\n\n    def session_maker(*args, **kwargs):\n        session = sessionmaker(*args, **kwargs)\n        # XXX in case we want to use session manager somehow bound \n        #     to request environment. For example, to generate user-specific\n        #     URLs.\n        #session.file_manager = \\\n        #        kwargs.get('file_manager', file_manager)\n        session.file_manager = file_manager\n        session.find_file_manager = six.create_bound_method(\n                                            find_file_manager,\n                                            session)\n\n        return session\n    return session_maker", "response": "Wrapper of file session maker adding links to a FileManager instance and a dictionary of file_managers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop_if_mostly_diverging(errdata):\n    n_increases = sum([\n        abs(y) - abs(x) > 0 for x, y in zip(errdata, errdata[1:])])\n    if len(errdata) * 0.5 < n_increases:\n        # most of the time, the next sample is worse than the previous sample\n        # relay is not healthy\n        return 0\n    else:\n        # most of the time, the next sample is better than the previous sample\n        # realy is in a healthy state\n        return -1", "response": "This function returns - 1 if the error difference between consecutive samples is lower than the previous sample or - 1 if the next sample is better than the previous sample"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_resolved_dependencies(self):\n        for dependency in self.dependencies:\n            if dependency.state != Task.State.DONE:\n                return False\n\n        return True", "response": "Return True if all dependencies are in State. DONE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of dependency names.", "response": "def dependencies_as_list(self):\n        \"\"\"Returns a list of dependency names.\"\"\"\n        dependencies = []\n        for dependency in self.dependencies:\n            dependencies.append(dependency.name)\n        return dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget task by name or create it if it does not exist.", "response": "def get_task(self, name):\n        \"\"\"Get task by name or create it if it does not exists.\"\"\"\n        if name in self.tasks.keys():\n            task = self.tasks[name]\n        else:\n            task = Task(name)\n            self.tasks[name] = task\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn next task from the stack that has all dependencies resolved.", "response": "def get_next(self):\n        \"\"\"Return next task from the stack that has all dependencies resolved.\n        Return None if there are no tasks with resolved dependencies or is there are no more tasks on stack.\n        Use `count` to check is there are still some task left on the stack.\n\n        raise ValueError if total ordering is not possible.\"\"\"\n\n        self.update_tasks_status()\n\n        if self.dirty:\n            self.tsort()\n            self.dirty = False\n\n        for key, task in self.tasks.iteritems():\n            if task.is_new() and task.has_resolved_dependencies():\n                return task\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_buildable_tasks(self):\n        self.update_tasks_status()\n        buildable_tasks_count = 0\n        for key, task in self.tasks.iteritems():\n            if task.state is Task.State.NEW:\n                if self.are_dependencies_buildable(task):\n                    buildable_tasks_count += 1\n                    logging.debug(\"Buildable task: %s\" % task.name )\n                else:\n                    logging.debug(\"Task %s has broken dependencies.\" % task.name )\n\n        return buildable_tasks_count", "response": "Count tasks that are new and have dependencies in non FAILED state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tsort(self):\n\n        task_dict = {}\n        for key, task in self.tasks.iteritems():\n            task_dict[task] = task.dependencies\n        # parts = parts.copy()\n        parts = task_dict.copy()\n\n        result = []\n        while True:\n            level = set([name for name, deps in parts.iteritems() if not deps])\n            if not level:\n                break\n            result.append(level)\n            parts = dict([(name, deps - level) for name, deps in parts.iteritems() if name not in level])\n        if parts:\n            raise ValueError('total ordering not possible (check for circular or missing dependencies)')\n        return result", "response": "Given a partial ordering return a totally ordered list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build(self, build_execution_configuration, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.build_with_http_info(build_execution_configuration, **kwargs)\n        else:\n            (data) = self.build_with_http_info(build_execution_configuration, **kwargs)\n            return data", "response": "Builds a new version of an anatomical entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_task_completed(self, task_id, build_result, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.build_task_completed_with_http_info(task_id, build_result, **kwargs)\n        else:\n            (data) = self.build_task_completed_with_http_info(task_id, build_result, **kwargs)\n            return data", "response": "This method is used to notify the completion of externally managed build task process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cancel_bbuild(self, build_execution_configuration_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.cancel_bbuild_with_http_info(build_execution_configuration_id, **kwargs)\n        else:\n            (data) = self.cancel_bbuild_with_http_info(build_execution_configuration_id, **kwargs)\n            return data", "response": "Cancel the build execution defined with given executionConfigurationId."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_config(self):\n        config = import_module('config')\n        variables = [var for var in dir(config) if not var.startswith('_')]\n        return {var: getattr(config, var) for var in variables}", "response": "Load project s config and return dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(name, default=None):\n        if '.' not in name:\n            raise Exception(\"Config path should be divided by at least one dot\")\n        section_name, var_path = name.split('.', 1)\n        section = Config._data.get(section_name)\n        return section.get(var_path)", "response": "Get a value from the project s config."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns last item with a key <= k. Raise ValueError if not found.", "response": "def find_le(self, k):\n        'Return last item with a key <= k.  Raise ValueError if not found.'\n        i = bisect_right(self._keys, k)\n        if i:\n            return self._items[i - 1]\n        raise ValueError('No item found with key at or below: %r' % (k,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns last item with a key <= k. Raise ValueError if not found.", "response": "def find_le_index(self, k):\n        'Return last item with a key <= k.  Raise ValueError if not found.'\n        i = bisect_right(self._keys, k)\n        if i:\n            return i - 1\n        raise ValueError('No item found with key at or below: %r' % (k,))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_lt(self, k):\n        i = bisect_left(self._keys, k)\n        if i:\n            return self._items[i - 1]\n        raise ValueError('No item found with key below: %r' % (k,))", "response": "Return the last item with a key < k. Raise ValueError if no such item is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns first item with a key >= equal to k. Raise ValueError if not found", "response": "def find_ge_index(self, k):\n        'Return first item with a key >= equal to k.  Raise ValueError if not found'\n        i = bisect_left(self._keys, k)\n        if i != len(self):\n            return i\n        raise ValueError('No item found with key at or above: %r' % (k,))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current brk value in the debugged process only x86_64 Linux", "response": "def get_dbg_brk_linux64():\n    '''\n    Return the current brk value in the debugged process (only x86_64 Linux)\n    '''\n    # TODO this method is so weird, find a unused address to inject code not\n    # the base address\n\n    debugger = get_debugger()\n\n    code = b'\\x0f\\x05'  # syscall\n\n    rax = debugger.get_reg(\"rax\")\n    rdi = debugger.get_reg(\"rdi\")\n    rip = debugger.get_reg(\"rip\")\n    efl = debugger.get_reg(\"efl\")\n\n    debugger.set_reg(\"rax\", 12)  # sys_brk\n    debugger.set_reg(\"rdi\", 0)\n\n    base = debugger.image_base()\n\n    inj = base\n\n    save = debugger.get_bytes(inj, len(code))\n\n    debugger.put_bytes(inj, code)\n\n    debugger.set_reg(\"rip\", inj)\n\n    debugger.step_into()\n    debugger.wait_ready()\n\n    brk_res = debugger.get_reg(\"rax\")\n\n    debugger.set_reg(\"rax\", rax)\n    debugger.set_reg(\"rdi\", rdi)\n    debugger.set_reg(\"rip\", rip)\n    debugger.set_reg(\"efl\", efl)\n\n    debugger.put_bytes(inj, save)\n\n    return brk_res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dbg_brk_linux32():\n    '''\n    Return the current brk value in the debugged process (only x86 Linux)\n    '''\n    # TODO this method is so weird, find a unused address to inject code not\n    # the base address\n\n    debugger = get_debugger()\n\n    code = b'\\xcd\\x80'  # int 0x80\n\n    eax = debugger.get_reg(\"eax\")\n    ebx = debugger.get_reg(\"ebx\")\n    eip = debugger.get_reg(\"eip\")\n    efl = debugger.get_reg(\"efl\")\n\n    debugger.set_reg(\"eax\", 45)  # sys_brk\n    debugger.set_reg(\"ebx\", 0)\n\n    base = debugger.image_base()\n\n    inj = base\n\n    save = debugger.get_bytes(inj, len(code))\n\n    debugger.put_bytes(inj, code)\n\n    debugger.set_reg(\"eip\", inj)\n\n    debugger.step_into()\n    debugger.wait_ready()\n\n    brk_res = debugger.get_reg(\"eax\")\n\n    debugger.set_reg(\"eax\", eax)\n    debugger.set_reg(\"ebx\", ebx)\n    debugger.set_reg(\"eip\", eip)\n    debugger.set_reg(\"efl\", efl)\n\n    debugger.put_bytes(inj, save)\n\n    return brk_res", "response": "Return the current brk value in the debugged process only x86 Linux 32 - bit mode"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the reloader task.", "response": "def start(\n        loop: abstract_loop = None,\n        interval: float = 0.5,\n        hook: hook_type = None) -> asyncio.Task:\n    \"\"\"\n    Start the reloader.\n\n    Create the task which is watching loaded modules\n    and manually added files via ``watch()``\n    and reloading the process in case of modification.\n    Attach this task to the loop.\n\n    If ``hook`` is provided, it will be called right before\n    the application goes to the reload stage.\n    \"\"\"\n    if loop is None:\n        loop = asyncio.get_event_loop()\n\n    global reload_hook\n    if hook is not None:\n        reload_hook = hook\n\n    global task\n    if not task:\n        modify_times = {}\n        executor = ThreadPoolExecutor(1)\n        task = call_periodically(\n            loop,\n            interval,\n            check_and_reload,\n            modify_times,\n            executor,\n        )\n    return task"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef strftime(dt, fmt):\n    '''\n    `strftime` implementation working before 1900\n    '''\n    if _illegal_s.search(fmt):\n        raise TypeError(\"This strftime implementation does not handle %s\")\n    if dt.year > 1900:\n        return dt.strftime(fmt)\n\n    fmt = fmt.replace('%c', '%a %b %d %H:%M:%S %Y')\\\n             .replace('%Y', str(dt.year))\\\n             .replace('%y', '{:04}'.format(dt.year)[-2:])\n\n    year = dt.year\n    # For every non-leap year century, advance by\n    # 6 years to get into the 28-year repeat cycle\n    delta = 2000 - year\n    off = 6*(delta // 100 + delta // 400)\n    year = year + off\n\n    # Move to around the year 2000\n    year = year + ((2000 - year)//28)*28\n    timetuple = dt.timetuple()\n    return time.strftime(fmt, (year,) + timetuple[1:])", "response": "strftime implementation working before 1900"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreports on the operation of a Postgres Library database", "response": "def library_pg(args, l, config):\n    \"\"\"Report on the operation of a Postgres Library database\"\"\"\n    import tabulate\n    import terminaltables\n    from textwrap import fill\n    from ambry.util.text import getTerminalSize\n    import sys\n\n    if args.connect:\n        try:\n            l.database.connection.execute('SELECT * FROM pg_stat_activity;')\n            sys.exit(0)\n        except Exception as e:\n            prt(str(e))\n            sys.exit(1)\n\n    db = l.database\n\n    (x, y) = getTerminalSize()\n\n    if args.processes:\n\n        headers = None\n        rows = []\n\n        for row in db.connection.execute('SELECT pid, client_addr, application_name ass, query FROM pg_stat_activity '):\n            if not headers:\n                headers = row.keys()\n            row = list(str(e) for e in row)\n\n            row[3] = fill(row[3],x-50)\n            rows.append(row)\n\n        #print tabulate.tabulate(rows, headers)\n        table =  terminaltables.UnixTable([headers]+rows)\n        print table.table\n\n    if args.blocks:\n\n        headers = None\n        rows = []\n\n        q1 = \"\"\"\nSELECT pid, database, mode, locktype, mode, relation, tuple, virtualxid FROM pg_locks order by pid;\n\"\"\"\n\n\n        q2 = \"\"\"\n  SELECT blocked_locks.pid     AS blocked_pid,\n         -- blocked_activity.usename  AS blocked_user,\n         blocking_locks.pid     AS blocking_pid,\n         -- blocking_activity.usename AS blocking_user,\n         blocked_activity.query    AS blocked_statement,\n         blocking_activity.query   AS current_statement_in_blocking_process\n   FROM  pg_catalog.pg_locks         blocked_locks\n    JOIN pg_catalog.pg_stat_activity blocked_activity  ON blocked_activity.pid = blocked_locks.pid\n    JOIN pg_catalog.pg_locks         blocking_locks\n        ON blocking_locks.locktype = blocked_locks.locktype\n        AND blocking_locks.DATABASE IS NOT DISTINCT FROM blocked_locks.DATABASE\n        AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n        AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n        AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n        AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid\n        AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n        AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n        AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n        AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n        AND blocking_locks.pid != blocked_locks.pid\n\n    JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\n   WHERE NOT blocked_locks.GRANTED;\n\n\"\"\"\n\n        for row in db.connection.execute(q2):\n            if not headers:\n                headers = row.keys()\n            row = list(str(e) for e in row)\n\n            row[2] = fill(row[2],(x-50)/2)\n            row[3] = fill(row[3], (x-50)/2)\n            rows.append(row)\n\n        if rows:\n            table = terminaltables.UnixTable([headers] + rows)\n            print table.table\n\n    if args.locks:\n\n            headers = None\n            rows = []\n\n            q = \"\"\"\n    SELECT pid, database, mode, locktype, mode, relation::regclass, tuple, virtualxid\n    FROM pg_locks\n    ORDER BY pid\n    ;\n    \"\"\"\n\n\n            for row in db.connection.execute(q):\n                if not headers:\n                    headers = row.keys()\n                row = list(str(e) for e in row)\n\n                row[2] = fill(row[2], (x - 50) / 2)\n                row[3] = fill(row[3], (x - 50) / 2)\n                rows.append(row)\n\n            if rows:\n                table = terminaltables.UnixTable([headers] + rows)\n                print table.table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _detect_timezone_windows():\n  # pylint: disable=global-statement\n  global win32timezone_to_en\n\n  # Try and fetch the key_name for the timezone using\n  # Get(Dynamic)TimeZoneInformation\n  tzi = DTZI_c()\n  kernel32 = ctypes.windll.kernel32\n  getter = kernel32.GetTimeZoneInformation\n  getter = getattr(kernel32, \"GetDynamicTimeZoneInformation\", getter)\n\n  # code is for daylight savings: 0 means disabled/not defined, 1 means enabled\n  # but inactive, 2 means enabled and active\n  _ = getter(ctypes.byref(tzi))\n\n  win32tz_key_name = tzi.key_name\n  if not win32tz_key_name:\n    if win32timezone is None:\n      return None\n    # We're on Windows before Vista/Server 2008 - need to look up the\n    # standard_name in the registry.\n    # This will not work in some multilingual setups if running in a language\n    # other than the operating system default\n    win32tz_name = tzi.standard_name\n    if not win32timezone_to_en:\n      win32timezone_to_en = dict(\n          win32timezone.TimeZoneInfo._get_indexed_time_zone_keys(\"Std\"))\n    win32tz_key_name = win32timezone_to_en.get(win32tz_name, win32tz_name)\n\n  territory = locale.getdefaultlocale()[0].split(\"_\", 1)[1]\n  olson_name = win32tz_map.win32timezones.get((win32tz_key_name, territory), win32tz_map.win32timezones.get(win32tz_key_name, None))\n  if not olson_name:\n    return None\n  if not isinstance(olson_name, str):\n    olson_name = olson_name.encode(\"ascii\")\n\n  return pytz.timezone(olson_name)", "response": "Detect timezone on Windows platform."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencrypts the given plaintext password using the given algorithm.", "response": "def encrypt_password(raw_password, algorithm='sha1', salt=None):\n    \"\"\"\n    Returns a string of the hexdigest of the given plaintext password and salt\n    using the given algorithm ('md5', 'sha1' or other supported by hashlib).\n    \"\"\"\n    if salt is None:\n        salt = binascii.hexlify(os.urandom(3))[:5]\n    else:\n        salt = salt.encode('utf-8')\n\n    raw_password = raw_password.encode('utf-8')\n    hash = hashlib.new(algorithm, salt+raw_password).hexdigest()\n    return '{}${}${}'.format(algorithm, salt.decode('utf-8'), hash)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the raw_password is correct for the encryption format.", "response": "def check_password(raw_password, enc_password):\n    \"\"\"\n    Returns a boolean of whether the raw_password was correct. Handles\n    encryption formats behind the scenes.\n    \"\"\"\n    algo, salt, hsh = enc_password.split('$')\n    return enc_password == encrypt_password(raw_password, algorithm=algo,\n                                            salt=salt)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef login(self, template='login'):\n        '''\n        This property will return component which will handle login requests.\n\n            auth.login(template='login.html')\n        '''\n        def _login(env, data):\n            form = self._login_form(env)\n            next = env.request.GET.get('next', '/')\n            login_failed = False\n            if env.request.method == 'POST':\n                if form.accept(env.request.POST):\n                    user_identity = self.get_user_identity(\n                                                env, **form.python_data)\n                    if user_identity is not None:\n                        response = HTTPSeeOther(location=next)\n                        return self.login_identity(user_identity, response)\n                    login_failed = True\n            data.form = form\n            data.login_failed = login_failed\n            data.login_url = env.root.login.as_url.qs_set(next=next)\n            return env.template.render_to_response(template, data.as_dict())\n        return web.match('/login', 'login') | _login", "response": "This property will return component which will handle login requests."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the content of this SupportLevelPage.", "response": "def content(self, content):\n        \"\"\"\n        Sets the content of this SupportLevelPage.\n\n        :param content: The content of this SupportLevelPage.\n        :type: list[str]\n        \"\"\"\n        allowed_values = [\"UNRELEASED\", \"EARLYACCESS\", \"SUPPORTED\", \"EXTENDED_SUPPORT\", \"EOL\"]\n        if not set(content).issubset(set(allowed_values)):\n            raise ValueError(\n                \"Invalid values for `content` [{0}], must be a subset of [{1}]\"\n                .format(\", \".join(map(str, set(content)-set(allowed_values))),\n                        \", \".join(map(str, allowed_values)))\n            )\n\n        self._content = content"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bpm_task_by_id(self, task_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_bpm_task_by_id_with_http_info(task_id, **kwargs)\n        else:\n            (data) = self.get_bpm_task_by_id_with_http_info(task_id, **kwargs)\n            return data", "response": "Get a single active BPM task."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all BPM tasks.", "response": "def get_bpm_tasks(self, **kwargs):\n        \"\"\"\n        List of (recently) active BPM tasks.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_bpm_tasks(callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :return: BpmTaskRestPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_bpm_tasks_with_http_info(**kwargs)\n        else:\n            (data) = self.get_bpm_tasks_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef notify_task(self, task_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.notify_task_with_http_info(task_id, **kwargs)\n        else:\n            (data) = self.notify_task_with_http_info(task_id, **kwargs)\n            return data", "response": "Notify PNC about a BPM task event."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart Repository Creation Task with url autodetect.", "response": "def start_r_creation_task_with_single_url(self, body, **kwargs):\n        \"\"\"\n        Start Repository Creation task with url autodetect (internal vs. external).\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.start_r_creation_task_with_single_url(body, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param RepositoryCreationUrlAutoRest body: Task parameters. (required)\n        :return: int\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.start_r_creation_task_with_single_url_with_http_info(body, **kwargs)\n        else:\n            (data) = self.start_r_creation_task_with_single_url_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy a file name or file - like - object to another file name or file - like object.", "response": "def copy_file_or_flo(input_, output, buffer_size=64 * 1024, cb=None):\n    \"\"\" Copy a file name or file-like-object to another\n    file name or file-like object\"\"\"\n\n    assert bool(input_)\n    assert bool(output)\n\n    input_opened = False\n    output_opened = False\n\n    try:\n        if isinstance(input_, string_types):\n\n            if not os.path.isdir(os.path.dirname(input_)):\n                os.makedirs(os.path.dirname(input_))\n\n            input_ = open(input_, 'r')\n            input_opened = True\n\n        if isinstance(output, string_types):\n\n            if not os.path.isdir(os.path.dirname(output)):\n                os.makedirs(os.path.dirname(output))\n\n            output = open(output, 'wb')\n            output_opened = True\n\n        # shutil.copyfileobj(input_,  output, buffer_size)\n\n        def copyfileobj(fsrc, fdst, length=buffer_size):\n            cumulative = 0\n            while True:\n                buf = fsrc.read(length)\n                if not buf:\n                    break\n                fdst.write(buf)\n                if cb:\n                    cumulative += len(buf)\n                    cb(len(buf), cumulative)\n\n        copyfileobj(input_, output)\n\n    finally:\n        if input_opened:\n            input_.close()\n\n        if output_opened:\n            output.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure(self, config=None, **kwargs):\n        self.config = config or {}\n        for key in ['messaging_token', 'number']:\n            if key not in self.config:\n                msg = \"Tropo backend config must set '%s'; config is %r\" %\\\n                      (key, config)\n                raise ImproperlyConfigured(msg)\n        if kwargs:\n            msg = \"All tropo backend config should be within the `config`\"\\\n                \"entry of the backend dictionary\"\n            raise ImproperlyConfigured(msg)", "response": "Configure all of our tropo backend config."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a Tropo program and return the result.", "response": "def execute_tropo_program(self, program):\n        \"\"\"\n        Ask Tropo to execute a program for us.\n\n        We can't do this directly;\n        we have to ask Tropo to call us back and then give Tropo the\n        program in the response body to that request from Tropo.\n\n        But we can pass data to Tropo and ask Tropo to pass it back\n        to us when Tropo calls us back. So, we just bundle up the program\n        and pass it to Tropo, then when Tropo calls us back, we\n        give the program back to Tropo.\n\n        We also cryptographically sign our program, so that\n        we can verify when we're called back with a program, that it's\n        one that we sent to Tropo and has not gotten mangled.\n\n        See https://docs.djangoproject.com/en/1.4/topics/signing/ for more\n        about the signing API.\n\n        See https://www.tropo.com/docs/webapi/passing_in_parameters_text.htm\n        for the format we're using to call Tropo, pass it data, and ask\n        them to call us back.\n\n\n\n        :param program: A Tropo program, i.e. a dictionary with a 'tropo'\n            key whose value is a list of dictionaries, each representing\n            a Tropo command.\n        \"\"\"\n        # The signer will also \"pickle\" the data structure for us\n        signed_program = signing.dumps(program)\n\n        params = {\n            'action': 'create',  # Required by Tropo\n            'token': self.config['messaging_token'],  # Identify ourselves\n            'program': signed_program,  # Additional data\n        }\n        data = json.dumps(params)\n\n        # Tell Tropo we'd like our response in JSON format\n        # and our data is in that format too.\n        headers = {\n            'accept': 'application/json',\n            'content-type': 'application/json',\n        }\n        response = requests.post(base_url,\n                                 data=data,\n                                 headers=headers)\n\n        # If the HTTP request failed, raise an appropriate exception - e.g.\n        # if our network (or Tropo) are down:\n        response.raise_for_status()\n\n        result = json.loads(response.content)\n        if not result['success']:\n            raise Exception(\"Tropo error: %s\" % result.get('error', 'unknown'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, id_, text, identities, context=None):\n\n        # Build our program\n        from_ = self.config['number'].replace('-', '')\n        commands = []\n        for identity in identities:\n            # We'll include a 'message' command for each recipient.\n            # The Tropo doc explicitly says that while passing a list\n            # of destination numbers is not a syntax error, only the\n            # first number on the list will get sent the message. So\n            # we have to send each one as a separate `message` command.\n            commands.append(\n                {\n                    'message': {\n                        'say': {'value': text},\n                        'to': identity,\n                        'from': from_,\n                        'channel': 'TEXT',\n                        'network': 'SMS'\n                    }\n                }\n            )\n            program = {\n                'tropo': commands,\n            }\n        self.execute_tropo_program(program)", "response": "Send a message to a specific user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dotted(self):\n        v = str(self.geoid.tract).zfill(6)\n        return v[0:4] + '.' + v[4:]", "response": "Return just the tract number excluding the state and county in the dotted format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dynamic subclass that has the extra parameters built in", "response": "def subclass(cls, vt_code, vt_args):\n        \"\"\"Return a dynamic subclass that has the extra parameters built in\"\"\"\n        from geoid import get_class\n        import geoid.census\n\n        parser = get_class(geoid.census, vt_args.strip('/')).parse\n\n        cls = type(vt_code.replace('/', '_'), (cls,), {'vt_code': vt_code, 'parser': parser})\n        globals()[cls.__name__] = cls\n        assert cls.parser\n\n        return cls"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _open(self, path, skip_to_end = True, offset = None):\n      fh = os.fdopen(os.open(path, os.O_RDONLY | os.O_NONBLOCK))\n\n      # If the file is being opened for the first time, jump to the end.\n      # Otherwise, it is being reopened after a rotation, and we want\n      # content from the beginning.\n      if offset is None:\n         if skip_to_end:\n            fh.seek(0, 2)\n\n            self._offset = fh.tell()\n         else:\n            self._offset = 0\n      else:\n         fh.seek(offset)\n         self._offset = fh.tell()\n      \n      self._fh = fh\n      self._lastsize = fh.tell()\n      self._inode = os.stat(self._path).st_ino", "response": "Open a file and store its metadata."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read(self, limit = None):\n      # The code that used to be here was self._fh.read(limit)\n      # However, this broke on OSX. os.read, however, works fine, but doesn't\n      # take the None argument or have any way to specify \"read to the end\".\n      # This emulates that behaviour.\n      while True:\n         # Check that we haven't closed this file\n         if not self._fh:\n            return False\n         dataread = os.read(self._fh.fileno(), limit or 65535)\n         if len(dataread) > 0:\n            self._buf += dataread\n            if limit is not None:\n               return True\n         else:\n            return False", "response": "Reads the file and refills the buffer if it finds any."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hasBeenRotated(self):\n      try:\n         # If the inodes don't match, it means the file has been replaced.\n         # The inode number cannot be recycled as long as we hold the\n         # filehandle open, so this test can be trusted.\n         return os.stat(self._path).st_ino != self._inode\n      except OSError:\n         # If the file doesn't exist, let's call it \"rotated\".\n         return True", "response": "Returns a boolean indicating whether the file has been removed and recreated during the time it has been open."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reopen(self):\n      # Read any remaining content in the file and store it in a buffer.\n      self._read()\n      # Close it to ensure we don't leak file descriptors\n      self._close()\n      \n      # Reopen the file.\n      try:\n         self._open(self._path, skip_to_end = False)\n         return True\n      except OSError:\n         # If opening fails, it was probably deleted.\n         return False", "response": "Reopens the file. Usually used after it has been rotated."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readlines(self):\n\n      # If the file is not open, there's nothing to return\n      if not self._fh:\n         raise StopIteration\n\n      at_eof = False\n      while True:\n         # Clean the buffer sometimes.\n         if self._bufoffset > (self._maxreadsize / 2):\n            self._buf = self._buf[self._bufoffset:]\n            self._bufoffset = 0\n\n         # Fill up the buffer if necessary.\n         if len(self._buf) < self._maxreadsize:\n            at_eof = not self._read(self._maxreadsize)\n\n         # Look for the next line.\n         try:\n            next_newline = self._buf.index(\"\\n\", self._bufoffset)\n            line = self._buf[self._bufoffset:next_newline]\n            self._bufoffset = next_newline + 1\n            # Save the current file offset for yielding and advance the file offset.\n            offset = self._offset\n            self._offset += len(line) + 1\n            if self._longline:\n               # This is the remaining chunk of a long line, we're not going\n               # to yield it.\n               self._longline = False\n            else:\n               yield line, offset\n\n         except ValueError:\n            # Reached the end of the buffer without finding any newlines.\n            if not at_eof:\n               # Line is longer than the half the buffer size? - Nope\n               logger.warning(\"Skipping over longline at %s:%d\", self._path,\n                                                                 self._offset)\n               self._bufoffset = len(self._buf) - 1\n               self._longline = True\n            raise StopIteration", "response": "A generator producing lines from the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck for new files deleted files and rotated files.", "response": "def _rescan(self, skip_to_end = True):\n      \"\"\"Check for new files, deleted files, and rotated files.\"\"\"\n      # Get listing of matching files.\n      paths = []\n      for single_glob in self._globspec:\n          paths.extend(glob.glob(single_glob))\n\n      # Remove files that don't appear in the new list.\n      for path in self._tailedfiles.keys():\n         if path not in paths:\n            self._tailedfiles[path]._close()\n            del self._tailedfiles[path]\n\n      # Add any files we don't have open yet.\n      for path in paths:\n         try:\n            # If the file has been rotated, reopen it.\n            if self._tailedfiles[path].hasBeenRotated():\n               # If it can't be reopened, close it.\n               if not self._tailedfiles[path].reopen():\n                  del self._tailedfiles[path]\n         except KeyError:\n            # Open a file that we haven't seen yet.\n            self._tailedfiles[path] = TailedFile(path, skip_to_end = skip_to_end, offset = self._offsets.get(path, None))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a generator that yields tuples with lines seen since the last time poll was called. Will not block.", "response": "def poll(self, force_rescan = False):\n      \"\"\"A generator producing (path, line) tuples with lines seen since the last time poll() was called. Will not block. Checks for new/deleted/rotated files every `interval` seconds, but will check every time if `force_rescan` is True. (default False)\"\"\"\n      # Check for new, deleted, and rotated files.\n      if force_rescan or time.time() > self._last_scan + self._interval:\n         self._rescan(skip_to_end = False)\n         self._last_scan = time.time()\n\n      filereaders = {}\n      for path, tailedfile in self._tailedfiles.iteritems():\n         filereaders[path] = tailedfile.readlines()\n\n      # One line is read from each file in turn, in an attempt to read\n      # from all files evenly. They'll be in an undefined order because\n      # of using a dict for filereaders, but that's not a problem\n      # because some entropy here is desirable for evenness.\n      while len(filereaders) > 0:\n         for path in filereaders.keys():\n            lines = filereaders[path]\n            try:\n               line, offset = lines.next()\n            except StopIteration:\n               # Reached end the of this file.\n               del filereaders[path]\n               break\n            \n            yield (path, offset), line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef offsets(self):\n      for path, tailedfile in self._tailedfiles.iteritems():\n         yield path, tailedfile._offset", "response": "A generator producing a tuple for all tailed files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to a remote route.", "response": "def connectTo(self, remoteRouteName):\n        \"\"\"\n        Set the name of the route which will be added to outgoing boxes.\n        \"\"\"\n        self.remoteRouteName = remoteRouteName\n        # This route must not be started before its router is started.  If\n        # sender is None, then the router is not started.  When the router is\n        # started, it will start this route.\n        if self.router._sender is not None:\n            self.start()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sendBox(self, box):\n        if self.remoteRouteName is _unspecified:\n            raise RouteNotConnected()\n        if self.remoteRouteName is not None:\n            box[_ROUTE] = self.remoteRouteName.encode('ascii')\n        self.router._sender.sendBox(box)", "response": "Send a box to the router."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new route to associate the given route name with the given receiver.", "response": "def bindRoute(self, receiver, routeName=_unspecified):\n        \"\"\"\n        Create a new route to associate the given route name with the given\n        receiver.\n\n        @type routeName: C{unicode} or L{NoneType}\n        @param routeName: The identifier for the newly created route.  If\n            C{None}, boxes with no route in them will be delivered to this\n            receiver.\n\n        @rtype: L{Route}\n        \"\"\"\n        if routeName is _unspecified:\n            routeName = self.createRouteIdentifier()\n        # self._sender may yet be None; if so, this route goes into _unstarted\n        # and will have its sender set correctly in startReceivingBoxes below.\n        route = Route(self, receiver, routeName)\n        mapping = self._routes\n        if mapping is None:\n            mapping = self._unstarted\n        mapping[routeName] = route\n        return route"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts all the route tracking boxes that are not yet started.", "response": "def startReceivingBoxes(self, sender):\n        \"\"\"\n        Initialize route tracking objects.\n        \"\"\"\n        self._sender = sender\n        for routeName, route in self._unstarted.iteritems():\n            # Any route which has been bound but which does not yet have a\n            # remote route name should not yet be started.  These will be\n            # started in Route.connectTo.\n            if route.remoteRouteName is not _unspecified:\n                route.start()\n        self._routes = self._unstarted\n        self._unstarted = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndispatch the given box to the IBoxReceiver associated with the route indicated by the box.", "response": "def ampBoxReceived(self, box):\n        \"\"\"\n        Dispatch the given box to the L{IBoxReceiver} associated with the route\n        indicated by the box, or handle it directly if there is no route.\n        \"\"\"\n        route = box.pop(_ROUTE, None)\n        self._routes[route].receiver.ampBoxReceived(box)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stopReceivingBoxes(self, reason):\n        for routeName, route in self._routes.iteritems():\n            route.stop(reason)\n        self._routes = None", "response": "Stop all the boxes that have been added to this router."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _s3bukt(self):\n        from boto.exception import S3ResponseError\n        import time\n\n        try:\n            (b, ctime) = self._tlocal.s3bukt\n            if time.time() - ctime > 60:\n                raise AttributeError\n            return b\n        except AttributeError:\n\n            try:\n                # Validate by listing the bucket if there is no prefix.\n                # If there is a prefix, validate by listing only the prefix\n                # itself, to avoid errors when an IAM policy has been applied.\n                if self._prefix:\n                    b = self._s3conn.get_bucket(self._bucket_name, validate=0)\n                    b.get_key(self._prefix)\n                else:\n                    b = self._s3conn.get_bucket(self._bucket_name, validate=1)\n            except S3ResponseError as e:\n\n                if \"404 Not Found\" in str(e):\n                    raise\n\n                b = self._s3conn.get_bucket(self._bucket_name, validate=0)\n\n            self._tlocal.s3bukt = (b, time.time())\n            return b", "response": "Get the bucket without vlaidation when the return to the original validation is not a 404."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npush build to Brew", "response": "def push_build(id, tag_prefix):\n    \"\"\"\n    Push build to Brew\n    \"\"\"\n    req = swagger_client.BuildRecordPushRequestRest()\n    req.tag_prefix = tag_prefix\n    req.build_record_id = id\n    response = utils.checked_api_call(pnc_api.build_push, 'push', body=req)\n    if response:\n        return utils.format_json_list(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push_build_set(id, tag_prefix):\n    req = swagger_client.BuildConfigSetRecordPushRequestRest()\n    req.tag_prefix = tag_prefix\n    req.build_config_set_record_id = id\n    response = utils.checked_api_call(pnc_api.build_push, 'push_record_set', body=req)\n    if response:\n        return utils.format_json_list(response)", "response": "Push build set to Brew\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push_build_status(id):\n    response = utils.checked_api_call(pnc_api.build_push, 'status', build_record_id=id)\n    if response:\n        return utils.format_json(response)", "response": "Get status of Brew push."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates TransientFile and file on FS from given input stream and original file name.", "response": "def create_transient(self, input_stream, original_name, length=None):\n        '''Create TransientFile and file on FS from given input stream and \n        original file name.'''\n        ext = os.path.splitext(original_name)[1]\n        transient = self.new_transient(ext)\n        if not os.path.isdir(self.transient_root):\n            os.makedirs(self.transient_root)\n\n        self._copy_file(input_stream, transient.path, length=length)\n        return transient"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new TransientFile with random name and given extension.", "response": "def new_transient(self, ext=''):\n        '''Creates empty TransientFile with random name and given extension.\n        File on FS is not created'''\n        name = random_name(self.transient_length) + ext\n        return TransientFile(self.transient_root, name, self)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_transient(self, name):\n        '''Restores TransientFile object with given name.\n        Should be used when form is submitted with file name and no file'''\n        # security checks: basically no folders are allowed\n        assert not ('/' in name or '\\\\' in name or name[0] in '.~')\n        transient = TransientFile(self.transient_root, name, self)\n        if not os.path.isfile(transient.path):\n            raise OSError(errno.ENOENT, 'Transient file has been lost',\n                          transient.path)\n        return transient", "response": "Restores TransientFile object with given name. Should be used when form is submitted with file name and no file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef store(self, transient_file, persistent_file):\n        '''Makes PersistentFile from TransientFile'''\n        #for i in range(5):\n        #    persistent_file = PersistentFile(self.persistent_root,\n        #                                     persistent_name, self)\n        #    if not os.path.exists(persistent_file.path):\n        #        break\n        #else:\n        #    raise Exception('Unable to find free file name')\n        dirname = os.path.dirname(persistent_file.path)\n        if not os.path.isdir(dirname):\n            os.makedirs(dirname)\n        os.rename(transient_file.path, persistent_file.path)\n        return persistent_file", "response": "Makes PersistentFile from TransientFile"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sign_payload(self, payload):\n        app_key = self._app_key\n        t = int(time.time() * 1000)\n        requestStr = {\n            'header': self._req_header,\n            'model': payload\n        }\n        data = json.dumps({'requestStr': json.dumps(requestStr)})\n        data_str = '{}&{}&{}&{}'.format(self._req_token, t, app_key, data)\n        sign = hashlib.md5(data_str.encode('utf-8')).hexdigest()\n        params = {\n            't': t,\n            'appKey': app_key,\n            'sign': sign,\n            'data': data,\n        }\n        return params", "response": "Signs the payload using the appkey"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef request(self, action, payload, timeout=3):\n        if self._req_token is None:  # \u83b7\u53d6 token\n            self._fetch_token()\n\n        url = _gen_url(action)\n        params = self._sign_payload(payload)\n        response = self.http.get(url, params=params,\n                                 cookies=self._cookies.get('cookie'),\n                                 timeout=timeout)\n        rv = response.json()\n        code, msg = rv['ret'][0].split('::')\n        # app id \u548c key \u4e0d\u5339\u914d\uff0c\u4e00\u822c\u5e94\u8be5\u4e0d\u4f1a\u51fa\u73b0\u8fd9\u79cd\u60c5\u51b5\n        if code == 'FAIL_SYS_PARAMINVALID_ERROR':\n            raise RuntimeError('Xiami api app id and key not match.')\n        elif code == 'FAIL_SYS_TOKEN_EXOIRED':  # \u5237\u65b0 token\n            self._fetch_token()\n        elif code == 'FAIL_BIZ_GLOBAL_NEED_LOGIN':\n            # TODO: \u5355\u72ec\u5b9a\u4e49\u4e00\u4e2a Exception\n            raise RuntimeError('Xiami api need access token.')\n        else:\n            if code != 'SUCCESS':\n                logger.warning('Xiami request failed:: '\n                               'req_action: {}, req_payload: {}\\n'\n                               'response: {}'\n                               .format(action, payload, rv))\n            return code, msg, rv", "response": "\u867e\u7c73 API \u8bf7\u6c42\u6d41\u7a0b\uff1a\n\n        1. \u83b7\u53d6\u4e00\u4e2a token\uff1a\u968f\u4fbf\u8bbf\u95ee\u4e00\u4e2a\u7f51\u9875\uff0c\u670d\u52a1\u7aef\u4f1a set cookie\u3002\n           \u6839\u636e\u89c2\u5bdf\uff0c\u8fd9\u4e2a token \u4e00\u822c\u662f 7 \u5929\u8fc7\u671f\n        2. \u5bf9\u8bf7\u6c42\u7b7e\u540d\uff1a\u89c1 _sign_payload \u65b9\u6cd5\n        3. \u53d1\u9001\u8bf7\u6c42"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef login(self, email, password):\n        payload = {\n            'account': email,\n            'password': password\n        }\n        code, msg, rv = self.request(\n            'mtop.alimusic.xuser.facade.xiamiuserservice.login',\n            payload\n        )\n        if code == 'SUCCESS':\n            # TODO: \u4fdd\u5b58 refreshToken \u548c\u8fc7\u671f\u65f6\u95f4\u7b49\u66f4\u591a\u4fe1\u606f\n            # \u6839\u636e\u76ee\u524d\u89c2\u5bdf\uff0ctoken \u8fc7\u671f\u65f6\u95f4\u6709\u4e09\u5e74\n            accessToken = rv['data']['data']['accessToken']\n            self.set_access_token(accessToken)\n        return rv", "response": "login to an user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef playlist_detail(self, playlist_id):\n        action = 'mtop.alimusic.music.list.collectservice.getcollectdetail'\n        payload = {'listId': playlist_id}\n        code, msg, rv = self.request(action, payload)\n        return rv['data']['data']['collectDetail']", "response": "Get playlist s songs and collect detail"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of all playlists for a user.", "response": "def user_playlists(self, user_id, page=1, limit=30):\n        \"\"\"\n        NOTE: \u7528\u6237\u6b4c\u5355\u6709\u53ef\u80fd\u662f\u4ec5\u81ea\u5df1\u53ef\u89c1\n        \"\"\"\n        action = 'mtop.alimusic.music.list.collectservice.getcollectbyuser'\n        payload = {\n            'userId': user_id,\n            'pagingVO': {\n                'page': page,\n                'pageSize': limit\n            }\n        }\n        code, msg, rv = self.request(action, payload)\n        # TODO: \u652f\u6301\u83b7\u53d6\u66f4\u591a\n        return rv['data']['data']['collects']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_favorite_song(self, song_id, op):\n        op = 'un' if op == 'del' else ''\n        action = 'mtop.alimusic.fav.songfavoriteservice.{}favoritesong'.format(op)\n        payload = {\n            'songId': song_id\n        }\n        code, msg, rv = self.request(action, payload)\n        return rv['data']['data']['status'] == 'true'", "response": "Update the user s favorite song."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_playlist_song(self, playlist_id, song_id, op):\n        action = 'mtop.alimusic.music.list.collectservice.{}songs'.format(\n            'delete' if op == 'del' else 'add')\n        payload = {\n            'listId': playlist_id,\n            'songIds': [song_id]\n        }\n        code, msg, rv = self.request(action, payload)\n        return rv['data']['data']['success'] == 'true'", "response": "Update a playlist s song."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_dependency(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.add_dependency_with_http_info(id, **kwargs)\n        else:\n            (data) = self.add_dependency_with_http_info(id, **kwargs)\n            return data", "response": "Adds a dependency to the specified build configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a product version to the specified build configuration.", "response": "def add_product_version(self, id, **kwargs):\n        \"\"\"\n        Associates a product version to the specified config\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.add_product_version(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Build Configuration id (required)\n        :param ProductVersionRest body:\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.add_product_version_with_http_info(id, **kwargs)\n        else:\n            (data) = self.add_product_version_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclones an existing Build ConfigurationSingleton clf", "response": "def clone(self, id, **kwargs):\n        \"\"\"\n        Clones an existing Build Configuration\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.clone(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Build Configuration id (required)\n        :return: BuildConfigurationSingleton\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.clone_with_http_info(id, **kwargs)\n        else:\n            (data) = self.clone_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_by_product_id(self, product_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_all_by_product_id_with_http_info(product_id, **kwargs)\n        else:\n            (data) = self.get_all_by_product_id_with_http_info(product_id, **kwargs)\n            return data", "response": "Get all Build Configurations of a Product."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all Build Configurations of a Project", "response": "def get_all_by_project_id(self, project_id, **kwargs):\n        \"\"\"\n        Gets all Build Configurations of a Project\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_all_by_project_id(project_id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int project_id: Project id (required)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :param str sort: Sorting RSQL\n        :param str q: RSQL Query\n        :return: BuildConfigurationPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_all_by_project_id_with_http_info(project_id, **kwargs)\n        else:\n            (data) = self.get_all_by_project_id_with_http_info(project_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_builds(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_builds_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_builds_with_http_info(id, **kwargs)\n            return data", "response": "Get all BuildRecords associated with this Build Configuration. Returns an empty list if no build records are found."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_dependencies(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_dependencies_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_dependencies_with_http_info(id, **kwargs)\n            return data", "response": "Get the direct dependencies of the specified configuration."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_product_versions(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_product_versions_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_product_versions_with_http_info(id, **kwargs)\n            return data", "response": "Get associated Product Versions of the specified Configuration\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets specific audited revision of this build configuration.", "response": "def get_revision(self, id, rev, **kwargs):\n        \"\"\"\n        Get specific audited revision of this build configuration\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_revision(id, rev, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Build configuration id (required)\n        :param int rev: Build configuration rev (required)\n        :return: BuildConfigurationAuditedSingleton\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_revision_with_http_info(id, rev, **kwargs)\n        else:\n            (data) = self.get_revision_with_http_info(id, rev, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the audited revisions of this build configuration.", "response": "def get_revisions(self, id, **kwargs):\n        \"\"\"\n        Gets audited revisions of this build configuration\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_revisions(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Build configuration id (required)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :param str sort: Sorting RSQL\n        :return: BuildConfigurationAuditedPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_revisions_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_revisions_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the minimal set of supported genericParameters and their description for the BuildConfiguration. There can be also other supported parameters not know by core. This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please define a `callback` function to be invoked when receiving the response. >>> def callback_function(response): >>> pprint(response) >>> >>> thread = api.get_supported_generic_parameters(callback=callback_function) :param callback function: The callback function for asynchronous request. (optional) :return: None If the method is called asynchronously, returns the request thread.", "response": "def get_supported_generic_parameters(self, **kwargs):\n        \"\"\"\n        Gets the minimal set of supported genericParameters and their description for the BuildConfiguration. There can be also other supported parameters not know by core.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_supported_generic_parameters(callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_supported_generic_parameters_with_http_info(**kwargs)\n        else:\n            (data) = self.get_supported_generic_parameters_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a configuration from the specified config set.", "response": "def remove_dependency(self, id, dependency_id, **kwargs):\n        \"\"\"\n        Removes a configuration from the specified config set\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.remove_dependency(id, dependency_id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Build configuration set id (required)\n        :param int dependency_id: Build configuration id (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.remove_dependency_with_http_info(id, dependency_id, **kwargs)\n        else:\n            (data) = self.remove_dependency_with_http_info(id, dependency_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a product version from the specified config set.", "response": "def remove_product_version(self, id, product_version_id, **kwargs):\n        \"\"\"\n        Removes a product version from the specified config set\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.remove_product_version(id, product_version_id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Build configuration set id (required)\n        :param int product_version_id: Product version id (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.remove_product_version_with_http_info(id, product_version_id, **kwargs)\n        else:\n            (data) = self.remove_product_version_with_http_info(id, product_version_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrigger a build of a specific Build Configuration.", "response": "def trigger(self, id, **kwargs):\n        \"\"\"\n        Triggers a build of a specific Build Configuration\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.trigger(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Build Configuration id (required)\n        :param str callback_url: Optional Callback URL\n        :param bool temporary_build: Is it a temporary build or a standard build?\n        :param bool force_rebuild: DEPRECATED: Use RebuildMode.\n        :param bool build_dependencies: Should we build also dependencies of this BuildConfiguration?\n        :param bool keep_pod_on_failure: Should we keep the build container running, if the build fails?\n        :param bool timestamp_alignment: Should we add a timestamp during the alignment? Valid only for temporary builds.\n        :param str rebuild_mode: Rebuild Modes: FORCE: always rebuild the configuration; EXPLICIT_DEPENDENCY_CHECK: check if any of user defined dependencies has been update; IMPLICIT_DEPENDENCY_CHECK: check if any captured dependency has been updated;\n        :return: BuildRecordSingleton\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.trigger_with_http_info(id, **kwargs)\n        else:\n            (data) = self.trigger_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef trigger_audited(self, id, rev, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.trigger_audited_with_http_info(id, rev, **kwargs)\n        else:\n            (data) = self.trigger_audited_with_http_info(id, rev, **kwargs)\n            return data", "response": "Triggers a build of a specific Build Configuration in a specific revision."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate an existing Build Configuration and returns a BuildConfigurationAudited entity.", "response": "def update_and_get_audited(self, id, **kwargs):\n        \"\"\"\n        Updates an existing Build Configuration and returns BuildConfigurationAudited entity\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.update_and_get_audited(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Build Configuration id (required)\n        :param BuildConfigurationRest body:\n        :return: BuildConfigurationAuditedSingleton\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.update_and_get_audited_with_http_info(id, **kwargs)\n        else:\n            (data) = self.update_and_get_audited_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef debug_break(sig, frame):\n    d = {'_frame': frame}         # Allow access to frame object.\n    d.update(frame.f_globals)  # Unless shadowed by global\n    d.update(frame.f_locals)\n\n    i = code.InteractiveConsole(d)\n    message = \"Signal recieved : entering python shell.\\nTraceback:\\n\"\n    message += ''.join(traceback.format_stack(frame))\n    i.interact(message)", "response": "Interrupt running process and provide a python prompt for interactive\n    debugging."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints parameteters and return values of the each call of the wrapped function. Usage: decorate appropriate function or method: @trace def myf(): ...", "response": "def trace(fn): # pragma: no cover\n    \"\"\" Prints parameteters and return values of the each call of the wrapped function.\n\n    Usage:\n        decorate appropriate function or method:\n            @trace\n            def myf():\n                ...\n    \"\"\"\n    def wrapped(*args, **kwargs):\n        msg = []\n        msg.append('Enter {}('.format(fn.__name__))\n\n        if args:\n            msg.append(', '.join([str(x) for x in args]))\n\n        if kwargs:\n            kwargs_str = ', '.join(['{}={}'.format(k, v) for k, v in list(kwargs.items())])\n            if args:\n                msg.append(', ')\n            msg.append(kwargs_str)\n        msg.append(')')\n        print(''.join(msg))\n        ret = fn(*args, **kwargs)\n        print('Return {}'.format(ret))\n        return ret\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef patch_file_open(): # pragma: no cover\n\n    openfiles = set()\n    oldfile = builtins.file\n\n    class newfile(oldfile):\n        def __init__(self, *args, **kwargs):\n            self.x = args[0]\n\n            all_fds = count_open_fds()\n\n            print('### {} OPENING {} ( {} total )###'.format(\n                len(openfiles), str(self.x), all_fds))\n            oldfile.__init__(self, *args, **kwargs)\n\n            openfiles.add(self)\n\n        def close(self):\n            print('### {} CLOSING {} ###'.format(len(openfiles), str(self.x)))\n            oldfile.close(self)\n            openfiles.remove(self)\n\n    def newopen(*args, **kwargs):\n        return newfile(*args, **kwargs)\n\n    builtins.file = newfile\n    builtins.open = newopen", "response": "A Monkey patch to log opening and closing of files which is useful for debugging file descriptor exhaustion."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nauthenticating using the given L { AMP client and return a Deferred that fires when the login has succeeded or if the server rejects the login attempt.", "response": "def login(client, credentials):\n    \"\"\"\n    Authenticate using the given L{AMP} instance.  The protocol must be\n    connected to a server with responders for L{PasswordLogin} and\n    L{PasswordChallengeResponse}.\n\n    @param client: A connected L{AMP} instance which will be used to issue\n        authentication commands.\n\n    @param credentials: An object providing L{IUsernamePassword} which will\n        be used to authenticate this connection to the server.\n\n    @return: A L{Deferred} which fires when authentication has succeeded or\n        which fails with L{UnauthorizedLogin} if the server rejects the\n        authentication attempt.\n    \"\"\"\n    if not IUsernamePassword.providedBy(credentials):\n        raise UnhandledCredentials()\n    d = client.callRemote(\n        PasswordLogin, username=credentials.username)\n    def cbChallenge(response):\n        args = PasswordChallengeResponse.determineFrom(\n            response['challenge'], credentials.password)\n        d = client.callRemote(PasswordChallengeResponse, **args)\n        return d.addCallback(lambda ignored: client)\n    d.addCallback(cbChallenge)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef determineFrom(cls, challenge, password):\n        nonce = secureRandom(16)\n        response = _calcResponse(challenge, nonce, password)\n        return dict(cnonce=nonce, response=response)", "response": "Create a nonce and use it along with the given challenge and password and generate the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the given plaintext password against the response in this credentials object.", "response": "def checkPassword(self, password):\n        \"\"\"\n        Check the given plaintext password against the response in this\n        credentials object.\n\n        @type password: C{str}\n        @param password: The known correct password associated with\n            C{self.username}.\n\n        @return: A C{bool}, C{True} if this credentials object agrees with the\n            given password, C{False} otherwise.\n        \"\"\"\n        if isinstance(password, unicode):\n            password = password.encode('utf-8')\n        correctResponse = _calcResponse(self.challenge, self.nonce, password)\n        return correctResponse == self.response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef passwordLogin(self, username):\n        self.challenge = secureRandom(16)\n        self.username = username\n        return {'challenge': self.challenge}", "response": "Generate a new challenge for the given username."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _login(self, credentials):\n        d = self.portal.login(credentials, None, IBoxReceiver)\n        def cbLoggedIn((interface, avatar, logout)):\n            self.logout = logout\n            self.boxReceiver = avatar\n            self.boxReceiver.startReceivingBoxes(self.boxSender)\n            return {}\n        d.addCallback(cbLoggedIn)\n        return d", "response": "Login to our portal with the given credentials."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify the response to a challenge.", "response": "def passwordChallengeResponse(self, cnonce, response):\n        \"\"\"\n        Verify the response to a challenge.\n        \"\"\"\n        return self._login(_AMPUsernamePassword(\n            self.username, self.challenge, cnonce, response))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when the connection has been lost.", "response": "def connectionLost(self, reason):\n        \"\"\"\n        If a login has happened, perform a logout.\n        \"\"\"\n        AMP.connectionLost(self, reason)\n        if self.logout is not None:\n            self.logout()\n            self.boxReceiver = self.logout = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbinding position changed signal with this", "response": "def on_position_changed(self, position):\n        \"\"\"bind position changed signal with this\"\"\"\n        if not self._lyric:\n            return\n\n        pos = find_previous(position*1000 + 300, self._pos_list)\n        if pos is not None and pos != self._pos:\n            self.current_sentence = self._pos_s_map[pos]\n            self._pos = pos"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbinds song changed signal with this", "response": "def on_song_changed(self, song):\n        \"\"\"bind song changed signal with this\"\"\"\n        if song is None or song.lyric is None:\n            self._lyric = None\n            self._pos_s_map = {}\n        else:\n            self._lyric = song.lyric.content\n            self._pos_s_map = parse(self._lyric)\n        self._pos_list = sorted(list(self._pos_s_map.keys()))\n        self._pos = None\n        self.current_sentence = ''"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sanitizeStructTime(struct):\n    maxValues = (9999, 12, 31, 23, 59, 59)\n    minValues = (1, 1, 1, 0, 0, 0)\n    newstruct = []\n    for value, maxValue, minValue in zip(struct[:6], maxValues, minValues):\n        newstruct.append(max(minValue, min(value, maxValue)))\n    return tuple(newstruct) + struct[6:]", "response": "Convert struct_time tuples with possibly invalid values to valid\n    ones by substituting closest valid value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a timedelta to a sign hour and minute triple.", "response": "def _timedeltaToSignHrMin(offset):\n    \"\"\"\n    Return a (sign, hour, minute) triple for the offset described by timedelta.\n\n    sign is a string, either \"+\" or \"-\". In the case of 0 offset, sign is \"+\".\n    \"\"\"\n    minutes = round((offset.days * 3600000000 * 24\n                     + offset.seconds * 1000000\n                     + offset.microseconds)\n                    / 60000000.0)\n    if minutes < 0:\n        sign = '-'\n        minutes = -minutes\n    else:\n        sign = '+'\n    return (sign, minutes // 60, minutes % 60)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new Time instance from a string a human might type.", "response": "def fromHumanly(klass, humanStr, tzinfo=None, now=None):\n        \"\"\"Return a new Time instance from a string a human might type.\n\n        @param humanStr: the string to be parsed.\n\n        @param tzinfo: A tzinfo instance indicating the timezone to assume if\n        none is specified in humanStr. If None, assume UTC.\n\n        @param now: A Time instance to be considered \"now\" for when\n        interpreting relative dates like \"tomorrow\". If None, use the real now.\n\n        Total crap now, it just supports weekdays, \"today\" and \"tomorrow\" for\n        now. This is pretty insufficient and useless, but good enough for some\n        demo functionality, or something.\n        \"\"\"\n        humanStr = humanStr.strip()\n        if now is None:\n            now = Time()\n        if tzinfo is None:\n            tzinfo = FixedOffset(0, 0)\n\n        for pattern, creator in klass.humanlyPatterns:\n            match = pattern.match(humanStr)\n            if not match \\\n            or match.span()[1] != len(humanStr):\n                continue\n            try:\n                return creator(klass, match, tzinfo, now)\n            except ValueError:\n                continue\n        raise ValueError, 'could not parse date: %r' % (humanStr,)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new Time instance from a string formated as in ISO 8601 format.", "response": "def fromISO8601TimeAndDate(klass, iso8601string, tzinfo=None):\n        \"\"\"Return a new Time instance from a string formated as in ISO 8601.\n\n        If the given string contains no timezone, it is assumed to be in the\n        timezone specified by the parameter `tzinfo`, or UTC if tzinfo is None.\n        An input string with an explicit timezone will always override tzinfo.\n\n        If the given iso8601string does not contain all parts of the time, they\n        will default to 0 in the timezone given by `tzinfo`.\n\n        WARNING: this function is incomplete. ISO is dumb and their standards\n        are not free. Only a subset of all valid ISO 8601 dates are parsed,\n        because I can't find a formal description of the format. However,\n        common ones should work.\n        \"\"\"\n\n        def calculateTimezone():\n            if groups['zulu'] == 'Z':\n                return FixedOffset(0, 0)\n            else:\n                tzhour = groups.pop('tzhour')\n                tzmin = groups.pop('tzmin')\n                if tzhour is not None:\n                    return FixedOffset(int(tzhour), int(tzmin or 0))\n            return tzinfo or FixedOffset(0, 0)\n\n        def coerceGroups():\n            groups['month'] = groups['month1'] or groups['month2']\n            groups['week'] = groups['week1'] or groups['week2']\n            # don't include fractional seconds, because it's not an integer.\n            defaultTo0 = ['hour', 'minute', 'second']\n            defaultTo1 = ['month', 'day', 'week', 'weekday', 'dayofyear']\n            if groups['fractionalsec'] is None:\n                groups['fractionalsec'] = '0'\n            for key in defaultTo0:\n                if groups[key] is None:\n                    groups[key] = 0\n            for key in defaultTo1:\n                if groups[key] is None:\n                    groups[key] = 1\n            groups['fractionalsec'] = float('.'+groups['fractionalsec'])\n            for key in defaultTo0 + defaultTo1 + ['year']:\n                groups[key] = int(groups[key])\n\n            for group, min, max in [\n                # some years have only 52 weeks\n                ('week', 1, 53),\n                ('weekday', 1, 7),\n                ('month', 1, 12),\n                ('day', 1, 31),\n                ('hour', 0, 24),\n                ('minute', 0, 59),\n\n                # Sometime in the 22nd century AD, two leap seconds will be\n                # required every year.  In the 25th century AD, four every\n                # year.  We'll ignore that for now though because it would be\n                # tricky to get right and we certainly don't need it for our\n                # target applications.  In other words, post-singularity\n                # Martian users, please do not rely on this code for\n                # compatibility with Greater Galactic Protectorate of Earth\n                # date/time formatting!  Apologies, but no library I know of in\n                # Python is sufficient for processing their dates and times\n                # without ADA bindings to get the radiation-safety zone counter\n                # correct. -glyph\n\n                ('second', 0, 61),\n                # don't forget leap years\n                ('dayofyear', 1, 366)]:\n                if not min <= groups[group] <= max:\n                    raise ValueError, '%s must be in %i..%i' % (group, min, max)\n\n        def determineResolution():\n            if match.group('fractionalsec') is not None:\n                return max(datetime.timedelta.resolution,\n                    datetime.timedelta(\n                        microseconds=1 * 10 ** -len(\n                            match.group('fractionalsec')) * 1000000))\n\n            for testGroup, resolution in [\n            ('second', datetime.timedelta(seconds=1)),\n            ('minute', datetime.timedelta(minutes=1)),\n            ('hour', datetime.timedelta(hours=1)),\n            ('weekday', datetime.timedelta(days=1)),\n            ('dayofyear', datetime.timedelta(days=1)),\n            ('day', datetime.timedelta(days=1)),\n            ('week1', datetime.timedelta(weeks=1)),\n            ('week2', datetime.timedelta(weeks=1))]:\n                if match.group(testGroup) is not None:\n                    return resolution\n\n            if match.group('month1') is not None \\\n            or match.group('month2') is not None:\n                if self._time.month == 12:\n                    return datetime.timedelta(days=31)\n                nextMonth = self._time.replace(month=self._time.month+1)\n                return nextMonth - self._time\n            else:\n                nextYear = self._time.replace(year=self._time.year+1)\n                return nextYear - self._time\n\n        def calculateDtime(tzinfo):\n            \"\"\"Calculate a datetime for the start of the addressed period.\"\"\"\n\n            if match.group('week1') is not None \\\n            or match.group('week2') is not None:\n                if not 0 < groups['week'] <= 53:\n                    raise ValueError(\n                        'week must be in 1..53 (was %i)' % (groups['week'],))\n                dtime = datetime.datetime(\n                    groups['year'],\n                    1,\n                    4,\n                    groups['hour'],\n                    groups['minute'],\n                    groups['second'],\n                    int(round(groups['fractionalsec'] * 1000000)),\n                    tzinfo=tzinfo\n                )\n                dtime -= datetime.timedelta(days = dtime.weekday())\n                dtime += datetime.timedelta(\n                    days = (groups['week']-1) * 7 + groups['weekday'] - 1)\n                if dtime.isocalendar() != (\n                    groups['year'], groups['week'], groups['weekday']):\n                    # actually the problem could be an error in my logic, but\n                    # nothing should cause this but requesting week 53 of a\n                    # year with 52 weeks.\n                    raise ValueError('year %04i has no week %02i' %\n                                     (groups['year'], groups['week']))\n                return dtime\n\n            if match.group('dayofyear') is not None:\n                dtime = datetime.datetime(\n                    groups['year'],\n                    1,\n                    1,\n                    groups['hour'],\n                    groups['minute'],\n                    groups['second'],\n                    int(round(groups['fractionalsec'] * 1000000)),\n                    tzinfo=tzinfo\n                )\n                dtime += datetime.timedelta(days=groups['dayofyear']-1)\n                if dtime.year != groups['year']:\n                    raise ValueError(\n                        'year %04i has no day of year %03i' %\n                        (groups['year'], groups['dayofyear']))\n                return dtime\n\n            else:\n                return datetime.datetime(\n                    groups['year'],\n                    groups['month'],\n                    groups['day'],\n                    groups['hour'],\n                    groups['minute'],\n                    groups['second'],\n                    int(round(groups['fractionalsec'] * 1000000)),\n                    tzinfo=tzinfo\n                )\n\n\n        match = klass.iso8601pattern.match(iso8601string)\n        if match is None:\n            raise ValueError(\n                '%r could not be parsed as an ISO 8601 date and time' %\n                (iso8601string,))\n\n        groups = match.groupdict()\n        coerceGroups()\n        if match.group('hour') is not None:\n            timezone = calculateTimezone()\n        else:\n            timezone = None\n        self = klass.fromDatetime(calculateDtime(timezone))\n        self.resolution = determineResolution()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromStructTime(klass, structTime, tzinfo=None):\n        dtime = datetime.datetime(tzinfo=tzinfo, *structTime[:6])\n        self = klass.fromDatetime(dtime)\n        self.resolution = datetime.timedelta(seconds=1)\n        return self", "response": "Return a new Time instance from a time. struct_time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new Time instance from a datetime. datetime instance.", "response": "def fromDatetime(klass, dtime):\n        \"\"\"Return a new Time instance from a datetime.datetime instance.\n\n        If the datetime instance does not have an associated timezone, it is\n        assumed to be UTC.\n        \"\"\"\n        self = klass.__new__(klass)\n        if dtime.tzinfo is not None:\n            self._time = dtime.astimezone(FixedOffset(0, 0)).replace(tzinfo=None)\n        else:\n            self._time = dtime\n        self.resolution = datetime.timedelta.resolution\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new Time instance from a number of seconds since the POSIX epoch.", "response": "def fromPOSIXTimestamp(klass, secs):\n        \"\"\"Return a new Time instance from seconds since the POSIX epoch.\n\n        The POSIX epoch is midnight Jan 1, 1970 UTC. According to POSIX, leap\n        seconds don't exist, so one UTC day is exactly 86400 seconds, even if\n        it wasn't.\n\n        @param secs: a number of seconds, represented as an integer, long or\n        float.\n        \"\"\"\n        self = klass.fromDatetime(_EPOCH + datetime.timedelta(seconds=secs))\n        self.resolution = datetime.timedelta()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromRFC2822(klass, rfc822string):\n\n        # parsedate_tz is going to give us a \"struct_time plus\", a 10-tuple\n        # containing the 9 values a struct_time would, i.e.: (tm_year, tm_mon,\n        # tm_day, tm_hour, tm_min, tm_sec, tm_wday, tm_yday, tm_isdst), plus a\n        # bonus \"offset\", which is an offset (in _seconds_, of all things).\n\n        maybeStructTimePlus = parsedate_tz(rfc822string)\n\n        if maybeStructTimePlus is None:\n            raise ValueError, 'could not parse RFC 2822 date %r' % (rfc822string,)\n        structTimePlus = sanitizeStructTime(maybeStructTimePlus)\n        offsetInSeconds = structTimePlus[-1]\n        if offsetInSeconds is None:\n            offsetInSeconds = 0\n        self = klass.fromStructTime(\n            structTimePlus,\n            FixedOffset(\n                hours=0,\n                minutes=offsetInSeconds // 60))\n        self.resolution = datetime.timedelta(seconds=1)\n        return self", "response": "Return a new Time instance from a string formated as described in RFC 2822."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asDatetime(self, tzinfo=None):\n        if tzinfo is None:\n            tzinfo = FixedOffset(0, 0)\n\n        if not self.isTimezoneDependent():\n            return self._time.replace(tzinfo=tzinfo)\n        else:\n            return self._time.replace(tzinfo=FixedOffset(0, 0)).astimezone(tzinfo)", "response": "Return this time as an aware datetime. datetime instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef asRFC2822(self, tzinfo=None, includeDayOfWeek=True):\n        dtime = self.asDatetime(tzinfo)\n\n        if tzinfo is None:\n            rfcoffset = '-0000'\n        else:\n            rfcoffset = '%s%02i%02i' % _timedeltaToSignHrMin(dtime.utcoffset())\n\n        rfcstring = ''\n        if includeDayOfWeek:\n            rfcstring += self.rfc2822Weekdays[dtime.weekday()] + ', '\n\n        rfcstring += '%i %s %4i %02i:%02i:%02i %s' % (\n            dtime.day,\n            self.rfc2822Months[dtime.month - 1],\n            dtime.year,\n            dtime.hour,\n            dtime.minute,\n            dtime.second,\n            rfcoffset)\n\n        return rfcstring", "response": "Return this Time formatted as specified in RFC 2822."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn this time formatted as specified by ISO 8861.", "response": "def asISO8601TimeAndDate(self, includeDelimiters=True, tzinfo=None,\n                             includeTimezone=True):\n        \"\"\"Return this time formatted as specified by ISO 8861.\n\n        ISO 8601 allows optional dashes to delimit dates and colons to delimit\n        times. The parameter includeDelimiters (default True) defines the\n        inclusion of these delimiters in the output.\n\n        If tzinfo is a datetime.tzinfo instance, the output time will be in the\n        timezone given. If it is None (the default), then the timezone string\n        will not be included in the output, and the time will be in UTC.\n\n        The includeTimezone parameter coresponds to the inclusion of an\n        explicit timezone. The default is True.\n        \"\"\"\n        if not self.isTimezoneDependent():\n            tzinfo = None\n        dtime = self.asDatetime(tzinfo)\n\n        if includeDelimiters:\n            dateSep = '-'\n            timeSep = ':'\n        else:\n            dateSep = timeSep = ''\n\n        if includeTimezone:\n            if tzinfo is None:\n                timezone = '+00%s00' % (timeSep,)\n            else:\n                sign, hour, min = _timedeltaToSignHrMin(dtime.utcoffset())\n                timezone = '%s%02i%s%02i' % (sign, hour, timeSep, min)\n        else:\n            timezone = ''\n\n        microsecond = ('%06i' % (dtime.microsecond,)).rstrip('0')\n        if microsecond:\n            microsecond = '.' + microsecond\n\n        parts = [\n            ('%04i' % (dtime.year,), datetime.timedelta(days=366)),\n            ('%s%02i' % (dateSep, dtime.month), datetime.timedelta(days=31)),\n            ('%s%02i' % (dateSep, dtime.day), datetime.timedelta(days=1)),\n            ('T', datetime.timedelta(hours=1)),\n            ('%02i' % (dtime.hour,), datetime.timedelta(hours=1)),\n            ('%s%02i' % (timeSep, dtime.minute), datetime.timedelta(minutes=1)),\n            ('%s%02i' % (timeSep, dtime.second), datetime.timedelta(seconds=1)),\n            (microsecond, datetime.timedelta(microseconds=1)),\n            (timezone, datetime.timedelta(hours=1))\n        ]\n\n        formatted = ''\n        for part, minResolution in parts:\n            if self.resolution <= minResolution:\n                formatted += part\n\n        return formatted"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns this time represented as a time. struct_time.", "response": "def asStructTime(self, tzinfo=None):\n        \"\"\"Return this time represented as a time.struct_time.\n\n        tzinfo is a datetime.tzinfo instance coresponding to the desired\n        timezone of the output. If is is the default None, UTC is assumed.\n        \"\"\"\n        dtime = self.asDatetime(tzinfo)\n        if tzinfo is None:\n            return dtime.utctimetuple()\n        else:\n            return dtime.timetuple()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning this time as a short string.", "response": "def asHumanly(self, tzinfo=None, now=None, precision=Precision.MINUTES):\n        \"\"\"Return this time as a short string, tailored to the current time.\n\n        Parts of the date that can be assumed are omitted. Consequently, the\n        output string depends on the current time. This is the format used for\n        displaying dates in most user visible places in the quotient web UI.\n\n        By default, the current time is determined by the system clock. The\n        current time used for formatting the time can be changed by providing a\n        Time instance as the parameter 'now'.\n\n        @param precision: The smallest unit of time that will be represented\n        in the returned string.  Valid values are L{Time.Precision.MINUTES} and\n        L{Time.Precision.SECONDS}.\n\n        @raise InvalidPrecision: if the specified precision is not either\n        L{Time.Precision.MINUTES} or L{Time.Precision.SECONDS}.\n        \"\"\"\n        try:\n            timeFormat = Time._timeFormat[precision]\n        except KeyError:\n            raise InvalidPrecision(\n                    'Use Time.Precision.MINUTES or Time.Precision.SECONDS')\n\n        if now is None:\n            now = Time().asDatetime(tzinfo)\n        else:\n            now = now.asDatetime(tzinfo)\n        dtime = self.asDatetime(tzinfo)\n\n        # Same day?\n        if dtime.date() == now.date():\n            if self.isAllDay():\n                return 'all day'\n            return dtime.strftime(timeFormat).lower()\n        else:\n            res = str(dtime.date().day) + dtime.strftime(' %b')  # day + month\n            # Different year?\n            if not dtime.date().year == now.date().year:\n                res += dtime.strftime(' %Y')\n            if not self.isAllDay():\n                res += dtime.strftime(', %s' % (timeFormat,)).lower()\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a pair describing the bounds of this time instance.", "response": "def getBounds(self, tzinfo=None):\n        \"\"\"\n        Return a pair describing the bounds of self.\n\n        This returns a pair (min, max) of Time instances. It is not quite the\n        same as (self, self + self.resolution). This is because timezones are\n        insignificant for instances with a resolution greater or equal to 1\n        day.\n\n        To illustrate the problem, consider a Time instance::\n\n            T = Time.fromHumanly('today', tzinfo=anything)\n\n        This will return an equivalent instance independent of the tzinfo used.\n        The hour, minute, and second of this instance are 0, and its resolution\n        is one day.\n\n        Now say we have a sorted list of times, and we want to get all times\n        for 'today', where whoever said 'today' is in a timezone that's 5 hours\n        ahead of UTC. The start of 'today' in this timezone is UTC 05:00. The\n        example instance T above is before this, but obviously it is today.\n\n        The min and max times this returns are such that all potentially\n        matching instances are within this range. However, this range might\n        contain unmatching instances.\n\n        As an example of this, if 'today' is April first 2005, then\n        Time.fromISO8601TimeAndDate('2005-04-01T00:00:00') sorts in the same\n        place as T from above, but is not in the UTC+5 'today'.\n\n        TIME IS FUN!\n        \"\"\"\n        if self.resolution >= datetime.timedelta(days=1) \\\n        and tzinfo is not None:\n            time = self._time.replace(tzinfo=tzinfo)\n        else:\n            time = self._time\n\n        return (\n            min(self.fromDatetime(time), self.fromDatetime(self._time)),\n            max(self.fromDatetime(time + self.resolution),\n                self.fromDatetime(self._time + self.resolution))\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef oneDay(self):\n        day = self.__class__.fromDatetime(self.asDatetime().replace(\n                hour=0, minute=0, second=0, microsecond=0))\n        day.resolution = datetime.timedelta(days=1)\n        return day", "response": "Return a new Time instance representing the first day of the start of self."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a logger by name.", "response": "def get_logger(name, file_name=None, stream=None, template=None, propagate=False, level=None):\n    \"\"\"Get a logger by name.\n\n    \"\"\"\n\n    logger = logging.getLogger(name)\n    running_tests = (\n        'test' in sys.argv  # running with setup.py\n        or sys.argv[0].endswith('py.test'))  # running with py.test\n    if running_tests and not level:\n        # testing without level, this means tester does not want to see any log messages.\n        level = logging.CRITICAL\n\n    if not level:\n        level = logging.INFO\n    logger.setLevel(level)\n    logger.propagate = propagate\n\n    formatter = logging.Formatter(template)\n\n    if not stream:\n        stream = sys.stdout\n\n    logger.handlers = []\n    handler = logging.StreamHandler(stream=stream)\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n\n    if file_name:\n        handler = logging.FileHandler(file_name)\n        handler.setFormatter(logging.Formatter('%(asctime)s '+template))\n        logger.addHandler(handler)\n\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlike memoize but forgets after 10 seconds.", "response": "def expiring_memoize(obj):\n    \"\"\"Like memoize, but forgets after 10 seconds.\"\"\"\n\n    cache = obj.cache = {}\n    last_access = obj.last_access = defaultdict(int)\n\n    @wraps(obj)\n    def memoizer(*args, **kwargs):\n        key = str(args) + str(kwargs)\n\n        if last_access[key] and last_access[key] + 10 < time():\n            if key in cache:\n                del cache[key]\n\n        last_access[key] = time()\n\n        if key not in cache:\n            cache[key] = obj(*args, **kwargs)\n        return cache[key]\n\n    return memoizer"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures logging for the given configuration.", "response": "def configure_logging(cfg, custom_level=None):\n    \"\"\"Don't know what this is for ....\"\"\"\n    import itertools as it\n    import operator as op\n\n    if custom_level is None:\n        custom_level = logging.WARNING\n    for entity in it.chain.from_iterable(it.imap(op.methodcaller('viewvalues'),\n                                                 [cfg] + [cfg.get(k, dict()) for k in ['handlers', 'loggers']])):\n        if isinstance(entity, Mapping) and entity.get('level') == 'custom':\n            entity['level'] = custom_level\n    logging.config.dictConfig(cfg)\n    logging.captureWarnings(cfg.warnings)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates an MD5 for a possibly large file by breaking it into chunks and returning it.", "response": "def md5_for_file(f, block_size=2 ** 20):\n    \"\"\"Generate an MD5 has for a possibly large file by breaking it into\n    chunks.\"\"\"\n\n    md5 = hashlib.md5()\n    try:\n        # Guess that f is a FLO.\n        f.seek(0)\n\n        return md5_for_stream(f, block_size=block_size)\n\n    except AttributeError:\n        # Nope, not a FLO. Maybe string?\n\n        file_name = f\n        with open(file_name, 'rb') as f:\n            return md5_for_file(f, block_size)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_acro(past, prefix, s):  # pragma: no cover\n\n    def _make_acro(s, t=0):\n        \"\"\"Make an acronym of s for trial t\"\"\"\n\n        # Really should cache these ...\n        v = ['a', 'e', 'i', 'o', 'u', 'y']\n        c = [chr(x) for x in six_xrange(ord('a'), ord('z') + 1) if chr(x) not in v]\n\n        s = re.sub(r'\\W+', '', s.lower())\n\n        vx = [x for x in s if x in v]  # Vowels in input string\n        cx = [x for x in s if x in c]  # Consonants in input string\n\n        if s.startswith('Mc'):\n\n            if t < 1:\n                return 'Mc' + v[0]\n            if t < 2:\n                return 'Mc' + c[0]\n\n        if s[0] in v:  # Starts with a vowel\n            if t < 1:\n                return vx[0] + cx[0] + cx[1]\n            if t < 2:\n                return vx[0] + vx[1] + cx[0]\n\n        if s[0] in c and s[1] in c:  # Two first consonants\n            if t < 1:\n                return cx[0] + cx[1] + vx[0]\n            if t < 2:\n                return cx[0] + cx[1] + cx[2]\n\n        if t < 3:\n            return cx[0] + vx[0] + cx[1]\n        if t < 4:\n            return cx[0] + cx[1] + cx[2]\n        if t < 5:\n            return cx[0] + vx[0] + vx[1]\n        if t < 6:\n            return cx[0] + cx[1] + cx[-1]\n\n        # These are punts; just take a substring\n\n        if t < 7:\n            return s[0:3]\n        if t < 8:\n            return s[1:4]\n        if t < 9:\n            return s[2:5]\n        if t < 10:\n            return s[3:6]\n\n        return None\n\n    for t in six_xrange(11): # Try multiple forms until one isn't in the past acronyms\n\n        try:\n            a = _make_acro(s, t)\n\n            if a is not None:\n                if prefix:\n                    aps = prefix + a\n                else:\n                    aps = a\n\n                if aps not in past:\n                    past.add(aps)\n                    return a\n\n        except IndexError:\n            pass\n\n    raise Exception('Could not get acronym.')", "response": "Create an acronym from the input string s."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensure_dir_exists(path):\n\n    import os\n\n    f_dir = os.path.dirname(path)\n\n    if not os.path.exists(f_dir):\n        os.makedirs(f_dir)\n\n    return f_dir", "response": "Ensures that the path to the file exists"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwalks a dict and yield a 3 - tuple containing the path sub - dicts and values for each key in the dict.", "response": "def walk_dict(d):\n    \"\"\"Walk a tree (nested dicts).\n\n    For each 'path', or dict, in the tree, returns a 3-tuple containing:\n    (path, sub-dicts, values)\n\n    where:\n    * path is the path to the dict\n    * sub-dicts is a tuple of (key,dict) pairs for each sub-dict in this dict\n    * values is a tuple of (key,value) pairs for each (non-dict) item in this dict\n\n    \"\"\"\n    # nested dict keys\n    nested_keys = tuple(k for k in list(d.keys()) if isinstance(d[k], dict))\n    # key/value pairs for non-dicts\n    items = tuple((k, d[k]) for k in list(d.keys()) if k not in nested_keys)\n\n    # return path, key/sub-dict pairs, and key/value pairs\n    yield ('/', [(k, d[k]) for k in nested_keys], items)\n\n    # recurse each subdict\n    for k in nested_keys:\n        for res in walk_dict(d[k]):\n            # for each result, stick key in path and pass on\n            res = ('/%s' % k + res[0], res[1], res[2])\n            yield res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_log_rate(output_f, N=None, message='', print_rate=None):\n\n    if print_rate and not N:\n        N = 100\n\n    if not N:\n        N = 5000\n\n    d = [0,  # number of items processed\n         time(),  # start time. This one gets replaced after first message\n         N,  # ticker to next message\n         N,  # frequency to log a message\n         message,\n         print_rate,\n         deque([], maxlen=4)  # Deque for averaging last N rates\n         ]\n\n    assert isinstance(output_f, Callable)\n\n    f = partial(_log_rate, output_f, d)\n    f.always = output_f\n    f.count = lambda: d[0]\n\n    return f", "response": "Initialze the log_rate function. Returnas a partial function to call for\n    each event."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _log_rate(output_f, d, message=None):\n\n    if d[2] <= 0:\n\n        if message is None:\n            message = d[4]\n\n        # Average the rate over the length of the deque.\n        d[6].append(int(d[3] / (time() - d[1])))\n        rate = sum(d[6]) / len(d[6])\n\n        # Prints the processing rate in 1,000 records per sec.\n        output_f(message + ': ' + str(rate) + '/s ' + str(d[0] / 1000) + 'K ')\n\n        d[1] = time()\n\n        # If the print_rate was specified, adjust the number of records to\n        # aproximate that rate.\n        if d[5]:\n            target_rate = rate * d[5]\n            d[3] = int((target_rate + d[3]) / 2)\n\n        d[2] = d[3]\n\n    d[0] += 1\n    d[2] -= 1", "response": "Log a message for the Nth time the method is called."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the number of open file descriptors for current process", "response": "def count_open_fds():\n    \"\"\"return the number of open file descriptors for current process.\n\n    .. warning: will only work on UNIX-like os-es.\n\n    http://stackoverflow.com/a/7142094\n\n    \"\"\"\n\n    pid = os.getpid()\n    procs = subprocess.check_output(\n        ['lsof', '-w', '-Ff', '-p', str(pid)])\n\n    nprocs = len(\n        [s for s in procs.split('\\n') if s and s[0] == 'f' and s[1:].isdigit()]\n    )\n    return nprocs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_url_to_dict(url):\n    p = urlparse(url)\n\n    return {\n        'scheme': p.scheme,\n        'netloc': p.netloc,\n        'path': p.path,\n        'params': p.params,\n        'query': p.query,\n        'fragment': p.fragment,\n        'username': p.username,\n        'password': p.password,\n        'hostname': p.hostname,\n        'port': p.port\n    }", "response": "Parse a url and return a dict with keys for all of the parts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchange one or more parts of a URL", "response": "def set_url_part(url, **kwargs):\n    \"\"\"Change one or more parts of a URL\"\"\"\n    d = parse_url_to_dict(url)\n\n    d.update(kwargs)\n\n    return unparse_url_dict(d)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfilter a URL by returning only the parts specified in the keywords", "response": "def filter_url(url, **kwargs):\n    \"\"\"filter a URL by returning a URL with only the parts specified in the keywords\"\"\"\n\n    d = parse_url_to_dict(url)\n\n    d.update(kwargs)\n\n    return unparse_url_dict({k: v for k, v in list(d.items()) if v})"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfulls name of an object including the module", "response": "def qualified_class_name(o):\n    \"\"\"Full name of an object, including the module\"\"\"\n    module = o.__class__.__module__\n    if module is None or module == str.__class__.__module__:\n        return o.__class__.__name__\n    return module + '.' + o.__class__.__name__"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfulls name of a class including the module.", "response": "def qualified_name(cls):\n    \"\"\"Full name of a class, including the module. Like qualified_class_name, but when you already have a class \"\"\"\n    module = cls.__module__\n    if module is None or module == str.__class__.__module__:\n        return cls.__name__\n    return module + '.' + cls.__name__"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef qualified_name_import(cls):\n\n    parts = qualified_name(cls).split('.')\n\n    return \"from {} import {}\".format('.'.join(parts[:-1]), parts[-1])", "response": "Returns the qualified name of a class including the module."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransposes the columns into rows then remove all of the rows that are empty after the first cell.", "response": "def drop_empty(rows):\n    \"\"\"Transpose the columns into rows, remove all of the rows that are empty after the first cell, then\n    transpose back. The result is that columns that have a header but no data in the body are removed, assuming\n    the header is the first row. \"\"\"\n    return zip(*[col for col in zip(*rows) if bool(filter(bool, col[1:]))])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a module.http://stackoverflow.com/a/1668289 :param modname: :param paranoid: :return:", "response": "def delete_module(modname, paranoid=None):\n    \"\"\" Delete a module.http://stackoverflow.com/a/1668289\n    :param modname:\n    :param paranoid:\n    :return:\n    \"\"\"\n    from sys import modules\n    try:\n        thismod = modules[modname]\n    except KeyError:\n        raise ValueError(modname)\n    these_symbols = dir(thismod)\n    if paranoid:\n        try:\n            paranoid[:]  # sequence support\n        except:\n            raise ValueError('must supply a finite list for paranoid')\n        else:\n            these_symbols = paranoid[:]\n    del modules[modname]\n    for mod in modules.values():\n        try:\n            delattr(mod, modname)\n        except AttributeError:\n            pass\n        if paranoid:\n            for symbol in these_symbols:\n                if symbol[:2] == '__':  # ignore special symbols\n                    continue\n                try:\n                    delattr(mod, symbol)\n                except AttributeError:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_class_proxy(cls, theclass):\n\n        def make_method(name):\n            def method(self, *args, **kw):\n                return getattr(object.__getattribute__(self, \"_obj\"), name)(*args, **kw)\n            return method\n\n        namespace = {}\n        for name in cls._special_names:\n            if hasattr(theclass, name):\n                namespace[name] = make_method(name)\n        return type(\"%s(%s)\" % (cls.__name__, theclass.__name__), (cls,), namespace)", "response": "creates a proxy for the given class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the inflation based on a value and a reference value", "response": "def _compute_inflation(value, reference_value):\n        \"\"\"\n        Helper function to compute the inflation/deflation based on a value and\n        a reference value\n        \"\"\"\n        res = value / float(reference_value)\n        return InflationResult(factor=res, value=res - 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, reference, country,  target=datetime.date.today()):\n\n        # Set country & reference to object's country & reference respectively\n        reference = self.reference if reference is None else reference\n\n        # Get the reference and target indices (values) from the source\n        reference_value = self.data.get(reference, country).value\n        target_value = self.data.get(target, country).value\n\n        # Compute the inflation value and return it\n        return self._compute_inflation(target_value, reference_value)", "response": "Get the inflation value change for the target date based \n        on the reference date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninflate a given amount to a target date from a reference date and a country.", "response": "def inflate(self, amount, target=datetime.date.today(), reference=None,\n                country=None):\n        \"\"\"\n        Inflate a given amount to the target date from a reference date (or\n        the object's reference year if no reference date is provided) in a\n        given country (or objects country if no country is provided). The\n        amount has to be provided as it was valued in the reference year.\n        \"\"\"\n        country = country if country else self.country\n\n        # Get the inflation for the two dates and country\n        inflation = self.get(reference, country, target)\n        # Return the inflated/deflated amount\n        return amount * inflation.factor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses argv and runs neccessary command. Is to be used in manage.py file. Accept a dict with digest name as keys and instances of :class:`Cli<iktomi.management.commands.Cli>` objects as values. The format of command is the following:: ./manage.py digest_name:command_name[ arg1[ arg2[...]]][ --key1=kwarg1[...]] where command_name is a part of digest instance method name, args and kwargs are passed to the method. For details, see :class:`Cli<iktomi.management.commands.Cli>` docs.", "response": "def manage(commands, argv=None, delim=':'):\n    '''\n    Parses argv and runs neccessary command. Is to be used in manage.py file.\n\n    Accept a dict with digest name as keys and instances of\n    :class:`Cli<iktomi.management.commands.Cli>`\n    objects as values.\n\n    The format of command is the following::\n\n        ./manage.py digest_name:command_name[ arg1[ arg2[...]]][ --key1=kwarg1[...]]\n\n    where command_name is a part of digest instance method name, args and kwargs\n    are passed to the method. For details, see\n    :class:`Cli<iktomi.management.commands.Cli>` docs.\n    '''\n\n    commands = {(k.decode('utf-8') if isinstance(k, six.binary_type) else k): v\n                for k, v in commands.items()}\n\n    # Default django autocompletion script is registered to manage.py\n    # We use the same name for this script and it seems to be ok\n    # to implement the same interface\n    def perform_auto_complete(commands):\n        from .lazy import LazyCli\n        cwords = os.environ['COMP_WORDS'].split()[1:]\n        cword = int(os.environ['COMP_CWORD'])\n\n        try:\n            curr = cwords[cword - 1]\n        except IndexError:\n            curr = ''\n\n        suggest = []\n        if len(cwords) > 1 and cwords[0] in commands.keys():\n            value = commands[cwords[0]]\n            if isinstance(value, LazyCli):\n                value = value.get_digest()\n\n            for cmd_name, _ in value.get_funcs():\n                cmd_name = cmd_name[8:]\n                suggest.append(cmd_name)\n            if curr == \":\":\n                curr = ''\n        else:\n            suggest += list(commands.keys()) + [x+\":\" for x in commands.keys()]\n        suggest.sort()\n        output = u\" \".join(filter(lambda x: x.startswith(curr), suggest))\n        sys.stdout.write(output)\n\n    auto_complete = 'IKTOMI_AUTO_COMPLETE' in os.environ or \\\n                    'DJANGO_AUTO_COMPLETE' in os.environ\n    if auto_complete:\n        perform_auto_complete(commands)\n        sys.exit(0)\n\n    argv = sys.argv if argv is None else argv\n    if len(argv) > 1:\n        cmd_name = argv[1]\n        raw_args = argv[2:]\n        args, kwargs = [], {}\n        # parsing params\n        for item in raw_args:\n            if item.startswith('--'):\n                splited = item[2:].split('=', 1)\n                if len(splited) == 2:\n                    k,v = splited\n                elif len(splited) == 1:\n                    k,v = splited[0], True\n                kwargs[k] = v\n            else:\n                args.append(item)\n\n        # trying to get command instance\n        if delim in cmd_name:\n            digest_name, command = cmd_name.split(delim)\n        else:\n            digest_name = cmd_name\n            command = None\n        try:\n            digest = commands[digest_name]\n        except KeyError:\n            _command_list(commands)\n            sys.exit('ERROR: Command \"{}\" not found'.format(digest_name))\n        try:\n            if command is None:\n                if isinstance(digest, Cli):\n                    help_ = digest.description(argv[0], digest_name)\n                    sys.stdout.write(help_)\n                    sys.exit('ERROR: \"{}\" command digest requires command name'\\\n                                .format(digest_name))\n                digest(*args, **kwargs)\n            else:\n                digest(command, *args, **kwargs)\n        except CommandNotFound:\n            help_ = digest.description(argv[0], digest_name)\n            sys.stdout.write(help_)\n            sys.exit('ERROR: Command \"{}:{}\" not found'.format(digest_name, command))\n    else:\n        _command_list(commands)\n        sys.exit('Please provide any command')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef description(self, argv0='manage.py', command=None):\n        '''Description outputed to console'''\n        command = command or self.__class__.__name__.lower()\n        import inspect\n        _help = u''\n        _help += u'{}\\n'.format(command)\n        if self.__doc__:\n            _help += self._fix_docstring(self.__doc__) +'\\n'\n        else:\n            _help += u'{}\\n'.format(command)\n\n        funcs = self.get_funcs()\n        funcs.sort(key=lambda x: six.get_function_code(x[1]).co_firstlineno)\n\n        for attr, func in funcs:\n            func = getattr(self, attr)\n            comm = attr.replace('command_', '', 1)\n            args = inspect.getargspec(func).args[1:]\n            args = (' [' + '] ['.join(args) + ']') if args else ''\n\n            _help += \"\\t{} {}:{}{}\\n\".format(\n                            argv0, command, comm, args)\n\n            if func.__doc__:\n                _help += self._fix_docstring(func.__doc__, 2)\n        return _help", "response": "Return a string that can be used to display a description of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate Adder avatars for any IBoxReceiver request.", "response": "def requestAvatar(self, avatarId, mind, *interfaces):\n        \"\"\"\n        Create Adder avatars for any IBoxReceiver request.\n        \"\"\"\n        if IBoxReceiver in interfaces:\n            return (IBoxReceiver, Adder(avatarId), lambda: None)\n        raise NotImplementedError()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_error(self, env):\n        '''\n        Unhandled exception handler.\n        You can put any logging, error warning, etc here.'''\n        logger.exception('Exception for %s %s :',\n                         env.request.method, env.request.url)", "response": "Unhandled exception handler.\n        You can put any logging, error warning, etc here."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle(self, env, data):\n        '''\n        Calls application and handles following cases:\n            * catches `webob.HTTPException` errors.\n            * catches unhandled exceptions, calls `handle_error` method\n              and returns 500.\n            * returns 404 if the app has returned None`.\n        '''\n        try:\n            response = self.handler(env, data)\n            if response is None:\n                logger.debug('Application returned None '\n                             'instead of Response object')\n                response = HTTPNotFound()\n        except HTTPException as e:\n            response = e\n        except Exception as e:\n            self.handle_error(env)\n            response = HTTPInternalServerError()\n        return response", "response": "Handles the request and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexpose the decorated method for this L{Exposer} with the given key. A method which is exposed will be able to be retrieved by this L{Exposer}'s C{get} method with that key. If no key is provided, the key is the method name of the exposed method. Use like so:: class MyClass: @someExposer.expose() def foo(): ... or:: class MyClass: @someExposer.expose('foo') def unrelatedMethodName(): ... @param key: a hashable object, used by L{Exposer.get} to look up the decorated method later. If None, the key is the exposed method's name. @return: a 1-argument callable which records its input as exposed, then returns it.", "response": "def expose(self, key=None):\n        \"\"\"\n        Expose the decorated method for this L{Exposer} with the given key.  A\n        method which is exposed will be able to be retrieved by this\n        L{Exposer}'s C{get} method with that key.  If no key is provided, the\n        key is the method name of the exposed method.\n\n        Use like so::\n\n            class MyClass:\n                @someExposer.expose()\n                def foo(): ...\n\n        or::\n\n            class MyClass:\n                @someExposer.expose('foo')\n                def unrelatedMethodName(): ...\n\n        @param key: a hashable object, used by L{Exposer.get} to look up the\n        decorated method later.  If None, the key is the exposed method's name.\n\n        @return: a 1-argument callable which records its input as exposed, then\n        returns it.\n        \"\"\"\n        def decorator(function):\n            rkey = key\n            if rkey is None:\n                if isinstance(function, FunctionType):\n                    rkey = function.__name__\n                else:\n                    raise NameRequired()\n            if rkey not in self._exposed:\n                self._exposed[rkey] = []\n            self._exposed[rkey].append(function)\n            return function\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves key from an instance of a class which previously exposed it.", "response": "def get(self, obj, key):\n        \"\"\"\n        Retrieve 'key' from an instance of a class which previously exposed it.\n\n        @param key: a hashable object, previously passed to L{Exposer.expose}.\n\n        @return: the object which was exposed with the given name on obj's key.\n\n        @raise MethodNotExposed: when the key in question was not exposed with\n        this exposer.\n        \"\"\"\n        if key not in self._exposed:\n            raise MethodNotExposed()\n        rightFuncs = self._exposed[key]\n        T = obj.__class__\n        seen = {}\n        for subT in inspect.getmro(T):\n            for name, value in subT.__dict__.items():\n                for rightFunc in rightFuncs:\n                    if value is rightFunc:\n                        if name in seen:\n                            raise MethodNotExposed()\n                        return value.__get__(obj, T)\n                seen[name] = True\n        raise MethodNotExposed()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the default bundle config file as an AttrDict.", "response": "def default_bundle_config():\n    \"\"\"Return the default bundle config file as an AttrDict.\"\"\"\n\n    import os\n    from ambry.util import AttrDict\n\n    config = AttrDict()\n    f = os.path.join(\n        os.path.dirname(\n            os.path.realpath(__file__)),\n        'bundle.yaml')\n\n    config.update_yaml(f)\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn package_data because setuptools is too stupid to handle nested directories.", "response": "def find_package_data():\n    \"\"\" Returns package_data, because setuptools is too stupid to handle nested directories.\n\n    Returns:\n        dict: key is \"ambry\", value is list of paths.\n    \"\"\"\n\n    l = list()\n    for start in ('ambry/support', 'ambry/bundle/default_files'):\n        for root, dirs, files in os.walk(start):\n\n            for f in files:\n\n                if f.endswith('.pyc'):\n                    continue\n\n                path = os.path.join(root, f).replace('ambry/', '')\n\n                l.append(path)\n\n    return {'ambry': l}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate a file from another file object for copying", "response": "def update(self, of):\n        \"\"\"Update a file from another file, for copying\"\"\"\n\n        # The other values should be set when the file object is created with dataset.bsfile()\n        for p in ('mime_type', 'preference', 'state', 'hash', 'modified', 'size', 'contents', 'source_hash', 'data'):\n            setattr(self, p, getattr(of, p))\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unpacked_contents(self):\n\n        from nbformat import read\n\n        import msgpack\n\n        if self.mime_type == 'text/plain':\n            return self.contents.decode('utf-8')\n        elif self.mime_type == 'application/msgpack':\n            # FIXME: Note: I'm not sure that encoding='utf-8' will not break old data.\n            # We need utf-8 to make python3 to work. (kazbek)\n            # return msgpack.unpackb(self.contents)\n            return msgpack.unpackb(self.contents, encoding='utf-8')\n        else:\n            return self.contents", "response": "Unpacks the contents of the object into a list of bytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nunpacks message pack rows into a stream of dicts.", "response": "def dict_row_reader(self):\n        \"\"\" Unpacks message pack rows into a stream of dicts. \"\"\"\n\n        rows = self.unpacked_contents\n\n        if not rows:\n            return\n\n        header = rows.pop(0)\n\n        for row in rows:\n            yield dict(list(zip(header, row)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the contents and set the hash and modification time", "response": "def update_contents(self, contents, mime_type):\n        \"\"\"Update the contents and set the hash and modification time\"\"\"\n        import hashlib\n        import time\n\n        new_size = len(contents)\n\n        self.mime_type = mime_type\n\n        if mime_type == 'text/plain':\n            self.contents = contents.encode('utf-8')\n        else:\n            self.contents = contents\n\n        old_hash = self.hash\n\n        self.hash = hashlib.md5(self.contents).hexdigest()\n\n        if self.size and (old_hash != self.hash):\n            self.modified = int(time.time())\n\n        self.size = new_size"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a text stream to TSV", "response": "def un(source, wrapper=list, error_bad_lines=True):\n    \"\"\"Parse a text stream to TSV\n\n    If the source is a string, it is converted to a line-iterable stream. If\n    it is a file handle or other object, we assume that we can iterate over\n    the lines in it.\n\n    The result is a generator, and what it contains depends on whether the\n    second argument is set and what it is set to.\n\n    If the second argument is set to list, the default, then each element of\n    the result is a list of strings. If it is set to a class generated with\n    namedtuple(), then each element is an instance of this class, or None if\n    there were too many or too few fields.\n\n    Although newline separated input is preferred, carriage-return-newline is\n    accepted on every platform.\n\n    Since there is no definite order to the fields of a dict, there is no\n    consistent way to format dicts for output. To avoid the asymmetry of a\n    type that can be read but not written, plain dictionary parsing is\n    omitted.\n    \"\"\"\n    if isinstance(source, six.string_types):\n        source = six.StringIO(source)\n\n    # Prepare source lines for reading\n    rows = parse_lines(source)\n\n    # Get columns\n    if is_namedtuple(wrapper):\n        columns = wrapper._fields\n        wrapper = wrapper._make\n    else:\n        columns = next(rows, None)\n        if columns is not None:\n            i, columns = columns\n            yield wrapper(columns)\n\n    # Get values\n    for i, values in rows:\n        if check_line_consistency(columns, values, i, error_bad_lines):\n            yield wrapper(values)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to(items, output=None):\n    strings = (format_collection(item) for item in items)\n    if output is None:\n        return strings\n    else:\n        for s in strings:\n            output.write(s + '\\n')", "response": "Present a collection of items as TSV\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_logged_user(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_logged_user_with_http_info(**kwargs)\n        else:\n            (data) = self.get_logged_user_with_http_info(**kwargs)\n            return data", "response": "Get logged user and in case not existing creates a new one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing a variety of methods to determine which bundle to use", "response": "def get_bundle_ref(args, l, use_history=False):\n    \"\"\" Use a variety of methods to determine which bundle to use\n\n    :param args:\n    :return:\n    \"\"\"\n\n    if not use_history:\n\n        if args.id:\n            return (args.id, '-i argument')\n\n        if hasattr(args, 'bundle_ref') and args.bundle_ref:\n            return (args.bundle_ref, 'bundle_ref argument')\n\n\n        if 'AMBRY_BUNDLE' in os.environ:\n            return (os.environ['AMBRY_BUNDLE'], 'environment')\n\n        cwd_bundle = os.path.join(os.getcwd(), 'bundle.yaml')\n\n        if os.path.exists(cwd_bundle):\n\n            with open(cwd_bundle) as f:\n                from ambry.identity import Identity\n\n                config = yaml.load(f)\n                try:\n                    ident = Identity.from_dict(config['identity'])\n                    return (ident.vid, 'directory')\n                except KeyError:\n                    pass\n\n    history = l.edit_history()\n\n    if history:\n        return (history[0].d_vid, 'history')\n\n    return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bundle_variant(args, l, rc):\n\n    from ambry.orm.exc import ConflictError\n\n    ob = l.bundle(args.ref)\n\n    d = dict(\n        dataset=args.dataset or ob.identity.dataset,\n        revision=args.revision,\n        source=args.source or ob.identity.source,\n        bspace=args.space or ob.identity.bspace,\n        subset=args.subset or ob.identity.subset,\n        btime=args.time or ob.identity.btime,\n        variation=args.variation or ob.identity.variation)\n\n    try:\n        ambry_account = rc.accounts.get('ambry', {})\n    except:\n        ambry_account = None\n\n    if not ambry_account:\n        fatal(\"Failed to get an accounts.ambry entry from the configuration. \")\n\n    if not ambry_account.get('name') or not ambry_account.get('email'):\n        fatal('Must set accounts.ambry.email and accounts.ambry.name n account config file')\n\n    try:\n        b = l.new_bundle(assignment_class=args.key, **d)\n        b.metadata.contacts.wrangler.name = ambry_account.get('name')\n        b.metadata.contacts.wrangler.email = ambry_account.get('email')\n        b.commit()\n\n    except ConflictError:\n        fatal(\"Can't create dataset; one with a conflicting name already exists\")\n\n    # Now, need to copy over all of the partitions into the new bundle.\n    for p in ob.partitions:\n        ds = b.dataset.new_source(p.name, ref=p.name, reftype='partition')\n        print ds\n\n    b.build_source_files.sources.objects_to_record()\n\n    b.commit()", "response": "Create a new bundle as a variant of an existing bundle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bundle_new(args, l, rc):\n\n    from ambry.orm.exc import ConflictError\n\n    d = dict(\n        dataset=args.dataset,\n        revision=args.revision,\n        source=args.source,\n        bspace=args.space,\n        subset=args.subset,\n        btime=args.time,\n        variation=args.variation)\n\n    try:\n        ambry_account = rc.accounts.get('ambry', {})\n    except:\n        ambry_account = None\n\n    if not ambry_account:\n        fatal(\"Failed to get an accounts.ambry entry from the configuration. \")\n\n    if not ambry_account.get('name') or not ambry_account.get('email'):\n        fatal('Must set accounts.ambry.email and accounts.ambry.name n account config file')\n\n    if args.dryrun:\n        from ..identity import Identity\n        d['revision'] = 1\n        d['id'] = 'dXXX'\n        print(str(Identity.from_dict(d)))\n        return\n\n    try:\n        b = l.new_bundle(assignment_class=args.key, **d)\n\n        if ambry_account:\n            b.metadata.contacts.wrangler = ambry_account\n\n        b.build_source_files.bundle_meta.objects_to_record()\n        b.commit()\n\n    except ConflictError:\n        fatal(\"Can't create dataset; one with a conflicting name already exists\")\n\n    print(b.identity.fqname)", "response": "Create a new bundle"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_app(self, app):\n        if self.loaded_apps.get(app):\n            return self.loaded_apps.get(app)\n\n        self.loaded_apps[app] = None\n        initial_data_class = import_string(self.get_class_path(app))\n        if issubclass(initial_data_class, BaseInitialData):\n            self.log('Loaded app {0}'.format(app))\n            self.loaded_apps[app] = initial_data_class\n\n        return self.loaded_apps[app]", "response": "Tries to load an initial data class for a specified app."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads and runs update_initial_data for the specified app.", "response": "def update_app(self, app):\n        \"\"\"\n        Loads and runs `update_initial_data` of the specified app. Any dependencies contained within the\n        initial data class will be run recursively. Dependency cycles are checked for and a cache is built\n        for updated apps to prevent updating the same app more than once.\n        :param app: The name of the app to update. This should be the same path as defined\n            in settings.INSTALLED_APPS\n        :type app: str\n        \"\"\"\n        # don't update this app if it has already been updated\n        if app in self.updated_apps:\n            return\n\n        # load the initial data class\n        try:\n            initial_data_class = self.load_app(app)\n        except ImportError as e:\n            message = str(e)\n\n            # Check if this error is simply the app not having initial data\n            if 'No module named' in message and 'fixtures' in message:\n                self.log('No initial data file for {0}'.format(app))\n                return\n            else:\n                # This is an actual import error we should know about\n                raise\n\n        self.log('Checking dependencies for {0}'.format(app))\n\n        # get dependency list\n        dependencies = self.get_dependency_call_list(app)\n\n        # update initial data of dependencies\n        for dependency in dependencies:\n            self.update_app(dependency)\n\n        self.log('Updating app {0}'.format(app))\n\n        # Update the initial data of the app and gather any objects returned for deletion. Objects registered for\n        # deletion can either be returned from the update_initial_data function or programmatically added with the\n        # register_for_deletion function in the BaseInitialData class.\n        initial_data_instance = initial_data_class()\n        model_objs_registered_for_deletion = initial_data_instance.update_initial_data() or []\n        model_objs_registered_for_deletion.extend(initial_data_instance.get_model_objs_registered_for_deletion())\n\n        # Add the objects to be deleted from the app to the global list of objects to be deleted.\n        self.model_objs_registered_for_deletion.extend(model_objs_registered_for_deletion)\n\n        # keep track that this app has been updated\n        self.updated_apps.add(app)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_deletions(self):\n\n        deduplicated_objs = {}\n        for model in self.model_objs_registered_for_deletion:\n            key = '{0}:{1}'.format(\n                ContentType.objects.get_for_model(model, for_concrete_model=False),\n                model.id\n            )\n            deduplicated_objs[key] = model\n\n        # Create receipts for every object registered for deletion\n        now = timezone.now()\n        registered_for_deletion_receipts = [\n            RegisteredForDeletionReceipt(\n                model_obj_type=ContentType.objects.get_for_model(model_obj, for_concrete_model=False),\n                model_obj_id=model_obj.id,\n                register_time=now)\n            for model_obj in deduplicated_objs.values()\n        ]\n\n        # Do a bulk upsert on all of the receipts, updating their registration time.\n        RegisteredForDeletionReceipt.objects.bulk_upsert(\n            registered_for_deletion_receipts, ['model_obj_type_id', 'model_obj_id'], update_fields=['register_time'])\n\n        # Delete all receipts and their associated model objects that weren't updated\n        for receipt in RegisteredForDeletionReceipt.objects.exclude(register_time=now):\n            try:\n                receipt.model_obj.delete()\n            except:  # noqa\n                # The model object may no longer be there, its ctype may be invalid, or it might be protected.\n                # Regardless, the model object cannot be deleted, so go ahead and delete its receipt.\n                pass\n            receipt.delete()", "response": "Handles deletion of objects that were previously managed by the initial data process but no longer contains objects that were managed by the initial data process but no longer contains objects that were not managed by the initial data process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_all_apps(self):\n        for app in apps.get_app_configs():\n            self.update_app(app.name)\n\n        # During update_app, all apps added model objects that were registered for deletion.\n        # Delete all objects that were previously managed by the initial data process\n        self.handle_deletions()", "response": "Updates all apps and objects that were previously managed by the initial data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset(self):\n        self.dataset_index.reset()\n        self.partition_index.reset()\n        self.identifier_index.reset()", "response": "Resets (deletes) all indexes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\njoin terms using OR operator.", "response": "def _or_join(self, terms):\n        \"\"\" Joins terms using OR operator.\n\n        Args:\n            terms (list): terms to join\n\n        Examples:\n            self._or_join(['term1', 'term2']) -> 'term1 OR term2'\n\n        Returns:\n            str\n        \"\"\"\n\n        if isinstance(terms, (tuple, list)):\n            if len(terms) > 1:\n                return '(' + ' OR '.join(terms) + ')'\n            else:\n                return terms[0]\n        else:\n            return terms"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _and_join(self, terms):\n        if len(terms) > 1:\n            return ' AND '.join([self._or_join(t) for t in terms])\n        else:\n            return self._or_join(terms[0])", "response": "Joins the terms using AND operator."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nindexes exactly one object of the Ambry system.", "response": "def index_one(self, instance, force=False):\n        \"\"\" Indexes exactly one object of the Ambry system.\n\n        Args:\n            instance (any): instance to index.\n            force (boolean): if True replace document in the index.\n\n        Returns:\n            boolean: True if document added to index, False if document already exists in the index.\n        \"\"\"\n        if not self.is_indexed(instance) and not force:\n            doc = self._as_document(instance)\n            self._index_document(doc, force=force)\n            logger.debug('{} indexed as\\n {}'.format(instance.__class__, pformat(doc)))\n            return True\n\n        logger.debug('{} already indexed.'.format(instance.__class__))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a dataset to a document indexed by to FTS index.", "response": "def _as_document(self, dataset):\n        \"\"\" Converts dataset to document indexed by to FTS index.\n\n        Args:\n            dataset (orm.Dataset): dataset to convert.\n\n        Returns:\n            dict with structure matches to BaseDatasetIndex._schema.\n\n        \"\"\"\n\n        # find tables.\n\n        assert isinstance(dataset, Dataset)\n\n        execute = object_session(dataset).connection().execute\n\n        query = text(\"\"\"\n            SELECT t_name, c_name, c_description\n            FROM columns\n            JOIN tables ON c_t_vid = t_vid WHERE t_d_vid = :dataset_vid;\"\"\")\n\n        columns = u('\\n').join(\n            [u(' ').join(list(text_type(e) for e in t)) for t in execute(query, dataset_vid=str(dataset.identity.vid))])\n\n        doc = '\\n'.join([u('{}').format(x) for x in [dataset.config.metadata.about.title,\n                                                     dataset.config.metadata.about.summary,\n                                                     dataset.identity.id_,\n                                                     dataset.identity.vid,\n                                                     dataset.identity.source,\n                                                     dataset.identity.name,\n                                                     dataset.identity.vname,\n                                                     columns]])\n\n        # From the source, make a variety of combinations for keywords:\n        # foo.bar.com -> \"foo foo.bar foo.bar.com bar.com\"\n        parts = u('{}').format(dataset.identity.source).split('.')\n        sources = (['.'.join(g) for g in [parts[-i:] for i in range(2, len(parts) + 1)]]\n                   + ['.'.join(g) for g in [parts[:i] for i in range(0, len(parts))]])\n\n        # Re-calculate the summarization of grains, since the geoid 0.0.7 package had a bug where state level\n        # summaries had the same value as state-level allvals\n        def resum(g):\n            try:\n                return str(GVid.parse(g).summarize())\n            except (KeyError, ValueError):\n                return g\n\n        def as_list(value):\n            \"\"\" Converts value to the list. \"\"\"\n            if not value:\n                return []\n            if isinstance(value, string_types):\n                lst = [value]\n            else:\n                try:\n                    lst = list(value)\n                except TypeError:\n                    lst = [value]\n            return lst\n\n        about_time = as_list(dataset.config.metadata.about.time)\n        about_grain = as_list(dataset.config.metadata.about.grain)\n\n        keywords = (\n            list(dataset.config.metadata.about.groups) +\n            list(dataset.config.metadata.about.tags) +\n            about_time +\n            [resum(g) for g in about_grain] +\n            sources)\n\n        document = dict(\n            vid=u('{}').format(dataset.identity.vid),\n            title=u('{} {}').format(dataset.identity.name, dataset.config.metadata.about.title),\n            doc=u('{}').format(doc),\n            keywords=' '.join(u('{}').format(x) for x in keywords)\n        )\n\n        return document"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _expand_terms(self, terms):\n\n        ret = {\n            'keywords': list(),\n            'doc': list()}\n\n        if not isinstance(terms, dict):\n            stp = SearchTermParser()\n            terms = stp.parse(terms, term_join=self.backend._and_join)\n\n        if 'about' in terms:\n            ret['doc'].append(terms['about'])\n\n        if 'source' in terms:\n            ret['keywords'].append(terms['source'])\n        return ret", "response": "Expands the terms of the dataset to the appropriate fields."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert given partition to a document indexed by FTS backend.", "response": "def _as_document(self, partition):\n        \"\"\" Converts given partition to the document indexed by FTS backend.\n\n        Args:\n            partition (orm.Partition): partition to convert.\n\n        Returns:\n            dict with structure matches to BasePartitionIndex._schema.\n\n        \"\"\"\n\n        schema = ' '.join(\n            u'{} {} {} {} {}'.format(\n                c.id,\n                c.vid,\n                c.name,\n                c.altname,\n                c.description) for c in partition.table.columns)\n\n        values = ''\n\n        for stat in partition.stats:\n            if stat.uvalues :\n                # SOme geometry vlaues are super long. They should not be in uvbalues, but when they are,\n                # need to cut them down.\n                values += ' '.join(e[:200] for e in stat.uvalues) + '\\n'\n\n        # Re-calculate the summarization of grains, since the geoid 0.0.7 package had a bug where state level\n        # summaries had the same value as state-level allvals\n        def resum(g):\n            try:\n                return str(GVid.parse(g).summarize())\n            except KeyError:\n                return g\n            except ValueError:\n                logger.debug(\"Failed to parse gvid '{}' from partition '{}' grain coverage\"\n                             .format(g, partition.identity.vname))\n                return g\n\n        keywords = (\n            ' '.join(partition.space_coverage) + ' ' +\n            ' '.join([resum(g) for g in partition.grain_coverage if resum(g)]) + ' ' +\n            ' '.join(str(x) for x in partition.time_coverage)\n        )\n\n        doc_field = u('{} {} {} {} {} {}').format(\n            values,\n            schema,\n            ' '.join([\n                u('{}').format(partition.identity.vid),\n                u('{}').format(partition.identity.id_),\n                u('{}').format(partition.identity.name),\n                u('{}').format(partition.identity.vname)]),\n            partition.display.title,\n            partition.display.description,\n            partition.display.sub_description,\n            partition.display.time_description,\n            partition.display.geo_description\n        )\n\n        document = dict(\n            vid=u('{}').format(partition.identity.vid),\n            dataset_vid=u('{}').format(partition.identity.as_dataset().vid),\n            title=u('{}').format(partition.table.description),\n            keywords=u('{}').format(keywords),\n            doc=doc_field)\n\n        return document"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexpanding partition terms to the appropriate fields.", "response": "def _expand_terms(self, terms):\n        \"\"\" Expands partition terms to the appropriate fields.\n\n        Args:\n            terms (dict or str):\n\n        Returns:\n            dict: keys are field names, values are query strings\n        \"\"\"\n        ret = {\n            'keywords': list(),\n            'doc': list(),\n            'from': None,\n            'to': None}\n\n        if not isinstance(terms, dict):\n            stp = SearchTermParser()\n            terms = stp.parse(terms, term_join=self.backend._and_join)\n\n        if 'about' in terms:\n            ret['doc'].append(terms['about'])\n\n        if 'with' in terms:\n            ret['doc'].append(terms['with'])\n\n        if 'in' in terms:\n            place_vids = self._expand_place_ids(terms['in'])\n            ret['keywords'].append(place_vids)\n\n        if 'by' in terms:\n            ret['keywords'].append(terms['by'])\n        ret['from'] = terms.get('from', None)\n        ret['to'] = terms.get('to', None)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _expand_place_ids(self, terms):\n\n        place_vids = []\n        first_type = None\n\n        for result in self.backend.identifier_index.search(terms):\n\n            if not first_type:\n                first_type = result.type\n\n            if result.type != first_type:\n                # Ignore ones that aren't the same type as the best match\n                continue\n\n            place_vids.append(result.vid)\n\n        if place_vids:\n            # Add the 'all region' gvids for the higher level\n            all_set = set(itertools.chain.from_iterable(iallval(GVid.parse(x)) for x in place_vids))\n            place_vids += list(str(x) for x in all_set)\n            return place_vids\n        else:\n            return terms", "response": "Given a list of terms to lookup all of the place identifiers to get gvids for the higher level\n           ."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert given identifier to the document indexed by FTS backend.", "response": "def _as_document(self, identifier):\n        \"\"\" Converts given identifier to the document indexed by FTS backend.\n\n        Args:\n            identifier (dict): identifier to convert. Dict contains at\n                least 'identifier', 'type' and 'name' keys.\n\n        Returns:\n            dict with structure matches to BaseIdentifierIndex._schema.\n\n        \"\"\"\n        return {\n            'identifier': u('{}').format(identifier['identifier']),\n            'type': u('{}').format(identifier['type']),\n            'name': u('{}').format(identifier['name'])\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a map geographic area terms to the geo grain GVid values", "response": "def _geograins(self):\n        \"\"\"Create a map geographic area terms to the geo grain GVid values \"\"\"\n\n        from geoid.civick import GVid\n\n        geo_grains = {}\n\n        for sl, cls in GVid.sl_map.items():\n            if '_' not in cls.level:\n                geo_grains[self.stem(cls.level)] = str(cls.nullval().summarize())\n\n        return geo_grains"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a search term to get a dictionary of unique names.", "response": "def parse(self, s, term_join=None):\n        \"\"\" Parses search term to\n\n        Args:\n            s (str): string with search term.\n            or_join (callable): function to join 'OR' terms.\n\n        Returns:\n            dict: all of the terms grouped by marker. Key is a marker, value is a term.\n\n        Example:\n            >>> SearchTermParser().parse('table2 from 1978 to 1979 in california')\n            {'to': 1979, 'about': 'table2', 'from': 1978, 'in': 'california'}\n        \"\"\"\n\n        if not term_join:\n            term_join = lambda x: '(' + ' OR '.join(x) + ')'\n\n        toks = self.scan(s)\n\n        # Examples: starting with this query:\n        # diabetes from 2014 to 2016 source healthindicators.gov\n\n        # Assume the first term is ABOUT, if it is not marked with a marker.\n        if toks and toks[0] and (toks[0][0] == self.TERM or toks[0][0] == self.QUOTEDTERM):\n            toks = [(self.MARKER, 'about')] + toks\n\n\n        # The example query produces this list of tokens:\n        #[(3, 'about'),\n        # (0, 'diabetes'),\n        # (3, 'from'),\n        # (4, 2014),\n        # (3, 'to'),\n        # (4, 2016),\n        # (3, 'source'),\n        # (0, 'healthindicators.gov')]\n\n        # Group the terms by their marker.\n\n        bymarker = []\n        for t in toks:\n            if t[0] == self.MARKER:\n                bymarker.append((t[1], []))\n            else:\n                bymarker[-1][1].append(t)\n\n\n        # After grouping tokens by their markers\n        # [('about', [(0, 'diabetes')]),\n        # ('from', [(4, 2014)]),\n        # ('to', [(4, 2016)]),\n        # ('source', [(0, 'healthindicators.gov')])\n        # ]\n\n        # Convert some of the markers based on their contents. This just changes the marker type for keywords\n        # we'll do more adjustments later.\n        comps = []\n        for t in bymarker:\n\n            t = list(t)\n\n            if t[0] == 'in' and len(t[1]) == 1 and isinstance(t[1][0][1], string_types) and self.stem(\n                    t[1][0][1]) in self.geograins.keys():\n                t[0] = 'by'\n\n            # If the from term isn't an integer, then it is really a source.\n            if t[0] == 'from' and len(t[1]) == 1 and t[1][0][0] != self.YEAR:\n                t[0] = 'source'\n\n            comps.append(t)\n\n        # After conversions\n        # [['about', [(0, 'diabetes')]],\n        #  ['from', [(4, 2014)]],\n        #  ['to', [(4, 2016)]],\n        #  ['source', [(0, 'healthindicators.gov')]]]\n\n        # Join all of the terms into single marker groups\n        groups = {marker: [] for marker, _ in comps}\n\n        for marker, terms in comps:\n            groups[marker] += [term for marker, term in terms]\n\n        # At this point, the groups dict is formed, but it will have a list\n        # for each marker that has multiple terms.\n\n        # Only a few of the markers should have more than one term, so move\n        # extras to the about group\n\n        for marker, group in groups.items():\n\n            if marker == 'about':\n                continue\n\n            if len(group) > 1 and marker not in self.multiterms:\n                groups[marker], extras = [group[0]], group[1:]\n\n                if not 'about' in groups:\n                    groups['about'] = extras\n                else:\n                    groups['about'] += extras\n\n            if marker == 'by':\n                groups['by'] = [ self.geograins.get(self.stem(e)) for e in group]\n\n        for marker, terms in iteritems(groups):\n\n            if len(terms) > 1:\n                if marker in 'in':\n                    groups[marker] = ' '.join(terms)\n                else:\n                    groups[marker] = term_join(terms)\n            elif len(terms) == 1:\n                groups[marker] = terms[0]\n            else:\n                pass\n\n        # After grouping:\n        # {'to': 2016,\n        #  'about': 'diabetes',\n        #  'from': 2014,\n        #  'source': 'healthindicators.gov'}\n\n        # If there were any markers with multiple terms, they would be cast in the or_join form.\n\n\n        return groups"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n\n    module = self.distribution.ext_modules[0]\n\n    building_for_windows = self.plat_name in ['win32', 'win-amd64']\n    if building_for_windows:\n      module.define_macros.append(('_CRT_SECURE_NO_WARNINGS', '1'))\n      module.libraries.append('advapi32')\n\n    if self.dynamic_linking:\n      module.libraries.append('yara')\n    else:\n      for source in yara_sources:\n        module.sources.append(source)\n\n    build_ext.build_ext.run(self)", "response": "Execute the build command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating tables according sqlalchemy data model.", "response": "def command_create_tables(self, meta_name=None, verbose=False):\n        '''\n        Create tables according sqlalchemy data model.\n\n        Is not a complex migration tool like alembic, just creates tables that\n        does not exist::\n\n            ./manage.py sqla:create_tables [--verbose] [meta_name]\n        '''\n\n        def _create_metadata_tables(metadata):\n            for table in metadata.sorted_tables:\n                if verbose:\n                    print(self._schema(table))\n                else:\n                    print('  '+table.name)\n                engine = self.session.get_bind(clause=table)\n                metadata.create_all(bind=engine, tables=[table])\n\n        if isinstance(self.metadata, MetaData):\n            print('Creating tables...')\n            _create_metadata_tables(self.metadata)\n        else:\n            for current_meta_name, metadata in self.metadata.items():\n                if meta_name not in (current_meta_name, None):\n                    continue\n                print('Creating tables for {}...'.format(current_meta_name))\n                _create_metadata_tables(metadata)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef command_drop_tables(self, meta_name=None):\n        '''\n        Drops all tables without dropping a database::\n\n            ./manage.py sqla:drop_tables [meta_name]\n        '''\n        answer = six.moves.input(u'All data will lost. Are you sure? [y/N] ')\n\n        if answer.strip().lower()!='y':\n            sys.exit('Interrupted')\n\n        def _drop_metadata_tables(metadata):\n            table = next(six.itervalues(metadata.tables), None)\n            if table is None:\n                print('Failed to find engine')\n            else:\n                engine = self.session.get_bind(clause=table)\n                drop_everything(engine)\n                print('Done')\n\n        if isinstance(self.metadata, MetaData):\n            print('Droping tables... ', end='')\n            _drop_metadata_tables(self.metadata)\n        else:\n            for current_meta_name, metadata in self.metadata.items():\n                if meta_name not in (current_meta_name, None):\n                    continue\n                print('Droping tables for {}... '.format(current_meta_name),\n                      end='')\n                _drop_metadata_tables(metadata)", "response": "Drops all tables without dropping a database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint current database schema.", "response": "def command_schema(self, name=None):\n        '''\n        Prints current database schema (according sqlalchemy database model)::\n\n            ./manage.py sqla:schema [name]\n        '''\n        meta_name = table_name = None\n        if name:\n            if isinstance(self.metadata, MetaData):\n                table_name = name\n            elif '.' in name:\n                meta_name, table_name = name.split('.', 1)\n            else:\n                meta_name = name\n\n        def _print_metadata_schema(metadata):\n            if table_name is None:\n                for table in metadata.sorted_tables:\n                    print(self._schema(table))\n            else:\n                try:\n                    table = metadata.tables[table_name]\n                except KeyError:\n                    sys.exit('Table {} is not found'.format(name))\n                print(self._schema(table))\n\n        if isinstance(self.metadata, MetaData):\n            _print_metadata_schema(self.metadata)\n        else:\n            for current_meta_name, metadata in self.metadata.items():\n                if meta_name not in (current_meta_name, None):\n                    continue\n                _print_metadata_schema(metadata)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef command_gen(self, *names):\n        '''\n        Runs generator functions.\n\n        Run `docs` generator function::\n\n            ./manage.py sqla:gen docs\n\n        Run `docs` generator function with `count=10`::\n\n            ./manage.py sqla:gen docs:10\n        '''\n        if not names:\n            sys.exit('Please provide generator names')\n        for name in names:\n            name, count = name, 0\n            if ':' in name:\n                name, count = name.split(':', 1)\n            count = int(count)\n            create = self.generators[name]\n            print('Generating `{0}` count={1}'.format(name, count))\n            create(self.session, count)\n            self.session.commit()", "response": "Generate a new record set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_conn_info(self):\n        from sockjs.cyclone.conn import ConnectionInfo\n\n        \"\"\" Return C{ConnectionInfo} object from current transport \"\"\"\n        return ConnectionInfo(self.request.remote_ip,\n                              self.request.cookies,\n                              self.request.arguments,\n                              self.request.headers,\n                              self.request.path)", "response": "Return a ConnectionInfo object from current transport"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_table_names(statement):\n\n    parts = statement.to_unicode().split()\n\n    tables = set()\n\n    for i, token in enumerate(parts):\n        if token.lower() == 'from' or token.lower().endswith('join'):\n            tables.add(parts[i + 1].rstrip(';'))\n\n    return list(tables)", "response": "Returns a list of table names found in the sqlparse parse tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninstalls partition s mpr to the database.", "response": "def install(self, connection, partition, table_name=None, index_columns=None, materialize=False,\n                logger=None):\n        \"\"\" Installs partition's mpr to the database to allow to execute sql queries over mpr.\n\n        Args:\n            connection:\n            partition (orm.Partition):\n            materialize (boolean): if True, create generic table. If False create MED over mpr.\n\n        Returns:\n            str: name of the created table.\n\n        \"\"\"\n\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall all partitons of the table and creates view with union of all partitons.", "response": "def install_table(self, connection, table, logger = None):\n        \"\"\" Installs all partitons of the table and create view with union of all partitons.\n\n        Args:\n            connection: connection to database who stores mpr data.\n            table (orm.Table):\n        \"\"\"\n        # first install all partitions of the table\n\n        queries = []\n        query_tmpl = 'SELECT * FROM {}'\n        for partition in table.partitions:\n            partition.localize()\n            installed_name = self.install(connection, partition)\n            queries.append(query_tmpl.format(installed_name))\n\n        # now create view with union of all partitions.\n        query = 'CREATE VIEW {} AS {} '.format( table.vid, '\\nUNION ALL\\n'.join(queries))\n        logger.debug('Creating view for table.\\n    table: {}\\n    query: {}'.format(table.vid, query))\n        self._execute(connection, query, fetch=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query(self, connection, query, fetch=True):\n\n        self.install_module(connection)\n\n        statements = sqlparse.parse(sqlparse.format(query, strip_comments=True))\n\n        # install all partitions and replace table names in the query.\n        #\n        logger.debug('Finding and installing all partitions from query. \\n    query: {}'.format(query))\n        new_query = []\n\n        if len(statements) > 1:\n            raise BadSQLError(\"Can only query a single statement\")\n\n        if len(statements) == 0:\n            raise BadSQLError(\"DIdn't get any statements in '{}'\".format(query))\n\n        statement = statements[0]\n\n        logger.debug( 'Searching statement for partition ref.\\n    statement: {}'.format(statement.to_unicode()))\n\n        #statement = self.install_statement(connection, statement.to_unicode())\n\n        logger.debug(\n            'Executing updated query after partition install.'\n            '\\n    query before update: {}\\n    query to execute (updated query): {}'\n            .format(statement, new_query))\n\n        return self._execute(connection, statement.to_unicode(), fetch=fetch)", "response": "Executes a SQL query and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_build_configuration_id_by_name(name):\n    response = utils.checked_api_call(pnc_api.build_configs, 'get_all', q='name==' + name).content\n    if not response:\n        return None\n    return response[0].id", "response": "Returns the id of the build configuration with the given name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the build configuration with the given name or None if no match", "response": "def get_build_configuration_by_name(name):\n    \"\"\"\n    Returns the build configuration matching the name\n    :param name: name of build configuration\n    :return: The matching build configuration, or None if no match found\n    \"\"\"\n    response = utils.checked_api_call(pnc_api.build_configs, 'get_all', q='name==' + name).content\n    if not response:\n        return None\n    return response[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef config_id_exists(search_id):\n    response = utils.checked_api_call(pnc_api.build_configs, 'get_specific', id=search_id)\n    if not response:\n        return False\n    return True", "response": "Test if a build configuration with the given id exists"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build(id=None, name=None, revision=None,\n          temporary_build=False, timestamp_alignment=False,\n          no_build_dependencies=False,\n          keep_pod_on_failure=False,\n          force_rebuild=False,\n          rebuild_mode=common.REBUILD_MODES_DEFAULT):\n    \"\"\"\n    Trigger a BuildConfiguration by name or ID\n    \"\"\"\n    data = build_raw(id, name, revision, temporary_build, timestamp_alignment, no_build_dependencies,\n              keep_pod_on_failure, force_rebuild, rebuild_mode)\n    if data:\n        return utils.format_json(data)", "response": "Trigger a BuildConfiguration by name or ID\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_build_configuration(id=None, name=None):\n    data = get_build_configuration_raw(id, name)\n    if data:\n        return utils.format_json(data)", "response": "Retrieve a specific BuildConfiguration"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_build_configuration(id, **kwargs):\n    data = update_build_configuration_raw(id, **kwargs)\n    if data:\n        return utils.format_json(data)", "response": "Update an existing BuildConfiguration with new information"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_build_configuration(id=None, name=None):\n    data = delete_build_configuration_raw(id, name)\n    if data:\n        return utils.format_json(data)", "response": "Delete an existing BuildConfiguration"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist all BuildConfigurations associated with a given Product.", "response": "def list_build_configurations_for_product(id=None, name=None, page_size=200, page_index=0, sort=\"\", q=\"\"):\n    \"\"\"\n    List all BuildConfigurations associated with the given Product.\n    \"\"\"\n    data = list_build_configurations_for_product_raw(id, name, page_size, page_index, sort, q)\n    if data:\n        return utils.format_json_list(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_build_configurations_for_project(id=None, name=None, page_size=200, page_index=0, sort=\"\", q=\"\"):\n    data = list_build_configurations_for_project_raw(id, name, page_size, page_index, sort, q)\n    if data:\n        return utils.format_json_list(data)", "response": "List all BuildConfigurations associated with a given Project."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all BuildConfigurations associated with a given ProductVersion", "response": "def list_build_configurations_for_product_version(product_id, version_id, page_size=200, page_index=0, sort=\"\", q=\"\"):\n    \"\"\"\n    List all BuildConfigurations associated with the given ProductVersion\n    \"\"\"\n    data = list_build_configurations_for_project_raw(product_id, version_id, page_size, page_index, sort, q)\n    if data:\n        return utils.format_json_list(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an existing BuildConfiguration as a dependency to another BuildConfiguration.", "response": "def add_dependency(id=None, name=None, dependency_id=None, dependency_name=None):\n    \"\"\"\n    Add an existing BuildConfiguration as a dependency to another BuildConfiguration.\n    \"\"\"\n    data = add_dependency_raw(id, name, dependency_id, dependency_name)\n    if data:\n        return utils.format_json_list(data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a BuildConfiguration from the dependency list of another BuildConfiguration", "response": "def remove_dependency(id=None, name=None, dependency_id=None, dependency_name=None):\n    \"\"\"\n    Remove a BuildConfiguration from the dependency list of another BuildConfiguration\n    \"\"\"\n    data = remove_dependency_raw(id, name, dependency_id, dependency_name)\n    if data:\n        return utils.format_json_list(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_product_versions_for_build_configuration(id=None, name=None, page_size=200, page_index=0, sort=\"\", q=\"\"):\n    data = list_product_versions_for_build_configuration_raw(id, name, page_size, page_index, sort, q)\n    if data:\n        return utils.format_json_list(data)", "response": "List all ProductVersions associated with a BuildConfiguration"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassociate an existing ProductVersion with a BuildConfiguration", "response": "def add_product_version_to_build_configuration(id=None, name=None, product_version_id=None):\n    \"\"\"\n    Associate an existing ProductVersion with a BuildConfiguration\n    \"\"\"\n    data = remove_product_version_from_build_configuration_raw(id, name, product_version_id)\n    if data:\n        return utils.format_json_list(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_product_version_from_build_configuration(id=None, name=None, product_version_id=None):\n    data = remove_product_version_from_build_configuration_raw(id, name, product_version_id)\n    if data:\n        return utils.format_json_list(data)", "response": "Remove a ProductVersion from an existing BuildConfiguration"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_revisions_of_build_configuration(id=None, name=None, page_size=200, page_index=0, sort=\"\"):\n    data = list_revisions_of_build_configuration_raw(id, name, page_size, page_index, sort)\n    if data:\n        return utils.format_json_list(data)", "response": "List audited revisions of a BuildConfiguration"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_revision_of_build_configuration(revision_id, id=None, name=None):\n    data = get_revision_of_build_configuration_raw(revision_id, id, name)\n    if data:\n        return utils.format_json_list(data)", "response": "Get a specific audited revision of a BuildConfiguration"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all BuildConfigurations in a hierarchy", "response": "def list_build_configurations(page_size=200, page_index=0, sort=\"\", q=\"\"):\n    \"\"\"\n    List all BuildConfigurations\n    \"\"\"\n    data = list_build_configurations_raw(page_size, page_index, sort, q)\n    if data:\n        return utils.format_json_list(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tzabbr_register(abbr, name, region, zone, dst):\n  newabbr = tzabbr()\n  newabbr.abbr = abbr\n  newabbr.name = name\n  newabbr.region = region\n  newabbr.zone = zone\n  newabbr.dst = dst\n\n  if abbr not in all:\n    all[abbr] = newabbr\n\n  if not region in regions:\n    regions[region] = {}\n\n  assert abbr not in regions[region]\n  regions[region][abbr] = newabbr", "response": "Register a new timezone abbreviation in the global registry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_license(**kwargs):\n    License = create_license_object(**kwargs)\n    response = utils.checked_api_call(pnc_api.licenses, 'create_new', body=License)\n    if response:\n        return utils.format_json(response.content)", "response": "Create a new License in the NIC"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_license(id):\n    response = utils.checked_api_call(\n        pnc_api.licenses, 'get_specific', id= id)\n    if response:\n        return utils.format_json(response.content)", "response": "Get a specific License by either ID or fullname"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_license(license_id):\n\n    response = utils.checked_api_call(pnc_api.licenses, 'delete', id=license_id)\n    if response:\n        return utils.format_json(response.content)", "response": "Delete a License by ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the License with given ID with a new License", "response": "def update_license(license_id, **kwargs):\n    \"\"\"\n    Replace the License with given ID with a new License\n    \"\"\"\n    updated_license = pnc_api.licenses.get_specific(id=license_id).content\n\n    for key, value in iteritems(kwargs):\n        if value:\n            setattr(updated_license, key, value)\n\n    response = utils.checked_api_call(\n        pnc_api.licenses,\n        'update',\n        id=int(license_id),\n        body=updated_license)\n    if response:\n        return utils.format_json(response.content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_licenses(page_size=200, page_index=0, sort=\"\", q=\"\"):\n    response = utils.checked_api_call(pnc_api.licenses, 'get_all', page_size=page_size, page_index=page_index, sort=sort, q=q)\n    if response:\n        return utils.format_json_list(response.content)", "response": "List all License objects in a node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply transformations to the image.", "response": "def transform(self, img, transformation, params):\n        '''\n        Apply transformations to the image.\n\n        New transformations can be defined as methods::\n\n            def do__transformationname(self, img, transformation, params):\n                'returns new image with transformation applied'\n                ...\n\n            def new_size__transformationname(self, size, target_size, params):\n                'dry run, returns a size of image if transformation is applied'\n                ...\n        '''\n        # Transformations MUST be idempotent.\n        # The limitation is caused by implementation of\n        # image upload in iktomi.cms.\n        # The transformation can be applied twice:\n        # on image upload after crop (when TransientFile is created)\n        # and on object save (when PersistentFile is created).\n        method = getattr(self, 'do__' + transformation)\n        return method(img, transformation, params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchoosing a resizer depending an image size", "response": "def get_resizer(self, size, target_size):\n        '''Choose a resizer depending an image size'''\n        sw, sh = size\n        if sw >= sh * self.rate:\n            return self.hor_resize\n        else:\n            return self.vert_resize"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, song):\n        if song in self._songs:\n            return\n        self._songs.append(song)\n        logger.debug('Add %s to player playlist', song)", "response": "Add a song to the playlist"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(self, song):\n        if song in self._songs:\n            return\n        if self._current_song is None:\n            self._songs.append(song)\n        else:\n            index = self._songs.index(self._current_song)\n            self._songs.insert(index + 1, song)", "response": "insert a new song into the list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, song):\n        if song in self._songs:\n            if self._current_song is None:\n                self._songs.remove(song)\n            elif song == self._current_song:\n                next_song = self.next_song\n                # \u968f\u673a\u6a21\u5f0f\u4e0b\u6216\u8005\u6b4c\u5355\u53ea\u5269\u4e00\u9996\u6b4c\u66f2\uff0c\u4e0b\u4e00\u9996\u53ef\u80fd\u548c\u5f53\u524d\u6b4c\u66f2\u76f8\u540c\n                if next_song == self.current_song:\n                    self.current_song = None\n                    self._songs.remove(song)\n                    self.current_song = self.next_song\n                else:\n                    self.current_song = self.next_song\n                    self._songs.remove(song)\n            else:\n                self._songs.remove(song)\n            logger.debug('Remove {} from player playlist'.format(song))\n        else:\n            logger.debug('Remove failed: {} not in playlist'.format(song))\n\n        if song in self._bad_songs:\n            self._bad_songs.remove(song)", "response": "Remove a song from the playlist."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the current song", "response": "def current_song(self, song):\n        \"\"\"\u8bbe\u7f6e\u5f53\u524d\u6b4c\u66f2\uff0c\u5c06\u6b4c\u66f2\u52a0\u5165\u5230\u64ad\u653e\u5217\u8868\uff0c\u5e76\u53d1\u51fa song_changed \u4fe1\u53f7\n\n        .. note::\n\n            \u8be5\u65b9\u6cd5\u7406\u8bba\u4e0a\u53ea\u5e94\u8be5\u88ab Player \u5bf9\u8c61\u8c03\u7528\u3002\n        \"\"\"\n        self._last_song = self.current_song\n        if song is None:\n            self._current_song = None\n        # add it to playlist if song not in playlist\n        elif song in self._songs:\n            self._current_song = song\n        else:\n            self.insert(song)\n            self._current_song = song\n        self.song_changed.emit(song)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a good song from the playlist.", "response": "def _get_good_song(self, base=0, random_=False, direction=1):\n        \"\"\"\u4ece\u64ad\u653e\u5217\u8868\u4e2d\u83b7\u53d6\u4e00\u9996\u53ef\u4ee5\u64ad\u653e\u7684\u6b4c\u66f2\n\n        :param base: base index\n        :param random: random strategy or not\n        :param direction: forward if > 0 else backword\n\n        >>> pl = Playlist([1, 2, 3])\n        >>> pl._get_good_song()\n        1\n        >>> pl._get_good_song(base=1)\n        2\n        >>> pl._bad_songs = [2]\n        >>> pl._get_good_song(base=1, direction=-1)\n        1\n        >>> pl._get_good_song(base=1)\n        3\n        >>> pl._bad_songs = [1, 2, 3]\n        >>> pl._get_good_song()\n        \"\"\"\n        if not self._songs or len(self._songs) <= len(self._bad_songs):\n            logger.debug('No good song in playlist.')\n            return None\n\n        good_songs = []\n        if direction > 0:\n            song_list = self._songs[base:] + self._songs[0:base]\n        else:\n            song_list = self._songs[base::-1] + self._songs[:base:-1]\n        for song in song_list:\n            if song not in self._bad_songs:\n                good_songs.append(song)\n        if random_:\n            return random.choice(good_songs)\n        else:\n            return good_songs[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets next song for player based on playback_mode", "response": "def next_song(self):\n        \"\"\"next song for player, calculated based on playback_mode\"\"\"\n        # \u5982\u679c\u6ca1\u6709\u6b63\u5728\u64ad\u653e\u7684\u6b4c\u66f2\uff0c\u627e\u5217\u8868\u91cc\u9762\u7b2c\u4e00\u9996\u80fd\u64ad\u653e\u7684\n        if self.current_song is None:\n            return self._get_good_song()\n\n        if self.playback_mode == PlaybackMode.random:\n            next_song = self._get_good_song(random_=True)\n        else:\n            current_index = self._songs.index(self.current_song)\n            if current_index == len(self._songs) - 1:\n                if self.playback_mode in (PlaybackMode.loop, PlaybackMode.one_loop):\n                    next_song = self._get_good_song()\n                elif self.playback_mode == PlaybackMode.sequential:\n                    next_song = None\n            else:\n                next_song = self._get_good_song(base=current_index+1)\n        return next_song"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef previous_song(self):\n        if self.current_song is None:\n            return self._get_good_song(base=-1, direction=-1)\n\n        if self.playback_mode == PlaybackMode.random:\n            previous_song = self._get_good_song(direction=-1)\n        else:\n            current_index = self._songs.index(self.current_song)\n            previous_song = self._get_good_song(base=current_index - 1, direction=-1)\n        return previous_song", "response": "get the previous song for player to play\nMimeType"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset state of the object", "response": "def state(self, value):\n        \"\"\"set player state, emit state changed signal\n\n        outer object should not set state directly,\n        use ``pause`` / ``resume`` / ``stop`` / ``play`` method instead.\n        \"\"\"\n        self._state = value\n        self.state_changed.emit(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef play_song(self, song):\n        if song is not None and song == self.current_song:\n            logger.warning('The song is already under playing.')\n        else:\n            self._playlist.current_song = song", "response": "\u64ad\u653e\u6307\u5b9a\u6b4c\u66f2\n\n        \u5982\u679c\u76ee\u6807\u6b4c\u66f2\u4e0e\u5f53\u524d\u6b4c\u66f2\u4e0d\u76f8\u540c\uff0c\u5219\u4fee\u6539\u64ad\u653e\u5217\u8868\u5f53\u524d\u6b4c\u66f2\uff0c\n        \u64ad\u653e\u5217\u8868\u4f1a\u53d1\u51fa song_changed \u4fe1\u53f7\uff0cplayer \u76d1\u542c\u5230\u4fe1\u53f7\u540e\u8c03\u7528 play \u65b9\u6cd5\uff0c\n        \u5230\u90a3\u65f6\u624d\u4f1a\u771f\u6b63\u7684\u64ad\u653e\u65b0\u7684\u6b4c\u66f2\u3002\u5982\u679c\u548c\u5f53\u524d\u64ad\u653e\u6b4c\u66f2\u76f8\u540c\uff0c\u5219\u5ffd\u7565\u3002\n\n        .. note::\n\n            \u8c03\u7528\u65b9\u4e0d\u5e94\u8be5\u76f4\u63a5\u8c03\u7528 playlist.current_song = song \u6765\u5207\u6362\u6b4c\u66f2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _on_song_changed(self, song):\n        logger.debug('Player received song changed signal')\n        if song is not None:\n            logger.info('Try to play song: %s' % song)\n            if song.url:\n                self.play(song.url)\n            else:\n                self._playlist.mark_as_bad(song)\n                self.play_next()\n        else:\n            self.stop()\n            logger.info('No good song in player playlist anymore.')", "response": "Called when a song is changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_managed_gavs(artifact, repo_url=None, mgmt_type=MGMT_TYPE.DEPENDENCIES, mvn_repo_local=None):\n\n    # download the pom\n    pom_path = download_pom(repo_url, artifact)\n    if pom_path:\n        pom_dir = os.path.split(pom_path)[0]\n\n        # get effective pom\n        eff_pom = get_effective_pom(pom_dir, repo_url, mvn_repo_local)\n        shutil.rmtree(pom_dir, True)\n        if not eff_pom:\n            return None\n\n        # read dependencyManagement/pluginManagement section\n        managed_arts = read_management(eff_pom, mgmt_type)\n    else:\n        managed_arts = None\n\n    return managed_arts", "response": "Reads all artifacts managed by the given artifact from the dependencyManagement section of the given artifact."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the effective POM from the downloaded pom.", "response": "def get_effective_pom(pom_dir, repo_url, mvn_repo_local, profiles=None, additional_params=None):\n    \"\"\"\n    Gets the effective pom from the downloaded pom. There has to be complete source tree (at least the pom tree) in case\n    that the root pom contains some modules.\n\n    :param pom_dir: directory where the pom is prepared (including potential patches)\n    :param repo_url: repository URL, where all dependencies needed to resolve the effective POM are available\n    :param mvn_repo_local: path to local repository to use if a non-default location is required\n    :returns: the effective pom as a string or None if a problem occurs\n    \"\"\"\n    global effective_pom_cache\n\n    pom_file = None\n    try:\n        pom_file = open(os.path.join(pom_dir, \"pom.xml\"))\n        pom = pom_file.read()\n    finally:\n        if pom_file:\n            pom_file.close()\n    artifact = MavenArtifact(pom=pom)\n    gav = artifact.get_gav()\n\n    eff_pom = None\n    if repo_url in effective_pom_cache.keys():\n        if gav in effective_pom_cache[repo_url].keys():\n            if profiles in effective_pom_cache[repo_url][gav].keys():\n                if additional_params in effective_pom_cache[repo_url][gav][profiles].keys():\n                    eff_pom = effective_pom_cache[repo_url][gav][profiles][additional_params]\n\n    if not eff_pom:\n        try:\n            eff_pom = _read_effective_pom(pom_dir, repo_url, mvn_repo_local, profiles, additional_params)\n        finally:\n            if eff_pom:\n                effective_pom_cache.setdefault(repo_url, {}).setdefault(gav, {}).setdefault(profiles, {})[additional_params] = eff_pom\n\n    return eff_pom"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun mvn clean command with provided additional parameters to perform pom updates by pom - manipulation - ext.", "response": "def alter_poms(pom_dir, additional_params, repo_url=None, mvn_repo_local=None):\n    \"\"\"\n    Runs mvn clean command with provided additional parameters to perform pom updates by pom-manipulation-ext.\n    \"\"\"\n    work_dir = os.getcwd()\n    os.chdir(pom_dir)\n\n    try:\n        if repo_url:\n            settings_filename = create_mirror_settings(repo_url)\n        else:\n            settings_filename = None\n\n        args = [\"mvn\", \"clean\"]\n        if mvn_repo_local:\n            args.extend([\"-s\", settings_filename])\n        if mvn_repo_local:\n            args.append(\"-Dmaven.repo.local=%s\" % mvn_repo_local)\n        param_list = additional_params.split(\" \")\n        args.extend(param_list)\n\n        logging.debug(\"Running command: %s\", \" \".join(args))\n        command = Popen(args, stdout=PIPE, stderr=STDOUT)\n        stdout = command.communicate()[0]\n        if command.returncode:\n            logging.error(\"POM manipulation failed. Output:\\n%s\" % stdout)\n        else:\n            logging.debug(\"POM manipulation succeeded. Output:\\n%s\" % stdout)\n    finally:\n        os.chdir(work_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pom_contains_modules():\n    pom_file = None\n    try:\n        pom_file = open(\"pom.xml\")\n        pom = pom_file.read()\n    finally:\n        if pom_file:\n            pom_file.close()\n\n    artifact = MavenArtifact(pom=pom)\n    if artifact.modules:\n        return True\n    else:\n        return False", "response": "Checks if pom. xml contains modules tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the URL of the Nexus group repository for the given MEAD tag.", "response": "def get_repo_url(mead_tag, nexus_base_url, prefix=\"hudson-\", suffix=\"\"):\n    \"\"\"\n    Creates repository Nexus group URL composed of:\n        <nexus_base_url>/content/groups/<prefix><mead_tag><suffix>\n\n    :param mead_tag: name of the MEAD tag used to create the proxy URL in settings.xml\n    :param nexus_base_url: the base URL of a Nexus instance\n    :param prefix: Nexus group name prefix, default is \"hudson-\"\n    :param suffix: Nexus group name suffix, e.g. \"-jboss-central\" or \"-reverse\"\n    :returns:\n    \"\"\"\n    result = urlparse.urljoin(nexus_base_url, \"content/groups/\")\n    result = urlparse.urljoin(result, \"%s%s%s/\" % (prefix, mead_tag, suffix))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading a pom file from given artifact_url and saves it as pom. xml into target_dir.", "response": "def download_pom(repo_url=None, artifact=None, pom_url=None, target_dir=None):\n    \"\"\"\n    Downloads a pom file with give GAV (as array) or from given pom_url and saves it as pom.xml into target_dir.\n\n    :param repo_url: repository URL from which the pom should be downloaded, mandatory only if no pom_url provided\n    :param artifact: MavenArtifact instance, mandatory only if no pom_url provided\n    :param pom_url: URL of the pom to download, not mandatory\n    :target_dir: target directory path, where the pom should be saved, not mandatory\n    :returns: path to the saved pom, useful if no target_dir provided\n    \"\"\"\n    if not pom_url:\n        pom_url = urlparse.urljoin(repo_url, \"%s/\" % string.replace(artifact.groupId, \".\", \"/\"))\n        pom_url = urlparse.urljoin(pom_url, \"%s/\" % artifact.artifactId)\n        pom_url = urlparse.urljoin(pom_url, \"%s/\" % artifact.version)\n        pom_url = urlparse.urljoin(pom_url, \"%s-%s.pom\" % (artifact.artifactId, artifact.version))\n\n    handler = None\n    try:\n        handler = urlopen(pom_url)\n    except HTTPError as err:\n        logging.error(\"Failed to download POM %s. %s\", pom_url, err)\n        return None\n\n    if not target_dir:\n        num = 1\n        while not target_dir or os.path.exists(target_dir):\n            target_dir = \"/tmp/maven-temp-path-%s\" % num\n            num += 1\n\n    pom_path = os.path.join(target_dir, \"pom.xml\")\n\n    if handler.getcode() == 200:\n        pom = handler.read()\n        handler.close()\n        if not os.path.exists(target_dir):\n            os.makedirs(target_dir)\n        pom_file = None\n        try:\n            pom_file = open(pom_path, \"w\")\n            pom_file.write(pom)\n        finally:\n            if pom_file:\n                pom_file.close()\n\n    return pom_path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a mirror settings. xml in current working directory which when used makes Maven use given repo URL as a mirror of all available repositories.", "response": "def create_mirror_settings(repo_url):\n    \"\"\"\n    Creates settings.xml in current working directory, which when used makes Maven use given repo URL as a mirror of all\n    repositories to look at.\n\n    :param repo_url: the repository URL to use\n    :returns: filepath to the created file\n    \"\"\"\n    cwd = os.getcwd()\n    settings_path = os.path.join(cwd, \"settings.xml\")\n\n    settings_file = None\n    try:\n        settings_file = open(settings_path, \"w\")\n        settings_file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n        settings_file.write('<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\\n')\n        settings_file.write('          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\\n')\n        settings_file.write('          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\\n')\n        settings_file.write('<mirrors>\\n')\n        settings_file.write('    <mirror>\\n')\n        settings_file.write('      <id>repo-mirror</id>\\n')\n        settings_file.write('        <url>%s</url>\\n' % repo_url)\n        settings_file.write('      <mirrorOf>*</mirrorOf>\\n')\n        settings_file.write('    </mirror>\\n')\n        settings_file.write('  </mirrors>\\n')\n        settings_file.write('</settings>\\n')\n    finally:\n        if settings_file:\n            settings_file.close()\n\n    return settings_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget songs list from search keywords", "response": "def search(self, s, stype=1, offset=0, total='true', limit=60):\n        \"\"\"get songs list from search keywords\"\"\"\n        action = uri + '/search/get'\n        data = {\n            's': s,\n            'type': stype,\n            'offset': offset,\n            'total': total,\n            'limit': 60\n        }\n        resp = self.request('POST', action, data)\n        if resp['code'] == 200:\n            return resp['result']['songs']\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef artist_infos(self, artist_id):\n        action = uri + '/artist/' + str(artist_id)\n        data = self.request('GET', action)\n        return data", "response": "Get information about a specific artist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef album_infos(self, album_id):\n        action = uri + '/album/' + str(album_id)\n        data = self.request('GET', action)\n        if data['code'] == 200:\n            return data['album']", "response": "Get information about an album."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd or del to playlist", "response": "def op_music_to_playlist(self, mid, pid, op):\n        \"\"\"\n        :param op: add or del\n        \"\"\"\n        url_add = uri + '/playlist/manipulate/tracks'\n        trackIds = '[\"' + str(mid) + '\"]'\n        data_add = {\n            'tracks': str(mid),  # music id\n            'pid': str(pid),    # playlist id\n            'trackIds': trackIds,  # music id str\n            'op': op   # opation\n        }\n        data = self.request('POST', url_add, data_add)\n        code = data.get('code')\n\n        # \u4ece\u6b4c\u5355\u4e2d\u6210\u529f\u7684\u79fb\u9664\u6b4c\u66f2\u65f6\uff0ccode \u662f 200\n        # \u5f53\u4ece\u6b4c\u5355\u4e2d\u79fb\u9664\u4e00\u9996\u4e0d\u5b58\u5728\u7684\u6b4c\u66f2\u65f6\uff0ccode \u4e5f\u662f 200\n        # \u5f53\u5411\u6b4c\u5355\u6dfb\u52a0\u6b4c\u66f2\u65f6\uff0c\u5982\u679c\u6b4c\u66f2\u5df2\u7ecf\u5728\u5217\u8868\u5f53\u4e2d\uff0c\n        # \u8fd4\u56de code \u4e3a 502\n        if code == 200:\n            return 1\n        elif code == 502:\n            return -1\n        else:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting mv detail :param mvid: mv id :return:", "response": "def get_mv_detail(self, mvid):\n        \"\"\"Get mv detail\n        :param mvid: mv id\n        :return:\n        \"\"\"\n        url = uri + '/mv/detail?id=' + str(mvid)\n        return self.request('GET', url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_lyric_by_songid(self, mid):\n        # tv \u8868\u793a\u7ffb\u8bd1\u3002-1\uff1a\u8868\u793a\u8981\u7ffb\u8bd1\uff0c1\uff1a\u4e0d\u8981\n        url = uri + '/song/lyric?' + 'id=' + str(mid) + '&lv=1&kv=1&tv=-1'\n        return self.request('GET', url)", "response": "Get lyrics by song id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating or open an index for the given schema and index_name.", "response": "def _init_index(root_dir, schema, index_name):\n    \"\"\" Creates new index or opens existing.\n\n    Args:\n        root_dir (str): root dir where to find or create index.\n        schema (whoosh.fields.Schema): schema of the index to create or open.\n        index_name (str): name of the index.\n\n    Returns:\n        tuple ((whoosh.index.FileIndex, str)): first element is index, second is index directory.\n    \"\"\"\n\n    index_dir = os.path.join(root_dir, index_name)\n    try:\n        if not os.path.exists(index_dir):\n            os.makedirs(index_dir)\n            return create_in(index_dir, schema), index_dir\n        else:\n            return open_dir(index_dir), index_dir\n    except Exception as e:\n        logger.error(\"Init error: failed to open search index at: '{}': {} \".format(index_dir, e))\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset(self):\n        if os.path.exists(self.index_dir):\n            rmtree(self.index_dir)\n        self.index = None", "response": "Resets the index by removing the index directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all(self):\n        datasets = []\n        for dataset in self.index.searcher().documents():\n            res = DatasetSearchResult()\n            res.vid = dataset['vid']\n            res.b_score = 1\n            datasets.append(res)\n        return datasets", "response": "Returns list with all indexed datasets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, search_phrase, limit=None):\n        query_string = self._make_query_from_terms(search_phrase)\n        self._parsed_query = query_string\n        schema = self._get_generic_schema()\n\n        parser = QueryParser('doc', schema=schema)\n\n        query = parser.parse(query_string)\n\n        datasets = defaultdict(DatasetSearchResult)\n\n        # collect all datasets\n        logger.debug('Searching datasets using `{}` query.'.format(query))\n        with self.index.searcher() as searcher:\n            results = searcher.search(query, limit=limit)\n            for hit in results:\n                vid = hit['vid']\n                datasets[vid].vid = hit['vid']\n                datasets[vid].b_score += hit.score\n\n        # extend datasets with partitions\n        logger.debug('Extending datasets with partitions.')\n        for partition in self.backend.partition_index.search(search_phrase):\n            datasets[partition.dataset_vid].p_score += partition.score\n            datasets[partition.dataset_vid].partitions.add(partition)\n        return list(datasets.values())", "response": "Searches for datasets by search phrase."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_query_from_terms(self, terms):\n\n        expanded_terms = self._expand_terms(terms)\n\n        cterms = ''\n\n        if expanded_terms['doc']:\n            cterms = self.backend._and_join(expanded_terms['doc'])\n\n        if expanded_terms['keywords']:\n            if cterms:\n                cterms = self.backend._and_join(\n                    cterms, self.backend._join_keywords(expanded_terms['keywords']))\n            else:\n                cterms = self.backend._join_keywords(expanded_terms['keywords'])\n\n        logger.debug('Dataset terms conversion: `{}` terms converted to `{}` query.'.format(terms, cterms))\n        return cterms", "response": "Converts a dictionary of term names to a query string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn whoosh s generic schema of the dataset.", "response": "def _get_generic_schema(self):\n        \"\"\" Returns whoosh's generic schema of the dataset. \"\"\"\n        schema = Schema(\n            vid=ID(stored=True, unique=True),  # Object id\n            title=NGRAMWORDS(),\n            keywords=KEYWORD,  # Lists of coverage identifiers, ISO time values and GVIDs, source names, source abbrev\n            doc=TEXT)  # Generated document for the core of the topic search\n        return schema"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete given dataset from index.", "response": "def _delete(self, vid=None):\n        \"\"\" Deletes given dataset from index.\n\n        Args:\n            vid (str): dataset vid.\n\n        \"\"\"\n\n        assert vid is not None, 'vid argument can not be None.'\n        writer = self.index.writer()\n        writer.delete_by_term('vid', vid)\n        writer.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if dataset is already indexed otherwise returns False.", "response": "def is_indexed(self, dataset):\n        \"\"\" Returns True if dataset is already indexed. Otherwise returns False. \"\"\"\n        with self.index.searcher() as searcher:\n            result = searcher.search(Term('vid', dataset.vid))\n            return bool(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for identifiers by search phrase.", "response": "def search(self, search_phrase, limit=None):\n        \"\"\" Finds identifier by search phrase. \"\"\"\n        self._parsed_query = search_phrase\n        schema = self._get_generic_schema()\n        parser = QueryParser('name', schema=schema)\n        query = parser.parse(search_phrase)\n\n        class PosSizeWeighting(scoring.WeightingModel):\n\n            def scorer(self, searcher, fieldname, text, qf=1):\n                return self.PosSizeScorer(searcher, fieldname, text, qf=qf)\n\n            class PosSizeScorer(scoring.BaseScorer):\n                def __init__(self, searcher, fieldname, text, qf=1):\n                    self.searcher = searcher\n                    self.fieldname = fieldname\n                    self.text = text\n                    self.qf = qf\n                    self.bmf25 = scoring.BM25F()\n\n                def max_quality(self):\n                    return 40\n\n                def score(self, matcher):\n                    poses = matcher.value_as('positions')\n                    return (2.0 / (poses[0] + 1) + 1.0 / (len(self.text) / 4 + 1) +\n                            self.bmf25.scorer(searcher, self.fieldname, self.text).score(matcher))\n\n        with self.index.searcher(weighting=PosSizeWeighting()) as searcher:\n            results = searcher.search(query, limit=limit)\n            for hit in results:\n                vid = hit['identifier']\n                yield IdentifierSearchResult(\n                    score=hit.score, vid=vid,\n                    type=hit.get('type', False),\n                    name=hit.get('name', ''))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the given identifier document to the index.", "response": "def _index_document(self, identifier, force=False):\n        \"\"\" Adds identifier document to the index. \"\"\"\n        writer = self.index.writer()\n        all_names = set([x['name'] for x in self.index.searcher().documents()])\n        if identifier['name'] not in all_names:\n            writer.add_document(**identifier)\n            writer.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning whoosh s generic schema.", "response": "def _get_generic_schema(self):\n        \"\"\" Returns whoosh's generic schema. \"\"\"\n        schema = Schema(\n            identifier=ID(stored=True),  # Partition versioned id\n            type=ID(stored=True),\n            name=NGRAM(phrase=True, stored=True, minsize=2, maxsize=8))\n        return schema"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete given identifier from index.", "response": "def _delete(self, identifier=None):\n        \"\"\" Deletes given identifier from index.\n\n        Args:\n            identifier (str): identifier of the document to delete.\n\n        \"\"\"\n        assert identifier is not None, 'identifier argument can not be None.'\n        writer = self.index.writer()\n        writer.delete_by_term('identifier', identifier)\n        writer.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_indexed(self, identifier):\n        with self.index.searcher() as searcher:\n            result = searcher.search(Term('identifier', identifier['identifier']))\n            return bool(result)", "response": "Returns True if identifier is already indexed otherwise returns False."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning list with all indexed partitions.", "response": "def all(self):\n        \"\"\" Returns list with all indexed partitions. \"\"\"\n        partitions = []\n        for partition in self.index.searcher().documents():\n            partitions.append(\n                PartitionSearchResult(dataset_vid=partition['dataset_vid'], vid=partition['vid'], score=1))\n        return partitions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(self, search_phrase, limit=None):\n\n        query_string = self._make_query_from_terms(search_phrase)\n        self._parsed_query = query_string\n        schema = self._get_generic_schema()\n        parser = QueryParser('doc', schema=schema)\n        query = parser.parse(query_string)\n        logger.debug('Searching partitions using `{}` query.'.format(query))\n        with self.index.searcher() as searcher:\n            results = searcher.search(query, limit=limit)\n            for hit in results:\n                yield PartitionSearchResult(\n                    vid=hit['vid'], dataset_vid=hit['dataset_vid'], score=hit.score)", "response": "Searches for partitions by search phrase."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a FTS query for partition created from decomposed search terms.", "response": "def _make_query_from_terms(self, terms):\n        \"\"\" returns a FTS query for partition created from decomposed search terms.\n\n        args:\n            terms (dict or str):\n\n        returns:\n            str containing fts query.\n\n        \"\"\"\n\n        expanded_terms = self._expand_terms(terms)\n\n        cterms = ''\n        if expanded_terms['doc']:\n            cterms = self.backend._or_join(expanded_terms['doc'])\n\n        keywords = expanded_terms['keywords']\n\n        frm_to = self._from_to_as_term(expanded_terms['from'], expanded_terms['to'])\n\n        if frm_to:\n            keywords.append(frm_to)\n\n        if keywords:\n            if cterms:\n                cterms = self.backend._and_join(\n                    [cterms, self.backend._field_term('keywords', expanded_terms['keywords'])])\n            else:\n                cterms = self.backend._field_term('keywords', expanded_terms['keywords'])\n\n        logger.debug('partition terms conversion: `{}` terms converted to `{}` query.'.format(terms, cterms))\n\n        return cterms"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts from and to FTS query format.", "response": "def _from_to_as_term(self, frm, to):\n        \"\"\" Turns from and to into the query format.\n\n        Args:\n            frm (str): from year\n            to (str): to year\n\n        Returns:\n            FTS query str with years range.\n\n        \"\"\"\n\n        # The wackiness with the conversion to int and str, and adding ' ', is because there\n        # can't be a space between the 'TO' and the brackets in the time range\n        # when one end is open\n        from_year = ''\n        to_year = ''\n\n        def year_or_empty(prefix, year, suffix):\n            try:\n                return prefix + str(int(year)) + suffix\n            except (ValueError, TypeError):\n                return ''\n\n        if frm:\n            from_year = year_or_empty('', frm, ' ')\n\n        if to:\n            to_year = year_or_empty(' ', to, '')\n\n        if bool(from_year) or bool(to_year):\n            return '[{}TO{}]'.format(from_year, to_year)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _index_document(self, document, force=False):\n        if force:\n            self._delete(vid=document['vid'])\n\n        writer = self.index.writer()\n        writer.add_document(**document)\n        writer.commit()", "response": "Adds a parition document to the index."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self, _):\n        #l.debug(\"Copying %d bytes of memory with id %s.\" % (len(self.mem), self.id))\n        c = SimSymbolicDbgMemory(\n            mem=self.mem.branch(),\n            memory_id=self.id,\n            endness=self.endness,\n            abstract_backer=self._abstract_backer,\n            read_strategies=[ s.copy() for s in self.read_strategies ],\n            write_strategies=[ s.copy() for s in self.write_strategies ],\n            stack_region_map=self._stack_region_map,\n            generic_region_map=self._generic_region_map\n        )\n\n        return c", "response": "Returns a copy of the SimSymbolicDbgMemory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef column(self):\n        from ambry.orm.exc import NotFoundError\n\n        if not hasattr(self, 'partition'):\n            return None\n\n        if not self.name:\n            return None\n\n        try:\n            try:\n                return self.partition.column(self.name)\n            except AttributeError:\n                return self.partition.table.column(self.name)\n        except NotFoundError:\n            return None", "response": "Return the ambry column"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef repository_type(self, repository_type):\n        allowed_values = [\"MAVEN\", \"NPM\", \"COCOA_POD\", \"GENERIC_PROXY\"]\n        if repository_type not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `repository_type` ({0}), must be one of {1}\"\n                .format(repository_type, allowed_values)\n            )\n\n        self._repository_type = repository_type", "response": "Sets the repository_type of this TargetRepositoryRest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef worker(inqueue, outqueue, initializer=None, initargs=(), maxtasks=None):\n    from ambry.library import new_library\n    from ambry.run import get_runconfig\n    import traceback\n\n    assert maxtasks is None or (type(maxtasks) == int and maxtasks > 0)\n\n    put = outqueue.put\n    get = inqueue.get\n\n    if hasattr(inqueue, '_writer'):\n        inqueue._writer.close()\n        outqueue._reader.close()\n\n    if initializer is not None:\n        initializer(*initargs)\n\n    try:\n        task = get()\n    except (EOFError, IOError):\n        debug('worker got EOFError or IOError -- exiting')\n        return\n\n    if task is None:\n        debug('worker got sentinel -- exiting')\n        return\n\n    job, i, func, args, kwds = task\n\n    # func = mapstar = map(*args)\n\n    # Since there is only one source build per process, we know the structure\n    # of the args beforehand.\n    mp_func = args[0][0]\n    mp_args = list(args[0][1][0])\n\n    library = new_library(get_runconfig())\n    library.database.close()  # Maybe it is still open after the fork.\n    library.init_debug()\n\n    bundle_vid = mp_args[0]\n\n    try:\n\n        b = library.bundle(bundle_vid)\n        library.logger = b.logger # So library logs to the same file as the bundle.\n\n        b = b.cast_to_subclass()\n        b.multi = True  # In parent it is a number, in child, just needs to be true to get the right logger template\n        b.is_subprocess = True\n        b.limited_run = bool(int(os.getenv('AMBRY_LIMITED_RUN', 0)))\n\n        assert b._progress == None  # Don't want to share connections across processes\n\n        mp_args[0] = b\n        result = (True, [mp_func(*mp_args)])\n\n    except Exception as e:\n        import traceback\n        tb = traceback.format_exc()\n        b.error('Subprocess {} raised an exception: {}'.format(os.getpid(), e.message), False)\n        b.error(tb, False)\n        result = (False, e)\n\n    assert result\n\n    b.progress.close()\n    library.close()\n\n    try:\n        put((job, i, result))\n    except Exception as e:\n        wrapped = MaybeEncodingError(e, result[1])\n        debug(\"Possible encoding error while sending result: %s\" % (wrapped))\n        put((job, i, (False, wrapped)))", "response": "This function is used to run a worker for bundle operations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the library with the given database and accounts password.", "response": "def init_library(database_dsn, accounts_password, limited_run = False):\n    \"\"\"Child initializer, setup in Library.process_pool\"\"\"\n\n    import os\n    import signal\n\n    # Have the child processes ignore the keyboard interrupt, and other signals. Instead, the parent will\n    # catch these, and clean up the children.\n    signal.signal(signal.SIGINT, signal.SIG_IGN)\n    #signal.signal(signal.SIGTERM, sigterm_handler)\n\n    os.environ['AMBRY_DB'] = database_dsn\n    if accounts_password:\n        os.environ['AMBRY_PASSWORD'] = accounts_password\n    os.environ['AMBRY_LIMITED_RUN'] = '1' if limited_run else '0'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ningesting a source using only arguments that can be pickled for multiprocessing access", "response": "def build_mp(b, stage, source_name, force):\n    \"\"\"Ingest a source, using only arguments that can be pickled, for multiprocessing access\"\"\"\n\n    source = b.source(source_name)\n\n    with b.progress.start('build_mp',stage,message=\"MP build\", source=source) as ps:\n        ps.add(message='Running source {}'.format(source.name), source=source, state='running')\n        r = b.build_source(stage, source, ps, force)\n\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unify_mp(b, partition_name):\n\n    with b.progress.start('coalesce_mp',0,message=\"MP coalesce {}\".format(partition_name)) as ps:\n        r = b.unify_partition(partition_name, None, ps)\n\n    return r", "response": "Unify all of the segment partitions for a parent partition and run stats on the MPR file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ningesting a source using only arguments that can be pickled for multiprocessing access", "response": "def ingest_mp(b, stage, source_name, clean_files):\n    \"\"\"Ingest a source, using only arguments that can be pickled, for multiprocessing access\"\"\"\n\n    source = b.source(source_name)\n\n    with b.progress.start('ingest_mp',0,message=\"MP ingestion\", source=source) as ps:\n        r =  b._ingest_source(source, ps, clean_files)\n\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _repopulate_pool(self):\n        for i in range(self._processes - len(self._pool)):\n            w = self.Process(target=self._worker_f,\n                             args=(self._inqueue, self._outqueue,\n                                   self._initializer,\n                                   self._initargs, self._maxtasksperchild))\n            self._pool.append(w)\n            w.name = w.name.replace('Process', 'PoolWorker')\n            w.daemon = True\n            w.start()\n            debug('added worker')", "response": "Repopulate the pool with the number of processes up to the specified number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _compose(self, name, args, mkdir=True):\n        from os.path import normpath\n        from ambry.dbexceptions import ConfigurationError\n\n        root = p = self._config.filesystem[name].format(root=self._root)\n\n        if args:\n            args = [e.strip() for e in args]\n            p = join(p, *args)\n\n        if not isdir(p) and mkdir:\n            makedirs(p)\n\n        p = normpath(p)\n\n        if not p.startswith(root):\n            raise ConfigurationError(\"Path for name='{}', args={} resolved outside of define filesystem root\"\n                                 .format(name, args))\n\n        return p", "response": "Get a named filesystem entry and extend it into a path with additional\n        path arguments"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compose(self, name, *args):\n\n        return self._compose(name, args, mkdir=False)", "response": "Compose a new base directory and return the new base directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubstitute the root dir into the database DSN for Sqlite", "response": "def database_dsn(self):\n        \"\"\"Substitute the root dir into the database DSN, for Sqlite\"\"\"\n\n        if not self._config.library.database:\n            return 'sqlite:///{root}/library.db'.format(root=self._root)\n\n        return self._config.library.database.format(root=self._root)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_table_map(table, headers):\n\n    header_parts = {}\n    for i, h in enumerate(headers):\n        header_parts[h] = 'row[{}]'.format(i)\n\n    body_code = 'lambda row: [{}]'.format(','.join(header_parts.get(c.name, 'None') for c in table.columns))\n    header_code = 'lambda row: [{}]'.format(\n        ','.join(header_parts.get(c.name, \"'{}'\".format(c.name)) for c in table.columns))\n\n    return eval(header_code), eval(body_code)", "response": "Create a function to map from rows with the structure of the headers to the structure of the table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naugmenting the pipeline by adding a new pipe section to each stage that has one or more pipes.", "response": "def augment_pipeline(pl, head_pipe=None, tail_pipe=None):\n    \"\"\"\n    Augment the pipeline by adding a new pipe section to each stage that has one or more pipes. Can be used for debugging\n\n    :param pl:\n    :param DebugPipe:\n    :return:\n    \"\"\"\n\n    for k, v in iteritems(pl):\n        if v and len(v) > 0:\n            if head_pipe and k != 'source':  # Can't put anything before the source.\n                v.insert(0, head_pipe)\n\n            if tail_pipe:\n                v.append(tail_pipe)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts given string to ascii ignoring non ascii.", "response": "def _to_ascii(s):\n    \"\"\" Converts given string to ascii ignoring non ascii.\n    Args:\n        s (text or binary):\n\n    Returns:\n        str:\n    \"\"\"\n    # TODO: Always use unicode within ambry.\n    from six import text_type, binary_type\n    if isinstance(s, text_type):\n        ascii_ = s.encode('ascii', 'ignore')\n    elif isinstance(s, binary_type):\n        ascii_ = s.decode('utf-8').encode('ascii', 'ignore')\n    else:\n        raise Exception('Unknown text type - {}'.format(type(s)))\n    return ascii_"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef report_progress(self):\n        from time import time\n\n        # rows, rate = pl.sink.report_progress()\n        return (self.i, round(float(self.i) / float(time() - self._start_time), 2))", "response": "This function is called by the scheduler to report the current process progress. It is called by the scheduler to report the current process progress."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a slice string of the same form as used by __getitem__ >>>", "response": "def parse(v):\n        \"\"\"\n        Parse a slice string, of the same form as used by __getitem__\n\n        >>> Slice.parse(\"2:3,7,10:12\")\n\n        :param v: Input string\n        :return: A list of tuples, one for each element of the slice string\n        \"\"\"\n\n        parts = v.split(',')\n\n        slices = []\n\n        for part in parts:\n            p = part.split(':')\n\n            if len(p) == 1:\n                slices.append(int(p[0]))\n            elif len(p) == 2:\n                slices.append(tuple(p))\n            else:\n                raise ValueError(\"Too many ':': {}\".format(part))\n\n        return slices"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nignore the incomming header and replace it with the destination header", "response": "def process_header(self, headers):\n        \"\"\"Ignore the incomming header and replace it with the destination header\"\"\"\n\n        return [c.name for c in self.source.dest_table.columns][1:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noverriding this method to change the way that column names from the source are altered to become column names in the schema. This method is called from :py:meth:`mangle_header` for each column in the header, and :py:meth:`mangle_header` is called from the RowGenerator, so it will alter the row both when the schema is being generated and when data are being inserted into the partition. Implement it in your bundle class to change the how columsn are converted from the source into database-friendly names :param i: Column number :param n: Original column name :return: A new column name", "response": "def mangle_column_name(self, i, n):\n        \"\"\"\n        Override this method to change the way that column names from the source are altered to\n        become column names in the schema. This method is called from :py:meth:`mangle_header` for each column in the\n        header, and :py:meth:`mangle_header` is called from the RowGenerator, so it will alter the row both when the\n        schema is being generated and when data are being inserted into the partition.\n\n        Implement it in your bundle class to change the how columsn are converted from the source into database-friendly\n        names\n\n        :param i: Column number\n        :param n: Original column name\n        :return: A new column name\n        \"\"\"\n        from ambry.orm import Column\n\n        if not n:\n            return 'column{}'.format(i)\n\n        mn = Column.mangle_name(str(n).strip())\n\n        return mn"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeferring initialization b/c the object con be constructed without a valid source", "response": "def init(self):\n        \"\"\"Deferred initialization b/c the object con be constructed without a valid source\"\"\"\n        from itertools import chain\n\n        def maybe_int(v):\n            try:\n                return int(v)\n            except ValueError:\n                return None\n\n        if not self.initialized:\n\n            self.data_start_line = 1\n            self.data_end_line = None\n            self.header_lines = [0]\n\n            if self.source.start_line:\n                self.data_start_line = self.source.start_line\n            if self.source.end_line:\n                self.data_end_line = self.source.end_line\n            if self.source.header_lines:\n                self.header_lines = list(map(maybe_int, self.source.header_lines))\n            if self.source.comment_lines:\n                self.header_comment_lines = list(map(maybe_int, self.source.comment_lines))\n\n            max_header_line = max(chain(self.header_comment_lines, self.header_lines))\n\n            if self.data_start_line <= max_header_line:\n                self.data_start_line = max_header_line + 1\n\n            if not self.header_comment_lines:\n                min_header_line = min(chain(self.header_lines))\n                if min_header_line:\n                    self.header_comment_lines = list(range(0, min_header_line))\n\n            self.headers = []\n            self.header_comments = []\n            self.footers = []\n\n            self.initialized = True\n            self.i = 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rate(self):\n\n        end = self._end_time if self._end_time else time.time()\n\n        return self._count / (end - self._start_time)", "response": "Report the insertion rate in records per second"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _subset(self, subset):\n        pl = Pipeline(bundle=self.bundle)\n        for group_name, pl_segment in iteritems(self):\n            if group_name not in subset:\n                continue\n            pl[group_name] = pl_segment\n        return pl", "response": "Return a new pipeline with a subset of the sections"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconfigure from a dictionary of pipeline configuration.", "response": "def configure(self, pipe_config):\n        \"\"\"Configure from a dict\"\"\"\n\n        # Create a context for evaluating the code for each pipeline. This removes the need\n        # to qualify the class names with the module\n        import ambry.etl\n        import sys\n        # ambry.build comes from ambry.bundle.files.PythonSourceFile#import_bundle\n        eval_locals = dict(list(locals().items()) + list(ambry.etl.__dict__.items()) +\n                           list(sys.modules['ambry.build'].__dict__.items()))\n\n        replacements = {}\n\n        def eval_pipe(pipe):\n            if isinstance(pipe, string_types):\n                try:\n                    return eval(pipe, {}, eval_locals)\n                except SyntaxError as e:\n                    raise SyntaxError(\"SyntaxError while parsing pipe '{}' from metadata: {}\"\n                                      .format(pipe, e))\n            else:\n                return pipe\n\n        def pipe_location(pipe):\n            \"\"\"Return a location prefix from a pipe, or None if there isn't one \"\"\"\n            if not isinstance(pipe, string_types):\n                return None\n\n            elif pipe[0] in '+-$!':\n                return pipe[0]\n\n            else:\n                return None\n\n        for segment_name, pipes in list(pipe_config.items()):\n            if segment_name == 'final':\n                # The 'final' segment is actually a list of names of Bundle methods to call afer the pipeline\n                # completes\n                super(Pipeline, self).__setattr__('final', pipes)\n            elif segment_name == 'replace':\n                for frm, to in iteritems(pipes):\n                    self.replace(eval_pipe(frm), eval_pipe(to))\n            else:\n\n                # Check if any of the pipes have a location command. If not, the pipe\n                # is cleared and the set of pipes replaces the ones that are there.\n                if not any(bool(pipe_location(pipe)) for pipe in pipes):\n                    # Nope, they are all clean\n                    self[segment_name] = [eval_pipe(pipe) for pipe in pipes]\n                else:\n                    for i, pipe in enumerate(pipes):\n\n                        if pipe_location(pipe):  # The pipe is prefixed with a location command\n                            location = pipe_location(pipe)\n                            pipe = pipe[1:]\n                        else:\n                            raise PipelineError(\n                                'If any pipes in a section have a location command, they all must'\n                                ' Segment: {} pipes: {}'.format(segment_name, pipes))\n\n                        ep = eval_pipe(pipe)\n\n                        if location == '+':  # append to the segment\n                            self[segment_name].append(ep)\n                        elif location == '-':  # Prepend to the segment\n                            self[segment_name].prepend(ep)\n                        elif location == '!':  # Replace a pipe of the same class\n\n                            if isinstance(ep, type):\n                                repl_class = ep\n                            else:\n                                repl_class = ep.__class__\n\n                            self.replace(repl_class, ep, segment_name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace(self, repl_class, replacement, target_segment_name=None):\n\n        for segment_name, pipes in iteritems(self):\n\n            if target_segment_name and segment_name != target_segment_name:\n                raise Exception()\n\n            repl_pipes = []\n            found = False\n            for pipe in pipes:\n                if isinstance(pipe, repl_class):\n                    pipe = replacement\n                    found = True\n\n                repl_pipes.append(pipe)\n\n            if found:\n                found = False\n                self[segment_name] = repl_pipes", "response": "Replace a pipe segment specified by its class with another segment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall FDW or materialize view for given partition.", "response": "def install(self, connection, partition, table_name=None, columns=None, materialize=False,\n                logger=None):\n        \"\"\" Creates FDW or materialize view for given partition.\n\n        Args:\n            connection: connection to postgresql\n            partition (orm.Partition):\n            materialize (boolean): if True, create read-only table. If False create virtual table.\n\n        Returns:\n            str: name of the created table.\n\n        \"\"\"\n\n        partition.localize()\n\n        self._add_partition(connection, partition)\n        fdw_table = partition.vid\n        view_table = '{}_v'.format(fdw_table)\n\n        if materialize:\n            with connection.cursor() as cursor:\n                view_exists = self._relation_exists(connection, view_table)\n                if view_exists:\n                    logger.debug(\n                        'Materialized view of the partition already exists.\\n    partition: {}, view: {}'\n                        .format(partition.name, view_table))\n                else:\n                    query = 'CREATE MATERIALIZED VIEW {} AS SELECT * FROM {};'\\\n                        .format(view_table, fdw_table)\n                    logger.debug(\n                        'Creating new materialized view of the partition.'\n                        '\\n    partition: {}, view: {}, query: {}'\n                        .format(partition.name, view_table, query))\n                    cursor.execute(query)\n                    cursor.execute('COMMIT;')\n\n        final_table = view_table if materialize else fdw_table\n\n        with connection.cursor() as cursor:\n            view_q = \"CREATE VIEW IF NOT EXISTS {} AS SELECT * FROM {} \".format(partition.vid, final_table)\n            cursor.execute(view_q)\n            cursor.execute('COMMIT;')\n\n        return partition.vid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an index on the columns.", "response": "def index(self, connection, partition, columns):\n        \"\"\" Create an index on the columns.\n\n        Args:\n            connection:\n            partition (orm.Partition):\n            columns (list of str):\n\n        \"\"\"\n        query_tmpl = 'CREATE INDEX ON {table_name} ({column});'\n        table_name = '{}_v'.format(partition.vid)\n        for column in columns:\n            query = query_tmpl.format(table_name=table_name, column=column)\n            logger.debug('Creating postgres index.\\n    column: {}, query: {}'.format(column, query))\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                cursor.execute('COMMIT;')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclosing the connection to the database.", "response": "def close(self):\n        \"\"\" Closes connection to database. \"\"\"\n        if getattr(self, '_connection', None):\n            logger.debug('Closing postgresql connection.')\n            self._connection.close()\n            self._connection = None\n        if getattr(self, '_engine', None):\n            self._engine.dispose()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_mpr_table(self, connection, partition):\n        # TODO: This is the first candidate for optimization. Add field to partition\n        # with table name and update it while table creation.\n        # Optimized version.\n        #\n        # return partition.mpr_table or raise exception\n\n        # Not optimized version.\n        #\n        # first check either partition has materialized view.\n        logger.debug(\n            'Looking for materialized view of the partition.\\n    partition: {}'.format(partition.name))\n        foreign_table = partition.vid\n        view_table = '{}_v'.format(foreign_table)\n        view_exists = self._relation_exists(connection, view_table)\n        if view_exists:\n            logger.debug(\n                'Materialized view of the partition found.\\n    partition: {}, view: {}'\n                .format(partition.name, view_table))\n            return view_table\n\n        # now check for fdw/virtual table\n        logger.debug(\n            'Looking for foreign table of the partition.\\n    partition: {}'.format(partition.name))\n        foreign_exists = self._relation_exists(connection, foreign_table)\n        if foreign_exists:\n            logger.debug(\n                'Foreign table of the partition found.\\n    partition: {}, foreign table: {}'\n                .format(partition.name, foreign_table))\n            return foreign_table\n        raise MissingTableError('postgres database does not have table for {} partition.'\n                                .format(partition.vid))", "response": "Returns the name of the postgres table who stores mpr data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_partition(self, connection, partition):\n        logger.debug('Creating foreign table for partition.\\n    partition: {}'.format(partition.name))\n        with connection.cursor() as cursor:\n            postgres_med.add_partition(cursor, partition.datafile, partition.vid)", "response": "Creates FDW for the partition."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a connection to the postgres database who stores mpr data.", "response": "def _get_connection(self):\n        \"\"\" Returns connection to the postgres database.\n\n        Returns:\n            connection to postgres database who stores mpr data.\n\n        \"\"\"\n        if not getattr(self, '_connection', None):\n            logger.debug(\n                'Creating new connection.\\n   dsn: {}'\n                .format(self._dsn))\n\n            d = parse_url_to_dict(self._dsn)\n            self._connection = psycopg2.connect(\n                database=d['path'].strip('/'), user=d['username'], password=d['password'],\n                port=d['port'], host=d['hostname'])\n            # It takes some time to find the way how to get raw connection from sqlalchemy. So,\n            # I leave the commented code.\n            #\n            # self._engine = create_engine(self._dsn)\n            # self._connection = self._engine.raw_connection()\n            #\n        return self._connection"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting given query and returns result.", "response": "def _execute(self, connection, query, fetch=True):\n        \"\"\" Executes given query and returns result.\n\n        Args:\n            connection: connection to postgres database who stores mpr data.\n            query (str): sql query\n            fetch (boolean, optional): if True, fetch query result and return it. If False, do not fetch.\n\n        Returns:\n            iterable with query result or None if fetch is False.\n\n        \"\"\"\n        # execute query\n        with connection.cursor() as cursor:\n            cursor.execute(query)\n            if fetch:\n                return cursor.fetchall()\n            else:\n                cursor.execute('COMMIT;')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _relation_exists(cls, connection, relation):\n        schema_name, table_name = relation.split('.')\n\n        exists_query = '''\n            SELECT 1\n            FROM   pg_catalog.pg_class c\n            JOIN   pg_catalog.pg_namespace n ON n.oid = c.relnamespace\n            WHERE  n.nspname = %s\n            AND    c.relname = %s\n            AND    (c.relkind = 'r' OR c.relkind = 'v' OR c.relkind = 'm')\n                -- r - table, v - view, m - materialized view.\n        '''\n        with connection.cursor() as cursor:\n            cursor.execute(exists_query, [schema_name, table_name])\n            result = cursor.fetchall()\n            return result == [(1,)]", "response": "Returns True if the relation exists in the postgres db otherwise returns False."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading data from the worldbank. org API.", "response": "def load(self, country=\"all\"):\n        \"\"\"\n        Load data\n        \"\"\"\n        u = (\"https://api.worldbank.org/v2/countries/{}/indicators/CPTOTSAXN\"\n             \"?format=json&per_page=10000\").format(country)\n        r = requests.get(u)\n        j = r.json()\n        cpi_data = j[1]\n\n        # Loop through the rows of the datapackage with the help of data\n        for row in cpi_data:\n            # Get the code and the name and transform to uppercase\n            # so that it'll match no matter the case\n            iso_3 = row[\"countryiso3code\"].upper()\n            iso_2 = row[\"country\"][\"id\"].upper()\n            name = row[\"country\"]['value'].upper()\n            # Get the date (which is in the field Year) and the CPI value\n            date = row['date']\n            cpi = row['value']\n            for key in [iso_3, iso_2, name]:\n                existing = self.data.get(key, {})\n                existing[str(date)] = cpi\n                if key:\n                    self.data[key] = existing"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the CPI value for a specific time.", "response": "def get(self, date=datetime.date.today(), country=None):\n        \"\"\"\n        Get the CPI value for a specific time. Defaults to today. This uses\n        the closest method internally but sets limit to one day.\n        \"\"\"\n        if not country:\n            country = self.country\n        if country == \"all\":\n            raise ValueError(\"You need to specify a country\")\n        if not isinstance(date, str) and not isinstance(date, int):\n            date = date.year\n\n        cpi = self.data.get(country.upper(), {}).get(str(date))\n        if not cpi:\n            raise ValueError(\"Missing CPI data for {} for {}\".format(\n                country, date))\n\n        return CPIResult(date=date, value=cpi)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstringing - based reverse API. Returns subreverse object.", "response": "def build_subreverse(self, _name, **kwargs):\n        '''\n        String-based reverse API. Returns subreverse object::\n\n            env.root.build_subreverse('user', user_id=1).profile\n        '''\n        _, subreverse = self._build_url_silent(_name, **kwargs)\n        return subreverse"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_url(self, _name, **kwargs):\n        '''\n        String-based reverse API. Returns URL object::\n\n            env.root.build_url('user.profile', user_id=1)\n\n        Checks that all necessary arguments are provided and all\n        provided arguments are used.\n        '''\n        used_args, subreverse =  self._build_url_silent(_name, **kwargs)\n\n        if set(kwargs).difference(used_args):\n            raise UrlBuildingError(\n                'Not all arguments are used during URL building: {}'\\\n                    .format(', '.join(set(kwargs).difference(used_args))))\n        return subreverse.as_url", "response": "String - based reverse API. Returns URL object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_url(self):\n        '''\n        Reverse object converted to `web.URL`.\n\n        If Reverse is bound to env:\n            * try to build relative URL,\n            * use current domain name, port and scheme as default\n        '''\n        if '' in self._scope:\n            return self._finalize().as_url\n\n        if not self._is_endpoint:\n            raise UrlBuildingError('Not an endpoint {}'.format(repr(self)))\n\n        if self._ready:\n            path, host = self._path, self._host\n        else:\n            return self().as_url\n\n        # XXX there is a little mess with `domain` and `host` terms\n        if ':' in host:\n            domain, port = host.split(':')\n        else:\n            domain = host\n            port = None\n\n        if self._bound_env:\n            request = self._bound_env.request\n            scheme_port = {'http': '80',\n                           'https': '443'}.get(request.scheme, '80')\n\n            # Domain to compare with the result of build.\n            # If both values are equal, domain part can be hidden from result.\n            # Take it from route_state, not from env.request, because\n            # route_state contains domain values with aliased replaced by their\n            # primary value\n            primary_domain = self._bound_env._route_state.primary_domain\n            host_split = request.host.split(':')\n            request_domain = host_split[0]\n            request_port = host_split[1] if len(host_split) > 1 else scheme_port\n            port = port or request_port\n\n            return URL(path, host=domain or request_domain,\n                       port=port if port != scheme_port else None,\n                       scheme=request.scheme, fragment=self._fragment,\n                       show_host=host and (domain != primary_domain \\\n                                           or port != request_port))\n        return URL(path, host=domain, port=port,\n                   fragment=self._fragment, show_host=True)", "response": "Return the URL for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bind_to_env(self, bound_env):\n        '''\n        Get a copy of the reverse, bound to `env` object.\n        Can be found in env.root attribute::\n\n            # done in iktomi.web.app.Application\n            env.root = Reverse.from_handler(app).bind_to_env(env)\n        '''\n        return self.__class__(self._scope, self._location,\n                              path=self._path, host=self._host,\n                              fragment=self._fragment,\n                              ready=self._ready,\n                              need_arguments=self._need_arguments,\n                              finalize_params=self._finalize_params,\n                              parent=self._parent,\n                              bound_env=bound_env)", "response": "Returns a copy of the reverse bound to env. root."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_url(cls, url, show_host=True):\n        '''Parse string and get URL instance'''\n        # url must be idna-encoded and url-quotted\n\n        if six.PY2:\n            if isinstance(url, six.text_type):\n                url = url.encode('utf-8')\n            parsed = urlparse(url)\n            netloc = parsed.netloc.decode('utf-8') # XXX HACK\n        else:# pragma: no cover\n            if isinstance(url, six.binary_type):\n                url = url.decode('utf-8', errors='replace') # XXX\n            parsed = urlparse(url)\n            netloc = parsed.netloc\n\n        query = _parse_qs(parsed.query)\n        host = netloc.split(':', 1)[0] if ':' in netloc else netloc\n\n        port = netloc.split(':')[1] if ':' in netloc else ''\n        path = unquote(parsed.path)\n        fragment = unquote(parsed.fragment)\n        if not fragment and not url.endswith('#'):\n            fragment = None\n        return cls(path,\n                   query, host,\n                   port, parsed.scheme, fragment, show_host)", "response": "Parse string and get URL instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting values in QuerySet MultiDict", "response": "def qs_set(self, *args, **kwargs):\n        '''Set values in QuerySet MultiDict'''\n        if args and kwargs:\n            raise TypeError('Use positional args or keyword args not both')\n        query = self.query.copy()\n        if args:\n            mdict = MultiDict(args[0])\n            for k in mdict.keys():\n                if k in query:\n                    del query[k]\n            for k, v in mdict.items():\n                query.add(k, v)\n        else:\n            for k, v in kwargs.items():\n                query[k] = v\n        return self._copy(query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef qs_add(self, *args, **kwargs):\n        '''Add value to QuerySet MultiDict'''\n        query = self.query.copy()\n        if args:\n            mdict = MultiDict(args[0])\n            for k, v in mdict.items():\n                query.add(k, v)\n        for k, v in kwargs.items():\n            query.add(k, v)\n        return self._copy(query=query)", "response": "Add value to QuerySet MultiDict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete value from QuerySet MultiDict", "response": "def qs_delete(self, *keys):\n        '''Delete value from QuerySet MultiDict'''\n        query = self.query.copy()\n        for key in set(keys):\n            try:\n                del query[key]\n            except KeyError:\n                pass\n        return self._copy(query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef qs_get(self, key, default=None):\n        '''Get a value from QuerySet MultiDict'''\n        return self.query.get(key, default=default)", "response": "Get a value from QuerySet MultiDict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_readable(self):\n        '''\n        Gets human-readable representation of the url (as unicode string,\n        IRI according RFC3987)\n        '''\n        query = (u'?' + u'&'.join(u'{}={}'.format(urlquote(k), urlquote(v))\n                                  for k, v in six.iteritems(self.query))\n                 if self.query else '')\n        hash_part = (u'#' + self.fragment) if self.fragment is not None else u''\n\n        path, query, hash_part = uri_to_iri_parts(self.path, query, hash_part)\n\n        if self.host:\n            port = u':' + self.port if self.port else u''\n            return u''.join((self.scheme, '://', self.host, port, path, query, hash_part))\n        else:\n            return path + query + hash_part", "response": "Gets human - readable representation of the url according RFC3987"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncanceling running build. This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please define a `callback` function to be invoked when receiving the response. >>> def callback_function(response): >>> pprint(response) >>> >>> thread = api.cancel(id, callback=callback_function) :param callback function: The callback function for asynchronous request. (optional) :param int id: BuildRecord id (required) :return: None If the method is called asynchronously, returns the request thread.", "response": "def cancel(self, id, **kwargs):\n        \"\"\"\n        Cancel running build.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.cancel(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: BuildRecord id (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.cancel_with_http_info(id, **kwargs)\n        else:\n            (data) = self.cancel_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets SSH credentials for a build record.", "response": "def get_ssh_credentials(self, id, **kwargs):\n        \"\"\"\n        Gets ssh credentials for a build\n        This GET request is for authenticated users only. The path for the endpoint is not restful to be able to authenticate this GET request only.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_ssh_credentials(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: BuildRecord id (required)\n        :return: SshCredentialsSingleton\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_ssh_credentials_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_ssh_credentials_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_support_level(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_all_support_level_with_http_info(**kwargs)\n        else:\n            (data) = self.get_all_support_level_with_http_info(**kwargs)\n            return data", "response": "Get all Product Releases Support Level\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_release(id, **kwargs):\n    data = update_release_raw(id, **kwargs)\n    if data:\n        return utils.format_json(data)", "response": "Update an existing ProductRelease with new information"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting provider by id", "response": "def get(self, identifier):\n        \"\"\"get provider by id\"\"\"\n        for provider in self._providers:\n            if provider.identifier == identifier:\n                return provider\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches song album artist or album by keyword", "response": "def search(self, keyword, source_in=None, **kwargs):\n        \"\"\"search song/artist/album by keyword\n\n        TODO: search album or artist\n        \"\"\"\n        for provider in self._providers:\n            if source_in is not None:\n                if provider.identifier not in source_in:\n                    continue\n\n            try:\n                result = provider.search(keyword=keyword)\n            except Exception as e:\n                logger.exception(str(e))\n                logger.error('Search %s in %s failed.' % (keyword, provider))\n            else:\n                yield result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_song_standby(self, song, onlyone=True):\n        def get_score(standby):\n            score = 1\n            # \u5206\u6570\u5360\u6bd4\u5173\u7cfb\uff1a\n            # title + album > artist\n            # artist > title > album\n            if song.artists_name != standby.artists_name:\n                score -= 0.4\n            if song.title != standby.title:\n                score -= 0.3\n            if song.album_name != standby.album_name:\n                score -= 0.2\n            return score\n\n        valid_sources = [p.identifier for p in self.list() if p.identifier != song.source]\n        q = '{} {}'.format(song.title, song.artists_name)\n\n        standby_list = []\n        for result in self.search(q, source_in=valid_sources, limit=10):\n            for standby in result.songs[:2]:\n                standby_list.append(standby)\n        standby_list = sorted(\n            standby_list,\n            key=lambda standby: get_score(standby), reverse=True\n        )\n\n        valid_standby_list = []\n        for standby in standby_list:\n            if standby.url:\n                valid_standby_list.append(standby)\n                if get_score(standby) == 1 or onlyone:\n                    break\n                if len(valid_standby_list) >= 2:\n                    break\n        return valid_standby_list", "response": "try to list all valid standby songs in all providers"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a class by importing its module from a fully qualified string.", "response": "def import_class_by_string(name):\n    \"\"\"Return a class by importing its module from a fully qualified string.\"\"\"\n    components = name.split('.')\n    clazz = components.pop()\n    mod = __import__('.'.join(components))\n\n    components += [clazz]\n    for comp in components[1:]:\n        mod = getattr(mod, comp)\n\n    return mod"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_for_build_configuration(self, configuration_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_all_for_build_configuration_with_http_info(configuration_id, **kwargs)\n        else:\n            (data) = self.get_all_for_build_configuration_with_http_info(configuration_id, **kwargs)\n            return data", "response": "Get all Build Records linked to a specific Build Configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_for_project(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_all_for_project_with_http_info(name, **kwargs)\n        else:\n            (data) = self.get_all_for_project_with_http_info(name, **kwargs)\n            return data", "response": "Get all BuildRecords produced from the BuildConfiguration by name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_for_project_0(self, project_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_all_for_project_0_with_http_info(project_id, **kwargs)\n        else:\n            (data) = self.get_all_for_project_0_with_http_info(project_id, **kwargs)\n            return data", "response": "Get all Build Records linked to a specific Project\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget Build Record attributes.", "response": "def get_attributes(self, id, **kwargs):\n        \"\"\"\n        Get Build Record attributes.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_attributes(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: BuildRecord id (required)\n        :return: AttributeSingleton\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_attributes_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_attributes_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_build_configuration_audited(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_build_configuration_audited_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_build_configuration_audited_with_http_info(id, **kwargs)\n            return data", "response": "Get the audited build configuration for specific build record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget artifacts built for specific Build Record", "response": "def get_built_artifacts(self, id, **kwargs):\n        \"\"\"\n        Gets artifacts built for specific Build Record\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_built_artifacts(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: BuildRecord id (required)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :param str sort: Sorting RSQL\n        :param str q: RSQL Query\n        :return: ArtifactPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_built_artifacts_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_built_artifacts_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_completed_or_runnning(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_completed_or_runnning_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_completed_or_runnning_with_http_info(id, **kwargs)\n            return data", "response": "Get a BuildRecord from the specified BuildRecord."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dependency_artifacts(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_dependency_artifacts_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_dependency_artifacts_with_http_info(id, **kwargs)\n            return data", "response": "Get dependency artifacts for specific Build Record"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dependency_graph(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_dependency_graph_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_dependency_graph_with_http_info(id, **kwargs)\n            return data", "response": "Get the dependency graph for a Build Record."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_logs(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_logs_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_logs_with_http_info(id, **kwargs)\n            return data", "response": "Get logs for specific Build Record"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets Repour logs for specific Build Record", "response": "def get_repour_logs(self, id, **kwargs):\n        \"\"\"\n        Gets repour logs for specific Build Record\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_repour_logs(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: BuildRecord id (required)\n        :return: str\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_repour_logs_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_repour_logs_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put_attribute(self, id, key, value, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.put_attribute_with_http_info(id, key, value, **kwargs)\n        else:\n            (data) = self.put_attribute_with_http_info(id, key, value, **kwargs)\n            return data", "response": "Add attribute to the BuildRecord."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying Build Records by attribute.", "response": "def query_by_attribute(self, key, value, **kwargs):\n        \"\"\"\n        Get Build Records by attribute.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.query_by_attribute(key, value, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param str key: Attribute key (required)\n        :param str value: Attribute value (required)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :param str sort: Sorting RSQL\n        :param str q: RSQL Query\n        :return: BuildRecordPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.query_by_attribute_with_http_info(key, value, **kwargs)\n        else:\n            (data) = self.query_by_attribute_with_http_info(key, value, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an attribute from BuildRecord.", "response": "def remove_attribute(self, id, key, **kwargs):\n        \"\"\"\n        Remove attribute from BuildRecord.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.remove_attribute(id, key, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: BuildRecord id (required)\n        :param str key: Attribute key (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.remove_attribute_with_http_info(id, key, **kwargs)\n        else:\n            (data) = self.remove_attribute_with_http_info(id, key, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_unconstrained_bytes(self, name, bits, source=None, key=None, inspect=True, events=True, **kwargs):\n\n        if (self.category == 'mem' and\n                options.CGC_ZERO_FILL_UNCONSTRAINED_MEMORY in self.state.options):\n            # CGC binaries zero-fill the memory for any allocated region\n            # Reference: (https://github.com/CyberGrandChallenge/libcgc/blob/master/allocate.md)\n            return self.state.solver.BVV(0, bits)\n        elif options.SPECIAL_MEMORY_FILL in self.state.options and self.state._special_memory_filler is not None:\n            return self.state._special_memory_filler(name, bits, self.state)\n        else:\n            if options.UNDER_CONSTRAINED_SYMEXEC in self.state.options:\n                if source is not None and type(source) is int:\n                    alloc_depth = self.state.uc_manager.get_alloc_depth(source)\n                    kwargs['uc_alloc_depth'] = 0 if alloc_depth is None else alloc_depth + 1\n            r = self.state.solver.Unconstrained(name, bits, key=key, inspect=inspect, events=events, **kwargs)\n            return r", "response": "Get some consecutive unconstrained bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the build_type of this BuildConfigurationRest.", "response": "def build_type(self, build_type):\n        \"\"\"\n        Sets the build_type of this BuildConfigurationRest.\n\n        :param build_type: The build_type of this BuildConfigurationRest.\n        :type: str\n        \"\"\"\n        allowed_values = [\"MVN\", \"NPM\"]\n        if build_type not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `build_type` ({0}), must be one of {1}\"\n                .format(build_type, allowed_values)\n            )\n\n        self._build_type = build_type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new SSHClient and connect it and return the SshClient instance.", "response": "def ssh_client(host, username=None, password=None, **kwargs):\n    \"\"\"\n    Create a new :class:`paramiko.SSHClient`, connect it and return the\n    instance.\n\n    This is a simple wrapper around the connect method that add some good\n    defaults when using username/password to connect.\n    \"\"\"\n    client = paramiko.SSHClient()\n    # save hostname and username on the instance - this is a ugly hack\n    # but I don't see any other way to do that for now. Note that\n    # this is only used for SshSession.__str__.\n    client.hostname = host\n    client.username = username\n    if username is not None:\n        kwargs['username'] = username\n    if password is not None:\n        kwargs['password'] = password\n    if username is not None and password is not None:\n        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        kwargs.setdefault('look_for_keys', False)\n    client.connect(host, **kwargs)\n    return client"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef failUnlessWarns(self, category, message, filename, f,\n                   *args, **kwargs):\n    \"\"\"\n    Fail if the given function doesn't generate the specified warning when\n    called. It calls the function, checks the warning, and forwards the\n    result of the function if everything is fine.\n\n    @param category: the category of the warning to check.\n    @param message: the output message of the warning to check.\n    @param filename: the filename where the warning should come from.\n    @param f: the function which is supposed to generate the warning.\n    @type f: any callable.\n    @param args: the arguments to C{f}.\n    @param kwargs: the keywords arguments to C{f}.\n\n    @return: the result of the original function C{f}.\n    \"\"\"\n    warningsShown = []\n    def warnExplicit(*args):\n        warningsShown.append(args)\n\n    origExplicit = warnings.warn_explicit\n    try:\n        warnings.warn_explicit = warnExplicit\n        result = f(*args, **kwargs)\n    finally:\n        warnings.warn_explicit = origExplicit\n\n    if not warningsShown:\n        self.fail(\"No warnings emitted\")\n    first = warningsShown[0]\n    for other in warningsShown[1:]:\n        if other[:2] != first[:2]:\n            self.fail(\"Can't handle different warnings\")\n    gotMessage, gotCategory, gotFilename, lineno = first[:4]\n    self.assertEqual(gotMessage, message)\n    self.assertIdentical(gotCategory, category)\n\n    # Use starts with because of .pyc/.pyo issues.\n    self.failUnless(\n        filename.startswith(gotFilename),\n        'Warning in %r, expected %r' % (gotFilename, filename))\n\n    # It would be nice to be able to check the line number as well, but\n    # different configurations actually end up reporting different line\n    # numbers (generally the variation is only 1 line, but that's enough\n    # to fail the test erroneously...).\n    # self.assertEqual(lineno, xxx)\n\n    return result", "response": "Fail if the given function doesn t generate the specified warning."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _setup_default_handler(progname, fmt=None, datefmt=None, **_):\n    handler = logging.StreamHandler()\n\n    if not fmt:\n        # ex: 2017-08-26T14:47:44.968+00:00 <progname> (<PID>) INFO: <msg>\n        fmt_prefix = '%(asctime)s.%(msecs)03dZ '\n        fmt_suffix = ' (%(process)d) %(levelname)s: ' + '%(message)s'\n        fmt = fmt_prefix + progname + fmt_suffix\n    if not datefmt:\n        datefmt = '%Y-%m-%dT%H:%M:%S'\n\n    formatter = logging.Formatter(fmt=fmt, datefmt=datefmt)\n    handler.setFormatter(formatter)\n    return handler", "response": "Setup a default logging handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_logging(progname, level, handlers, **kwargs):\n    for h in handlers:\n        if h == 'stream':\n            handler = _setup_default_handler(progname, **kwargs)\n        else:\n            handler_module_path = 'ulogger.{}'.format(h)\n            try:\n                handler_module = import_module(\n                    handler_module_path, package='ulogger')\n            except ImportError:\n                msg = 'Unsupported log handler: \"{}\".'.format(h)\n                raise exceptions.ULoggerError(msg)\n\n            try:\n                get_handler = getattr(handler_module, 'get_handler')\n            except AttributeError:\n                msg = '\"get_handler\" function not implemented for \"{}\".'\n                raise exceptions.ULoggerError(msg.format(h))\n\n            handler = get_handler(progname, **kwargs)\n        logging.getLogger('').addHandler(handler)\n\n    level = logging.getLevelName(level)\n    logging.getLogger('').setLevel(level)", "response": "Setup logging to stdout syslog or stackdriver."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nkeying memory address(int) or register name(str) size: size of object in bytes", "response": "def sim(self, key, size=None):\n        '''\n        key: memory address(int) or register name(str)\n        size: size of object in bytes\n        '''\n        project = load_project()\n        if key in project.arch.registers:\n            if size is None:\n                size = project.arch.registers[key][1]\n            size *= 8\n            s = claripy.BVS(\"angrdbg_reg_\" + str(key), size)\n            setattr(self.state.regs, key, s)\n            self.symbolics[key] = (s, size)\n        elif isinstance(key, int) or isinstance(key, long):\n            if size is None:\n                size = project.arch.bits\n            else:\n                size *= 8\n            s = claripy.BVS(\"angrdbg_mem_\" + hex(key), size)\n            self.state.memory.store(key, s)\n            self.symbolics[key] = (s, size)\n        elif isinstance(key, claripy.ast.bv.BV):\n            key = self.state.solver.eval(key, cast_to=int)\n            self.sim(key, size)\n        else:\n            raise ValueError(\n                \"key must be a register name or a memory address, not %s\" % str(\n                    type(key)))\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_distributed_artifact(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.add_distributed_artifact_with_http_info(id, **kwargs)\n        else:\n            (data) = self.add_distributed_artifact_with_http_info(id, **kwargs)\n            return data", "response": "Adds an artifact to the list of distributed artifacts for this product milestone."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cancel_milestone_close(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.cancel_milestone_close_with_http_info(id, **kwargs)\n        else:\n            (data) = self.cancel_milestone_close_with_http_info(id, **kwargs)\n            return data", "response": "Cancel Product Milestone Release process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclose a Product Milestone", "response": "def close_milestone(self, id, **kwargs):\n        \"\"\"\n        Close/Release a Product Milestone\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.close_milestone(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Product Milestone id (required)\n        :param ProductMilestoneRest body:\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.close_milestone_with_http_info(id, **kwargs)\n        else:\n            (data) = self.close_milestone_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the artifacts distributed in this milestone.", "response": "def get_distributed_artifacts(self, id, **kwargs):\n        \"\"\"\n        Get the artifacts distributed in this milestone\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_distributed_artifacts(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Product milestone id (required)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :param str sort: Sorting RSQL\n        :param str q: RSQL Query\n        :return: ArtifactPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_distributed_artifacts_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_distributed_artifacts_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the set of build records that produced artifacts distributed in a Product Milestone.", "response": "def get_distributed_builds(self, id, **kwargs):\n        \"\"\"\n        Gets the set of builds which produced artifacts distributed/shipped in a Product Milestone\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get_distributed_builds(id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int id: Product Milestone id (required)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :param str sort: Sorting RSQL\n        :param str q: RSQL Query\n        :return: BuildRecordPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_distributed_builds_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_distributed_builds_with_http_info(id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_performed_builds(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_performed_builds_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_performed_builds_with_http_info(id, **kwargs)\n            return data", "response": "Get the set of builds performed during a Product Milestone cycle."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_distributed_artifact(self, id, artifact_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.remove_distributed_artifact_with_http_info(id, artifact_id, **kwargs)\n        else:\n            (data) = self.remove_distributed_artifact_with_http_info(id, artifact_id, **kwargs)\n            return data", "response": "Remove an artifact from the specified product milestone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef playlists(self):\n        if self._playlists is None:\n            playlists_data = self._api.user_playlists(self.identifier)\n            playlists = []\n            for playlist_data in playlists_data:\n                playlist = _deserialize(playlist_data, PlaylistSchema)\n                playlists.append(playlist)\n            self._playlists = playlists\n        return self._playlists", "response": "Get a list of user s playlists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fav_songs(self):\n        if self._fav_songs is None:\n            songs_data = self._api.user_favorite_songs(self.identifier)\n            self._fav_songs = []\n            if not songs_data:\n                return\n            for song_data in songs_data:\n                song = _deserialize(song_data, NestedSongSchema)\n                self._fav_songs.append(song)\n        return self._fav_songs", "response": "Return a list of all user s songs that are favorite."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses an RFC 3339 - formatted timestamp and return a .", "response": "def parse(timestamp, utc=False, produce_naive=False):\n    '''\n    Parse an :RFC:`3339`-formatted timestamp and return a\n    `datetime.datetime`.\n\n    If the timestamp is presented in UTC, then the `tzinfo` parameter of the\n    returned `datetime` will be set to `pytz.utc`.\n\n    >>> parse('2009-01-01T10:01:02Z')\n    datetime.datetime(2009, 1, 1, 10, 1, 2, tzinfo=<UTC>)\n\n    Otherwise, a `tzinfo` instance is created with the appropriate offset, and\n    the `tzinfo` parameter of the returned `datetime` is set to that value.\n\n    >>> parse('2009-01-01T14:01:02-04:00')\n    datetime.datetime(2009, 1, 1, 14, 1, 2, tzinfo=<UTC-04:00>)\n\n    However, if `parse()`  is called with `utc=True`, then the returned\n    `datetime` will be normalized to UTC (and its tzinfo parameter set to\n    `pytz.utc`), regardless of the input timezone.\n\n    >>> parse('2009-01-01T06:01:02-04:00', utc=True)\n    datetime.datetime(2009, 1, 1, 10, 1, 2, tzinfo=<UTC>)\n\n    The input is strictly required to conform to :RFC:`3339`, and appropriate\n    exceptions are thrown for invalid input.\n\n    >>> parse('2009-01-01T06:01:02')\n    Traceback (most recent call last):\n    ...\n    ValueError: timestamp does not conform to RFC 3339\n\n    >>> parse('2009-01-01T25:01:02Z')\n    Traceback (most recent call last):\n    ...\n    ValueError: hour must be in 0..23\n\n    '''\n\n    parse_re = re.compile(r'''^(?:(?:(?P<date_fullyear>[0-9]{4})\\-(?P<date_month>[0-9]{2})\\-(?P<date_mday>[0-9]{2}))T(?:(?:(?P<time_hour>[0-9]{2})\\:(?P<time_minute>[0-9]{2})\\:(?P<time_second>[0-9]{2})(?P<time_secfrac>(?:\\.[0-9]{1,}))?)(?P<time_offset>(?:Z|(?P<time_numoffset>(?P<time_houroffset>(?:\\+|\\-)[0-9]{2})\\:(?P<time_minuteoffset>[0-9]{2}))))))$''',\n                          re.I | re.X)\n\n    match = parse_re.match(timestamp)\n\n    if match is not None:\n        if match.group('time_offset') in [\"Z\", \"z\", \"+00:00\", \"-00:00\"]:\n            if produce_naive is True:\n                tzinfo = None\n            else:\n                tzinfo = pytz.utc\n        else:\n            if produce_naive is True:\n                raise ValueError(\"cannot produce a naive datetime from \" +\n                                 \"a local timestamp\")\n            else:\n                tzinfo = FixedOffset(int(match.group('time_houroffset')),\n                                     int(match.group('time_minuteoffset')))\n\n        secfrac = match.group('time_secfrac')\n        if secfrac is None:\n            microsecond = 0\n        else:\n            microsecond = int(round(float(secfrac) * 1000000))\n\n        dt_out = datetime(year=int(match.group('date_fullyear')),\n                          month=int(match.group('date_month')),\n                          day=int(match.group('date_mday')),\n                          hour=int(match.group('time_hour')),\n                          minute=int(match.group('time_minute')),\n                          second=int(match.group('time_second')),\n                          microsecond=microsecond,\n                          tzinfo=tzinfo)\n\n        if utc:\n            dt_out = dt_out.astimezone(pytz.utc)\n\n        return dt_out\n    else:\n        raise ValueError(\"timestamp does not conform to RFC 3339\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a song to the list of song models.", "response": "def add_song(fpath, g_songs, g_artists, g_albums):\n    \"\"\"\n    parse music file metadata with Easymp3 and return a song\n    model.\n    \"\"\"\n    try:\n        if fpath.endswith('mp3') or fpath.endswith('ogg') or fpath.endswith('wma'):\n            metadata = EasyMP3(fpath)\n        elif fpath.endswith('m4a'):\n            metadata = EasyMP4(fpath)\n    except MutagenError as e:\n        logger.exception('Mutagen parse metadata failed, ignore.')\n        return None\n\n    metadata_dict = dict(metadata)\n    for key in metadata.keys():\n        metadata_dict[key] = metadata_dict[key][0]\n    if 'title' not in metadata_dict:\n        title = fpath.rsplit('/')[-1].split('.')[0]\n        metadata_dict['title'] = title\n    metadata_dict.update(dict(\n        url=fpath,\n        duration=metadata.info.length * 1000  # milesecond\n    ))\n    schema = EasyMP3MetadataSongSchema(strict=True)\n    try:\n        data, _ = schema.load(metadata_dict)\n    except ValidationError:\n        logger.exeception('\u89e3\u6790\u97f3\u4e50\u6587\u4ef6({}) \u5143\u6570\u636e\u5931\u8d25'.format(fpath))\n        return\n\n    # NOTE: use {title}-{artists_name}-{album_name} as song identifier\n    title = data['title']\n    album_name = data['album_name']\n    artist_name_list = [\n        name.strip()\n        for name in re.split(r'[,&]', data['artists_name'])]\n    artists_name = ','.join(artist_name_list)\n    duration = data['duration']\n    album_artist_name = data['album_artist_name']\n\n    # \u751f\u6210 song model\n    # \u7528\u6765\u751f\u6210 id \u7684\u5b57\u7b26\u4e32\u5e94\u8be5\u5c3d\u91cf\u51cf\u5c11\u65e0\u7528\u4fe1\u606f\uff0c\u8fd9\u6837\u6216\u8bb8\u80fd\u51cf\u5c11 id \u51b2\u7a81\u6982\u7387\n    song_id_str = ''.join([title, artists_name, album_name, str(int(duration))])\n    song_id = gen_id(song_id_str)\n    if song_id not in g_songs:\n        # \u5269\u4e0b album, lyric \u4e09\u4e2a\u5b57\u6bb5\u6ca1\u6709\u521d\u59cb\u5316\n        song = LSongModel(identifier=song_id,\n                          artists=[],\n                          title=title,\n                          url=fpath,\n                          duration=duration,\n                          comments=[],\n                          # \u4e0b\u9762\u8fd9\u4e9b\u5b57\u6bb5\u4e0d\u5411\u5916\u66b4\u9732\n                          genre=data['genre'],\n                          cover=data['cover'],\n                          date=data['date'],\n                          desc=data['desc'],\n                          disc=data['disc'],\n                          track=data['track'])\n        g_songs[song_id] = song\n    else:\n        song = g_songs[song_id]\n        logger.debug('Duplicate song: %s %s', song.url, fpath)\n        return\n\n    # \u751f\u6210 album artist model\n    album_artist_id = gen_id(album_artist_name)\n    if album_artist_id not in g_artists:\n        album_artist = create_artist(album_artist_id, album_artist_name)\n        g_artists[album_artist_id] = album_artist\n    else:\n        album_artist = g_artists[album_artist_id]\n\n    # \u751f\u6210 album model\n    album_id_str = album_name + album_artist_name\n    album_id = gen_id(album_id_str)\n    if album_id not in g_albums:\n        album = create_album(album_id, album_name)\n        g_albums[album_id] = album\n    else:\n        album = g_albums[album_id]\n\n    # \u5904\u7406\u4e13\u8f91\u7684\u6b4c\u624b\u4fe1\u606f\u548c\u6b4c\u66f2\u4fe1\u606f\uff0c\u4e13\u8f91\u6b4c\u624b\u7684\u4e13\u8f91\u5217\u8868\u4fe1\u606f\n    if album not in album_artist.albums:\n        album_artist.albums.append(album)\n    if album_artist not in album.artists:\n        album.artists.append(album_artist)\n    if song not in album.songs:\n        album.songs.append(song)\n\n    # \u5904\u7406\u6b4c\u66f2\u7684\u6b4c\u624b\u548c\u4e13\u8f91\u4fe1\u606f\uff0c\u4ee5\u53ca\u6b4c\u624b\u7684\u6b4c\u66f2\u5217\u8868\n    song.album = album\n    for artist_name in artist_name_list:\n        artist_id = gen_id(artist_name)\n        if artist_id in g_artists:\n            artist = g_artists[artist_id]\n        else:\n            artist = create_artist(identifier=artist_id, name=artist_name)\n            g_artists[artist_id] = artist\n        if artist not in song.artists:\n            song.artists.append(artist)\n        if song not in artist.songs:\n            artist.songs.append(song)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscan media files in all paths", "response": "def scan(self, paths=None, depth=2):\n        \"\"\"scan media files in all paths\n        \"\"\"\n        song_exts = ['mp3', 'ogg', 'wma', 'm4a']\n        exts = song_exts\n        paths = paths or [Library.DEFAULT_MUSIC_FOLDER]\n        depth = depth if depth <= 3 else 3\n        media_files = []\n        for directory in paths:\n            logger.debug('\u6b63\u5728\u626b\u63cf\u76ee\u5f55(%s)...', directory)\n            media_files.extend(scan_directory(directory, exts, depth))\n        logger.info('\u5171\u626b\u63cf\u5230 %d \u4e2a\u97f3\u4e50\u6587\u4ef6\uff0c\u51c6\u5907\u5c06\u5176\u5f55\u5165\u672c\u5730\u97f3\u4e50\u5e93', len(media_files))\n\n        for fpath in media_files:\n            add_song(fpath, self._songs, self._artists, self._albums)\n        logger.info('\u5f55\u5165\u672c\u5730\u97f3\u4e50\u5e93\u5b8c\u6bd5')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls each nested handler until one of them returns nonzero result.", "response": "def cases(self, env, data):\n        '''Calls each nested handler until one of them returns nonzero result.\n\n        If any handler returns `None`, it is interpreted as \n        \"request does not match, the handler has nothing to do with it and \n        `web.cases` should try to call the next handler\".'''\n        for handler in self.handlers:\n            env._push()\n            data._push()\n            try:\n                result = handler(env, data)\n            finally:\n                env._pop()\n                data._pop()\n            if result is not None:\n                return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a map between Windows and Olson timezone names.", "response": "def create_win32tz_map(windows_zones_xml):\n  \"\"\"Creates a map between Windows and Olson timezone names.\n\n  Args:\n    windows_zones_xml: The CLDR XML mapping.\n\n  Yields:\n    (win32_name, olson_name, comment)\n  \"\"\"\n  coming_comment = None\n  win32_name = None\n  territory = None\n  parser = genshi.input.XMLParser(StringIO(windows_zones_xml))\n  map_zones = {}\n  zone_comments = {}\n\n  for kind, data, _ in parser:\n    if kind == genshi.core.START and str(data[0]) == \"mapZone\":\n      attrs = data[1]\n      win32_name, territory, olson_name = (\n          attrs.get(\"other\"), attrs.get(\"territory\"), attrs.get(\"type\").split(\" \")[0])\n\n      map_zones[(win32_name, territory)] = olson_name\n    elif kind == genshi.core.END and str(data) == \"mapZone\" and win32_name:\n      if coming_comment:\n        zone_comments[(win32_name, territory)] = coming_comment\n        coming_comment = None\n      win32_name = None\n    elif kind == genshi.core.COMMENT:\n      coming_comment = data.strip()\n    elif kind in (genshi.core.START, genshi.core.END, genshi.core.COMMENT):\n      coming_comment = None\n\n  for win32_name, territory in sorted(map_zones):\n    yield (win32_name, territory, map_zones[(win32_name, territory)],\n           zone_comments.get((win32_name, territory), None))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_stored_win32tz_map():\n  windows_zones_xml = download_cldr_win32tz_map_xml()\n  source_hash = hashlib.md5(windows_zones_xml).hexdigest()\n\n  if hasattr(windows_zones_xml, \"decode\"):\n    windows_zones_xml = windows_zones_xml.decode(\"utf-8\")\n\n  map_zones = create_win32tz_map(windows_zones_xml)\n  map_dir = os.path.dirname(os.path.abspath(__file__))\n  map_filename = os.path.join(map_dir, \"win32tz_map.py\")\n  if os.path.exists(map_filename):\n    reload(win32tz_map)\n    current_hash = getattr(win32tz_map, \"source_hash\", None)\n    if current_hash == source_hash:\n      return False\n\n  map_file = open(map_filename, \"w\")\n\n  comment = \"Map between Windows and Olson timezones taken from %s\" % (\n      _CLDR_WINZONES_URL,)\n  comment2 = \"Generated automatically from datetime_tz.py\"\n  map_file.write(\"'''%s\\n\" % comment)\n  map_file.write(\"%s'''\\n\" % comment2)\n\n  map_file.write(\"source_hash = '%s' # md5 sum of xml source data\\n\" % (\n      source_hash))\n\n  map_file.write(\"win32timezones = {\\n\")\n  for win32_name, territory, olson_name, comment in map_zones:\n    if territory == '001':\n      map_file.write(\"  %r: %r, # %s\\n\" % (\n          str(win32_name), str(olson_name), comment or \"\"))\n    else:\n      map_file.write(\"  %r: %r, # %s\\n\" % (\n          (str(win32_name), str(territory)), str(olson_name), comment or \"\"))\n  map_file.write(\"}\\n\")\n\n  map_file.close()\n  return True", "response": "Downloads the cldr win32 timezone map and stores it in win32tz_map. py."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a memory object from memory.", "response": "def load_mo(self, state, page_idx):\n        \"\"\"\n        Loads a memory object from memory.\n        :param page_idx: the index into the page\n        :returns: a tuple of the object\n        \"\"\"\n        mo = self._storage[page_idx - self._page_addr]\n        #print filter(lambda x: x != None, self._storage)\n        if mo is None and hasattr(self, \"from_dbg\"):\n            byte_val = get_debugger().get_byte(page_idx)\n            mo = SimMemoryObject(claripy.BVV(byte_val, 8), page_idx)\n            self._storage[page_idx - self._page_addr] = mo\n        return mo"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the slice of the memory objects from the memory.", "response": "def load_slice(self, state, start, end):\n        \"\"\"\n        Return the memory objects overlapping with the provided slice.\n        :param start: the start address\n        :param end: the end address (non-inclusive)\n        :returns: tuples of (starting_addr, memory_object)\n        \"\"\"\n        items = []\n        if start > self._page_addr + self._page_size or end < self._page_addr:\n            l.warning(\"Calling load_slice on the wrong page.\")\n            return items\n\n        for addr in range(max(start, self._page_addr), min(\n                end, self._page_addr + self._page_size)):\n            i = addr - self._page_addr\n            mo = self._storage[i]\n            if mo is None and hasattr(self, \"from_dbg\"):\n                byte_val = get_debugger().get_byte(addr)\n                mo = SimMemoryObject(claripy.BVV(byte_val, 8), addr)\n                self._storage[i] = mo\n            if mo is not None and (not items or items[-1][1] is not mo):\n                items.append((addr, mo))\n        #print filter(lambda x: x != None, self._storage)\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading memory objects from paged memory.", "response": "def load_objects(self, addr, num_bytes, ret_on_segv=False):\n        \"\"\"\n        Load memory objects from paged memory.\n\n        :param addr: Address to start loading.\n        :param num_bytes: Number of bytes to load.\n        :param bool ret_on_segv: True if you want load_bytes to return directly when a SIGSEV is triggered, otherwise\n                                 a SimSegfaultError will be raised.\n        :return: list of tuples of (addr, memory_object)\n        :rtype: tuple\n        \"\"\"\n\n        result = []\n        end = addr + num_bytes\n        for page_addr in self._containing_pages(addr, end):\n            try:\n                #print \"Getting page %x\" % (page_addr // self._page_size)\n                page = self._get_page(page_addr // self._page_size)\n                #print \"... got it\"\n            except KeyError:\n                #print \"... missing\"\n                #print \"... SEGV\"\n                # missing page\n                if self.allow_segv:\n                    if ret_on_segv:\n                        break\n                    raise SimSegfaultError(addr, 'read-miss')\n                else:\n                    continue\n\n            if self.allow_segv and not page.concrete_permissions & DbgPage.PROT_READ:\n                #print \"... SEGV\"\n                if ret_on_segv:\n                    break\n                raise SimSegfaultError(addr, 'non-readable')\n            result.extend(page.load_slice(self.state, addr, end))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef memory_objects_for_name(self, n):\n        return set([self[i] for i in self.addrs_for_name(n)])", "response": "Returns a set of SimMemoryObjects that contain expressions that contain a variable with the name of\n        n."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a set of SimMemoryObjects that contain expressions that contain a variable with the hash h.", "response": "def memory_objects_for_hash(self, n):\n        \"\"\"\n        Returns a set of :class:`SimMemoryObjects` that contain expressions that contain a variable with the hash\n        `h`.\n        \"\"\"\n        return set([self[i] for i in self.addrs_for_hash(n)])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the permissions for a page at the given address.", "response": "def permissions(self, addr, permissions=None):\n        \"\"\"\n        Returns the permissions for a page at address `addr`.\n\n        If optional argument permissions is given, set page permissions to that prior to returning permissions.\n        \"\"\"\n\n        if self.state.solver.symbolic(addr):\n            raise SimMemoryError(\n                \"page permissions cannot currently be looked up for symbolic addresses\")\n\n        if isinstance(addr, claripy.ast.bv.BV):\n            addr = self.state.solver.eval(addr)\n\n        page_num = addr // self._page_size\n\n        try:\n            page = self._get_page(page_num)\n        except KeyError:\n            raise SimMemoryError(\"page does not exist at given address\")\n\n        # Set permissions for the page\n        if permissions is not None:\n            if isinstance(permissions, (int, long)):\n                permissions = claripy.BVV(permissions, 3)\n\n            if not isinstance(permissions, claripy.ast.bv.BV):\n                raise SimMemoryError(\n                    \"Unknown permissions argument type of {0}.\".format(\n                        type(permissions)))\n\n            page.permissions = permissions\n\n        return page.permissions"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, *args, **kwargs):\n\n        if self.start and self.start.state == 'done' and kwargs.get('log_action') != 'done':\n            raise ProgressLoggingError(\"Can't add -- process section is done\")\n\n        self.augment_args(args, kwargs)\n\n        kwargs['log_action'] = kwargs.get('log_action', 'add')\n\n        rec = Process(**kwargs)\n\n        self._session.add(rec)\n\n        self.rec = rec\n\n        if self._logger:\n            self._logger.info(self.rec.log_str)\n\n        self._session.commit()\n        self._ai_rec_id = None\n\n        return self.rec.id", "response": "Add a new record to the section"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the last section record", "response": "def update(self, *args, **kwargs):\n        \"\"\"Update the last section record\"\"\"\n\n        self.augment_args(args, kwargs)\n\n        kwargs['log_action'] = kwargs.get('log_action', 'update')\n\n        if not self.rec:\n            return self.add(**kwargs)\n        else:\n            for k, v in kwargs.items():\n\n                # Don't update object; use whatever was set in the original record\n                if k not in ('source', 's_vid', 'table', 't_vid', 'partition', 'p_vid'):\n                    setattr(self.rec, k, v)\n\n            self._session.merge(self.rec)\n            if self._logger:\n                self._logger.info(self.rec.log_str)\n            self._session.commit()\n\n            self._ai_rec_id = None\n            return self.rec.id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_update(self, *args, **kwargs):\n\n        if not self._ai_rec_id:\n            self._ai_rec_id = self.add(*args, **kwargs)\n        else:\n            au_save = self._ai_rec_id\n            self.update(*args, **kwargs)\n            self._ai_rec_id = au_save\n\n        return self._ai_rec_id", "response": "A records is added then on subsequent calls updated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the record set to done", "response": "def update_done(self, *args, **kwargs):\n        \"\"\"Clear out the previous update\"\"\"\n        kwargs['state'] = 'done'\n        self.update(*args, **kwargs)\n        self.rec = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef done(self, *args, **kwargs):\n        kwargs['state'] = 'done'\n        pr_id = self.add(*args, log_action='done', **kwargs)\n\n        self._session.query(Process).filter(Process.group == self._group).update({Process.state: 'done'})\n        self.start.state = 'done'\n        self._session.commit()\n\n        return pr_id", "response": "Mark the whole ProgressSection as done"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self, phase, stage, **kwargs):\n        return ProgressSection(self, self._session, phase, stage, self._logger, **kwargs)", "response": "Start a new routine or stage or phase"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all start records for this dataset grouped by the start record", "response": "def records(self):\n        \"\"\"Return all start records for this the dataset, grouped by the start record\"\"\"\n\n        return (self._session.query(Process)\n                .filter(Process.d_vid == self._d_vid)).all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all start records for this dataset grouped by the start record", "response": "def starts(self):\n        \"\"\"Return all start records for this the dataset, grouped by the start record\"\"\"\n\n        return (self._session.query(Process)\n                .filter(Process.d_vid == self._d_vid)\n                .filter(Process.log_action == 'start')\n                ).all()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query(self):\n\n        return self._session.query(Process).filter(Process.d_vid == self._d_vid)", "response": "Return all start records for this dataset grouped by the start record"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exceptions(self):\n\n        return (self._session.query(Process)\n                .filter(Process.d_vid == self._d_vid)\n                .filter(Process.exception_class != None)\n                .order_by(Process.modified)).all()", "response": "Return all start records for this dataset grouped by the start record"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean(self):\n\n        # Deleting seems to be really weird and unrelable.\n        self._session \\\n            .query(Process) \\\n            .filter(Process.d_vid == self._d_vid) \\\n            .delete(synchronize_session='fetch')\n\n        for r in self.records:\n            self._session.delete(r)\n\n        self._session.commit()", "response": "Delete all of the records in the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build(self):\n        from ambry.orm.config import BuildConfigGroupAccessor\n\n        # It is a lightweight object, so no need to cache\n        return BuildConfigGroupAccessor(self.dataset, 'buildstate', self._session)", "response": "Access build configuration values as attributes. See self. process\n            for a usage example"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the log record.", "response": "def configure_logging(add_handler, log=log):\n    \"\"\"\n    Configure log records.  If adding a handler, make the formatter print all\n    passed in key:value data.\n        ie log.extra('msg', extra=dict(a=1))\n        generates  'msg  a=1'\n\n    `add_handler` (True, False, None, or Handler instance)\n        if True, add a logging.StreamHandler() instance\n        if False, do not add any handlers.\n        if given a handler instance, add that the the logger\n    \"\"\"\n    _ignore_log_keys = set(logging.makeLogRecord({}).__dict__)\n\n    def _json_format(record):\n        extras = ' '.join(\n            \"%s=%s\" % (k, record.__dict__[k])\n            for k in set(record.__dict__).difference(_ignore_log_keys))\n        if extras:\n            record.msg = \"%s    %s\" % (record.msg, extras)\n        return record\n\n    class ColoredJsonFormatter(ColoredFormatter):\n        def format(self, record):\n            record = _json_format(record)\n            return super(ColoredJsonFormatter, self).format(record)\n    if isinstance(add_handler, logging.Handler):\n        log.addHandler(add_handler)\n    elif add_handler is True:\n        if not any(isinstance(h, logging.StreamHandler) for h in log.handlers):\n            _h = logging.StreamHandler()\n            _h.setFormatter(ColoredJsonFormatter(\n                \"%(log_color)s%(levelname)-8s %(message)s %(reset)s %(cyan)s\",\n                reset=True\n            ))\n            log.addHandler(_h)\n    elif not log.handlers:\n        log.addHandler(logging.NullHandler())\n    log.setLevel(logging.DEBUG)\n    log.propagate = False\n    return log"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the system_image_type of this BuildEnvironmentRest.", "response": "def system_image_type(self, system_image_type):\n        \"\"\"\n        Sets the system_image_type of this BuildEnvironmentRest.\n\n        :param system_image_type: The system_image_type of this BuildEnvironmentRest.\n        :type: str\n        \"\"\"\n        allowed_values = [\"DOCKER_IMAGE\", \"VIRTUAL_MACHINE_RAW\", \"VIRTUAL_MACHINE_QCOW2\", \"LOCAL_WORKSPACE\"]\n        if system_image_type not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `system_image_type` ({0}), must be one of {1}\"\n                .format(system_image_type, allowed_values)\n            )\n\n        self._system_image_type = system_image_type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple with all cms app namespaces", "response": "def get_public_cms_app_namespaces():\n    \"\"\"\n    :return: a tuple() with all cms app namespaces\n    \"\"\"\n    qs = Page.objects.public()\n    qs = qs.exclude(application_namespace=None)\n    qs = qs.order_by('application_namespace')\n\n    try:\n        application_namespaces = list(\n            qs.distinct('application_namespace').values_list(\n                'application_namespace', flat=True))\n    except NotImplementedError:\n        # If SQLite used:\n        #   DISTINCT ON fields is not supported by this database backend\n        application_namespaces = list(\n            set(qs.values_list('application_namespace', flat=True)))\n\n    application_namespaces.sort()\n\n    return tuple(application_namespaces)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a tuple with all public urls in the given language_code.", "response": "def get_public_cms_page_urls(*, language_code):\n    \"\"\"\n    :param language_code: e.g.: \"en\" or \"de\"\n    :return: Tuple with all public urls in the given language\n    \"\"\"\n    pages = Page.objects.public()\n    urls = [page.get_absolute_url(language=language_code) for page in pages]\n    urls.sort()\n    return tuple(urls)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dict of all of the docs with the source associated with the doc as a key", "response": "def group_by_source(self):\n        \"\"\"Return a dict of all of the docs, with the source associated\n        with the doc as a key\"\"\"\n        from collections import defaultdict\n        docs = defaultdict(list)\n\n        for k, v in self.items():\n            if 'source' in v:\n                docs[v.source].append(dict(v.items()))\n\n        return docs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preauthChild(self, path):\n        newpath = abspath(joinpath(self.path, normpath(path)))\n        if not newpath.startswith(self.path):\n            raise InsecurePath(\"%s is not a child of %s\" % (newpath, self.path))\n        return self.clonePath(newpath)", "response": "Return a new instance of the class with the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef childSearchPreauth(self, *paths):\n        p = self.path\n        for child in paths:\n            jp = joinpath(p, child)\n            if exists(jp):\n                return self.clonePath(jp)", "response": "Return my first existing child with a name in paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattempts to return a path with my name given multiple possible possibleCOOKIE extensions.", "response": "def siblingExtensionSearch(self, *exts):\n        \"\"\"Attempt to return a path with my name, given multiple possible\n        extensions.\n\n        Each extension in exts will be tested and the first path which exists\n        will be returned.  If no path exists, None will be returned.  If '' is\n        in exts, then if the file referred to by this path exists, 'self' will\n        be returned.\n\n        The extension '*' has a magic meaning, which means \"any path that\n        begins with self.path+'.' is acceptable\".\n        \"\"\"\n        p = self.path\n        for ext in exts:\n            if not ext and self.exists():\n                return self\n            if ext == '*':\n                basedot = basename(p)+'.'\n                for fn in listdir(dirname(p)):\n                    if fn.startswith(basedot):\n                        return self.clonePath(joinpath(dirname(p), fn))\n            p2 = p + ext\n            if exists(p2):\n                return self.clonePath(p2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of FilePaths representing my children that match the given pattern.", "response": "def globChildren(self, pattern):\n        \"\"\"\n        Assuming I am representing a directory, return a list of\n        FilePaths representing my children that match the given\n        pattern.\n        \"\"\"\n        import glob\n        path = self.path[-1] == '/' and self.path + pattern or slash.join([self.path, pattern])\n        return map(self.clonePath, glob.glob(path))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a path naming a temporary sibling of this path in a secure fashion.", "response": "def temporarySibling(self):\n        \"\"\"\n        Create a path naming a temporary sibling of this path in a secure fashion.\n        \"\"\"\n        sib = self.parent().child(_secureEnoughString() + self.basename())\n        sib.requireCreate()\n        return sib"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a single line from C { proc / diskstats } into a two - tuple of the device name and an instance of the appropriate record type.", "response": "def parseDiskStatLine(L):\n    \"\"\"\n    Parse a single line from C{/proc/diskstats} into a two-tuple of the name of\n    the device to which it corresponds (ie 'hda') and an instance of the\n    appropriate record type (either L{partitionstat} or L{diskstat}).\n    \"\"\"\n    parts = L.split()\n    device = parts[2]\n    if len(parts) == 7:\n        factory = partitionstat\n    else:\n        factory = diskstat\n    return device, factory(*map(int, parts[3:]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a short string name of the current working applet.", "response": "def discoverCurrentWorkingDevice(procMounts='/proc/self/mounts'):\n    \"\"\"\n    Return a short string naming the device which backs the current working\n    directory, ie C{/dev/hda1}.\n    \"\"\"\n    possibilities = []\n    cwd = os.getcwd()\n    with file(procMounts, 'rb') as f:\n        for L in f:\n            parts = L.split()\n            if cwd.startswith(parts[1]):\n                possibilities.append((len(parts[1]), parts[0]))\n    possibilities.sort()\n    try:\n        return possibilities[-1][-1]\n    except IndexError:\n        return '<unknown>'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef makeBenchmarkRunner(path, args):\n    def runner():\n        return BenchmarkProcess.spawn(\n            executable=sys.executable,\n            args=['-Wignore'] + args,\n            path=path.path,\n            env=os.environ)\n    return runner", "response": "Make a function that will run two Python processes serially."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start():\n    os.write(BenchmarkProcess.BACKCHANNEL_OUT, BenchmarkProcess.START)\n    response = util.untilConcludes(os.read, BenchmarkProcess.BACKCHANNEL_IN, 1)\n    if response != BenchmarkProcess.START:\n        raise RuntimeError(\n            \"Parent process responded with %r instead of START \" % (response,))", "response": "Start recording stats.  Call this from a benchmark script when your setup\n    is done.  Call this at most once.\n\n    @raise RuntimeError: Raised if the parent process responds with anything\n    other than an acknowledgement of this message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop():\n    os.write(BenchmarkProcess.BACKCHANNEL_OUT, BenchmarkProcess.STOP)\n    response = util.untilConcludes(os.read, BenchmarkProcess.BACKCHANNEL_IN, 1)\n    if response != BenchmarkProcess.STOP:\n        raise RuntimeError(\n            \"Parent process responded with %r instead of STOP\" % (response,))", "response": "Stop recording stats.  Call this from a benchmark script when the code you\n    want benchmarked has finished.  Call this exactly the same number of times\n    you call L{start} and only after calling it.\n\n    @raise RuntimeError: Raised if the parent process responds with anything\n    other than an acknowledgement of this message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n    name = sys.argv[1]\n    path = filepath.FilePath('.stat').temporarySibling()\n    path.makedirs()\n    func = makeBenchmarkRunner(path, sys.argv[1:])\n    try:\n        bench(name, path, func)\n    finally:\n        path.remove()", "response": "This is the main function for the base benchmark script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef spawn(cls, executable, args, path, env, spawnProcess=None):\n        d = defer.Deferred()\n        proto = cls(d, filepath.FilePath(path))\n        if spawnProcess is None:\n            spawnProcess = reactor.spawnProcess\n        spawnProcess(\n            proto,\n            executable,\n            [executable] + args,\n            path=path,\n            env=env,\n            childFDs={0: 'w', 1: 'r', 2: 'r',\n                      cls.BACKCHANNEL_OUT: 'r',\n                      cls.BACKCHANNEL_IN: 'w'})\n        return d", "response": "Spawn a new process and return a Deferred that fires with a two - tuple of exit status and output."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(orcid_id):\n    resp = requests.get(ORCID_PUBLIC_BASE_URL + unicode(orcid_id),\n                        headers=BASE_HEADERS)\n    json_body = resp.json()\n    return Author(json_body)", "response": "Get an author based on an ORCID identifier."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _contextualize(contextFactory, contextReceiver):\n    value = context.get(contextFactory, _NOT_SPECIFIED)\n    if value is not _NOT_SPECIFIED:\n        return contextReceiver(value)\n    else:\n        return context.call({contextFactory: contextFactory()},\n                            _contextualize, contextFactory, contextReceiver)", "response": "A function that can be used to create a new base object for the sequence of items in the sequence that are not yet in the current execution sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(content):\n    ms_sentence_map = dict()\n    sentence_pattern = re.compile(r'\\[(\\d+(:\\d+){0,2}(\\.\\d+)?)\\]')\n    lines = content.splitlines()\n    for line in lines:\n        m = sentence_pattern.search(line, 0)\n        if m:\n            time_str = m.group(1)\n            mileseconds = 0\n            unit = 1000\n            t_seq = time_str.split(':')\n            t_seq.reverse()\n            for num in t_seq:\n                mileseconds += float(num) * unit\n                unit *= 60\n            sentence = line[m.end():]\n            ms_sentence_map[mileseconds] = sentence\n    return ms_sentence_map", "response": "Parse the content of the last line of the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_product(name, abbreviation, **kwargs):\n    data = create_product_raw(name, abbreviation, **kwargs)\n    if data:\n        return utils.format_json(data)", "response": "Create a new Product object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_product(product_id, **kwargs):\n    content = update_product_raw(product_id, **kwargs)\n    if content:\n        return utils.format_json(content)", "response": "Update a Product with new information"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a specific Product by name or ID", "response": "def get_product(id=None, name=None):\n    \"\"\"\n    Get a specific Product by name or ID\n    \"\"\"\n    content = get_product_raw(id, name)\n    if content:\n        return utils.format_json(content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting all ProductVersions for a given Product", "response": "def list_versions_for_product(id=None, name=None, page_size=200, page_index=0, sort='', q=''):\n    \"\"\"\n    List all ProductVersions for a given Product\n    \"\"\"\n    content = list_versions_for_product_raw(id, name, page_size, page_index, sort, q)\n    if content:\n        return utils.format_json_list(content)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting all Products in a Page", "response": "def list_products(page_size=200, page_index=0, sort=\"\", q=\"\"):\n    \"\"\"\n    List all Products\n    \"\"\"\n    content = list_products_raw(page_size, page_index, sort, q)\n    if content:\n        return utils.format_json_list(content)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef migrate(connection, dsn):\n    all_migrations = _get_all_migrations()\n    logger.debug('Collected migrations: {}'.format(all_migrations))\n\n    for version, modname in all_migrations:\n        if _is_missed(connection, version) and version <= SCHEMA_VERSION:\n            logger.info('Missed migration: {} migration is missed. Migrating...'.format(version))\n            module = __import__(modname, fromlist='dummy')\n\n            # run each migration under its own transaction. This allows us to apply valid migrations\n            # and break on invalid.\n            trans = connection.begin()\n            try:\n                module.Migration().migrate(connection)\n                _update_version(connection, version)\n                trans.commit()\n            except:\n                trans.rollback()\n                logger.error(\"Failed to migrate '{}'  on {} \".format(version, dsn))\n                raise", "response": "Runs all migrations and applies missed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_migration_template(name):\n    assert name, 'Name of the migration can not be empty.'\n    from . import migrations\n\n    # Find next number\n    #\n    package = migrations\n    prefix = package.__name__ + '.'\n    all_versions = []\n    for importer, modname, ispkg in pkgutil.iter_modules(package.__path__, prefix):\n        version = int(modname.split('.')[-1].split('_')[0])\n        all_versions.append(version)\n\n    next_number = max(all_versions) + 1\n\n    # Generate next migration name\n    #\n    next_migration_name = '{}_{}.py'.format(next_number, name)\n    migration_fullname = os.path.join(package.__path__[0], next_migration_name)\n\n    # Write next migration file content.\n    #\n    with open(migration_fullname, 'w') as f:\n        f.write(MIGRATION_TEMPLATE)\n    return migration_fullname", "response": "Creates migration file. Returns created file name.\n    Args:\n        name (str): name of the migration.\n\n    Returns:\n        str: name of the migration file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn database version. Args: connection (sqlalchemy connection): Raises: Assuming user_version pragma (sqlite case) and user_version table (postgresql case) exist because they created with the database creation. Returns: int: version of the database.", "response": "def get_stored_version(connection):\n    \"\"\" Returns database version.\n\n    Args:\n        connection (sqlalchemy connection):\n\n    Raises: Assuming user_version pragma (sqlite case) and user_version table (postgresql case)\n        exist because they created with the database creation.\n\n    Returns:\n        int: version of the database.\n\n    \"\"\"\n\n    if connection.engine.name == 'sqlite':\n        version = connection.execute('PRAGMA user_version').fetchone()[0]\n        if version == 0:\n            raise VersionIsNotStored\n        return version\n    elif connection.engine.name == 'postgresql':\n        try:\n            r = connection\\\n                .execute('SELECT version FROM {}.user_version;'.format(POSTGRES_SCHEMA_NAME))\\\n                .fetchone()\n            if not r:\n                raise VersionIsNotStored\n\n            version = r[0]\n\n        except ProgrammingError:\n            # This happens when the user_version table doesn't exist\n            raise VersionIsNotStored\n        return version\n    else:\n        raise DatabaseError('Do not know how to get version from {} engine.'.format(connection.engine.name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate_version(connection, dsn):\n    try:\n        version = get_stored_version(connection)\n    except VersionIsNotStored:\n        logger.debug('Version not stored in the db: assuming new database creation.')\n        version = SCHEMA_VERSION\n        _update_version(connection, version)\n    assert isinstance(version, int)\n\n    if version > 10 and version < 100:\n        raise DatabaseError('You are trying to open an old SQLite database.')\n\n    if _migration_required(connection):\n        migrate(connection, dsn)", "response": "Validates that the version of the database is correct."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if ambry models do not match to db tables. Otherwise returns False.", "response": "def _migration_required(connection):\n    \"\"\" Returns True if ambry models do not match to db tables. Otherwise returns False. \"\"\"\n    stored_version = get_stored_version(connection)\n    actual_version = SCHEMA_VERSION\n    assert isinstance(stored_version, int)\n    assert isinstance(actual_version, int)\n    assert stored_version <= actual_version, \\\n        'Db version can not be greater than models version. Update your source code.'\n    return stored_version < actual_version"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the database with the given version.", "response": "def _update_version(connection, version):\n    \"\"\" Updates version in the db to the given version.\n\n    Args:\n        connection (sqlalchemy connection): sqlalchemy session where to update version.\n        version (int): version of the migration.\n\n    \"\"\"\n    if connection.engine.name == 'sqlite':\n        connection.execute('PRAGMA user_version = {}'.format(version))\n\n    elif connection.engine.name == 'postgresql':\n\n        connection.execute(DDL('CREATE SCHEMA IF NOT EXISTS {};'.format(POSTGRES_SCHEMA_NAME)))\n        connection.execute(DDL('CREATE SCHEMA IF NOT EXISTS {};'.format(POSTGRES_PARTITION_SCHEMA_NAME)))\n\n        connection.execute('CREATE TABLE IF NOT EXISTS {}.user_version(version INTEGER NOT NULL);'\n                           .format(POSTGRES_SCHEMA_NAME))\n\n        # upsert.\n        if connection.execute('SELECT * FROM {}.user_version;'.format(POSTGRES_SCHEMA_NAME)).fetchone():\n            # update\n            connection.execute('UPDATE {}.user_version SET version = {};'\n                               .format(POSTGRES_SCHEMA_NAME, version))\n        else:\n            # insert\n            connection.execute('INSERT INTO {}.user_version (version) VALUES ({})'\n                               .format(POSTGRES_SCHEMA_NAME, version))\n    else:\n        raise DatabaseMissingError('Do not know how to migrate {} engine.'\n                                   .format(connection.engine.driver))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_all_migrations():\n    from . import migrations\n\n    package = migrations\n    prefix = package.__name__ + '.'\n    all_migrations = []\n    for importer, modname, ispkg in pkgutil.iter_modules(package.__path__, prefix):\n        version = int(modname.split('.')[-1].split('_')[0])\n        all_migrations.append((version, modname))\n\n    all_migrations = sorted(all_migrations, key=lambda x: x[0])\n    return all_migrations", "response": "Returns sorted list of all migrations."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the database from the base SQL.", "response": "def create(self):\n        \"\"\"Create the database from the base SQL.\"\"\"\n\n        if not self.exists():\n            self._create_path()\n            self.create_tables()\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_path(self):\n\n        if self.driver == 'sqlite' and 'memory' not in self.dsn and self.dsn != 'sqlite://':\n\n            dir_ = os.path.dirname(self.path)\n\n            if dir_ and not os.path.exists(dir_):\n                try:\n                    # Multiple process may try to make, so it could already\n                    # exist\n                    os.makedirs(dir_)\n                except Exception:\n                    pass\n\n                if not os.path.exists(dir_):\n                    raise Exception(\"Couldn't create directory \" + dir_)", "response": "Create the path to hold the database if one wwas specified."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exists(self):\n\n        if self.driver == 'sqlite' and not os.path.exists(self.path):\n            return False\n\n        # init engine\n        self.engine\n\n        try:\n            # Since we are using the connection, rather than the session, need to\n            # explicitly set the search path.\n\n            from sqlalchemy.engine.reflection import Inspector\n\n            inspector = Inspector.from_engine(self.engine)\n\n            if 'config' in inspector.get_table_names(schema=self._schema):\n                return True\n            else:\n                return False\n        finally:\n            self.close_connection()", "response": "Return True if the database exists or False if the database does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the SqlAlchemy engine for this database.", "response": "def engine(self):\n        \"\"\"return the SqlAlchemy engine for this database.\"\"\"\n\n        if not self._engine:\n\n            if 'postgres' in self.driver:\n\n                if 'connect_args' not in self.engine_kwargs:\n                    self.engine_kwargs['connect_args'] = {\n                        'application_name': '{}:{}'.format(self._application_prefix, os.getpid())\n                    }\n\n                # For most use, a small pool is good to prevent connection exhaustion, but these settings may\n                # be too low for the main public web application.\n\n                self._engine = create_engine(self.dsn, echo=self._echo,\n                                             pool_size=5, max_overflow=5, **self.engine_kwargs)\n\n            else:\n                self._engine = create_engine(\n                    self.dsn, echo=self._echo, **self.engine_kwargs)\n\n            #\n            # Disconnect connections that have a different PID from the one they were created in.\n            # This protects against re-use in multi-processing.\n            #\n            @event.listens_for(self._engine, 'connect')\n            def connect(dbapi_connection, connection_record):\n                connection_record.info['pid'] = os.getpid()\n\n            @event.listens_for(self._engine, 'checkout')\n            def checkout(dbapi_connection, connection_record, connection_proxy):\n\n                from sqlalchemy.exc import DisconnectionError\n                pid = os.getpid()\n                if connection_record.info['pid'] != pid:\n\n                    connection_record.connection = connection_proxy.connection = None\n                    raise DisconnectionError(\n                        \"Connection record belongs to pid %s, attempting to check out in pid %s\" %\n                        (connection_record.info['pid'], pid))\n\n            if self.driver == 'sqlite':\n                @event.listens_for(self._engine, 'connect')\n                def pragma_on_connect(dbapi_con, con_record):\n                    \"\"\"ISSUE some Sqlite pragmas when the connection is created.\"\"\"\n\n                    # dbapi_con.execute('PRAGMA foreign_keys = ON;')\n                    # Not clear that there is a performance improvement.\n\n                    # dbapi_con.execute('PRAGMA journal_mode = WAL')\n                    dbapi_con.execute('PRAGMA synchronous = OFF')\n                    dbapi_con.execute('PRAGMA temp_store = MEMORY')\n                    dbapi_con.execute('PRAGMA cache_size = 500000')\n                    if self._foreign_keys:\n                        dbapi_con.execute('PRAGMA foreign_keys=ON')\n\n            with self._engine.connect() as conn:\n                _validate_version(conn, self.dsn)\n\n        return self._engine"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connection(self):\n        if not self._connection:\n            logger.debug('Opening connection to: {}'.format(self.dsn))\n            self._connection = self.engine.connect()\n            logger.debug('Opened connection to: {}'.format(self.dsn))\n\n        # logger.debug(\"Opening connection to: {}\".format(self.dsn))\n        return self._connection", "response": "Return an SqlAlchemy connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef session(self):\n        from sqlalchemy.orm import sessionmaker\n        from sqlalchemy.event import listen\n\n        if not self.Session:\n            self.Session = sessionmaker(bind=self.engine)\n\n        if not self._session:\n            self._session = self.Session()\n            # set the search path\n\n            if self._schema:\n                def after_begin(session, transaction, connection):\n                    # import traceback\n                    # print traceback.print_stack()\n                    session.execute('SET search_path TO {}'.format(self._schema))\n\n                listen(self._session, 'after_begin', after_begin)\n\n        return self._session", "response": "Return a SqlAlchemy session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an SqlAlchemy MetaData object bound to the engine.", "response": "def metadata(self):\n        \"\"\"Return an SqlAlchemy MetaData object, bound to the engine.\"\"\"\n\n        from sqlalchemy import MetaData\n\n        metadata = MetaData(bind=self.engine, schema=self._schema)\n\n        metadata.reflect(self.engine)\n\n        return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_config_root(self):\n\n        try:\n            self.session.query(Dataset).filter_by(id=ROOT_CONFIG_NAME).one()\n            self.close_session()\n        except NoResultFound:\n            o = Dataset(\n                id=ROOT_CONFIG_NAME,\n                vid=ROOT_CONFIG_NAME_V,\n                name=ROOT_CONFIG_NAME,\n                vname=ROOT_CONFIG_NAME_V,\n                fqname='datasetroot-0.0.0~' + ROOT_CONFIG_NAME_V,\n                cache_key=ROOT_CONFIG_NAME,\n                version='0.0.0',\n                source=ROOT_CONFIG_NAME,\n                dataset=ROOT_CONFIG_NAME,\n                revision=1,\n            )\n            self.session.add(o)\n            self.commit()", "response": "Adds the root dataset which holds configuration values for the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new dataset with the given attributes.", "response": "def new_dataset(self, *args, **kwargs):\n        \"\"\" Creates a new dataset\n\n        :param args: Positional args passed to the Dataset constructor.\n        :param kwargs:  Keyword args passed to the Dataset constructor.\n        :return: :class:`ambry.orm.Dataset`\n        :raises: :class:`ambry.orm.ConflictError` if the a Dataset records already exists with the given vid\n        \"\"\"\n\n        ds = Dataset(*args, **kwargs)\n\n        try:\n            self.session.add(ds)\n            self.session.commit()\n            ds._database = self\n            return ds\n        except IntegrityError as e:\n            self.session.rollback()\n            raise ConflictError(\n                \"Can't create dataset '{}'; one probably already exists: {} \".format(str(ds), e))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the root dataset which hold configuration values for the library", "response": "def root_dataset(self):\n        \"\"\"Return the root dataset, which hold configuration values for the library\"\"\"\n        ds = self.dataset(ROOT_CONFIG_NAME_V)\n        ds._database = self\n        return ds"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef package_dataset(self):\n\n        return self.session.query(Dataset).filter(Dataset.vid != ROOT_CONFIG_NAME_V).one()", "response": "For sqlite bundle packages return the first dataset that is not the root config name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dataset given a vid or id.", "response": "def dataset(self, ref, load_all=False, exception=True):\n        \"\"\"Return a dataset, given a vid or id\n\n        :param ref: Vid or id  for a dataset. If an id is provided, will it will return the one with the\n        largest revision number\n        :param load_all: Use a query that eagerly loads everything.\n        :return: :class:`ambry.orm.Dataset`\n\n        \"\"\"\n\n        ref = str(ref)\n\n        try:\n            ds = self.session.query(Dataset).filter(Dataset.vid == ref).one()\n        except NoResultFound:\n            ds = None\n\n        if not ds:\n            try:\n                ds = self.session \\\n                    .query(Dataset) \\\n                    .filter(Dataset.id == ref) \\\n                    .order_by(Dataset.revision.desc()) \\\n                    .first()\n            except NoResultFound:\n                ds = None\n\n        if not ds:\n            try:\n                ds = self.session.query(Dataset).filter(Dataset.vname == ref).one()\n            except NoResultFound:\n                ds = None\n\n        if not ds:\n            try:\n                ds = self.session \\\n                    .query(Dataset) \\\n                    .filter(Dataset.name == ref) \\\n                    .order_by(Dataset.revision.desc()) \\\n                    .first()\n            except NoResultFound:\n                ds = None\n\n        if ds:\n            ds._database = self\n            return ds\n        elif exception:\n            raise NotFoundError('No dataset in library for vid : {} '.format(ref))\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef datasets(self):\n\n        return self.session.query(Dataset).filter(Dataset.vid != ROOT_CONFIG_NAME_V).all()", "response": "Return all datasets in the database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfast delete of all of a datasets codes columns partitions and tables", "response": "def delete_tables_partitions(self, ds):\n        \"\"\"Fast delete of all of a datasets codes, columns, partitions and tables\"\"\"\n        from ambry.orm import Code, Column, Table, Partition, ColumnStat, Process\n\n        ssq = self.session.query\n\n        ssq(Process).filter(Process.d_vid == ds.vid).delete()\n        ssq(Code).filter(Code.d_vid == ds.vid).delete()\n        ssq(ColumnStat).filter(ColumnStat.d_vid == ds.vid).delete()\n        ssq(Column).filter(Column.d_vid == ds.vid).delete()\n        ssq(Partition).filter(Partition.d_vid == ds.vid).delete()\n\n        for source in ds.sources:\n            source._dest_table = None\n\n        ssq(Table).filter(Table.d_vid == ds.vid).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_partitions(self, ds):\n        from ambry.orm import Partition\n\n        ssq = self.session.query\n\n        ssq(Process).filter(Process.d_vid == ds.vid).delete()\n        ssq(Code).filter(Code.d_vid == ds.vid).delete()\n        ssq(ColumnStat).filter(ColumnStat.d_vid == ds.vid).delete()\n        ssq(Partition).filter(Partition.d_vid == ds.vid).delete()", "response": "Fast delete of all of a datasets codes columns partitions and tables"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_dataset(self, ds, incver=False, cb=None, **kwargs):\n        from ambry.orm import Table, Column, Partition, File, ColumnStat, Code, \\\n            DataSource, SourceTable, SourceColumn\n\n        tables = [Table, Column, Partition, File, ColumnStat, Code, SourceTable, SourceColumn, DataSource]\n\n        return self._copy_dataset_copy(ds, tables, incver, cb, **kwargs)", "response": "Copy a dataset into the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy only files and configs into the database.", "response": "def copy_dataset_files(self, ds, incver=False, cb=None, **kwargs):\n        \"\"\"\n        Copy only files and configs into the database.\n        :param ds: The source dataset to copy\n        :param cb: A progress callback, taking two parameters: cb(message, num_records)\n        :return:\n        \"\"\"\n        from ambry.orm import File\n\n        tables = [File]\n\n        return self._copy_dataset_copy(ds, tables, incver, cb, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the next sequence id for a child object that has a child sequence_id field", "response": "def next_sequence_id(self, parent_table_class, parent_vid, child_table_class):\n        \"\"\"Get the next sequence id for child objects for a parent object that has a child sequence\n        field\"\"\"\n\n        from sqlalchemy import text\n\n        # Name of sequence id column in the child\n        c_seq_col = child_table_class.sequence_id.property.columns[0].name\n\n        p_seq_col = getattr(parent_table_class, c_seq_col).property.columns[0].name\n\n        p_vid_col = parent_table_class.vid.property.columns[0].name\n\n        if self.driver == 'sqlite':\n            # The Sqlite version is not atomic, but Sqlite also doesn't support concurrency\n            # So, we don't have to open a new connection, but we also can't open a new connection, so\n            # this uses the session.\n            self.commit()\n            sql = text(\"SELECT  {p_seq_col} FROM {p_table} WHERE {p_vid_col} = '{parent_vid}' \"\n                       .format(p_table=parent_table_class.__tablename__, p_seq_col=p_seq_col,\n                               p_vid_col=p_vid_col, parent_vid=parent_vid))\n\n            v = next(iter(self.session.execute(sql)))[0]\n            sql = text(\"UPDATE {p_table} SET {p_seq_col} = {p_seq_col} + 1 WHERE {p_vid_col} = '{parent_vid}' \"\n                       .format(p_table=parent_table_class.__tablename__, p_seq_col=p_seq_col,\n                               p_vid_col=p_vid_col, parent_vid=parent_vid))\n\n            self.session.execute(sql)\n            self.commit()\n            return v\n\n        else:\n            # Must be postgres, or something else that supports \"RETURNING\"\n            sql = text(\"\"\"\n            UPDATE {p_table} SET {p_seq_col} = {p_seq_col} + 1 WHERE {p_vid_col} = '{parent_vid}' RETURNING {p_seq_col}\n            \"\"\".format(p_table=parent_table_class.__tablename__, p_seq_col=p_seq_col, p_vid_col=p_vid_col,\n                       parent_vid=parent_vid))\n\n            self.connection.execute('SET search_path TO {}'.format(self._schema))\n            r = self.connection.execute(sql)\n            v = next(iter(r))[0]\n            return v-1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a single table in the database.", "response": "def create_table(table, connection, schema=None):\n        \"\"\"Create a single table, primarily used din migrations\"\"\"\n\n        orig_schemas = {}\n\n        # These schema shenanigans are almost certainly wrong.\n        # But they are expedient. For Postgres, it puts the library\n        # tables in the Library schema. We need to change the schema for all tables in case\n        # the table we are creating references another table\n        if schema:\n            connection.execute(\"SET search_path TO {}\".format(schema))\n\n            for table in ALL_TABLES:\n                orig_schemas[table.__table__] = table.__table__.schema\n                table.__table__.schema = schema\n\n        table.__table__.create(bind=connection.engine)\n\n        # We have to put the schemas back because when installing to a warehouse.\n        # the same library classes can be used to access a Sqlite database, which\n        # does not handle schemas.\n        if schema:\n            for it, orig_schema in list(orig_schemas.items()):\n                it.schema = orig_schema"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield a sequence of items from g.", "response": "def _deferGenerator(g, deferred=None):\n    \"\"\"\n    See L{waitForDeferred}.\n    \"\"\"\n    result = None\n    while 1:\n        if deferred is None:\n            deferred = defer.Deferred()\n        try:\n            result = g.next()\n        except StopIteration:\n            deferred.callback(result)\n            return deferred\n        except:\n            deferred.errback()\n            return deferred\n\n        # Deferred.callback(Deferred) raises an error; we catch this case\n        # early here and give a nicer error message to the user in case\n        # they yield a Deferred. Perhaps eventually these semantics may\n        # change.\n        if isinstance(result, defer.Deferred):\n            return defer.fail(TypeError(\"Yield waitForDeferred(d), not d!\"))\n\n        if isinstance(result, defer.waitForDeferred):\n            waiting = [True, None]\n            # Pass vars in so they don't get changed going around the loop\n            def gotResult(r, waiting=waiting, result=result):\n                result.result = r\n                if waiting[0]:\n                    waiting[0] = False\n                    waiting[1] = r\n                else:\n                    _deferGenerator(g, deferred)\n            result.d.addBoth(gotResult)\n            if waiting[0]:\n                # Haven't called back yet, set flag so that we get reinvoked\n                # and return from the loop\n                waiting[0] = False\n                return deferred\n            result = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef return_locals(func):\n    '''Modifies decorated function to return its locals'''\n\n    @functools.wraps(func)\n    def wrap(*args, **kwargs):\n        frames = []\n\n        def tracer(frame, event, arg): # pragma: no cover\n            # coverage does not work in this function because the tracer\n            # is deactivated here\n            frames.append(frame)\n            sys.settrace(old_tracer)\n            if old_tracer is not None:\n                return old_tracer(frame, event, arg)\n\n        old_tracer = sys.gettrace()\n        # tracer is activated on next call, return or exception\n        sys.settrace(tracer)\n        try:\n            func(*args, **kwargs)\n        finally:\n            sys.settrace(old_tracer)\n        assert len(frames) == 1\n        argspec = inspect.getargspec(func)\n        argnames = list(argspec.args)\n        if argspec.varargs is not None:\n            argnames.append(argspec.varargs)\n        if argspec.keywords is not None:\n            argnames.append(argspec.keywords)\n        return {name: value for name, value in frames.pop(0).f_locals.items()\n                if name not in argnames}\n\n    return wrap", "response": "Modifies decorated function to return its locals"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef multidb_binds(databases, package=None, engine_params=None):\n    '''Creates dictionary to be passed as `binds` parameter to\n    `sqlalchemy.orm.sessionmaker()` from dictionary mapping models module name\n    to connection URI that should be used for these models. Models module must\n    have `metadata` attribute. `package` when set must be a package or package\n    name for all models modules.'''\n    engine_params = engine_params or {}\n    if not (package is None or isinstance(package, six.string_types)):\n        package = getattr(package, '__package__', None) or package.__name__\n    binds = {}\n    for ref, uri in databases.items():\n        md_ref = '.'.join(filter(None, [package, ref]))\n        md_module = import_module(md_ref)\n        try:\n            metadata = md_module.metadata\n        except AttributeError:\n            raise ImportError(\n                'Cannot import name metadata from module {}'.format(md_ref))\n        engine = create_engine(uri, **engine_params)\n        # Dot before [name] is required to allow setting logging level etc. for\n        # all them at once.\n        engine.logger = logging.getLogger('sqlalchemy.engine.[%s]' % ref)\n        for table in metadata.sorted_tables:\n            binds[table] = engine\n    return binds", "response": "Creates dictionary to be passed as binds parameter to\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all builds in a node", "response": "def list_builds(page_size=200, page_index=0, sort=\"\", q=\"\"):\n    \"\"\"\n    List all builds\n    :param page_size: number of builds returned per query\n    :param sort: RSQL sorting query\n    :param q: RSQL query\n    :return:\n    \"\"\"\n    response = utils.checked_api_call(pnc_api.builds_running, 'get_all', page_size=page_size, page_index=page_index, sort=sort, q=q)\n    if response:\n        return response.content"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate list of artifacts for offline repository.", "response": "def generate_repo_list(product_name=None, product_version=None, product_milestone=None):\n    \"\"\"\n    Generates list of artifacts for offline repository.\n    \"\"\"\n    if not validate_input_parameters(product_name, product_version, product_milestone):\n        sys.exit(1)\n    product_version = pnc_api.product_versions.get_all(q=\"version=='\"+ product_version + \"';product.name=='\"+product_name+\"'\")\n    if not product_version.content:\n        logging.error('Specified product version not found.')\n        sys.exit(1)\n    product_version_id = product_version.content[0].id\n    milestone = pnc_api.product_milestones.get_all(q=\"version=='\"+ product_milestone + \"';productVersion.id=='\"+str(product_version_id)+\"'\")\n    if not milestone.content:\n        logging.error('Specified milestone not found.')\n        sys.exit(1)\n    milestone_id = milestone.content[0].id\n    builds = get_all_successful_builds(milestone_id)\n    if not builds:\n        logging.warning('No builds performed in the milestone.')\n        return\n    for build in builds:\n        built_artifacts = get_all_artifacts(build.id)\n        for artifact in built_artifacts:\n            print(artifact.identifier)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef login(username=None, password=None):\n    global user\n    user = UserConfig()\n    if username:\n        user.username = username\n    else:\n        user.username = user.input_username()\n\n    if password:\n        user.password = password\n    else:\n        user.password = user.input_password()\n\n    if (not ( user.username and user.password) ):\n        logging.error(\"Username and password must be provided for login\")\n        return;\n    user.retrieve_keycloak_token()\n    user.apiclient = user.create_api_client()\n    save()", "response": "Log in to PNC using the supplied username and password."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrescheduling this call for a different time .", "response": "def reset(self, secondsFromNow):\n        \"\"\"Reschedule this call for a different time\n\n        @type secondsFromNow: C{float}\n        @param secondsFromNow: The number of seconds from the time of the\n        C{reset} call at which this call will be scheduled.\n\n        @raise AlreadyCancelled: Raised if this call has been cancelled.\n        @raise AlreadyCalled: Raised if this call has already been made.\n        \"\"\"\n        if self.cancelled:\n            raise error.AlreadyCancelled\n        elif self.called:\n            raise error.AlreadyCalled\n        else:\n            if self.seconds is None:\n                new_time = base.seconds() + secondsFromNow\n            else:\n                new_time = self.seconds() + secondsFromNow\n            if new_time < self.time:\n                self.delayed_time = 0\n                self.time = new_time\n                self.resetter(self)\n            else:\n                self.delayed_time = new_time - self.time"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreschedules this call for a later time.", "response": "def delay(self, secondsLater):\n        \"\"\"Reschedule this call for a later time\n\n        @type secondsLater: C{float}\n        @param secondsLater: The number of seconds after the originally\n        scheduled time for which to reschedule this call.\n\n        @raise AlreadyCancelled: Raised if this call has been cancelled.\n        @raise AlreadyCalled: Raised if this call has already been made.\n        \"\"\"\n        if self.cancelled:\n            raise error.AlreadyCancelled\n        elif self.called:\n            raise error.AlreadyCalled\n        else:\n            self.delayed_time += secondsLater\n            if self.delayed_time < 0:\n                self.activate_delay()\n                self.resetter(self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    startLogging(stdout)\n    checker = InMemoryUsernamePasswordDatabaseDontUse()\n    checker.addUser(\"testuser\", \"examplepass\")\n    realm = AdditionRealm()\n    factory = CredAMPServerFactory(Portal(realm, [checker]))\n    reactor.listenTCP(7805, factory)\n    reactor.run()", "response": "Start the AMP server and the reactor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_meta(self, instance):\n        self.use_title_tag = True\n        self.title = instance.title", "response": "Set django - meta stuff from LandingPageModel instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check(self, field):\n        '''\n        Returns permissions determined by object itself\n        '''\n        if self.permissions is None:\n            return field.parent.permissions\n        return self.permissions", "response": "Returns permissions determined by object itself and its parent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a view by name and return an instance of that class.", "response": "def _load_view(self, template_engine_name, template_dir):\n        \"\"\"\n        Load view by name and return an instance.\n        \"\"\"\n        file_name = template_engine_name.lower()\n        class_name = \"{}View\".format(template_engine_name.title())\n        try:\n            view_module = import_module(\"rails.views.{}\".format(file_name))\n        except ImportError:\n            raise Exception(\"Template engine '{}' not found in 'rails.views'\".format(file_name))\n        view_class = getattr(view_module, class_name)\n        return view_class(template_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nterminates process with PID pid and returns True if process finished during timeout. Current user must have permission to access process information.", "response": "def terminate(pid, sig, timeout):\n    '''Terminates process with PID `pid` and returns True if process finished\n    during `timeout`. Current user must have permission to access process\n    information.'''\n    os.kill(pid, sig)\n    start = time.time()\n    while True:\n        try:\n            # This is requireed if it's our child to avoid zombie. Also\n            # is_running() returns True for zombie process.\n            _, status = os.waitpid(pid, os.WNOHANG)\n        except OSError as exc:\n            if exc.errno != errno.ECHILD: # pragma: nocover\n                raise\n        else:\n            if status:\n                return True\n        if not is_running(pid):\n            return True\n        if time.time()-start>=timeout:\n            return False\n        time.sleep(0.1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef doublefork(pidfile, logfile, cwd, umask): # pragma: nocover\n    '''Daemonize current process.\n    After first fork we return to the shell and removing our self from\n    controling terminal via `setsid`.\n    After second fork we are not session leader any more and cant get\n    controlling terminal when opening files.'''\n    try:\n        if os.fork():\n            os._exit(os.EX_OK)\n    except OSError as e:\n        sys.exit('fork #1 failed: ({}) {}'.format(e.errno, e.strerror))\n    os.setsid()\n    os.chdir(cwd)\n    os.umask(umask)\n    try:\n        if os.fork():\n            os._exit(os.EX_OK)\n    except OSError as e:\n        sys.exit('fork #2 failed: ({}) {}'.format(e.errno, e.strerror))\n    if logfile is not None:\n        si = open('/dev/null')\n        if six.PY2:\n            so = open(logfile, 'a+', 0)\n        else:\n            so = io.open(logfile, 'ab+', 0)\n            so = io.TextIOWrapper(so, write_through=True, encoding=\"utf-8\")\n\n        os.dup2(si.fileno(), 0)\n        os.dup2(so.fileno(), 1)\n        os.dup2(so.fileno(), 2)\n        sys.stdin = si\n        sys.stdout = sys.stderr = so\n    with open(pidfile, 'w') as f:\n        f.write(str(os.getpid()))", "response": "Daemonize current process.\n    After first fork we return to the shell and removing our self from\n    controling terminal via `setsid`.\n    After second fork we are not session leader any more and cant get\n    controlling terminal when opening files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for Repository Configurations based on internal or external url ignoring the protocol and. git suffix. Only exact matches are returned.", "response": "def match(self, search, **kwargs):\n        \"\"\"\n        Searches for Repository Configurations based on internal or external url, ignoring the protocol and \\\".git\\\" suffix. Only exact matches are returned.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.match(search, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param str search: Url to search for (required)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :param str sort: Sorting RSQL\n        :return: RepositoryConfigurationPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.match_with_http_info(search, **kwargs)\n        else:\n            (data) = self.match_with_http_info(search, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for Repository Configurations based on internal or external url.", "response": "def search(self, search, **kwargs):\n        \"\"\"\n        Search for Repository Configurations based on internal or external url, ignoring the protocol and \\\".git\\\" suffix. The matching is done using LIKE.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.search(search, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param str search: Url part to search for (required)\n        :param int page_index: Page Index\n        :param int page_size: Pagination size\n        :param str sort: Sorting RSQL\n        :return: RepositoryConfigurationPage\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.search_with_http_info(search, **kwargs)\n        else:\n            (data) = self.search_with_http_info(search, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_mead(config=None, run_build=False, environment=1, suffix=\"\", product_name=None, product_version=None,\n              look_up_only=\"\",clean_group=False):\n    \"\"\"\n    Create Build group based on Make-Mead configuration file\n    :param config: Make Mead config name\n    :return:\n    \"\"\"\n    ret=make_mead_impl(config, run_build, environment, suffix, product_name, product_version, look_up_only, clean_group)\n    if type(ret) == int and ret != 0:\n        sys.exit(ret)\n    return ret", "response": "Create a Mead build group based on Make - Mead configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef partition(self, id_):\n        from ..orm import Partition as OrmPartition\n        from sqlalchemy import or_\n        from ..identity import PartialPartitionName\n\n        if isinstance(id_, PartitionIdentity):\n            id_ = id_.id_\n        elif isinstance(id_, PartialPartitionName):\n            id_ = id_.promote(self.bundle.identity.name)\n\n        session = self.bundle.dataset._database.session\n        q = session\\\n            .query(OrmPartition)\\\n            .filter(OrmPartition.d_vid == self.bundle.dataset.vid)\\\n            .filter(or_(OrmPartition.id == str(id_).encode('ascii'),\n                        OrmPartition.vid == str(id_).encode('ascii')))\n\n        try:\n            orm_partition = q.one()\n            return self.bundle.wrap_partition(orm_partition)\n        except NoResultFound:\n            orm_partition = None\n\n        if not orm_partition:\n            q = session\\\n                .query(OrmPartition)\\\n                .filter(OrmPartition.d_vid == self.bundle.dataset.vid)\\\n                .filter(OrmPartition.name == str(id_).encode('ascii'))\n\n            try:\n                orm_partition = q.one()\n                return self.bundle.wrap_partition(orm_partition)\n            except NoResultFound:\n                orm_partition = None\n\n        return orm_partition", "response": "Get a partition by the id number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding an ORM object based on a PartitionId.", "response": "def _find_orm(self, pnq):\n        \"\"\"Return a Partition object from the database based on a PartitionId.\n\n        An ORM object is returned, so changes can be persisted.\n\n        \"\"\"\n        # import sqlalchemy.orm.exc\n        from ambry.orm import Partition as OrmPartition  # , Table\n        from sqlalchemy.orm import joinedload  # , joinedload_all\n\n        assert isinstance(pnq, PartitionNameQuery), \"Expected PartitionNameQuery, got {}\".format(type(pnq))\n\n        pnq = pnq.with_none()\n\n        q = self.bundle.dataset._database.session.query(OrmPartition)\n\n        if pnq.fqname is not NameQuery.ANY:\n            q = q.filter(OrmPartition.fqname == pnq.fqname)\n        elif pnq.vname is not NameQuery.ANY:\n            q = q.filter(OrmPartition.vname == pnq.vname)\n        elif pnq.name is not NameQuery.ANY:\n            q = q.filter(OrmPartition.name == str(pnq.name))\n        else:\n            if pnq.time is not NameQuery.ANY:\n                q = q.filter(OrmPartition.time == pnq.time)\n\n            if pnq.space is not NameQuery.ANY:\n                q = q.filter(OrmPartition.space == pnq.space)\n\n            if pnq.grain is not NameQuery.ANY:\n                q = q.filter(OrmPartition.grain == pnq.grain)\n\n            if pnq.format is not NameQuery.ANY:\n                q = q.filter(OrmPartition.format == pnq.format)\n\n            if pnq.segment is not NameQuery.ANY:\n                q = q.filter(OrmPartition.segment == pnq.segment)\n\n            if pnq.table is not NameQuery.ANY:\n\n                if pnq.table is None:\n                    q = q.filter(OrmPartition.t_id is None)\n                else:\n                    tr = self.bundle.table(pnq.table)\n\n                    if not tr:\n                        raise ValueError(\"Didn't find table named {} in {} bundle path = {}\".format(\n                            pnq.table, pnq.vname, self.bundle.database.path))\n\n                    q = q.filter(OrmPartition.t_vid == tr.vid)\n\n        ds = self.bundle.dataset\n\n        q = q.filter(OrmPartition.d_vid == ds.vid)\n\n        q = q.order_by(\n            OrmPartition.vid.asc()).order_by(\n            OrmPartition.segment.asc())\n\n        q = q.options(joinedload(OrmPartition.table))\n\n        return q"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_db_from_pandas(self, frame, table=None, data=None, load=True, **kwargs):\n\n        from ..orm import Column\n        # from dbexceptions import ConfigurationError\n\n        # Create the table from the information in the data frame.\n        with self.bundle.session:\n            sch = self.bundle.schema\n            t = sch.new_table(table)\n\n            if frame.index.name:\n                id_name = frame.index.name\n            else:\n                id_name = 'id'\n\n            sch.add_column(t, id_name,\n                           datatype=Column.convert_numpy_type(frame.index.dtype),\n                           is_primary_key=True)\n\n            for name, type_ in zip([row for row in frame.columns],\n                                   [row for row in frame.convert_objects(convert_numeric=True,\n                                                                         convert_dates=True).dtypes]):\n                sch.add_column(t, name, datatype=Column.convert_numpy_type(type_))\n                sch.write_schema()\n\n        p = self.new_partition(table=table, data=data, **kwargs)\n\n        if load:\n            pk_name = frame.index.name\n            with p.inserter(table) as ins:\n                for i, row in frame.iterrows():\n                    d = dict(row)\n                    d[pk_name] = i\n\n                    ins.insert(d)\n        return p", "response": "Create a new db partition from a pandas data frame."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating an existing Project with new information", "response": "def update_project(id, **kwargs):\n    \"\"\"\n    Update an existing Project with new information\n    \"\"\"\n    content = update_project_raw(id, **kwargs)\n    if content:\n        return utils.format_json(content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a specific Project by ID or name", "response": "def get_project(id=None, name=None):\n    \"\"\"\n    Get a specific Project by ID or name\n    \"\"\"\n    content = get_project_raw(id, name)\n    if content:\n        return utils.format_json(content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a Project by ID or name.", "response": "def delete_project(id=None, name=None):\n    \"\"\"\n    Delete a Project by ID or name.\n    \"\"\"\n    content = delete_project_raw(id, name)\n    if content:\n        return utils.format_json(content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncancel the build record push result.", "response": "def cancel(self, build_record_id, **kwargs):\n        \"\"\"\n        Build record push results.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.cancel(build_record_id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int build_record_id: Build Record id (required)\n        :param BuildRecordPushResultRest body:\n        :return: int\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.cancel_with_http_info(build_record_id, **kwargs)\n        else:\n            (data) = self.cancel_with_http_info(build_record_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting Build Record Push Result by Id..", "response": "def get(self, build_record_id, **kwargs):\n        \"\"\"\n        Get Build Record Push Result by Id..\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.get(build_record_id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int build_record_id: Build Record id (required)\n        :return: BuildRecordPushResultRest\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_with_http_info(build_record_id, **kwargs)\n        else:\n            (data) = self.get_with_http_info(build_record_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npush build record results to Brew. an ecords", "response": "def push(self, **kwargs):\n        \"\"\"\n        Push build record results to Brew.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.push(callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param BuildRecordPushRequestRest body:\n        :return: list[ResultRest]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.push_with_http_info(**kwargs)\n        else:\n            (data) = self.push_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npushing an anatomy build record into an anatomy build record.", "response": "def push_0(self, build_record_id, **kwargs):\n        \"\"\"\n        Build record push results.\n        \n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please define a `callback` function\n        to be invoked when receiving the response.\n        >>> def callback_function(response):\n        >>>     pprint(response)\n        >>>\n        >>> thread = api.push_0(build_record_id, callback=callback_function)\n\n        :param callback function: The callback function\n            for asynchronous request. (optional)\n        :param int build_record_id: Build Record id (required)\n        :param BuildRecordPushResultRest body:\n        :return: int\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.push_0_with_http_info(build_record_id, **kwargs)\n        else:\n            (data) = self.push_0_with_http_info(build_record_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push_record_set(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.push_record_set_with_http_info(**kwargs)\n        else:\n            (data) = self.push_record_set_with_http_info(**kwargs)\n            return data", "response": "Push build config set record to Brew."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_handler(self, handler):\n        if self.handler is not None:\n            raise Exception('Attempted to overwrite BaseSession handler')\n\n        self.handler = handler\n        self.transport_name = self.handler.name\n\n        if self.conn_info is None:\n            self.conn_info = handler.get_conn_info()\n            self.stats.sessionOpened(self.transport_name)\n\n        return True", "response": "Set the BaseSession handler."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_state(self):\n        if self.state == SESSION_STATE.CONNECTING:\n            self.state = SESSION_STATE.OPEN\n\n            self.conn.connectionMade(self.conn_info)", "response": "Verify if session was not yet opened and call the C { connectionMade method."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the session or endpoint connection.", "response": "def close(self, code=3000, message='Go away!'):\n        \"\"\" Close session or endpoint connection.\n\n        @param code: Closing code\n\n        @param message: Close message\n        \"\"\"\n        if self.state != SESSION_STATE.CLOSED:\n            try:\n                self.conn.connectionLost()\n            except Exception as e:\n                log.msg(\"Failed to call connectionLost(): %r.\" % e)\n            finally:\n                self.state = SESSION_STATE.CLOSED\n                self.close_reason = (code, message)\n\n            # Bump stats\n            self.stats.sessionClosed(self.transport_name)\n\n            # If we have active handler, notify that session was closed\n            if self.handler is not None:\n                self.handler.session_closed()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling by the thread when the session is closed.", "response": "def delayed_close(self):\n        \"\"\" Delayed close - won't close immediately, but on the next reactor\n        loop. \"\"\"\n        self.state = SESSION_STATE.CLOSING\n        reactor.callLater(0, self.close)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if session was closed.", "response": "def is_closed(self):\n        \"\"\" Check if session was closed. \"\"\"\n        return (self.state == SESSION_STATE.CLOSED \n                or self.state == SESSION_STATE.CLOSING)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _random_key(self):\n        hashstr = '%s%s' % (random.random(), self.time_module.time())\n        return hashlib.md5(hashstr).hexdigest()", "response": "Return random session key"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef promote(self):\n        if self.expiry is not None:\n            self.promoted = self.time_module.time() + self.expiry", "response": "Promote the object to alive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the active cyclone handler for the session.", "response": "def set_handler(self, handler, start_heartbeat=True):\n        \"\"\" Set active handler for the session\n\n        @param handler: Associate active cyclone handler with the session\n\n        @param start_heartbeat: Should session start heartbeat immediately\n        \"\"\"\n        # Check if session already has associated handler\n        if self.handler is not None:\n            handler.send_pack(proto.disconnect(2010,\n                                               \"Another connection still open\"))\n            return False\n\n        if self._verify_ip and self.conn_info is not None:\n            # If IP address doesn't match - refuse connection\n            if handler.request.remote_ip != self.conn_info.ip:\n                log.msg('Attempted to attach to session %s (%s) from '\n                        'different IP (%s)' % ( self.session_id,\n                                                self.conn_info.ip,\n                                                handler.request.remote_ip\n                                              )\n                       )\n\n                handler.send_pack(proto.disconnect(2010, 'Attempted to connect '\n                                         'to session from different IP'))\n                return False\n\n        if ( self.state == SESSION_STATE.CLOSING\n             or self.state == SESSION_STATE.CLOSED):\n            handler.send_pack(proto.disconnect(*self.get_close_reason()))\n            return False\n\n        # Associate handler and promote session\n        super(Session, self).set_handler(handler)\n\n        self.promote()\n\n        if start_heartbeat:\n            self.start_heartbeat()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify_state(self):\n        # If we're in CONNECTING state - send 'o' message to the client\n        if self.state == SESSION_STATE.CONNECTING:\n            self.handler.send_pack(proto.CONNECT)\n\n        # Call parent implementation\n        super(Session, self).verify_state()", "response": "Verify if the session was not yet opened and call any necessary methods."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message to the remote server.", "response": "def send_message(self, msg, stats=True):\n        \"\"\" Send or queue outgoing message\n\n        @param msg: Message to send\n\n        @param stats: If set to True, will update statistics after operation\n                      completes\n        \"\"\"\n        self.send_jsonified(proto.json_encode(msg), stats)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a JSON - encoded message to the next available instance of the class.", "response": "def send_jsonified(self, msg, stats=True):\n        \"\"\" Send JSON-encoded message\n\n        @param msg: JSON encoded string to send\n        @param stats: If set to True, will update statistics after operation\n                      completes\n        \"\"\"\n        assert isinstance(msg, basestring), 'Can only send strings'\n\n        if isinstance(msg, unicode):\n            msg = msg.encode('utf-8')\n\n        if self._immediate_flush:\n            if self.handler and self.send_queue.is_empty():\n                # Send message right away\n                self.handler.send_pack('a[%s]' % msg)\n            else:\n                self.send_queue.push(msg)\n                self.flush()\n        else:\n            self.send_queue.push(msg)\n\n            if not self._pending_flush:\n                reactor.callLater(0, self.flush)\n                self._pending_flush = True\n\n        if stats:\n            self.stats.packSent(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flush(self):\n        self._pending_flush = False\n\n        if self.handler is None:\n            return\n\n        if self.send_queue.is_empty():\n            return\n\n        self.handler.send_pack('a[%s]' % self.send_queue.get())\n        self.send_queue.clear()", "response": "Flush the send queue if there s an active connection running"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses session. @param code: Closing code @param message: Closing message", "response": "def close(self, code=3000, message='Go away!'):\n        \"\"\" Close session.\n\n        @param code: Closing code\n\n        @param message: Closing message\n        \"\"\"\n        if self.state != SESSION_STATE.CLOSED:\n            # Notify handler\n            if self.handler is not None:\n                self.handler.send_pack(proto.disconnect(code, message))\n\n        super(Session, self).close(code, message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_heartbeat(self):\n        self.stop_heartbeat()\n\n        self._heartbeat_timer = task.LoopingCall(self._heartbeat)\n        self._heartbeat_timer.start(self._heartbeat_interval, False)", "response": "Start the heartbeat timer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles incoming messages from the cache", "response": "def messagesReceived(self, msg_list):\n        \"\"\" Handle incoming messages\n\n        @param msg_list: Message list to process\n        \"\"\"\n        self.stats.packReceived(len(msg_list))\n\n        for msg in msg_list:\n            self.conn.messageReceived(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parser(cls, v):\n        return geoid.census.State.parse(str(v).zfill(2))", "response": "Ensure that the upstream parser gets two digits."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the dependency structure of an artifact.", "response": "def get_dependency_structure(self, artifact=None, include_dependencies=False):\n        \"\"\"\n        Reads dependency structure. If an artifact is passed in you get only its dependencies otherwise the complete\n        structure is returned.\n\n        :param artifact: an artifact task or artifact name if only an artifact's deps are needed\n        :param include_dependencies: flag to include also dependencies in returned artifacts and their dependencies in\n                                     dependencies dict\n        :return: tuple of artifact names list and dependencies dictionary where value is a Task list\n        \"\"\"\n        artifacts = []\n        dependencies_dict = {}\n        if artifact:\n            if isinstance(artifact, str):\n                artifact = self.get_tasks().get_task(artifact)\n            artifacts.append(artifact.name)\n            dependencies_dict[artifact.name] =  artifact.ordered_dependencies()\n\n            if include_dependencies:\n                for dep in dependencies_dict[artifact.name]:\n                    artifacts.append(dep.name)\n                    dependencies_dict[dep.name] =  dep.ordered_dependencies()\n        else:\n            for key, task in self.get_tasks().tasks.iteritems():\n                artifacts.append(task.name)\n                dependencies_dict[task.name] = task.ordered_dependencies()\n\n        return artifacts, dependencies_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _do_read_config(self, config_file, pommanipext):\n        parser = InterpolationConfigParser()\n        dataset = parser.read(config_file)\n        if config_file not in dataset:\n            raise IOError(\"Config file %s not found.\" % config_file)\n        if parser.has_option('common','include'):\n            include = parser.get('common', 'include')\n            if include is not \"\":\n                sections_ = self.read_and_load(include)\n                for section_ in sections_:\n                    if parser.has_section(section_):\n                        raise DuplicateSectionError( \"The config section [%s] is existed in %s and include %s cfg file\" % ( section_, config_file, re.split(\"\\\\s+\", include.strip())[1]))\n                parser._sections.update(sections_)\n\n        pom_manipulator_config = {}\n        common_section = {}\n        package_configs = {}\n\n        if pommanipext and pommanipext != '' and pommanipext != 'None': #TODO ref: remove none check, it is passed over cmd line in jenkins build\n            parse_pom_manipulator_ext(pom_manipulator_config, parser, pommanipext)\n\n        if not parser.has_section('common'):\n            logging.error('Mandatory common section missing from configuration file.')\n            raise NoSectionError('Mandatory common section missing from configuration file.')\n        common_section['tag'] = parser.get('common', 'tag')\n        common_section['target'] = parser.get('common', 'target')\n        common_section['jobprefix'] = parser.get('common', 'jobprefix')\n        common_section['jobciprefix'] = parser.get('common', 'jobciprefix')\n        common_section['jobjdk'] = parser.get('common', 'jobjdk')\n        if parser.has_option('common', 'mvnver'):\n            common_section['mvnver'] = parser.get('common', 'mvnver')\n        if parser.has_option('common', 'skiptests'):\n            common_section['skiptests'] = parser.get('common', 'skiptests')\n        if parser.has_option('common', 'base'):\n            common_section['base'] = parser.get('common', 'base')\n        if parser.has_option('common', 'citemplate'):\n            common_section['citemplate'] = parser.get('common', 'citemplate')\n        if parser.has_option('common', 'jenkinstemplate'):\n            common_section['jenkinstemplate'] = parser.get('common', 'jenkinstemplate')\n        if parser.has_option('common', 'product_name'):\n            common_section['product_name'] = parser.get('common', 'product_name')\n\n        if parser.has_option('common', 'include'):\n            common_section['include'] = parser.get('common', 'include')\n\n        common_section['jobfailureemail'] = parser.get('common', 'jobfailureemail')\n\n        config_dir = utils.get_dir(config_file)\n\n        #Jira\n        if parser.has_option('common', 'shared_config') and parser.get('common', 'shared_config') is not \"\":\n            parse_shared_config(common_section, config_dir, parser)\n\n        common_section['jobtimeout'] = parser.getint('common', 'jobtimeout')\n\n        common_section['options'] = {}\n        # If the configuration file has global properties insert these into the common properties map.\n        # These may be overridden later by particular properties.\n        if parser.has_option('common', 'globalproperties'):\n            common_section['options']['properties'] = dict(x.strip().split('=') for x in parser.get('common', 'globalproperties').replace(\",\\n\", \",\").split(','))\n        else:\n            # Always ensure properties has a valid dictionary so code below doesn't need multiple checks.\n            common_section['options']['properties'] = {}\n        # The same for global profiles\n        if parser.has_option('common', 'globalprofiles'):\n            common_section['options']['profiles'] = [x.strip() for x in parser.get('common', 'globalprofiles').split(',')]\n        else:\n            # Always ensure profiles has a valid list so code below doesn't need multiple checks.\n            common_section['options']['profiles'] = []\n\n        if os.path.dirname(config_file):\n            config_path = os.path.dirname(config_file)\n        else:\n            config_path = os.getcwd()\n        logging.info(\"Configuration file is %s and path %s\", os.path.basename(config_file), config_path)\n\n        for section in parser.sections():\n            config_type = self.read_config_type(parser, section)\n            if section == 'common' or config_type == \"bom-builder-meta\":\n                logging.debug ('Skipping section due to meta-type %s', section)\n                continue\n\n            self._do_read_section(config_path, os.path.basename(config_file), package_configs, parser, section)\n\n        return (common_section, package_configs, pom_manipulator_config)", "response": "Reads config file for a single job defined by section."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform_generator(fn):\n    if six.PY2:\n        fn.func_dict['is_transform_generator'] = True\n    else:\n        # py3\n        fn.__dict__['is_transform_generator'] = True\n    return fn", "response": "A decorator that marks transform pipes that should be called to create the real transform"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn true of the function has been marked with @transform_generator", "response": "def is_transform_generator(fn):\n    \"\"\"Return true of the function has been marked with @transform_generator\"\"\"\n    try:\n        if six.PY2:\n            fn.func_dict['is_transform_generator'] = True\n        else:\n            # py3\n            return fn.__dict__.get('is_transform_generator', False)\n    except AttributeError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting empty strings and strings with only spaces to None values.", "response": "def nullify(v):\n    \"\"\"Convert empty strings and strings with only spaces to None values. \"\"\"\n\n    if isinstance(v, six.string_types):\n        v = v.strip()\n\n    if v is None or v == '':\n        return None\n    else:\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_float(v):\n\n    if v is None or not str(v).strip():\n        return None\n\n    return float(str(v).replace(',', ''))", "response": "Remove commas from a float"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving commas from a float", "response": "def clean_int(v):\n    \"\"\"Remove commas from a float\"\"\"\n\n    if v is None or not str(v).strip():\n        return None\n\n    return int(str(v).replace(',', ''))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse as an integer or a subclass of Int.", "response": "def parse_int(v, header_d):\n    \"\"\"Parse as an integer, or a subclass of Int.\"\"\"\n\n    v = nullify(v)\n\n    if v is None:\n        return None\n\n    try:\n        # The converson to float allows converting float strings to ints.\n        # The conversion int('2.134') will fail.\n        return int(round(float(v), 0))\n    except (TypeError, ValueError) as e:\n        raise CastingError(int, header_d, v, 'Failed to cast to integer')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_text(v, header_d):\n\n    v = nullify(v)\n\n    if v is None:\n        return None\n\n    try:\n        return six.text_type(v).strip()\n    except Exception as e:\n        raise CastingError(six.text_type, header_d, v, str(e))", "response": "Parses unicode.\n\n    Note:\n        unicode types for py2 and str types for py3."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_binary(v, header_d):\n\n    # This is often a no-op, but it ocassionally converts numbers into strings\n\n    v = nullify(v)\n\n    if v is None:\n        return None\n\n    if six.PY2:\n        try:\n            return six.binary_type(v).strip()\n        except UnicodeEncodeError:\n            return six.text_type(v).strip()\n    else:\n        # py3\n        try:\n            return six.binary_type(v, 'utf-8').strip()\n        except UnicodeEncodeError:\n            return six.text_type(v).strip()", "response": "Parses binary string.\n\n    Note:\n        <str> for py2 and <binary> for py3."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parseJuiceHeaders(lines):\n    b = JuiceBox()\n    bodylen = 0\n    key = None\n    for L in lines:\n        if L[0] == ' ':\n            # continuation\n            assert key is not None\n            b[key] += '\\r\\n'+L[1:]\n            continue\n        parts = L.split(': ', 1)\n        if len(parts) != 2:\n            raise MalformedJuiceBox(\"Wrong number of parts: %r\" % (L,))\n        key, value = parts\n        key = normalizeKey(key)\n        b[key] = value\n    return int(b.pop(LENGTH, 0)), b", "response": "Parse a list of header lines into a JuiceBox."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a callable to invoke when executing the named command.", "response": "def lookupFunction(self, proto, name, namespace):\n        \"\"\"Return a callable to invoke when executing the named command.\n        \"\"\"\n        # Try to find a method to be invoked in a transaction first\n        # Otherwise fallback to a \"regular\" method\n        fName = self.autoDispatchPrefix + name\n        fObj = getattr(self, fName, None)\n        if fObj is not None:\n            # pass the namespace along\n            return self._auto(fObj, proto, namespace)\n\n        assert namespace is None, 'Old-style parsing'\n        # Fall back to simplistic command dispatching - we probably want to get\n        # rid of this eventually, there's no reason to do extra work and write\n        # fewer docs all the time.\n        fName = self.baseDispatchPrefix + name\n        return getattr(self, fName, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sendBoxCommand(self, command, box, requiresAnswer=True):\n        if self._outstandingRequests is None:\n            return fail(CONNECTION_LOST)\n        box[COMMAND] = command\n        tag = self._nextTag()\n        if requiresAnswer:\n            box[ASK] = tag\n            result = self._outstandingRequests[tag] = Deferred()\n        else:\n            result = None\n        box.sendTo(self)\n        return result", "response": "Send a command across the wire with the given C { uice. Box }."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nswitch this Juice instance to a new protocol.", "response": "def _switchTo(self, newProto, clientFactory=None):\n        \"\"\" Switch this Juice instance to a new protocol.  You need to do this\n        'simultaneously' on both ends of a connection; the easiest way to do\n        this is to use a subclass of ProtocolSwitchCommand.\n        \"\"\"\n\n        assert self.innerProtocol is None, \"Protocol can only be safely switched once.\"\n        self.setRawMode()\n        self.innerProtocol = newProto\n        self.innerProtocolClientFactory = clientFactory\n        newProto.makeConnection(self.transport)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sendPacket(self, completeBox):\n        assert not self.__locked, \"You cannot send juice packets when a connection is locked\"\n        if self._startingTLSBuffer is not None:\n            self._startingTLSBuffer.append(completeBox)\n        else:\n            if debug:\n                log.msg(\"Juice send: %s\" % pprint.pformat(dict(completeBox.iteritems())))\n\n            self.transport.write(completeBox.serialize())", "response": "Send a juice. Box to my peer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding rows in a reduced format with one dimension per secondary dimension and all other dimensions filtered.", "response": "def dataframe(self, filtered_dims={}, unstack=False, df_class=None, add_code=False):\n        \"\"\"\n        Yield rows in a reduced format, with one dimension as an index, one measure column per\n        secondary dimension, and all other dimensions filtered.\n\n\n        :param measure: The column names of one or more measures\n        :param p_dim: The primary dimension. This will be the index of the dataframe.\n        :param s_dim: a secondary dimension. The returned frame will be unstacked on this dimension\n        :param unstack:\n        :param filtered_dims: A dict of dimension columns names that are filtered, mapped to the dimension value\n        to select.\n        :param add_code: When substitution a label for a column, also add the code value.\n        :return:\n        \"\"\"\n\n        measure = self.table.column(measure)\n        p_dim = self.table.column(p_dim)\n\n        assert measure\n        assert p_dim\n\n        if s_dim:\n            s_dim = self.table.column(s_dim)\n\n        from six import text_type\n\n        def maybe_quote(v):\n            from six import string_types\n            if isinstance(v, string_types):\n                return '\"{}\"'.format(v)\n            else:\n                return v\n\n        all_dims = [p_dim.name] + filtered_dims.keys()\n\n        if s_dim:\n            all_dims.append(s_dim.name)\n\n        if filtered_dims:\n            all_dims += filtered_dims.keys()\n\n        all_dims = [text_type(c) for c in all_dims]\n\n        # \"primary_dimensions\" means something different here, all of the dimensions in the\n        # dataset that do not have children.\n        primary_dims = [text_type(c.name) for c in self.primary_dimensions]\n\n        if set(all_dims) != set(primary_dims):\n            raise ValueError(\"The primary, secondary and filtered dimensions must cover all dimensions\" +\n                             \" {} != {}\".format(sorted(all_dims), sorted(primary_dims)))\n\n        columns = []\n\n        p_dim_label = None\n        s_dim_label = None\n\n        if p_dim.label:\n\n            # For geographic datasets, also need the gvid\n            if p_dim.type_is_gvid:\n                columns.append(p_dim.name)\n\n            p_dim = p_dim_label = p_dim.label\n            columns.append(p_dim_label.name)\n\n\n\n        else:\n            columns.append(p_dim.name)\n\n        if s_dim:\n\n            if s_dim.label:\n                s_dim = s_dim_label = s_dim.label\n                columns.append(s_dim_label.name)\n            else:\n                columns.append(s_dim.name)\n\n        columns.append(measure.name)\n\n        # Create the predicate to filter out the filtered dimensions\n        if filtered_dims:\n            code = ' and '.join(\"row.{} == {}\".format(k, maybe_quote(v)) for k, v in filtered_dims.items())\n\n            predicate = eval('lambda row: {}'.format(code))\n        else:\n            predicate = lambda row: True\n\n        df = self.analysis.dataframe(predicate, columns=columns, df_class=df_class)\n\n        if unstack:\n            # Need to set the s_dim in the index to get a hierarchical index, required for unstacking.\n            # The final df will have only the p_dim as an index.\n\n            if s_dim:\n                df = df.set_index([p_dim.name, s_dim.name])\n\n                df = df.unstack()\n\n                df.columns = df.columns.get_level_values(1)  # [' '.join(col).strip() for col in df.columns.values]\n\n            else:\n                # Can't actually unstack without a second dimension.\n                df = df.set_index(p_dim.name)\n\n            df.reset_index()\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dependency_graph_for_set(self, id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('callback'):\n            return self.get_dependency_graph_for_set_with_http_info(id, **kwargs)\n        else:\n            (data) = self.get_dependency_graph_for_set_with_http_info(id, **kwargs)\n            return data", "response": "Get the dependency graph for a Build Record Set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, search_phrase, limit=None):\n        # SQLite FTS can't find terms with `-`, therefore all hyphens were replaced with underscore\n        # before save. Now to get appropriate result we need to replace all hyphens in the search phrase.\n        # See http://stackoverflow.com/questions/3865733/how-do-i-escape-the-character-in-sqlite-fts3-queries\n        search_phrase = search_phrase.replace('-', '_')\n        query, query_params = self._make_query_from_terms(search_phrase)\n\n        self._parsed_query = (query, query_params)\n\n        connection = self.backend.library.database.connection\n        # Operate on the raw connection\n        connection.connection.create_function('rank', 1, _make_rank_func((1., .1, 0, 0)))\n\n        logger.debug('Searching datasets using `{}` query.'.format(query))\n        results = connection.execute(query,\n                                     **query_params).fetchall()  # Query on the Sqlite proxy to the raw connection\n\n        datasets = defaultdict(DatasetSearchResult)\n        for result in results:\n            vid, score = result\n            datasets[vid] = DatasetSearchResult()\n            datasets[vid].vid = vid\n            datasets[vid].b_score = score\n\n        logger.debug('Extending datasets with partitions.')\n        for partition in self.backend.partition_index.search(search_phrase):\n            datasets[partition.dataset_vid].p_score += partition.score\n            datasets[partition.dataset_vid].partitions.add(partition)\n        return list(datasets.values())", "response": "Search for datasets by search phrase."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the dataset to document indexed by to FTS index.", "response": "def _as_document(self, dataset):\n        \"\"\" Converts dataset to document indexed by to FTS index.\n\n        Args:\n            dataset (orm.Dataset): dataset to convert.\n\n        Returns:\n            dict with structure matches to BaseDatasetIndex._schema.\n\n        \"\"\"\n        assert isinstance(dataset, Dataset)\n\n        doc = super(self.__class__, self)._as_document(dataset)\n\n        # SQLite FTS can't find terms with `-`, replace it with underscore here and while searching.\n        # See http://stackoverflow.com/questions/3865733/how-do-i-escape-the-character-in-sqlite-fts3-queries\n        doc['keywords'] = doc['keywords'].replace('-', '_')\n        doc['doc'] = doc['doc'].replace('-', '_')\n        doc['title'] = doc['title'].replace('-', '_')\n        return doc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _index_document(self, document, force=False):\n        query = text(\"\"\"\n            INSERT INTO dataset_index(vid, title, keywords, doc)\n            VALUES(:vid, :title, :keywords, :doc);\n        \"\"\")\n        self.backend.library.database.connection.execute(query, **document)", "response": "Adds a document to the index."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _delete(self, vid=None):\n        query = text(\"\"\"\n            DELETE FROM dataset_index\n            WHERE vid = :vid;\n        \"\"\")\n        self.backend.library.database.connection.execute(query, vid=vid)", "response": "Deletes given dataset from index."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if dataset is already indexed otherwise returns False.", "response": "def is_indexed(self, dataset):\n        \"\"\" Returns True if dataset is already indexed. Otherwise returns False. \"\"\"\n        query = text(\"\"\"\n            SELECT vid\n            FROM dataset_index\n            WHERE vid = :vid;\n        \"\"\")\n        result = self.backend.library.database.connection.execute(query, vid=dataset.vid)\n        return bool(result.fetchall())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all(self):\n        datasets = []\n\n        query = text(\"\"\"\n            SELECT vid\n            FROM dataset_index;\"\"\")\n\n        for result in self.backend.library.database.connection.execute(query):\n            res = DatasetSearchResult()\n            res.vid = result[0]\n            res.b_score = 1\n            datasets.append(res)\n        return datasets", "response": "Returns list with all indexed datasets."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a generator that yields all indexed identifiers.", "response": "def list_documents(self, limit=None):\n        \"\"\" Generates vids of all indexed identifiers.\n\n        Args:\n            limit (int, optional): If not empty, the maximum number of results to return\n\n        Generates:\n            str: vid of the document.\n        \"\"\"\n        limit_str = ''\n        if limit:\n            try:\n                limit_str = 'LIMIT {}'.format(int(limit))\n            except (TypeError, ValueError):\n                pass\n\n        query = ('SELECT identifier FROM identifier_index ' + limit_str)\n\n        for row in self.backend.library.database.connection.execute(query).fetchall():\n            yield row['identifier']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete given identifier from index.", "response": "def _delete(self, identifier=None):\n        \"\"\" Deletes given identifier from index.\n\n        Args:\n            identifier (str): identifier of the document to delete.\n\n        \"\"\"\n        query = text(\"\"\"\n            DELETE FROM identifier_index\n            WHERE identifier = :identifier;\n        \"\"\")\n        self.backend.library.database.connection.execute(query, identifier=identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if identifier is already indexed otherwise returns False.", "response": "def is_indexed(self, identifier):\n        \"\"\" Returns True if identifier is already indexed. Otherwise returns False. \"\"\"\n        query = text(\"\"\"\n            SELECT identifier\n            FROM identifier_index\n            WHERE identifier = :identifier;\n        \"\"\")\n        result = self.backend.library.database.connection.execute(query, identifier=identifier['identifier'])\n        return bool(result.fetchall())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all(self):\n        identifiers = []\n\n        query = text(\"\"\"\n            SELECT identifier, type, name\n            FROM identifier_index;\"\"\")\n\n        for result in self.backend.library.database.connection.execute(query):\n            vid, type_, name = result\n            res = IdentifierSearchResult(\n                score=1, vid=vid, type=type_, name=name)\n            identifiers.append(res)\n        return identifiers", "response": "Returns list with all indexed identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search(self, search_phrase, limit=None):\n\n        # SQLite FTS can't find terms with `-`, therefore all hyphens replaced with underscore before save.\n        # Now to make proper query we need to replace all hyphens in the search phrase.\n        # See http://stackoverflow.com/questions/3865733/how-do-i-escape-the-character-in-sqlite-fts3-queries\n        search_phrase = search_phrase.replace('-', '_')\n        terms = SearchTermParser().parse(search_phrase)\n        from_year = terms.pop('from', None)\n        to_year = terms.pop('to', None)\n\n        query, query_params = self._make_query_from_terms(terms)\n\n        self._parsed_query = (query, query_params)\n\n        connection = self.backend.library.database.connection\n\n        connection.connection.create_function('rank', 1, _make_rank_func((1., .1, 0, 0)))\n\n        # SQLite FTS implementation does not allow to create indexes on FTS tables.\n        # see https://sqlite.org/fts3.html 1.5. Summary, p 1:\n        # ... it is not possible to create indices ...\n        #\n        # So, filter years range here.\n\n        results = connection.execute(query, query_params).fetchall()\n\n        for result in results:\n            vid, dataset_vid, score, db_from_year, db_to_year = result\n            if from_year and from_year < db_from_year:\n                continue\n            if to_year and to_year > db_to_year:\n                continue\n            yield PartitionSearchResult(\n                vid=vid, dataset_vid=dataset_vid, score=score)", "response": "Searches for partitions by search phrase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the partition to document indexed by to FTS index.", "response": "def _as_document(self, partition):\n        \"\"\" Converts partition to document indexed by to FTS index.\n\n        Args:\n            partition (orm.Partition): partition to convert.\n\n        Returns:\n            dict with structure matches to BasePartitionIndex._schema.\n\n        \"\"\"\n        doc = super(self.__class__, self)._as_document(partition)\n\n        # SQLite FTS can't find terms with `-`, replace it with underscore here and while searching.\n        # See http://stackoverflow.com/questions/3865733/how-do-i-escape-the-character-in-sqlite-fts3-queries\n        doc['keywords'] = doc['keywords'].replace('-', '_')\n        doc['doc'] = doc['doc'].replace('-', '_')\n        doc['title'] = doc['title'].replace('-', '_')\n\n        # pass time_coverage to the _index_document.\n        doc['time_coverage'] = partition.time_coverage\n        return doc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_query_from_terms(self, terms):\n\n        match_query = ''\n\n        expanded_terms = self._expand_terms(terms)\n        if expanded_terms['doc']:\n            match_query = self.backend._and_join(expanded_terms['doc'])\n\n        if expanded_terms['keywords']:\n            if match_query:\n                match_query = self.backend._and_join(\n                    [match_query, self.backend._join_keywords(expanded_terms['keywords'])])\n            else:\n                match_query = self.backend._join_keywords(expanded_terms['keywords'])\n\n        if match_query:\n            query = text(\"\"\"\n                SELECT vid, dataset_vid, rank(matchinfo(partition_index)) AS score, from_year, to_year\n                FROM partition_index\n                WHERE partition_index MATCH :match_query\n                ORDER BY score DESC;\n            \"\"\")\n            query_params = {\n                'match_query': match_query}\n        else:\n            query = text(\"\"\"\n                SELECT vid, dataset_vid, rank(matchinfo(partition_index)), from_year, to_year AS score\n                FROM partition_index\"\"\")\n            query_params = {}\n\n        return query, query_params", "response": "Creates a query for partition from decomposed search terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _index_document(self, document, force=False):\n        from ambry.util import int_maybe\n        time_coverage = document.pop('time_coverage', [])\n        from_year = None\n        to_year = None\n        if time_coverage:\n            from_year = int_maybe(time_coverage[0])\n            to_year = int_maybe(time_coverage[-1])\n\n        query = text(\"\"\"\n            INSERT INTO partition_index(vid, dataset_vid, title, keywords, doc, from_year, to_year)\n            VALUES(:vid, :dataset_vid, :title, :keywords, :doc, :from_year, :to_year); \"\"\")\n        self.backend.library.database.connection.execute(\n            query, from_year=from_year, to_year=to_year, **document)", "response": "Adds a parition document to the index."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list with vids of all indexed partitions.", "response": "def all(self):\n        \"\"\" Returns list with vids of all indexed partitions. \"\"\"\n        partitions = []\n\n        query = text(\"\"\"\n            SELECT dataset_vid, vid\n            FROM partition_index;\"\"\")\n\n        for result in self.backend.library.database.connection.execute(query):\n            dataset_vid, vid = result\n            partitions.append(PartitionSearchResult(dataset_vid=dataset_vid, vid=vid, score=1))\n        return partitions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef timedelta_seconds(td):\n    '''\n    Return the offset stored by a :class:`datetime.timedelta` object as an\n    integer number of seconds.  Microseconds, if present, are rounded to\n    the nearest second.\n\n    Delegates to\n    :meth:`timedelta.total_seconds() <datetime.timedelta.total_seconds()>`\n    if available.\n\n    >>> timedelta_seconds(timedelta(hours=1))\n    3600\n    >>> timedelta_seconds(timedelta(hours=-1))\n    -3600\n    >>> timedelta_seconds(timedelta(hours=1, minutes=30))\n    5400\n    >>> timedelta_seconds(timedelta(hours=1, minutes=30,\n    ... microseconds=300000))\n    5400\n    >>> timedelta_seconds(timedelta(hours=1, minutes=30,\n    ...\tmicroseconds=900000))\n    5401\n\n    '''\n\n    try:\n        return int(round(td.total_seconds()))\n    except AttributeError:\n        days = td.days\n        seconds = td.seconds\n        microseconds = td.microseconds\n\n        return int(round((days * 86400) + seconds + (microseconds / 1000000)))", "response": "Returns the offset stored by a datetime. timedelta object as an an\n    integer number of seconds."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a string representing the timezone offset.", "response": "def timezone(utcoffset):\n    '''\n    Return a string representing the timezone offset.\n    Remaining seconds are rounded to the nearest minute.\n\n    >>> timezone(3600)\n    '+01:00'\n    >>> timezone(5400)\n    '+01:30'\n    >>> timezone(-28800)\n    '-08:00'\n\n    '''\n\n    hours, seconds = divmod(abs(utcoffset), 3600)\n    minutes = round(float(seconds) / 60)\n\n    if utcoffset >= 0:\n        sign = '+'\n    else:\n        sign = '-'\n    return '{0}{1:02d}:{2:02d}'.format(sign, int(hours), int(minutes))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting if an ID exists within any arbitrary API", "response": "def id_exists(api, search_id):\n    \"\"\"\n    Test if an ID exists within any arbitrary API\n    :param api: api to search for search_id\n    :param search_id: id to test for\n    :return: True if an entity with ID search_id exists, false otherwise\n    \"\"\"\n    response = utils.checked_api_call(api, 'get_specific', id=search_id)\n    return response is not None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_id_by_name(api, search_name):\n    entities = api.get_all(q='name==' + \"'\" + search_name + \"'\").content\n    if entities:\n        return entities[0].id\n    return", "response": "Search for a specific object by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the difference between build and build_done states", "response": "def build_duration(self):\n        \"\"\"Return the difference between build and build_done states\"\"\"\n\n        return int(self.state.build_done) - int(self.state.build)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the difference between build and build_done states in a human readable format", "response": "def build_duration_pretty(self):\n        \"\"\"Return the difference between build and build_done states, in a human readable format\"\"\"\n        from ambry.util import pretty_time\n        from time import time\n\n        if not self.state.building:\n            return None\n\n        built = self.state.built or time()\n\n        try:\n            return pretty_time(int(built) - int(self.state.building))\n        except TypeError:  # one of the values is  None or not a number\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef built_datetime(self):\n        from datetime import datetime\n        try:\n            return datetime.fromtimestamp(self.state.build_done)\n        except TypeError:\n            # build_done is null\n            return None", "response": "Return the built time as a datetime object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the time the bundle was created as a datetime object", "response": "def new_datetime(self):\n        \"\"\"Return the time the bundle was created as a datetime object\"\"\"\n        from datetime import datetime\n\n        try:\n            return datetime.fromtimestamp(self.state.new)\n        except TypeError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the time of the last operation on the bundle as a datetime object", "response": "def last_datetime(self):\n        \"\"\"Return the time of the last operation on the bundle as a datetime object\"\"\"\n        from datetime import datetime\n\n        try:\n            return datetime.fromtimestamp(self.state.lasttime)\n        except TypeError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, session):\n        self._items[session.session_id] = session\n\n        if session.expiry is not None:\n            self._queue.push(session)", "response": "Add a session to the container."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexpires any old entries in the queue.", "response": "def expire(self, current_time=None):\n        \"\"\" Expire any old entries\n\n        @param current_time: Optional time to be used to clean up queue (can be\n                             used in unit tests)\n        \"\"\"\n        if self._queue.is_empty():\n            return\n\n        if current_time is None:\n            current_time = time.time()\n\n        while not self._queue.is_empty():\n            # Get top most item\n            top = self._queue.peek()\n\n            # Early exit if item was not promoted and its expiration time\n            # is greater than now.\n            if top.promoted is None and top.expiry_date > current_time:\n                break\n\n            # Pop item from the stack\n            top = self._queue.pop()\n\n            need_reschedule = (top.promoted is not None\n                               and top.promoted > current_time)\n\n            # Give chance to reschedule\n            if not need_reschedule:\n                top.promoted = None\n                top.on_delete(False)\n\n                need_reschedule = (top.promoted is not None\n                                   and top.promoted > current_time)\n\n            # If item is promoted and expiration time somewhere in future\n            # just reschedule it\n            if need_reschedule:\n                top.expiry_date = top.promoted\n                top.promoted = None\n                self._queue.push(top)\n            else:\n                del self._items[top.session_id]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_email(recipients, subject, message, attachments=None):\n    if not attachments:\n        attachments = []\n\n    if os.path.exists(EMAIL_SETTINGS_FILE):\n        email_settings = json.load(open(EMAIL_SETTINGS_FILE))\n        sender = email_settings.get('sender', 'ambry@localhost')\n        use_tls = email_settings.get('use_tls')\n        username = email_settings['username']\n        password = email_settings['password']\n        server = email_settings['server']\n    else:\n        # use local smtp\n        server = 'localhost'\n        username = None\n        password = None\n        sender = 'ambry@localhost'\n\n    # Create the container (outer) email message.\n    msg = MIMEMultipart()\n    msg['Subject'] = subject\n    msg['From'] = sender\n    msg['To'] = ','.join(recipients)\n    msg.attach(MIMEText(message, 'plain'))\n\n    # Add attachments.\n    for file_name in attachments:\n        if os.path.exists(file_name):\n            with open(file_name, 'r') as fp:\n                attachment = MIMEBase('application', 'text')\n                attachment.set_payload(fp.read())\n                attachment.add_header(\n                    'Content-Disposition',\n                    'attachment; filename=\"{}\"'.format(os.path.basename(file_name)))\n                msg.attach(attachment)\n\n    # The actual mail send.\n    srv = smtplib.SMTP(server)\n    if use_tls:\n        srv.starttls()\n    if username:\n        srv.login(username, password)\n\n    srv.sendmail(sender, ','.join(recipients), msg.as_string())\n    srv.quit()", "response": "Sends email.\n    Args:\n        recipients (list of str):\n        subject (str):\n        message (str):\n        attachments (list of str): list containing full paths (txt files only) to attach to email."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_product_versions(page_size=200, page_index=0, sort=\"\", q=\"\"):\n    content = list_product_versions_raw(page_size, page_index, sort, q)\n    if content:\n        return utils.format_json_list(content)", "response": "List all ProductVersions in a node"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new ProductVersion for a given Product.", "response": "def create_product_version(product_id, version, **kwargs):\n    \"\"\"\n    Create a new ProductVersion.\n    Each ProductVersion represents a supported product release stream, which includes milestones and releases typically associated with a single major.minor version of a Product.\n    Follows the Red Hat product support cycle, and typically includes Alpha, Beta, GA, and CP releases with the same major.minor version.\n\n    Example:\n    ProductVersion 1.0 includes the following releases:\n    1.0.Beta1, 1.0.GA, 1.0.1, etc.\n    \"\"\"\n    data = create_product_version_raw(product_id, version, **kwargs)\n    if data:\n        return utils.format_json(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a ProductVersion with ID id with new values.", "response": "def update_product_version(id, **kwargs):\n    \"\"\"\n    Update the ProductVersion with ID id with new values.\n    \"\"\"\n    content = update_product_version_raw(id, **kwargs)\n    if content:\n        return utils.format_json(content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepare_data(self):\n        '''\n        Method returning data passed to template.\n        Subclasses can override it.\n        '''\n        value = self.get_raw_value()\n        return dict(widget=self,\n                    field=self.field,\n                    value=value,\n                    readonly=not self.field.writable)", "response": "Method returning data passed to template.\n        Subclasses can override it.\n        Subclasses can override it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render(self):\n        '''\n        Renders widget to template\n        '''\n        data = self.prepare_data()\n        if self.field.readable:\n            return self.env.template.render(self.template, **data)\n        return ''", "response": "Renders widget to template"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _request(self, url, *,\n                 method='GET', headers=None, data=None, result_callback=None):\n        \"\"\"Perform asynchronous request.\n\n        :param str url: request URL.\n        :param str method: request method.\n        :param dict headers: request headers.\n        :param object data: JSON-encodable object.\n        :param object -> object result_callback: result callback.\n\n        :rtype: dict\n        :raise: APIError\n        \"\"\"\n\n        request = self._prepare_request(url, method, headers, data)\n\n        retries_left = self._conn_retries\n\n        while True:\n            try:\n                response = yield self._client.fetch(request)\n                try:\n                    if result_callback:\n                        return result_callback(response.body)\n                except (ValueError, TypeError) as err:\n                    raise MalformedResponse(err) from None\n\n                return response.body\n\n            except httpclient.HTTPError as err:\n                resp_body = err.response.body \\\n                    if err.response is not None else None\n                if err.code == 599:\n                    if self._conn_retries is None or retries_left <= 0:\n                        raise CommunicationError(err) from None\n                    else:\n                        retries_left -= 1\n                        retry_in = (self._conn_retries - retries_left) * 2\n                        self._log.warning('Server communication error: %s. '\n                                          'Retrying in %s seconds.', err,\n                                          retry_in)\n                        yield gen.sleep(retry_in)\n                        continue\n                elif 400 <= err.code < 500:\n                    raise ClientError(err.code, resp_body) from None\n\n                raise ServerError(err.code, resp_body) from None", "response": "Perform asynchronous request.\n\n        :param str url: request URL.\n        :param str method: request method.\n        :param dict headers: request headers.\n        :param object data: JSON-encodable object.\n        :param object -> object result_callback: result callback.\n\n        :rtype: dict\n        :raise: APIError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepare_request(self, url, method, headers, data):\n\n        request = httpclient.HTTPRequest(\n            url=url, method=method, headers=headers, body=data,\n            connect_timeout=self._connect_timeout,\n            request_timeout=self._request_timeout,\n            auth_username=self._username, auth_password=self._password,\n            client_cert=self._client_cert, client_key=self._client_key,\n            ca_certs=self._ca_certs, validate_cert=self._verify_cert)\n\n        return request", "response": "Prepare HTTP request.\n\n        :param str url: request URL.\n        :param str method: request method.\n        :param dict headers: request headers.\n        :param object data: JSON-encodable object.\n\n        :rtype: httpclient.HTTPRequest"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter(self):\n        # Note that self._reader is already initialized (in __init__) for\n        # the first input file. This is less clean than it could be, but it\n        # makes testing easier, since open() is then only called once for\n        # each input file.\n\n        count = 0\n        reader = self._reader\n        reads = iter(self.reads)\n        first = True\n\n        for blastFilename in self.blastFilenames:\n            if first:\n                # No need to check params in the first file. We already read\n                # them in and stored them in __init__.\n                first = False\n            else:\n                reader = self._getReader(blastFilename, self.scoreClass)\n                differences = checkCompatibleParams(\n                    self.params.applicationParams, reader.params)\n                if differences:\n                    raise ValueError(\n                        'Incompatible BLAST parameters found. The parameters '\n                        'in %s differ from those originally found in %s. %s' %\n                        (blastFilename, self.blastFilenames[0], differences))\n\n            for readAlignments in reader.readAlignments(reads):\n                count += 1\n                yield readAlignments\n\n        # Make sure all reads were used.\n        try:\n            read = next(reads)\n        except StopIteration:\n            pass\n        else:\n            raise ValueError(\n                'Reads iterator contained more reads than the number of BLAST '\n                'records found (%d). First unknown read id is %r.' %\n                (count, read.id))", "response": "Iterates over the file with the specified BLAST files and yields C { ReadAlignments } instances."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a read object for the given subject sequence title.", "response": "def getSubjectSequence(self, title):\n        \"\"\"\n        Obtain information about a subject sequence given its title.\n\n        This information is cached in self._subjectTitleToSubject. It can\n        be obtained from either a) an sqlite database (given via the\n        sqliteDatabaseFilename argument to __init__), b) the FASTA that was\n        originally given to BLAST (via the databaseFilename argument), or\n        c) from the BLAST database using blastdbcmd (which can be\n        unreliable - occasionally failing to find subjects that are in its\n        database).\n\n        @param title: A C{str} sequence title from a BLAST hit. Of the form\n            'gi|63148399|gb|DQ011818.1| Description...'.\n        @return: An C{AARead} or C{DNARead} instance, depending on the type of\n            BLAST database in use.\n\n        \"\"\"\n        if self.params.application in {'blastp', 'blastx'}:\n            readClass = AARead\n        else:\n            readClass = DNARead\n\n        if self._subjectTitleToSubject is None:\n            if self._databaseFilename is None:\n                if self._sqliteDatabaseFilename is None:\n                    # Fall back to blastdbcmd.  ncbidb has to be imported\n                    # as below so ncbidb.getSequence can be patched by our\n                    # test suite.\n                    from dark import ncbidb\n                    seq = ncbidb.getSequence(\n                        title, self.params.applicationParams['database'])\n                    return readClass(seq.description, str(seq.seq))\n                else:\n                    # An Sqlite3 database is used to look up subjects.\n                    self._subjectTitleToSubject = SqliteIndex(\n                        self._sqliteDatabaseFilename,\n                        fastaDirectory=self._databaseDirectory,\n                        readClass=readClass)\n            else:\n                # Build an in-memory dict to look up subjects. This only\n                # works for small databases, obviously.\n                titles = {}\n                for read in FastaReads(self._databaseFilename,\n                                       readClass=readClass):\n                    titles[read.id] = read\n                self._subjectTitleToSubject = titles\n\n        return self._subjectTitleToSubject[title]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadjusting the HSPs for plotting.", "response": "def adjustHspsForPlotting(self, titleAlignments):\n        \"\"\"\n        Our HSPs are about to be plotted. If we are using e-values, these need\n        to be adjusted.\n\n        @param titleAlignments: An instance of L{TitleAlignment}.\n        \"\"\"\n        # If we're using bit scores, there's nothing to do.\n        if self.scoreClass is HigherIsBetterScore:\n            return\n\n        # Convert all e-values to high positive values, and keep track of the\n        # maximum converted value.\n        maxConvertedEValue = None\n        zeroHsps = []\n\n        # Note: don't call self.hsps() here because that will read them\n        # from disk again, which is not what's wanted.\n        for hsp in titleAlignments.hsps():\n            if hsp.score.score == 0.0:\n                zeroHsps.append(hsp)\n            else:\n                convertedEValue = -1.0 * log10(hsp.score.score)\n                hsp.score.score = convertedEValue\n                if (maxConvertedEValue is None or\n                        convertedEValue > maxConvertedEValue):\n                    maxConvertedEValue = convertedEValue\n\n        if zeroHsps:\n            # Save values so that we can use them in self.adjustPlot\n            self._maxConvertedEValue = maxConvertedEValue\n            self._zeroEValueFound = True\n\n            # Adjust all zero e-value HSPs to have numerically high values.\n            if self.randomizeZeroEValues:\n                for hsp in zeroHsps:\n                    hsp.score.score = (maxConvertedEValue + 2 + uniform(\n                        0, ZERO_EVALUE_UPPER_RANDOM_INCREMENT))\n            else:\n                for count, hsp in enumerate(zeroHsps, start=1):\n                    hsp.score.score = maxConvertedEValue + count\n        else:\n            self._zeroEValueFound = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadjusts the plotted reads by adding a horizontal line to the plotted reads if we re plotting e - values and a zero e - value was found.", "response": "def adjustPlot(self, readsAx):\n        \"\"\"\n        Add a horizontal line to the plotted reads if we're plotting e-values\n        and a zero e-value was found.\n\n        @param readsAx: A Matplotlib sub-plot instance, as returned by\n            matplotlib.pyplot.subplot.\n        \"\"\"\n        # If we're using bit scores, there's nothing to do.\n        if self.scoreClass is HigherIsBetterScore:\n            return\n\n        if self._zeroEValueFound:\n            readsAx.axhline(y=self._maxConvertedEValue + 0.5, color='#cccccc',\n                            linewidth=0.5)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sum(self, axis=0, dtype=None):\n        if axis not in [0, 1, 'index', 'columns']:\n            raise ValueError('\"axis\" parameter must be one of 0, 1, \"index\", '\n                             'or \"columns\".')\n\n        sum_kwargs = {}\n        if dtype is not None:\n            sum_kwargs['dtype'] = dtype\n        y = self.values.sum(axis=axis, **sum_kwargs)\n\n        if axis == 0 or axis == 'index':\n            y = profile.ExpProfile(y, genes=self.cells)\n        else:\n            y = profile.ExpProfile(y, genes=self.genes)\n\n        return y", "response": "Sum over rows or columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_heatmap(self, highlight_genes=None, highlight_samples=None,\n                          highlight_color=None, **kwargs):\n        \"\"\"Generate a heatmap (`ExpHeatmap`) of the matrix.\n\n        See :class:`ExpHeatmap` constructor for keyword arguments.\n\n        Parameters\n        ----------\n        highlight_genes : list of str\n            List of genes to highlight\n        highlight_color : str\n            Color to use for highlighting\n\n        Returns\n        -------\n        `ExpHeatmap`\n            The heatmap.\n        \"\"\"\n        from .visualize import ExpHeatmap\n        from .visualize import HeatmapGeneAnnotation\n        from .visualize import HeatmapSampleAnnotation\n\n        #if highlight_genes is not None:\n        #    assert isinstance(highlight_genes, Iterable)\n        #if highlight_samples is not None:\n        #    assert isinstance(highlight_genes, Iterable)\n        if highlight_color is not None:\n            assert isinstance(highlight_color, str)\n\n        if highlight_color is None:\n            highlight_color = 'blue'\n\n        if highlight_genes is None:\n            highlight_genes = []\n\n        if highlight_samples is None:\n            highlight_samples = []\n\n        gene_annotations = kwargs.pop('gene_annotations', [])\n        for g in highlight_genes:\n            gene_annotations.append(\n                HeatmapGeneAnnotation(g, highlight_color, label=g))\n\n        sample_annotations = kwargs.pop('sample_annotations', [])\n        for s in highlight_samples:\n            sample_annotations.append(\n                HeatmapSampleAnnotation(s, highlight_color, label=s)\n            )\n\n        return ExpHeatmap(self,\n                          gene_annotations=gene_annotations,\n                          sample_annotations=sample_annotations,\n                          **kwargs)", "response": "Generates a heatmap of the matrix."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_figure(self, heatmap_kw=None, **kwargs):\n        if heatmap_kw is not None:\n            assert isinstance(heatmap_kw, dict)\n\n        if heatmap_kw is None:\n            heatmap_kw = {}\n\n        return self.get_heatmap(**heatmap_kw).get_figure(**kwargs)", "response": "Generate a plotly figure showing the matrix as a heatmap."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort_genes(self, stable=True, inplace=False, ascending=True):\n        kind = 'quicksort'\n        if stable:\n            kind = 'mergesort'\n        return self.sort_index(kind=kind, inplace=inplace, ascending=ascending)", "response": "Sort the rows of the matrix alphabetically by gene name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sort_samples(self, stable=True, inplace=False, ascending=True):\n        kind = 'quicksort'\n        if stable:\n            kind = 'mergesort'\n        return self.sort_index(axis=1, kind=kind, inplace=inplace,\n                               ascending=ascending)", "response": "Sort the columns of the matrix alphabetically by sample name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncenter the expression of each gene ( row ).", "response": "def center_genes(self, use_median=False, inplace=False):\n        \"\"\"Center the expression of each gene (row).\"\"\"\n        if use_median:\n            X = self.X - \\\n                np.tile(np.median(self.X, axis=1), (self.n, 1)).T\n        else:\n            X = self.X - \\\n                np.tile(np.mean(self.X, axis=1), (self.n, 1)).T\n\n        if inplace:\n            self.X[:,:] = X\n            matrix = self\n        else:\n            matrix = ExpMatrix(genes=self.genes, samples=self.samples,\n                               X=X)\n        return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstandardizes the expression of each gene ( row ).", "response": "def standardize_genes(self, inplace=False):\n        \"\"\"Standardize the expression of each gene (row).\"\"\"\n        matrix = self.center_genes(inplace=inplace)\n        matrix.X[:,:] = matrix.X / \\\n            np.tile(np.std(matrix.X, axis=1, ddof=1), (matrix.n, 1)).T\n        return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_genes(self, gene_names : Iterable[str], inplace=False):\n\n        return self.drop(set(self.genes) - set(gene_names),\n                         inplace=inplace)", "response": "Filter the expression matrix against a set of genes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an ExpMatrix containing all pairwise sample correlations.", "response": "def sample_correlations(self):\n        \"\"\"Returns an `ExpMatrix` containing all pairwise sample correlations.\n\n        Returns\n        -------\n        `ExpMatrix`\n            The sample correlation matrix.\n\n        \"\"\"\n        C = np.corrcoef(self.X.T)\n        corr_matrix = ExpMatrix(genes=self.samples, samples=self.samples, X=C)\n        return corr_matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_tsv(cls, file_path: str, gene_table: ExpGeneTable = None,\n                 encoding: str = 'UTF-8', sep: str = '\\t'):\n        \"\"\"Read expression matrix from a tab-delimited text file.\n\n        Parameters\n        ----------\n        file_path: str\n            The path of the text file.\n        gene_table: `ExpGeneTable` object, optional\n            The set of valid genes. If given, the genes in the text file will\n            be filtered against this set of genes. (None)\n        encoding: str, optional\n            The file encoding. (\"UTF-8\")\n        sep: str, optional\n            The separator. (\"\\t\")\n\n        Returns\n        -------\n        `ExpMatrix`\n            The expression matrix.\n        \"\"\"\n        # use pd.read_csv to parse the tsv file into a DataFrame\n        matrix = cls(pd.read_csv(file_path, sep=sep, index_col=0, header=0,\n                                 encoding=encoding))\n\n        # parse index column separately\n        # (this seems to be the only way we can prevent pandas from converting\n        #  \"nan\" or \"NaN\" to floats in the index)['1_cell_306.120', '1_cell_086.024', '1_cell_168.103']\n        #ind = pd.read_csv(file_path, sep=sep, usecols=[0, ], header=0,\n        #                  encoding=encoding, na_filter=False)\n        ind = pd.read_csv(file_path, sep=sep, usecols=[0, ], header=None,\n                          skiprows=1, encoding=encoding, na_filter=False)\n\n        matrix.index = ind.iloc[:, 0]\n        matrix.index.name = 'Genes'\n\n        if gene_table is not None:\n            # filter genes\n            matrix = matrix.filter_genes(gene_table.gene_names)\n\n        return matrix", "response": "Read an expression matrix from a tab - delimited text file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the expression matrix to a tab - delimited text file.", "response": "def write_tsv(self, file_path: str, encoding: str = 'UTF-8',\n                  sep: str = '\\t'):\n        \"\"\"Write expression matrix to a tab-delimited text file.\n\n        Parameters\n        ----------\n        file_path: str\n            The path of the output file.\n        encoding: str, optional\n            The file encoding. (\"UTF-8\")\n\n        Returns\n        -------\n        None\n        \"\"\"\n        #if six.PY2:\n        #    sep = sep.encode('UTF-8')\n\n        self.to_csv(\n            file_path, sep=sep, float_format='%.5f', mode='w',\n            encoding=encoding, quoting=csv.QUOTE_NONE\n        )\n\n        _LOGGER.info('Wrote %d x %d expression matrix to \"%s\".',\n                    self.p, self.n, file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_sparse(self, file_path: str):\n\n        coo = sparse.coo_matrix(self.X)\n        data = OrderedDict([(0, coo.row+1), (1, coo.col+1), (2, coo.data)])\n        df = pd.DataFrame(data, columns=data.keys())\n        with open(file_path, 'w') as ofh:\n            ofh.write('%%MatrixMarket matrix coordinate real general\\n')\n            ofh.write('%%%s\\n' % '\\t'.join(self.genes.astype(str)))\n            ofh.write('%%%s\\n' % '\\t'.join(self.cells.astype(str)))\n            ofh.write('%\\n')\n            ofh.write('%d %d %d\\n' % (coo.shape[0], coo.shape[1], coo.nnz))\n            df.to_csv(ofh, sep=' ', float_format='%.5f',\n                      header=None, index=None)", "response": "Write a sparse representation of the object to a tab - delimited text file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_sparse(cls, file_path: str):\n        \n        with open(file_path) as fh:\n            next(fh)  # skip header line\n            genes = next(fh)[1:-1].split('\\t')\n            cells = next(fh)[1:-1].split('\\t')\n            next(fh)\n            m, n, nnz = [int(s) for s in next(fh)[:-1].split(' ')]\n        \n        t = pd.read_csv(file_path, sep=' ', skiprows=5, header=None,\n                        dtype={0: np.uint32, 1: np.uint32})\n        \n        i = t[0].values - 1\n        j = t[1].values - 1\n        data = t[2].values\n\n        assert data.size == nnz\n\n        X = sparse.coo_matrix((data, (i,j)), shape=[m, n]).todense()\n\n        return cls(X=X, genes=genes, cells=cells)", "response": "Read a sparse representation of a tab - delimited text file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_10xgenomics(cls, tarball_fpath: str, prefix: str,\n                         use_ensembl_ids: bool = False):\n        \"\"\"Read a 10X genomics compressed tarball containing expression data.\n        \n        Note: common prefix patterns:\n        - \"filtered_gene_bc_matrices/[annotations]/\"\n        - \"filtered_matrices_mex/[annotations]/\"\n\n        TODO: docstring\"\"\"\n\n        _LOGGER.info('Reading file: %s', tarball_fpath)\n\n        with tarfile.open(tarball_fpath, mode='r:gz') as tf:\n            ti = tf.getmember('%smatrix.mtx' % prefix)\n            with tf.extractfile(ti) as fh:\n                mtx = scipy.io.mmread(fh)\n\n            ti = tf.getmember('%sgenes.tsv' % prefix)\n            with tf.extractfile(ti) as fh:\n                wrapper = io.TextIOWrapper(fh, encoding='ascii')\n                i = 1\n                if use_ensembl_ids:\n                    i = 0\n                gene_names = \\\n                        [row[i] for row in csv.reader(wrapper, delimiter='\\t')]\n\n            ti = tf.getmember('%sbarcodes.tsv' % prefix)\n            with tf.extractfile(ti) as fh:\n                wrapper = io.TextIOWrapper(fh, encoding='ascii')\n                barcodes = \\\n                        [row[0] for row in csv.reader(wrapper, delimiter='\\t')]\n\n\n            assert mtx.shape[0] == len(gene_names)\n            assert mtx.shape[1] == len(barcodes)\n        \n        _LOGGER.info('Matrix dimensions: %s', str(mtx.shape))\n        X = mtx.todense()\n        matrix = cls(X=X, genes=gene_names, cells=barcodes)\n        \n        return matrix", "response": "Read a 10X genomics compressed tarball containing expression data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning to obtain the argument parser.", "response": "def get_argument_parser():\n    \"\"\"Function to obtain the argument parser.\n\n    Parameters\n    ----------\n\n    Returns\n    -------\n    `argparse.ArgumentParser`\n        A fully configured `argparse.ArgumentParser` object.\n\n    Notes\n    -----\n    This function can also be used by the `sphinx-argparse` extension for\n    sphinx to generate documentation for this script.\n    \"\"\"\n    desc = 'Convert Entrez IDs to gene symbols.'\n    parser = cli.get_argument_parser(desc=desc)\n\n    file_mv = cli.file_mv\n\n    g = parser.add_argument_group('Input and output files')\n\n    g.add_argument('-e', '--expression-file', required=True,\n                   type=cli.str_type, metavar=file_mv,\n                   help='The expression file.')\n\n    g.add_argument('-g', '--gene-file', required=True,\n                   type=cli.str_type, metavar=file_mv,\n                   help=textwrap.dedent('''\\\n                   The gene file (e.g., generated by the\n                   ensembl_extract_protein_coding_genes.py script).'''))\n\n    g.add_argument('-c', '--entrez2gene-file', required=True,\n                   type=cli.str_type, metavar=file_mv,\n                   help=textwrap.dedent('''\\\n                   The entrez2gene file (.e.g., generated by the\n                   ncbi_extract_entrez2gene.py script).'''))\n\n    g.add_argument('-o', '--output-file', required=True,\n                   type=cli.str_type, metavar=file_mv,\n                   help='The output file.')\n\n    g = parser.add_argument_group('Conversion options')\n\n    g.add_argument('-s', '--strip-affy-suffix', action='store_true',\n                   help=textwrap.dedent('''\\\n                   Strip the suffix \"_at\" from all Entrez IDs.\n                   (For use in affymetrix microarray pipeline.)'''))\n\n    cli.add_reporting_args(parser)\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_chain(chain):\n    link = chain[0][0]\n    for i in range(1, len(chain) - 1):\n        if chain[i][1] == 'R':\n            link = hash_function(link + chain[i][0]).digest()\n        elif chain[i][1] == 'L':\n            link = hash_function(chain[i][0] + link).digest()\n        else:\n            raise MerkleError('Link %s has no side value: %s' % (str(i), str(codecs.encode(chain[i][0], 'hex_codec'))))\n    if link == chain[-1][0]:\n        return link\n    else:\n        raise MerkleError('The Merkle Chain is not valid.')", "response": "Verify a merkle chain to see if the Merkle root can be reproduced."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_hex_chain(chain):\n    return codecs.encode(check_chain([(codecs.decode(i[0], 'hex_codec'), i[1]) for i in chain]), 'hex_codec')", "response": "Verify a merkle chain with hashes hex encoded to see if the merkle root can be reproduced."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a Node based on a precomputed hex encoded hash value.", "response": "def add_hash(self, value):\n        \"\"\"Add a Node based on a precomputed, hex encoded, hash value.\n        \"\"\"\n        self.leaves.append(Node(codecs.decode(value, 'hex_codec'), prehashed=True))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(self):\n        self.root = None\n        for leaf in self.leaves:\n            leaf.p, leaf.sib, leaf.side = (None, ) * 3", "response": "Clears the Merkle Tree by releasing the Merkle root and each leaf s references."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the merkle root and make references between nodes in the tree.", "response": "def build_fun(self, layer=None):\n        \"\"\"Calculate the merkle root and make references between nodes in the tree.\n        Written in functional style purely for fun.\n        \"\"\"\n        if not layer:\n            if not self.leaves:\n                raise MerkleError('The tree has no leaves and cannot be calculated.')\n            layer = self.leaves[::]\n        layer = self._build(layer)\n        if len(layer) == 1:\n            self.root = layer[0]\n        else:\n            self.build_fun(layer=layer)\n        return self.root.val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _build(self, leaves):\n        new, odd = [], None\n        # check if even number of leaves, promote odd leaf to next level, if not\n        if len(leaves) % 2 == 1:\n            odd = leaves.pop(-1)\n        for i in range(0, len(leaves), 2):\n            newnode = Node(leaves[i].val + leaves[i + 1].val)\n            newnode.l, newnode.r = leaves[i], leaves[i + 1]\n            leaves[i].side, leaves[i + 1].side, leaves[i].p, leaves[i + 1].p = 'L', 'R', newnode, newnode\n            leaves[i].sib, leaves[i + 1].sib = leaves[i + 1], leaves[i]\n            new.append(newnode)\n        if odd:\n            new.append(odd)\n        return new", "response": "Private helper function to create the next aggregation level and put all references in place."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_chain(self, index):\n        chain = []\n        this = self.leaves[index]\n        chain.append((this.val, 'SELF'))\n        while this.p:\n            chain.append((this.sib.val, this.sib.side))\n            this = this.p\n        chain.append((this.val, 'ROOT'))\n        return chain", "response": "Assemble and return the chain leading from a given node to the merkle root of this tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_chains(self):\n        return [self.get_chain(i) for i in range(len(self.leaves))]", "response": "Assemble and return a list of all chains for all leaf nodes to the merkle root."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_hex_chain(self, index):\n        return [(codecs.encode(i[0], 'hex_codec'), i[1]) for i in self.get_chain(index)]", "response": "Assemble and return the chain leading from a given node to the merkle root of this tree\n        with hash values in hex form\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassembling and return a list of all chains for all nodes to the merkle root hex encoded.", "response": "def get_all_hex_chains(self):\n        \"\"\"Assemble and return a list of all chains for all nodes to the merkle root, hex encoded.\n        \"\"\"\n        return [[(codecs.encode(i[0], 'hex_codec'), i[1]) for i in j] for j in self.get_all_chains()]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_whole_subtrees(self):\n        subtrees = []\n        loose_leaves = len(self.leaves) - 2**int(log(len(self.leaves), 2))\n        the_node = self.root\n        while loose_leaves:\n            subtrees.append(the_node.l)\n            the_node = the_node.r\n            loose_leaves = loose_leaves - 2**int(log(loose_leaves, 2))\n        subtrees.append(the_node)\n        return subtrees", "response": "Returns an array of nodes in the tree that have balanced subtrees beneath them."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new leaf and adjust the tree without rebuilding the whole thing.", "response": "def add_adjust(self, data, prehashed=False):\n        \"\"\"Add a new leaf, and adjust the tree, without rebuilding the whole thing.\n        \"\"\"\n        subtrees = self._get_whole_subtrees()\n        new_node = Node(data, prehashed=prehashed)\n        self.leaves.append(new_node)\n        for node in reversed(subtrees):\n            new_parent = Node(node.val + new_node.val)\n            node.p, new_node.p = new_parent, new_parent\n            new_parent.l, new_parent.r = node, new_node\n            node.sib, new_node.sib = new_node, node\n            node.side, new_node.side = 'L', 'R'\n            new_node = new_node.p\n        self.root = new_node"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fold_enrichment(self):\n        expected = self.K * (self.n/float(self.N))\n        return self.k / expected", "response": "Returns the fold enrichment of the gene set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pretty_format(self, max_name_length=0):\n\n        assert isinstance(max_name_length, (int, np.integer))\n\n        if max_name_length < 0 or (1 <= max_name_length <= 2):\n            raise ValueError('max_name_length must be 0 or >= 3.')\n\n        gs_name = self.gene_set._name\n        if max_name_length > 0 and len(gs_name) > max_name_length:\n            assert max_name_length >= 3\n            gs_name = gs_name[:(max_name_length - 3)] + '...'\n\n        param_str = '(%d/%d @ %d/%d, pval=%.1e, fe=%.1fx)' \\\n                % (self.k, self.K, self.n, self.N,\n                   self.pval, self.fold_enrichment)\n\n        return '%s %s' % (gs_name, param_str)", "response": "Returns a nicely formatted string describing the result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(recordFilenames, fastaFilename, title, xRange, bitRange):\n    reads = FastaReads(fastaFilename)\n    blastReadsAlignments = BlastReadsAlignments(reads, recordFilenames)\n    filtered = blastReadsAlignments.filter(whitelist=set([title]),\n                                           negativeTitleRegex='.')\n    titlesAlignments = TitlesAlignments(filtered)\n\n    if title not in titlesAlignments:\n        print('%s: Title %r not found in BLAST output' % (sys.argv[0], title))\n        sys.exit(3)\n\n    for titleAlignment in titlesAlignments[title]:\n        for hsp in titleAlignment.hsps:\n            if ((xRange is None or (xRange[0] <= hsp.subjectEnd and\n                                    xRange[1] >= hsp.subjectStart)) and\n                (bitRange is None or (bitRange[0] <= hsp.score.score <=\n                                      bitRange[1]))):\n                print(('query: %s, start: %d, end: %d, score: %d' % (\n                       titleAlignment.read.id, hsp.subjectStart,\n                       hsp.subjectEnd, hsp.score.score)))", "response": "This function is the main function of the BLAST run. It will print reads that match in a specified X - axis and bit score range and BLAST run."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_seq(ac, start_i=None, end_i=None):\n\n    ac_dispatch = [\n        {\n            \"re\": re.compile(r\"^(?:AC|N[CGMPRTW])_|^[A-L]\\w\\d|^U\\d\"),\n            \"fetcher\": _fetch_seq_ncbi\n        },\n        {\n            \"re\": re.compile(r\"^ENS[TP]\\d+\"),\n            \"fetcher\": _fetch_seq_ensembl\n        },\n    ]\n\n    eligible_fetchers = [\n        dr[\"fetcher\"] for dr in ac_dispatch if dr[\"re\"].match(ac)\n    ]\n\n    if len(eligible_fetchers) == 0:\n        raise RuntimeError(\"No sequence fetcher for {ac}\".format(ac=ac))\n\n    if len(eligible_fetchers) >= 1:  # pragma: nocover (no way to test)\n        _logger.debug(\"Multiple sequence fetchers found for \"\n                     \"{ac}; using first\".format(ac=ac))\n\n    fetcher = eligible_fetchers[0]\n    _logger.debug(\"fetching {ac} with {f}\".format(ac=ac, f=fetcher))\n\n    try:\n        return fetcher(ac, start_i, end_i)\n    except requests.RequestException as ex:\n        raise RuntimeError(\"Failed to fetch {ac} ({ex})\".format(ac=ac, ex=ex))", "response": "Fetches sequences and subsequences from NCBI eutils and Ensembl\n    REST interfaces."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fetch_seq_ensembl(ac, start_i=None, end_i=None):\n\n    url_fmt = \"http://rest.ensembl.org/sequence/id/{ac}\"\n    url = url_fmt.format(ac=ac)\n    r = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n    r.raise_for_status()\n    seq = r.json()[\"seq\"]\n    return seq if (start_i is None or end_i is None) else seq[start_i:end_i]", "response": "Fetch the specified sequence slice from Ensembl using the public\n    REST interface."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fetch_seq_ncbi(ac, start_i=None, end_i=None):\n\n    db = \"protein\" if ac[1] == \"P\" else \"nucleotide\"\n    url_fmt = (\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?\"\n               \"db={db}&id={ac}&rettype=fasta\")\n\n    if start_i is None or end_i is None:\n        url = url_fmt.format(db=db, ac=ac)\n    else:\n        url_fmt += \"&seq_start={start}&seq_stop={stop}\"\n        url = url_fmt.format(db=db, ac=ac, start=start_i + 1, stop=end_i)\n\n    url += \"&tool={tool}&email={email}\".format(tool=ncbi_tool, email=ncbi_email)\n\n    url = _add_eutils_api_key(url)\n\n    n_retries = 0\n    while True:\n        resp = requests.get(url)\n        if resp.ok:\n            seq = \"\".join(resp.text.splitlines()[1:])\n            return seq\n        if n_retries >= retry_limit:\n            break\n        if n_retries == 0:\n            _logger.warning(\"Failed to fetch {}\".format(url))\n        sleeptime = random.randint(n_retries,3) ** n_retries\n        _logger.warning(\"Failure {}/{}; retry in {} seconds\".format(n_retries, retry_limit, sleeptime))\n        time.sleep(sleeptime)\n        n_retries += 1\n    # Falls through only on failure\n    resp.raise_for_status()", "response": "Fetch sequences from NCBI using the eutils interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd eutils api key to the query string", "response": "def _add_eutils_api_key(url):\n    \"\"\"Adds eutils api key to the query\n\n    :param url: eutils url with a query string\n    :return: url with api_key parameter set to the value of environment\n    variable 'NCBI_API_KEY' if available\n    \"\"\"\n    apikey = os.environ.get(\"NCBI_API_KEY\")\n    if apikey:\n        url += \"&api_key={apikey}\".format(apikey=apikey)\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncontents == tuple of non-sparse values", "response": "def rom(addr, dout, CONTENT):\n    ''' CONTENT == tuple of non-sparse values '''\n    @always_comb\n    def read():\n        dout.next = CONTENT[int(addr)]\n\n    return read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ram_sp_ar(clk, we, addr, di, do):\n    ''' RAM: Single-Port, Asynchronous Read '''\n\n    memL = [Signal(intbv(0)[len(di):]) for _ in range(2**len(addr))]\n\n    @always(clk.posedge)\n    def write():\n        if we:\n            memL[int(addr)].next = di\n\n    @always_comb\n    def read():\n        do.next = memL[int(addr)]\n\n    return write, read", "response": "Single - Port Asynchronous Read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ram_sdp_rf(clk, we, addrw, addrr, di, do):\n    ''' RAM: Simple-Dual-Port, Read-First '''\n\n    memL = [Signal(intbv(0)[len(di):]) for _ in range(2**len(addrr))]\n\n    @always(clk.posedge)\n    def write():\n        if we:\n            memL[int(addrw)].next = di\n        do.next = memL[int(addrr)]\n\n    return write", "response": "A function that creates a read - first ram for a given set of sources."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ram_dp_rf(clka, clkb, wea, web, addra, addrb, dia, dib, doa, dob):\n    ''' RAM: Dual-Port, Read-First '''\n\n    memL = [Signal(intbv(0)[len(dia):]) for _ in range(2**len(addra))]\n\n    @always(clka.posedge)\n    def writea():\n        if wea:\n            memL[int(addra)].next = dia\n\n        doa.next = memL[int(addra)]\n\n    @always(clkb.posedge)\n    def writeb():\n        if web:\n            memL[int(addrb)].next = dib\n\n        dob.next = memL[int(addrb)]\n\n    return writea, writeb", "response": "RAM - Dual - Port Read - First"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting ROM to Verilog format.", "response": "def convert_rom(ADDR_WIDTH=8, DATA_WIDTH=8, CONTENT=(4,5,6,7)):\n    ''' Convert ROM'''\n    addr = Signal(intbv(0)[ADDR_WIDTH:])\n    dout = Signal(intbv(0)[DATA_WIDTH:])\n    toVerilog(rom, addr, dout, CONTENT)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_ram_sp_rf(ADDR_WIDTH=8, DATA_WIDTH=8):\n    ''' Convert RAM: Single-Port, Read-First '''\n    clk = Signal(bool(0))\n    we = Signal(bool(0))\n    addr = Signal(intbv(0)[ADDR_WIDTH:])\n    di = Signal(intbv(0)[DATA_WIDTH:])\n    do = Signal(intbv(0)[DATA_WIDTH:])\n    toVerilog(ram_sp_rf, clk, we, addr, di, do)", "response": "Convert RAM: Single - Port Read - First"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_ram_sp_wf(ADDR_WIDTH=8, DATA_WIDTH=8):\n    ''' Convert RAM: Single-Port, Write-First '''\n    clk = Signal(bool(0))\n    we = Signal(bool(0))\n    addr = Signal(intbv(0)[ADDR_WIDTH:])\n    di = Signal(intbv(0)[DATA_WIDTH:])\n    do = Signal(intbv(0)[DATA_WIDTH:])\n    toVerilog(ram_sp_wf, clk, we, addr, di, do)", "response": "Convert RAM: Single - Port Write - First"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_ram_sp_ar(ADDR_WIDTH=8, DATA_WIDTH=8):\n    ''' Convert RAM: Single-Port, Asynchronous Read '''\n    clk = Signal(bool(0))\n    we = Signal(bool(0))\n    addr = Signal(intbv(0)[ADDR_WIDTH:])\n    di = Signal(intbv(0)[DATA_WIDTH:])\n    do = Signal(intbv(0)[DATA_WIDTH:])\n    toVerilog(ram_sp_ar, clk, we, addr, di, do)", "response": "Convert RAM: Single - Port Asynchronous Read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_ram_sdp_rf(ADDR_WIDTH=8, DATA_WIDTH=8):\n    ''' Convert RAM: Simple-Dual-Port, Read-First '''\n    clk = Signal(bool(0))\n    we = Signal(bool(0))\n    addrw = Signal(intbv(0)[ADDR_WIDTH:])\n    addrr = Signal(intbv(0)[ADDR_WIDTH:])\n    di = Signal(intbv(0)[DATA_WIDTH:])\n    do = Signal(intbv(0)[DATA_WIDTH:])\n    toVerilog(ram_sdp_rf, clk, we, addrw, addrr, di, do)", "response": "Convert RAM to Verilog format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_ram_sdp_wf(ADDR_WIDTH=8, DATA_WIDTH=8):\n    ''' Convert RAM: Simple-Dual-Port, Write-First '''\n    clk = Signal(bool(0))\n    we = Signal(bool(0))\n    addrw = Signal(intbv(0)[ADDR_WIDTH:])\n    addrr = Signal(intbv(0)[ADDR_WIDTH:])\n    di = Signal(intbv(0)[DATA_WIDTH:])\n    do = Signal(intbv(0)[DATA_WIDTH:])\n    toVerilog(ram_sdp_wf, clk, we, addrw, addrr, di, do)", "response": "Convert RAM to Verilog format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_ram_sdp_ar(ADDR_WIDTH=8, DATA_WIDTH=8):\n    ''' Convert RAM: Simple-Dual-Port, Asynchronous Read'''\n    clk = Signal(bool(0))\n    we = Signal(bool(0))\n    addrw = Signal(intbv(0)[ADDR_WIDTH:])\n    addrr = Signal(intbv(0)[ADDR_WIDTH:])\n    di = Signal(intbv(0)[DATA_WIDTH:])\n    do = Signal(intbv(0)[DATA_WIDTH:])\n    toVerilog(ram_sdp_ar, clk, we, addrw, addrr, di, do)", "response": "Convert RAM SDP AR to Verilog format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_ram_dp_ar(ADDR_WIDTH=8, DATA_WIDTH=8):\n    ''' Convert RAM: Dual-Port, Asynchronous Read '''\n    clka = Signal(bool(0))\n    clkb = Signal(bool(0))\n    wea = Signal(bool(0))\n    web = Signal(bool(0))\n    addra = Signal(intbv(0)[ADDR_WIDTH:])\n    addrb = Signal(intbv(0)[ADDR_WIDTH:])\n    dia = Signal(intbv(0)[DATA_WIDTH:])\n    dib = Signal(intbv(0)[DATA_WIDTH:])\n    doa = Signal(intbv(0)[DATA_WIDTH:])\n    dob = Signal(intbv(0)[DATA_WIDTH:])\n    toVerilog(ram_dp_ar, clka, clkb, wea, web, addra, addrb, dia, dib, doa, dob)", "response": "Convert RAM to Verilog format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post_to_twitter(self, message=None):\n\n        consumer = oauth2.Consumer(key=conf.TWITTER_CONSUMER_KEY,\n                                  secret=conf.TWITTER_CONSUMER_SECRET)\n        token = oauth2.Token(key=conf.TWITTER_ACCESS_TOKEN, secret=conf.TWITTER_ACCESS_SECRET)\n        client = SimpleTwitterClient(consumer=consumer, token=token)\n\n        if not message:\n            message = self.get_message()\n        \n        hash_tag = '#status'\n        \n        if conf.BASE_URL:\n            permalink = urlparse.urljoin(conf.BASE_URL, reverse('overseer:event_short', args=[self.pk]))\n            if len(message) + len(permalink) + len(hash_tag) > 138:\n                message = '%s.. %s %s' % (message[:140-4-len(hash_tag)-len(permalink)], permalink, hash_tag)\n            else:\n                message = '%s %s %s' % (message, permalink, hash_tag) \n        else:\n            if len(message) + len(hash_tag) > 139:\n                message = '%s.. %s' % (message[:140-3-len(hash_tag)], hash_tag)\n            else:\n                message = '%s %s' % (message, hash_tag)\n                \n        return client.update_status(message)", "response": "Update the status of the user to twitter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the gene ontology file associated with a GO annotation file.", "response": "def get_gaf_gene_ontology_file(path):\n    \"\"\"Extract the gene ontology file associated with a GO annotation file.\n\n    Parameters\n    ----------\n    path: str\n        The path name of the GO annotation file.\n\n    Returns\n    -------\n    str\n        The URL of the associated gene ontology file.\n    \"\"\"\n    assert isinstance(path, str)\n\n    version = None\n    with misc.smart_open_read(path, encoding='UTF-8', try_gzip=True) as fh:\n        for l in fh:\n            if l[0] != '!':\n                break\n            if l.startswith('!GO-version:'):\n                version = l.split(' ')[1]\n                break\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply(self, im):\n        from scipy.ndimage.interpolation import shift\n        return shift(im, map(lambda x: -x, self.delta), mode='nearest')", "response": "Apply an n - dimensional displacement by shifting an image or volume."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes an optimal displacement between two ndimensional arrays.", "response": "def compute(a, b):\n        \"\"\"\n        Compute an optimal displacement between two ndarrays.\n\n        Finds the displacement between two ndimensional arrays. Arrays must be\n        of the same size. Algorithm uses a cross correlation, computed efficiently\n        through an n-dimensional fft.\n\n        Parameters\n        ----------\n        a : ndarray\n            The first array\n\n        b : ndarray\n            The second array\n        \"\"\"\n        from numpy.fft import rfftn, irfftn\n        from numpy import unravel_index, argmax\n\n        # compute real-valued cross-correlation in fourier domain\n        s = a.shape\n        f = rfftn(a)\n        f *= rfftn(b).conjugate()\n        c = abs(irfftn(f, s))\n\n        # find location of maximum\n        inds = unravel_index(argmax(c), s)\n\n        # fix displacements that are greater than half the total size\n        pairs = zip(inds, a.shape)\n        # cast to basic python int for serialization\n        adjusted = [int(d - n) if d > n // 2 else int(d) for (d, n) in pairs]\n\n        return Displacement(adjusted)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing optimal displacements localized along an axis", "response": "def compute(a, b, axis):\n        \"\"\"\n        Finds optimal displacements localized along an axis\n        \"\"\"\n        delta = []\n        for aa, bb in zip(rollaxis(a, axis, 0), rollaxis(b, axis, 0)):\n            delta.append(Displacement.compute(aa, bb).delta)\n        return LocalDisplacement(delta, axis=axis)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply(self, im):\n        from scipy.ndimage.interpolation import shift\n\n        im = rollaxis(im, self.axis)\n        im.setflags(write=True)\n        for ind in range(0, im.shape[0]):\n            im[ind] = shift(im[ind],  map(lambda x: -x, self.delta[ind]), mode='nearest')\n        im = rollaxis(im, 0, self.axis+1)\n        return im", "response": "Apply axis - localized displacements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_sample_sheet(output_file, accessions, names, celfile_urls, sel=None):\n    assert isinstance(output_file, str)\n    assert isinstance(accessions, (list, tuple))\n    for acc in accessions:\n        assert isinstance(acc, str)\n    assert isinstance(names, (list, tuple))\n    for n in names:\n        assert isinstance(n, str)\n    assert isinstance(celfile_urls, (list, tuple))\n    for u in celfile_urls:\n        assert isinstance(u, str)\n    if sel is not None:\n        assert isinstance(sel, Iterable)\n        for i in sel:\n            assert isinstance(i, (int, np.integer))\n\n    with open(output_file, 'wb') as ofh:\n        writer = csv.writer(ofh, dialect='excel-tab',\n                            lineterminator=os.linesep,\n                            quoting=csv.QUOTE_NONE)\n        # write header\n        writer.writerow(['Accession', 'Name', 'CEL file name', 'CEL file URL'])\n        n = len(list(names))\n        if sel is None:\n            sel = range(n)\n        for i in sel:\n            cf = celfile_urls[i].split('/')[-1]\n            # row = [accessions[i], names[i], cf, celfile_urls[i]]\n            writer.writerow([accessions[i], names[i], cf, celfile_urls[i]])", "response": "Generate a sample sheet in tab - separated text format."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a command and return a C { CompletedProcess instance.", "response": "def execute(self, command):\n        \"\"\"\n        Execute (or simulate) a command. Add to our log.\n\n        @param command: Either a C{str} command (which will be passed to the\n            shell) or a C{list} of command arguments (including the executable\n            name), in which case the shell is not used.\n        @return: A C{CompletedProcess} instance. This has attributes such as\n            C{returncode}, C{stdout}, and C{stderr}. See pydoc subprocess.\n        \"\"\"\n        if isinstance(command, six.string_types):\n            # Can't have newlines in a command given to the shell.\n            strCommand = command = command.replace('\\n', ' ').strip()\n            shell = True\n        else:\n            strCommand = ' '.join(command)\n            shell = False\n\n        if self._dryRun:\n            self.log.append('$ ' + strCommand)\n            return\n\n        start = time()\n        self.log.extend([\n            '# Start command (shell=%s) at %s' % (shell, ctime(start)),\n            '$ ' + strCommand,\n        ])\n\n        if six.PY3:\n            try:\n                result = run(command, check=True, stdout=PIPE,\n                             stderr=PIPE, shell=shell, universal_newlines=True)\n            except CalledProcessError as e:\n                from sys import stderr\n                print('CalledProcessError:', e, file=stderr)\n                print('STDOUT:\\n%s' % e.stdout, file=stderr)\n                print('STDERR:\\n%s' % e.stderr, file=stderr)\n                raise\n        else:\n            try:\n                result = check_call(command, stdout=PIPE, stderr=PIPE,\n                                    shell=shell, universal_newlines=True)\n            except CalledProcessError as e:\n                from sys import stderr\n                print('CalledProcessError:', e, file=stderr)\n                print('Return code: %s' % e.returncode, file=stderr)\n                print('Output:\\n%s' % e.output, file=stderr)\n                raise\n\n        stop = time()\n        elapsed = (stop - start)\n        self.log.extend([\n            '# Stop command at %s' % ctime(stop),\n            '# Elapsed = %f seconds' % elapsed,\n        ])\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef NCBISequenceLinkURL(title, default=None):\n    try:\n        ref = title.split('|')[3].split('.')[0]\n    except IndexError:\n        return default\n    else:\n        return 'http://www.ncbi.nlm.nih.gov/nuccore/%s' % (ref,)", "response": "Returns the URL of a link to the info page at NCBI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an HTML A tag dispalying a link to the info page at NCBI.", "response": "def NCBISequenceLink(title, default=None):\n    \"\"\"\n    Given a sequence title, like \"gi|42768646|gb|AY516849.1| Homo sapiens\",\n    return an HTML A tag dispalying a link to the info page at NCBI.\n\n    title: the sequence title to produce an HTML link for.\n    default: the value to return if the title cannot be parsed.\n    \"\"\"\n    url = NCBISequenceLinkURL(title)\n    if url is None:\n        return default\n    else:\n        return '<a href=\"%s\" target=\"_blank\">%s</a>' % (url, title)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _sortHTML(titlesAlignments, by, limit=None):\n    out = []\n    for i, title in enumerate(titlesAlignments.sortTitles(by), start=1):\n        if limit is not None and i > limit:\n            break\n        titleAlignments = titlesAlignments[title]\n        link = NCBISequenceLink(title, title)\n        out.append(\n            '%3d: reads=%d, len=%d, max=%s median=%s<br/>'\n            '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;%s' %\n            (i, titleAlignments.readCount(), titleAlignments.subjectLength,\n             titleAlignments.bestHsp().score.score,\n             titleAlignments.medianScore(), link))\n    return HTML('<pre>' + '<br/>'.join(out) + '</pre>')", "response": "Sort the alignments in a list of strings by the given attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _writeFASTA(self, i, image):\n        if isinstance(self._titlesAlignments.readsAlignments.reads,\n                      FastqReads):\n            format_ = 'fastq'\n        else:\n            format_ = 'fasta'\n        filename = '%s/%d.%s' % (self._outputDir, i, format_)\n        titleAlignments = self._titlesAlignments[image['title']]\n        with open(filename, 'w') as fp:\n            for titleAlignment in titleAlignments:\n                fp.write(titleAlignment.read.toString(format_))\n        return format_", "response": "Write a FASTA file containing the set of reads that hit a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _writeFeatures(self, i, image):\n        basename = 'features-%d.txt' % i\n        filename = '%s/%s' % (self._outputDir, basename)\n        featureList = image['graphInfo']['features']\n        with open(filename, 'w') as fp:\n            for feature in featureList:\n                fp.write('%s\\n\\n' % feature.feature)\n        return basename", "response": "Write a text file containing the features as a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DosDateTimeToTimeTuple(dosDateTime):\n    dos_date = dosDateTime >> 16\n    dos_time = dosDateTime & 0xffff\n    day = dos_date & 0x1f\n    month = (dos_date >> 5) & 0xf\n    year = 1980 + (dos_date >> 9)\n    second = 2 * (dos_time & 0x1f)\n    minute = (dos_time >> 5) & 0x3f\n    hour = dos_time >> 11\n    return time.localtime(\n        time.mktime((year, month, day, hour, minute, second, 0, 1, -1)))", "response": "Convert an MS - DOS format date time to a Python time tuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bitScoreToEValue(bitScore, dbSize, dbSequenceCount, queryLength,\n                     lengthAdjustment):\n    \"\"\"\n    Convert a bit score to an e-value.\n\n    @param bitScore: The C{float} bit score to convert.\n    @param dbSize: The C{int} total size of the database (i.e., the sum of\n        the lengths of all sequences in the BLAST database).\n    @param dbSequenceCount: The C{int} number of sequences in the database.\n    @param queryLength: The C{int} length of the query.\n    @param lengthAdjustment: The C{int} length adjustment (BLAST XML output\n        calls this the Statistics_hsp-len).\n    @return: A C{float} e-value.\n    \"\"\"\n    effectiveDbSize = (\n        (dbSize - dbSequenceCount * lengthAdjustment) *\n        (queryLength - lengthAdjustment)\n    )\n    return effectiveDbSize * (2.0 ** (-1.0 * bitScore))", "response": "Convert a bit score to an e - value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eValueToBitScore(eValue, dbSize, dbSequenceCount, queryLength,\n                     lengthAdjustment):\n    \"\"\"\n    Convert an e-value to a bit score.\n\n    @param eValue: The C{float} e-value to convert.\n    @param dbSize: The C{int} total size of the database (i.e., the sum of\n        the lengths of all sequences in the BLAST database).\n    @param dbSequenceCount: The C{int} number of sequences in the database.\n    @param queryLength: The C{int} length of the query.\n    @param lengthAdjustment: The C{int} length adjustment (BLAST XML output\n        calls this the Statistics_hsp-len).\n    @return: A C{float} bit score.\n    \"\"\"\n    effectiveDbSize = (\n        (dbSize - dbSequenceCount * lengthAdjustment) *\n        (queryLength - lengthAdjustment)\n    )\n    return -1.0 * (log(eValue / effectiveDbSize) / _LOG2)", "response": "Convert an e - value to a bit score."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a BTOP string and return a generator that yields integers and 2 - tuples of the sequence of integers and 2 - tuples of the subject letters and the corresponding BTOP letters.", "response": "def parseBtop(btopString):\n    \"\"\"\n    Parse a BTOP string.\n\n    The format is described at https://www.ncbi.nlm.nih.gov/books/NBK279682/\n\n    @param btopString: A C{str} BTOP sequence.\n    @raise ValueError: If C{btopString} is not valid BTOP.\n    @return: A generator that yields a series of integers and 2-tuples of\n        letters, as found in the BTOP string C{btopString}.\n    \"\"\"\n    isdigit = str.isdigit\n    value = None\n    queryLetter = None\n    for offset, char in enumerate(btopString):\n        if isdigit(char):\n            if queryLetter is not None:\n                raise ValueError(\n                    'BTOP string %r has a query letter %r at offset %d with '\n                    'no corresponding subject letter' %\n                    (btopString, queryLetter, offset - 1))\n            value = int(char) if value is None else value * 10 + int(char)\n        else:\n            if value is not None:\n                yield value\n                value = None\n                queryLetter = char\n            else:\n                if queryLetter is None:\n                    queryLetter = char\n                else:\n                    if queryLetter == '-' and char == '-':\n                        raise ValueError(\n                            'BTOP string %r has two consecutive gaps at '\n                            'offset %d' % (btopString, offset - 1))\n                    elif queryLetter == char:\n                        raise ValueError(\n                            'BTOP string %r has two consecutive identical %r '\n                            'letters at offset %d' %\n                            (btopString, char, offset - 1))\n                    yield (queryLetter, char)\n                    queryLetter = None\n\n    if value is not None:\n        yield value\n    elif queryLetter is not None:\n        raise ValueError(\n            'BTOP string %r has a trailing query letter %r with '\n            'no corresponding subject letter' % (btopString, queryLetter))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncounts the query and subject gaps in a BTOP string.", "response": "def countGaps(btopString):\n    \"\"\"\n    Count the query and subject gaps in a BTOP string.\n\n    @param btopString: A C{str} BTOP sequence.\n    @raise ValueError: If L{parseBtop} finds an error in the BTOP string\n        C{btopString}.\n    @return: A 2-tuple of C{int}s, with the (query, subject) gaps counts as\n        found in C{btopString}.\n    \"\"\"\n    queryGaps = subjectGaps = 0\n    for countOrMismatch in parseBtop(btopString):\n        if isinstance(countOrMismatch, tuple):\n            queryChar, subjectChar = countOrMismatch\n            queryGaps += int(queryChar == '-')\n            subjectGaps += int(subjectChar == '-')\n\n    return (queryGaps, subjectGaps)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a BTOP string to a CIGAR string.", "response": "def btop2cigar(btopString, concise=False, aa=False):\n    \"\"\"\n    Convert a BTOP string to a CIGAR string.\n\n    @param btopString: A C{str} BTOP sequence.\n    @param concise: If C{True}, use 'M' for matches and mismatches instead\n        of the more specific 'X' and '='.\n    @param aa: If C{True}, C{btopString} will be interpreted as though it\n        refers to amino acids (as in the BTOP string produced by DIAMOND).\n        In that case, it is not possible to use the 'precise' CIGAR characters\n        because amino acids have multiple codons so we cannot know whether\n        an amino acid match is due to an exact nucleotide matches or not.\n        Also, the numbers in the BTOP string will be multiplied by 3 since\n        they refer to a number of amino acids matching.\n    @raise ValueError: If L{parseBtop} finds an error in C{btopString} or\n        if C{aa} and C{concise} are both C{True}.\n    @return: A C{str} CIGAR string.\n    \"\"\"\n    if aa and concise:\n        raise ValueError('aa and concise cannot both be True')\n\n    result = []\n    thisLength = thisOperation = currentLength = currentOperation = None\n\n    for item in parseBtop(btopString):\n        if isinstance(item, int):\n            thisLength = item\n            thisOperation = CEQUAL if concise else CMATCH\n        else:\n            thisLength = 1\n            query, reference = item\n            if query == '-':\n                # The query has a gap. That means that in matching the\n                # query to the reference a deletion is needed in the\n                # reference.\n                assert reference != '-'\n                thisOperation = CDEL\n            elif reference == '-':\n                # The reference has a gap. That means that in matching the\n                # query to the reference an insertion is needed in the\n                # reference.\n                thisOperation = CINS\n            else:\n                # A substitution was needed.\n                assert query != reference\n                thisOperation = CDIFF if concise else CMATCH\n\n        if thisOperation == currentOperation:\n            currentLength += thisLength\n        else:\n            if currentOperation:\n                result.append(\n                    '%d%s' %\n                    ((3 * currentLength) if aa else currentLength,\n                     currentOperation))\n            currentLength, currentOperation = thisLength, thisOperation\n\n    # We reached the end of the BTOP string. If there was an operation\n    # underway, emit it.  The 'if' here should only be needed to catch the\n    # case where btopString was empty.\n    assert currentOperation or btopString == ''\n    if currentOperation:\n        result.append(\n            '%d%s' %\n            ((3 * currentLength) if aa else currentLength, currentOperation))\n\n    return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef progress_callback(self, action, node, elapsed_time=None):\n        if action == 'load_start':\n            self.stdout.write('Loading fixture {}.{}...'.format(*node),\n                              ending='')\n            self.stdout.flush()\n        elif action == 'load_success':\n            message = 'SUCCESS'\n            if elapsed_time:\n                message += ' ({:.03} seconds) '.format(elapsed_time)\n\n            self.stdout.write(message)", "response": "Callback to report progress of load fixture."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a nicely formatted string with the GO term information.", "response": "def get_pretty_format(self, include_id=True, max_name_length=0,\n                          abbreviate=True):\n        \"\"\"Returns a nicely formatted string with the GO term information.\n\n        Parameters\n        ----------\n        include_id: bool, optional\n            Include the GO term ID.\n        max_name_length: int, optional\n            Truncate the formatted string so that its total length does not\n            exceed this value.\n        abbreviate: bool, optional\n            Do not use abberviations (see ``_abbrev``) to shorten the GO term\n            name.\n\n        Returns\n        -------\n        str\n            The formatted string.\n        \"\"\"\n        name = self.name\n        if abbreviate:\n            for abb in self._abbrev:\n                name = re.sub(abb[0], abb[1], name)\n        if 3 <= max_name_length < len(name):\n            name = name[:(max_name_length-3)] + '...'\n        if include_id:\n            return \"%s: %s (%s)\" % (self.domain_short, name, self.id)\n        else:\n            return \"%s: %s\" % (self.domain_short, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quantile_normalize(matrix, inplace=False, target=None):\n    assert isinstance(matrix, ExpMatrix)\n    assert isinstance(inplace, bool)\n    if target is not None:\n        assert isinstance(target, np.ndarray) and \\\n               np.issubdtype(target.dtype, np.float)\n\n    if not inplace:\n        # make a copy of the original data\n        matrix = matrix.copy()\n\n    X = matrix.X\n    _, n = X.shape\n    nan = []\n     # fill in missing values with evenly spaced quantiles\n    for j in range(n):\n        nan.append(np.nonzero(np.isnan(X[:, j]))[0])\n        if nan[j].size > 0:\n            q = np.arange(1, nan[j].size + 1, dtype=np.float64) / \\\n                (nan[j].size + 1.0)\n            fill = np.nanpercentile(X[:, j], 100 * q)\n            X[nan[j], j] = fill\n\n    # generate sorting indices\n    A = np.argsort(X, axis=0, kind='mergesort')  # mergesort is stable\n\n    # reorder matrix\n    for j in range(n):\n        matrix.iloc[:, j] = matrix.X[A[:, j], j]\n\n    # determine target distribution\n    if target is None:\n        # No target distribution is specified, calculate one based on the\n        # expression matrix.\n        target = np.mean(matrix.X, axis=1)\n    else:\n        # Use specified target distribution (after sorting).\n        target = np.sort(target)\n\n    # generate indices to reverse sorting\n    A = np.argsort(A, axis=0, kind='mergesort')  # mergesort is stable\n\n    # quantile-normalize\n    for j in range(n):\n        matrix.iloc[:, j] = target[A[:, j]]\n\n    # set missing values to NaN again\n    for j in range(n):\n        if nan[j].size > 0:\n            matrix.iloc[nan[j], j] = np.nan\n\n    return matrix", "response": "This function normalizes the given matrix by applying quantile normalization to the evenly spaced quantiles."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a C { dictionary representation of the HSP.", "response": "def toDict(self):\n        \"\"\"\n        Get information about the HSP as a dictionary.\n\n        @return: A C{dict} representation of the HSP.\n        \"\"\"\n        result = _Base.toDict(self)\n        result['score'] = self.score.score\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an argument parser object for the script.", "response": "def get_argument_parser():\n    \"\"\"Returns an argument parser object for the script.\"\"\"\n\n    desc = 'Filter FASTA file by chromosome names.'\n    parser = cli.get_argument_parser(desc=desc)\n\n    parser.add_argument(\n        '-f', '--fasta-file', default='-', type=str, help=textwrap.dedent(\"\"\"\\\n                Path of the FASTA file. The file may be gzip'ed.\n                If set to ``-``, read from ``stdin``.\"\"\"))\n\n    parser.add_argument(\n        '-s', '--species', type=str,\n        choices=sorted(ensembl.SPECIES_CHROMPAT.keys()),\n        default='human', help=textwrap.dedent(\"\"\"\\\n            Species for which to extract genes. (This parameter is ignored\n            if ``--chromosome-pattern`` is specified.)\"\"\")\n    )\n\n    parser.add_argument(\n        '-c', '--chromosome-pattern', type=str, required=False,\n        default=None, help=textwrap.dedent(\"\"\"\\\n            Regular expression that chromosome names have to match.\n            If not specified, determine pattern based on the setting of\n            ``--species``.\"\"\")\n    )\n\n    parser.add_argument(\n        '-o', '--output-file', type=str, required=True,\n        help=textwrap.dedent(\"\"\"\\\n            Path of output file. If set to ``-``, print to ``stdout``,\n            and redirect logging messages to ``stderr``.\"\"\"))\n\n    parser = cli.add_reporting_args(parser)\n    \n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_json_content_type(req, app):\n    res = req.get_response(app, catch_exc_info=True)\n    res.content_type = 'application/json; charset=utf-8'\n    return res", "response": "Ensure that the response content - type is json."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_app(global_conf, **app_conf):\n    # Configure the environment and fill conf dictionary.\n    environment.load_environment(global_conf, app_conf)\n\n    # Dispatch request to controllers.\n    app = controllers.make_router()\n\n    # Init request-dependant environment\n    app = set_application_url(app)\n\n    # CUSTOM MIDDLEWARE HERE (filtered by error handling middlewares)\n\n    # Handle Python exceptions\n    if not conf['debug']:\n        def json_error_template(head_html, exception, extra):\n            error_json = {\n                'code': 500,\n                'hint': u'See the HTTP server log to see the exception traceback.',\n                'message': exception,\n                }\n            if head_html:\n                error_json['head_html'] = head_html\n            if extra:\n                error_json['extra'] = extra\n            return json.dumps({'error': error_json})\n        weberror.errormiddleware.error_template = json_error_template\n        app = weberror.errormiddleware.ErrorMiddleware(app, global_conf, **conf['errorware'])\n\n    app = ensure_json_content_type(app)\n    app = add_x_api_version_header(app)\n\n    if conf['debug'] and ipdb is not None:\n        app = launch_debugger_on_exception(app)\n\n    return app", "response": "Create a WSGI application and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator that yields n - tuples of coordinates to fill the dimensions.", "response": "def dimensionalIterator(dimensions, maxItems=-1):\n    \"\"\"\n    Given a list of n positive integers, return a generator that yields\n    n-tuples of coordinates to 'fill' the dimensions. This is like an\n    odometer in a car, but the dimensions do not each have to be 10.\n\n    For example: dimensionalIterator((2, 3)) will yield in order\n    (0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2). See the tests in\n    test_dimension.py for many more examples.\n\n    A dimension may also be given as '*', to provide a dimension that is\n    never exhausted. For example, dimensionalIterator(('*', 2)) yields the\n    infinite series (0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1), ....\n\n    maxItems can be used to limit the number of tuples yielded.\n    \"\"\"\n    nDimensions = len(dimensions)\n    if nDimensions == 0 or maxItems == 0:\n        return\n    if any(map(lambda x: x != '*' and x <= 0, dimensions)):\n        raise ValueError\n    odometer = [0, ] * nDimensions\n    while maxItems != 0:\n        yield tuple(odometer)\n        maxItems -= 1\n        wheel = nDimensions - 1\n        while (dimensions[wheel] != '*' and\n               odometer[wheel] == dimensions[wheel] - 1 and\n               wheel >= 0):\n            odometer[wheel] = 0\n            wheel -= 1\n        if wheel < 0:\n            return\n        odometer[wheel] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats a DNA match as a string.", "response": "def matchToString(dnaMatch, read1, read2, matchAmbiguous=True, indent='',\n                  offsets=None):\n    \"\"\"\n    Format a DNA match as a string.\n\n    @param dnaMatch: A C{dict} returned by C{compareDNAReads}.\n    @param read1: A C{Read} instance or an instance of one of its subclasses.\n    @param read2: A C{Read} instance or an instance of one of its subclasses.\n    @param matchAmbiguous: If C{True}, ambiguous nucleotides that are\n        possibly correct were counted as actually being correct. Otherwise,\n        the match was done strictly, insisting that only non-ambiguous\n        nucleotides could contribute to the matching nucleotide count.\n    @param indent: A C{str} to indent all returned lines with.\n    @param offsets: If not C{None}, a C{set} of offsets of interest that were\n        only considered when making C{match}.\n    @return: A C{str} describing the match.\n    \"\"\"\n    match = dnaMatch['match']\n    identicalMatchCount = match['identicalMatchCount']\n    ambiguousMatchCount = match['ambiguousMatchCount']\n    gapMismatchCount = match['gapMismatchCount']\n    gapGapMismatchCount = match['gapGapMismatchCount']\n    nonGapMismatchCount = match['nonGapMismatchCount']\n\n    if offsets:\n        len1 = len2 = len(offsets)\n    else:\n        len1, len2 = map(len, (read1, read2))\n\n    result = []\n    append = result.append\n\n    append(countPrint('%sExact matches' % indent, identicalMatchCount,\n                      len1, len2))\n    append(countPrint('%sAmbiguous matches' % indent, ambiguousMatchCount,\n                      len1, len2))\n    if ambiguousMatchCount and identicalMatchCount:\n        anyMatchCount = identicalMatchCount + ambiguousMatchCount\n        append(countPrint('%sExact or ambiguous matches' % indent,\n                          anyMatchCount, len1, len2))\n\n    mismatchCount = (gapMismatchCount + gapGapMismatchCount +\n                     nonGapMismatchCount)\n    append(countPrint('%sMismatches' % indent, mismatchCount, len1, len2))\n    conflicts = 'conflicts' if matchAmbiguous else 'conflicts or ambiguities'\n    append(countPrint('%s  Not involving gaps (i.e., %s)' % (indent,\n                      conflicts), nonGapMismatchCount, len1, len2))\n    append(countPrint('%s  Involving a gap in one sequence' % indent,\n                      gapMismatchCount, len1, len2))\n    append(countPrint('%s  Involving a gap in both sequences' % indent,\n                      gapGapMismatchCount, len1, len2))\n\n    for read, key in zip((read1, read2), ('read1', 'read2')):\n        append('%s  Id: %s' % (indent, read.id))\n        length = len(read)\n        append('%s    Length: %d' % (indent, length))\n        gapCount = len(dnaMatch[key]['gapOffsets'])\n        append(countPrint('%s    Gaps' % indent, gapCount, length))\n        if gapCount:\n            append(\n                '%s    Gap locations (1-based): %s' %\n                (indent,\n                 ', '.join(map(lambda offset: str(offset + 1),\n                               sorted(dnaMatch[key]['gapOffsets'])))))\n        ambiguousCount = len(dnaMatch[key]['ambiguousOffsets'])\n        append(countPrint('%s    Ambiguous' % indent, ambiguousCount, length))\n        extraCount = dnaMatch[key]['extraCount']\n        if extraCount:\n            append(countPrint('%s    Extra nucleotides at end' % indent,\n                              extraCount, length))\n\n    return '\\n'.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compareDNAReads(read1, read2, matchAmbiguous=True, gapChars='-',\n                    offsets=None):\n    \"\"\"\n    Compare two DNA sequences.\n\n    @param read1: A C{Read} instance or an instance of one of its subclasses.\n    @param read2: A C{Read} instance or an instance of one of its subclasses.\n    @param matchAmbiguous: If C{True}, count ambiguous nucleotides that are\n        possibly correct as actually being correct, and score these in the\n        ambiguousMatchCount. Otherwise, we are strict and insist that only\n        non-ambiguous nucleotides can contribute to the matching nucleotide\n        count.\n    @param gapChars: An object supporting __contains__ with characters that\n        should be considered to be gaps.\n    @param offsets: If not C{None}, a C{set} of offsets of interest. Offsets\n        not in the set will not be considered.\n    @return: A C{dict} with information about the match and the individual\n        sequences (see below).\n    \"\"\"\n    identicalMatchCount = ambiguousMatchCount = 0\n    gapMismatchCount = nonGapMismatchCount = gapGapMismatchCount = 0\n    read1ExtraCount = read2ExtraCount = 0\n    read1GapOffsets = []\n    read2GapOffsets = []\n    read1AmbiguousOffsets = []\n    read2AmbiguousOffsets = []\n    empty = set()\n\n    def _identicalMatch(a, b):\n        return a == b and len(AMBIGUOUS[a]) == 1\n\n    def _ambiguousMatch(a, b, matchAmbiguous):\n        \"\"\"\n        Checks if two characters match ambiguously if matchAmbiguous is True.\n        A match is an ambiguous match if it is not an identical match, but the\n        sets of ambiguous characters overlap.\n        \"\"\"\n        return (matchAmbiguous and\n                not _identicalMatch(a, b) and\n                AMBIGUOUS.get(a, empty) & AMBIGUOUS.get(b, empty))\n\n    for offset, (a, b) in enumerate(zip_longest(read1.sequence.upper(),\n                                                read2.sequence.upper())):\n        # Use 'is not None' in the following to allow an empty offsets set\n        # to be passed.\n        if offsets is not None and offset not in offsets:\n            continue\n        if len(AMBIGUOUS.get(a, '')) > 1:\n            read1AmbiguousOffsets.append(offset)\n        if len(AMBIGUOUS.get(b, '')) > 1:\n            read2AmbiguousOffsets.append(offset)\n        if a is None:\n            # b has an extra character at its end (it cannot be None).\n            assert b is not None\n            read2ExtraCount += 1\n            if b in gapChars:\n                read2GapOffsets.append(offset)\n        elif b is None:\n            # a has an extra character at its end.\n            read1ExtraCount += 1\n            if a in gapChars:\n                read1GapOffsets.append(offset)\n        else:\n            # We have a character from both sequences (they could still be\n            # gap characters).\n            if a in gapChars:\n                read1GapOffsets.append(offset)\n                if b in gapChars:\n                    # Both are gaps. This can happen (though hopefully not\n                    # if the sequences were pairwise aligned).\n                    gapGapMismatchCount += 1\n                    read2GapOffsets.append(offset)\n                else:\n                    # a is a gap, b is not.\n                    gapMismatchCount += 1\n            else:\n                if b in gapChars:\n                    # b is a gap, a is not.\n                    gapMismatchCount += 1\n                    read2GapOffsets.append(offset)\n                else:\n                    # Neither is a gap character.\n                    if _identicalMatch(a, b):\n                        identicalMatchCount += 1\n                    elif _ambiguousMatch(a, b, matchAmbiguous):\n                        ambiguousMatchCount += 1\n                    else:\n                        nonGapMismatchCount += 1\n\n    return {\n        'match': {\n            'identicalMatchCount': identicalMatchCount,\n            'ambiguousMatchCount': ambiguousMatchCount,\n            'gapMismatchCount': gapMismatchCount,\n            'gapGapMismatchCount': gapGapMismatchCount,\n            'nonGapMismatchCount': nonGapMismatchCount,\n        },\n        'read1': {\n            'ambiguousOffsets': read1AmbiguousOffsets,\n            'extraCount': read1ExtraCount,\n            'gapOffsets': read1GapOffsets,\n        },\n        'read2': {\n            'ambiguousOffsets': read2AmbiguousOffsets,\n            'extraCount': read2ExtraCount,\n            'gapOffsets': read2GapOffsets,\n        },\n    }", "response": "Compares two DNA sequences and returns a C { dict } with information about the match and the individual sequence that are in the same base."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef findKozakConsensus(read):\n    readLen = len(read)\n    if readLen > 9:\n        offset = 6\n        readSeq = read.sequence\n        while offset < readLen - 3:\n            triplet = readSeq[offset:offset + 3]\n            if triplet == 'ATG':\n                if readSeq[offset + 3] == 'G':\n                    if readSeq[offset - 3] in 'GA':\n                        kozakQualityCount = sum((\n                            readSeq[offset - 1] == 'C',\n                            readSeq[offset - 2] == 'C',\n                            readSeq[offset - 4] == 'C',\n                            readSeq[offset - 5] == 'C',\n                            readSeq[offset - 6] == 'G'))\n\n                        kozakQualityPercent = kozakQualityCount / 5.0 * 100\n                        yield DNAKozakRead(read, offset - 6, offset + 4,\n                                           kozakQualityPercent)\n            offset += 1", "response": "This function returns a generator that yields a DNAKozakRead instance for each element in the DNA sequence that is most frequently found at the given positions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking for simple consistency between the FASTA file and the JSON files.", "response": "def check(fastaFile, jsonFiles):\n    \"\"\"\n    Check for simple consistency between the FASTA file and the JSON files.\n\n    Note that some checking is already performed by the BlastReadsAlignments\n    class. That includes checking the number of reads matches the number of\n    BLAST records and that read ids and BLAST record read ids match.\n\n    @param jsonFiles: A C{list} of names of our BLAST JSON. These may\n        may be compressed (as bz2).\n    @param fastaFile: The C{str} name of a FASTA-containing file.\n    \"\"\"\n    reads = FastaReads(fastaFile)\n    readsAlignments = BlastReadsAlignments(reads, jsonFiles)\n    for index, readAlignments in enumerate(readsAlignments):\n\n        # Check that all the alignments in the BLAST JSON do not have query\n        # sequences or query offsets that are greater than the length of\n        # the sequence given in the FASTA file.\n        fastaLen = len(readAlignments.read)\n        for readAlignment in readAlignments:\n            for hsp in readAlignment.hsps:\n                # The FASTA sequence should be at least as long as the\n                # query in the JSON BLAST record (minus any gaps).\n                assert (fastaLen >=\n                        len(hsp.query) - hsp.query.count('-')), (\n                    'record %d: FASTA len %d < HSP query len %d.\\n'\n                    'FASTA: %s\\nQuery match: %s' % (\n                        index, fastaLen, len(hsp.query),\n                        readAlignments.read.sequence, hsp.query))\n                # The FASTA sequence length should be larger than either of\n                # the query offsets mentioned in the JSON BLAST\n                # record. That's because readStart and readEnd are offsets\n                # into the read - so they can't be bigger than the read\n                # length.\n                #\n                # TODO: These asserts should be more informative when they\n                # fail.\n                assert fastaLen >= hsp.readEnd >= hsp.readStart, (\n                    'record %d: FASTA len %d not greater than both read '\n                    'offsets (%d - %d), or read offsets are non-increasing. '\n                    'FASTA: %s\\nQuery match: %s' % (\n                        index, fastaLen, hsp.readStart, hsp.readEnd,\n                        readAlignments.read.sequence, hsp.query))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the best identity threshold for a given nucleotide identity.", "response": "def thresholdForIdentity(identity, colors):\n    \"\"\"\n    Get the best identity threshold for a specific identity value.\n\n    @param identity: A C{float} nucleotide identity.\n    @param colors: A C{list} of (threshold, color) tuples, where threshold is a\n        C{float} and color is a C{str} to be used as a cell background. This\n        is as returned by C{parseColors}.\n    @return: The first C{float} threshold that the given identity is at least\n        as big as.\n    \"\"\"\n    for threshold, _ in colors:\n        if identity >= threshold:\n            return threshold\n    raise ValueError('This should never happen! Last threshold is not 0.0?')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses command line color information.", "response": "def parseColors(colors, defaultColor):\n    \"\"\"\n    Parse command line color information.\n\n    @param colors: A C{list} of space separated \"value color\" strings, such as\n        [\"0.9 red\", \"0.75 rgb(23, 190, 207)\", \"0.1 #CF3CF3\"].\n    @param defaultColor: The C{str} color to use for cells that do not reach\n        the identity fraction threshold of any color in C{colors}.\n    @return: A C{list} of (threshold, color) tuples, where threshold is a\n        C{float} (from C{colors}) and color is a C{str} (from C{colors}). The\n        list will be sorted by decreasing threshold values.\n    \"\"\"\n    result = []\n    if colors:\n        for colorInfo in colors:\n            fields = colorInfo.split(maxsplit=1)\n            if len(fields) == 2:\n                threshold, color = fields\n                try:\n                    threshold = float(threshold)\n                except ValueError:\n                    print('--color arguments must be given as space-separated '\n                          'pairs of \"value color\" where the value is a '\n                          'numeric identity threshold. Your value %r is not '\n                          'numeric.' % threshold, file=sys.stderr)\n                    sys.exit(1)\n                if 0.0 > threshold > 1.0:\n                    print('--color arguments must be given as space-separated '\n                          'pairs of \"value color\" where the value is a '\n                          'numeric identity threshold from 0.0 to 1.0. Your '\n                          'value %r is not in that range.' % threshold,\n                          file=sys.stderr)\n                    sys.exit(1)\n\n                result.append((threshold, color))\n            else:\n                print('--color arguments must be given as space-separated '\n                      'pairs of \"value color\". You have given %r, which does '\n                      'not contain a space.' % colorInfo, file=sys.stderr)\n                sys.exit(1)\n\n    result.sort(key=itemgetter(0), reverse=True)\n\n    if not result or result[-1][0] > 0.0:\n        result.append((0.0, defaultColor))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all read lengths excluding gap characters.", "response": "def getReadLengths(reads, gapChars):\n    \"\"\"\n    Get all read lengths, excluding gap characters.\n\n    @param reads: A C{Reads} instance.\n    @param gapChars: A C{str} of sequence characters considered to be gaps.\n    @return: A C{dict} keyed by read id, with C{int} length values.\n    \"\"\"\n    gapChars = set(gapChars)\n    result = {}\n    for read in reads:\n        result[read.id] = len(read) - sum(\n            character in gapChars for character in read.sequence)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef explanation(matchAmbiguous, concise, showLengths, showGaps, showNs):\n    result = [\"\"\"\n<h1>Sequence versus sequence identity table</h1>\n\n<p>\n\nThe table cells below show the nucleotide identity fraction for the sequences\n(<span class=\"best\">like this</span> for the best value in each row). The\nidentity fraction numerator is the sum of the number of identical\n    \"\"\"]\n\n    if matchAmbiguous:\n        result.append('nucleotides plus the number of ambiguously matching '\n                      'nucleotides.')\n    else:\n        result.append('nucleotides.')\n\n    result.append(\"\"\"The denominator\nis the length of the sequence <em>for the row</em>. Sequence gaps\nare not included when calculating their lengths.\n\n</p>\n    \"\"\")\n\n    if showLengths or showGaps or showNs or matchAmbiguous or not concise:\n        result.append(\"\"\"\n<p>\n\nKey to abbreviations:\n  <ul>\n    \"\"\")\n\n        if showLengths:\n            result.append('<li>L: sequence Length.</li>')\n\n        if showGaps:\n            result.append('<li>G: number of Gaps in sequence.</li>')\n\n        if showNs:\n            result.append('<li>N: number of N characters in sequence.</li>')\n\n        if not concise:\n            result.append('<li>IM: Identical nucleotide Matches.</li>')\n\n        if matchAmbiguous:\n            result.append('<li>AM: Ambiguous nucleotide Matches.</li>')\n\n        result.append(\"\"\"\n    <li>GG: Gap/Gap matches (both sequences have gaps).</li>\n    <li>G?: Gap/Non-gap mismatches (one sequence has a gap).</li>\n    <li>NE: Non-equal nucleotide mismatches.</li>\n  </ul>\n</p>\n\"\"\")\n\n    return '\\n'.join(result)", "response": "Make an explanation of the output HTML table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollect pairwise matching statistics for two sets of reads.", "response": "def collectData(reads1, reads2, square, matchAmbiguous):\n    \"\"\"\n    Get pairwise matching statistics for two sets of reads.\n\n    @param reads1: An C{OrderedDict} of C{str} read ids whose values are\n        C{Read} instances. These will be the rows of the table.\n    @param reads2: An C{OrderedDict} of C{str} read ids whose values are\n        C{Read} instances. These will be the columns of the table.\n    @param square: If C{True} we are making a square table of a set of\n        sequences against themselves (in which case we show nothing on the\n        diagonal).\n    @param matchAmbiguous: If C{True}, count ambiguous nucleotides that are\n        possibly correct as actually being correct. Otherwise, we are strict\n        and insist that only non-ambiguous nucleotides can contribute to the\n        matching nucleotide count.\n    \"\"\"\n    result = defaultdict(dict)\n    for id1, read1 in reads1.items():\n        for id2, read2 in reads2.items():\n            if id1 != id2 or not square:\n                match = compareDNAReads(\n                    read1, read2, matchAmbiguous=matchAmbiguous)['match']\n                if not matchAmbiguous:\n                    assert match['ambiguousMatchCount'] == 0\n                result[id1][id2] = result[id2][id1] = match\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a simple text table showing inter - sequence distances between two sets of nucleotides.", "response": "def simpleTable(tableData, reads1, reads2, square, matchAmbiguous, gapChars):\n    \"\"\"\n    Make a text table showing inter-sequence distances.\n\n    @param tableData: A C{defaultdict(dict)} keyed by read ids, whose values\n        are the dictionaries returned by compareDNAReads.\n    @param reads1: An C{OrderedDict} of C{str} read ids whose values are\n        C{Read} instances. These will be the rows of the table.\n    @param reads2: An C{OrderedDict} of C{str} read ids whose values are\n        C{Read} instances. These will be the columns of the table.\n    @param square: If C{True} we are making a square table of a set of\n        sequences against themselves (in which case we show nothing on the\n        diagonal).\n    @param matchAmbiguous: If C{True}, count ambiguous nucleotides that are\n        possibly correct as actually being correct. Otherwise, we are strict\n        and insist that only non-ambiguous nucleotides can contribute to the\n        matching nucleotide count.\n    @param gapChars: A C{str} of sequence characters considered to be gaps.\n    \"\"\"\n    readLengths1 = getReadLengths(reads1.values(), gapChars)\n    print('ID\\t' + '\\t'.join(reads2))\n\n    for id1, read1 in reads1.items():\n        read1Len = readLengths1[id1]\n        print(id1, end='')\n        for id2, read2 in reads2.items():\n            if id1 == id2 and square:\n                print('\\t', end='')\n            else:\n                stats = tableData[id1][id2]\n                identity = (\n                    stats['identicalMatchCount'] +\n                    (stats['ambiguousMatchCount'] if matchAmbiguous else 0)\n                ) / read1Len\n                print('\\t%.4f' % identity, end='')\n        print()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef htmlTable(tableData, reads1, reads2, square, matchAmbiguous, colors,\n              concise=False, showLengths=False, showGaps=False, showNs=False,\n              footer=False, div=False, gapChars='-'):\n    \"\"\"\n    Make an HTML table showing inter-sequence distances.\n\n    @param tableData: A C{defaultdict(dict)} keyed by read ids, whose values\n        are the dictionaries returned by compareDNAReads.\n    @param reads1: An C{OrderedDict} of C{str} read ids whose values are\n        C{Read} instances. These will be the rows of the table.\n    @param reads2: An C{OrderedDict} of C{str} read ids whose values are\n        C{Read} instances. These will be the columns of the table.\n    @param square: If C{True} we are making a square table of a set of\n        sequences against themselves (in which case we show nothing on the\n        diagonal).\n    @param matchAmbiguous: If C{True}, count ambiguous nucleotides that are\n        possibly correct as actually being correct. Otherwise, we are strict\n        and insist that only non-ambiguous nucleotides can contribute to the\n        matching nucleotide count.\n    @param colors: A C{list} of (threshold, color) tuples, where threshold is a\n        C{float} and color is a C{str} to be used as a cell background. This\n        is as returned by C{parseColors}.\n    @param concise: If C{True}, do not show match details.\n    @param showLengths: If C{True}, include the lengths of sequences.\n    @param showGaps: If C{True}, include the number of gaps in sequences.\n    @param showGaps: If C{True}, include the number of N characters in\n        sequences.\n    @param footer: If C{True}, incude a footer row giving the same information\n        as found in the table header.\n    @param div: If C{True}, return an HTML <div> fragment only, not a full HTML\n        document.\n    @param gapChars: A C{str} of sequence characters considered to be gaps.\n    @return: An HTML C{str} showing inter-sequence distances.\n    \"\"\"\n    readLengths1 = getReadLengths(reads1.values(), gapChars)\n    readLengths2 = getReadLengths(reads2.values(), gapChars)\n    result = []\n    append = result.append\n\n    def writeHeader():\n        # The header row of the table.\n        append('    <tr>')\n        append('    <td>&nbsp;</td>')\n        for read2 in reads2.values():\n            append('    <td class=\"title\"><span class=\"name\">%s</span>' %\n                   read2.id)\n            if showLengths and not square:\n                append('    <br>L:%d' % readLengths2[read2.id])\n            if showGaps and not square:\n                append('    <br>G:%d' % (len(read2) - readLengths2[read2.id]))\n            if showNs and not square:\n                append('    <br>N:%d' % read2.sequence.count('N'))\n            append('    </td>')\n        append('    </tr>')\n\n    if div:\n        append('<div>')\n    else:\n        append('<!DOCTYPE HTML>')\n        append('<html>')\n        append('<head>')\n        append('<meta charset=\"UTF-8\">')\n        append('</head>')\n        append('<body>')\n\n    append('<style>')\n    append(\"\"\"\n        table {\n            border-collapse: collapse;\n        }\n        table, td {\n            border: 1px solid #ccc;\n        }\n        tr:hover {\n            background-color: #f2f2f2;\n        }\n        td {\n            vertical-align: top;\n            font-size: 14px;\n        }\n        span.name {\n            font-weight: bold;\n        }\n        span.best {\n            font-weight: bold;\n        }\n    \"\"\")\n\n    # Add color style information for the identity thresholds.\n    for threshold, color in colors:\n        append('.%s { background-color: %s; }' % (\n            thresholdToCssName(threshold), color))\n\n    append('</style>')\n\n    if not div:\n        append(explanation(\n            matchAmbiguous, concise, showLengths, showGaps, showNs))\n    append('<div style=\"overflow-x:auto;\">')\n    append('<table>')\n    append('  <tbody>')\n\n    # Pre-process to find the best identities in each sample row.\n    bestIdentityForId = {}\n\n    for id1, read1 in reads1.items():\n        # Look for best identity for the sample.\n        read1Len = readLengths1[id1]\n        bestIdentity = -1.0\n        for id2, read2 in reads2.items():\n            if id1 != id2 or not square:\n                stats = tableData[id1][id2]\n                identity = (\n                    stats['identicalMatchCount'] +\n                    (stats['ambiguousMatchCount'] if matchAmbiguous else 0)\n                ) / read1Len\n                if identity > bestIdentity:\n                    bestIdentity = identity\n        bestIdentityForId[id1] = bestIdentity\n\n    writeHeader()\n\n    # The main body of the table.\n    for id1, read1 in reads1.items():\n        read1Len = readLengths1[id1]\n        append('    <tr>')\n        append('      <td class=\"title\"><span class=\"name\">%s</span>' % id1)\n        if showLengths:\n            append('<br/>L:%d' % read1Len)\n        if showGaps:\n            append('<br/>G:%d' % (len(read1) - read1Len))\n        if showNs:\n            append('<br/>N:%d' % read1.sequence.count('N'))\n        append('</td>')\n        for id2, read2 in reads2.items():\n            if id1 == id2 and square:\n                append('<td>&nbsp;</td>')\n                continue\n\n            stats = tableData[id1][id2]\n            identity = (\n                stats['identicalMatchCount'] +\n                (stats['ambiguousMatchCount'] if matchAmbiguous else 0)\n            ) / read1Len\n\n            append('      <td class=\"%s\">' % thresholdToCssName(\n                thresholdForIdentity(identity, colors)))\n\n            # The maximum percent identity.\n            if identity == bestIdentityForId[id1]:\n                scoreStyle = ' class=\"best\"'\n            else:\n                scoreStyle = ''\n\n            append('<span%s>%.4f</span>' % (scoreStyle, identity))\n\n            if not concise:\n                append('<br/>IM:%d' % stats['identicalMatchCount'])\n\n                if matchAmbiguous:\n                    append('<br/>AM:%d' % stats['ambiguousMatchCount'])\n\n                append(\n                    '<br/>GG:%d'\n                    '<br/>G?:%d'\n                    '<br/>NE:%d' %\n                    (stats['gapGapMismatchCount'],\n                     stats['gapMismatchCount'],\n                     stats['nonGapMismatchCount']))\n            append('      </td>')\n        append('    </tr>')\n\n    if footer:\n        writeHeader()\n\n    append('  </tbody>')\n    append('</table>')\n    append('</div>')\n\n    if div:\n        append('</div>')\n    else:\n        append('</body>')\n        append('</html>')\n\n    return '\\n'.join(result)", "response": "This function returns an HTML table showing inter - sequence distances."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_task(function, *args, **kwargs):\n    name = \"{}\".format(uuid4())\n    handler = None\n    deps = set()\n\n    if 'name' in kwargs:\n        name = kwargs['name']\n        del kwargs['name']\n    elif function is not None:\n        name = \"{}-{}\".format(function.__name__, name)\n\n    if 'handler' in kwargs:\n        handler = kwargs['handler']\n        del kwargs['handler']\n\n    if 'dependencies' in kwargs:\n        for dep in kwargs['dependencies']:\n            deps.add(dep)\n        del kwargs['dependencies']\n\n    for arg in args:\n        if isinstance(arg, Task):\n            deps.add(arg.name)\n\n    for key in kwargs:\n        if isinstance(kwargs[key], Task):\n            deps.add(kwargs[key].name)\n\n    return Task(name, function, handler, frozenset(deps), args, kwargs)", "response": "Create a new task object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hs_join(ls_hsi, hso):\n    N = len(ls_hsi)\n    ls_hsi_rdy, ls_hsi_vld = zip(*ls_hsi)\n    ls_hsi_rdy, ls_hsi_vld = list(ls_hsi_rdy), list(ls_hsi_vld)\n    hso_rdy, hso_vld = hso\n\n    @always_comb\n    def _hsjoin():\n        all_vld = True\n        for i in range(N):\n            all_vld = all_vld and ls_hsi_vld[i]\n        hso_vld.next = all_vld\n        for i in range(N):\n            ls_hsi_rdy[i].next = all_vld and hso_rdy\n\n    return _hsjoin", "response": "Synchronizes a list of input handshake interfaces and a list of output handshake interfaces"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsynchronizes ( forks ) to a list of output handshake interfaces.", "response": "def hs_fork(hsi, ls_hso):\n    \"\"\" [One-to-many] Synchronizes (forks) to a list of output handshake interfaces: input is ready when ALL outputs are ready\n            hsi    - (i) input handshake tuple (ready, valid)\n            ls_hso - (o) list of output handshake tuples (ready, valid)\n    \"\"\"\n    N = len(ls_hso)\n    hsi_rdy, hsi_vld = hsi\n    ls_hso_rdy, ls_hso_vld = zip(*ls_hso)\n    ls_hso_rdy, ls_hso_vld = list(ls_hso_rdy), list(ls_hso_vld)\n\n    @always_comb\n    def _hsfork():\n        all_rdy = True\n        for i in range(N):\n            all_rdy = all_rdy and ls_hso_rdy[i]\n        hsi_rdy.next = all_rdy\n        for i in range(N):\n            ls_hso_vld[i].next = all_rdy and hsi_vld\n\n    return _hsfork"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hs_demux(sel, hsi, ls_hso):\n    N = len(ls_hso)\n    hsi_rdy, hsi_vld = hsi\n    ls_hso_rdy, ls_hso_vld = zip(*ls_hso)\n    ls_hso_rdy, ls_hso_vld = list(ls_hso_rdy), list(ls_hso_vld)\n\n    @always_comb\n    def _hsdemux():\n        hsi_rdy.next = 0\n        for i in range(N):\n            ls_hso_vld[i].next = 0\n            if i == sel:\n                hsi_rdy.next = ls_hso_rdy[i]\n                ls_hso_vld[i].next = hsi_vld\n\n    return _hsdemux", "response": "One - to - many Demultiplexes to a list of output handshake interfaces that can be used to connect to the inputHSO."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hs_arbmux(rst, clk, ls_hsi, hso, sel, ARBITER_TYPE=\"priority\"):\n    N = len(ls_hsi)\n    ls_hsi_rdy, ls_hsi_vld = zip(*ls_hsi)\n    ls_hsi_vld = list(ls_hsi_vld)\n\n    # Needed to avoid: \"myhdl.ConversionError: Signal in multiple list is not supported:\"\n    ls_vld = [Signal(bool(0)) for _ in range(N)]\n    _a = [assign(ls_vld[i], ls_hsi_vld[i]) for i in range(N)]\n\n    sel_s = Signal(intbv(0, min=0, max=N))\n    @always_comb\n    def _sel():\n        sel.next = sel_s\n\n    priority_update = None\n\n    if (ARBITER_TYPE == \"roundrobin\"):\n        hso_rdy, hso_vld = hso\n        priority_update = Signal(bool(0))\n\n        @always_comb\n        def _prio():\n            priority_update.next = hso_rdy and hso_vld\n\n    _arb = arbiter(rst=rst, clk=clk, req_vec=ls_vld, gnt_idx=sel_s, gnt_rdy=priority_update, ARBITER_TYPE=ARBITER_TYPE)\n\n    _mux = hs_mux(sel=sel_s, ls_hsi=ls_hsi, hso=hso)\n\n    return instances()", "response": "A function that creates a list of active input interfaces and connects it to the output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file_md5sum(path):\n    with open(path, 'rb') as fh:\n        h = str(hashlib.md5(fh.read()).hexdigest())\n    return h", "response": "Calculate the MD5 hash for a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef smart_open_read(path=None, mode='rb', encoding=None, try_gzip=False):\n    assert mode in ('r', 'rb')\n    assert path is None or isinstance(path, (str, _oldstr))\n    assert isinstance(mode, (str, _oldstr))\n    assert encoding is None or isinstance(encoding, (str, _oldstr))\n    assert isinstance(try_gzip, bool)\n\n    fh = None\n    binfh = None\n    gzfh = None\n    if path is None:\n        # open stdin\n        fh = io.open(sys.stdin.fileno(), mode=mode, encoding=encoding)\n\n    else:\n        # open an actual file\n\n        if try_gzip:\n            # gzip.open defaults to mode 'rb'\n            gzfh = try_open_gzip(path)\n\n        if gzfh is not None:\n            logger.debug('Opening gzip''ed file.')\n            # wrap gzip stream\n            binfh = io.BufferedReader(gzfh)\n            if 'b' not in mode:\n                # add a text wrapper on top\n                logger.debug('Adding text wrapper.')\n                fh = io.TextIOWrapper(binfh, encoding=encoding)\n\n        else:\n            fh = io.open(path, mode=mode, encoding=encoding)\n\n    yield_fh = fh\n    if fh is None:\n        yield_fh = binfh\n\n    try:\n        yield yield_fh\n\n    finally:\n        # close all open files\n        if fh is not None:\n            # make sure we don't close stdin\n            if fh.fileno() != sys.stdin.fileno():\n                fh.close()\n\n        if binfh is not None:\n            binfh.close()\n\n        if gzfh is not None:\n            gzfh.close()", "response": "Open a file for reading or return stdin."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef smart_open_write(path=None, mode='wb', encoding=None):\n    if path is not None:\n        # open a file\n        fh = io.open(path, mode=mode, encoding=encoding)\n    else:\n        # open stdout\n        fh = io.open(sys.stdout.fileno(), mode=mode, encoding=encoding)\n        #fh = sys.stdout\n\n    try:\n        yield fh\n\n    finally:\n        # make sure we don't close stdout\n        if fh.fileno() != sys.stdout.fileno():\n            fh.close()", "response": "Open a file for writing or return stdout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_url_size(url):\n    r = requests.head(url, headers={'Accept-Encoding': 'identity'})\n    size = int(r.headers['content-length'])\n    return size", "response": "Get the size of a URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_url_file_name(url):\n\n    assert isinstance(url, (str, _oldstr))\n    return urlparse.urlparse(url).path.split('/')[-1]", "response": "Get the file name from an url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nensure that a directory exists.", "response": "def make_sure_dir_exists(dir_, create_subfolders=False):\n    \"\"\"Ensures that a directory exists.\n\n    Adapted from StackOverflow users \"Bengt\" and \"Heikki Toivonen\"\n    (http://stackoverflow.com/a/5032238).\n\n    Parameters\n    ----------\n    dir_: str\n        The directory path.\n    create_subfolders: bool, optional\n        Whether to create any inexistent subfolders. [False]\n    \n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    OSError\n        If a file system error occurs.\n    \"\"\"\n    assert isinstance(dir_, (str, _oldstr))\n    assert isinstance(create_subfolders, bool)\n\n    try:\n        if create_subfolders:\n            os.makedirs(dir_)\n        else:\n            os.mkdir(dir_)\n    except OSError as exception:\n        if exception.errno != errno.EEXIST:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the size of a file in bytes.", "response": "def get_file_size(path):\n    \"\"\"The the size of a file in bytes.\n\n    Parameters\n    ----------\n    path: str\n        The path of the file.\n\n    Returns\n    -------\n    int\n        The size of the file in bytes.\n\n    Raises\n    ------\n    IOError\n        If the file does not exist.\n    OSError\n        If a file system error occurs.\n    \"\"\"\n    assert isinstance(path, (str, _oldstr))\n\n    if not os.path.isfile(path):\n        raise IOError('File \"%s\" does not exist.', path)\n\n    return os.path.getsize(path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_file_checksum(path):\n\n    if not (sys.platform.startswith('linux') or \\\n                        sys.platform in ['darwin', 'cygwin']):\n        raise OSError('This function is not available on your platform.')\n\n    assert isinstance(path, (str, _oldstr))\n\n    if not os.path.isfile(path): # not a file\n        raise IOError('File \"%s\" does not exist.' %(path))\n\n    # calculate checksum\n    sub = subproc.Popen('sum \"%s\"' %(path), bufsize=-1, shell=True,\n                        stdout=subproc.PIPE)\n    stdoutdata = sub.communicate()[0]\n    assert sub.returncode == 0\n\n    # in Python 3, communicate() returns bytes that need to be decoded\n    encoding = locale.getpreferredencoding()\n    stdoutstr = str(stdoutdata, encoding=encoding)\n\n    file_checksum = int(stdoutstr.split(' ')[0])\n    logger.debug('Checksum of file \"%s\": %d', path, file_checksum)\n    return file_checksum", "response": "Get the checksum of a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen a plain - text file that may be gziped.", "response": "def gzip_open_text(path, encoding=None):\n    \"\"\"Opens a plain-text file that may be gzip'ed.\n\n    Parameters\n    ----------\n    path : str\n        The file.\n    encoding : str, optional\n        The encoding to use.\n\n    Returns\n    -------\n    file-like\n        A file-like object.\n\n    Notes\n    -----\n    Generally, reading gzip'ed files with gzip.open is very slow, and it is\n    preferable to pipe the file into the python script using ``gunzip -c``.\n    The script then reads the file from stdin.\n    \"\"\"\n    if encoding is None:\n        encoding = sys.getdefaultencoding()\n\n    assert os.path.isfile(path)\n\n    is_compressed = False\n    try:\n        gzip.open(path, mode='rb').read(1)\n    except IOError:\n        pass\n    else:\n        is_compressed = True\n\n    if is_compressed:\n        if six.PY2:\n            import codecs\n            zf = gzip.open(path, 'rb')\n            reader = codecs.getreader(encoding)\n            fh = reader(zf)\n\n        else:\n            fh = gzip.open(path, mode='rt', encoding=encoding)\n\n    else:\n        # the following works in Python 2.7, thanks to future\n        fh = open(path, mode='r', encoding=encoding)\n\n    return fh"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bisect_index(a, x):\n    i = bisect.bisect_left(a, x)\n    if i != len(a) and a[i] == x:\n        return i\n    raise ValueError", "response": "Find the leftmost index of an element in a sorted list using binary search."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the first column of a tab - delimited text file.", "response": "def read_single(path, encoding = 'UTF-8'):\n    \"\"\" Reads the first column of a tab-delimited text file.\n\n    The file can either be uncompressed or gzip'ed.\n\n    Parameters\n    ----------\n    path: str\n        The path of the file.\n    enc: str\n        The file encoding.\n\n    Returns\n    -------\n    List of str\n        A list containing the elements in the first column.\n\n    \"\"\"\n    assert isinstance(path, (str, _oldstr))\n    data = []\n    with smart_open_read(path, mode='rb', try_gzip=True) as fh:\n        reader = csv.reader(fh, dialect='excel-tab', encoding=encoding)\n        for l in reader:\n            data.append(l[0])\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a TCP firewall rule to the project.", "response": "def add_tcp_firewall_rule(project, access_token, name, tag, port):\n    \"\"\"Adds a TCP firewall rule.\n\n    TODO: docstring\"\"\"\n    \n    headers = {\n        'Authorization': 'Bearer %s' % access_token.access_token\n    }\n    \n    payload = {\n        \"name\": name,\n        \"kind\": \"compute#firewall\",\n        \"sourceRanges\": [ \"0.0.0.0/0\" ],\n        \"targetTags\": [ tag ],\n        \"allowed\": [ { \"IPProtocol\": \"tcp\", \"ports\": [ str(port), ] } ],\n        \"network\": \"projects/%s/global/networks/default\" % project\n    }\n    \n    r = requests.post('https://www.googleapis.com/compute/v1/'\n                      'projects/%s/global/firewalls'\n                      % project, headers=headers, json=payload)\n    r.raise_for_status()\n    op = r.json()['name']\n\n    LOGGER.info('Requested to add firewall rule for tag \"%s\" '\n                '(operation \"%s\")...', tag, op)\n\n    return op"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(taxids, conn, force_download, silent):\n    if not silent:\n        click.secho(\"WARNING: Update is very time consuming and can take several \"\n                    \"hours depending which organisms you are importing!\", fg=\"yellow\")\n\n        if not taxids:\n            click.echo(\"Please note that you can restrict import to organisms by \"\n                       \"NCBI taxonomy IDs\")\n            click.echo(\"Example (human, mouse, rat):\\n\")\n            click.secho(\"\\tpyuniprot update --taxids 9606,10090,10116\\n\\n\", fg=\"green\")\n\n    if taxids:\n        taxids = [int(taxid.strip()) for taxid in taxids.strip().split(',') if re.search('^ *\\d+ *$', taxid)]\n\n    database.update(taxids=taxids, connection=conn, force_download=force_download, silent=silent)", "response": "Update the UniProt database with the given taxonomy IDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck a later set of BLAST parameters against those originally found.", "response": "def checkCompatibleParams(initialParams, laterParams):\n    \"\"\"\n    Check a later set of BLAST parameters against those originally found.\n\n    @param initialParams: A C{dict} with the originally encountered BLAST\n        parameter settings.\n    @param laterParams: A C{dict} with BLAST parameter settings encountered\n        later.\n    @return: A C{str} summary of the parameter differences if the parameter\n        sets differ, else C{None}.\n    \"\"\"\n\n    # Note that although the params contains a 'date', its value is empty\n    # (as far as I've seen). This could become an issue one day if it\n    # becomes non-empty and differs between JSON files that we cat\n    # together. In that case we may need to be more specific in our params\n    # compatible checking.\n    err = []\n    for param in initialParams:\n        if param in laterParams:\n            if (param not in VARIABLE_PARAMS and\n                    initialParams[param] != laterParams[param]):\n                err.append(\n                    '\\tParam %r initial value %r differs from '\n                    'later value %r' % (param, initialParams[param],\n                                        laterParams[param]))\n        else:\n            err.append('\\t%r found in initial parameters, not found '\n                       'in later parameters' % param)\n    for param in laterParams:\n        if param not in initialParams:\n            err.append('\\t%r found in later parameters, not seen in '\n                       'initial parameters' % param)\n\n    return 'Summary of differences:\\n%s' % '\\n'.join(err) if err else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the GeneSet object to a flat list of strings.", "response": "def to_list(self):\n        \"\"\"Converts the GeneSet object to a flat list of strings.\n\n        Note: see also :meth:`from_list`.\n\n        Parameters\n        ----------\n\n        Returns\n        -------\n        list of str\n            The data from the GeneSet object as a flat list.\n        \"\"\"\n        src = self._source or ''\n        coll = self._collection or ''\n        desc = self._description or ''\n\n        l = [self._id, src, coll, self._name,\n             ','.join(sorted(self._genes)), desc]\n        return l"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_list(cls, l):\n        id_ = l[0]\n        name = l[3]\n        genes = l[4].split(',')\n\n        src = l[1] or None\n        coll = l[2] or None\n        desc = l[5] or None\n\n        return cls(id_, name, genes, src, coll, desc)", "response": "Generate a GeneSet object from a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef findPrimerBidi(primer, seq):\n    # Note that we reverse complement the primer to find the reverse\n    # matches. This is much simpler than reverse complementing the sequence\n    # because it allows us to use findPrimer and to deal with overlapping\n    # matches correctly.\n    forward = findPrimer(primer, seq)\n    reverse = findPrimer(reverse_complement(primer), seq)\n    return forward, reverse", "response": "Find a primer in a sequence and its reverse complemented."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef findPrimerBidiLimits(primer, seq):\n    forward, reverse = findPrimerBidi(primer, seq)\n    if forward:\n        start = forward[-1] + len(primer)\n        end = len(seq)\n        for offset in reverse:\n            if offset >= start:\n                end = offset\n                break\n    else:\n        start = 0\n        end = reverse[0] if reverse else len(seq)\n\n    return start, end", "response": "Find the extreme offsets of a primer in a sequence and its\n    reverse complement."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef numericallySortFilenames(names):\n\n    def numericPrefix(name):\n        \"\"\"\n        Find any numeric prefix of C{name} and return it as an C{int}.\n\n        @param: A C{str} file name, whose name possibly starts with digits.\n        @return: The C{int} number at the start of the name, else 0 if\n            there are no leading digits in the name.\n        \"\"\"\n        count = 0\n        for ch in name:\n            if ch in string.digits:\n                count += 1\n            else:\n                break\n        return 0 if count == 0 else int(name[0:count])\n\n    return sorted(names, key=lambda name: numericPrefix(basename(name)))", "response": "Sort a list of file names by their numerical prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef asHandle(fileNameOrHandle, mode='r'):\n    if isinstance(fileNameOrHandle, six.string_types):\n        if fileNameOrHandle.endswith('.gz'):\n            if six.PY3:\n                yield gzip.open(fileNameOrHandle, mode='rt', encoding='UTF-8')\n            else:\n                yield gzip.GzipFile(fileNameOrHandle)\n        elif fileNameOrHandle.endswith('.bz2'):\n            if six.PY3:\n                yield bz2.open(fileNameOrHandle, mode='rt', encoding='UTF-8')\n            else:\n                yield bz2.BZ2File(fileNameOrHandle)\n        else:\n            with open(fileNameOrHandle) as fp:\n                yield fp\n    else:\n        yield fileNameOrHandle", "response": "A generator that can be used to open a file or a file handle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parseRangeString(s, convertToZeroBased=False):\n\n    result = set()\n    for _range in s.split(','):\n        match = _rangeRegex.match(_range)\n        if match:\n            start, end = match.groups()\n            start = int(start)\n            if end is None:\n                end = start\n            else:\n                end = int(end)\n            if start > end:\n                start, end = end, start\n            if convertToZeroBased:\n                result.update(range(start - 1, end))\n            else:\n                result.update(range(start, end + 1))\n        else:\n            raise ValueError(\n                'Illegal range %r. Ranges must single numbers or '\n                'number-number.' % _range)\n\n    return result", "response": "Parses a string of the form 1 - 5 12 100 - 200 and returns a set of all C { int s in the specified set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the offsets and base counts for a single nucleotide into a string.", "response": "def nucleotidesToStr(nucleotides, prefix=''):\n    \"\"\"\n    Convert offsets and base counts to a string.\n\n    @param nucleotides: A C{defaultdict(Counter)} instance, keyed\n        by C{int} offset, with nucleotides keying the Counters.\n    @param prefix: A C{str} to put at the start of each line.\n    @return: A C{str} representation of the offsets and nucleotide\n        counts for each.\n    \"\"\"\n    result = []\n    for offset in sorted(nucleotides):\n        result.append(\n            '%s%d: %s' % (prefix, offset,\n                          baseCountsToStr(nucleotides[offset])))\n    return '\\n'.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef countPrint(mesg, count, len1, len2=None):\n    def percentage(a, b):\n        \"\"\"\n        What percent of a is b?\n\n        @param a: a numeric value.\n        @param b: a numeric value.\n        @return: the C{float} percentage.\n        \"\"\"\n        return 100.0 * a / b if b else 0.0\n\n    if count == 0:\n        return '%s: %d' % (mesg, count)\n    else:\n        len2 = len2 or len1\n        if len1 == len2:\n            return '%s: %d/%d (%.2f%%)' % (\n                mesg, count, len1, percentage(count, len1))\n        else:\n            return ('%s: %d/%d (%.2f%%) of sequence 1, '\n                    '%d/%d (%.2f%%) of sequence 2' % (\n                        mesg,\n                        count, len1, percentage(count, len1),\n                        count, len2, percentage(count, len2)))", "response": "Print a message followed by an integer count and a percentage of length len1 and length len2."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads general - purpose scripts to a Google Storage bucket.", "response": "def upload_scripts(client, script_dir, overwrite=True):\n    \"\"\"Uploads general-purpose scripts to a Google Storage bucket.\n    \n    TODO: docstring\"\"\"\n    local_dir = os.path.join(genometools._root, 'data', 'gcloud', 'scripts')\n    match = _BUCKET_PAT.match(script_dir)\n    script_bucket = match.group(1)\n    script_prefix = match.group(2)\n\n    depth = len(local_dir.split(os.sep))\n\n    for root, dirs, files in os.walk(local_dir):\n        rel_path = '/'.join(root.split(os.sep)[depth:])\n        for f in files:\n            local_path = os.path.join(root, f)\n\n            if rel_path:\n                remote_path = '/'.join([script_prefix, rel_path, f])\n            else:\n                remote_path = '/'.join([script_prefix, f])\n            _LOGGER.info('Uploading \"%s\"...', remote_path)\n            storage.upload_file(client, script_bucket, local_path, remote_path,\n                                overwrite=overwrite)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nobtains a JSON record reader for DIAMOND records.", "response": "def _getReader(self, filename, scoreClass):\n        \"\"\"\n        Obtain a JSON record reader for DIAMOND records.\n\n        @param filename: The C{str} file name holding the JSON.\n        @param scoreClass: A class to hold and compare scores (see scores.py).\n        \"\"\"\n        if filename.endswith('.json') or filename.endswith('.json.bz2'):\n            return JSONRecordsReader(filename, scoreClass)\n        else:\n            raise ValueError(\n                'Unknown DIAMOND record file suffix for file %r.' % filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting DIAMOND records and yield C{ReadAlignments} instances. @return: A generator that yields C{ReadAlignments} instances.", "response": "def iter(self):\n        \"\"\"\n        Extract DIAMOND records and yield C{ReadAlignments} instances.\n\n        @return: A generator that yields C{ReadAlignments} instances.\n        \"\"\"\n        # Note that self._reader is already initialized (in __init__) for\n        # the first input file. This is less clean than it could be, but it\n        # makes testing easier, since open() is then only called once for\n        # each input file.\n\n        reads = iter(self.reads)\n        first = True\n\n        for filename in self.filenames:\n            if first:\n                # The first file has already been opened, in __init__.\n                first = False\n                reader = self._reader\n            else:\n                reader = self._getReader(filename, self.scoreClass)\n\n            for readAlignments in reader.readAlignments(reads):\n                yield readAlignments\n\n        # Any remaining query reads must have had no subject matches.\n        for read in reads:\n            yield ReadAlignments(read, [])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getSubjectSequence(self, title):\n        if self._subjectTitleToSubject is None:\n            if self._databaseFilename is None:\n                # An Sqlite3 database is used to look up subjects.\n                self._subjectTitleToSubject = SqliteIndex(\n                    self._sqliteDatabaseFilename,\n                    fastaDirectory=self._databaseDirectory,\n                    readClass=AAReadWithX)\n            else:\n                # Build a dict to look up subjects.\n                titles = {}\n                for read in FastaReads(self._databaseFilename,\n                                       readClass=AAReadWithX):\n                    titles[read.id] = read\n                self._subjectTitleToSubject = titles\n\n        return self._subjectTitleToSubject[title]", "response": "Obtain information about a subject sequence given its title."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the URLs for all runs from a given project.", "response": "def get_project_urls(project):\n    \"\"\"Get the URLs for all runs from a given project.\n    \n    TODO: docstring\"\"\"\n    urls = []\n    with ftputil.FTPHost(sra_host, sra_user, sra_password) as ftp_host:\n        download_paths = []\n        exp_dir = '/sra/sra-instant/reads/ByStudy/sra/SRP/%s/%s/' \\\n                %(project[:6], project)\n        ftp_host.chdir(exp_dir)\n        run_folders = ftp_host.listdir(ftp_host.curdir)\n\n        # compile a list of all files\n        for folder in run_folders:\n            files = ftp_host.listdir(folder)\n            assert len(files) == 1\n            for f in files:\n                path = exp_dir + folder + '/' + f\n                urls.append(path)\n    return urls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef twos_complement(rst, clk, rx_rdy, rx_vld, rx_dat, tx_rdy, tx_vld, tx_dat):\n    ''' Two's complement conversion of a binary number\n        Input handshake & data\n            rx_rdy - (o) Ready\n            rx_vld - (i) Valid\n            rx_dat - (i) Data\n        Output handshake & data\n            tx_rdy - (i) Ready\n            tx_vld - (o) Valid\n            tx_dat - (o) Data\n\n        Implementation: 3-stage pipeline\n            stage 0: registers input data\n            stage 1: inverts data coming from stage 0 and registers the inverted data\n            stage 2: increments data coming from stage 1 and registers the incremented data\n\n            Each stage is implemented as a separate process controlled by a central pipeline control unit via an enable signal\n            The pipeline control unit manages the handshake and synchronizes the operation of the stages\n    '''\n\n    DATA_WIDTH = len(rx_dat)\n\n    NUM_STAGES = 3\n\n    stage_en = Signal(intbv(0)[NUM_STAGES:])\n\n    pipe_ctrl = pipeline_control( rst = rst,\n                                  clk = clk,\n                                  rx_vld = rx_vld,\n                                  rx_rdy = rx_rdy,\n                                  tx_vld = tx_vld,\n                                  tx_rdy = tx_rdy,\n                                  stage_enable = stage_en)\n\n    s0_dat = Signal(intbv(0)[DATA_WIDTH:])\n\n    @always_seq(clk.posedge, reset=rst)\n    def stage_0():\n        ''' Register input data'''\n        if (stage_en[0]):\n            s0_dat.next = rx_dat\n\n\n    s1_dat = Signal(intbv(0)[DATA_WIDTH:])\n\n    @always_seq(clk.posedge, reset=rst)\n    def stage_1():\n        ''' Invert data'''\n        if (stage_en[1]):\n            s1_dat.next = ~s0_dat\n\n\n    s2_dat = Signal(intbv(0)[DATA_WIDTH:])\n\n    @always_seq(clk.posedge, reset=rst)\n    def stage_2():\n        ''' Add one to data'''\n        if (stage_en[2]):\n            s2_dat.next = s1_dat + 1\n\n\n    @always_comb\n    def comb():\n        tx_dat.next = s2_dat.signed()\n\n    return instances()", "response": "Two s complement conversion of a binary number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_argument_parser():\n\n    desc = 'Generate a mapping of Entrez IDs to gene symbols.'\n\n    parser = cli.get_argument_parser(desc=desc)\n\n    parser.add_argument(\n        '-f', '--gene2acc-file', type=str, required=True,\n        help=textwrap.dedent(\"\"\"\\\n            Path of gene2accession.gz file (from\n            ftp://ftp.ncbi.nlm.nih.gov/gene/DATA), or a filtered version\n            thereof.\"\"\")\n    )\n\n    parser.add_argument(\n        '-o', '--output-file', type=str, required=True,\n        help=textwrap.dedent(\"\"\"\\\n            Path of output file. If set to ``-``, print to ``stdout``,\n            and redirect logging messages to ``stderr``.\"\"\")\n    )\n\n    parser.add_argument(\n        '-l', '--log-file', type=str, default=None,\n        help='Path of log file. If not specified, print to stdout.'\n    )\n\n    parser.add_argument(\n        '-q', '--quiet', action='store_true',\n        help='Suppress all output except warnings and errors.'\n    )\n\n    parser.add_argument(\n        '-v', '--verbose', action='store_true',\n        help='Enable verbose output. Ignored if ``--quiet`` is specified.'\n    )\n\n    return parser", "response": "Creates the argument parser for the extract_entrez2gene. py script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_gene2acc(file_path, logger):\n    gene2acc = {}\n    with misc.smart_open_read(file_path, mode='rb', try_gzip=True) as fh:\n        reader = csv.reader(fh, dialect='excel-tab')\n        next(reader)  # skip header\n        for i, l in enumerate(reader):\n            id_ = int(l[1])\n            symbol = l[15]\n\n            try:\n                gene2acc[id_].append(symbol)\n            except KeyError:\n                gene2acc[id_] = [symbol]\n\n            # print (l[0],l[15])\n\n    # make sure all EntrezIDs map to a unique gene symbol\n    n = len(gene2acc)\n    for k, v in gene2acc.items():\n        symbols = sorted(set(v))\n        assert len(symbols) == 1\n        gene2acc[k] = symbols[0]\n\n    all_symbols = sorted(set(gene2acc.values()))\n    m = len(all_symbols)\n\n    logger.info('Found %d Entrez Gene IDs associated with %d gene symbols.',\n                n, m)\n    return gene2acc", "response": "Reads the gene2accession. gz file and returns a dict of Entrez ID - > gene symbol mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_entrez2gene(file_path, entrez2gene, logger):\n    with misc.smart_open_write(file_path, mode='wb') as ofh:\n        writer = csv.writer(ofh, dialect='excel-tab',\n                            lineterminator=os.linesep)\n        for k in sorted(entrez2gene.keys(), key=lambda x: int(x)):\n            writer.writerow([k, entrez2gene[k]])\n    logger.info('Output written to file \"%s\".', file_path)", "response": "Writes the entrez id - > gene symbol mapping to a tab - delimited text file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(args=None):\n    vinfo = sys.version_info\n    if not (vinfo >= (2, 7)):\n        raise SystemError('Python interpreter version >= 2.7 required, '\n                          'found %d.%d instead.' % (vinfo.major, vinfo.minor))\n\n    if args is None:\n        parser = get_argument_parser()\n        args = parser.parse_args()\n\n    gene2acc_file = args.gene2acc_file\n    output_file = args.output_file\n    log_file = args.log_file\n    quiet = args.quiet\n    verbose = args.verbose\n\n    # configure logger\n    log_stream = sys.stdout\n    if output_file == '-':\n        log_stream = sys.stderr\n\n    logger = misc.get_logger(log_stream=log_stream, log_file=log_file,\n                             quiet=quiet, verbose=verbose)\n\n    entrez2gene = read_gene2acc(gene2acc_file, logger)\n    write_entrez2gene(output_file, entrez2gene, logger)\n\n    return 0", "response": "This function is the main entry point for the entrez2gene command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find(s):\n\n    abbrev1 = None\n    origS = s\n\n    if ' ' in s:\n        # Convert first word to title case, others to lower.\n        first, rest = s.split(' ', 1)\n        s = first.title() + ' ' + rest.lower()\n    else:\n        s = s.title()\n\n    if s in NAMES:\n        abbrev1 = s\n    elif s in ABBREV3_TO_ABBREV1:\n        abbrev1 = ABBREV3_TO_ABBREV1[s]\n    elif s in NAMES_TO_ABBREV1:\n        abbrev1 = NAMES_TO_ABBREV1[s]\n    else:\n        # Look for a 3-letter codon.\n        def findCodon(target):\n            for abbrev1, codons in CODONS.items():\n                for codon in codons:\n                    if codon == target:\n                        return abbrev1\n\n        abbrev1 = findCodon(origS.upper())\n\n    if abbrev1:\n        return AminoAcid(\n            NAMES[abbrev1], ABBREV3[abbrev1], abbrev1, CODONS[abbrev1],\n            PROPERTIES[abbrev1], PROPERTY_DETAILS[abbrev1],\n            PROPERTY_CLUSTERS[abbrev1])", "response": "Find an amino acid whose name or abbreviation is s."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract amino acid property values or cluster numbers for a sequence.", "response": "def _propertiesOrClustersForSequence(sequence, propertyNames, propertyValues,\n                                     missingAAValue):\n    \"\"\"\n    Extract amino acid property values or cluster numbers for a sequence.\n\n    @param sequence: An C{AARead} (or a subclass) instance.\n    @param propertyNames: An iterable of C{str} property names (each of which\n        must be a key of a key in the C{propertyValues} C{dict}).\n    @param propertyValues: A C{dict} in the form of C{PROPERTY_DETAILS} or\n        C{PROPERTY_CLUSTERS} (see above).\n    @param missingAAValue: A C{float} value to use for properties when an AA\n        (e.g., 'X') is not known.\n    @raise ValueError: If an unknown property is given in C{propertyNames}.\n    @return: A C{dict} keyed by (lowercase) property name, with values that are\n        C{list}s of the corresponding property value in C{propertyValues} in\n        order of sequence position.\n    \"\"\"\n    propertyNames = sorted(map(str.lower, set(propertyNames)))\n\n    # Make sure all mentioned property names exist for at least one AA.\n    knownProperties = set()\n    for names in propertyValues.values():\n        knownProperties.update(names)\n    unknown = set(propertyNames) - knownProperties\n    if unknown:\n        raise ValueError(\n            'Unknown propert%s: %s.' %\n            ('y' if len(unknown) == 1 else 'ies', ', '.join(unknown)))\n\n    aas = sequence.sequence.upper()\n    result = {}\n\n    for propertyName in propertyNames:\n        result[propertyName] = values = []\n        append = values.append\n        for aa in aas:\n            try:\n                properties = propertyValues[aa]\n            except KeyError:\n                # No such AA.\n                append(missingAAValue)\n            else:\n                append(properties[propertyName])\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef matchToString(aaMatch, read1, read2, indent='', offsets=None):\n    match = aaMatch['match']\n    matchCount = match['matchCount']\n    gapMismatchCount = match['gapMismatchCount']\n    gapGapMismatchCount = match['gapGapMismatchCount']\n    nonGapMismatchCount = match['nonGapMismatchCount']\n\n    if offsets:\n        len1 = len2 = len(offsets)\n    else:\n        len1, len2 = map(len, (read1, read2))\n\n    result = []\n    append = result.append\n\n    append(countPrint('%sMatches' % indent, matchCount, len1, len2))\n    mismatchCount = (gapMismatchCount + gapGapMismatchCount +\n                     nonGapMismatchCount)\n    append(countPrint('%sMismatches' % indent, mismatchCount, len1, len2))\n    append(countPrint('%s  Not involving gaps (i.e., conflicts)' % (indent),\n                      nonGapMismatchCount, len1, len2))\n    append(countPrint('%s  Involving a gap in one sequence' % indent,\n                      gapMismatchCount, len1, len2))\n    append(countPrint('%s  Involving a gap in both sequences' % indent,\n                      gapGapMismatchCount, len1, len2))\n\n    for read, key in zip((read1, read2), ('read1', 'read2')):\n        append('%s  Id: %s' % (indent, read.id))\n        length = len(read)\n        append('%s    Length: %d' % (indent, length))\n        gapCount = len(aaMatch[key]['gapOffsets'])\n        append(countPrint('%s    Gaps' % indent, gapCount, length))\n        if gapCount:\n            append(\n                '%s    Gap locations (1-based): %s' %\n                (indent,\n                 ', '.join(map(lambda offset: str(offset + 1),\n                               sorted(aaMatch[key]['gapOffsets'])))))\n        extraCount = aaMatch[key]['extraCount']\n        if extraCount:\n            append(countPrint('%s    Extra nucleotides at end' % indent,\n                              extraCount, length))\n\n    return '\\n'.join(result)", "response": "Formats a amino acid sequence match as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compareAaReads(read1, read2, gapChars='-', offsets=None):\n    matchCount = 0\n    gapMismatchCount = nonGapMismatchCount = gapGapMismatchCount = 0\n    read1ExtraCount = read2ExtraCount = 0\n    read1GapOffsets = []\n    read2GapOffsets = []\n\n    for offset, (a, b) in enumerate(zip_longest(read1.sequence.upper(),\n                                                read2.sequence.upper())):\n        # Use 'is not None' in the following to allow an empty offsets set\n        # to be passed.\n        if offsets is not None and offset not in offsets:\n            continue\n        if a is None:\n            # b has an extra character at its end (it cannot be None).\n            assert b is not None\n            read2ExtraCount += 1\n            if b in gapChars:\n                read2GapOffsets.append(offset)\n        elif b is None:\n            # a has an extra character at its end.\n            read1ExtraCount += 1\n            if a in gapChars:\n                read1GapOffsets.append(offset)\n        else:\n            # We have a character from both sequences (they could still be\n            # gap characters).\n            if a in gapChars:\n                read1GapOffsets.append(offset)\n                if b in gapChars:\n                    # Both are gaps. This can happen (though hopefully not\n                    # if the sequences were pairwise aligned).\n                    gapGapMismatchCount += 1\n                    read2GapOffsets.append(offset)\n                else:\n                    # a is a gap, b is not.\n                    gapMismatchCount += 1\n            else:\n                if b in gapChars:\n                    # b is a gap, a is not.\n                    gapMismatchCount += 1\n                    read2GapOffsets.append(offset)\n                else:\n                    # Neither is a gap character.\n                    if a == b:\n                        matchCount += 1\n                    else:\n                        nonGapMismatchCount += 1\n\n    return {\n        'match': {\n            'matchCount': matchCount,\n            'gapMismatchCount': gapMismatchCount,\n            'gapGapMismatchCount': gapGapMismatchCount,\n            'nonGapMismatchCount': nonGapMismatchCount,\n        },\n        'read1': {\n            'extraCount': read1ExtraCount,\n            'gapOffsets': read1GapOffsets,\n        },\n        'read2': {\n            'extraCount': read2ExtraCount,\n            'gapOffsets': read2GapOffsets,\n        },\n    }", "response": "Compares two amino acid sequences and returns a dictionary with the number of matches and the individual amino acid sequences."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse read id color specification.", "response": "def parseColors(colors, args):\n    \"\"\"\n    Parse read id color specification.\n\n    @param colors: A C{list} of C{str}s. Each item is of the form, e.g.,\n        'green X Y Z...', where each of X, Y, Z, ... etc. is either a read\n        id or the name of a FASTA or FASTQ file containing reads whose ids\n        should be displayed with the corresponding color. Note that if read\n        ids contain spaces you will need to use the latter (i.e. FASTA/Q file\n        name) approach because C{args.colors} is split on whitespace.\n    @param args: The argparse C{Namespace} instance holding the other parsed\n        command line arguments.\n    @return: A C{dict} whose keys are colors and whose values are sets of\n        read ids.\n    \"\"\"\n    result = defaultdict(set)\n    for colorInfo in colors:\n        readIds = colorInfo.split()\n        color = readIds.pop(0)\n        for readId in readIds:\n            if os.path.isfile(readId):\n                filename = readId\n                if args.fasta:\n                    reads = FastaReads(filename)\n                else:\n                    reads = FastqReads(filename)\n                for read in reads:\n                    result[color].add(read.id)\n            else:\n                result[color].add(readId)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_release(download_file, release=None):\n    if release is None:\n        release = get_latest_release()\n    url = 'http://viewvc.geneontology.org/viewvc/GO-SVN/ontology-releases/%s/go-basic.obo' % release\n    #download_file = 'go-basic_%s.obo' % release\n    misc.http_download(url, download_file)", "response": "Downloads the go - basic. obo file for the specified release."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the release date of the current Gene Ontolgo release.", "response": "def get_current_ontology_date():\n    \"\"\"Get the release date of the current Gene Ontolgo release.\"\"\"\n    with closing(requests.get(\n            'http://geneontology.org/ontology/go-basic.obo',\n            stream=True)) as r:\n        for i, l in enumerate(r.iter_lines(decode_unicode=True)):\n            if i == 1:\n                assert l.split(':')[0] == 'data-version'\n                date = l.split('/')[-1]\n                break\n\n    return date"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute a task returning a TaskResult", "response": "def execute(function, name):\n    \"\"\"\n    Execute a task, returning a TaskResult\n    \"\"\"\n    try:\n        return TaskResult(name, True, None, function())\n    except Exception as exc:\n        return TaskResult(name, False, exc, None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntruncate a string after a certain number of chars.", "response": "def truncatechars(value, arg):\n    \"\"\"\n    Truncates a string after a certain number of chars.\n\n    Argument: Number of chars to truncate after.\n    \"\"\"\n    try:\n        length = int(arg)\n    except ValueError: # Invalid literal for int().\n        return value # Fail silently.\n    if len(value) > length:\n        return value[:length] + '...'\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handler500(request):\n    from django.template import Context, loader\n    from django.http import HttpResponseServerError\n    from overseer.context_processors import default\n    import logging\n    import sys\n    try:\n        context = default(request)\n    except Exception, e:\n        logging.error(e, exc_info=sys.exc_info(), extra={'request': request})\n        context = {}\n    \n    context['request'] = request\n    \n    t = loader.get_template('500.html') # You need to create a 500.html template.\n    return HttpResponseServerError(t.render(Context(context)))", "response": "500 error handler.\n\n    Templates: `500.html`\n    Context: None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an argument parser with basic options for reading GTF files.", "response": "def get_gtf_argument_parser(desc, default_field_name='gene'):\n    \"\"\"Return an argument parser with basic options for reading GTF files.\n\n    Parameters\n    ----------\n    desc: str\n        Description of the ArgumentParser\n    default_field_name: str, optional\n        Name of field in GTF file to look for.\n\n    Returns\n    -------\n    `argparse.ArgumentParser` object\n        The argument parser.\n    \"\"\"\n    parser = cli.get_argument_parser(desc=desc)\n\n    parser.add_argument(\n        '-a', '--annotation-file', default='-', type=str,\n        help=textwrap.dedent(\"\"\"\\\n            Path of Ensembl gene annotation file (in GTF format). The file\n            may be gzip'ed. If set to ``-``, read from ``stdin``.\"\"\")\n    )\n\n    parser.add_argument(\n        '-o', '--output-file', required=True, type=str,\n        help=textwrap.dedent(\"\"\"\\\n            Path of output file. If set to ``-``, print to ``stdout``,\n            and redirect logging messages to ``stderr``.\"\"\")\n    )\n\n    #parser.add_argument(\n    #    '-s', '--species', type=str,\n    #    choices=sorted(ensembl.SPECIES_CHROMPAT.keys()), default='human',\n    #    help=textwrap.dedent(\"\"\"\\\n    #        Species for which to extract genes. (This parameter is ignored\n    #        if ``--chromosome-pattern`` is specified.)\"\"\")\n    #)\n\n    parser.add_argument(\n        '-c', '--chromosome-pattern', type=str, required=False,\n        default=None, help=textwrap.dedent(\"\"\"\\\n            Regular expression that chromosome names have to match. [None]\n            \"\"\")\n    )\n\n    #parser.add_argument(\n    #    '-f', '--field-name', type=str, default=default_field_name,\n    #    help=textwrap.dedent(\"\"\"\\\n    #        Rows in the GTF file that do not contain this value\n    #        in the third column are ignored.\"\"\")\n    #)\n\n    cli.add_reporting_args(parser)\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef jsonresolver_loader(url_map):\n    from flask import current_app\n    from . import current_jsonschemas\n    url_map.add(Rule(\n        \"{0}/<path:path>\".format(current_app.config['JSONSCHEMAS_ENDPOINT']),\n        endpoint=current_jsonschemas.get_schema,\n        host=current_app.config['JSONSCHEMAS_HOST']))", "response": "A JSON resolver plugin that loads the schema endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge_layouts(layouts):\n    ''' Utility function for merging multiple layouts.\n\n    Args:\n        layouts (list): A list of BIDSLayout instances to merge.\n    Returns:\n        A BIDSLayout containing merged files and entities.\n    Notes:\n        Layouts will be merged in the order of the elements in the list. I.e.,\n        the first Layout will be updated with all values in the 2nd Layout,\n        then the result will be updated with values from the 3rd Layout, etc.\n        This means that order matters: in the event of entity or filename\n        conflicts, later layouts will take precedence.\n    '''\n    layout = layouts[0].clone()\n\n    for l in layouts[1:]:\n        layout.files.update(l.files)\n        layout.domains.update(l.domains)\n\n        for k, v in l.entities.items():\n            if k not in layout.entities:\n                layout.entities[k] = v\n            else:\n                layout.entities[k].files.update(v.files)\n\n    return layout", "response": "Utility function for merging multiple BIDSLayout instances into one BIDSLayout."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck whether the file matches all of the passed entities extensions and domains.", "response": "def _matches(self, entities=None, extensions=None, domains=None,\n                 regex_search=False):\n        \"\"\"\n        Checks whether the file matches all of the passed entities and\n        extensions.\n\n        Args:\n            entities (dict): A dictionary of entity names -> regex patterns.\n            extensions (str, list): One or more file extensions to allow.\n            domains (str, list): One or more domains the file must match.\n            regex_search (bool): Whether to require exact match (False) or\n                regex search (True) when comparing the query string to each\n                entity.\n        Returns:\n            True if _all_ entities and extensions match; False otherwise.\n        \"\"\"\n        if extensions is not None:\n            if isinstance(extensions, six.string_types):\n                extensions = [extensions]\n            extensions = '(' + '|'.join(extensions) + ')$'\n            if re.search(extensions, self.filename) is None:\n                return False\n\n        if domains is not None:\n            domains = listify(domains)\n            if not set(self.domains) & set(domains):\n                return False\n\n        if entities is not None:\n\n            for name, val in entities.items():\n\n                if (name not in self.tags) ^ (val is None):\n                    return False\n\n                if val is None:\n                    continue\n\n                def make_patt(x):\n                    patt = '%s' % x\n                    if isinstance(x, (int, float)):\n                        # allow for leading zeros if a number was specified\n                        # regardless of regex_search\n                        patt = '0*' + patt\n                    if not regex_search:\n                        patt = '^%s$' % patt\n                    return patt\n\n                ent_patts = [make_patt(x) for x in listify(val)]\n                patt = '|'.join(ent_patts)\n\n                if re.search(patt, str(self.tags[name].value)) is None:\n                    return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the File as a named tuple.", "response": "def as_named_tuple(self):\n        \"\"\"\n        Returns the File as a named tuple. The full path plus all entity\n        key/value pairs are returned as attributes.\n        \"\"\"\n        keys = list(self.entities.keys())\n        replaced = []\n        for i, k in enumerate(keys):\n            if iskeyword(k):\n                replaced.append(k)\n                keys[i] = '%s_' % k\n        if replaced:\n            safe = ['%s_' % k for k in replaced]\n            warnings.warn(\"Entity names cannot be reserved keywords when \"\n                          \"representing a File as a namedtuple. Replacing \"\n                          \"entities %s with safe versions %s.\" % (keys, safe))\n        entities = dict(zip(keys, self.entities.values()))\n        _File = namedtuple('File', 'filename ' + ' '.join(entities.keys()))\n        return _File(filename=self.path, **entities)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncopying the contents of a file to a new location with target MimeType filename defined by the current File s entities and the specified path_patterns.", "response": "def copy(self, path_patterns, symbolic_link=False, root=None,\n             conflicts='fail'):\n        ''' Copy the contents of a file to a new location, with target\n        filename defined by the current File's entities and the specified\n        path_patterns. '''\n        new_filename = build_path(self.entities, path_patterns)\n        if not new_filename:\n            return None\n\n        if new_filename[-1] == os.sep:\n            new_filename += self.filename\n\n        if isabs(self.path) or root is None:\n            path = self.path\n        else:\n            path = join(root, self.path)\n\n        if not exists(path):\n            raise ValueError(\"Target filename to copy/symlink (%s) doesn't \"\n                             \"exist.\" % path)\n\n        if symbolic_link:\n            contents = None\n            link_to = path\n        else:\n            with open(path, 'r') as f:\n                contents = f.read()\n            link_to = None\n\n        write_contents_to_file(new_filename, contents=contents,\n                               link_to=link_to, content_mode='text', root=root,\n                               conflicts=conflicts)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match_file(self, f, update_file=False):\n        if self.map_func is not None:\n            val = self.map_func(f)\n        else:\n            m = self.regex.search(f.path)\n            val = m.group(1) if m is not None else None\n\n        return self._astype(val)", "response": "Determines whether the passed file matches the Entity."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_or_load_domain(self, domain):\n        ''' Return a domain if one already exists, or create a new one if not.\n\n        Args:\n            domain (str, dict): Can be one of:\n                - The name of the Domain to return (fails if none exists)\n                - A path to the Domain configuration file\n                - A dictionary containing configuration information\n        '''\n        if isinstance(domain, six.string_types):\n            if domain in self.domains:\n                return self.domains[domain]\n            elif exists(domain):\n                with open(domain, 'r') as fobj:\n                    domain = json.load(fobj)\n            else:\n                raise ValueError(\"No domain could be found/loaded from input \"\n                                 \"'{}'; value must be either the name of an \"\n                                 \"existing Domain, or a valid path to a \"\n                                 \"configuration file.\".format(domain))\n\n        # At this point, domain is a dict\n        name = domain['name']\n        if name in self.domains:\n            msg = (\"Domain with name '{}' already exists; returning existing \"\n                   \"Domain configuration.\".format(name))\n            warnings.warn(msg)\n            return self.domains[name]\n\n        entities = domain.get('entities', [])\n        domain = Domain(domain)\n        for e in entities:\n            self.add_entity(domain=domain, **e)\n        self.domains[name] = domain\n        return self.domains[name]", "response": "Return a domain if one already exists or create a new one if not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_inclusions(self, f, domains=None):\n        ''' Check file or directory against regexes in config to determine if\n            it should be included in the index '''\n\n        filename = f if isinstance(f, six.string_types) else f.path\n\n        if domains is None:\n            domains = list(self.domains.values())\n\n        # Inject the Layout at the first position for global include/exclude\n        domains = list(domains)\n        domains.insert(0, self)\n\n        for dom in domains:\n            # If file matches any include regex, then True\n            if dom.include:\n                for regex in dom.include:\n                    if re.search(regex, filename):\n                        return True\n                return False\n            else:\n                # If file matches any exclude regex, then False\n                for regex in dom.exclude:\n                    if re.search(regex, filename, flags=re.UNICODE):\n                        return False\n        return True", "response": "Check if the file or directory is included in the index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind an Entity instance by name. Checks both name and id fields.", "response": "def _find_entity(self, entity):\n        ''' Find an Entity instance by name. Checks both name and id fields.'''\n        if entity in self.entities:\n            return self.entities[entity]\n        _ent = [e for e in self.entities.values() if e.name == entity]\n        if len(_ent) > 1:\n            raise ValueError(\"Entity name '%s' matches %d entities. To \"\n                             \"avoid ambiguity, please prefix the entity \"\n                             \"name with its domain (e.g., 'bids.%s'.\" %\n                             (entity, len(_ent), entity))\n        if _ent:\n            return _ent[0]\n\n        raise ValueError(\"No entity '%s' found.\" % entity)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_index(self, filename):\n        ''' Save the current Layout's index to a .json file.\n\n        Args:\n            filename (str): Filename to write to.\n\n        Note: At the moment, this won't serialize directory-specific config\n        files. This means reconstructed indexes will only work properly in\n        cases where there aren't multiple layout specs within a project.\n        '''\n        data = {}\n        for f in self.files.values():\n            entities = {v.entity.id: v.value for k, v in f.tags.items()}\n            data[f.path] = {'domains': f.domains, 'entities': entities}\n        with open(filename, 'w') as outfile:\n            json.dump(data, outfile)", "response": "Save the current Layout s index to a. json file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the Layout s index from a plaintext file.", "response": "def load_index(self, filename, reindex=False):\n        ''' Load the Layout's index from a plaintext file.\n\n        Args:\n            filename (str): Path to the plaintext index file.\n            reindex (bool): If True, discards entity values provided in the\n                loaded index and instead re-indexes every file in the loaded\n                index against the entities defined in the config. Default is\n                False, in which case it is assumed that all entity definitions\n                in the loaded index are correct and do not need any further\n                validation.\n\n        Note: At the moment, directory-specific config files aren't serialized.\n        This means reconstructed indexes will only work properly in cases\n        where there aren't multiple layout specs within a project.\n        '''\n        self._reset_index()\n        with open(filename, 'r') as fobj:\n            data = json.load(fobj)\n\n        for path, file in data.items():\n\n            ents, domains = file['entities'], file['domains']\n\n            root, f = dirname(path), basename(path)\n            if reindex:\n                self._index_file(root, f, domains)\n            else:\n                f = self._make_file_object(root, f)\n                tags = {k: Tag(self.entities[k], v) for k, v in ents.items()}\n                f.tags = tags\n                self.files[f.path] = f\n\n                for ent, val in f.entities.items():\n                    self.entities[ent].add_file(f.path, val)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new Entity to tracking.", "response": "def add_entity(self, domain, **kwargs):\n        ''' Add a new Entity to tracking. '''\n\n        # Set the entity's mapping func if one was specified\n        map_func = kwargs.get('map_func', None)\n        if map_func is not None and not callable(kwargs['map_func']):\n            if self.entity_mapper is None:\n                raise ValueError(\"Mapping function '%s' specified for Entity \"\n                                 \"'%s', but no entity mapper was passed when \"\n                                 \"initializing the current Layout. Please make\"\n                                 \" sure the 'entity_mapper' argument is set.\" %\n                                 (map_func, kwargs['name']))\n            map_func = getattr(self.entity_mapper, kwargs['map_func'])\n            kwargs['map_func'] = map_func\n\n        ent = Entity(domain=domain, **kwargs)\n        domain.add_entity(ent)\n\n        if ent.mandatory:\n            self.mandatory.add(ent.id)\n\n        if ent.directory is not None:\n            ent.directory = ent.directory.replace('{{root}}', self.root)\n\n        self.entities[ent.id] = ent\n        for alias in ent.aliases:\n            self.entities[alias] = ent\n        if self.dynamic_getters:\n            func = partial(getattr(self, 'get'), target=ent.name,\n                           return_type='id')\n            func_name = inflect.engine().plural(ent.name)\n            setattr(self, 'get_%s' % func_name, func)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the files and metadata from the current Layout.", "response": "def get(self, return_type='tuple', target=None, extensions=None,\n            domains=None, regex_search=None, **kwargs):\n        \"\"\"\n        Retrieve files and/or metadata from the current Layout.\n\n        Args:\n            return_type (str): Type of result to return. Valid values:\n                'tuple': returns a list of namedtuples containing file name as\n                    well as attribute/value pairs for all named entities.\n                'file': returns a list of matching filenames.\n                'dir': returns a list of directories.\n                'id': returns a list of unique IDs. Must be used together with\n                    a valid target.\n                'obj': returns a list of matching File objects.\n            target (str): The name of the target entity to get results for\n                (if return_type is 'dir' or 'id').\n            extensions (str, list): One or more file extensions to filter on.\n                Files with any other extensions will be excluded.\n            domains (list): Optional list of domain names to scan for files.\n                If None, all available domains are scanned.\n            regex_search (bool or None): Whether to require exact matching\n                (False) or regex search (True) when comparing the query string\n                to each entity. If None (default), uses the value found in\n                self.\n            kwargs (dict): Any optional key/values to filter the entities on.\n                Keys are entity names, values are regexes to filter on. For\n                example, passing filter={ 'subject': 'sub-[12]'} would return\n                only files that match the first two subjects.\n\n        Returns:\n            A named tuple (default) or a list (see return_type for details).\n        \"\"\"\n\n        if regex_search is None:\n            regex_search = self.regex_search\n\n        result = []\n        filters = {}\n        filters.update(kwargs)\n\n        for filename, file in self.files.items():\n            if not file._matches(filters, extensions, domains, regex_search):\n                continue\n            result.append(file)\n\n        # Convert to relative paths if needed\n        if not self.absolute_paths:\n            for i, f in enumerate(result):\n                f = copy(f)\n                f.path = relpath(f.path, self.root)\n                result[i] = f\n\n        if return_type == 'file':\n            return natural_sort([f.path for f in result])\n\n        if return_type == 'tuple':\n            result = [r.as_named_tuple() for r in result]\n            return natural_sort(result, field='filename')\n\n        if return_type.startswith('obj'):\n            return result\n\n        else:\n            valid_entities = self.get_domain_entities(domains)\n\n            if target is None:\n                raise ValueError('If return_type is \"id\" or \"dir\", a valid '\n                                 'target entity must also be specified.')\n            result = [x for x in result if target in x.entities]\n\n            if return_type == 'id':\n                result = list(set([x.entities[target] for x in result]))\n                return natural_sort(result)\n\n            elif return_type == 'dir':\n                template = valid_entities[target].directory\n                if template is None:\n                    raise ValueError('Return type set to directory, but no '\n                                     'directory template is defined for the '\n                                     'target entity (\\\"%s\\\").' % target)\n                # Construct regex search pattern from target directory template\n                to_rep = re.findall('\\{(.*?)\\}', template)\n                for ent in to_rep:\n                    patt = valid_entities[ent].pattern\n                    template = template.replace('{%s}' % ent, patt)\n                template += '[^\\%s]*$' % os.path.sep\n                matches = [f.dirname for f in result\n                           if re.search(template, f.dirname)]\n                return natural_sort(list(set(matches)))\n\n            else:\n                raise ValueError(\"Invalid return_type specified (must be one \"\n                                 \"of 'tuple', 'file', 'id', or 'dir'.\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count(self, entity, files=False):\n        return self._find_entity(entity).count(files)", "response": "Returns the number of unique values or files for the named entity."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn information for all Files tracked in the Layout as a pandas DataFrame.", "response": "def as_data_frame(self, **kwargs):\n        \"\"\"\n        Return information for all Files tracked in the Layout as a pandas\n        DataFrame.\n\n        Args:\n            kwargs: Optional keyword arguments passed on to get(). This allows\n                one to easily select only a subset of files for export.\n        Returns:\n            A pandas DataFrame, where each row is a file, and each column is\n                a tracked entity. NaNs are injected whenever a file has no\n                value for a given attribute.\n        \"\"\"\n        try:\n            import pandas as pd\n        except ImportError:\n            raise ImportError(\"What are you doing trying to export a Layout \"\n                              \"as a pandas DataFrame when you don't have \"\n                              \"pandas installed? Eh? Eh?\")\n        if kwargs:\n            files = self.get(return_type='obj', **kwargs)\n        else:\n            files = self.files.values()\n        data = pd.DataFrame.from_records([f.entities for f in files])\n        data.insert(0, 'path', [f.path for f in files])\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwalking up the file tree from the specified path and return the nearest matching file.", "response": "def get_nearest(self, path, return_type='file', strict=True, all_=False,\n                    ignore_strict_entities=None, full_search=False, **kwargs):\n        ''' Walk up the file tree from the specified path and return the\n        nearest matching file(s).\n\n        Args:\n            path (str): The file to search from.\n            return_type (str): What to return; must be one of 'file' (default)\n                or 'tuple'.\n            strict (bool): When True, all entities present in both the input\n                path and the target file(s) must match perfectly. When False,\n                files will be ordered by the number of matching entities, and\n                partial matches will be allowed.\n            all_ (bool): When True, returns all matching files. When False\n                (default), only returns the first match.\n            ignore_strict_entities (list): Optional list of entities to\n                exclude from strict matching when strict is True. This allows\n                one to search, e.g., for files of a different type while\n                matching all other entities perfectly by passing\n                ignore_strict_entities=['type'].\n            full_search (bool): If True, searches all indexed files, even if\n                they don't share a common root with the provided path. If\n                False, only files that share a common root will be scanned.\n            kwargs: Optional keywords to pass on to .get().\n        '''\n\n        entities = {}\n        for ent in self.entities.values():\n            m = ent.regex.search(path)\n            if m:\n                entities[ent.name] = ent._astype(m.group(1))\n\n        # Remove any entities we want to ignore when strict matching is on\n        if strict and ignore_strict_entities is not None:\n            for k in ignore_strict_entities:\n                entities.pop(k, None)\n\n        results = self.get(return_type='file', **kwargs)\n\n        folders = defaultdict(list)\n\n        for filename in results:\n            f = self.get_file(filename)\n            folders[f.dirname].append(f)\n\n        def count_matches(f):\n            f_ents = f.entities\n            keys = set(entities.keys()) & set(f_ents.keys())\n            shared = len(keys)\n            return [shared, sum([entities[k] == f_ents[k] for k in keys])]\n\n        matches = []\n\n        search_paths = []\n        while True:\n            if path in folders and folders[path]:\n                search_paths.append(path)\n            parent = dirname(path)\n            if parent == path:\n                break\n            path = parent\n\n        if full_search:\n            unchecked = set(folders.keys()) - set(search_paths)\n            search_paths.extend(path for path in unchecked if folders[path])\n\n        for path in search_paths:\n            # Sort by number of matching entities. Also store number of\n            # common entities, for filtering when strict=True.\n            num_ents = [[f] + count_matches(f) for f in folders[path]]\n            # Filter out imperfect matches (i.e., where number of common\n            # entities does not equal number of matching entities).\n            if strict:\n                num_ents = [f for f in num_ents if f[1] == f[2]]\n            num_ents.sort(key=lambda x: x[2], reverse=True)\n\n            if num_ents:\n                matches.append(num_ents[0][0])\n\n            if not all_:\n                break\n\n        matches = [m.path if return_type == 'file' else m.as_named_tuple()\n                   for m in matches]\n        return matches if all_ else matches[0] if matches else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a target filename for a file or dictionary of entities.", "response": "def build_path(self, source, path_patterns=None, strict=False,\n                   domains=None):\n        ''' Constructs a target filename for a file or dictionary of entities.\n\n        Args:\n            source (str, File, dict): The source data to use to construct the\n                new file path. Must be one of:\n                - A File object\n                - A string giving the path of a File contained within the\n                  current Layout.\n                - A dict of entities, with entity names in keys and values in\n                  values\n            path_patterns (list): Optional path patterns to use to construct\n                the new file path. If None, the Layout-defined patterns will\n                be used.\n            strict (bool): If True, all entities must be matched inside a\n                pattern in order to be a valid match. If False, extra entities\n                will be ignored so long as all mandatory entities are found.\n            domains (str, list): Optional name(s) of domain(s) to scan for\n                path patterns. If None, all domains are scanned. If two or more\n                domains are provided, the order determines the precedence of\n                path patterns (i.e., earlier domains will have higher\n                precedence).\n        '''\n\n        if isinstance(source, six.string_types):\n            if source not in self.files:\n                source = join(self.root, source)\n\n            source = self.get_file(source)\n\n        if isinstance(source, File):\n            source = source.entities\n\n        if path_patterns is None:\n            if domains is None:\n                domains = list(self.domains.keys())\n            path_patterns = []\n            for dom in listify(domains):\n                path_patterns.extend(self.domains[dom].path_patterns)\n\n        return build_path(source, path_patterns, strict)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_contents_to_file(self, entities, path_patterns=None,\n                               contents=None, link_to=None,\n                               content_mode='text', conflicts='fail',\n                               strict=False, domains=None, index=False,\n                               index_domains=None):\n        \"\"\"\n        Write arbitrary data to a file defined by the passed entities and\n        path patterns.\n\n        Args:\n            entities (dict): A dictionary of entities, with Entity names in\n                keys and values for the desired file in values.\n            path_patterns (list): Optional path patterns to use when building\n                the filename. If None, the Layout-defined patterns will be\n                used.\n            contents (object): Contents to write to the generate file path.\n                Can be any object serializable as text or binary data (as\n                defined in the content_mode argument).\n            conflicts (str): One of 'fail', 'skip', 'overwrite', or 'append'\n            that defines the desired action when the output path already\n            exists. 'fail' raises an exception; 'skip' does nothing;\n            'overwrite' overwrites the existing file; 'append' adds a suffix\n            to each file copy, starting with 1. Default is 'fail'.\n            strict (bool): If True, all entities must be matched inside a\n                pattern in order to be a valid match. If False, extra entities\n                will be ignored so long as all mandatory entities are found.\n            domains (list): List of Domains to scan for path_patterns. Order\n                determines precedence (i.e., earlier Domains will be scanned\n                first). If None, all available domains are included.\n            index (bool): If True, adds the generated file to the current\n                index using the domains specified in index_domains.\n            index_domains (list): List of domain names to attach the generated\n                file to when indexing. Ignored if index == False.  If None,\n                All available domains are used.\n\n        \"\"\"\n        path = self.build_path(entities, path_patterns, strict, domains)\n\n        if path is None:\n            raise ValueError(\"Cannot construct any valid filename for \"\n                             \"the passed entities given available path \"\n                             \"patterns.\")\n\n        write_contents_to_file(path, contents=contents, link_to=link_to,\n                               content_mode=content_mode, conflicts=conflicts,\n                               root=self.root)\n\n        if index:\n            # TODO: Default to using only domains that have at least one\n            # tagged entity in the generated file.\n            if index_domains is None:\n                index_domains = list(self.domains.keys())\n            self._index_file(self.root, path, index_domains)", "response": "Writes arbitrary data to a file in the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef configure_logger(name, log_stream=sys.stdout, log_file=None,\n                     log_level=logging.INFO, keep_old_handlers=False,\n                     propagate=False):\n    \"\"\"Configures and returns a logger.\n\n    This function serves to simplify the configuration of a logger that\n    writes to a file and/or to a stream (e.g., stdout).\n\n    Parameters\n    ----------\n    name: str\n        The name of the logger. Typically set to ``__name__``.\n    log_stream: a stream object, optional\n        The stream to write log messages to. If ``None``, do not write to any\n        stream. The default value is `sys.stdout`.\n    log_file: str, optional\n        The path of a file to write log messages to. If None, do not write to\n        any file. The default value is ``None``.\n    log_level: int, optional\n        A logging level as `defined`__ in Python's logging module. The default\n        value is `logging.INFO`.\n    keep_old_handlers: bool, optional\n        If set to ``True``, keep any pre-existing handlers that are attached to\n        the logger. The default value is ``False``.\n    propagate: bool, optional\n        If set to ``True``, propagate the loggers messages to the parent\n        logger. The default value is ``False``.\n\n    Returns\n    -------\n    `logging.Logger`\n        The logger.\n\n    Notes\n    -----\n    Note that if ``log_stream`` and ``log_file`` are both ``None``, no handlers\n    will be created.\n\n    __ loglvl_\n\n    .. _loglvl: https://docs.python.org/2/library/logging.html#logging-levels\n\n    \"\"\"\n    # create a child logger\n    logger = logging.getLogger(name)\n\n    # set the logger's level\n    logger.setLevel(log_level)\n\n    # set the logger's propagation attribute\n    logger.propagate = propagate\n\n    if not keep_old_handlers:\n        # remove previously attached handlers\n        logger.handlers = []\n\n    # create the formatter\n    log_fmt = '[%(asctime)s] %(levelname)s: %(message)s'\n    log_datefmt = '%Y-%m-%d %H:%M:%S'\n    formatter = logging.Formatter(log_fmt, log_datefmt)\n\n    # create and attach the handlers\n\n    if log_stream is not None:\n        # create a StreamHandler\n        stream_handler = logging.StreamHandler(log_stream)\n        stream_handler.setFormatter(formatter)\n        logger.addHandler(stream_handler)\n\n    if log_file is not None:\n        # create a FileHandler\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n\n    if log_stream is None and log_file is None:\n        # \"no handler\" => use NullHandler\n        logger.addHandler(logging.NullHandler())\n      \n    return logger", "response": "Configures and returns a logger that writes to a file and optionally to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(milliseconds, func, *args, **kwargs):\n\n    stopper = threading.Event()\n    def interval(seconds, func, *args, **kwargs):\n        \"\"\"outer wrapper\"\"\"\n        def wrapper():\n            \"\"\"inner wrapper\"\"\"\n            if stopper.isSet():\n                return\n            interval(seconds, func, *args, **kwargs)\n            try:\n                func(*args, **kwargs)\n            except: # pylint: disable=bare-except\n                logging.error(\"Error during interval\")\n                logging.error(traceback.format_exc())\n\n        thread = threading.Timer(seconds, wrapper)\n        thread.daemon = True\n        thread.start()\n    interval(milliseconds/1000, func, *args, **kwargs)\n    return stopper", "response": "Start a function every 1000 seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake two C { list } of codons and returns information about the min and max distance between them.", "response": "def codonInformation(codons1, codons2):\n    \"\"\"\n    Take two C{list} of codons, and returns information about the min and\n    max distance between them.\n\n    @param codon1: a C{list} of codons.\n    @param codon2: a C{list} of codons.\n\n    @return: a dict whose keys are C{int} distances and whose values are lists\n        of pairs of codons.\n    \"\"\"\n    result = defaultdict(list)\n    for c1 in codons1:\n        for c2 in codons2:\n            distance = findDistance(c1, c2)\n            result[distance].append([c1, c2])\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts protein-coding genes and store in tab-delimited text file. Parameters ---------- args: argparse.Namespace object, optional The argument values. If not specified, the values will be obtained by parsing the command line arguments using the `argparse` module. Returns ------- int Exit code (0 if no error occurred). Raises ------ SystemError If the version of the Python interpreter is not >= 2.7.", "response": "def main(args=None):\n    \"\"\"Extract protein-coding genes and store in tab-delimited text file.\n\n    Parameters\n    ----------\n    args: argparse.Namespace object, optional\n        The argument values. If not specified, the values will be obtained by\n        parsing the command line arguments using the `argparse` module.\n\n    Returns\n    -------\n    int\n        Exit code (0 if no error occurred).\n \n    Raises\n    ------\n    SystemError\n        If the version of the Python interpreter is not >= 2.7.\n    \"\"\"\n\n    vinfo = sys.version_info\n    if not vinfo >= (2, 7):\n        raise SystemError('Python interpreter version >= 2.7 required, '\n                          'found %d.%d instead.' %(vinfo.major, vinfo.minor))\n\n    if args is None:\n        # parse command-line arguments\n        parser = get_argument_parser()\n        args = parser.parse_args()\n\n    input_file = args.annotation_file\n    output_file = args.output_file\n    # species = args.species\n    chrom_pat = args.chromosome_pattern\n    log_file = args.log_file\n    quiet = args.quiet\n    verbose = args.verbose\n\n    # configure root logger\n    log_stream = sys.stdout\n    if output_file == '-':\n        # if we print output to stdout, redirect log messages to stderr\n        log_stream = sys.stderr\n\n    logger = misc.get_logger(log_stream=log_stream, log_file=log_file,\n                             quiet=quiet, verbose=verbose)\n\n    #if chrom_pat is None:\n    #    chrom_pat = ensembl.SPECIES_CHROMPAT[species]\n\n    if chrom_pat is not None:\n        logger.info('Regular expression used for filtering chromosome names: '\n                    '\"%s\"', chrom_pat)\n\n    if input_file == '-':\n        input_file = sys.stdin\n\n    if output_file == '-':\n        output_file = sys.stdout\n\n    genes = ensembl.get_protein_coding_genes(\n        input_file,\n        chromosome_pattern=chrom_pat)\n    genes.to_csv(output_file, sep='\\t', index=False)\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_stats(self, *stats):\n\n        self.statistics = OrderedDict()\n        for port in self.ports:\n            port_stats = IxeStatTotal(port).get_attributes(FLAG_RDONLY, *stats)\n            port_stats.update({c + '_rate': v for c, v in\n                               IxeStatRate(port).get_attributes(FLAG_RDONLY, *stats).items()})\n            self.statistics[str(port)] = port_stats\n        return self.statistics", "response": "Read port statistics from chassis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_stats(self, *stats):\n        from ixexplorer.ixe_stream import IxePacketGroupStream\n        sleep_time = 0.1  # in cases we only want few counters but very fast we need a smaller sleep time\n        if not stats:\n            stats = [m.attrname for m in IxePgStats.__tcl_members__ if m.flags & FLAG_RDONLY]\n            sleep_time = 1\n\n        # Read twice to refresh rate statistics.\n        for port in self.tx_ports_streams:\n            port.api.call_rc('streamTransmitStats get {} 1 4096'.format(port.uri))\n        for rx_port in self.rx_ports:\n            rx_port.api.call_rc('packetGroupStats get {} 0 65536'.format(rx_port.uri))\n        time.sleep(sleep_time)\n\n        self.statistics = OrderedDict()\n        for tx_port, streams in self.tx_ports_streams.items():\n            for stream in streams:\n                stream_stats = OrderedDict()\n                tx_port.api.call_rc('streamTransmitStats get {} 1 4096'.format(tx_port.uri))\n                stream_tx_stats = IxeStreamTxStats(tx_port, stream.index)\n                stream_stats_tx = {c: v for c, v in stream_tx_stats.get_attributes(FLAG_RDONLY).items()}\n                stream_stats['tx'] = stream_stats_tx\n                stream_stat_pgid = IxePacketGroupStream(stream).groupId\n                stream_stats_pg = pg_stats_dict()\n                for port in self.session.ports.values():\n                    stream_stats_pg[str(port)] = OrderedDict(zip(stats, [-1] * len(stats)))\n                for rx_port in self.rx_ports:\n                    if not stream.rx_ports or rx_port in stream.rx_ports:\n                        rx_port.api.call_rc('packetGroupStats get {} 0 65536'.format(rx_port.uri))\n                        pg_stats = IxePgStats(rx_port, stream_stat_pgid)\n                        stream_stats_pg[str(rx_port)] = pg_stats.read_stats(*stats)\n                stream_stats['rx'] = stream_stats_pg\n                self.statistics[str(stream)] = stream_stats\n        return self.statistics", "response": "Read stream statistics from chassis."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps that provides common interface to all arbiters", "response": "def arbiter(rst, clk, req_vec, gnt_vec=None, gnt_idx=None, gnt_vld=None, gnt_rdy=None, ARBITER_TYPE=\"priority\"):\n    ''' Wrapper that provides common interface to all arbiters '''\n    if ARBITER_TYPE == \"priority\":\n        _arb = arbiter_priority(req_vec, gnt_vec, gnt_idx, gnt_vld)\n    elif (ARBITER_TYPE == \"roundrobin\"):\n        _arb = arbiter_roundrobin(rst, clk, req_vec, gnt_vec, gnt_idx, gnt_vld, gnt_rdy)\n    else:\n        assert \"Arbiter: Unknown arbiter type: {}\".format(ARBITER_TYPE)\n\n    return _arb"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef arbiter_priority(req_vec, gnt_vec=None, gnt_idx=None, gnt_vld=None):\n    REQ_NUM = len(req_vec)\n    gnt_vec_s = Signal(intbv(0)[REQ_NUM:])\n    gnt_idx_s = Signal(intbv(0, min=0, max=REQ_NUM))\n    gnt_vld_s = Signal(bool(0))\n\n    @always_comb\n    def prioroty_encoder():\n        gnt_vec_s.next = 0\n        gnt_idx_s.next = 0\n        gnt_vld_s.next = 0\n        for i in range(REQ_NUM):\n            if ( req_vec[i]==1 ):\n                gnt_vec_s.next[i] = 1\n                gnt_idx_s.next = i\n                gnt_vld_s.next = 1\n                break\n\n    if gnt_vec!=None: _vec = assign(gnt_vec, gnt_vec_s)\n    if gnt_idx!=None: _idx = assign(gnt_idx, gnt_idx_s)\n    if gnt_vld!=None: _vld = assign(gnt_vld, gnt_vld_s)\n\n    return instances()", "response": "Static priority arbiter for the current request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrounding Robin arbiter for the current request and grant.", "response": "def arbiter_roundrobin(rst, clk, req_vec, gnt_vec=None, gnt_idx=None, gnt_vld=None, gnt_rdy=None):\n    \"\"\" Round Robin arbiter: finds the active request with highest priority and presents its index on the gnt_idx output.\n            req_vec - (i) vector of request signals, priority changes dynamically\n            gnt_vec - (o) optional, vector of grants, one grant per request, only one grant can be active at at time\n            gnt_idx - (o) optional, grant index, index of the granted request\n            gnt_vld - (o) optional, grant valid, indicate that there is a granted request\n            gnt_rdy - (i) grant ready, indicates that the current grant is consumed and priority should be updated.\n                          The priority is updated only if there is a valid grant when gnt_rdy is activated.\n                          When priority is updated, the currently granted req_vec[gnt_idx] gets the lowest priority and\n                          req_vec[gnt_idx+1] gets the highest priority.\n                          gnt_rdy should be activated in the same clock cycle when output the grant is used\n    \"\"\"\n    REQ_NUM = len(req_vec)\n    ptr = Signal(intbv(0, min=0, max=REQ_NUM))\n\n    gnt_vec_s = Signal(intbv(0)[REQ_NUM:])\n    gnt_idx_s = Signal(intbv(0, min=0, max=REQ_NUM))\n    gnt_vld_s = Signal(bool(0))\n\n    @always(clk.posedge)\n    def ptr_proc():\n        if (rst):\n            ptr.next = REQ_NUM-1\n        elif (gnt_rdy and gnt_vld_s):\n            ptr.next = gnt_idx_s\n\n    @always_comb\n    def roundrobin_encoder():\n        gnt_vec_s.next = 0\n        gnt_idx_s.next = 0\n        gnt_vld_s.next = 0\n        for i in range(REQ_NUM):\n            if (i>ptr):\n                if ( req_vec[i]==1 ):\n                    gnt_vec_s.next[i] = 1\n                    gnt_idx_s.next = i\n                    gnt_vld_s.next = 1\n                    return\n        for i in range(REQ_NUM):\n            if ( req_vec[i]==1 ):\n                gnt_vec_s.next[i] = 1\n                gnt_idx_s.next = i\n                gnt_vld_s.next = 1\n                return\n\n    if gnt_vec!=None: _vec = assign(gnt_vec, gnt_vec_s)\n    if gnt_idx!=None: _idx = assign(gnt_idx, gnt_idx_s)\n    if gnt_vld!=None: _vld = assign(gnt_vld, gnt_vld_s)\n\n    return instances()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns 24 - byte Truncated Digest sequence seq", "response": "def seq_seqhash(seq, normalize=True):\n    \"\"\"returns 24-byte Truncated Digest sequence `seq`\n\n    >>> seq_seqhash(\"\")\n    'z4PhNX7vuL3xVChQ1m2AB9Yg5AULVxXc'\n\n    >>> seq_seqhash(\"ACGT\")\n    'aKF498dAxcJAqme6QYQ7EZ07-fiw8Kw2'\n\n    >>> seq_seqhash(\"acgt\")\n    'aKF498dAxcJAqme6QYQ7EZ07-fiw8Kw2'\n\n    >>> seq_seqhash(\"acgt\", normalize=False)\n    'eFwawHHdibaZBDcs9kW3gm31h1NNJcQe'\n\n    \"\"\"\n\n    seq = normalize_sequence(seq) if normalize else seq\n    return str(vmc_digest(seq, digest_size=24))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns seguid for sequence seq", "response": "def seq_seguid(seq, normalize=True):\n    \"\"\"returns seguid for sequence `seq`\n\n    This seguid is compatible with BioPython's seguid.\n\n    >>> seq_seguid('')\n    '2jmj7l5rSw0yVb/vlWAYkK/YBwk'\n\n    >>> seq_seguid('ACGT')\n    'IQiZThf2zKn/I1KtqStlEdsHYDQ'\n\n    >>> seq_seguid('acgt')\n    'IQiZThf2zKn/I1KtqStlEdsHYDQ'\n\n    >>> seq_seguid('acgt', normalize=False)\n    'lII0AoG1/I8qKY271rgv5CFZtsU'\n\n    \"\"\"\n    seq = normalize_sequence(seq) if normalize else seq\n    bseq = seq.encode(\"ascii\")\n    return base64.b64encode(hashlib.sha1(bseq).digest()).decode(\"ascii\").rstrip(\n        '=')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef seq_md5(seq, normalize=True):\n    seq = normalize_sequence(seq) if normalize else seq\n    bseq = seq.encode(\"ascii\")\n    return hashlib.md5(bseq).hexdigest()", "response": "returns unicode md5 as hex digest for sequence seq."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning unicode sha1 hexdigest for sequence seq", "response": "def seq_sha1(seq, normalize=True):\n    \"\"\"returns unicode sha1 hexdigest for sequence `seq`.\n\n    >>> seq_sha1('')\n    'da39a3ee5e6b4b0d3255bfef95601890afd80709'\n\n    >>> seq_sha1('ACGT')\n    '2108994e17f6cca9ff2352ada92b6511db076034'\n\n    >>> seq_sha1('acgt')\n    '2108994e17f6cca9ff2352ada92b6511db076034'\n\n    >>> seq_sha1('acgt', normalize=False)\n    '9482340281b5fc8f2a298dbbd6b82fe42159b6c5'\n\n    \"\"\"\n\n    seq = normalize_sequence(seq) if normalize else seq\n    bseq = seq.encode(\"ascii\")\n    return hashlib.sha1(bseq).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning unicode sequence sha512 hexdigest for sequence seq", "response": "def seq_sha512(seq, normalize=True):\n    \"\"\"returns unicode sequence sha512 hexdigest for sequence `seq`.\n\n    >>> seq_sha512('')\n    'cf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e'\n\n    >>> seq_sha512('ACGT')\n    '68a178f7c740c5c240aa67ba41843b119d3bf9f8b0f0ac36cf701d26672964efbd536d197f51ce634fc70634d1eefe575bec34c83247abc52010f6e2bbdb8253'\n\n    >>> seq_sha512('acgt')\n    '68a178f7c740c5c240aa67ba41843b119d3bf9f8b0f0ac36cf701d26672964efbd536d197f51ce634fc70634d1eefe575bec34c83247abc52010f6e2bbdb8253'\n\n    >>> seq_sha512('acgt', normalize=False)\n    '785c1ac071dd89b69904372cf645b7826df587534d25c41edb2862e54fb2940d697218f2883d2bf1a11cdaee658c7f7ab945a1cfd08eb26cbce57ee88790250a'\n\n    \"\"\"\n\n    seq = normalize_sequence(seq) if normalize else seq\n    bseq = seq.encode(\"ascii\")\n    return hashlib.sha512(bseq).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn VMC identifier for sequence seq", "response": "def seq_vmc_identifier(seq, normalize=True):\n    \"\"\"returns VMC identifier (record) for sequence `seq`\n\n    See https://github.com/ga4gh/vmc\n\n    >>> seq_vmc_identifier(\"\") == {'namespace': 'VMC', 'accession': 'GS_z4PhNX7vuL3xVChQ1m2AB9Yg5AULVxXc'}\n    True\n\n    >>> seq_vmc_identifier(\"ACGT\") == {'namespace': 'VMC', 'accession': 'GS_aKF498dAxcJAqme6QYQ7EZ07-fiw8Kw2'}\n    True\n\n    >>> seq_vmc_identifier(\"acgt\") == {'namespace': 'VMC', 'accession': 'GS_aKF498dAxcJAqme6QYQ7EZ07-fiw8Kw2'}\n    True\n\n    >>> seq_vmc_identifier(\"acgt\", normalize=False) == {'namespace': 'VMC', 'accession': 'GS_eFwawHHdibaZBDcs9kW3gm31h1NNJcQe'}\n    True\n\n    \"\"\"\n    seq = normalize_sequence(seq) if normalize else seq\n    return {\"namespace\": \"VMC\", \"accession\": \"GS_\" + str(vmc_digest(seq))}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps a single - end read using STAR.", "response": "def map_single_end(credentials, instance_config, instance_name,\n                   script_dir, index_dir, fastq_file, output_dir,\n                   num_threads=None, seed_start_lmax=None,\n                   mismatch_nmax=None, multimap_nmax=None,\n                   splice_min_overhang=None,\n                   out_mult_nmax=None, sort_bam=True, keep_unmapped=False,\n                   self_destruct=True, compressed=True,\n                   **kwargs):\n    \"\"\"Maps single-end reads using STAR.\n\n    Reads are expected in FASTQ format. By default, they are also expected to\n    be compressed with gzip.\n\n    - recommended machine type: \"n1-standard-16\" (60 GB of RAM, 16 vCPUs).\n    - recommended disk size: depends on size of FASTQ files, at least 128 GB.\n\n    TODO: docstring\"\"\"\n\n    if sort_bam:\n        out_sam_type = 'BAM SortedByCoordinate'\n    else:\n        out_sam_type = 'BAM Unsorted'\n\n    # template expects a list of FASTQ files\n    fastq_files = fastq_file\n    if isinstance(fastq_files, (str, _oldstr)):\n        fastq_files = [fastq_file]\n\n    template = _TEMPLATE_ENV.get_template(\n        os.path.join('map_single-end.sh'))\n    startup_script = template.render(\n        script_dir=script_dir,\n        index_dir=index_dir,\n        fastq_files=fastq_files,\n        output_dir=output_dir,\n        num_threads=num_threads,\n        seed_start_lmax=seed_start_lmax,\n        self_destruct=self_destruct,\n        mismatch_nmax=mismatch_nmax,\n        multimap_nmax=multimap_nmax,\n        splice_min_overhang=splice_min_overhang,\n        out_mult_nmax=out_mult_nmax,\n        keep_unmapped=keep_unmapped,\n        compressed=compressed,\n        out_sam_type=out_sam_type)\n\n    if len(startup_script) > 32768:\n        raise ValueError('Startup script larger than 32,768 bytes!')\n\n    #print(startup_script)\n\n    op_name = instance_config.create_instance(\n        credentials, instance_name, startup_script=startup_script, **kwargs)\n\n    return op_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a STAR index.", "response": "def generate_index(credentials, instance_config, instance_name,\n                   script_dir, genome_file, output_dir, annotation_file=None,\n                   splice_overhang=100,\n                   num_threads=8, chromosome_bin_bits=18,\n                   genome_memory_limit=31000000000,\n                   self_destruct=True,\n                   **kwargs):\n    \"\"\"Generates a STAR index.\n\n    Recommended machine type: \"n1-highmem-8\" (52 GB of RAM, 8 vCPUs)\n\n    TODO: docstring\"\"\"\n\n    template = _TEMPLATE_ENV.get_template(\n        os.path.join('generate_index.sh'))\n    startup_script = template.render(\n        script_dir=script_dir,\n        genome_file=genome_file,\n        annotation_file=annotation_file,\n        splice_overhang=splice_overhang,\n        output_dir=output_dir,\n        num_threads=num_threads,\n        chromosome_bin_bits=chromosome_bin_bits,\n        genome_memory_limit=genome_memory_limit,\n        self_destruct=self_destruct)\n\n    op_name = instance_config.create_instance(\n        credentials, instance_name, startup_script=startup_script, **kwargs)\n\n    return op_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload and parse an Ensembl CHECKSUMS file and obtain checksums.", "response": "def get_file_checksums(url, ftp=None):\n    \"\"\"Download and parse an Ensembl CHECKSUMS file and obtain checksums.\n\n    Parameters\n    ----------\n    url : str\n        The URL of the CHECKSUM file.\n    ftp : `ftplib.FTP` or `None`, optional\n        An FTP connection.\n    \n    Returns\n    -------\n    `collections.OrderedDict`\n        An ordered dictionary containing file names as keys and checksums as\n        values.\n\n    Notes\n    -----\n    The checksums contains in Ensembl CHECKSUM files are obtained with the\n    UNIX `sum` command.\n    \"\"\"\n    assert isinstance(url, (str, _oldstr))\n    if ftp is not None:\n        assert isinstance(ftp, ftplib.FTP)\n\n    # open FTP connection if necessary\n    close_connection = False\n    ftp_server = 'ftp.ensembl.org'\n    ftp_user = 'anonymous'\n    if ftp is None:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(ftp_user)\n        close_connection = True    \n    \n    # download and parse CHECKSUM file\n    data = []\n    ftp.retrbinary('RETR %s' % url, data.append)\n    data = ''.join(d.decode('utf-8') for d in data).split('\\n')[:-1]\n    file_checksums = OrderedDict()\n    for d in data:\n        file_name = d[(d.rindex(' ') + 1):]\n        sum_ = int(d[:d.index(' ')])\n        file_checksums[file_name] = sum_\n    \n    logger.debug('Obtained checksums for %d files', len(file_checksums))\n\n    # close FTP connection if we opened it\n    if close_connection:\n        ftp.close()\n    \n    return file_checksums"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listify(obj, ignore=(list, tuple, type(None))):\n    ''' Wraps all non-list or tuple objects in a list; provides a simple way\n    to accept flexible arguments. '''\n    return obj if isinstance(obj, ignore) else [obj]", "response": "Wraps all non - list objects in a list ; provides a simple way to accept flexible arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_divisions(taxdump_file):\n    \n    with tarfile.open(taxdump_file) as tf:    \n        with tf.extractfile('division.dmp') as fh:\n            df = pd.read_csv(fh, header=None, sep='|', encoding='ascii')\n\n    # only keep division ids and names\n    df = df.iloc[:, [0, 2]]\n\n    # remove tab characters flanking each division name\n    df.iloc[:, 1] = df.iloc[:, 1].str.strip('\\t')\n\n    # generate dictionary\n    divisions = {}\n    for _, row in df.iterrows():\n        divisions[row.iloc[1]] = row.iloc[0]\n    \n    return divisions", "response": "Returns a dictionary mapping division names to division IDs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_species_taxon_ids(taxdump_file,\n                           select_divisions=None, exclude_divisions=None):\n    \"\"\"Get a list of species taxon IDs (allow filtering by division).\"\"\"\n    \n    if select_divisions and exclude_divisions:\n        raise ValueError('Cannot specify \"select_divisions\" and '\n                         '\"exclude_divisions\" at the same time.')\n\n    select_division_ids = None\n    exclude_division_ids = None\n    \n    divisions = None\n    if select_divisions or exclude_divisions:\n        divisions = _get_divisions(taxdump_file)\n        \n    if select_divisions:\n        select_division_ids = set([divisions[d] for d in select_divisions])\n        \n    elif exclude_divisions:\n        exclude_division_ids = set([divisions[d] for d in exclude_divisions])\n    \n    with tarfile.open(taxdump_file) as tf:    \n    \n        with tf.extractfile('nodes.dmp') as fh:\n            df = pd.read_csv(fh, header=None, sep='|', encoding='ascii')\n\n    # select only tax_id, rank, and division id columns\n    df = df.iloc[:, [0, 2, 4]]\n\n    if select_division_ids:\n        # select only species from specified divisions\n        df = df.loc[df.iloc[:, 2].isin(select_division_ids)]\n            \n    elif exclude_division_ids:\n        # exclude species from specified divisions\n        df = df.loc[~df.iloc[:, 2].isin(exclude_division_ids)]\n    \n    # remove tab characters flanking each rank name\n    df.iloc[:, 1] = df.iloc[:, 1].str.strip('\\t')\n\n    # get taxon IDs for all species\n    taxon_ids = df.iloc[:, 0].loc[df.iloc[:, 1] == 'species'].values\n    return taxon_ids", "response": "Get a list of species taxon IDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_species(taxdump_file, select_divisions=None,\n                exclude_divisions=None, nrows=None):\n    \"\"\"Get a dataframe with species information.\"\"\"\n    \n    if select_divisions and exclude_divisions:\n        raise ValueError('Cannot specify \"select_divisions\" and '\n                         '\"exclude_divisions\" at the same time.')\n\n    select_taxon_ids = _get_species_taxon_ids(\n        taxdump_file,\n        select_divisions=select_divisions,\n        exclude_divisions=exclude_divisions)\n    select_taxon_ids = set(select_taxon_ids)\n    \n    with tarfile.open(taxdump_file) as tf:\n        with tf.extractfile('names.dmp') as fh:    \n            df = pd.read_csv(fh, header=None, sep='|',\n                             encoding='ascii', nrows=nrows)\n\n    # only keep information we need\n    df = df.iloc[:, [0, 1, 3]]\n\n    # only select selected species\n    df = df.loc[df.iloc[:, 0].isin(select_taxon_ids)]\n\n    # remove tab characters flanking each \"name class\" entry\n    df.iloc[:, 2] = df.iloc[:, 2].str.strip('\\t')\n\n    # select only \"scientific name\" and \"common name\" rows\n    df = df.loc[df.iloc[:, 2].isin(['scientific name', 'common name'])]\n\n    # remove tab characters flanking each \"name\" entry \n    df.iloc[:, 1] = df.iloc[:, 1].str.strip('\\t')\n    \n    # collapse common names for each scientific name\n    common_names = defaultdict(list)\n    cn = df.loc[df.iloc[:, 2] == 'common name']\n    for _, row in cn.iterrows():\n        common_names[row.iloc[0]].append(row.iloc[1])\n        \n    # build final dataframe (this is very slow)\n    sn = df.loc[df.iloc[:, 2] == 'scientific name']\n    species = []\n    for i, row in sn.iterrows():\n        species.append([row.iloc[0], row.iloc[1],\n                        '|'.join(common_names[row.iloc[0]])])\n    species_df = pd.DataFrame(species).set_index(0)\n    species_df.columns = ['scientific_name', 'common_names']\n    species_df.index.name = 'taxon_id'\n    return species_df", "response": "Get a dataframe with species information."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset group of attributes without calling set between attributes regardless of global auto_set.", "response": "def set_attributes(self, **attributes):\n        \"\"\" Set group of attributes without calling set between attributes regardless of global auto_set.\n\n        Set will be called only after all attributes are set based on global auto_set.\n\n        :param attributes: dictionary of <attribute, value> to set.\n        \"\"\"\n\n        auto_set = IxeObject.get_auto_set()\n        IxeObject.set_auto_set(False)\n        for name, value in attributes.items():\n            setattr(self, name, value)\n        if auto_set:\n            self.ix_set()\n        IxeObject.set_auto_set(auto_set)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a consensus sequence for a given hit.", "response": "def consensusSequence(recordFilename, hitId, fastaFilename, eCutoff=None,\n                      db='nt', actualSequenceId=None):\n    \"\"\"\n    Build a consensus sequence against a target sequence.\n\n    recordFilename: the BLAST XML output file.\n    hitId: the str sequence id to examine the BLAST output for hits against.\n    fastaFilename: The name of the FASTA file containing query sequences,\n        or a list of fasta sequences from SeqIO.parse\n    eCutoff: converted e values less than this will be ignored.\n    db: the BLAST db to use to look up the target and, if given, actual\n        sequence.\n    actualSequenceId: the str id of the actual sequence (if known).\n    \"\"\"\n\n    print('TODO: This function is not finished yet.')\n    return\n\n    start = time()\n    if isinstance(recordFilename, str):\n        # TODO: REMOVE THE LIMIT IN THE NEXT LINE!\n        allhits = findHits(recordFilename, set([hitId]), limit=100)\n    else:\n        allhits = recordFilename\n    sequence = getSequence(hitId, db)\n    fasta, summary = summarizeHits(allhits, fastaFilename, eCutoff=eCutoff)\n    minX, maxX = summary['minX'], summary['maxX']\n    if actualSequenceId:\n        # UNUSED.\n        # actualSequence = getSequence(actualSequenceId, db)\n        pass\n    print(summary['hitCount'])\n    print('seq len =', len(sequence))\n    fasta = summary['fasta']\n    # The length of the consensus depends on where the query sequences fell\n    # when aligned with the target. The consensus could extend the target\n    # at both ends.\n    consensusLen = maxX - minX\n    consensus = [None, ] * consensusLen\n    for item in summary['items']:\n        print('NEW HSP')\n        printHSP(item['origHsp'])  # TODO: REMOVE ME\n        hsp = item['hsp']\n        print('HIT query-start=%d query-stop=%d subj-start=%d subj-stop=%d' % (\n            hsp['queryStart'], hsp['queryEnd'], hsp['subjectStart'],\n            hsp['subjectEnd']))\n        # print '   match: %s%s' % ('.' * hsp['subjectStart'], '-' *\n        # (hsp['subjectEnd'] - hsp['subjectStart']))\n        if item['frame']['subject'] > 0:\n            query = fasta[item['sequenceId']].seq\n        else:\n            query = fasta[item['sequenceId']].reverse_complement().seq\n        print('       target:',\n              sequence[hsp['queryStart']:hsp['queryEnd']].seq)\n        print('        query:', query)\n        match = []\n        for index in range(hsp['subjectStart'], hsp['subjectEnd']):\n            queryIndex = index - hsp['queryStart']\n            match.append('.' if query[queryIndex] == sequence[index] else '*')\n        print('        match: %s%s' % (\n            ' ' * (hsp['subjectStart'] - hsp['queryStart']), ''.join(match)))\n        print('        score:', item['convertedE'])\n        print('    match len:', hsp['subjectEnd'] - hsp['subjectStart'])\n        print('subject frame:', item['frame']['subject'])\n        for queryIndex, sequenceIndex in enumerate(\n                range(hsp['queryStart'], hsp['queryEnd'])):\n            consensusIndex = sequenceIndex + minX\n            locus = consensus[consensusIndex]\n            if locus is None:\n                consensus[consensusIndex] = locus = defaultdict(int)\n            locus[query[queryIndex]] += 1\n\n    # Print the consensus before the target, if any.\n    for index in range(minX, 0):\n        consensusIndex = index - minX\n        if consensus[consensusIndex]:\n            print('%d: %r' % (index, consensus[consensusIndex]))\n    # Print the consensus as it overlaps with the target, if any.\n    for index in range(0, len(sequence)):\n        consensusIndex = index - minX\n        try:\n            if consensus[consensusIndex]:\n                print('%d: %r (%s)' % (\n                    index, consensus[index], sequence[index]))\n        except KeyError:\n            # There's nothing left in the consensus, so we're done.\n            break\n    for index in range(len(sequence), maxX):\n        consensusIndex = index - minX\n        if consensus[consensusIndex]:\n            print('%d: %r' % (index, consensus[consensusIndex]))\n    stop = time()\n    report('Consensus sequence generated in %.3f mins.' %\n           ((stop - start) / 60.0))\n    return summary, consensus"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconsult site e retorna faixa para localidade", "response": "def consulta_faixa(self, localidade, uf):\n        \"\"\"Consulta site e retorna faixa para localidade\"\"\"\n        url = 'consultaFaixaCepAction.do'\n        data = {\n            'UF': uf,\n            'Localidade': localidade.encode('cp1252'),\n            'cfm': '1',\n            'Metodo': 'listaFaixaCEP',\n            'TipoConsulta': 'faixaCep',\n            'StartRow': '1',\n            'EndRow': '10',\n        }\n        html = self._url_open(url, data).read()\n        return self._parse_faixa(html)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconsult site e retorna lista de resultados", "response": "def consulta(self, endereco, primeiro=False,\n                 uf=None, localidade=None, tipo=None, numero=None):\n        \"\"\"Consulta site e retorna lista de resultados\"\"\"\n\n        if uf is None:\n            url = 'consultaEnderecoAction.do'\n            data = {\n                'relaxation': endereco.encode('ISO-8859-1'),\n                'TipoCep': 'ALL',\n                'semelhante': 'N',\n                'cfm': 1,\n                'Metodo': 'listaLogradouro',\n                'TipoConsulta': 'relaxation',\n                'StartRow': '1',\n                'EndRow': '10'\n            }\n        else:\n            url = 'consultaLogradouroAction.do'\n            data = {\n                'Logradouro': endereco.encode('ISO-8859-1'),\n                'UF': uf,\n                'TIPO': tipo,\n                'Localidade': localidade.encode('ISO-8859-1'),\n                'Numero': numero,\n                'cfm': 1,\n                'Metodo': 'listaLogradouro',\n                'TipoConsulta': 'logradouro',\n                'StartRow': '1',\n                'EndRow': '10'\n            }\n\n        h = self._url_open(url, data)\n        html = h.read()\n\n        if primeiro:\n            return self.detalhe()\n        else:\n            return self._parse_tabela(html)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _request(self, url, *,\n                 method='GET', headers=None, data=None, result_callback=None):\n        \"\"\"Perform synchronous request.\n\n        :param str url: request URL.\n        :param str method: request method.\n        :param object data: JSON-encodable object.\n        :param object -> object result_callback: result callback.\n\n        :rtype: dict\n        :raise: APIError\n        \"\"\"\n\n        retries_left = self._conn_retries\n\n        while True:\n            s = self._make_session()\n            try:\n                cert = None\n                if self._client_cert and self._client_key:\n                    cert = (self._client_cert, self._client_key)\n                elif self._client_cert:\n                    cert = self._client_cert\n\n                if self._verify_cert:\n                    verify = True\n                    if self._ca_certs:\n                        verify = self._ca_certs\n                else:\n                    verify = False\n\n                auth = None\n                if self._username and self._password:\n                    auth = (self._username, self._password)\n\n                response = s.request(method, url, data=data,\n                                     timeout=self._connect_timeout,\n                                     cert=cert,\n                                     headers=headers,\n                                     verify=verify,\n                                     auth=auth)\n                \"\"\":type: requests.models.Response\n                \"\"\"\n                if 400 <= response.status_code < 500:\n                    raise ClientError(\n                        response.status_code, response.content)\n                elif response.status_code >= 500:\n                    raise ServerError(\n                        response.status_code, response.content)\n\n                try:\n                    if result_callback:\n                        return result_callback(response.content)\n                except (ValueError, TypeError) as err:\n                    raise MalformedResponse(err) from None\n\n                return response.content\n\n            except (requests.exceptions.RequestException,\n                    requests.exceptions.BaseHTTPError) as exc:\n                if self._conn_retries is None or retries_left <= 0:\n                    raise CommunicationError(exc) from None\n                else:\n                    retries_left -= 1\n                    retry_in = (self._conn_retries - retries_left) * 2\n                    self._log.warning('Server communication error: %s. '\n                                      'Retrying in %s seconds.', exc, retry_in)\n                    time.sleep(retry_in)\n                    continue\n            finally:\n                s.close()", "response": "Perform a synchronous request to the specified URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_session():\n\n        sess = requests.Session()\n        sess.mount('http://', requests.adapters.HTTPAdapter(max_retries=False))\n        sess.mount('https://', requests.adapters.HTTPAdapter(max_retries=False))\n\n        return sess", "response": "Create session object.\n\n        :rtype: requests.Session"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_clinical_data(tcga_id):\n\n    payload = {\n        'attachment': 'true',\n        \"filters\": json.dumps({\n            \"op\": \"and\",\n            \"content\": [\n                {\n                    \"op\":\"in\",\n                    \"content\":{\n                        \"field\":\"cases.project.program.name\",\n                        \"value\":[\"TCGA\"]}},\n                {\n                    \"op\": \"in\",\n                    \"content\": {\n                        \"field\": \"project.project_id\",\n                        \"value\": [tcga_id]}}]\n        }),\n        'fields': 'case_id',\n        'expand': 'demographic,diagnoses,family_histories,exposures',\n        'format': 'JSON',\n        'pretty': 'true',\n        'size': 10000,\n        'filename': 'clinical.project-%s' % tcga_id,\n    }\n    r = requests.get('https://gdc-api.nci.nih.gov/cases', params=payload)\n    \n    j = json.loads(r.content.decode())\n    clinical = {}\n    valid = 0\n    for s in j:\n        if 'diagnoses' not in s:\n            continue\n        valid += 1\n        assert len(s['diagnoses']) == 1\n        diag = s['diagnoses'][0]\n        tcga_id = diag['submitter_id'][:12]\n        clinical[tcga_id] = diag\n\n    logger.info('Found clinical data for %d cases.', valid)\n    df = pd.DataFrame.from_dict(clinical).T\n    df.sort_index(inplace=True)\n    return df", "response": "Get clinical data for a TCGA project."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget biospecimen data for a TCGA project.", "response": "def get_biospecimen_data(tcga_id):\n    \"\"\"Get biospecimen data for a TCGA project.\n    \n    Parameters\n    ----------\n    tcga_id : str\n        The TCGA project ID.\n    \n    Returns\n    -------\n    `pandas.DataFrame`\n        The biospecmin data.\n\n    Notes\n    -----\n    Biospecimen data is associated with individual vials. TCGA vials correspond\n    to portions of a sample, and are uniquely identified by a 16-character\n    barcode. For example, one vial can contain FFPE material and the other\n    fresh-frozen material from the same sample. Each row in the returned data\n    frame corresponds to a vial.\n    \"\"\"\n\n    payload = {\n        'attachment': 'true',\n        \"filters\": json.dumps({\n            \"op\": \"and\",\n            \"content\": [\n                {\n                    \"op\":\"in\",\n                    \"content\":{\n                        \"field\":\"cases.project.program.name\",\n                        \"value\":[\"TCGA\"]}},\n                {\n                    \"op\": \"in\",\n                    \"content\": {\n                        \"field\": \"project.project_id\",\n                        \"value\": [tcga_id]}}]\n        }),\n        'fields': 'case_id',\n        'expand': ('samples,samples.portions,'\n                   'samples.portions.analytes,'\n                   'samples.portions.analytes.aliquots,'\n                   'samples.portions.analytes.aliquots.annotations,'\n                   'samples.portions.analytes.annotations,'\n                   'samples.portions.submitter_id,'\n                   'samples.portions.slides,'\n                   'samples.portions.annotations,'\n                   'samples.portions.center'),\n        'format': 'JSON',\n        'pretty': 'true',\n        'size': 10000,\n        'filename': 'biospecimen.project-%s' % tcga_id,\n    }\n    r = requests.get('https://gdc-api.nci.nih.gov/cases', params=payload)\n    \n    j = json.loads(r.content.decode())\n    biospec = {}\n    valid = 0\n    for case in j:\n        if 'samples' not in case:\n            continue\n        valid += 1\n        for s in case['samples']:\n            tcga_id = s['submitter_id'][:16]\n            del s['portions']\n            del s['submitter_id']\n            biospec[tcga_id] = s\n\n    logger.info('Found biospecimen data for %d cases.', valid)\n    df = pd.DataFrame.from_dict(biospec).T\n    df.sort_index(inplace=True)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_masked_cnv_manifest(tcga_id):\n    payload = {\n        \"filters\": json.dumps({\n            \"op\": \"and\",\n            \"content\" : [\n                {\n                    \"op\":\"in\",\n                    \"content\":{\n                        \"field\":\"cases.project.program.name\",\n                        \"value\":[\"TCGA\"]}},\n                {\n                    \"op\":\"in\",\n                    \"content\":{\n                        \"field\":\"cases.project.project_id\",\n                        \"value\":[tcga_id]}},\n                {\n                    \"op\":\"in\",\n                    \"content\":{\n                        \"field\":\"files.data_category\",\n                        \"value\":[\"Copy Number Variation\"]}},\n                {\n                    \"op\":\"in\",\n                    \"content\":{\n                        \"field\":\"files.data_type\",\n                        \"value\":[\"Masked Copy Number Segment\"]}}]\n        }),\n        \"return_type\":\"manifest\",\n        \"size\":10000,\n    }\n\n    r = requests.get('https://gdc-api.nci.nih.gov/files', params=payload)\n    df = pd.read_csv(io.StringIO(r.text), sep='\\t', header=0)\n    logger.info('Obtained manifest with %d files.', df.shape[0])\n    return df", "response": "Get manifest for masked copy - number variation data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_file_samples(file_ids):\n    assert isinstance(file_ids, Iterable)\n\n    # query TCGA API to get sample barcodes associated with file IDs\n    payload = {\n        \"filters\":json.dumps({\n            \"op\":\"in\",\n            \"content\":{\n                \"field\":\"files.file_id\",\n                \"value\": list(file_ids),\n            }\n        }),\n        \"fields\":\"file_id,cases.samples.submitter_id\",\n        \"size\":10000\n    }\n    r = requests.post('https://gdc-api.nci.nih.gov/files', data=payload)\n    j = json.loads(r.content.decode('utf-8'))\n    file_samples = OrderedDict()\n    for hit in j['data']['hits']:\n        file_id = hit['file_id']\n        assert len(hit['cases']) == 1\n        case = hit['cases'][0]\n        assert len(case['samples']) == 1\n        sample = case['samples'][0]\n        sample_barcode = sample['submitter_id']\n        file_samples[file_id] = sample_barcode\n\n    df = pd.DataFrame.from_dict(file_samples, orient='index')\n    df = df.reset_index()\n    df.columns = ['file_id', 'sample_barcode']\n    return df", "response": "Get the TCGA associated sample barcodes for a list of file IDs."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters file_sample data frame to only keep one file per sample.", "response": "def get_unique_sample_files(file_samples):\n    \"\"\"Filter file_sample data frame to only keep one file per sample.\n    \n    Params\n    ------\n    file_samples : `pandas.DataFrame`\n        A data frame containing a mapping between file IDs and sample barcodes.\n        This type of data frame is returned by :meth:`get_file_samples`.\n        \n    Returns\n    -------\n    `pandas.DataFrame`\n        The filtered data frame.\n\n    Notes\n    -----\n    In order to remove redundant files in a consistent fashion, the samples are\n    sorted by file ID, and then the first file for each sample is kept.\n    \"\"\"\n    assert isinstance(file_samples, pd.DataFrame)\n\n    df = file_samples  # use shorter variable name\n\n    # sort data frame by file ID\n    df = df.sort_values('file_id')\n\n    # - some samples have multiple files with the same barcode,\n    #   corresponding to different aliquots\n    # get rid of those duplicates\n    logger.info('Original number of files: %d', len(df.index))\n    df.drop_duplicates('sample_barcode', keep='first', inplace=True)\n    logger.info('Number of files after removing duplicates from different '\n                'aliquots: %d', len(df.index))\n\n    # - some samples also have multiple files corresponding to different vials\n    # add an auxilliary column that contains the sample barcode without the\n    # vial tag (first 15 characters)\n    df['sample_barcode15'] = df['sample_barcode'].apply(lambda x: x[:15])\n\n    # use auxilliary column to get rid of duplicate files\n    df.drop_duplicates('sample_barcode15', keep='first', inplace=True)\n    logger.info('Number of files after removing duplicates from different '\n                'vials: %d', len(df.index))\n\n    # get rid of auxilliary column \n    df.drop('sample_barcode15', axis=1, inplace=True)\n\n    # restore original order using the (numerical) index\n    df.sort_index(inplace=True)\n    \n    # return the filtered data frame\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fresh_primary_tumors(biospecimen):\n    df = biospecimen  # use shorter variable name\n\n    # get rid of FFPE samples\n    num_before = len(df.index)\n    df = df.loc[~df['is_ffpe']]\n    logger.info('Excluded %d files associated with FFPE samples '\n                '(out of %d files in total).',\n                num_before - len(df.index), num_before)\n\n    # only keep primary tumors\n    num_before = len(df.index)\n    df = df.loc[df['sample_type'] == 'Primary Tumor']\n    logger.info('Excluded %d files not corresponding to primary tumor '\n                'samples (out of %d files in total).',\n                num_before - len(df.index), num_before)\n\n    return df", "response": "Filter biospecimen data to only keep non - FFPE primary tumors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove sequence duplicates from FASTA.", "response": "def dedupFasta(reads):\n    \"\"\"\n    Remove sequence duplicates (based on sequence) from FASTA.\n\n    @param reads: a C{dark.reads.Reads} instance.\n    @return: a generator of C{dark.reads.Read} instances with no duplicates.\n    \"\"\"\n    seen = set()\n    add = seen.add\n    for read in reads:\n        hash_ = md5(read.sequence.encode('UTF-8')).digest()\n        if hash_ not in seen:\n            add(hash_)\n            yield read"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dePrefixAndSuffixFasta(sequences):\n    sequences = sorted(sequences, key=lambda s: len(s.seq), reverse=True)\n    seen = set()\n    for s in sequences:\n        thisSeq = str(s.seq)\n        thisHash = md5(thisSeq.encode('UTF-8')).digest()\n        if thisHash not in seen:\n            # Add prefixes.\n            newHash = md5()\n            for nucl in thisSeq:\n                newHash.update(nucl.encode('UTF-8'))\n                seen.add(newHash.digest())\n            # Add suffixes.\n            for start in range(len(thisSeq) - 1):\n                seen.add(md5(thisSeq[start + 1:].encode('UTF-8')).digest())\n            yield s", "response": "Returns a generator that yields a sequence of Bio. Seq objects with no duplicates and no fully contained\n        subsequences."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a list of open file descriptors each with FASTA content remove the reads found in the 2nd 3rd etc files from the first file .", "response": "def fastaSubtract(fastaFiles):\n    \"\"\"\n    Given a list of open file descriptors, each with FASTA content,\n    remove the reads found in the 2nd, 3rd, etc files from the first file\n    in the list.\n\n    @param fastaFiles: a C{list} of FASTA filenames.\n    @raises IndexError: if passed an empty list.\n    @return: An iterator producing C{Bio.SeqRecord} instances suitable for\n        writing to a file using C{Bio.SeqIO.write}.\n\n    \"\"\"\n    reads = {}\n    firstFile = fastaFiles.pop(0)\n    for seq in SeqIO.parse(firstFile, 'fasta'):\n        reads[seq.id] = seq\n\n    for fastaFile in fastaFiles:\n        for seq in SeqIO.parse(fastaFile, 'fasta'):\n            # Make sure that reads with the same id have the same sequence.\n            if seq.id in reads:\n                assert str(seq.seq) == str(reads[seq.id].seq)\n            reads.pop(seq.id, None)\n\n    return iter(reads.values())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef combineReads(filename, sequences, readClass=DNARead,\n                 upperCase=False, idPrefix='command-line-read-'):\n    \"\"\"\n    Combine FASTA reads from a file and/or sequence strings.\n\n    @param filename: A C{str} file name containing FASTA reads.\n    @param sequences: A C{list} of C{str} sequences. If a sequence\n        contains spaces, the last field (after splitting on spaces) will be\n        used as the sequence and the first fields will be used as the sequence\n        id.\n    @param readClass: The class of the individual reads.\n    @param upperCase: If C{True}, reads will be converted to upper case.\n    @param idPrefix: The C{str} prefix that will be used for the id of the\n        sequences in C{sequences} that do not have an id specified. A trailing\n        sequence number will be appended to this prefix. Note that\n        'command-line-read-', the default id prefix, could collide with ids in\n        the FASTA file, if given. So output might be ambiguous. That's why we\n        allow the caller to specify a custom prefix.\n    @return: A C{FastaReads} instance.\n    \"\"\"\n    # Read sequences from a FASTA file, if given.\n    if filename:\n        reads = FastaReads(filename, readClass=readClass, upperCase=upperCase)\n    else:\n        reads = Reads()\n\n    # Add any individually specified subject sequences.\n    if sequences:\n        for count, sequence in enumerate(sequences, start=1):\n            # Try splitting the sequence on its last space and using the\n            # first part of the split as the read id. If there's no space,\n            # assign a generic id.\n            parts = sequence.rsplit(' ', 1)\n            if len(parts) == 2:\n                readId, sequence = parts\n            else:\n                readId = '%s%d' % (idPrefix, count)\n            if upperCase:\n                sequence = sequence.upper()\n            read = readClass(readId, sequence)\n            reads.add(read)\n\n    return reads", "response": "Combine FASTA reads from a file and or a sequence string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over the sequences in the files in self. files_ yielding each read class instance.", "response": "def iter(self):\n        \"\"\"\n        Iterate over the sequences in the files in self.files_, yielding each\n        as an instance of the desired read class.\n        \"\"\"\n        count = 0\n        for _file in self._files:\n            with asHandle(_file) as fp:\n                # Duplicate some code here so as not to test\n                # self._upperCase in the loop.\n                if self._upperCase:\n                    for seq in SeqIO.parse(fp, 'fasta'):\n                        read = self._readClass(seq.description,\n                                               str(seq.seq.upper()))\n                        yield read\n                        count += 1\n                else:\n                    for seq in SeqIO.parse(fp, 'fasta'):\n                        read = self._readClass(seq.description, str(seq.seq))\n                        yield read\n                        count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter(self):\n        if self._upperCase:\n            for id_ in self._fasta:\n                yield self._readClass(id_, str(self._fasta[id_]).upper())\n        else:\n            for id_ in self._fasta:\n                yield self._readClass(id_, str(self._fasta[id_]))", "response": "Iterate over the sequences in self. files_ yielding each read class as an instance of the desired read class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _getFilename(self, fileNumber):\n        cur = self._connection.cursor()\n        cur.execute('SELECT name FROM files WHERE id = ?', (fileNumber,))\n        row = cur.fetchone()\n        if row is None:\n            return None\n        else:\n            return row[0]", "response": "Given a file number get its name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a file name get its file number.", "response": "def _getFileNumber(self, filename):\n        \"\"\"\n        Given a file name, get its file number (if any).\n\n        @param filename: A C{str} file name.\n        @return: An C{int} file number or C{None} if no file with that name\n            has been added.\n        \"\"\"\n        cur = self._connection.cursor()\n        cur.execute('SELECT id FROM files WHERE name = ?', (filename,))\n        row = cur.fetchone()\n        if row is None:\n            return None\n        else:\n            return row[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new filename to the database.", "response": "def _addFilename(self, filename):\n        \"\"\"\n        Add a new file name.\n\n        @param filename: A C{str} file name.\n        @raise ValueError: If a file with this name has already been added.\n        @return: The C{int} id of the newly added file.\n        \"\"\"\n        cur = self._connection.cursor()\n        try:\n            cur.execute('INSERT INTO files(name) VALUES (?)', (filename,))\n        except sqlite3.IntegrityError as e:\n            if str(e).find('UNIQUE constraint failed') > -1:\n                raise ValueError('Duplicate file name: %r' % filename)\n            else:\n                raise\n        else:\n            fileNumber = cur.lastrowid\n            self._connection.commit()\n            return fileNumber"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addFile(self, filename):\n        endswith = filename.lower().endswith\n        if endswith('.bgz') or endswith('.gz'):\n            useBgzf = True\n        elif endswith('.bz2'):\n            raise ValueError(\n                'Compressed FASTA is only supported in BGZF format. Use '\n                'bgzip to compresss your FASTA.')\n        else:\n            useBgzf = False\n\n        fileNumber = self._addFilename(filename)\n        connection = self._connection\n        count = 0\n        try:\n            with connection:\n                if useBgzf:\n                    try:\n                        fp = bgzf.open(filename, 'rb')\n                    except ValueError as e:\n                        if str(e).find('BGZF') > -1:\n                            raise ValueError(\n                                'Compressed FASTA is only supported in BGZF '\n                                'format. Use the samtools bgzip utility '\n                                '(instead of gzip) to compresss your FASTA.')\n                        else:\n                            raise\n                    else:\n                        try:\n                            for line in fp:\n                                if line[0] == '>':\n                                    count += 1\n                                    id_ = line[1:].rstrip(' \\t\\n\\r')\n                                    connection.execute(\n                                        'INSERT INTO sequences(id, '\n                                        'fileNumber, offset) VALUES (?, ?, ?)',\n                                        (id_, fileNumber, fp.tell()))\n                        finally:\n                            fp.close()\n                else:\n                    with open(filename) as fp:\n                        offset = 0\n                        for line in fp:\n                            offset += len(line)\n                            if line[0] == '>':\n                                count += 1\n                                id_ = line[1:].rstrip(' \\t\\n\\r')\n                                connection.execute(\n                                    'INSERT INTO sequences(id, fileNumber, '\n                                    'offset) VALUES (?, ?, ?)',\n                                    (id_, fileNumber, offset))\n        except sqlite3.IntegrityError as e:\n            if str(e).find('UNIQUE constraint failed') > -1:\n                original = self._find(id_)\n                if original is None:\n                    # The id must have appeared twice in the current file,\n                    # because we could not look it up in the database\n                    # (i.e., it was INSERTed but not committed).\n                    raise ValueError(\n                        \"FASTA sequence id '%s' found twice in file '%s'.\" %\n                        (id_, filename))\n                else:\n                    origFilename, _ = original\n                    raise ValueError(\n                        \"FASTA sequence id '%s', found in file '%s', was \"\n                        \"previously added from file '%s'.\" %\n                        (id_, filename, origFilename))\n            else:\n                raise\n        else:\n            return count", "response": "Add a new file to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find(self, id_):\n        cur = self._connection.cursor()\n        cur.execute(\n            'SELECT fileNumber, offset FROM sequences WHERE id = ?', (id_,))\n        row = cur.fetchone()\n        if row is None:\n            return None\n        else:\n            return self._getFilename(row[0]), row[1]", "response": "Find the filename and offset of a sequence given its id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the attribute string of a GFF or GTF annotation into a dictionary containing attribute name and value pairs.", "response": "def parse_attributes(s):\n    \"\"\" Parses the ``attribute`` string of a GFF/GTF annotation.\n\n    Parameters\n    ----------\n    s : str\n        The attribute string.\n\n    Returns\n    -------\n    dict\n        A dictionary containing attribute name/value pairs.\n\n    Notes\n    -----\n    The ``attribute`` string is the 9th field of each annotation (row),\n    as described in the\n    `GTF format specification <http://mblab.wustl.edu/GTF22.html>`_.\n    \"\"\"\n    # use regular expression with negative lookbehind to make sure we don't\n    # split on escaped semicolons (\"\\;\")\n    attr_sep = re.compile(r'(?<!\\\\)\\s*;\\s*')\n    attr = {}\n    atts = attr_sep.split(s)\n    for a in atts:\n        #print(a)\n        kv = a.split(' ', maxsplit=1)\n        if len(kv) == 2:\n            k, v = kv\n            v = v.strip('\"')\n            attr[k] = v\n    return attr"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the BLAST record for Derek.", "response": "def printBlastRecordForDerek(record):\n    \"\"\"\n    This is a hacked version of printBlastRecord that I wrote in\n    Addenbrookes hospital so Derek could try hacking on the reads\n    that had low e values.  It's called by bin/print-blast-xml-for-derek.py\n    \"\"\"\n    if len(record.alignments) == 0:\n        return 0\n    if record.descriptions[0].e > 1e-120:\n        return 0\n    print(record.query, end=' ')\n    for i, alignment in enumerate(record.alignments):\n        print(record.descriptions[i].e, end=' ')\n        for hspIndex, hsp in enumerate(alignment.hsps, start=1):\n            if hsp.sbjct_start < hsp.sbjct_end:\n                sense = 1\n                if hsp.sbjct_start < 2200:\n                    side = 'left'\n                else:\n                    side = 'right'\n            else:\n                sense = -1\n                if hsp.sbjct_end < 2200:\n                    side = 'left'\n                else:\n                    side = 'right'\n            print(sense, side)\n            break\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits a sequence id string like Protein name [ pathogen name ] into two - tuple elements.", "response": "def splitNames(names):\n    \"\"\"\n    Split a sequence id string like \"Protein name [pathogen name]\" into two\n    pieces using the final square brackets to delimit the pathogen name.\n\n    @param names: A C{str} \"protein name [pathogen name]\" string.\n    @return: A 2-C{tuple} giving the C{str} protein name and C{str} pathogen\n        name. If C{names} cannot be split on square brackets, it is\n        returned as the first tuple element, followed by _NO_PATHOGEN_NAME.\n    \"\"\"\n    match = _PATHOGEN_RE.match(names)\n    if match:\n        proteinName = match.group(1).strip()\n        pathogenName = match.group(2).strip()\n    else:\n        proteinName = names\n        pathogenName = _NO_PATHOGEN_NAME\n\n    return proteinName, pathogenName"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the number of proteins for each pathogen in a list of FASTA files.", "response": "def getPathogenProteinCounts(filenames):\n    \"\"\"\n    Get the number of proteins for each pathogen in C{filenames}.\n\n    @param filenames: Either C{None} or a C{list} of C{str} FASTA file names.\n        If C{None} an empty C{Counter} is returned. If FASTA file names are\n        given, their sequence ids should have the format used in the NCBI\n        bacterial and viral protein reference sequence files, in which the\n        protein name is followed by the pathogen name in square brackets.\n    @return: A C{Counter} keyed by C{str} pathogen name, whose values are\n        C{int}s with the count of the number of proteins for the pathogen.\n    \"\"\"\n    result = Counter()\n    if filenames:\n        for filename in filenames:\n            for protein in FastaReads(filename):\n                _, pathogenName = splitNames(protein.id)\n                if pathogenName != _NO_PATHOGEN_NAME:\n                    result[pathogenName] += 1\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, pathogenName, sampleName):\n        pathogenIndex = self._pathogens.setdefault(pathogenName,\n                                                   len(self._pathogens))\n        sampleIndex = self._samples.setdefault(sampleName, len(self._samples))\n\n        try:\n            return self._readsFilenames[(pathogenIndex, sampleIndex)]\n        except KeyError:\n            reads = Reads()\n            for proteinMatch in self._proteinGrouper.pathogenNames[\n                    pathogenName][sampleName]['proteins'].values():\n                for read in self._readsClass(proteinMatch['readsFilename']):\n                    reads.add(read)\n            saveFilename = join(\n                proteinMatch['outDir'],\n                'pathogen-%d-sample-%d.%s' % (pathogenIndex, sampleIndex,\n                                              self._format))\n            reads.filter(removeDuplicatesById=True)\n            nReads = reads.save(saveFilename, format_=self._format)\n            # Save the unique read count into self._proteinGrouper\n            self._proteinGrouper.pathogenNames[\n                pathogenName][sampleName]['uniqueReadCount'] = nReads\n            self._readsFilenames[(pathogenIndex, sampleIndex)] = saveFilename\n            return saveFilename", "response": "Adds a new entry to the internal cache and returns the file name holding all the reads that match the given pathogen name and sample name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlooks up a pathogen name, sample name combination and get its FASTA/FASTQ file name and unique read count. This method should be used instead of C{add} in situations where you want an exception to be raised if a pathogen/sample combination has not already been passed to C{add}. @param pathogenName: A C{str} pathogen name. @param sampleName: A C{str} sample name. @raise KeyError: If the pathogen name or sample name have not been seen, either individually or in combination. @return: A (C{str}, C{int}) tuple retrieved from self._readsFilenames", "response": "def lookup(self, pathogenName, sampleName):\n        \"\"\"\n        Look up a pathogen name, sample name combination and get its\n        FASTA/FASTQ file name and unique read count.\n\n        This method should be used instead of C{add} in situations where\n        you want an exception to be raised if a pathogen/sample combination has\n        not already been passed to C{add}.\n\n        @param pathogenName: A C{str} pathogen name.\n        @param sampleName: A C{str} sample name.\n        @raise KeyError: If the pathogen name or sample name have not been\n            seen, either individually or in combination.\n        @return: A (C{str}, C{int}) tuple retrieved from self._readsFilenames\n        \"\"\"\n        pathogenIndex = self._pathogens[pathogenName]\n        sampleIndex = self._samples[sampleName]\n        return self._readsFilenames[(pathogenIndex, sampleIndex)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a file of sample indices and names sorted by index.", "response": "def writeSampleIndex(self, fp):\n        \"\"\"\n        Write a file of sample indices and names, sorted by index.\n\n        @param fp: A file-like object, opened for writing.\n        \"\"\"\n        print('\\n'.join(\n            '%d %s' % (index, name) for (index, name) in\n            sorted((index, name) for (name, index) in self._samples.items())\n        ), file=fp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a file of pathogen indices and names sorted by index.", "response": "def writePathogenIndex(self, fp):\n        \"\"\"\n        Write a file of pathogen indices and names, sorted by index.\n\n        @param fp: A file-like object, opened for writing.\n        \"\"\"\n        print('\\n'.join(\n            '%d %s' % (index, name) for (index, name) in\n            sorted((index, name) for (name, index) in self._pathogens.items())\n        ), file=fp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a title summarizing the pathogens and samples.", "response": "def _title(self):\n        \"\"\"\n        Create a title summarizing the pathogens and samples.\n\n        @return: A C{str} title.\n        \"\"\"\n        return (\n            'Overall, proteins from %d pathogen%s were found in %d sample%s.' %\n            (len(self.pathogenNames),\n             '' if len(self.pathogenNames) == 1 else 's',\n             len(self.sampleNames),\n             '' if len(self.sampleNames) == 1 else 's'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addFile(self, filename, fp):\n        if self._sampleName:\n            sampleName = self._sampleName\n        elif self._sampleNameRegex:\n            match = self._sampleNameRegex.search(filename)\n            if match:\n                sampleName = match.group(1)\n            else:\n                sampleName = filename\n        else:\n            sampleName = filename\n\n        outDir = join(dirname(filename), self._assetDir)\n\n        self.sampleNames[sampleName] = join(outDir, 'index.html')\n\n        for index, proteinLine in enumerate(fp):\n            proteinLine = proteinLine[:-1]\n            (coverage, medianScore, bestScore, readCount, hspCount,\n             proteinLength, names) = proteinLine.split(None, 6)\n\n            proteinName, pathogenName = splitNames(names)\n\n            if pathogenName not in self.pathogenNames:\n                self.pathogenNames[pathogenName] = {}\n\n            if sampleName not in self.pathogenNames[pathogenName]:\n                self.pathogenNames[pathogenName][sampleName] = {\n                    'proteins': {},\n                    'uniqueReadCount': None,\n                }\n\n            proteins = self.pathogenNames[pathogenName][sampleName]['proteins']\n\n            # We should only receive one line of information for a given\n            # pathogen/sample/protein combination.\n            if proteinName in proteins:\n                raise ValueError(\n                    'Protein %r already seen for pathogen %r sample %r.' %\n                    (proteinName, pathogenName, sampleName))\n\n            readsFilename = join(outDir, '%d.%s' % (index, self._format))\n\n            proteins[proteinName] = {\n                'bestScore': float(bestScore),\n                'bluePlotFilename': join(outDir, '%d.png' % index),\n                'coverage': float(coverage),\n                'readsFilename': readsFilename,\n                'hspCount': int(hspCount),\n                'index': index,\n                'medianScore': float(medianScore),\n                'outDir': outDir,\n                'proteinLength': int(proteinLength),\n                'proteinName': proteinName,\n                'proteinURL': NCBISequenceLinkURL(proteinName),\n                'readCount': int(readCount),\n            }\n\n            if self._saveReadLengths:\n                readsClass = (FastaReads if self._format == 'fasta'\n                              else FastqReads)\n                proteins[proteinName]['readLengths'] = tuple(\n                    len(read) for read in readsClass(readsFilename))", "response": "Read and record the protein information for a given pathogen sample."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the number of unique reads in the pathogen file.", "response": "def _computeUniqueReadCounts(self):\n        \"\"\"\n        Add all pathogen / sample combinations to self.pathogenSampleFiles.\n\n        This will make all de-duplicated (by id) FASTA/FASTQ files and store\n        the number of de-duplicated reads into C{self.pathogenNames}.\n        \"\"\"\n        for pathogenName, samples in self.pathogenNames.items():\n            for sampleName in samples:\n                self.pathogenSampleFiles.add(pathogenName, sampleName)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nproduces a string representation of the pathogen summary.", "response": "def toStr(self):\n        \"\"\"\n        Produce a string representation of the pathogen summary.\n\n        @return: A C{str} suitable for printing.\n        \"\"\"\n        # Note that the string representation contains much less\n        # information than the HTML summary. E.g., it does not contain the\n        # unique (de-duplicated, by id) read count, since that is only computed\n        # when we are making combined FASTA files of reads matching a\n        # pathogen.\n        readCountGetter = itemgetter('readCount')\n        result = []\n        append = result.append\n\n        append(self._title())\n        append('')\n\n        for pathogenName in sorted(self.pathogenNames):\n            samples = self.pathogenNames[pathogenName]\n            sampleCount = len(samples)\n            append('%s (in %d sample%s)' %\n                   (pathogenName,\n                    sampleCount, '' if sampleCount == 1 else 's'))\n            for sampleName in sorted(samples):\n                proteins = samples[sampleName]['proteins']\n                proteinCount = len(proteins)\n                totalReads = sum(readCountGetter(p) for p in proteins.values())\n                append('  %s (%d protein%s, %d read%s)' %\n                       (sampleName,\n                        proteinCount, '' if proteinCount == 1 else 's',\n                        totalReads, '' if totalReads == 1 else 's'))\n                for proteinName in sorted(proteins):\n                    append(\n                        '    %(coverage).2f\\t%(medianScore).2f\\t'\n                        '%(bestScore).2f\\t%(readCount)4d\\t%(hspCount)4d\\t'\n                        '%(index)3d\\t%(proteinName)s'\n                        % proteins[proteinName])\n            append('')\n\n        return '\\n'.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nproduce an HTML string representation of the pathogen summary.", "response": "def toHTML(self, pathogenPanelFilename=None, minProteinFraction=0.0,\n               pathogenType='viral', sampleIndexFilename=None,\n               pathogenIndexFilename=None):\n        \"\"\"\n        Produce an HTML string representation of the pathogen summary.\n\n        @param pathogenPanelFilename: If not C{None}, a C{str} filename to\n            write a pathogen panel PNG image to.\n        @param minProteinFraction: The C{float} minimum fraction of proteins\n            in a pathogen that must be matched by a sample in order for that\n            pathogen to be displayed for that sample.\n        @param pathogenType: A C{str} giving the type of the pathogen involved,\n            either 'bacterial' or 'viral'.\n        @param sampleIndexFilename: A C{str} filename to write a sample index\n            file to. Lines in the file will have an integer index, a space, and\n            then the sample name.\n        @param pathogenIndexFilename: A C{str} filename to write a pathogen\n            index file to. Lines in the file will have an integer index, a\n            space, and then the pathogen name.\n        @return: An HTML C{str} suitable for printing.\n        \"\"\"\n        if pathogenType not in ('bacterial', 'viral'):\n            raise ValueError(\n                \"Unrecognized pathogenType argument: %r. Value must be either \"\n                \"'bacterial' or 'viral'.\" % pathogenType)\n\n        highlightSymbol = '&starf;'\n        self._computeUniqueReadCounts()\n\n        if pathogenPanelFilename:\n            self.pathogenPanel(pathogenPanelFilename)\n\n        if sampleIndexFilename:\n            with open(sampleIndexFilename, 'w') as fp:\n                self.pathogenSampleFiles.writeSampleIndex(fp)\n\n        if pathogenIndexFilename:\n            with open(pathogenIndexFilename, 'w') as fp:\n                self.pathogenSampleFiles.writePathogenIndex(fp)\n\n        toDelete = defaultdict(list)\n        for pathogenName in self.pathogenNames:\n            proteinCount = self._pathogenProteinCount[pathogenName]\n            for s in self.pathogenNames[pathogenName]:\n                if proteinCount:\n                    sampleProteinFraction = (\n                        len(self.pathogenNames[pathogenName][s]['proteins']) /\n                        proteinCount)\n                else:\n                    sampleProteinFraction = 1.0\n                if sampleProteinFraction < minProteinFraction:\n                    toDelete[pathogenName].append(s)\n\n        for pathogenName in toDelete:\n            for sample in toDelete[pathogenName]:\n                del self.pathogenNames[pathogenName][sample]\n\n        pathogenNames = sorted(\n            pathogenName for pathogenName in self.pathogenNames\n            if len(self.pathogenNames[pathogenName]) > 0)\n        nPathogenNames = len(pathogenNames)\n        sampleNames = sorted(self.sampleNames)\n\n        result = [\n            '<html>',\n            '<head>',\n            '<title>',\n            'Summary of pathogens',\n            '</title>',\n            '<meta charset=\"UTF-8\">',\n            '</head>',\n            '<body>',\n            '<style>',\n            '''\\\n            body {\n                margin-left: 2%;\n                margin-right: 2%;\n            }\n            hr {\n                display: block;\n                margin-top: 0.5em;\n                margin-bottom: 0.5em;\n                margin-left: auto;\n                margin-right: auto;\n                border-style: inset;\n                border-width: 1px;\n            }\n            p.pathogen {\n                margin-top: 10px;\n                margin-bottom: 3px;\n            }\n            p.sample {\n                margin-top: 10px;\n                margin-bottom: 3px;\n            }\n            .significant {\n                color: red;\n                margin-right: 2px;\n            }\n            .sample {\n                margin-top: 5px;\n                margin-bottom: 2px;\n            }\n            ul {\n                margin-bottom: 2px;\n            }\n            .indented {\n                margin-left: 2em;\n            }\n            .sample-name {\n                font-size: 125%;\n                font-weight: bold;\n            }\n            .pathogen-name {\n                font-size: 125%;\n                font-weight: bold;\n            }\n            .index-name {\n                font-weight: bold;\n            }\n            .index {\n                font-size: small;\n            }\n            .protein-name {\n                font-family: \"Courier New\", Courier, monospace;\n            }\n            .stats {\n                font-family: \"Courier New\", Courier, monospace;\n                white-space: pre;\n            }\n            .protein-list {\n                margin-top: 2px;\n            }''',\n            '</style>',\n            '</head>',\n            '<body>',\n        ]\n\n        proteinFieldsDescription = [\n            '<p>',\n            'In all bullet point protein lists below, there are the following '\n            'fields:',\n            '<ol>',\n            '<li>Coverage fraction.</li>',\n            '<li>Median bit score.</li>',\n            '<li>Best bit score.</li>',\n            '<li>Read count.</li>',\n            '<li>HSP count (a read can match a protein more than once).</li>',\n            '<li>Protein length (in AAs).</li>',\n            '<li>Index (just ignore this).</li>',\n        ]\n\n        if self._saveReadLengths:\n            proteinFieldsDescription.append(\n                '<li>All read lengths (in parentheses).</li>')\n\n        proteinFieldsDescription.extend([\n            '<li>Protein name.</li>',\n            '</ol>',\n            '</p>',\n        ])\n\n        append = result.append\n\n        append('<h1>Summary of pathogens</h1>')\n        append('<p>')\n        append(self._title())\n\n        if self._pathogenProteinCount:\n            percent = minProteinFraction * 100.0\n            if nPathogenNames < len(self.pathogenNames):\n                if nPathogenNames == 1:\n                    append('Pathogen protein fraction filtering has been '\n                           'applied, so information on only 1 pathogen is '\n                           'displayed. This is the only pathogen for which at '\n                           'least one sample matches at least %.2f%% of the '\n                           'pathogen proteins.' % percent)\n                else:\n                    append('Pathogen protein fraction filtering has been '\n                           'applied, so information on only %d pathogens is '\n                           'displayed. These are the only pathogens for which '\n                           'at least one sample matches at least %.2f%% of '\n                           'the pathogen proteins.' % (nPathogenNames,\n                                                       percent))\n            else:\n                append('Pathogen protein fraction filtering has been applied, '\n                       'but all pathogens have at least %.2f%% of their '\n                       'proteins matched by at least one sample.' % percent)\n\n            append('Samples that match a pathogen (and pathogens with a '\n                   'matching sample) with at least this protein fraction are '\n                   'highlighted using <span class=\"significant\">%s</span>.' %\n                   highlightSymbol)\n\n        append('</p>')\n\n        if pathogenPanelFilename:\n            append('<p>')\n            append('<a href=\"%s\">Panel showing read count per pathogen, per '\n                   'sample.</a>' % pathogenPanelFilename)\n            append('Red vertical bars indicate samples with an unusually high '\n                   'read count.')\n            append('</p>')\n\n        result.extend(proteinFieldsDescription)\n\n        # Write a linked table of contents by pathogen.\n        append('<p><span class=\"index-name\">Pathogen index:</span>')\n        append('<span class=\"index\">')\n        for pathogenName in pathogenNames:\n            append('<a href=\"#pathogen-%s\">%s</a>' % (pathogenName,\n                                                      pathogenName))\n            append('&middot;')\n        # Get rid of final middle dot and add a period.\n        result.pop()\n        result[-1] += '.'\n        append('</span></p>')\n\n        # Write a linked table of contents by sample.\n        append('<p><span class=\"index-name\">Sample index:</span>')\n        append('<span class=\"index\">')\n        for sampleName in sampleNames:\n            append('<a href=\"#sample-%s\">%s</a>' % (sampleName, sampleName))\n            append('&middot;')\n        # Get rid of final middle dot and add a period.\n        result.pop()\n        result[-1] += '.'\n        append('</span></p>')\n\n        # Write all pathogens (with samples (with proteins)).\n        append('<hr>')\n        append('<h1>Pathogens by sample</h1>')\n\n        for pathogenName in pathogenNames:\n            samples = self.pathogenNames[pathogenName]\n            sampleCount = len(samples)\n            pathogenProteinCount = self._pathogenProteinCount[pathogenName]\n            if pathogenType == 'viral':\n                pathogenNameHTML = '<a href=\"%s%s\">%s</a>' % (\n                    self.VIRALZONE, quote(pathogenName), pathogenName)\n            else:\n                pathogenNameHTML = pathogenName\n            append(\n                '<a id=\"pathogen-%s\"></a>'\n                '<p class=\"pathogen\"><span class=\"pathogen-name\">%s</span>'\n                '%s, was matched by %d sample%s:</p>' %\n                (pathogenName, pathogenNameHTML,\n                 ((' (with %d protein%s)' %\n                   (pathogenProteinCount,\n                    '' if pathogenProteinCount == 1 else 's'))\n                  if pathogenProteinCount else ''),\n                 sampleCount,\n                 '' if sampleCount == 1 else 's'))\n            for sampleName in sorted(samples):\n                readsFileName = self.pathogenSampleFiles.lookup(\n                    pathogenName, sampleName)\n                proteins = samples[sampleName]['proteins']\n                proteinCount = len(proteins)\n                uniqueReadCount = samples[sampleName]['uniqueReadCount']\n                if pathogenProteinCount and (\n                        proteinCount / pathogenProteinCount >=\n                        minProteinFraction):\n                    highlight = ('<span class=\"significant\">%s</span>' %\n                                 highlightSymbol)\n                else:\n                    highlight = ''\n\n                append(\n                    '<p class=\"sample indented\">'\n                    '%sSample <a href=\"#sample-%s\">%s</a> '\n                    '(%d protein%s, <a href=\"%s\">%d de-duplicated (by id) '\n                    'read%s</a>, <a href=\"%s\">panel</a>):</p>' %\n                    (highlight, sampleName, sampleName,\n                     proteinCount, '' if proteinCount == 1 else 's',\n                     readsFileName,\n                     uniqueReadCount, '' if uniqueReadCount == 1 else 's',\n                     self.sampleNames[sampleName]))\n                append('<ul class=\"protein-list indented\">')\n                for proteinName in sorted(proteins):\n                    proteinMatch = proteins[proteinName]\n                    append(\n                        '<li>'\n                        '<span class=\"stats\">'\n                        '%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f '\n                        '%(readCount)5d %(hspCount)5d %(proteinLength)4d '\n                        '%(index)3d '\n                        % proteinMatch\n                    )\n\n                    if self._saveReadLengths:\n                        append('(%s) ' % ', '.join(\n                            map(str, sorted(proteinMatch['readLengths']))))\n\n                    append(\n                        '</span> '\n                        '<span class=\"protein-name\">'\n                        '%(proteinName)s'\n                        '</span> '\n                        '(<a href=\"%(bluePlotFilename)s\">blue plot</a>, '\n                        '<a href=\"%(readsFilename)s\">reads</a>'\n                        % proteinMatch)\n\n                    if proteinMatch['proteinURL']:\n                        # Append this directly to the last string in result, to\n                        # avoid introducing whitespace when we join result\n                        # using '\\n'.\n                        result[-1] += (', <a href=\"%s\">NCBI</a>' %\n                                       proteinMatch['proteinURL'])\n                    result[-1] += ')'\n\n                    append('</li>')\n\n                append('</ul>')\n\n        # Write all samples (with pathogens (with proteins)).\n        append('<hr>')\n        append('<h1>Samples by pathogen</h1>')\n\n        for sampleName in sampleNames:\n            samplePathogenNames = [\n                pathName for pathName in self.pathogenNames\n                if sampleName in self.pathogenNames[pathName]]\n\n            append(\n                '<a id=\"sample-%s\"></a>'\n                '<p class=\"sample\">Sample <span class=\"sample-name\">%s</span> '\n                'matched proteins from %d pathogen%s, '\n                '<a href=\"%s\">panel</a>:</p>' %\n                (sampleName, sampleName, len(samplePathogenNames),\n                 '' if len(samplePathogenNames) == 1 else 's',\n                 self.sampleNames[sampleName]))\n\n            for pathogenName in sorted(samplePathogenNames):\n                readsFileName = self.pathogenSampleFiles.lookup(pathogenName,\n                                                                sampleName)\n                proteins = self.pathogenNames[pathogenName][sampleName][\n                    'proteins']\n                uniqueReadCount = self.pathogenNames[\n                    pathogenName][sampleName]['uniqueReadCount']\n                proteinCount = len(proteins)\n                pathogenProteinCount = self._pathogenProteinCount[pathogenName]\n\n                highlight = ''\n                if pathogenProteinCount:\n                    proteinCountStr = '%d/%d protein%s' % (\n                        proteinCount, pathogenProteinCount,\n                        '' if pathogenProteinCount == 1 else 's')\n                    if (proteinCount / pathogenProteinCount >=\n                            minProteinFraction):\n                        highlight = ('<span class=\"significant\">%s</span>' %\n                                     highlightSymbol)\n                else:\n                    proteinCountStr = '%d protein%s' % (\n                        proteinCount, '' if proteinCount == 1 else 's')\n\n                append(\n                    '<p class=\"sample indented\">'\n                    '%s<a href=\"#pathogen-%s\">%s</a> %s, '\n                    '<a href=\"%s\">%d de-duplicated (by id) read%s</a>:</p>' %\n                    (highlight, pathogenName, pathogenName,\n                     proteinCountStr, readsFileName,\n                     uniqueReadCount, '' if uniqueReadCount == 1 else 's'))\n                append('<ul class=\"protein-list indented\">')\n                for proteinName in sorted(proteins):\n                    proteinMatch = proteins[proteinName]\n                    append(\n                        '<li>'\n                        '<span class=\"stats\">'\n                        '%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f '\n                        '%(readCount)5d %(hspCount)5d %(proteinLength)4d '\n                        '%(index)3d '\n                        '</span> '\n                        '<span class=\"protein-name\">'\n                        '%(proteinName)s'\n                        '</span> '\n                        '(<a href=\"%(bluePlotFilename)s\">blue plot</a>, '\n                        '<a href=\"%(readsFilename)s\">reads</a>'\n                        % proteinMatch)\n\n                    if proteinMatch['proteinURL']:\n                        # Append this directly to the last string in result, to\n                        # avoid introducing whitespace when we join result\n                        # using '\\n'.\n                        result[-1] += (', <a href=\"%s\">NCBI</a>' %\n                                       proteinMatch['proteinURL'])\n                    result[-1] += ')'\n\n                    append('</li>')\n\n                append('</ul>')\n\n        append('</body>')\n        append('</html>')\n\n        return '\\n'.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes an image of a graph giving the pathogen read count versus the number of samples in the pathogen.", "response": "def _pathogenSamplePlot(self, pathogenName, sampleNames, ax):\n        \"\"\"\n        Make an image of a graph giving pathogen read count (Y axis) versus\n        sample id (X axis).\n\n        @param pathogenName: A C{str} pathogen name.\n        @param sampleNames: A sorted C{list} of sample names.\n        @param ax: A matplotlib C{axes} instance.\n        \"\"\"\n        readCounts = []\n        for i, sampleName in enumerate(sampleNames):\n            try:\n                readCount = self.pathogenNames[pathogenName][sampleName][\n                    'uniqueReadCount']\n            except KeyError:\n                readCount = 0\n            readCounts.append(readCount)\n\n        highlight = 'r'\n        normal = 'gray'\n        sdMultiple = 2.5\n        minReadsForHighlighting = 10\n        highlighted = []\n\n        if len(readCounts) == 1:\n            if readCounts[0] > minReadsForHighlighting:\n                color = [highlight]\n                highlighted.append(sampleNames[0])\n            else:\n                color = [normal]\n        else:\n            mean = np.mean(readCounts)\n            sd = np.std(readCounts)\n            color = []\n            for readCount, sampleName in zip(readCounts, sampleNames):\n                if (readCount > (sdMultiple * sd) + mean and\n                        readCount >= minReadsForHighlighting):\n                    color.append(highlight)\n                    highlighted.append(sampleName)\n                else:\n                    color.append(normal)\n\n        nSamples = len(sampleNames)\n        x = np.arange(nSamples)\n        yMin = np.zeros(nSamples)\n        ax.set_xticks([])\n        ax.set_xlim((-0.5, nSamples - 0.5))\n        ax.vlines(x, yMin, readCounts, color=color)\n        if highlighted:\n            title = '%s\\nIn red: %s' % (\n                pathogenName, fill(', '.join(highlighted), 50))\n        else:\n            # Add a newline to keep the first line of each title at the\n            # same place as those titles that have an \"In red:\" second\n            # line.\n            title = pathogenName + '\\n'\n\n        ax.set_title(title, fontsize=10)\n        ax.tick_params(axis='both', which='major', labelsize=8)\n        ax.tick_params(axis='both', which='minor', labelsize=6)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pathogenPanel(self, filename):\n        import matplotlib\n        matplotlib.use('PDF')\n        import matplotlib.pyplot as plt\n\n        self._computeUniqueReadCounts()\n        pathogenNames = sorted(self.pathogenNames)\n        sampleNames = sorted(self.sampleNames)\n\n        cols = 5\n        rows = int(len(pathogenNames) / cols) + (\n            0 if len(pathogenNames) % cols == 0 else 1)\n        figure, ax = plt.subplots(rows, cols, squeeze=False)\n\n        coords = dimensionalIterator((rows, cols))\n\n        for i, pathogenName in enumerate(pathogenNames):\n            row, col = next(coords)\n            self._pathogenSamplePlot(pathogenName, sampleNames, ax[row][col])\n\n        # Hide the final panel graphs (if any) that have no content. We do\n        # this because the panel is a rectangular grid and some of the\n        # plots at the end of the last row may be unused.\n        for row, col in coords:\n            ax[row][col].axis('off')\n\n        figure.suptitle(\n            ('Per-sample read count for %d pathogen%s and %d sample%s.\\n\\n'\n             'Sample name%s: %s') % (\n                 len(pathogenNames),\n                 '' if len(pathogenNames) == 1 else 's',\n                 len(sampleNames),\n                 '' if len(sampleNames) == 1 else 's',\n                 '' if len(sampleNames) == 1 else 's',\n                 fill(', '.join(sampleNames), 50)),\n            fontsize=20)\n        figure.set_size_inches(5.0 * cols, 2.0 * rows, forward=True)\n        plt.subplots_adjust(hspace=0.4)\n\n        figure.savefig(filename)", "response": "Make a panel of images with each image being a graph giving each image being a graph giving each pathogen read count and each sample id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_args(request_args, allowed_int_args=[], allowed_str_args=[]):\n    args = {}\n\n    for allowed_int_arg in allowed_int_args:\n        int_value = request_args.get(allowed_int_arg, default=None, type=None)\n        if int_value:\n            args[allowed_int_arg] = int(int_value)\n\n    for allowed_str_arg in allowed_str_args:\n        str_value = request_args.get(allowed_str_arg, default=None, type=None)\n        if str_value:\n            args[allowed_str_arg] = str_value\n\n    return args", "response": "Check allowed argument names and return is as dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of diseases by query parameters", "response": "def query_disease():\n    \"\"\"\n    Returns list of diseases by query parameters\n    ---\n\n    tags:\n\n      - Query functions\n\n    parameters:\n\n      - name: identifier\n        in: query\n        type: string\n        required: false\n        description: Disease identifier\n        default: DI-03832\n\n      - name: ref_id\n        in: query\n        type: string\n        required: false\n        description: reference identifier\n        default: 104300\n\n      - name: ref_type\n        in: query\n        type: string\n        required: false\n        description: Reference type\n        default: MIM\n\n      - name: name\n        in: query\n        type: string\n        required: false\n        description: Disease name\n        default: Alzheimer disease\n\n      - name: acronym\n        in: query\n        type: string\n        required: false\n        description: Disease acronym\n        default: AD\n\n      - name: description\n        in: query\n        type: string\n        required: false\n        description: Description of disease\n        default: '%neurodegenerative disorder%'\n\n      - name: limit\n        in: query\n        type: integer\n        required: false\n        description: limit of results numbers\n        default: 10\n    \"\"\"\n    allowed_str_args = ['identifier', 'ref_id', 'ref_type', 'name', 'acronym', 'description']\n\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=allowed_str_args\n    )\n\n    return jsonify(query.disease(**args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query_alternative_full_name():\n\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['name', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.alternative_full_name(**args))", "response": "Query the alternative full name by query parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_alternative_short_name():\n\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['name', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.alternative_short_name(**args))", "response": "Returns list of alternative short name by query parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nquery other gene name by query parameters", "response": "def query_other_gene_name():\n    \"\"\"\n    Returns list of alternative short name by query query parameters\n    ---\n\n    tags:\n\n      - Query functions\n\n    parameters:\n\n      - name: type_\n        in: query\n        type: string\n        required: false\n        description: Alternative short name\n        default: CVAP\n\n      - name: name\n        in: query\n        type: string\n        required: false\n        description: Alternative short name\n        default: CVAP\n\n      - name: entry_name\n        in: query\n        type: string\n        required: false\n        description: UniProt entry name\n        default: A4_HUMAN\n\n      - name: limit\n        in: query\n        type: integer\n        required: false\n        description: limit of results numbers\n        default: 10\n    \"\"\"\n\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['name', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.other_gene_name(**args))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying UniProt s accession numbers by query parameters", "response": "def query_accession():\n    \"\"\"\n    Returns list of accession numbers by query query parameters\n    ---\n\n    tags:\n\n      - Query functions\n\n    parameters:\n\n      - name: accession\n        in: query\n        type: string\n        required: false\n        description: UniProt accession number\n        default: P05067\n\n      - name: entry_name\n        in: query\n        type: string\n        required: false\n        description: UniProt entry name\n        default: A4_HUMAN\n\n      - name: limit\n        in: query\n        type: integer\n        required: false\n        description: limit of results numbers\n        default: 10\n    \"\"\"\n\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['accession', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.accession(**args))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying PubMed identifier by query parameters", "response": "def query_pmid():\n    \"\"\"\n    Returns list of PubMed identifier by query parameters\n    ---\n\n    tags:\n\n      - Query functions\n\n    parameters:\n\n      - name: pmid\n        in: query\n        type: string\n        required: false\n        description: PubMed identifier\n        default: 20697050\n\n      - name: entry_name\n        in: query\n        type: string\n        required: false\n        description: UniProt entry name\n        default: A4_HUMAN\n\n      - name: first\n        in: query\n        type: string\n        required: false\n        description: first page\n        default: 987\n\n      - name: last\n        in: query\n        type: string\n        required: false\n        description: last page\n        default: 995\n\n      - name: volume\n        in: query\n        type: string\n        required: false\n        description: Volume\n        default: 67\n\n      - name: name\n        in: query\n        type: string\n        required: false\n        description: Name of journal\n        default: 'Arch. Neurol.'\n\n      - name: date\n        in: query\n        type: string\n        required: false\n        description: Publication date\n        default: 2010\n\n      - name: title\n        in: query\n        type: string\n        required: false\n        description: Title of publication\n        default: '%amyloidosis%'\n\n      - name: limit\n        in: query\n        type: integer\n        required: false\n        description: limit of results numbers\n        default: 10\n    \"\"\"\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['first', 'last', 'volume', 'name', 'date', 'title', 'entry_name'],\n        allowed_int_args=['pmid', 'limit']\n    )\n\n    return jsonify(query.pmid(**args))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning list of host organism by query parameters", "response": "def query_organism_host():\n    \"\"\"\n    Returns list of host organism by query parameters\n    ---\n\n    tags:\n\n      - Query functions\n\n    parameters:\n\n      - name: taxid\n        in: query\n        type: integer\n        required: false\n        description: NCBI taxonomy identifier\n        default: 9606\n\n      - name: entry_name\n        in: query\n        type: string\n        required: false\n        description: UniProt entry name\n        default: A4_HUMAN\n\n      - name: limit\n        in: query\n        type: integer\n        required: false\n        description: limit of results numbers\n        default: 10\n    \"\"\"\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['entry_name'],\n        allowed_int_args=['taxid', 'limit']\n    )\n\n    return jsonify(query.organism_host(**args))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_db_reference():\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['type_', 'identifier', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.db_reference(**args))", "response": "Query UniProt database for cross references by query parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_feature():\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['type_', 'identifier', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.feature(**args))", "response": "Query UniProt s feature API"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_function():\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['text', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.function(**args))", "response": "Query UniProt function by query parameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_keyword():\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['name', 'identifier', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    print(args)\n\n    return jsonify(query.keyword(**args))", "response": "Returns list of keywords linked to entries by query parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries UniProt for the EC numbers of the current entry.", "response": "def query_ec_number():\n    \"\"\"\n    Returns list of Enzyme Commission Numbers (EC numbers) by query parameters\n    ---\n    tags:\n\n      - Query functions\n\n    parameters:\n\n      - name: ec_number\n        in: query\n        type: string\n        required: false\n        description: Enzyme Commission Number\n        default: '1.1.1.1'\n\n      - name: entry_name\n        in: query\n        type: string\n        required: false\n        description: UniProt entry name\n        default: ADHX_HUMAN\n\n      - name: limit\n        in: query\n        type: integer\n        required: false\n        description: limit of results numbers\n        default: 10\n    \"\"\"\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['ec_number', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n    return jsonify(query.ec_number(**args))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_subcellular_location():\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['location', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.subcellular_location(**args))", "response": "Returns list of subcellular locations by query parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query_tissue_specificity():\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['comment', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.tissue_specificity(**args))", "response": "Returns list of tissue specificity by query parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query_tissue_in_reference():\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['tissue', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n\n    return jsonify(query.tissue_in_reference(**args))", "response": "Returns a list of tissues linked to references by query parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_disease_comment():\n    args = get_args(\n        request_args=request.args,\n        allowed_str_args=['comment', 'entry_name'],\n        allowed_int_args=['limit']\n    )\n    return jsonify(query.disease_comment(**args))", "response": "Returns a list of diseases comments on uniProt entry in the order they were linked to UniProt"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter(self):\n        upperCase = self._upperCase\n        for _file in self._files:\n            with asHandle(_file) as fp:\n                records = SeqIO.parse(fp, 'fasta')\n                while True:\n                    try:\n                        record = next(records)\n                    except StopIteration:\n                        break\n                    try:\n                        structureRecord = next(records)\n                    except StopIteration:\n                        raise ValueError('Structure file %r has an odd number '\n                                         'of records.' % _file)\n\n                    if len(structureRecord) != len(record):\n                        raise ValueError(\n                            'Sequence %r length (%d) is not equal to '\n                            'structure %r length (%d) in input file %r.' % (\n                                record.description, len(record),\n                                structureRecord.description,\n                                len(structureRecord), _file))\n\n                    if upperCase:\n                        read = self._readClass(\n                            record.description,\n                            str(record.seq.upper()),\n                            str(structureRecord.seq.upper()))\n                    else:\n                        read = self._readClass(record.description,\n                                               str(record.seq),\n                                               str(structureRecord.seq))\n\n                    yield read", "response": "Iterate over the sequences in self. file_ yielding each as an anonymized read class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef npartial(func, *args, **kwargs):\n  def wrapped(self, node):\n    func(self, *args, **kwargs)\n  return wrapped", "response": "Returns a partial node visitor function"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef aa3_to_aa1(seq):\n    if seq is None:\n        return None\n    return \"\".join(aa3_to_aa1_lut[aa3]\n                   for aa3 in [seq[i:i + 3] for i in range(0, len(seq), 3)])", "response": "convert string of 3 - letter amino acids to 1 - letter amino acids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrim a sequence to include the left and right flanking sequences of the given size flank and elided by elision.", "response": "def elide_sequence(s, flank=5, elision=\"...\"):\n    \"\"\"trim a sequence to include the left and right flanking sequences of\n    size `flank`, with the intervening sequence elided by `elision`.\n\n    >>> elide_sequence(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n    'ABCDE...VWXYZ'\n\n    >>> elide_sequence(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", flank=3)\n    'ABC...XYZ'\n\n    >>> elide_sequence(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", elision=\"..\")\n    'ABCDE..VWXYZ'\n\n    >>> elide_sequence(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", flank=12)\n    'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n\n    >>> elide_sequence(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", flank=12, elision=\".\")\n    'ABCDEFGHIJKL.OPQRSTUVWXYZ'\n\n    \"\"\"\n\n    elided_sequence_len = flank + flank + len(elision)\n    if len(s) <= elided_sequence_len:\n        return s\n    return s[:flank] + elision + s[-flank:]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize_sequence(seq):\n\n    nseq = re.sub(r\"[\\s\\*]\", \"\", seq).upper()\n    m = re.search(\"[^A-Z]\", nseq)\n    if m:\n        _logger.debug(\"Original sequence: \" + seq)\n        _logger.debug(\"Normalized sequence: \" + nseq)\n        _logger.debug(\"First non-[A-Z] at {}\".format(m.start()))\n        raise RuntimeError(\"Normalized sequence contains non-alphabetic characters\")\n    return nseq", "response": "return normalized representation of sequence for hashing\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef translate_cds(seq, full_codons=True, ter_symbol=\"*\"):\n    if seq is None:\n        return None\n\n    if len(seq) == 0:\n        return \"\"\n\n    if full_codons and len(seq) % 3 != 0:\n        raise ValueError(\"Sequence length must be a multiple of three\")\n\n    seq = replace_u_to_t(seq)\n    seq = seq.upper()\n\n    protein_seq = list()\n    for i in range(0, len(seq) - len(seq) % 3, 3):\n        try:\n            aa = dna_to_aa1_lut[seq[i:i + 3]]\n        except KeyError:\n            raise ValueError(\"Codon {} at position {}..{} is undefined in codon table\".format(\n                seq[i:i + 3], i+1, i+3))\n        protein_seq.append(aa)\n\n    # check for trailing bases and add the ter symbol if required\n    if not full_codons and len(seq) % 3 != 0:\n        protein_seq.append(ter_symbol)\n\n    return ''.join(protein_seq)", "response": "Translate a DNA or RNA sequence into a single - letter amino acid sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef request(self, url, *,\n                method='GET', headers=None, data=None, result_callback=None):\n        \"\"\"Perform request.\n\n        :param str url: request URL.\n        :param str method: request method.\n        :param dict headers: request headers.\n        :param object data: request data.\n        :param object -> object result_callback: result callback.\n\n        :rtype: dict\n        :raise: APIError\n        \"\"\"\n\n        url = self._make_full_url(url)\n\n        self._log.debug('Performing %s request to %s', method, url)\n        return self._request(url, method=method, headers=headers, data=data,\n                             result_callback=result_callback)", "response": "Perform a request to the specified URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_full_url(self, url):\n\n        return SLASH.join([self._api_base_url, url.lstrip(SLASH)])", "response": "Given base and relative URL construct the full URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_dictionaries(current, new, only_defaults=False, template_special_case=False):\n    '''\n    Merge two settings dictionaries, recording how many changes were needed.\n\n    '''\n    changes = 0\n    for key, value in new.items():\n        if key not in current:\n            if hasattr(global_settings, key):\n                current[key] = getattr(global_settings, key)\n                LOGGER.debug(\"Set %r to global default %r.\", key, current[key])\n            else:\n                current[key] = copy.copy(value)\n                LOGGER.debug(\"Set %r to %r.\", key, current[key])\n                changes += 1\n                continue\n        elif only_defaults:\n            continue\n        current_value = current[key]\n        if hasattr(current_value, 'items'):\n            changes += merge_dictionaries(current_value, value)\n        elif isinstance(current_value, (list, tuple)):\n            for element in value:\n                if element not in current_value:\n                    if template_special_case and key == 'TEMPLATES':\n                        existing_matches = [\n                            template for template in current_value if template['BACKEND'] == element['BACKEND']\n                        ]\n                        if existing_matches:\n                            changes += merge_dictionaries(existing_matches[0], element)\n                        else:\n                            current[key] = list(current_value) + [element]\n                            LOGGER.debug(\"Added %r to %r.\", element, key)\n                            changes += 1\n                    else:\n                        current[key] = list(current_value) + [element]\n                        LOGGER.debug(\"Added %r to %r.\", element, key)\n                        changes += 1\n        elif isinstance(current_value, Promise) or isinstance(value, Promise):\n            # If we don't know what to do with it, replace it.\n            if current_value is not value:\n                current[key] = value\n                LOGGER.debug(\"Set %r to %r.\", key, current[key])\n                changes += 1\n        else:\n            # If we don't know what to do with it, replace it.\n            if current_value != value:\n                current[key] = value\n                LOGGER.debug(\"Set %r to %r.\", key, current[key])\n                changes += 1\n    return changes", "response": "Merge two settings dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_settings(settings, environment_settings=True):\n    '''\n    Given a settings object, run automatic configuration of all\n    the apps in INSTALLED_APPS.\n    '''\n    changes = 1\n    iterations = 0\n\n    while changes:\n        changes = 0\n        app_names = ['django_autoconfig'] + list(settings['INSTALLED_APPS'])\n        if environment_settings:\n            app_names.append('django_autoconfig.environment_settings')\n        for app_name in app_names:\n            import django_autoconfig.contrib\n            if autoconfig_module_exists(app_name):\n                module = importlib.import_module(\"%s.autoconfig\" % (app_name,))\n            elif app_name in django_autoconfig.contrib.CONTRIB_CONFIGS:\n                module = django_autoconfig.contrib.CONTRIB_CONFIGS[app_name]\n            else:\n                continue\n            changes += merge_dictionaries(\n                settings,\n                getattr(module, 'SETTINGS', {}),\n                template_special_case=True,\n            )\n            changes += merge_dictionaries(\n                settings,\n                getattr(module, 'DEFAULT_SETTINGS', {}),\n                only_defaults=True,\n            )\n            for relationship in getattr(module, 'RELATIONSHIPS', []):\n                changes += relationship.apply_changes(settings)\n\n        if iterations >= MAX_ITERATIONS:\n            raise ImproperlyConfigured(\n                'Autoconfiguration could not reach a consistent state'\n            )\n        iterations += 1\n    LOGGER.debug(\"Autoconfiguration took %d iterations.\", iterations)", "response": "Given a settings object run automatic configuration of all the apps in INSTALLED_APPS and apply any settings that are not already set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconfigure urls from a list of apps.", "response": "def configure_urls(apps, index_view=None, prefixes=None):\n    '''\n    Configure urls from a list of apps.\n    '''\n    prefixes = prefixes or {}\n    urlpatterns = patterns('')\n\n    if index_view:\n        from django.views.generic.base import RedirectView\n        urlpatterns += patterns('',\n            url(r'^$', RedirectView.as_view(pattern_name=index_view, permanent=False)),\n        )\n\n    for app_name in apps:\n        app_module = importlib.import_module(app_name)\n        if module_has_submodule(app_module, 'urls'):\n            module = importlib.import_module(\"%s.urls\" % app_name)\n            if not hasattr(module, 'urlpatterns'):\n                # Resolver will break if the urls.py file is completely blank.\n                continue\n            app_prefix = prefixes.get(app_name, app_name.replace(\"_\",\"-\"))\n            urlpatterns += patterns(\n                '',\n                url(\n                    r'^%s/' % app_prefix if app_prefix else '',\n                    include(\"%s.urls\" % app_name),\n                ),\n            )\n\n\n    return urlpatterns"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_images(data):\n    if isinstance(data, ndarray):\n        data = fromarray(data)\n    \n    if not isinstance(data, Images):\n        data = fromarray(asarray(data))\n\n    if len(data.shape) not in set([3, 4]):\n        raise Exception('Number of image dimensions %s must be 2 or 3' % (len(data.shape)))\n\n    return data", "response": "Check and reformat input images if needed\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that the reference is valid.", "response": "def check_reference(images, reference):\n    \"\"\"\n    Ensure the reference matches image dimensions\n    \"\"\"\n    if not images.shape[1:] == reference.shape:\n        raise Exception('Image shape %s and reference shape %s must match'\n                        % (images.shape[1:], reference.shape))\n    return reference"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating an ExpGene object from a dictionary.", "response": "def from_dict(cls, data: Dict[str, Union[str, int]]):\n        \"\"\"Generate an `ExpGene` object from a dictionary.\n\n        Parameters\n        ----------\n        data : dict\n            A dictionary with keys corresponding to attribute names.\n            Attributes with missing keys will be assigned `None`.\n\n        Returns\n        -------\n        `ExpGene`\n            The gene.\n        \"\"\"\n        assert isinstance(data, dict)\n\n        if 'ensembl_id' not in data:\n            raise ValueError('An \"ensembl_id\" key is missing!')\n\n        # make a copy\n        data = dict(data)\n        \n        for attr in ['name', 'chromosome', 'position', 'length',\n                     'type', 'source']:\n            if attr in data and data[attr] == '':\n                data[attr] = None            \n\n        data['type_'] = data['type']\n        del data['type']\n\n        return cls(**data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the start and end offsets of a matching read.", "response": "def add(self, start, end):\n        \"\"\"\n        Add the start and end offsets of a matching read.\n\n        @param start: The C{int} start offset of the read match in the subject.\n        @param end: The C{int} end offset of the read match in the subject.\n            This is Python-style: the end offset is not included in the match.\n        \"\"\"\n        assert start <= end\n        self._intervals.append((start, end))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef walk(self):\n        intervals = sorted(self._intervals)\n\n        def nextFull():\n            start, stop = intervals.pop(0)\n            while intervals:\n                if intervals[0][0] <= stop:\n                    _, thisStop = intervals.pop(0)\n                    if thisStop > stop:\n                        stop = thisStop\n                else:\n                    break\n            return (start, stop)\n\n        if intervals:\n            # If the first interval (read) starts after zero, yield an\n            # initial empty section to get us to the first interval.\n            if intervals[0][0] > 0:\n                yield (self.EMPTY, (0, intervals[0][0]))\n\n            while intervals:\n                # Yield a full interval followed by an empty one (if there\n                # is another interval pending).\n                lastFull = nextFull()\n                yield (self.FULL, lastFull)\n                if intervals:\n                    yield (self.EMPTY, (lastFull[1], intervals[0][0]))\n\n            # Yield the final empty section, if any.\n            if lastFull[1] < self._targetLength:\n                yield (self.EMPTY, (lastFull[1], self._targetLength))\n\n        else:\n            yield (self.EMPTY, (0, self._targetLength))", "response": "A generator that returns the non - overlapping read intervals that match the subject."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the fraction of a subject is matched by its set of reads.", "response": "def coverage(self):\n        \"\"\"\n        Get the fraction of a subject is matched by its set of reads.\n\n        @return: The C{float} fraction of a subject matched by its reads.\n        \"\"\"\n        if self._targetLength == 0:\n            return 0.0\n\n        coverage = 0\n        for (intervalType, (start, end)) in self.walk():\n            if intervalType == self.FULL:\n                # Adjust start and end to ignore areas where the read falls\n                # outside the target.\n                coverage += (min(end, self._targetLength) - max(0, start))\n        return float(coverage) / self._targetLength"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef coverageCounts(self):\n        coverageCounts = Counter()\n        for start, end in self._intervals:\n            coverageCounts.update(range(max(0, start),\n                                        min(self._targetLength, end)))\n        return coverageCounts", "response": "Returns a Counter containing the number of times each location in the subject is covered by a read."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the total reduction for a given offset.", "response": "def _reductionForOffset(self, offset):\n        \"\"\"\n        Calculate the total reduction for a given X axis offset.\n\n        @param offset: The C{int} offset.\n        @return: The total C{float} reduction that should be made for this\n            offset.\n        \"\"\"\n        reduction = 0\n        for (thisOffset, thisReduction) in self._adjustments:\n            if offset >= thisOffset:\n                reduction += thisReduction\n            else:\n                break\n        return reduction"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadjusts the read and subject start and end offsets in an HSP instance.", "response": "def adjustHSP(self, hsp):\n        \"\"\"\n        Adjust the read and subject start and end offsets in an HSP.\n\n        @param hsp: a L{dark.hsp.HSP} or L{dark.hsp.LSP} instance.\n        \"\"\"\n        reduction = self._reductionForOffset(\n            min(hsp.readStartInSubject, hsp.subjectStart))\n\n        hsp.readEndInSubject = hsp.readEndInSubject - reduction\n        hsp.readStartInSubject = hsp.readStartInSubject - reduction\n        hsp.subjectEnd = hsp.subjectEnd - reduction\n        hsp.subjectStart = hsp.subjectStart - reduction"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlooking up a gene set by its index.", "response": "def get_by_index(self, i):\n        \"\"\"Look up a gene set by its index.\n\n        Parameters\n        ----------\n        i: int\n            The index of the gene set.\n\n        Returns\n        -------\n        GeneSet\n            The gene set.\n\n        Raises\n        ------\n        ValueError\n            If the given index is out of bounds.\n        \"\"\"\n        if i >= self.n:\n            raise ValueError('Index %d out of bounds ' % i +\n                             'for database with %d gene sets.' % self.n)\n        return self._gene_sets[self._gene_set_ids[i]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_tsv(cls, path, encoding='utf-8'):\n        gene_sets = []\n        n = 0\n        with open(path, 'rb') as fh:\n            reader = csv.reader(fh, dialect='excel-tab', encoding=encoding)\n            for l in reader:\n                n += 1\n                gs = GeneSet.from_list(l)\n                gene_sets.append(gs)\n        logger.debug('Read %d gene sets.', n)\n        logger.debug('Size of gene set list: %d', len(gene_sets))\n        return cls(gene_sets)", "response": "Read a gene set database from a tab - delimited text file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the database to a tab - delimited text file.", "response": "def write_tsv(self, path):\n        \"\"\"Write the database to a tab-delimited text file.\n\n        Parameters\n        ----------\n        path: str\n            The path name of the file.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        with open(path, 'wb') as ofh:\n            writer = csv.writer(\n                ofh, dialect='excel-tab',\n                quoting=csv.QUOTE_NONE, lineterminator=os.linesep\n            )\n            for gs in self._gene_sets.values():\n                writer.writerow(gs.to_list())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the complete MSigDB database from an XML file.", "response": "def read_msigdb_xml(cls, path, entrez2gene, species=None):  # pragma: no cover\n        \"\"\"Read the complete MSigDB database from an XML file.\n\n        The XML file can be downloaded from here:\n        http://software.broadinstitute.org/gsea/msigdb/download_file.jsp?filePath=/resources/msigdb/5.0/msigdb_v5.0.xml\n\n        Parameters\n        ----------\n        path: str\n            The path name of the XML file.\n        entrez2gene: dict or OrderedDict (str: str)\n            A dictionary mapping Entrez Gene IDs to gene symbols (names).\n        species: str, optional\n            A species name (e.g., \"Homo_sapiens\"). Only gene sets for that\n            species will be retained. (None)\n\n        Returns\n        -------\n        GeneSetCollection\n            The gene set database containing the MSigDB gene sets.\n        \"\"\"\n\n        # note: is XML file really encoded in UTF-8?\n\n        assert isinstance(path, (str, _oldstr))\n        assert isinstance(entrez2gene, (dict, OrderedDict))\n        assert species is None or isinstance(species, (str, _oldstr))\n\n        logger.debug('Path: %s', path)\n        logger.debug('entrez2gene type: %s', str(type(entrez2gene)))\n\n        i = [0]\n        gene_sets = []\n\n        total_gs = [0]\n        total_genes = [0]\n\n        species_excl = [0]\n        unknown_entrezid = [0]\n\n        src = 'MSigDB'\n\n        def handle_item(pth, item):\n            # callback function for xmltodict.parse()\n\n            total_gs[0] += 1\n            data = pth[1][1]\n\n            spec = data['ORGANISM']\n            # filter by species\n            if species is not None and spec != species:\n                species_excl[0] += 1\n                return True\n\n            id_ = data['SYSTEMATIC_NAME']\n            name = data['STANDARD_NAME']\n            coll = data['CATEGORY_CODE']\n            desc = data['DESCRIPTION_BRIEF']\n            entrez = data['MEMBERS_EZID'].split(',')\n\n            genes = []\n            for e in entrez:\n                total_genes[0] += 1\n                try:\n                    genes.append(entrez2gene[e])\n                except KeyError:\n                    unknown_entrezid[0] += 1\n\n            if not genes:\n                logger.warning('Gene set \"%s\" (%s) has no known genes!',\n                               name, id_)\n                return True\n\n            gs = GeneSet(id_, name, genes, source=src,\n                         collection=coll, description=desc)\n            gene_sets.append(gs)\n            i[0] += 1\n            return True\n\n        # parse the XML file using the xmltodict package\n        with io.open(path, 'rb') as fh:\n            xmltodict.parse(fh.read(), encoding='UTF-8', item_depth=2,\n                            item_callback=handle_item)\n\n        # report some statistics\n        if species_excl[0] > 0:\n            kept = total_gs[0] - species_excl[0]\n            perc = 100 * (kept / float(total_gs[0]))\n            logger.info('%d of all %d gene sets (%.1f %%) belonged to the '\n                        'specified species.', kept, total_gs[0], perc)\n\n        if unknown_entrezid[0] > 0:\n            unkn = unknown_entrezid[0]\n            # known = total_genes[0] - unknown_entrezid[0]\n            perc = 100 * (unkn / float(total_genes[0]))\n            logger.warning('%d of a total of %d genes (%.1f %%) had an ' +\n                           'unknown Entrez ID.', unkn, total_genes[0], perc)\n\n        logger.info('Parsed %d entries, resulting in %d gene sets.',\n                    total_gs[0], len(gene_sets))\n\n        return cls(gene_sets)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nproviding a textual description of the feature and its qualifiers to be used as a label in a plot legend.", "response": "def legendLabel(self):\n        \"\"\"\n        Provide a textual description of the feature and its qualifiers to be\n        used as a label in a plot legend.\n\n        @return: A C{str} description of the feature.\n        \"\"\"\n        excludedQualifiers = set((\n            'codon_start', 'db_xref', 'protein_id', 'region_name',\n            'ribosomal_slippage', 'rpt_type', 'translation', 'transl_except',\n            'transl_table')\n        )\n        maxValueLength = 30\n        result = []\n        if self.feature.qualifiers:\n            for qualifier in sorted(self.feature.qualifiers.keys()):\n                if qualifier not in excludedQualifiers:\n                    value = ', '.join(self.feature.qualifiers[qualifier])\n                    if qualifier == 'site_type' and value == 'other':\n                        continue\n                    if len(value) > maxValueLength:\n                        value = value[:maxValueLength - 3] + '...'\n                    result.append('%s: %s' % (qualifier, value))\n        return '%d-%d %s%s.%s' % (\n            int(self.feature.location.start),\n            int(self.feature.location.end),\n            self.feature.type,\n            ' (subfeature)' if self.subfeature else '',\n            ' ' + ', '.join(result) if result else '')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the features for a specific sequence title.", "response": "def add(self, fig, title, minX, maxX, offsetAdjuster=None,\n            sequenceFetcher=None):\n        \"\"\"\n        Find the features for a sequence title. If there aren't too many, add\n        the features to C{fig}. Return information about the features, as\n        described below.\n\n        @param fig: A matplotlib figure.\n        @param title: A C{str} sequence title from a BLAST hit. Of the form\n            'gi|63148399|gb|DQ011818.1| Description...'.\n        @param minX: The smallest x coordinate.\n        @param maxX: The largest x coordinate.\n         @param offsetAdjuster: a function for adjusting feature X axis offsets\n            for plotting.\n        @param sequenceFetcher: A function that takes a sequence title and a\n            database name and returns a C{Bio.SeqIO} instance. If C{None}, use\n            L{dark.entrez.getSequence}.\n        @return: If we seem to be offline, return C{None}. Otherwise, return\n            a L{FeatureList} instance.\n        \"\"\"\n\n        offsetAdjuster = offsetAdjuster or (lambda x: x)\n\n        fig.set_title('Target sequence features', fontsize=self.TITLE_FONTSIZE)\n        fig.set_yticks([])\n\n        features = FeatureList(title, self.DATABASE, self.WANTED_TYPES,\n                               sequenceFetcher=sequenceFetcher)\n\n        if features.offline:\n            fig.text(minX + (maxX - minX) / 3.0, 0,\n                     'You (or Genbank) appear to be offline.',\n                     fontsize=self.FONTSIZE)\n            fig.axis([minX, maxX, -1, 1])\n            return None\n\n        # If no interesting features were found, display a message saying\n        # so in the figure.  Otherwise, if we don't have too many features\n        # to plot, add the feature info to the figure.\n        nFeatures = len(features)\n        if nFeatures == 0:\n            # fig.text(minX + (maxX - minX) / 3.0, 0, 'No features found',\n            #          fontsize=self.FONTSIZE)\n            fig.text(0.5, 0.5, 'No features found',\n                     horizontalalignment='center', verticalalignment='center',\n                     transform=fig.transAxes, fontsize=self.FONTSIZE)\n            fig.axis([minX, maxX, -1, 1])\n        elif nFeatures <= self.MAX_FEATURES_TO_DISPLAY:\n            # Call the method in our subclass to do the figure display.\n            self._displayFeatures(fig, features, minX, maxX, offsetAdjuster)\n        else:\n            self.tooManyFeaturesToPlot = True\n            # fig.text(minX + (maxX - minX) / 3.0, 0,\n            # 'Too many features to plot.', fontsize=self.FONTSIZE)\n            fig.text(0.5, 0.5, 'Too many features to plot',\n                     horizontalalignment='center', verticalalignment='center',\n                     fontsize=self.FONTSIZE, transform=fig.transAxes)\n            fig.axis([minX, maxX, -1, 1])\n\n        return features"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _displayFeatures(self, fig, features, minX, maxX, offsetAdjuster):\n        labels = []\n        for index, feature in enumerate(features):\n            fig.plot([offsetAdjuster(feature.start),\n                      offsetAdjuster(feature.end)],\n                     [index * -0.2, index * -0.2], color=feature.color,\n                     linewidth=2)\n            labels.append(feature.legendLabel())\n\n        # Note that minX and maxX do not need to be adjusted by the offset\n        # adjuster. They are the already-adjusted min/max values as\n        # computed in computePlotInfo in blast.py\n        fig.axis([minX, maxX, (len(features) + 1) * -0.2, 0.2])\n\n        if labels:\n            # Put a legend above the figure.\n            box = fig.get_position()\n            fig.set_position([box.x0, box.y0,\n                              box.width, box.height * 0.2])\n            fig.legend(labels, loc='lower center', bbox_to_anchor=(0.5, 1.4),\n                       fancybox=True, shadow=True, ncol=2)", "response": "Display the given features in the given figure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay the given features in the given figure.", "response": "def _displayFeatures(self, fig, features, minX, maxX, offsetAdjuster):\n        \"\"\"\n        Add the given C{features} to the figure in C{fig}.\n\n        @param fig: A matplotlib figure.\n        @param features: A C{FeatureList} instance.\n        @param minX: The smallest x coordinate.\n        @param maxX: The largest x coordinate.\n        @param offsetAdjuster: a function for adjusting feature X axis offsets\n            for plotting.\n        \"\"\"\n        frame = None\n        labels = []\n        for feature in features:\n            start = offsetAdjuster(feature.start)\n            end = offsetAdjuster(feature.end)\n            if feature.subfeature:\n                subfeatureFrame = start % 3\n                if subfeatureFrame == frame:\n                    # Move overlapping subfeatures down a little to make them\n                    # visible.\n                    y = subfeatureFrame - 0.2\n                else:\n                    y = subfeatureFrame\n            else:\n                frame = start % 3\n                # If we have a polyprotein, shift it up slightly so we can see\n                # its components below it.\n                product = feature.feature.qualifiers.get('product', [''])[0]\n                if product.lower().find('polyprotein') > -1:\n                    y = frame + 0.2\n                else:\n                    y = frame\n            fig.plot([start, end], [y, y], color=feature.color, linewidth=2)\n            labels.append(feature.legendLabel())\n\n        # Note that minX and maxX do not need to be adjusted by the offset\n        # adjuster. They are the already-adjusted min/max values as\n        # computed in computePlotInfo in blast.py\n        fig.axis([minX, maxX, -0.5, 2.5])\n        fig.set_yticks(np.arange(3))\n        fig.set_ylabel('Frame')\n\n        if labels:\n            # Put a legend above the figure.\n            box = fig.get_position()\n            fig.set_position([box.x0, box.y0,\n                              box.width, box.height * 0.3])\n            fig.legend(labels, loc='lower center', bbox_to_anchor=(0.5, 2.5),\n                       fancybox=True, shadow=True, ncol=2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of latest articles", "response": "def recent_articles(limit=10, exclude=None):\n    \"\"\"Returns list of latest article\"\"\"\n    queryset = Article.objects.filter(published=True).order_by('-modified')\n    if exclude:\n        if hasattr(exclude, '__iter__'):\n            queryset = queryset.exclude(pk__in=exclude)\n        else:\n            queryset = queryset.exclude(pk=exclude)\n    return queryset"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _flatten(n):\n    if isinstance(n, collections.Sequence):\n        for x in n:\n            for y in _flatten(x):\n                yield y\n    else:\n        yield n", "response": "Recursively flatten a mixed sequence of sub - sequences and items"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap a Python stream to implement expect functionality.", "response": "def wrap(stream, unicode=False, window=1024, echo=False, close_stream=True):\n    \"\"\"Wrap a stream to implement expect functionality.\n\n    This function provides a convenient way to wrap any Python stream (a\n    file-like object) or socket with an appropriate :class:`Expecter` class for\n    the stream type. The returned object adds an :func:`Expect.expect` method\n    to the stream, while passing normal stream functions like *read*/*recv*\n    and *write*/*send* through to the underlying stream.\n\n    Here's an example of opening and wrapping a pair of network sockets::\n\n        import socket\n        import streamexpect\n\n        source, drain = socket.socketpair()\n        expecter = streamexpect.wrap(drain)\n        source.sendall(b'this is a test')\n        match = expecter.expect_bytes(b'test', timeout=5)\n\n        assert match is not None\n\n    :param stream: The stream/socket to wrap.\n    :param bool unicode: If ``True``, the wrapper will be configured for\n        Unicode matching, otherwise matching will be done on binary.\n    :param int window: Historical characters to buffer.\n    :param bool echo: If ``True``, echoes received characters to stdout.\n    :param bool close_stream: If ``True``, and the wrapper is used as a context\n        manager, closes the stream at the end of the context manager.\n    \"\"\"\n    if hasattr(stream, 'read'):\n        proxy = PollingStreamAdapter(stream)\n    elif hasattr(stream, 'recv'):\n        proxy = PollingSocketStreamAdapter(stream)\n    else:\n        raise TypeError('stream must have either read or recv method')\n\n    if echo and unicode:\n        callback = _echo_text\n    elif echo and not unicode:\n        callback = _echo_bytes\n    else:\n        callback = None\n\n    if unicode:\n        expecter = TextExpecter(proxy, input_callback=callback, window=window,\n                                close_adapter=close_stream)\n    else:\n        expecter = BytesExpecter(proxy, input_callback=callback, window=window,\n                                 close_adapter=close_stream)\n\n    return expecter"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_type(self, value):\n        if not isinstance(value, self.match_type):\n            raise TypeError('Type ' + str(type(value)) + ' does not match '\n                            'expected type ' + str(self.match_type))\n        else:\n            return value", "response": "Checks that the type of value matches the type of this *Searcher*. This method returns the value if it does not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch the provided buffer for matching bytes.", "response": "def search(self, buf):\n        \"\"\"Search the provided buffer for matching bytes.\n\n        Search the provided buffer for matching bytes. If the *match* is found,\n        returns a :class:`SequenceMatch` object, otherwise returns ``None``.\n\n        :param buf: Buffer to search for a match.\n        :return: :class:`SequenceMatch` if matched, None if no match was found.\n        \"\"\"\n        idx = self._check_type(buf).find(self._bytes)\n        if idx < 0:\n            return None\n        else:\n            start = idx\n            end = idx + len(self._bytes)\n            return SequenceMatch(self, buf[start:end], start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches the provided buffer for a match.", "response": "def search(self, buf):\n        \"\"\"Search the provided buffer for matching text.\n\n        Search the provided buffer for matching text. If the *match* is found,\n        returns a :class:`SequenceMatch` object, otherwise returns ``None``.\n\n        :param buf: Buffer to search for a match.\n        :return: :class:`SequenceMatch` if matched, None if no match was found.\n        \"\"\"\n        self._check_type(buf)\n        normalized = unicodedata.normalize(self.FORM, buf)\n        idx = normalized.find(self._text)\n        if idx < 0:\n            return None\n        start = idx\n        end = idx + len(self._text)\n        return SequenceMatch(self, normalized[start:end], start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch the provided buffer for a match to the object s regex.", "response": "def search(self, buf):\n        \"\"\"Search the provided buffer for a match to the object's regex.\n\n        Search the provided buffer for a match to the object's regex. If the\n        *match* is found, returns a :class:`RegexMatch` object, otherwise\n        returns ``None``.\n\n        :param buf: Buffer to search for a match.\n        :return: :class:`RegexMatch` if matched, None if no match was found.\n        \"\"\"\n        match = self._regex.search(self._check_type(buf))\n        if match is not None:\n            start = match.start()\n            end = match.end()\n            return RegexMatch(self, buf[start:end], start, end, match.groups())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self, buf):\n        self._check_type(buf)\n        best_match = None\n        best_index = sys.maxsize\n        for searcher in self:\n            match = searcher.search(buf)\n            if match and match.start < best_index:\n                best_match = match\n                best_index = match.start\n        return best_match", "response": "Search the provided buffer for a match to any of the available sub - searches."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npolling for a specific entry in the cache.", "response": "def poll(self, timeout):\n        \"\"\"\n        :param float timeout: Timeout in seconds.\n        \"\"\"\n        timeout = float(timeout)\n        end_time = time.time() + timeout\n        while True:\n            # Keep reading until data is received or timeout\n            incoming = self.stream.read(self._max_read)\n            if incoming:\n                return incoming\n            if (end_time - time.time()) < 0:\n                raise ExpectTimeout()\n            time.sleep(self._poll_period)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef poll(self, timeout):\n        now = time.time()\n        end_time = now + float(timeout)\n        prev_timeout = self.stream.gettimeout()\n        self.stream.settimeout(self._poll_period)\n        incoming = None\n        try:\n            while (end_time - now) >= 0:\n                try:\n                    incoming = self.stream.recv(self._max_read)\n                except socket.timeout:\n                    pass\n                if incoming:\n                    return incoming\n                now = time.time()\n            raise ExpectTimeout()\n        finally:\n            self.stream.settimeout(prev_timeout)", "response": "Poll for a single entry in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait for input matching the regex in pattern to appear on the stream.", "response": "def expect_regex(self, pattern, timeout=3, regex_options=0):\n        \"\"\"Wait for a match to the regex in *pattern* to appear on the stream.\n\n        Waits for input matching the regex *pattern* for up to *timeout*\n        seconds. If a match is found, a :class:`RegexMatch` result is returned.\n        If no match is found within *timeout* seconds, raise an\n        :class:`ExpectTimeout` exception.\n\n        :param pattern: The pattern to search for, as a single compiled regex\n            or a string that will be processed as a regex.\n        :param float timeout: Timeout in seconds.\n        :param regex_options: Options passed to the regex engine.\n        :return: :class:`RegexMatch` if matched, None if no match was found.\n        \"\"\"\n        return self.expect(RegexSearcher(pattern, regex_options), timeout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expect(self, searcher, timeout=3):\n        timeout = float(timeout)\n        end = time.time() + timeout\n        match = searcher.search(self._history[self._start:])\n        while not match:\n            # poll() will raise ExpectTimeout if time is exceeded\n            incoming = self._stream_adapter.poll(end - time.time())\n            self.input_callback(incoming)\n            self._history += incoming\n            match = searcher.search(self._history[self._start:])\n            trimlength = len(self._history) - self._window\n            if trimlength > 0:\n                self._start -= trimlength\n                self._history = self._history[trimlength:]\n\n        self._start += match.end\n        if (self._start < 0):\n            self._start = 0\n\n        return match", "response": "Wait for input matching searcher to be available for up to timeout seconds."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_graph(self):\n        self._graph = Graph()\n\n        # First add all nodes\n        for key in self.loader.disk_fixtures.keys():\n            self.graph.add_node(key)\n\n        # Then set dependencies\n        for key, fixture in self.loader.disk_fixtures.items():\n            for dependency in fixture.dependencies:\n                self.graph.add_dependency(key, dependency)", "response": "Initialize the internal graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_app_nodes(self, app_label):\n        return [node for node in self.graph.nodes if node[0] == app_label]", "response": "Get all nodes for given app_label"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all fixtures with given prefix.", "response": "def get_fixture_node(self, app_label, fixture_prefix):\n        \"\"\"\n        Get all fixtures in given app with given prefix.\n        :param str app_label: App label\n        :param str fixture_prefix: first part of the fixture name\n        :return: list of found fixtures.\n        \"\"\"\n        app_nodes = self.get_app_nodes(app_label=app_label)\n        nodes = [\n            node for node in app_nodes if node[1].startswith(fixture_prefix)\n            ]\n\n        if len(nodes) > 1:\n            raise MultipleFixturesFound(\n                \"The following fixtures with prefix '%s' are found in app '%s'\"\n                \": %s\" % (\n                    fixture_prefix, app_label, ', '.join(\n                        [node[1] for node in nodes]\n                    )\n                )\n            )\n        elif len(nodes) == 0:\n            raise FixtureNotFound(\"Fixture with prefix '%s' not found in app \"\n                                  \"'%s'\" % (fixture_prefix, app_label))\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_fixtures(self, nodes=None, progress_callback=None, dry_run=False):\n\n        if progress_callback and not callable(progress_callback):\n            raise Exception('Callback should be callable')\n\n        plan = self.get_plan(nodes=nodes)\n\n        try:\n            with transaction.atomic():\n                self.load_plan(plan=plan, progress_callback=progress_callback)\n                if dry_run:\n                    raise DryRun\n        except DryRun:\n            # Dry-run to get the atomic transaction rolled back\n            pass\n\n        return len(plan)", "response": "Load all fixtures for given nodes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving a plan from the graph.", "response": "def get_plan(self, nodes=None):\n        \"\"\"\n        Retrieve a plan, e.g. a list of fixtures to be loaded sorted on\n        dependency.\n\n        :param list nodes: list of nodes to be loaded.\n        :return:\n        \"\"\"\n        if nodes:\n            plan = self.graph.resolve_nodes(nodes)\n        else:\n            plan = self.graph.resolve_node()\n\n        return plan"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the reads and subject for the base sequence.", "response": "def basePlotter(blastHits, title):\n    \"\"\"\n    Plot the reads and the subject, so that bases in the reads which are\n    different from the subject are shown. Else a '.' is shown.\n    like so:\n    subject_gi  ATGCGTACGTACGACACC\n    read_1         A......TTC..T\n\n    @param blastHits: A L{dark.blast.BlastHits} instance.\n    @param title: A C{str} sequence title that was matched by BLAST. We plot\n        the reads that matched this title.\n    \"\"\"\n    result = []\n    params = blastHits.plotParams\n    assert params is not None, ('Oops, it looks like you forgot to run '\n                                'computePlotInfo.')\n\n    sequence = ncbidb.getSequence(title, blastHits.records.blastDb)\n    subject = sequence.seq\n    gi = title.split('|')[1]\n    sub = '%s\\t \\t \\t%s' % (gi, subject)\n    result.append(sub)\n\n    plotInfo = blastHits.titles[title]['plotInfo']\n    assert plotInfo is not None, ('Oops, it looks like you forgot to run '\n                                  'computePlotInfo.')\n\n    items = plotInfo['items']\n    count = 0\n    for item in items:\n        count += 1\n        hsp = item['hsp']\n        queryTitle = blastHits.fasta[item['readNum']].id\n        # If the product of the subject and query frame values is +ve,\n        # then they're either both +ve or both -ve, so we just use the\n        # query as is. Otherwise, we need to reverse complement it.\n        if item['frame']['subject'] * item['frame']['query'] > 0:\n            query = blastHits.fasta[item['readNum']].seq\n            reverse = False\n        else:\n            # One of the subject or query has negative sense.\n            query = blastHits.fasta[\n                item['readNum']].reverse_complement().seq\n            reverse = True\n        query = query.upper()\n        queryStart = hsp['queryStart']\n        subjectStart = hsp['subjectStart']\n        queryEnd = hsp['queryEnd']\n        subjectEnd = hsp['subjectEnd']\n\n        # Before comparing the read to the subject, make a string of the\n        # same length as the subject, which contains the read and\n        # has ' ' where the read does not match.\n        # 3 parts need to be taken into account:\n        # 1) the left offset (if the query doesn't stick out to the left)\n        # 2) the query. if the frame is -1, it has to be reversed.\n        # The query consists of 3 parts: left, middle (control for gaps)\n        # 3) the right offset\n\n        # Do part 1) and 2).\n        if queryStart < 0:\n            # The query is sticking out to the left.\n            leftQuery = ''\n            if subjectStart == 0:\n                # The match starts at the first base of the subject.\n                middleLeftQuery = ''\n            else:\n                # The match starts into the subject.\n                # Determine the length of the not matching query\n                # part to the left.\n                leftOffset = -1 * queryStart\n                rightOffset = subjectStart + leftOffset\n                middleLeftQuery = query[leftOffset:rightOffset]\n        else:\n            # The query is not sticking out to the left\n            # make the left offset.\n            leftQuery = queryStart * ' '\n\n            leftQueryOffset = subjectStart - queryStart\n            middleLeftQuery = query[:leftQueryOffset]\n\n        # Do part 3).\n        # Disregard gaps in subject while adding.\n        matchQuery = item['origHsp'].query\n        matchSubject = item['origHsp'].sbjct\n        index = 0\n        mid = ''\n        for item in range(len(matchQuery)):\n            if matchSubject[index] != ' ':\n                mid += matchQuery[index]\n            index += 1\n        # if the query has been reversed, turn the matched part around\n        if reverse:\n            rev = ''\n            toReverse = mid\n            reverseDict = {' ': ' ', '-': '-', 'A': 'T', 'T': 'A',\n                           'C': 'G', 'G': 'C', '.': '.', 'N': 'N'}\n            for item in toReverse:\n                newItem = reverseDict[item]\n                rev += newItem\n            mid = rev[::-1]\n\n        middleQuery = middleLeftQuery + mid\n\n        # add right not-matching part of the query\n        rightQueryOffset = queryEnd - subjectEnd\n        rightQuery = query[-rightQueryOffset:]\n        middleQuery += rightQuery\n\n        read = leftQuery + middleQuery\n\n        # do part 3)\n        offset = len(subject) - len(read)\n        # if the read is sticking out to the right\n        # chop it off\n        if offset < 0:\n            read = read[:offset]\n        # if it's not sticking out, fill the space with ' '\n        elif offset > 0:\n            read += offset * ' '\n\n        # compare the subject and the read, make a string\n        # called 'comparison', which contains a '.' if the bases\n        # are equal and the letter of the read if they are not.\n        comparison = ''\n        for readBase, subjectBase in zip(read, subject):\n            if readBase == ' ':\n                comparison += ' '\n            elif readBase == subjectBase:\n                comparison += '.'\n            elif readBase != subjectBase:\n                comparison += readBase\n            index += 1\n        que = '%s \\t %s' % (queryTitle, comparison)\n        result.append(que)\n\n        # sanity checks\n        assert (len(comparison) == len(subject)), (\n            '%d != %d' % (len(comparison), len(subject)))\n\n        index = 0\n        if comparison[index] == ' ':\n            index += 1\n        else:\n            start = index - 1\n            assert (start == queryStart or start == -1), (\n                '%s != %s or %s != -1' % (start, queryStart, start))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getAPOBECFrequencies(dotAlignment, orig, new, pattern):\n    cPattern = ['ACA', 'ACC', 'ACG', 'ACT', 'CCA', 'CCC', 'CCG', 'CCT',\n                'GCA', 'GCC', 'GCG', 'GCT', 'TCA', 'TCC', 'TCG', 'TCT']\n    tPattern = ['ATA', 'ATC', 'ATG', 'ATT', 'CTA', 'CTC', 'CTG', 'CTT',\n                'GTA', 'GTC', 'GTG', 'GTT', 'TTA', 'TTC', 'TTG', 'TTT']\n    # choose the right pattern\n    if pattern == 'cPattern':\n        patterns = cPattern\n        middleBase = 'C'\n    else:\n        patterns = tPattern\n        middleBase = 'T'\n    # generate the freqs dict with the right pattern\n    freqs = defaultdict(int)\n    for pattern in patterns:\n        freqs[pattern] = 0\n    # get the subject sequence from dotAlignment\n    subject = dotAlignment[0].split('\\t')[3]\n    # exclude the subject from the dotAlignment, so just the queries\n    # are left over\n    queries = dotAlignment[1:]\n    for item in queries:\n        query = item.split('\\t')[1]\n        index = 0\n        for queryBase in query:\n            qBase = query[index]\n            sBase = subject[index]\n            if qBase == new and sBase == orig:\n                try:\n                    plusSb = subject[index + 1]\n                    minusSb = subject[index - 1]\n                except IndexError:\n                    plusSb = 'end'\n                motif = '%s%s%s' % (minusSb, middleBase, plusSb)\n                if motif in freqs:\n                    freqs[motif] += 1\n            index += 1\n\n    return freqs", "response": "Returns the A - OBEC frequencies for the given dotAlignment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getCompleteFreqs(blastHits):\n    allFreqs = {}\n    for title in blastHits.titles:\n        allFreqs[title] = {\n            'C>A': {},\n            'C>G': {},\n            'C>T': {},\n            'T>A': {},\n            'T>C': {},\n            'T>G': {},\n        }\n        basesPlotted = basePlotter(blastHits, title)\n        for mutation in allFreqs[title]:\n            orig = mutation[0]\n            new = mutation[2]\n            if orig == 'C':\n                pattern = 'cPattern'\n            else:\n                pattern = 'tPattern'\n            freqs = getAPOBECFrequencies(basesPlotted, orig, new, pattern)\n            allFreqs[title][mutation] = freqs\n        numberOfReads = len(blastHits.titles[title]['plotInfo']['items'])\n        allFreqs[title]['numberOfReads'] = numberOfReads\n        allFreqs[title]['bitScoreMax'] = blastHits.titles[\n            title]['plotInfo']['bitScoreMax']\n    return allFreqs", "response": "Returns a dictionary which collects all mutation frequencies from all reads in the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef makeFrequencyGraph(allFreqs, title, substitution, pattern,\n                       color='blue', createFigure=True, showFigure=True,\n                       readsAx=False):\n    \"\"\"\n    For a title, make a graph showing the frequencies.\n\n    @param allFreqs: result from getCompleteFreqs\n    @param title: A C{str}, title of virus of which frequencies should be\n        plotted.\n    @param substitution: A C{str}, which substitution should be plotted;\n        must be one of 'C>A', 'C>G', 'C>T', 'T>A', 'T>C', 'T>G'.\n    @param pattern: A C{str}, which pattern we're looking for ( must be\n        one of 'cPattern', 'tPattern')\n    @param color: A C{str}, color of bars.\n    @param createFigure: If C{True}, create a figure.\n    @param showFigure: If C{True}, show the created figure.\n    @param readsAx: If not None, use this as the subplot for displaying reads.\n    \"\"\"\n    cPattern = ['ACA', 'ACC', 'ACG', 'ACT', 'CCA', 'CCC', 'CCG', 'CCT',\n                'GCA', 'GCC', 'GCG', 'GCT', 'TCA', 'TCC', 'TCG', 'TCT']\n    tPattern = ['ATA', 'ATC', 'ATG', 'ATT', 'CTA', 'CTC', 'CTG', 'CTT',\n                'GTA', 'GTC', 'GTG', 'GTT', 'TTA', 'TTC', 'TTG', 'TTT']\n\n    # choose the right pattern\n    if pattern == 'cPattern':\n        patterns = cPattern\n    else:\n        patterns = tPattern\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = readsAx or fig.add_subplot(111)\n    # how many bars\n    N = 16\n    ind = np.arange(N)\n    width = 0.4\n    # make a list in the right order, so that it can be plotted easily\n    divisor = allFreqs[title]['numberOfReads']\n    toPlot = allFreqs[title][substitution]\n    index = 0\n    data = []\n    for item in patterns:\n        newData = toPlot[patterns[index]] / divisor\n        data.append(newData)\n        index += 1\n    # create the bars\n    ax.bar(ind, data, width, color=color)\n    maxY = np.max(data) + 5\n    # axes and labels\n    if createFigure:\n        title = title.split('|')[4][:50]\n        ax.set_title('%s \\n %s' % (title, substitution), fontsize=20)\n        ax.set_ylim(0, maxY)\n        ax.set_ylabel('Absolute Number of Mutations', fontsize=16)\n        ax.set_xticks(ind + width)\n        ax.set_xticklabels(patterns, rotation=45, fontsize=8)\n    if createFigure is False:\n        ax.set_xticks(ind + width)\n        ax.set_xticklabels(patterns, rotation=45, fontsize=0)\n    else:\n        if showFigure:\n            plt.show()\n    return maxY", "response": "Make a graph showing the frequency of the current page."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef makeFrequencyPanel(allFreqs, patientName):\n    titles = sorted(\n        iter(allFreqs.keys()),\n        key=lambda title: (allFreqs[title]['bitScoreMax'], title))\n\n    origMaxY = 0\n    cols = 6\n    rows = len(allFreqs)\n    figure, ax = plt.subplots(rows, cols, squeeze=False)\n    substitutions = ['C>A', 'C>G', 'C>T', 'T>A', 'T>C', 'T>G']\n    colors = ['blue', 'black', 'red', 'yellow', 'green', 'orange']\n\n    for i, title in enumerate(titles):\n        for index in range(6):\n            for subst in allFreqs[str(title)]:\n                substitution = substitutions[index]\n                print(i, index, title, 'substitution', substitutions[index])\n                if substitution[0] == 'C':\n                    pattern = 'cPattern'\n                else:\n                    pattern = 'tPattern'\n                maxY = makeFrequencyGraph(allFreqs, title, substitution,\n                                          pattern, color=colors[index],\n                                          createFigure=False, showFigure=False,\n                                          readsAx=ax[i][index])\n                if maxY > origMaxY:\n                    origMaxY = maxY\n\n            # add title for individual plot.\n            # if used for other viruses, this will have to be adapted.\n            if index == 0:\n                gi = title.split('|')[1]\n                titles = title.split(' ')\n                try:\n                    typeIndex = titles.index('type')\n                except ValueError:\n                    typeNumber = 'gi: %s' % gi\n                else:\n                    typeNumber = titles[typeIndex + 1]\n\n                ax[i][index].set_ylabel(('Type %s \\n maxBitScore: %s' % (\n                    typeNumber, allFreqs[title]['bitScoreMax'])), fontsize=10)\n            # add xAxis tick labels\n            if i == 0:\n                ax[i][index].set_title(substitution, fontsize=13)\n            if i == len(allFreqs) - 1 or i == (len(allFreqs) - 1) / 2:\n                if index < 3:\n                    pat = ['ACA', 'ACC', 'ACG', 'ACT', 'CCA', 'CCC', 'CCG',\n                           'CCT', 'GCA', 'GCC', 'GCG', 'GCT', 'TCA', 'TCC',\n                           'TCG', 'TCT']\n                else:\n                    pat = ['ATA', 'ATC', 'ATG', 'ATT', 'CTA', 'CTC', 'CTG',\n                           'CTT', 'GTA', 'GTC', 'GTG', 'GTT', 'TTA', 'TTC',\n                           'TTG', 'TTT']\n                ax[i][index].set_xticklabels(pat, rotation=45, fontsize=8)\n\n    # make Y-axis equal\n    for i, title in enumerate(allFreqs):\n        for index in range(6):\n            a = ax[i][index]\n            a.set_ylim([0, origMaxY])\n    # add title of whole panel\n    figure.suptitle('Mutation Signatures in %s' % patientName, fontsize=20)\n    figure.set_size_inches(5 * cols, 3 * rows, forward=True)\n    figure.show()\n\n    return allFreqs", "response": "This function creates a plot showing the frequency of a single patient."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmutating a string in n places with chars chosen from replacements.", "response": "def mutateString(original, n, replacements='acgt'):\n    \"\"\"\n    Mutate C{original} in C{n} places with chars chosen from C{replacements}.\n\n    @param original: The original C{str} to mutate.\n    @param n: The C{int} number of locations to mutate.\n    @param replacements: The C{str} of replacement letters.\n\n    @return: A new C{str} with C{n} places of C{original} mutated.\n    @raises ValueError: if C{n} is too high, or C{replacement} contains\n        duplicates, or if no replacement can be made at a certain locus\n        because C{replacements} is of length one, or if C{original} is of\n        zero length.\n    \"\"\"\n    if not original:\n        raise ValueError('Empty original string passed.')\n\n    if n > len(original):\n        raise ValueError('Cannot make %d mutations in a string of length %d' %\n                         (n, len(original)))\n\n    if len(replacements) != len(set(replacements)):\n        raise ValueError('Replacement string contains duplicates')\n\n    if len(replacements) == 1 and original.find(replacements) != -1:\n        raise ValueError('Impossible replacement')\n\n    result = list(original)\n    length = len(original)\n\n    for offset in range(length):\n        if uniform(0.0, 1.0) < float(n) / (length - offset):\n            # Mutate.\n            while True:\n                new = choice(replacements)\n                if new != result[offset]:\n                    result[offset] = new\n                    break\n            n -= 1\n            if n == 0:\n                break\n\n    return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef writeDetails(accept, readId, taxonomy, fp):\n    fp.write('%s %s\\n       %s\\n\\n' % (\n        'MATCH:' if accept else 'MISS: ', readId,\n        ' | '.join(taxonomy) if taxonomy else 'No taxonomy found.'))", "response": "Writes the read and taxonomy details to fp."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild FM - index and write to file", "response": "def build(self, docs=None, filename=None):\n        \"\"\"Build FM-index\n        Params:\n            <iterator> | <generator> docs\n            <str> filename\n        \"\"\"\n        if docs:\n            if hasattr(docs, 'items'):\n                for (idx, doc) in sorted(getattr(docs, 'items')(),\n                                         key=lambda x: x[0]):\n                    self.fm.push_back(doc)\n            else:\n                for doc in filter(bool, docs):\n                    self.fm.push_back(doc)\n        self.fm.build()\n        if filename:\n            self.fm.write(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging of filter search results <list >", "response": "def _merge_search_result(self, search_results, _or=False):\n        \"\"\"Merge of filter search results\n        Params:\n            <str> | <Sequential> query\n            <bool> _or\n        Return:\n            <list> computed_dids\n        \"\"\"\n        all_docids = reduce(add, [list(x.keys()) for x in search_results])\n        if _or:\n            return sorted(set(all_docids), key=all_docids.index)\n        return [docid for docid in set(all_docids) if all_docids.count(docid) > 1]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, query, _or=False, ignores=[]):\n        if isinstance(query, str):\n            dids = MapIntInt({})\n            self.fm.search(query, dids)\n            dids = dids.asdict()\n            result = []\n            for did in sorted(dids.keys()):\n                doc = self.fm.get_document(did)\n                if not any(ignore in doc for ignore in ignores):\n                    count = dids[did]\n                    result.append(SEARCH_RESULT(int(did), [count], doc))\n            return result\n\n        search_results = []\n        for q in query:\n            dids = MapIntInt({})\n            self.fm.search(q, dids)\n            search_results.append(dids.asdict())\n        merged_dids = self._merge_search_result(search_results, _or)\n        result = []\n        for did in merged_dids:\n            doc = self.fm.get_document(did)\n            if not any(ignore in doc for ignore in ignores):\n                counts = map(lambda x: int(x.pop(did, 0)), search_results)\n                result.append(SEARCH_RESULT(int(did), list(counts), doc))\n        return result", "response": "Search word from FM - index"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count(self, query, _or=False):\n        if isinstance(query, str):\n            return self.fm.count(query, MapIntInt({}))\n        else:\n            search_results = []\n            for q in query:\n                dids = MapIntInt({})\n                self.fm.search(q, dids)\n                search_results.append(dids.asdict())\n            merged_dids = self._merge_search_result(search_results, _or)\n            counts = 0\n            for did in merged_dids:\n                if _or:\n                    counts += reduce(add, [int(x.pop(did, 0)) for x in search_results])\n                else:\n                    counts += min([int(x.pop(did, 0)) for x in search_results])\n            return counts", "response": "Count words from FM - index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, name, parents=None):\n        if not isinstance(name, Hashable):\n            raise TypeError(name)\n\n        parents = set(parents or ())\n        is_stub = False\n\n        if name in self._nodes:\n            if name in self._stubs:\n                node = Node(name, self._nodes[name].children, parents)\n                is_stub = True\n            else:\n                raise ValueError(name)\n        else:\n            node = Node(name, set(), parents)\n\n        # cycle detection\n        visited = set()\n\n        for parent in parents:\n            if self.ancestor_of(parent, name, visited=visited):\n                raise ValueError(parent)\n            elif parent == name:\n                raise ValueError(parent)\n\n        # Node safe to add\n        if is_stub:\n            self._stubs.remove(name)\n\n        if parents:\n            for parent_name in parents:\n                parent_node = self._nodes.get(parent_name)\n\n                if parent_node is not None:\n                    parent_node.children.add(name)\n                else:  # add stub\n                    self._nodes[parent_name] = Node(\n                        name=parent_name,\n                        children=set((name,)),\n                        parents=frozenset(),\n                    )\n                    self._stubs.add(parent_name)\n        else:\n            self._roots.add(name)\n\n        self._nodes[name] = node", "response": "Adds a node to the graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a node from the graph.", "response": "def remove(self, name, strategy=Strategy.promote):\n        \"\"\"\n        Remove a node from the graph. Returns the set of nodes that were\n        removed.\n\n        If the node doesn't exist, an exception will be raised.\n\n        name: The name of the node to remove.\n        strategy: (Optional, Strategy.promote) What to do with children\n            or removed nodes. The options are:\n\n            orphan: remove the node from the child's set of parents.\n            promote: replace the node with the the node's parents in the\n                childs set of parents.\n            remove: recursively remove all children of the node.\n        \"\"\"\n        removed = set()\n\n        stack = [name]\n\n        while stack:\n            current = stack.pop()\n            node = self._nodes.pop(current)\n\n            if strategy == Strategy.remove:\n                for child_name in node.children:\n                    child_node = self._nodes[child_name]\n\n                    child_node.parents.remove(current)\n\n                    stack.append(child_name)\n            else:\n                for child_name in node.children:\n                    child_node = self._nodes[child_name]\n\n                    child_node.parents.remove(current)\n\n                    if strategy == Strategy.promote:\n                        for parent_name in node.parents:\n                            parent_node = self._nodes[parent_name]\n\n                            parent_node.children.add(child_name)\n                            child_node.parents.add(parent_name)\n\n                    if not child_node.parents:\n                        self._roots.add(child_name)\n\n            if current in self._stubs:\n                self._stubs.remove(current)\n            elif current in self._roots:\n                self._roots.remove(current)\n            else:  # stubs and roots (by definition) don't have parents\n                for parent_name in node.parents:\n                    parent_node = self._nodes[parent_name]\n\n                    parent_node.children.remove(current)\n\n                    if parent_name in self._stubs and not parent_node.children:\n                        stack.append(parent_name)\n\n            removed.add(current)\n\n        return removed"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether a node has another node as an ancestor.", "response": "def ancestor_of(self, name, ancestor, visited=None):\n        \"\"\"\n        Check whether a node has another node as an ancestor.\n\n        name: The name of the node being checked.\n        ancestor: The name of the (possible) ancestor node.\n        visited: (optional, None) If given, a set of nodes that have\n            already been traversed. NOTE: The set will be updated with\n            any new nodes that are visited.\n\n        NOTE: If node doesn't exist, the method will return False.\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        node = self._nodes.get(name)\n\n        if node is None or name not in self._nodes:\n            return False\n\n        stack = list(node.parents)\n\n        while stack:\n            current = stack.pop()\n\n            if current == ancestor:\n                return True\n\n            if current not in visited:\n                visited.add(current)\n\n                node = self._nodes.get(current)\n                if node is not None:\n                    stack.extend(node.parents)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove any tasks that have stubs as ancestors and the stubs themselves. Returns the set of nodes which were removed.", "response": "def prune(self):\n        \"\"\"\n        Remove any tasks that have stubs as ancestors (and the stubs\n        themselves).\n\n        Returns the set of nodes which were removed.\n        \"\"\"\n        pruned = set()\n        stubs = frozenset(self._stubs)\n\n        for stub in stubs:\n            pruned.update(self.remove(stub, strategy=Strategy.remove))\n\n        return pruned - stubs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling render_to_response with a RequestConext", "response": "def respond(template, context={}, request=None, **kwargs):\n    \"Calls render_to_response with a RequestConext\"\n    from django.http import HttpResponse\n    from django.template import RequestContext\n    from django.template.loader import render_to_string    \n\n    if request:\n        default = context_processors.default(request)\n        default.update(context)\n    else:\n        default = context.copy()\n    \n    rendered = render_to_string(template, default, context_instance=request and RequestContext(request) or None)\n    return HttpResponse(rendered, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index(request):\n    \"Displays a list of all services and their current status.\"\n    \n    service_list = Service.objects.all()\n    \n    event_list = list(Event.objects\\\n                             .filter(Q(status__gt=0) | Q(date_updated__gte=datetime.datetime.now()-datetime.timedelta(days=1)))\\\n                             .order_by('-date_created')[0:6])\n    \n    if event_list:\n        latest_event, event_list = event_list[0], event_list[1:]\n    else:\n        latest_event = None\n    \n    return respond('overseer/index.html', {\n        'service_list': service_list,\n        'event_list': event_list,\n        'latest_event': latest_event,\n    }, request)", "response": "Displays a list of all services and their current status."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying a list of all services and their current status.", "response": "def service(request, slug):\n    \"Displays a list of all services and their current status.\"\n    \n    try:\n        service = Service.objects.get(slug=slug)\n    except Service.DoesNotExist:\n        return HttpResponseRedirect(reverse('overseer:index'))\n        \n    event_list = service.event_set.order_by('-date_created')\n    \n    return respond('overseer/service.html', {\n        'service': service,\n        'event_list': event_list,\n    }, request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying a list of all services and their current status.", "response": "def event(request, id):\n    \"Displays a list of all services and their current status.\"\n    \n    try:\n        evt = Event.objects.get(pk=id)\n    except Event.DoesNotExist:\n        return HttpResponseRedirect(reverse('overseer:index'))\n    \n    update_list = list(evt.eventupdate_set.order_by('-date_created'))\n    \n    return respond('overseer/event.html', {\n        'event': evt,\n        'update_list': update_list,\n    }, request)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef last_event(request, slug):\n    \"Displays a list of all services and their current status.\"\n    \n    try:\n        service = Service.objects.get(slug=slug)\n    except Service.DoesNotExist:\n        return HttpResponseRedirect(reverse('overseer:index'))\n    \n    try:\n        evt = service.event_set.order_by('-date_created')[0]\n    except IndexError:\n        return HttpResponseRedirect(service.get_absolute_url())\n    \n    return event(request, evt.pk)", "response": "Displays a list of all services and their current status."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_subscription(request, ident):\n    \"Shows subscriptions options for a verified subscriber.\"\n    \n    try:\n        subscription = Subscription.objects.get(ident=ident)\n    except Subscription.DoesNotExist:\n        return respond('overseer/invalid_subscription_token.html', {}, request)\n\n    if request.POST:\n        form = UpdateSubscriptionForm(request.POST, instance=subscription)\n        if form.is_valid():\n            if form.cleaned_data['unsubscribe']:\n                subscription.delete()\n        \n                return respond('overseer/unsubscribe_confirmed.html', {\n                    'email': subscription.email,\n                })\n            else:\n                form.save()\n\n            return HttpResponseRedirect(request.get_full_path())\n    else:\n        form = UpdateSubscriptionForm(instance=subscription)\n        \n    context = csrf(request)\n    context.update({\n        'form': form,\n        'subscription': subscription,\n        'service_list': Service.objects.all(),\n    })\n\n    return respond('overseer/update_subscription.html', context, request)", "response": "Shows subscriptions options for a verified subscriber."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows subscriptions options for a new subscriber.", "response": "def create_subscription(request):\n    \"Shows subscriptions options for a new subscriber.\"\n    \n    if request.POST:\n        form = NewSubscriptionForm(request.POST)\n        if form.is_valid():\n            unverified = form.save()\n\n            body = \"\"\"Please confirm your email address to subscribe to status updates from %(name)s:\\n\\n%(link)s\"\"\" % dict(\n                name=conf.NAME,\n                link=urlparse.urljoin(conf.BASE_URL, reverse('overseer:verify_subscription', args=[unverified.ident]))\n            )\n\n            # Send verification email\n            from_mail = conf.FROM_EMAIL\n            if not from_mail:\n                from_mail = 'overseer@%s' % request.get_host().split(':', 1)[0]\n            \n            send_mail('Confirm Subscription', body, from_mail, [unverified.email],\n                      fail_silently=True)\n            \n            # Show success page\n            return respond('overseer/create_subscription_complete.html', {\n                'subscription': unverified,\n            }, request)\n    else:\n        form = NewSubscriptionForm()\n\n    context = csrf(request)\n    context.update({\n        'form': form,\n        'service_list': Service.objects.all(),\n    })\n\n    return respond('overseer/create_subscription.html', context, request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_subscription(request, ident):\n    \n    try:\n        unverified = UnverifiedSubscription.objects.get(ident=ident)\n    except UnverifiedSubscription.DoesNotExist:\n        return respond('overseer/invalid_subscription_token.html', {}, request)\n    \n    subscription = Subscription.objects.get_or_create(email=unverified.email, defaults={\n        'ident': unverified.ident,\n    })[0]\n\n    subscription.services = unverified.services.all()\n    \n    unverified.delete()\n    \n    return respond('overseer/subscription_confirmed.html', {\n        'subscription': subscription,\n    }, request)", "response": "Verifies an unverified subscription and creates or appends a new subscription."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a Client object.", "response": "def get_client(key, project):\n    \"\"\"Gets a `Client` object (required by the other functions).\n    \n    TODO: docstring\"\"\"\n    cred = get_storage_credentials(key)\n    return storage.Client(project=project, credentials=cred)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists files on a bucket.", "response": "def get_files(client, bucket, prefix=''):\n    \"\"\"Lists files/objects on a bucket.\n    \n    TODO: docstring\"\"\"\n    bucket = client.get_bucket(bucket)\n    files = list(bucket.list_blobs(prefix=prefix))    \n    return files"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads a file from a bucket.", "response": "def download_file(client, bucket, remote_path, local_path, overwrite=False):\n    \"\"\"Downloads a file from a bucket.\n    \n    TODO: docstring\"\"\"\n    bucket = client.get_bucket(bucket)\n    if (not overwrite) and os.path.isfile(local_path):\n        raise OSError('File already exists!')\n    with open(local_path, 'wb') as ofh:\n        bucket.get_blob(remote_path).download_to_file(ofh)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a file from a bucket.", "response": "def delete_file(client, bucket, remote_path):\n    \"\"\"Deletes a file from a bucket.\n    \n    TODO: docstring\"\"\"\n    bucket = client.get_bucket(bucket)\n    bucket.delete_blob(remote_path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_file(client, bucket, local_path, remote_path, overwrite=False):\n    bucket = client.get_bucket(bucket)\n    blob = storage.Blob(remote_path, bucket)\n    if (not overwrite) and blob.exists():\n        raise Conflict('File/object already exists on the bucket!')\n    blob.upload_from_filename(local_path)", "response": "Uploads a file to a bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter(self, readAlignments):\n\n        # Implementation notes:\n        #\n        # 1. The order in which we carry out the filtering actions can make\n        #    a big difference in the result of this function. The current\n        #    ordering is based on what seems reasonable - it may not be the\n        #    best way to do things. E.g., if maxHspsPerHit is 1 and there\n        #    is a title regex, which should we perform first?\n        #\n        #    We perform filtering based on alignment before that based on\n        #    HSPs. That's because there's no point filtering all HSPs for\n        #    an alignment that we end up throwing away anyhow.\n        #\n        # 2. This function could be made faster if it first looked at its\n        #    arguments and dynamically created an acceptance function\n        #    (taking a readAlignments as an argument). The acceptance\n        #    function would run without examining the desired filtering\n        #    settings on each call the way the current code does.\n        #\n        # 3. A better approach with readIdRegex would be to allow the\n        #    passing of a regex object. Then the caller would make the\n        #    regex with whatever flags they liked (e.g., case insensitive).\n\n        #\n        # Alignment-only (i.e., non-HSP based) filtering.\n        #\n        if self.limit is not None and self.count == self.limit:\n            return False\n\n        # Does the read have too many alignments?\n        if (self.maxAlignmentsPerRead is not None and\n                len(readAlignments) > self.maxAlignmentsPerRead):\n            return False\n\n        # Filter on the read id.\n        if (self.readIdRegex and\n                self.readIdRegex.search(readAlignments.read.id) is None):\n            return False\n\n        if self.titleFilter:\n            # Remove alignments against sequences whose titles are\n            # unacceptable.\n            wantedAlignments = []\n            for alignment in readAlignments:\n                if (self.titleFilter.accept(alignment.subjectTitle) !=\n                        TitleFilter.REJECT):\n                    wantedAlignments.append(alignment)\n            if wantedAlignments:\n                readAlignments[:] = wantedAlignments\n            else:\n                return False\n\n        # Only return alignments that are against sequences of the\n        # desired length.\n        minSequenceLen = self.minSequenceLen\n        maxSequenceLen = self.maxSequenceLen\n        if minSequenceLen is not None or maxSequenceLen is not None:\n            wantedAlignments = []\n            for alignment in readAlignments:\n                length = alignment.subjectLength\n                if not ((minSequenceLen is not None and\n                         length < minSequenceLen) or\n                        (maxSequenceLen is not None and\n                         length > self.maxSequenceLen)):\n                    wantedAlignments.append(alignment)\n            if wantedAlignments:\n                readAlignments[:] = wantedAlignments\n            else:\n                return False\n\n        if self.taxonomy is not None:\n            wantedAlignments = []\n            for alignment in readAlignments:\n                lineage = self.lineageFetcher.lineage(alignment.subjectTitle)\n                if lineage:\n                    for taxonomyIdAndScientificName in lineage:\n                        if self.taxonomy in taxonomyIdAndScientificName:\n                            wantedAlignments.append(alignment)\n                else:\n                    # No lineage info was found. Keep the alignment\n                    # since we can't rule it out.  We could add another\n                    # option to control this.\n                    wantedAlignments.append(alignment)\n            if wantedAlignments:\n                readAlignments[:] = wantedAlignments\n            else:\n                return False\n\n        if self.oneAlignmentPerRead and readAlignments:\n            readAlignments[:] = [bestAlignment(readAlignments)]\n\n        #\n        # From here on we do only HSP-based filtering.\n        #\n\n        # Throw out any unwanted HSPs due to maxHspsPerHit.\n        if self.maxHspsPerHit is not None:\n            for alignment in readAlignments:\n                hsps = alignment.hsps\n                if len(hsps) > self.maxHspsPerHit:\n                    alignment.hsps = hsps[:self.maxHspsPerHit]\n\n        # Throw out HSPs whose scores are not good enough.\n        if self.scoreCutoff is not None:\n            wantedAlignments = []\n            for alignment in readAlignments:\n                hsps = alignment.hsps\n                wantedHsps = []\n                for hsp in hsps:\n                    if hsp.betterThan(self.scoreCutoff):\n                        wantedHsps.append(hsp)\n                if wantedHsps:\n                    alignment.hsps = wantedHsps\n                    wantedAlignments.append(alignment)\n            if wantedAlignments:\n                readAlignments[:] = wantedAlignments\n            else:\n                return False\n\n        # Throw out HSPs that don't match in the desired place on the\n        # matched sequence.\n        minStart = self.minStart\n        maxStop = self.maxStop\n        if minStart is not None or maxStop is not None:\n            wantedAlignments = []\n            for alignment in readAlignments:\n                hsps = alignment.hsps\n                wantedHsps = []\n                for hsp in hsps:\n                    if not ((minStart is not None and\n                             hsp.readStartInSubject < minStart) or\n                            (maxStop is not None and\n                             hsp.readEndInSubject > maxStop)):\n                        wantedHsps.append(hsp)\n                if wantedHsps:\n                    alignment.hsps = wantedHsps\n                    wantedAlignments.append(alignment)\n            if wantedAlignments:\n                readAlignments[:] = wantedAlignments\n            else:\n                return False\n\n        self.count += 1\n        return readAlignments", "response": "Filter a read s alignments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterable that yields all HSPs for all alignments of all reads.", "response": "def hsps(self):\n        \"\"\"\n        Provide access to all HSPs for all alignments of all reads.\n\n        @return: A generator that yields HSPs (or LSPs).\n        \"\"\"\n        for readAlignments in self:\n            for alignment in readAlignments:\n                for hsp in alignment.hsps:\n                    yield hsp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter(self, **kwargs):\n        self._filters.append(ReadsAlignmentsFilter(**kwargs).filter)\n        return self", "response": "Add a filter to this C { readsAlignments } object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the FTP URLs and checksums for the given species and release.", "response": "def get_annotation_urls_and_checksums(species, release=None, ftp=None):\n    \"\"\"Get FTP URLs and checksums for Ensembl genome annotations.\n    \n    Parameters\n    ----------\n    species : str or list of str\n        The species or list of species for which to get genome annotations\n        (e.g., \"Homo_sapiens\").\n    release : int, optional\n        The release number to look up. If `None`, use latest release. [None]\n    ftp : ftplib.FTP, optional\n        The FTP connection to use. If `None`, the function will open and close\n        its own connection using user \"anonymous\".\n    \"\"\"\n    ### type checks\n    assert isinstance(species, (str, _oldstr)) or isinstance(species, Iterable)\n    if release is not None:\n        assert isinstance(release, int)\n    if ftp is not None:\n        assert isinstance(ftp, ftplib.FTP)\n\n    ### open FTP connection if necessary\n    close_connection = False\n    ftp_server = 'ftp.ensembl.org'\n    ftp_user = 'anonymous'\n    if ftp is None:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(ftp_user)\n        close_connection = True    \n\n    ### determine release if necessary\n    if release is None:\n        # use latest release\n        release = util.get_latest_release(ftp=ftp)\n\n    species_data = OrderedDict()\n    if isinstance(species, (str, _oldstr)):\n        species_list = [species]\n    else:\n        species_list = species\n    for spec in species_list:\n\n        # get the GTF file URL\n        # => since the naming scheme isn't consistent across species,\n        #    we're using a flexible scheme here to find the right file\n        species_dir = '/pub/release-%d/gtf/%s' % (release, spec.lower())\n        data = []\n        ftp.dir(species_dir, data.append)\n        gtf_file = []\n        for d in data:\n            i = d.rindex(' ')\n            fn = d[(i + 1):]\n            if fn.endswith('.%d.gtf.gz' % release):\n                gtf_file.append(fn)\n        assert len(gtf_file) == 1\n        gtf_file = gtf_file[0]\n        _LOGGER.debug('GTF file: %s', gtf_file)\n\n        ### get the checksum for the GTF file\n        checksum_url = '/'.join([species_dir, 'CHECKSUMS'])\n        file_checksums = util.get_file_checksums(checksum_url, ftp=ftp)\n        gtf_checksum = file_checksums[gtf_file]\n        _LOGGER.debug('GTF file checksum: %d', gtf_checksum)\n\n        gtf_url = 'ftp://%s%s/%s' %(ftp_server, species_dir, gtf_file)\n\n        species_data[spec] = (gtf_url, gtf_checksum)\n\n    # close FTP connection, if we opened it\n    if close_connection:\n        ftp.close()\n\n    return species_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all genes of a specific a biotype from an Ensembl GTF file.", "response": "def get_genes(\n        path_or_buffer, valid_biotypes,\n        chunksize=10000,\n        chromosome_pattern=None,\n        #chromosome_pattern=r'(?:\\d\\d?|MT|X|Y)$',\n        only_manual=False,\n        remove_duplicates=True,\n        sort_by='name'):\n    \"\"\"Get all genes of a specific a biotype from an Ensembl GTF file.\n    \n    Parameters\n    ----------\n    path_or_buffer : str or buffer\n        The GTF file (either the file path or a buffer).\n    valid_biotypes : set of str\n        The set of biotypes to include (e.g., \"protein_coding\").\n    chromosome_pattern : str, optional\n        Regular expression specifying valid chromosomes. [None]\n    only_manual : bool, optional\n        Whether to exclude annotations with source \"ensembl\", which\n        are based only on an automatic annotation pipeline. [True]\n    remove_duplicates : bool, optional\n        Whether to remove duplicate annotations, i.e. those with different\n        Ensembl IDs for the same gene (only applies to protein-coding genes).\n        [True]\n    sort_by : str, optional\n        How to sort the genes. One of:\n          - 'name': Genes are ordered alphabetically by their name\n          - 'position': Genes are sorted by their position in the genome.abs\n                        Genes are first sorted by chromosome, then by their\n                        starting base pair position on the chromosome.\n          - 'position_fancy': Like 'position', but attempts to sort the\n                              chromosomes in a more logical order than strictly\n                              alphabetically. This currently works for human\n                              and mouse genomes.\n          - 'none': The order from the GTF file is retained. \n        Default: 'name'  \n\n    Returns\n    -------\n    `pandas.DataFrame`\n        Table with rows corresponding to the genes found.\n\n    Notes\n    -----\n    \n    Annotation sources and redundant gene annotations\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    \n    According to the Ensembl website (1), the Ensembl gene annotation\n    GTF files for human, mouse, zebrafish, rat and pig essentially\n    contain two sets of annotations:\n    \n    One set consists of all annotations with the \"ensembl\"\n    source annotation (column 2). These annotations are the product of\n    the automated Ensembl \"genebuild\" pipeline.\n    \n    The other set consists of genes that are manually annotated by\n    the HAVANA team (source \"havana\"), some of which have been merged with the\n    automatic annotations (source \"ensembl_havana\").\n    \n    There seems to be no overlap between genes annotated with \"havana\" and\n    \"ensembl_havana\" sources, respectively. However, there are a few genes for\n    which only annotations with source \"ensembl\" exist.\n    \n    Our policy is therefore to prefer annotations with source \"ensembl_havana\"\n    and \"havana\" over those with source \"ensembl\", and to only keep annotations\n    with source \"ensembl\" if there are no manually curated alternative\n    annotations.\n    \n    A special case is represented by mitochondrial genes, which always have the\n    source \"insdc\".\n    \n    (1) see http://www.ensembl.org/Help/Faq?id=152\n\n\n    Removal of duplicates\n    ~~~~~~~~~~~~~~~~~~~~~\n    \n    Unfortunately, the Ensembl gene annotations contain duplicates for a\n    handful of genes. For example, for MATR3, there are ENSG00000015479 and\n    ENSG00000280987, both of type\n    \"ensembl_havana\". There seems to be no clear criterion by which we could\n    rationally and automatically choose one ID over the other, at least based\n    on information contained\n    in the GTF file.\n    \n    We therefore remove duplicates according to following policy:\n    - For genes on '+' strand, keep the gene with the left-most starting\n      position.\n    - For genes on '-' strand, keep the gene with the right-most starting\n      position.\n    (In case the starting positions are equal, we keep the one that occurs\n    first in the GTF file.)\n    \n    We would like to use the pandas.DataFrame.drop_duplicates() function for\n    this. So we're temporarily reordering genes using their signed position,\n    and then we're using the original index (position) to restore the original\n    order.\n    \"\"\"\n    chrompat = None\n    if chromosome_pattern is not None:\n        chrompat = re.compile(chromosome_pattern)\n\n    # make sure this is a set\n    valid_biotypes = set(valid_biotypes)\n    \n    c = 0\n    num_lines = 0\n    num_chunks = 0\n    \n    t0 = time.time()\n    reader = pd.read_csv(path_or_buffer, encoding='ascii', sep='\\t',\n                         header=None, comment='#', dtype={0: str},\n                         chunksize=chunksize)\n            \n    # \"insdc\" is required to catch the mitochondrial protein-coding genes\n    valid_sources = set(['ensembl_havana', 'havana', 'insdc'])\n    \n    if not only_manual:\n        # we also accept annotations with source \"ensembl\", which are the\n        # product of an automated annotation pipeline\n        valid_sources.add('ensembl')\n        \n    excluded_chromosomes = set()\n\n    # parse GTF file and keep specific information\n    data = []\n    for j, df in enumerate(reader):\n        num_chunks += 1\n        num_lines += (df.shape[0])\n        \n        # select rows of type \"gene\"\n        sel = (df.iloc[:, 2] == 'gene')\n        \n        for i, row in df.loc[sel].iterrows():\n            \n            # parse attribute in 9th column\n            attr = gtf.parse_attributes(row[8].lstrip(' '))\n\n            # check if biotype is valid\n            biotype = attr['gene_biotype']\n            if biotype not in valid_biotypes:\n                continue\n\n            chrom = str(row[0])\n            source = row[1]\n            if chrompat is not None:\n                match = chrompat.match(chrom)\n                if match is None:\n                    excluded_chromosomes.add(chrom)\n                    continue\n\n            c += 1\n\n            # extract gene ID and gene name\n            ensembl_id = attr['gene_id']\n            try:\n                gene_name = attr['gene_name']\n            except KeyError:\n                # no gene name, so we'll use the ID as the name\n                gene_name = ensembl_id\n\n            # We define the position to be the index of the 5'-most base of the gene,\n            # according its orientation on the chromosome (DNA sequences are always represented 5'->3').\n            # We encode the strand as the sign of the index\n            # (\"+\" strand = positive sign, \"-\" strand = negative sign).\n            if row[6] == '+':\n                pos = int(row[3])-1\n            elif row[6] == '-':\n                pos = -(int(row[4])-1)\n            else:\n                raise ValueError('Invalid strand information: %s'\n                                 % str(row[6]))\n            length = abs(int(row[4]) - int(row[3])) + 1\n\n            #data.append([gene_name, ensembl_id, chrom, pos, length,\n            #             source, biotype])\n            data.append([ensembl_id, gene_name, chrom, pos, length,\n                         biotype, source])\n            \n    t1 = time.time()\n    \n    header = ['ensembl_id', 'name',\n              'chromosome', 'position', 'length',\n              'type', 'source']\n    df = pd.DataFrame(columns=header, data=data)\n    \n    if 'protein_coding' in valid_biotypes:\n        if only_manual:\n            # exclude protein-coding genes that are the based on\n            # automatic annotation (source \"ensembl\")\n            sel = (df['type'] == 'protein_coding' & df['source'] == 'ensembl')\n            df = df.loc[~sel]\n\n        else:\n            # make sure we only keep protein-coding genes with source \"ensembl\"\n            # if no manual annotations are available\n            sel_pc = df['type'] == 'protein_coding'\n\n            sel_ensembl = ((df['source'] == 'ensembl') & sel_pc)\n            sel_manual = ((df['source'] != 'ensembl') & sel_pc)\n            redundant_ensembl_genes = set(df.loc[sel_ensembl, 'name'].values) \\\n                    & set(df.loc[sel_manual, 'name'].values)\n            sel_redund = sel_ensembl & df['name'].isin(redundant_ensembl_genes)\n            num_genes_before = df.shape[0]\n            df = df.loc[~sel_redund]\n            num_genes_after = df.shape[0]\n            _LOGGER.info('Removed %d protein-coding genes with source '\n                        '\"ensembl\" that also had manual annotations.',\n                        num_genes_before - num_genes_after)\n        \n        if remove_duplicates:\n            # remove duplicate annotations (two or more Ensembl IDs for the\n            # same gene)\n            num_genes_before = df.shape[0]\n\n            sel_pc = df['type'] == 'protein_coding'\n            df_sel = df.loc[sel_pc].copy()\n\n            # sort by signed position value,\n            # in order to make sure we keep the most \"upstream\" annotation in\n            # the next step\n            df_sel.sort_values('position', kind='mergesort', inplace=True)\n\n            # remove duplicates by keeping the first occurrence\n            #df.drop_duplicates(['chromosome', 'name'], inplace=True)\n            df_sel.drop_duplicates('name', inplace=True)\n\n            # combine protein-coding genes and non-protein-coding genes again\n            df = pd.concat([df_sel, df.loc[~sel_pc]])\n\n            # restore original order using the numeric index\n            df.sort_index(inplace=True)\n\n            num_genes_after = df.shape[0]\n            _LOGGER.info('Removed %d duplicate protein-coding gene entries',\n                        num_genes_before - num_genes_after)\n        else:\n            # print names of genes with duplicate IDs\n            sel = df['type'] == 'protein_coding'\n\n            counts = df.loc[sel]['name'].value_counts()\n            sel = counts > 1\n            if sel.sum() > 0:\n                _LOGGER.info('Protein-coding genes with multiple Ensembl IDs:'\n                             '%s', ', '.join(['%s (%d)' % (k, v)\n                                             for k, v in counts[sel].items()]))\n\n    if sort_by == 'name':\n        # sort alphabetically by gene name\n        df.sort_values(['name'], kind='mergesort', inplace=True)\n\n    elif sort_by in ['position', 'position_fancy']:\n        # sort first by chromsome, then by absolute position\n        df_sort = pd.concat([df['chromosome'], df['position'].abs()], axis=1)\n        df_sort = df_sort.sort_values(['chromosome', 'position'],\n                                      kind='mergesort')\n        df = df.loc[df_sort.index]\n\n        if sort_by == 'position_fancy':\n            # Perform \"fancy\" positional sorting. Numbered chromosomes\n            # are ordered numerically, and followed by the X, Y, and MT\n            # chromosomes.\n            def transform_chrom(chrom):\n                \"\"\"Helper function to obtain specific sort order.\"\"\"\n                try:\n                    c = int(chrom)\n                except:\n                    if chrom in ['X', 'Y']:\n                        return chrom\n                    elif chrom == 'MT':\n                        return '_MT'  # sort to the end\n                    else:\n                        return '__' + chrom  # sort to the very end\n                else:\n                    # make sure numbered chromosomes are sorted numerically\n                    return '%02d' % c\n\n            chrom_for_sorting = df['chromosome'].apply(transform_chrom)\n            a = chrom_for_sorting.argsort(kind='mergesort')\n            df = df.iloc[a]\n            _LOGGER.info('Performed fancy sorting of chromosomes.')\n            \n    # set index to ensembl ID\n    df.set_index('ensembl_id', inplace=True)\n    \n    _LOGGER.info('Read %d lines (in %d chunks).', num_lines, num_chunks)\n    _LOGGER.info('Found %d valid gene entries.', c)\n    _LOGGER.info('Final number of unique genes: %d', df.shape[0])\n    _LOGGER.info('Parsing time: %.1f s', t1-t0)\n    \n    # additional statistics\n    all_chromosomes = list(df['chromosome'].unique())\n    _LOGGER.info('Valid chromosomes (%d): %s',\n                len(all_chromosomes),\n                ', '.join(all_chromosomes))\n    _LOGGER.info('Excluded chromosomes (%d): %s',\n                len(excluded_chromosomes),\n                ', '.join(sorted(excluded_chromosomes)))\n    \n    _LOGGER.info('Sources:')\n    for i, c in df['source'].value_counts().iteritems():\n        _LOGGER.info('- %s: %d', i, c)\n        \n    _LOGGER.info('Gene types:')\n    for i, c in df['type'].value_counts().iteritems():\n        _LOGGER.info('- %s: %d', i, c)\n    \n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_linc_rna_genes(\n        path_or_buffer,\n        remove_duplicates=True,\n        **kwargs):\n    r\"\"\"Get list of all protein-coding genes based on Ensembl GTF file.\n    \n    Parameters\n    ----------\n    See :func:`get_genes` function.\n\n    Returns\n    -------\n    `pandas.DataFrame`\n        Table with rows corresponding to protein-coding genes.\n\n    \"\"\"\n    valid_biotypes = set(['lincRNA'])\n    \n    df = get_genes(path_or_buffer, valid_biotypes,\n                   remove_duplicates=remove_duplicates, **kwargs)\n    return df", "response": "r Get list of all protein - coding genes based on Ensembl GTF file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates random data in a form of nested lists", "response": "def payload_generator(levels=0, dimensions=None, sequential=True, string=True, max_int=255, max_pkt_len=150, max_dim_size=3):\n    \"\"\" Generates random data in a form of nested lists, to be used as a test packet payload\n            levels - nesting levels:\n                0 - list of integers (single packet payload)\n                1 - list of lists of integers (list of packets)\n                2 - list of lists of lists of integers (list of packets, each packet containing list of messages)\n                etc.\n            dimensions - specifies the size of the lists; the specification can be partial, as what is not specified will be chosen randomly\n                if level=0:\n                    dimensions=None - list of integers of random length in the range [1,max_pkt_len]\n                    dimensions=5 - list of integers of length 5\n                if level=1:\n                    dimensions=None - list of random length in the range [1, max_dim_size], each element is an integer list of random length in the range [1, max_pkt_len]\n                    dimensions=5 - list of length 5, each element is an integer list of random length in the range [1, max_pkt_len]\n                    dimensions=[2, 3] - list of 2 elements, each element is an integer list, the first one of length 2, the second on of length 3\n                if level=2:\n                    dimensions=None - list of random length in the range [1, max_dim_size], each element is a list of random length in the range [1, max_dim_size], \n                                      each element of the second level lists is an integer list of random length in the range [1, max_pkt_len]\n                    dimensions=5 - list of length 5, each element is a list of random length in the range [1, max_dim_size], each element of the second level lists \n                                   is an integer list of random length in the range [1, max_pkt_len]\n                    dimensions=[2, 3] - list of 2 elements, each element is a list, the first one of length 2, the second on of length 3, each element of the second \n                                        level lists is an integer list of random length in the range [1, max_pkt_len]\n                    dimensions=[[3, 5], [6, 7, 8]] - list of 2 elements, each element is a list, the first one of length 2, the second on of length 3, each element of the second \n                                        level lists is an integer list of length respectively 3, 5, 6, 7, 8\n                if level=3:\n                    etc.\n                It is possible to specify dimensions partially, e.g dimensions=[[3, None], [6, 7, 8]] or dimensions=[None, [6, 7, 8]]. Dimensions that are not specified are \n                chosen randomly\n            sequential - if True, the payload is a cyclic sequence if integers in the range [0, max_int]\n                         if False, the payload is a sequence of random integers in the range [0, max_int]\n            string - if True, the payload is a byte string, e.g. '\\x04\\x05\\x06\\x07' as each byte is in the range [0, min(255, max_int)]\n                     if False, the payload is a list of integers in the range [0, max_int]\n            max_int - Upper limit for the integer range for the payload\n            max_pkt_len - Upper limit for the randomly chosen payload length\n            max_dim_size - Upper limit for the randomly chosen dimension sizes\n    \"\"\"\n\n    MAX_INT = max_int\n    if string:\n        MAX_INT = min(255, max_int)\n\n    MAX_DIM_SIZE = max_dim_size\n    MAX_PKT_LEN = max_pkt_len\n\n    def next_i():\n        ''' Generates next number from a cyclic integer sequence [0..MAX_INT]'''\n        next_i.i = (next_i.i+1)%(MAX_INT+1)\n        return next_i.i\n    next_i.i = 0;\n\n    def payload(length):\n        ''' Generates payload of given length '''\n        if (sequential) :\n            pld = [next_i() for _ in xrange(length)]\n        else:\n            pld = [random.randint(0, MAX_INT) for _ in xrange(length)]\n        if string:\n            pld = str(bytearray(pld))\n        return pld\n\n    def next_level(level, pld):\n        ''' Generates the next level of nested lists '''\n        if level>0:\n            # Next level of nested lists\n            if pld==None:\n                pld = random.randint(1, MAX_DIM_SIZE)\n            if isinstance(pld, int):\n                pld = pld*[None]\n            if isinstance(pld, list):\n                for i in range(len(pld)):\n                    pld[i] = next_level(level-1, pld[i])\n                return pld\n            else:\n                raise TypeError(\"Expected None, int or list, got {}: {}\".format(type(pld), pld))\n        elif level==0:\n            # Generate payload\n            if pld==None:\n                pld = random.randint(1, MAX_PKT_LEN)\n            if isinstance(pld, int):\n                return payload(pld)\n            else:\n                raise TypeError(\"Expected None or int, got {}: {}\".format(type(pld), pld))\n        else:\n            raise ValueError(\"Expected int>=0, got {}\".format(level))\n\n    pld = copy.deepcopy(dimensions)\n\n    pld = next_level(levels, pld)\n\n    return pld"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting information about a sequence from Genbank.", "response": "def getSequence(title, db='nucleotide'):\n    \"\"\"\n    Get information about a sequence from Genbank.\n\n    @param title: A C{str} sequence title from a BLAST hit. Of the form\n        'gi|63148399|gb|DQ011818.1| Description...'.\n    @param db: The C{str} name of the Entrez database to consult.\n\n    NOTE: this uses the network!  Also, there is a 3 requests/second limit\n    imposed by NCBI on these requests so be careful or your IP will be banned.\n    \"\"\"\n    titleId = title.split(' ', 1)[0]\n    try:\n        gi = titleId.split('|')[1]\n    except IndexError:\n        # Assume we have a gi number directly, and make sure it's a string.\n        gi = str(titleId)\n\n    try:\n        client = Entrez.efetch(db=db, rettype='gb', retmode='text', id=gi)\n    except URLError:\n        return None\n    else:\n        record = SeqIO.read(client, 'gb')\n        client.close()\n        return record"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the lowest layer of broken or overcast clouds.", "response": "def get_ceiling_cloud_layer(self):\n        \"\"\"\n        Returns the lowest layer of broken or overcast clouds.\n        :rtype: CloudLayer|None\n        \"\"\"\n        lowest_layer = None\n        for layer in self.cloud_layers:\n            if layer.coverage not in [CloudLayer.BROKEN, CloudLayer.OVERCAST]:\n                continue\n            if lowest_layer is None:\n                lowest_layer = layer\n                continue\n            if layer.height > lowest_layer.height:\n                continue\n            if layer.height < lowest_layer.height or \\\n                    lowest_layer.get_coverage_percentage() < layer.get_coverage_percentage():\n                lowest_layer = layer\n        return lowest_layer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing xml_data and loads it into properties.", "response": "def parse_xml_data(self):\n        \"\"\"\n        Parses `xml_data` and loads it into object properties.\n        \"\"\"\n        self.raw_text = self.xml_data.find('raw_text').text\n        self.station = WeatherStation(self.xml_data.find('station_id').text)\n        self.station.latitude = float(self.xml_data.find('latitude').text)\n        self.station.longitude = float(self.xml_data.find('longitude').text)\n        self.station.elevation = float(self.xml_data.find('elevation_m').text) * 3.28084"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads the XML data into the xml_data attribute.", "response": "def download_data(self, mock_response=None):\n        \"\"\"\n        Loads XML data into the `xml_data` attribute.\n        \"\"\"\n        if mock_response is not None:\n            body = mock_response\n        else:\n            api_url = self.get_api_url()\n            body = urlopen(api_url).read()\n        xml_root = ElementTree.fromstring(body)\n        xml_warnings = xml_root.find('warnings')\n        if len(xml_warnings.attrib) != 0:\n            print(\"Data warnings found: %s\" % xml_warnings.attrib)\n        xml_errors = xml_root.find('errors')\n        if len(xml_errors.attrib) != 0:\n            raise Exception(\"Data errors found: %s\" % xml_errors.attrib)\n        self.xml_data = xml_root.find('data')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsummarizes reads in a sequence file", "response": "def summarizeReads(file_handle, file_type):\n    \"\"\"\n    open a fasta or fastq file, prints number of of reads,\n    average length of read, total number of bases, longest,\n    shortest and median read, total number and average of\n    individual base (A, T, G, C, N).\n    \"\"\"\n    base_counts = defaultdict(int)\n    read_number = 0\n    total_length = 0\n    length_list = []\n\n    records = SeqIO.parse(file_handle, file_type)\n\n    for record in records:\n        total_length += len(record)\n        read_number += 1\n        length_list.append(len(record))\n        for base in record:\n            base_counts[base] += 1\n\n    result = {\n        \"read_number\": read_number,\n        \"total_length\": total_length,\n        \"average_length\": total_length / read_number if read_number > 0 else 0,\n        \"max_length\": max(length_list) if length_list else 0,\n        \"min_length\": min(length_list) if length_list else 0,\n        \"median_length\": median(length_list) if length_list else 0,\n        \"base_counts\": base_counts\n    }\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sequenceCategoryLengths(read, categories, defaultCategory=None,\n                            suppressedCategory='...', minLength=1):\n    \"\"\"\n    Summarize the nucleotides or AAs found in a read by assigning each to a\n    category and reporting the lengths of the contiguous category classes\n    found along the sequence.\n\n    @param read: A C{Read} instance or one of its subclasses.\n    @param categories: A C{dict} mapping nucleotides or AAs to category.\n    @param defaultCategory: The category to use if a sequence base is not\n        in C{categories}.\n    @param suppressedCategory: The category to use to indicate suppressed\n        sequence regions (i.e., made up of stretches of bases that are less\n        than C{minLength} in length).\n    @param minLength: stretches of the read that are less than this C{int}\n        length will be summed and reported as being in the\n        C{suppressedCategory} category.\n    @raise ValueError: If minLength is less than one.\n    @return: A C{list} of 2-C{tuples}. Each tuple contains a (category, count).\n    \"\"\"\n    result = []\n    append = result.append\n    get = categories.get\n    first = True\n    currentCategory = None\n    currentCount = 0\n    suppressing = False\n    suppressedCount = 0\n\n    if minLength < 1:\n        raise ValueError('minLength must be at least 1')\n\n    for base in read.sequence:\n        thisCategory = get(base, defaultCategory)\n        if first:\n            first = False\n            currentCategory = thisCategory\n            currentCount += 1\n        else:\n            if thisCategory == currentCategory:\n                # This base is still in the same category as the last base.\n                # Keep counting.\n                currentCount += 1\n            else:\n                # This is a new category.\n                if currentCount < minLength:\n                    # The category region that was just seen will not be\n                    # emitted.\n                    if suppressing:\n                        # Already suppressing. Suppress the just-seen\n                        # region too.\n                        suppressedCount += currentCount\n                    else:\n                        # Start suppressing.\n                        suppressedCount = currentCount\n                        suppressing = True\n                else:\n                    if suppressing:\n                        append((suppressedCategory, suppressedCount))\n                        suppressedCount = 0\n                        suppressing = False\n                    append((currentCategory, currentCount))\n                currentCategory = thisCategory\n                currentCount = 1\n\n    if suppressing:\n        append((suppressedCategory, suppressedCount + currentCount))\n    elif currentCount >= minLength:\n        append((currentCategory, currentCount))\n    elif currentCount:\n        append((suppressedCategory, currentCount))\n\n    return result", "response": "Summarize the nucleotides or AAs found in a read by assigning each to the appropriate category and reporting the lengths of the contiguous category classes that are found along the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsimplifying a given sequence title.", "response": "def simplifyTitle(title, target):\n    \"\"\"\n    Simplify a given sequence title.  Given a title, look for the first\n    occurrence of target anywhere in any of its words. Return a space-separated\n    string of the words of the title up to and including the occurrence of the\n    target.  Ignore case.\n\n    E.g.,\n\n      # Suffix\n      simplifyTitle('Bovine polyomavirus DNA, complete genome', 'virus') ->\n        'Bovine polyomavirus'\n\n      # Prefix\n      simplifyTitle('California sea lion polyomavirus 1 CSL6994', 'polyoma') ->\n        'California sea lion polyoma'\n\n      # Contained\n      simplifyTitle('California sea lion polyomavirus 1 CSL6994', 'yoma') ->\n        'California sea lion polyoma'\n\n    title: The string title of the sequence.\n    target: The word in the title that we should stop at.\n\n    \"\"\"\n    targetLen = len(target)\n    result = []\n\n    for word in title.split():\n        if len(word) >= targetLen:\n            offset = word.lower().find(target.lower())\n            if offset > -1:\n                result.append(word[:offset + targetLen])\n                break\n        result.append(word)\n    return ' '.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef registerSimulator(self, name=None, hdl=None, analyze_cmd=None, elaborate_cmd=None, simulate_cmd=None):\n        ''' Registers an HDL _simulator\n                name - str, user defined name, used to identify this _simulator record\n                hdl - str, case insensitive, (verilog, vhdl), the HDL to which the simulated MyHDL code will be converted\n                analyze_cmd - str, system command that will be run to analyze the generated HDL\n                elaborate_cmd - str, optional, system command that will be run after the analyze phase\n                simulate_cmd - str, system command that will be run to simulate the analyzed and elaborated design\n                Before execution of a command string the following substitutions take place:\n                    {topname} is substituted with the name of the simulated MyHDL function\n        '''\n        if not isinstance(name, str) or (name.strip() == \"\"):\n            raise ValueError(\"Invalid _simulator name\")\n        if hdl.lower() not in (\"vhdl\", \"verilog\"):\n            raise ValueError(\"Invalid hdl {}\".format(hdl))\n        if not isinstance(analyze_cmd, str) or (analyze_cmd.strip() == \"\"):\n            raise ValueError(\"Invalid analyzer command\")\n        if elaborate_cmd is not None:\n            if not isinstance(elaborate_cmd, str) or (elaborate_cmd.strip() == \"\"):\n                raise ValueError(\"Invalid elaborate_cmd command\")\n        if not isinstance(simulate_cmd, str) or (simulate_cmd.strip() == \"\"):\n            raise ValueError(\"Invalid _simulator command\")\n\n        self.sim_reg[name] = (hdl.lower(), analyze_cmd, elaborate_cmd, simulate_cmd)", "response": "Registers a new _simulator in the _simulated_cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _getCosimulation(self, func, **kwargs):\n        ''' Returns a co-simulation instance of func. \n            Uses the _simulator specified by self._simulator. \n            Enables traces if self._trace is True\n                func - MyHDL function to be simulated\n                kwargs - dict of func interface assignments: for signals and parameters\n        '''\n        vals = {}\n        vals['topname'] = func.func_name\n        vals['unitname'] = func.func_name.lower()\n        hdlsim = self._simulator\n        if not hdlsim:\n            raise ValueError(\"No _simulator specified\")\n        if not self.sim_reg.has_key(hdlsim):\n            raise ValueError(\"Simulator {} is not registered\".format(hdlsim))\n\n        hdl, analyze_cmd, elaborate_cmd, simulate_cmd = self.sim_reg[hdlsim]\n\n        # Convert to HDL\n        if hdl == \"verilog\":\n            toVerilog(func, **kwargs)\n            if self._trace:\n                self._enableTracesVerilog(\"./tb_{topname}.v\".format(**vals))\n        elif hdl == \"vhdl\":\n            toVHDL(func, **kwargs)\n\n        # Analyze HDL\n        os.system(analyze_cmd.format(**vals))\n        # Elaborate\n        if elaborate_cmd:\n            os.system(elaborate_cmd.format(**vals))\n        # Simulate\n        return Cosimulation(simulate_cmd.format(**vals), **kwargs)", "response": "Returns a co - simulation instance of func. \n            Uses the _simulator specified by self. _simulator. \n            Enables traces for verilog and vHDL functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _enableTracesVerilog(self, verilogFile):\n        ''' Enables traces in a Verilog file'''\n        fname, _ = os.path.splitext(verilogFile)\n        inserted = False\n        for _, line in enumerate(fileinput.input(verilogFile, inplace = 1)):\n            sys.stdout.write(line)\n            if line.startswith(\"end\") and not inserted:\n                sys.stdout.write('\\n\\n') \n                sys.stdout.write('initial begin\\n')\n                sys.stdout.write('    $dumpfile(\"{}_cosim.vcd\");\\n'.format(fname)) \n                sys.stdout.write('    $dumpvars(0, dut);\\n') \n                sys.stdout.write('end\\n\\n') \n                inserted = True", "response": "Enable traces in a Verilog file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _getDut(self, func, **kwargs):\n        ''' Returns a simulation instance of func. \n            Uses the simulator specified by self._simulator. \n            Enables traces if self._trace is True\n                func - MyHDL function to be simulated\n                kwargs - dict of func interface assignments: for signals and parameters\n        '''\n        if self._simulator==\"myhdl\":\n            if not self._trace:\n                sim_dut = func(**kwargs)\n            else:\n                sim_dut = traceSignals(func, **kwargs)\n        else:\n            sim_dut = self._getCosimulation(func, **kwargs)\n\n        return sim_dut", "response": "Returns a simulation instance of func. \n            Uses the simulator specified by self. _simulator. \n            Enables traces for signals and parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter(self):\n        for _file in self._files:\n            with asHandle(_file) as fp:\n                # Use FastqGeneralIterator because it provides access to\n                # the unconverted quality string (i.e., it doesn't try to\n                # figure out the numeric quality values, which we don't\n                # care about at this point).\n                for sequenceId, sequence, quality in FastqGeneralIterator(fp):\n                    yield self.readClass(sequenceId, sequence, quality)", "response": "Iterate over the sequences in self. files_ yielding each read class as an instance of the desired read class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the FASTA file named params['fastaFile'] and print out its sequence count.", "response": "def splitFASTA(params):\n    \"\"\"\n    Read the FASTA file named params['fastaFile'] and print out its\n    sequences into files named 0.fasta, 1.fasta, etc. with\n    params['seqsPerJob'] sequences per file.\n    \"\"\"\n    assert params['fastaFile'][-1] == 'a', ('You must specify a file in '\n                                            'fasta-format that ends in '\n                                            '.fasta')\n\n    fileCount = count = seqCount = 0\n    outfp = None\n    with open(params['fastaFile']) as infp:\n        for seq in SeqIO.parse(infp, 'fasta'):\n            seqCount += 1\n            if count == params['seqsPerJob']:\n                outfp.close()\n                count = 0\n            if count == 0:\n                outfp = open('%d.fasta' % fileCount, 'w')\n                fileCount += 1\n            count += 1\n            outfp.write('>%s\\n%s\\n' % (seq.description, str(seq.seq)))\n    outfp.close()\n    return fileCount, seqCount"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a task to the scheduler.", "response": "def add_task(self, task):\n        \"\"\"\n        Add a task to the scheduler.\n\n        task: The task to add.\n        \"\"\"\n        if not self._valid_name(task.name):\n            raise ValueError(task.name)\n\n        self._tasks[task.name] = task\n\n        incomplete_dependencies = set()\n\n        for dependency in task.dependencies:\n            if not self._valid_name(dependency) or dependency in self._failed:\n                # there may already be tasks dependent on this one.\n                self._cascade_failure(task.name)\n\n                break\n\n            if dependency not in self._completed:\n                incomplete_dependencies.add(dependency)\n        else:  # task hasn't failed\n            try:\n                self._graph.add(task.name, incomplete_dependencies)\n            except ValueError:\n                self._cascade_failure(task.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting a task. Returns the task that was started (or None if no task has been started). name: (optional, None) The task to start. If a name is given, Scheduler will attempt to start the task (and raise an exception if the task doesn't exist or isn't runnable). If no name is given, a task will be chosen arbitrarily", "response": "def start_task(self, name=None):\n        \"\"\"\n        Start a task.\n\n        Returns the task that was started (or None if no task has been\n            started).\n\n        name: (optional, None) The task to start. If a name is given,\n            Scheduler will attempt to start the task (and raise an\n            exception if the task doesn't exist or isn't runnable). If\n            no name is given, a task will be chosen arbitrarily\n        \"\"\"\n        if name is None:\n            for possibility in self._graph.roots:\n                if possibility not in self._running:\n                    name = possibility\n                    break\n            else:  # all tasks blocked/running/completed/failed\n                return None\n        else:\n            if name not in self._graph.roots or name in self._running:\n                raise ValueError(name)\n\n        self._running.add(name)\n\n        return self._tasks[name]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nending a running task. Raises an exception if the task isn t running.", "response": "def end_task(self, name, success=True):\n        \"\"\"\n        End a running task. Raises an exception if the task isn't\n        running.\n\n        name: The name of the task to complete.\n        success: (optional, True) Whether the task was successful.\n        \"\"\"\n        self._running.remove(name)\n\n        if success:\n            self._completed.add(name)\n            self._graph.remove(name, strategy=Strategy.orphan)\n        else:\n            self._cascade_failure(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fail_remaining(self):\n        self._failed.update(self._graph.nodes)\n        self._graph = Graph()\n        self._running = set()", "response": "Mark all unfinished tasks as failed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmark a task as failed.", "response": "def _cascade_failure(self, name):\n        \"\"\"\n        Mark a task (and anything that depends on it) as failed.\n\n        name: The name of the offending task\n        \"\"\"\n        if name in self._graph:\n            self._failed.update(\n                self._graph.remove(name, strategy=Strategy.remove)\n            )\n        else:\n            self._failed.add(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(gi, ranges):\n    # TODO: Make it so we can pass a 'db' argument to getSequence.\n    record = getSequence(gi)\n\n    if record is None:\n        print(\"Looks like you're offline.\")\n        sys.exit(3)\n    else:\n        printed = set()\n        if ranges:\n            for (start, end) in ranges:\n                for index, feature in enumerate(record.features):\n                    if (start < int(feature.location.end) and\n                            end > int(feature.location.start) and\n                            index not in printed):\n                        print(feature)\n                        printed.add(index)\n        else:\n            # Print all features.\n            for feature in record.features:\n                print(feature)", "response": "Print the features of the genbank entry given by gi."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new instance of the specified type.", "response": "def create_instance(credentials, project, zone, name,\n                    startup_script=None, startup_script_url=None,\n                    metadata=None,\n                    machine_type='f1-micro', tags=None,\n                    disk_size_gb=10, wait_until_done=False):\n    \"\"\"Create instance with startup script.\n\n    TODO: docstring\"\"\"\n\n    if startup_script is not None and startup_script_url is not None:\n        raise ValueError('Cannot specify a startup script string and URL '\n                         'at the same time!')\n\n    access_token = credentials.get_access_token()\n\n    if metadata is None:\n        metadata = {}\n    meta_items = [{'key': k, 'value': v} for k, v in metadata.items()]\n\n    if tags is None:\n        tags = []\n\n    if startup_script is not None:\n        meta_items.insert(\n            0, {'key': 'startup-script', 'value': startup_script}\n        )\n    elif startup_script_url is not None:\n        meta_items.insert(\n            0, {'key': 'startup-script-url', 'value': startup_script_url})\n\n    payload = {\n        \"name\": name,\n        \"zone\": \"projects/%s/zones/%s\" % (project, zone),\n        \"machineType\": \"projects/%s/zones/%s/machineTypes/%s\"\n                       % (project, zone, machine_type),\n        \"metadata\": {\n            \"items\": meta_items\n        },\n        \"tags\": {\n            \"items\": tags\n        },\n        \"disks\": [\n            {\n                \"type\": \"PERSISTENT\",\n                \"boot\": True,\n                \"mode\": \"READ_WRITE\",\n                \"autoDelete\": True,\n                \"deviceName\": name,\n                \"initializeParams\": {\n                    \"sourceImage\": \"projects/ubuntu-os-cloud/global/images/ubuntu-1604-xenial-v20170815a\",\n                    \"diskType\": \"projects/%s/zones/%s/diskTypes/pd-standard\" % (project, zone),\n                    \"diskSizeGb\": str(disk_size_gb)\n                }\n            }\n        ],\n        \"canIpForward\": False,\n        \"networkInterfaces\": [\n            {\n                \"network\": \"projects/%s/global/networks/default\" % project,\n                \"subnetwork\": \"projects/%s/regions/%s/subnetworks/default\" % (project, zone[:-2]),\n                \"accessConfigs\": [\n                    {\n                        \"name\": \"External NAT\", \"type\": \"ONE_TO_ONE_NAT\"\n                    }\n                ]\n            }\n        ],\n        \"description\": \"\",\n        \"scheduling\": {\n            \"preemptible\": False,\n            \"onHostMaintenance\": \"MIGRATE\",\n            \"automaticRestart\": True\n        },\n        \"serviceAccounts\": [\n            {\n                \"email\": \"default\",\n                \"scopes\": [\n                    'https://www.googleapis.com/auth/compute',\n                    \"https://www.googleapis.com/auth/devstorage.read_write\",\n                    \"https://www.googleapis.com/auth/logging.write\",\n                    \"https://www.googleapis.com/auth/monitoring.write\",\n                    \"https://www.googleapis.com/auth/servicecontrol\",\n                    \"https://www.googleapis.com/auth/service.management.readonly\",\n                    \"https://www.googleapis.com/auth/trace.append\"\n                ]\n            }\n        ]\n    }\n    #header = 'Authorization: Bearer 1/fFBGRNJru1FQd44AzqT3Zg'\n    headers = {\n        'Authorization': 'Bearer %s' % access_token.access_token\n    }\n\n    #print('Test:', json.dumps(payload, indent=4, sort_keys=True))\n    \n    _LOGGER.debug('Access token: %s' % access_token.access_token)\n\n    _LOGGER.debug('Payload: %s', json.dumps(payload, sort_keys=True, indent=4))\n\n\n    r = requests.post('https://www.googleapis.com/compute/v1/'\n                      'projects/%s/zones/%s/instances' % (project, zone),\n                      headers=headers, json=payload)\n\n    r.raise_for_status()\n\n    op_name = r.json()['name']\n\n    _LOGGER.info('Submitted request to create intsance '\n                '(HTTP code: %d).',\n                r.status_code)\n\n    if wait_until_done:\n        _LOGGER.info('Waiting until operation is done...')\n        wait_for_zone_op(access_token, project, zone, op_name)\n\n    return op_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes an instance. TODO: docstring", "response": "def delete_instance(credentials, project, zone, name, wait_until_done=False):\n    \"\"\"Delete an instance.\n\n    TODO: docstring\n    \"\"\"\n\n    access_token = credentials.get_access_token()\n\n    headers = {\n        'Authorization': 'Bearer %s' % access_token.access_token\n    }\n\n    r = requests.delete('https://www.googleapis.com/compute/v1/'\n                        'projects/%s/zones/%s/instances/%s'\n                        % (project, zone, name),\n                        headers=headers)\n\n    r.raise_for_status()\n\n    op_name = r.json()['name']\n\n    _LOGGER.info('Submitted request to create intsance '\n                '(HTTP code: %d).',\n                r.status_code)\n\n    if wait_until_done:\n        _LOGGER.info('Waiting until operation is done...')\n        wait_for_zone_op(access_token, project, zone, op_name)\n\n    return op_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wait_for_instance_deletion(credentials, project, zone, instance_name,\n                               interval_seconds=5):\n    \"\"\"Wait until an instance is deleted.\n    \n    We require that initially, the specified instance exists.\n    TODO: docstring\n    \"\"\"\n    \n    t0 = time.time()\n    access_token = credentials.get_access_token()\n    headers = {\n        'Authorization': 'Bearer %s' % access_token.access_token\n    }\n\n    r = requests.get('https://www.googleapis.com/compute/v1/'\n                     'projects/%s/zones/%s/instances/%s'\n                     % (project, zone, instance_name),\n                     headers=headers)\n    \n    if r.status_code == 404:\n        raise AssertionError('Instance \"%s\" does not exist!' % instance_name)\n        \n    r.raise_for_status()\n    _LOGGER.debug('Instance \"%s\" exists.', instance_name)\n\n    while True:\n        time.sleep(interval_seconds)\n\n        access_token = credentials.get_access_token()\n        headers = {\n            'Authorization': 'Bearer %s' % access_token.access_token\n        }\n\n        r = requests.get('https://www.googleapis.com/compute/v1/'\n                         'projects/%s/zones/%s/instances/%s'\n                         % (project, zone, instance_name),\n                         headers=headers)\n        if r.status_code == 404:\n            break\n        r.raise_for_status()\n        _LOGGER.debug('Instance \"%s\" still exists.', instance_name)\n        \n    t1 = time.time()\n    t = t1-t0\n    t_min = t/60.0\n    _LOGGER.info('Instance was deleted after %.1f s (%.1f m).', t, t_min)", "response": "Wait until an instance is deleted."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef samReferencesToStr(filenameOrSamfile, indent=0):\n    indent = ' ' * indent\n\n    def _references(sam):\n        result = []\n        for i in range(sam.nreferences):\n            result.append('%s%s (length %d)' % (\n                indent, sam.get_reference_name(i), sam.lengths[i]))\n        return '\\n'.join(result)\n\n    if isinstance(filenameOrSamfile, six.string_types):\n        with samfile(filenameOrSamfile) as sam:\n            return _references(sam)\n    else:\n        return _references(sam)", "response": "Return a C { str } describing the known reference names and lengths of a SAM file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _hardClip(sequence, quality, cigartuples):\n    hardClipCount = cigarLength = 0\n    for (operation, length) in cigartuples:\n        hardClipCount += operation == CHARD_CLIP\n        cigarLength += length if operation in _CONSUMES_QUERY else 0\n\n    sequenceLength = len(sequence)\n    if quality is not None:\n        assert sequenceLength == len(quality)\n    clipLeft = clipRight = 0\n    clippedSequence = sequence\n    clippedQuality = quality\n\n    if sequenceLength > cigarLength:\n        alreadyClipped = False\n    else:\n        assert sequenceLength == cigarLength\n        alreadyClipped = True\n\n    if hardClipCount == 0:\n        pass\n    elif hardClipCount == 1:\n        # Hard clip either at the start or the end.\n        if cigartuples[0][0] == CHARD_CLIP:\n            if not alreadyClipped:\n                clipLeft = cigartuples[0][1]\n                clippedSequence = sequence[clipLeft:]\n                if quality is not None:\n                    clippedQuality = quality[clipLeft:]\n        elif cigartuples[-1][0] == CHARD_CLIP:\n            if not alreadyClipped:\n                clipRight = cigartuples[-1][1]\n                clippedSequence = sequence[:-clipRight]\n                if quality is not None:\n                    clippedQuality = quality[:-clipRight]\n        else:\n            raise ValueError(\n                'Invalid CIGAR tuples (%s) contains hard-clipping operation '\n                'that is neither at the start nor the end of the sequence.' %\n                (cigartuples,))\n    elif hardClipCount == 2:\n        # Hard clip at both the start and end.\n        assert cigartuples[0][0] == cigartuples[-1][0] == CHARD_CLIP\n        if not alreadyClipped:\n            clipLeft, clipRight = cigartuples[0][1], cigartuples[-1][1]\n            clippedSequence = sequence[clipLeft:-clipRight]\n            if quality is not None:\n                clippedQuality = quality[clipLeft:-clipRight]\n    else:\n        raise ValueError(\n            'Invalid CIGAR tuples (%s) specifies hard-clipping %d times (2 '\n            'is the maximum).' % (cigartuples, hardClipCount))\n\n    weClipped = bool(clipLeft or clipRight)\n\n    if weClipped:\n        assert not alreadyClipped\n        if len(clippedSequence) + clipLeft + clipRight != sequenceLength:\n            raise ValueError(\n                'Sequence %r (length %d) clipped to %r (length %d), but the '\n                'difference between these two lengths (%d) is not equal to '\n                'the sum (%d) of the left and right clip lengths (%d and %d '\n                'respectively). CIGAR tuples: %s' %\n                (sequence, len(sequence),\n                 clippedSequence, len(clippedSequence),\n                 abs(len(sequence) - len(clippedSequence)),\n                 clipLeft + clipRight, clipLeft, clipRight, cigartuples))\n    else:\n        assert len(clippedSequence) == sequenceLength\n        if quality is not None:\n            assert len(clippedQuality) == sequenceLength\n\n    return clippedSequence, clippedQuality, weClipped", "response": "Hard clip a nucleotide sequence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addFilteringOptions(parser, samfileIsPositionalArg=False):\n        parser.add_argument(\n            '%ssamfile' % ('' if samfileIsPositionalArg else '--'),\n            required=True,\n            help='The SAM/BAM file to filter.')\n\n        parser.add_argument(\n            '--referenceId', metavar='ID', nargs='+', action='append',\n            help=('A reference sequence id whose alignments should be kept '\n                  '(alignments against other references will be dropped). '\n                  'If omitted, alignments against all references will be '\n                  'kept. May be repeated.'))\n\n        parser.add_argument(\n            '--dropUnmapped', default=False, action='store_true',\n            help='If given, unmapped matches will not be output.')\n\n        parser.add_argument(\n            '--dropSecondary', default=False, action='store_true',\n            help='If given, secondary matches will not be output.')\n\n        parser.add_argument(\n            '--dropSupplementary', default=False, action='store_true',\n            help='If given, supplementary matches will not be output.')\n\n        parser.add_argument(\n            '--dropDuplicates', default=False, action='store_true',\n            help=('If given, matches flagged as optical or PCR duplicates '\n                  'will not be output.'))\n\n        parser.add_argument(\n            '--keepQCFailures', default=False, action='store_true',\n            help=('If given, reads that are considered quality control '\n                  'failures will be included in the output.'))\n\n        parser.add_argument(\n            '--minScore', type=float,\n            help=('If given, alignments with --scoreTag (default AS) values '\n                  'less than this value will not be output. If given, '\n                  'alignments that do not have a score will not be output.'))\n\n        parser.add_argument(\n            '--maxScore', type=float,\n            help=('If given, alignments with --scoreTag (default AS) values '\n                  'greater than this value will not be output. If given, '\n                  'alignments that do not have a score will not be output.'))\n\n        parser.add_argument(\n            '--scoreTag', default='AS',\n            help=('The alignment tag to extract for --minScore and --maxScore '\n                  'comparisons.'))", "response": "Adds options to an argument parser for filtering SAM / BAM files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parseFilteringOptions(cls, args, filterRead=None, storeQueryIds=False):\n        referenceIds = (set(chain.from_iterable(args.referenceId))\n                        if args.referenceId else None)\n\n        return cls(\n            args.samfile,\n            filterRead=filterRead,\n            referenceIds=referenceIds,\n            storeQueryIds=storeQueryIds,\n            dropUnmapped=args.dropUnmapped,\n            dropSecondary=args.dropSecondary,\n            dropSupplementary=args.dropSupplementary,\n            dropDuplicates=args.dropDuplicates,\n            keepQCFailures=args.keepQCFailures,\n            minScore=args.minScore,\n            maxScore=args.maxScore)", "response": "Parse command line options added in addSAMFilteringOptions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the alignments from the SAM file.", "response": "def alignments(self):\n        \"\"\"\n        Get alignments from the SAM/BAM file, subject to filtering.\n        \"\"\"\n        referenceIds = self.referenceIds\n        dropUnmapped = self.dropUnmapped\n        dropSecondary = self.dropSecondary\n        dropSupplementary = self.dropSupplementary\n        dropDuplicates = self.dropDuplicates\n        keepQCFailures = self.keepQCFailures\n        storeQueryIds = self.storeQueryIds\n        filterRead = self.filterRead\n        minScore = self.minScore\n        maxScore = self.maxScore\n        scoreTag = self.scoreTag\n\n        if storeQueryIds:\n            self.queryIds = queryIds = set()\n\n        lastAlignment = None\n        count = 0\n        with samfile(self.filename) as samAlignment:\n            for count, alignment in enumerate(samAlignment.fetch(), start=1):\n                if storeQueryIds:\n                    queryIds.add(alignment.query_name)\n\n                if minScore is not None or maxScore is not None:\n                    try:\n                        score = alignment.get_tag(scoreTag)\n                    except KeyError:\n                        continue\n                    else:\n                        if ((minScore is not None and score < minScore) or\n                                (maxScore is not None and score > maxScore)):\n                            continue\n\n                # Secondary and supplementary alignments may have a '*'\n                # (pysam returns this as None) SEQ field, indicating that\n                # the previous sequence should be used. This is best\n                # practice according to section 2.5.2 of\n                # https://samtools.github.io/hts-specs/SAMv1.pdf So we use\n                # the last alignment query and quality strings if we get\n                # None as a query sequence.\n                if alignment.query_sequence is None:\n                    if lastAlignment is None:\n                        raise InvalidSAM(\n                            'pysam produced an alignment (number %d) with no '\n                            'query sequence without previously giving an '\n                            'alignment with a sequence.' % count)\n                    # Use the previous query sequence and quality. I'm not\n                    # making the call to _hardClip dependent on\n                    # alignment.cigartuples (as in the else clause below)\n                    # because I don't think it's possible for\n                    # alignment.cigartuples to be None in this case. If we\n                    # have a second match on a query, then it must be\n                    # aligned to something (i.e., it cannot be unmapped\n                    # with no CIGAR string). The assertion will tell us if\n                    # this is ever not the case.\n                    assert alignment.cigartuples\n                    (alignment.query_sequence,\n                     alignment.query_qualities, _) = _hardClip(\n                         lastAlignment.query_sequence,\n                         lastAlignment.query_qualities,\n                         alignment.cigartuples)\n                else:\n                    lastAlignment = alignment\n                    if alignment.cigartuples:\n                        (alignment.query_sequence,\n                         alignment.query_qualities, _) = _hardClip(\n                             alignment.query_sequence,\n                             alignment.query_qualities,\n                             alignment.cigartuples)\n\n                if ((filterRead is None or\n                     filterRead(Read(alignment.query_name,\n                                     alignment.query_sequence,\n                                     alignment.qual))) and\n                    not (\n                        (referenceIds and\n                         alignment.reference_name not in referenceIds) or\n                        (alignment.is_unmapped and dropUnmapped) or\n                        (alignment.is_secondary and dropSecondary) or\n                        (alignment.is_supplementary and dropSupplementary) or\n                        (alignment.is_duplicate and dropDuplicates) or\n                        (alignment.is_qcfail and not keepQCFailures))):\n                    yield alignment\n\n        self.alignmentCount = count"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the lengths of wanted references.", "response": "def referenceLengths(self):\n        \"\"\"\n        Get the lengths of wanted references.\n\n        @raise UnknownReference: If a reference id is not present in the\n            SAM/BAM file.\n        @return: A C{dict} of C{str} reference id to C{int} length with a key\n            for each reference id in C{self.referenceIds} or for all references\n            if C{self.referenceIds} is C{None}.\n        \"\"\"\n        result = {}\n        with samfile(self.filename) as sam:\n            if self.referenceIds:\n                for referenceId in self.referenceIds:\n                    tid = sam.get_tid(referenceId)\n                    if tid == -1:\n                        raise UnknownReference(\n                            'Reference %r is not present in the SAM/BAM file.'\n                            % referenceId)\n                    else:\n                        result[referenceId] = sam.lengths[tid]\n            else:\n                result = dict(zip(sam.references, sam.lengths))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef queries(self, rcSuffix='', rcNeeded=False, padChar='-',\n                queryInsertionChar='N', unknownQualityChar='!',\n                allowDuplicateIds=False, addAlignment=False):\n        \"\"\"\n        Produce padded (with gaps) queries according to the CIGAR string and\n        reference sequence length for each matching query sequence.\n\n        @param rcSuffix: A C{str} to add to the end of query names that are\n            reverse complemented. This is added before the /1, /2, etc., that\n            are added for duplicated ids (if there are duplicates and\n            C{allowDuplicateIds} is C{False}.\n        @param rcNeeded: If C{True}, queries that are flagged as matching when\n            reverse complemented should have reverse complementing when\n            preparing the output sequences. This must be used if the program\n            that created the SAM/BAM input flags reversed matches but does not\n            also store the reverse complemented query.\n        @param padChar: A C{str} of length one to use to pad queries with to\n            make them the same length as the reference sequence.\n        @param queryInsertionChar:  A C{str} of length one to use to insert\n            into queries when the CIGAR string indicates that the alignment\n            of a query would cause a deletion in the reference. This character\n            is inserted as a 'missing' query character (i.e., a base that can\n            be assumed to have been lost due to an error) whose existence is\n            necessary for the match to continue.\n        @param unknownQualityChar: The character to put into the quality\n            string when unknown bases are inserted in the query or the query\n            is padded on the left/right with gaps.\n        @param allowDuplicateIds: If C{True}, repeated query ids (due to\n            secondary or supplemental matches) will not have /1, /2, etc.\n            appended to their ids. So repeated ids may appear in the yielded\n            FASTA.\n        @param addAlignment: If C{True} the reads yielded by the returned\n            generator will also have an C{alignment} attribute, being the\n            C{pysam.AlignedSegment} for the query.\n        @raises InvalidSAM: If a query has an empty SEQ field and either there\n            is no previous alignment or the alignment is not marked as\n            secondary or supplementary.\n        @return: A generator that yields C{Read} instances that are padded\n            with gap characters to align them to the length of the reference\n            sequence. See C{addAlignment}, above, to yield reads with the\n            corresponding C{pysam.AlignedSegment}.\n        \"\"\"\n        referenceLength = self.referenceLength\n\n        # Hold the count for each id so we can add /1, /2 etc to duplicate\n        # ids (unless --allowDuplicateIds was given).\n        idCount = Counter()\n\n        MATCH_OPERATIONS = {CMATCH, CEQUAL, CDIFF}\n\n        for lineNumber, alignment in enumerate(\n                self.samFilter.alignments(), start=1):\n\n            query = alignment.query_sequence\n            quality = ''.join(chr(q + 33) for q in alignment.query_qualities)\n\n            if alignment.is_reverse:\n                if rcNeeded:\n                    query = DNARead('id', query).reverseComplement().sequence\n                    quality = quality[::-1]\n                if rcSuffix:\n                    alignment.query_name += rcSuffix\n\n            # Adjust the query id if it's a duplicate and we're not allowing\n            # duplicates.\n            if allowDuplicateIds:\n                queryId = alignment.query_name\n            else:\n                count = idCount[alignment.query_name]\n                idCount[alignment.query_name] += 1\n                queryId = alignment.query_name + (\n                    '' if count == 0 else '/%d' % count)\n\n            referenceStart = alignment.reference_start\n            atStart = True\n            queryIndex = 0\n            referenceIndex = referenceStart\n            alignedSequence = ''\n            alignedQuality = ''\n\n            for operation, length in alignment.cigartuples:\n\n                # The operations are tested in the order they appear in\n                # https://samtools.github.io/hts-specs/SAMv1.pdf It would be\n                # more efficient to test them in order of frequency of\n                # occurrence.\n                if operation in MATCH_OPERATIONS:\n                    atStart = False\n                    alignedSequence += query[queryIndex:queryIndex + length]\n                    alignedQuality += quality[queryIndex:queryIndex + length]\n                elif operation == CINS:\n                    # Insertion to the reference. This consumes query bases but\n                    # we don't output them because the reference cannot be\n                    # changed.  I.e., these bases in the query would need to be\n                    # inserted into the reference.  Remove these bases from the\n                    # query but record what would have been inserted into the\n                    # reference.\n                    atStart = False\n                    self.referenceInsertions[queryId].append(\n                        (referenceIndex,\n                         query[queryIndex:queryIndex + length]))\n                elif operation == CDEL:\n                    # Delete from the reference. Some bases from the reference\n                    # would need to be deleted to continue the match. So we put\n                    # an insertion into the query to compensate.\n                    atStart = False\n                    alignedSequence += queryInsertionChar * length\n                    alignedQuality += unknownQualityChar * length\n                elif operation == CREF_SKIP:\n                    # Skipped reference. Opens a gap in the query. For\n                    # mRNA-to-genome alignment, an N operation represents an\n                    # intron.  For other types of alignments, the\n                    # interpretation of N is not defined. So this is unlikely\n                    # to occur.\n                    atStart = False\n                    alignedSequence += queryInsertionChar * length\n                    alignedQuality += unknownQualityChar * length\n                elif operation == CSOFT_CLIP:\n                    # Bases in the query that are not part of the match. We\n                    # remove these from the query if they protrude before the\n                    # start or after the end of the reference. According to the\n                    # SAM docs, 'S' operations may only have 'H' operations\n                    # between them and the ends of the CIGAR string.\n                    if atStart:\n                        # Don't set atStart=False, in case there's another 'S'\n                        # operation.\n                        unwantedLeft = length - referenceStart\n                        if unwantedLeft > 0:\n                            # The query protrudes left. Copy its right part.\n                            alignedSequence += query[\n                                queryIndex + unwantedLeft:queryIndex + length]\n                            alignedQuality += quality[\n                                queryIndex + unwantedLeft:queryIndex + length]\n                            referenceStart = 0\n                        else:\n                            referenceStart -= length\n                            alignedSequence += query[\n                                queryIndex:queryIndex + length]\n                            alignedQuality += quality[\n                                queryIndex:queryIndex + length]\n                    else:\n                        unwantedRight = (\n                            (referenceStart + len(alignedSequence) + length) -\n                            referenceLength)\n\n                        if unwantedRight > 0:\n                            # The query protrudes right. Copy its left part.\n                            alignedSequence += query[\n                                queryIndex:queryIndex + length - unwantedRight]\n                            alignedQuality += quality[\n                                queryIndex:queryIndex + length - unwantedRight]\n                        else:\n                            alignedSequence += query[\n                                queryIndex:queryIndex + length]\n                            alignedQuality += quality[\n                                queryIndex:queryIndex + length]\n                elif operation == CHARD_CLIP:\n                    # Some bases have been completely removed from the query.\n                    # This (H) can only be present as the first and/or last\n                    # operation. There is nothing to do as the bases are simply\n                    # not present in the query string in the SAM/BAM file.\n                    pass\n                elif operation == CPAD:\n                    # This is \"silent deletion from the padded reference\",\n                    # which consumes neither query nor reference.\n                    atStart = False\n                else:\n                    raise ValueError('Unknown CIGAR operation:', operation)\n\n                if operation in _CONSUMES_QUERY:\n                    queryIndex += length\n\n                if operation in _CONSUMES_REFERENCE:\n                    referenceIndex += length\n\n            if queryIndex != len(query):\n                # Oops, we did not consume the entire query.\n                raise ValueError(\n                    'Query %r not fully consumed when parsing CIGAR string. '\n                    'Query %r (len %d), final query index %d, CIGAR: %r' %\n                    (alignment.query_name, query, len(query), queryIndex,\n                     alignment.cigartuples))\n\n            # We cannot test we consumed the entire reference.  The CIGAR\n            # string applies to (and exhausts) the query but is silent\n            # about the part of the reference that lies to the right of the\n            # aligned query.\n\n            # Put gap characters before and after the aligned sequence so that\n            # it is offset properly and matches the length of the reference.\n            padRightLength = (referenceLength -\n                              (referenceStart + len(alignedSequence)))\n            paddedSequence = (padChar * referenceStart +\n                              alignedSequence +\n                              padChar * padRightLength)\n            paddedQuality = (unknownQualityChar * referenceStart +\n                             alignedQuality +\n                             unknownQualityChar * padRightLength)\n\n            read = Read(queryId, paddedSequence, paddedQuality)\n\n            if addAlignment:\n                read.alignment = alignment\n\n            yield read", "response": "Generates a sequence of queries for the specified base and sequence names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef demux(sel, di, ls_do):\n    N = len(ls_do)\n    @always_comb\n    def _demux():\n        for i in range(N):\n            ls_do[i].next = 0\n            if i == sel:\n                ls_do[i].next = di\n    return _demux", "response": "Demultiplexes an input signal to a list of output signals\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ls_mux(sel, lsls_di, ls_do):\n    N = len(ls_do)\n    lsls_in = [list(x) for x in zip(*lsls_di)]\n    return [mux(sel, lsls_in[i], ls_do[i]) for i in range(N)]", "response": "Multiplexes a list of input signal structures to an output structure. \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects a bit - slice from a bit - vector bv_di bv_do bv_di offset - bit offset of the slice from bv_di bv_do", "response": "def bitslice_select(offset, bv_di, bv_do):\n    ''' Selects a bit-slice from a bit-vector\n            offset - (i) bit offset of the slice\n            bv_di  - (i) bit vector where the slice is taken from\n            bv_do  - (o) selected slice; the length of this bit-vector defines the number of bit in the slice\n\n            bv_do = bv_di[len(bv_do)+offset:offset]\n    '''\n    LEN_I = len(bv_di)\n    LEN_O = len(bv_do)\n\n    assert LEN_I >= LEN_O, \"bitslice_select: expects len(bv_di) >= len(bv_do), but len(bv_di)={}, len(bv_do)\".format(LEN_I, LEN_O)\n\n    OFFSET_MAX = LEN_I - LEN_O + 1\n\n    @always_comb\n    def _slice():\n        bv_do.next = 0\n        for i in range(OFFSET_MAX):\n            if i==offset:\n                for b in range(LEN_O):\n                    bv_do.next[b] = bv_di[i+b]\n\n    return _slice"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef byteslice_select(offset, bv_di, bv_do):\n    ''' Selects a slice of length 8*n aligned on a byte from a bit-vector\n            offset - (i) byte offset of the slice\n            bv_di  - (i) bit vector where the slice is taken from; must len(bv_di) = 8*m\n            bv_do  - (o) selected slice; must len(bv_do) = 8*n, n<=m; len(bv_do) defines the number of bit in the slice\n    '''\n    LEN_I = len(bv_di)\n    LEN_O = len(bv_do)\n\n    assert (LEN_I % 8)==0, \"byteslice_select: expects len(bv_di)=8*x, but len(bv_di)={} bits\".format(LEN_I)\n    assert (LEN_O % 8)==0, \"byteslice_select: expects len(bv_do)=8*x, but len(bv_do)={} bits\".format(LEN_O)\n\n    bit_offset = Signal(intbv(0)[len(offset)+3:])\n\n    @always_comb\n    def _offset():\n        bit_offset.next = offset << 3\n\n    _slice = bitslice_select(bit_offset, bv_di, bv_do)\n\n    return _offset, _slice", "response": "Selects a slice of length 8 * n aligned on a byte from a bit - vector\n            bv_di bv_do."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to obtain the argument parser.", "response": "def get_argument_parser():\n    \"\"\"Function to obtain the argument parser.\n\n    Returns\n    -------\n    A fully configured `argparse.ArgumentParser` object.\n\n    Notes\n    -----\n    This function is used by the `sphinx-argparse` extension for sphinx.\n\n    \"\"\"\n    file_mv = cli.file_mv\n\n    desc = 'Find all runs (SRR..) associated with an SRA experiment (SRX...).'\n\n    parser = cli.get_argument_parser(desc=desc)\n\n    parser.add_argument(\n        '-e', '--experiment-file', type=str, required=True, metavar=file_mv,\n        help='File with SRA experiment IDs (starting with \"SRX\").'\n    )\n\n    parser.add_argument(\n        '-o', '--output-file', type=str, required=True, metavar=file_mv,\n        help='The output file.'\n    )\n\n    cli.add_reporting_args(parser)\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(args=None):\n    if args is None:\n        # parse command-line arguments\n        parser = get_argument_parser()\n        args = parser.parse_args()\n\n    experiment_file = args.experiment_file\n    output_file = args.output_file\n\n    # log_file = args.log_file\n    # quiet = args.quiet\n    # verbose = args.verbose\n\n    # logger = misc.get_logger(log_file=log_file, quiet=quiet,\n    #                          verbose=verbose)\n\n    host = 'ftp-trace.ncbi.nlm.nih.gov'\n    user = 'anonymous'\n    password = 'anonymous'\n\n    # output_dir = download_dir + experiment_id + '/'\n    # make sure output directory exists\n    # misc.make_sure_dir_exists(output_dir)\n    # logger.info('Created output directory: \"%s\".', output_dir)\n\n    experiments = misc.read_single(experiment_file)\n\n    runs = []\n    with ftputil.FTPHost(host, user, password) as ftp_host:\n        for exp in experiments:\n            exp_dir = '/sra/sra-instant/reads/ByExp/sra/SRX/%s/%s/' \\\n                    % (exp[:6], exp)\n            ftp_host.chdir(exp_dir)\n            run_folders = ftp_host.listdir(ftp_host.curdir)\n            # logging.info('Found %d run folders.',len(run_folders))\n\n            for folder in run_folders:\n                files = ftp_host.listdir(folder)\n                assert len(files) == 1\n                runs.append((exp, folder))\n\n    with open(output_file, 'wb') as ofh:\n        writer = csv.writer(ofh, dialect='excel-tab',\n                            lineterminator=os.linesep,\n                            quoting=csv.QUOTE_NONE)\n        for r in runs:\n            writer.writerow(r)\n        \n    return 0", "response": "Download all. sra from NCBI SRA for a given experiment ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _one_to_many_query(cls, query_obj, search4, model_attrib):\n        model = model_attrib.parent.class_\n\n        if isinstance(search4, str):\n            query_obj = query_obj.join(model).filter(model_attrib.like(search4))\n\n        elif isinstance(search4, int):\n            query_obj = query_obj.join(model).filter(model_attrib == search4)\n\n        elif isinstance(search4, Iterable):\n            query_obj = query_obj.join(model).filter(model_attrib.in_(search4))\n\n        return query_obj", "response": "extends and returns a SQLAlchemy query object to allow one - to - many queries"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keyword(self, name=None, identifier=None, entry_name=None, limit=None, as_df=False):\n        q = self.session.query(models.Keyword)\n\n        model_queries_config = (\n            (name, models.Keyword.name),\n            (identifier, models.Keyword.identifier)\n        )\n        q = self.get_model_queries(q, model_queries_config)\n\n        q = self.get_many_to_many_queries(q, ((entry_name, models.Keyword.entries, models.Entry.name),))\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Method to query the database for a keyword."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef entry(self,\n              name=None,\n              dataset=None,\n              recommended_full_name=None,\n              recommended_short_name=None,\n              gene_name=None,\n              taxid=None,\n              accession=None,\n              organism_host=None,\n              feature_type=None,\n              function_=None,\n              ec_number=None,\n              db_reference=None,\n              alternative_name=None,\n              disease_comment=None,\n              disease_name=None,\n              tissue_specificity=None,\n              pmid=None,\n              keyword=None,\n              subcellular_location=None,\n              tissue_in_reference=None,\n              sequence=None,\n              limit=None,\n              as_df=False):\n        \"\"\"Method to query :class:`.models.Entry` objects in database\n\n        An entry is the root element in UniProt datasets. Everything is linked to entry and can be accessed from\n\n        :param name: UniProt entry name(s)\n        :type name: str or tuple(str) or None\n\n        :param dataset: Swiss-Prot or TrEMBL\n        :type name: str or tuple(str) or None\n\n        :param recommended_full_name: recommended full protein name(s)\n        :type recommended_full_name: str or tuple(str) or None\n\n        :param recommended_short_name: recommended short protein name(s)\n        :type recommended_short_name: str or tuple(str) or None\n\n        :param tissue_in_reference: tissue(s) mentioned in reference\n        :type tissue_in_reference: str or tuple(str) or None\n\n        :param subcellular_location: subcellular location(s)\n        :type subcellular_location: str or tuple(str) or None\n\n        :param keyword: keyword(s)\n        :type keyword: str or tuple(str) or None\n\n        :param pmid: PubMed identifier(s)\n        :type pmid: int or tuple(int) or None\n\n        :param tissue_specificity: tissue specificit(y/ies)\n        :type tissue_specificity: str or tuple(str) or None\n\n        :param disease_comment: disease_comment(s)\n        :type disease_comment: str or tuple(str) or None\n\n        :param alternative_name: alternative name(s)\n        :type alternative_name: str or tuple(str) or None\n\n        :param db_reference: cross reference identifier(s)\n        :type db_reference: str or tuple(str) or None\n\n        :param ec_number: enzyme classification number(s), e.g. 1.1.1.1\n        :type ec_number: str or tuple(str) or None\n\n        :param function_: description of protein function(s)\n        :type function_: str or tuple(str) or None\n\n        :param feature_type: feature type(s)\n        :type feature_type: str or tuple(str) or None\n\n        :param organism_host: organism host(s) as taxid(s)\n        :type organism_host: int or tuple(int) or None\n\n        :param accession: UniProt accession number(s)\n        :type accession: str or tuple(str) or None\n\n        :param disease_name: disease name(s)\n        :type disease_name: str or tuple(str) or None\n\n        :param gene_name: gene name(s)\n        :type gene_name: str or tuple(str) or None\n\n        :param taxid: NCBI taxonomy identifier(s)\n        :type taxid: int or tuple(int) or None\n\n        :param sequence: Amino acid sequence(s)\n        :type sequence: str or tuple(str) or None\n\n        :param limit:\n            - if `isinstance(limit,int)==True` -> limit\n            - if `isinstance(limit,tuple)==True` -> format:= tuple(page_number, results_per_page)\n            - if limit == None -> all results\n        :type limit: int or tuple(int) or None\n\n        :param bool as_df: if `True` results are returned as :class:`pandas.DataFrame`\n\n        :return:\n            - if `as_df == False` -> list(:class:`.models.Entry`)\n            - if `as_df == True`  -> :class:`pandas.DataFrame`\n        :rtype: list(:class:`.models.Entry`) or :class:`pandas.DataFrame`\n        \"\"\"\n        q = self.session.query(models.Entry)\n\n        model_queries_config = (\n            (dataset, models.Entry.dataset),\n            (name, models.Entry.name),\n            (recommended_full_name, models.Entry.recommended_full_name),\n            (recommended_short_name, models.Entry.recommended_short_name),\n            (gene_name, models.Entry.gene_name),\n            (taxid, models.Entry.taxid),\n        )\n        q = self.get_model_queries(q, model_queries_config)\n\n        one_to_many_queries_config = (\n            (accession, models.Accession.accession),\n            (organism_host, models.OrganismHost.taxid),\n            (feature_type, models.Feature.type_),\n            (function_, models.Function.text),\n            (ec_number, models.ECNumber.ec_number),\n            (db_reference, models.DbReference.identifier),\n            (alternative_name, models.AlternativeFullName.name),\n            (disease_comment, models.DiseaseComment.comment),\n            (tissue_specificity, models.TissueSpecificity.comment),\n            (sequence, models.Sequence.sequence),\n        )\n        q = self.get_one_to_many_queries(q, one_to_many_queries_config)\n\n        many_to_many_queries_config = (\n            (pmid, models.Entry.pmids, models.Pmid.pmid),\n            (keyword, models.Entry.keywords, models.Keyword.name),\n            (subcellular_location, models.Entry.subcellular_locations, models.SubcellularLocation.location),\n            (tissue_in_reference, models.Entry.tissue_in_references, models.TissueInReference.tissue)\n        )\n        q = self.get_many_to_many_queries(q, many_to_many_queries_config)\n\n        if disease_name:\n            q = q.join(models.Entry.disease_comments).join(models.DiseaseComment.disease)\n            if isinstance(disease_name, str):\n                q = q.filter(models.Disease.name.like(disease_name))\n            elif isinstance(disease_name, Iterable):\n                q = q.filter(models.Disease.name.in_(disease_name))\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Method to query UniProt Entry objects in database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disease(self,\n                identifier=None,\n                ref_id=None,\n                ref_type=None,\n                name=None,\n                acronym=None,\n                description=None,\n                entry_name=None,\n                limit=None,\n                as_df=False\n                ):\n        \"\"\"Method to query :class:`.models.Disease` objects in database\n\n\n        :param identifier: disease UniProt identifier(s)\n        :type identifier: str or tuple(str) or None\n\n        :param ref_id: identifier(s) of referenced database\n        :type ref_id: str or tuple(str) or None\n\n        :param ref_type: database name(s)\n        :type ref_type: str or tuple(str) or None\n\n        :param name: disease name(s)\n        :type name: str or tuple(str) or None\n\n        :param acronym: disease acronym(s)\n        :type acronym: str or tuple(str) or None\n\n        :param description: disease description(s)\n        :type description: str or tuple(str) or None\n\n        :param entry_name: name(s) in :class:`.models.Entry`\n        :type entry_name: str or tuple(str) or None\n\n        :param limit:\n            - if `isinstance(limit,int)==True` -> limit\n            - if `isinstance(limit,tuple)==True` -> format:= tuple(page_number, results_per_page)\n            - if limit == None -> all results\n        :type limit: int or tuple(int) or None\n\n        :param bool as_df: if `True` results are returned as :class:`pandas.DataFrame`\n\n        :return:\n            - if `as_df == False` -> list(:class:`.models.Disease`)\n            - if `as_df == True`  -> :class:`pandas.DataFrame`\n        :rtype: list(:class:`.models.Disease`) or :class:`pandas.DataFrame`\n        \"\"\"\n        q = self.session.query(models.Disease)\n\n        model_queries_config = (\n            (identifier, models.Disease.identifier),\n            (ref_id, models.Disease.ref_id),\n            (ref_type, models.Disease.ref_type),\n            (name, models.Disease.name),\n            (acronym, models.Disease.acronym),\n            (description, models.Disease.description)\n        )\n        q = self.get_model_queries(q, model_queries_config)\n\n        if entry_name:\n            q = q.session.query(models.Disease).join(models.DiseaseComment).join(models.Entry)\n            if isinstance(entry_name, str):\n                q = q.filter(models.Entry.name == entry_name)\n            elif isinstance(entry_name, Iterable):\n                q = q.filter(models.Entry.name.in_(entry_name))\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Method to query UniProt s disease objects in database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef accession(self, accession=None, entry_name=None, limit=None, as_df=False):\n        q = self.session.query(models.Accession)\n\n        model_queries_config = (\n            (accession, models.Accession.accession),\n        )\n        q = self.get_model_queries(q, model_queries_config)\n\n        q = self.get_one_to_many_queries(q, ((entry_name, models.Entry.name),))\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Method to query UniProt s Accession objects in database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef feature(self, type_=None, identifier=None, description=None, entry_name=None, limit=None, as_df=False):\n        q = self.session.query(models.Feature)\n\n        model_queries_config = (\n            (type_, models.Feature.type_),\n            (identifier, models.Feature.identifier),\n            (description, models.Feature.description)\n        )\n        q = self.get_model_queries(q, model_queries_config)\n\n        q = self.get_one_to_many_queries(q, ((entry_name, models.Entry.name),))\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Method to query the database for a specific feature."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef subcellular_location(self, location=None, entry_name=None, limit=None, as_df=False):\n        q = self.session.query(models.SubcellularLocation)\n\n        q = self.get_model_queries(q, ((location, models.SubcellularLocation.location),))\n\n        q = self.get_many_to_many_queries(q, ((entry_name, models.SubcellularLocation.entries, models.Entry.name),))\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Method to query the subcellular location of a specific entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dbreference_types(self):\n        q = self.session.query(distinct(models.DbReference.type_))\n        return [x[0] for x in q.all()]", "response": "Distinct database cross reference types in : class :. models. DbReference"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef datasets(self):\n        r = self.session.query(distinct(models.Entry.dataset)).all()\n        return [x[0] for x in r]", "response": "Return a list of distinct datasets in SwissProt or TrEMBL"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef subcellular_locations(self):\n        return [x[0] for x in self.session.query(models.SubcellularLocation.location).all()]", "response": "Distinct subcellular locations (``location`` in :class:`.models.SubcellularLocation`)\n\n        :return: all distinct subcellular locations\n        :rtype: list[str]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tissues_in_references(self):\n        return [x[0] for x in self.session.query(models.TissueInReference.tissue).all()]", "response": "Distinct tissues in references"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef keywords(self):\n        return [x[0] for x in self.session.query(models.Keyword.name).all()]", "response": "Distinct keywords ( name in models. Keyword )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef version(self):\n        return [x for x in self.session.query(models.Version).all()]", "response": "Version of UniPort knowledgebase"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reserve(self, force=False):\n\n        if not force:\n            try:\n                self.api.call_rc('ixPortTakeOwnership {}'.format(self.uri))\n            except Exception as _:\n                raise TgnError('Failed to take ownership for port {} current owner is {}'.format(self, self.owner))\n        else:\n            self.api.call_rc('ixPortTakeOwnership {} force'.format(self.uri))", "response": "Reserve port.\n\n        :param force: True - take forcefully, False - fail if port is reserved by other user"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite configuration to chassis.", "response": "def write(self):\n        \"\"\" Write configuration to chassis.\n\n        Raise StreamWarningsError if configuration warnings found.\n        \"\"\"\n\n        self.ix_command('write')\n        stream_warnings = self.streamRegion.generateWarningList()\n        warnings_list = (self.api.call('join ' + ' {' + stream_warnings + '} ' + ' LiStSeP').split('LiStSeP')\n                         if self.streamRegion.generateWarningList() else [])\n        for warning in warnings_list:\n            if warning:\n                raise StreamWarningsError(warning)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the configuration file from the file name.", "response": "def load_config(self, config_file_name):\n        \"\"\" Load configuration file from prt or str.\n\n        Configuration file type is extracted from the file suffix - prt or str.\n\n        :param config_file_name: full path to the configuration file.\n            IxTclServer must have access to the file location. either:\n                The config file is on shared folder.\n                IxTclServer run on the client machine.\n        \"\"\"\n        config_file_name = config_file_name.replace('\\\\', '/')\n        ext = path.splitext(config_file_name)[-1].lower()\n        if ext == '.prt':\n            self.api.call_rc('port import \"{}\" {}'.format(config_file_name, self.uri))\n        elif ext == '.str':\n            self.reset()\n            self.api.call_rc('stream import \"{}\" {}'.format(config_file_name, self.uri))\n        else:\n            raise ValueError('Configuration file type {} not supported.'.format(ext))\n        self.write()\n        self.discover()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the configuration file from the file name.", "response": "def save_config(self, config_file_name):\n        \"\"\" Save configuration file from prt or str.\n\n        Configuration file type is extracted from the file suffix - prt or str.\n\n        :param config_file_name: full path to the configuration file.\n            IxTclServer must have access to the file location. either:\n                The config file is on shared folder.\n                IxTclServer run on the client machine.\n        \"\"\"\n        config_file_name = config_file_name.replace('\\\\', '/')\n        ext = path.splitext(config_file_name)[-1].lower()\n        if ext == '.prt':\n            self.api.call_rc('port export \"{}\" {}'.format(config_file_name, self.uri))\n        elif ext == '.str':\n            # self.reset()\n            self.api.call_rc('stream export \"{}\" {}'.format(config_file_name, self.uri))\n        else:\n            raise ValueError('Configuration file type {} not supported.'.format(ext))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart transmit on the port.", "response": "def start_transmit(self, blocking=False):\n        \"\"\" Start transmit on port.\n\n        :param blocking: True - wait for traffic end, False - return after traffic start.\n        \"\"\"\n\n        self.session.start_transmit(blocking, False, self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstop capture on the current port.", "response": "def stop_capture(self, cap_file_name=None, cap_file_format=IxeCapFileFormat.mem):\n        \"\"\" Stop capture on port.\n\n        :param cap_file_name: prefix for the capture file name.\n            Capture file will be saved as pcap file named 'prefix' + 'URI'.pcap.\n        :param cap_file_format: exported file format\n        :return: number of captured frames\n        \"\"\"\n\n        return self.session.stop_capture(cap_file_name, cap_file_format, self)[self]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstops capture on ports.", "response": "def get_cap_frames(self, *frame_nums):\n        \"\"\" Stop capture on ports.\n\n        :param frame_nums: list of frame numbers to read.\n        :return: list of captured frames.\n        \"\"\"\n\n        frames = []\n        for frame_num in frame_nums:\n            if self.captureBuffer.getframe(frame_num) == '0':\n                frames.append(self.captureBuffer.frame)\n            else:\n                frames.append(None)\n        return frames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear all port stats.", "response": "def clear_port_stats(self):\n        \"\"\" Clear only port stats (leave stream and packet group stats).\n\n        Do not use - still working with Ixia to resolve.\n        \"\"\"\n        stat = IxeStat(self)\n        stat.ix_set_default()\n        stat.enableValidStats = True\n        stat.ix_set()\n        stat.write()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the PHY mode of the related port.", "response": "def set_phy_mode(self, mode=IxePhyMode.ignore):\n        \"\"\" Set phy mode to copper or fiber.\n        :param mode: requested PHY mode.\n        \"\"\"\n        if isinstance(mode, IxePhyMode):\n            if mode.value:\n                self.api.call_rc('port setPhyMode {} {}'.format(mode.value, self.uri))\n        else:\n            self.api.call_rc('port setPhyMode {} {}'.format(mode, self.uri))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_transmit_mode(self, mode):\n\n        self.api.call_rc('port setTransmitMode {} {}'.format(mode, self.uri))", "response": "set port transmit mode\n\n        :param mode: request transmit mode\n        :type mode: ixexplorer.ixe_port.IxeTransmitMode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive an ImageField image returns a list of images sizes in this form.", "response": "def get_image_sizes(image):\n    \"\"\"Given an ImageField `image`, returns a list of images sizes in this\n    form:\n\n    [\n        {\n            \"url\": \"http://example.com/xxx.jpg\",\n            \"width\": 1440,\n            \"height\": 960\n        },\n        [...]\n    ]\"\"\"\n\n    # It is possible to have the same width appear more than once, if\n    # THUMBNAIL_UPSCALE is set to False and the image's width is less than the\n    # largest value in FLEXIBLE_IMAGE_SIZES. So keep track of widths and\n    # don't output more than one image with the same width (which would result\n    # in an invalid `srcset` attribute).\n    sizes = []\n    seen_widths = []\n\n    for size in settings_sizes():\n        img = get_thumbnail_shim(image, size)\n\n        if img.width in seen_widths:\n            continue\n\n        seen_widths.append(img.width)\n\n        sizes.append({\n            \"url\": img.url,\n            \"width\": img.width,\n            \"height\": img.height,\n        })\n    return sizes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_template_context(src, container=\"div\", classes=\"\", inner_classes=\"\", alt=\"\", background_image=False, no_css=False, aria_hidden=False):\n    context = {\n        \"container\": container,\n        \"classes\": classes,\n        \"aspect_padding_bottom\": aspect_ratio_percent(src),\n        \"alt\": alt,\n        \"background_image\": background_image,\n        \"no_css\": no_css,\n        \"inner_classes\": inner_classes,\n        \"aria_hidden\": aria_hidden,\n    }\n\n    # We can't do any of the srcset (or JS switching fallback) if we don't\n    # have a thumbnail library installed.\n    if not get_thumbnail_engine():\n        context[\"image\"] = src\n        return context\n\n    sizes = get_image_sizes(src)\n    context[\"image_sizes\"] = sizes\n\n    # Set the first image in the list as the one to be rendered initially\n    # (pre-JS-fallback). `if sizes` might not be a necessary check...\n    context[\"image\"] = sizes[0]\n\n    context[\"image_sizes_json\"] = json.dumps(sizes)\n    srcset_items = [\"{} {}w\".format(size[\"url\"], size[\"width\"]) for size in sizes]\n\n    context[\"image_sizes_srcset\"] = \", \".join(srcset_items)\n    return context", "response": "Returns a template context for a flexible image template\n    tag implementation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nestimate registration model using cross - correlation.", "response": "def fit(self, images, reference=None):\n        \"\"\"\n        Estimate registration model using cross-correlation.\n\n        Use cross correlation to compute displacements between \n        images or volumes and reference. Displacements will be \n        2D for images and 3D for volumes.\n\n        Parameters\n        ----------\n        images : array-like or thunder images\n            The sequence of images / volumes to register.\n\n        reference : array-like\n            A reference image to align to.\n        \"\"\"\n        images = check_images(images)\n        reference = check_reference(images, reference)\n\n        def func(item):\n            key, image = item\n            return asarray([key, self._get(image, reference)])\n\n        transformations = images.map(func, with_keys=True).toarray()\n        if images.shape[0] == 1: \n            transformations = [transformations]\n\n        algorithm = self.__class__.__name__\n        return RegistrationModel(dict(transformations), algorithm=algorithm)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfit and apply registration model using cross - correlation.", "response": "def fit_and_transform(self, images, reference=None):\n        \"\"\"\n        Estimate and apply registration model using cross-correlation.\n\n        Use cross correlation to compute displacements between \n        images or volumes and reference, and apply the\n        estimated model to the data. Displacements will be \n        2D for images and 3D for volumes.\n\n        Parameters\n        ----------\n        images : array-like or thunder images\n            The sequence of images / volumes to register.\n\n        reference : array-like\n            A reference image to align to.\n        \"\"\"\n        images = check_images(images)\n        check_reference(images, reference)\n\n        def func(image):\n            t = self._get(image, reference)\n            return t.apply(image)\n\n        return images.map(func)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a path for a file based on a set of entities and a list of filename patterns.", "response": "def build_path(entities, path_patterns, strict=False):\n    \"\"\"\n    Constructs a path given a set of entities and a list of potential\n    filename patterns to use.\n\n    Args:\n        entities (dict): A dictionary mapping entity names to entity values.\n        path_patterns (str, list): One or more filename patterns to write\n            the file to. Entities should be represented by the name\n            surrounded by curly braces. Optional portions of the patterns\n            should be denoted by square brackets. Entities that require a\n            specific value for the pattern to match can pass them inside\n            carets. Default values can be assigned by specifying a string after\n            the pipe operator. E.g., (e.g., {type<image>|bold} would only match\n            the pattern if the entity 'type' was passed and its value is\n            \"image\", otherwise the default value \"bold\" will be used).\n                Example 1: 'sub-{subject}/[var-{name}/]{id}.csv'\n                Result 2: 'sub-01/var-SES/1045.csv'\n        strict (bool): If True, all passed entities must be matched inside a\n            pattern in order to be a valid match. If False, extra entities will\n            be ignored so long as all mandatory entities are found.\n\n    Returns:\n        A constructed path for this file based on the provided patterns.\n    \"\"\"\n    if isinstance(path_patterns, string_types):\n        path_patterns = [path_patterns]\n\n    # Loop over available patherns, return first one that matches all\n    for pattern in path_patterns:\n        # If strict, all entities must be contained in the pattern\n        if strict:\n            defined = re.findall('\\{(.*?)(?:<[^>]+>)?\\}', pattern)\n            if set(entities.keys()) - set(defined):\n                continue\n        # Iterate through the provided path patterns\n        new_path = pattern\n        optional_patterns = re.findall('\\[(.*?)\\]', pattern)\n        # First build from optional patterns if possible\n        for optional_pattern in optional_patterns:\n            optional_chunk = replace_entities(entities, optional_pattern) or ''\n            new_path = new_path.replace('[%s]' % optional_pattern,\n                                        optional_chunk)\n        # Replace remaining entities\n        new_path = replace_entities(entities, new_path)\n\n        if new_path:\n            return new_path\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_settings_from_environment(environ):\n    '''Deduce settings from environment variables'''\n    settings = {}\n    for name, value in environ.items():\n        if not name.startswith('DJANGO_'):\n            continue\n        name = name.replace('DJANGO_', '', 1)\n        if _ignore_setting(name):\n            continue\n        try:\n            settings[name] = ast.literal_eval(value)\n        except (SyntaxError, ValueError) as err:\n            LOGGER.warn(\"Unable to parse setting %s=%s (%s)\", name, value, err)\n    return settings", "response": "Deduce settings from environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the VMC Digest object for the given data.", "response": "def vmc_digest(data, digest_size=DEFAULT_DIGEST_SIZE):\n    \"\"\"Returns the VMC Digest as a Digest object, which has both bytes and str (\n    URL-safe, Base 64) representations.\n\n    >>> d = vmc_digest(\"\")\n\n    # I can't figure out how to make this test work on Py 2 and 3 :-(\n    >>> d                       # doctest: +SKIP\n    b'\\xcf\\x83\\xe15~\\xef\\xb8\\xbd\\xf1T(P\\xd6m\\x80'\n\n    >>> str(d)\n    'z4PhNX7vuL3xVChQ1m2AB9Yg5AULVxXc'\n\n    >>> len(d), len(str(d))\n    (24, 32)\n\n    >>> str(vmc_digest(\"\", 24))\n    'z4PhNX7vuL3xVChQ1m2AB9Yg5AULVxXc'\n\n    >>> vmc_digest(\"\", 17) \n    Traceback (most recent call last):\n    ...\n    ValueError: digest_size must be a multiple of 3\n\n    >>> vmc_digest(\"\", 66) \n    Traceback (most recent call last):\n    ...\n    ValueError: digest_size must be between 0 and 63 (bytes)\n\n\n    SHA-512 is 2x faster than SHA1 on modern 64-bit platforms.\n    However, few appliations require 512 bits (64 bytes) of keyspace.\n    That larger size translates into proportionally larger key size\n    requirements, with attendant performance implications.  By\n    truncating the SHA-512 digest [1], users may obtain a tunable\n    level of collision avoidance.\n\n    The string returned by this function is Base 64 encoded with\n    URL-safe characters [2], making it suitable for use with URLs or\n    filesystem paths.  Base 64 encoding results in an output string\n    that is 4/3 the size of the input.  If the length of the input\n    string is not divisible by 3, the output is right-padded with\n    equal signs (=), which have no information content. Therefore,\n    this function requires that digest_size is evenly divisible by 3.\n    (The resulting vmc_digest will be 4/3*digest_size bytes.)\n\n    According to [3], the probability of a collision using b bits with\n    m messages (sequences) is:\n\n       P(b, m) = m^2 / 2^(b+1).\n\n    Note that the collision probability depends on the number of\n    messages, but not their size.  Solving for the number of messages:\n\n       m(b, P) = sqrt(P * 2^(b+1))\n\n    Solving for the number of *bits*:\n\n       b(m, P) = log2(m^2/P) - 1\n\n    For various values of m and P, the number of *bytes* required\n    according to b(m,P) rounded to next multiple of 3 is:\n\n    +-------+----------+----------+----------+----------+----------+----------+\n    |   #m  | P<=1e-24 | P<=1e-21 | P<=1e-18 | P<=1e-15 | P<=1e-12 | P<=1e-09 |\n    +-------+----------+----------+----------+----------+----------+----------+\n    | 1e+06 |    15    |    12    |    12    |    9     |    9     |    9     |\n    | 1e+09 |    15    |    15    |    12    |    12    |    9     |    9     |\n    | 1e+12 |    15    |    15    |    15    |    12    |    12    |    9     |\n    | 1e+15 |    18    |    15    |    15    |    15    |    12    |    12    |\n    | 1e+18 |    18    |    18    |    15    |    15    |    15    |    12    |\n    | 1e+21 |    21    |    18    |    18    |    15    |    15    |    15    |\n    | 1e+24 |    21    |    21    |    18    |    18    |    15    |    15    |\n    +-------+----------+----------+----------+----------+----------+----------+\n\n    For example, given 1e+18 expected messages and a desired collision\n    probability < 1e-15, we use digest_size = 15 (bytes).\n\n    [1] http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf\n    [2] https://tools.ietf.org/html/rfc3548#section-4\n    [3] http://stackoverflow.com/a/4014407/342839\n    [4] http://stackoverflow.com/a/22029380/342839\n    [5] http://preshing.com/20110504/hash-collision-probabilities/\n    [6] https://en.wikipedia.org/wiki/Birthday_problem\n\n    \"\"\" \n\n    # TODO: Consider relaxing %3 constraint and stripping padding\n    if digest_size % 3 != 0:\n        raise ValueError(\"digest_size must be a multiple of 3\")\n    if not 0 <= digest_size <= 63:\n        raise ValueError(\"digest_size must be between 0 and 63 (bytes)\")\n\n    sha512 = Digest(hashlib.sha512(data.encode(ENC)).digest())\n    return sha512[:digest_size]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_variance(matrix, top):\n    assert isinstance(matrix, ExpMatrix)\n    assert isinstance(top, (int, np.integer))\n\n    if top >= matrix.p:\n        logger.warning('Variance filter has no effect '\n                       '(\"top\" parameter is >= number of genes).')\n        return matrix.copy()\n\n    var = np.var(matrix.X, axis=1, ddof=1)\n    total_var = np.sum(var)  # total sum of variance\n    a = np.argsort(var)\n    a = a[::-1]\n    sel = np.zeros(matrix.p, dtype=np.bool_)\n    sel[a[:top]] = True\n\n    lost_p = matrix.p - top\n    lost_var = total_var - np.sum(var[sel])\n    logger.info('Selected the %d most variable genes '\n                '(excluded %.1f%% of genes, representing %.1f%% '\n                'of total variance).',\n                top, 100 * (lost_p / float(matrix.p)),\n                100 * (lost_var / total_var))\n\n    matrix = matrix.loc[sel]\n    return matrix", "response": "Filter genes in an expression matrix by variance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_mean(matrix, top):\n    assert isinstance(matrix, ExpMatrix)\n    assert isinstance(top, int)\n\n    if top >= matrix.p:\n        logger.warning('Gene expression filter with `top` parameter that is '\n                       '>= the number of genes!')\n        top = matrix.p\n\n    a = np.argsort(np.mean(matrix.X, axis=1))\n    a = a[::-1]\n\n    sel = np.zeros(matrix.p, dtype=np.bool_)\n    sel[a[:top]] = True\n\n    matrix = matrix.loc[sel]\n    return matrix", "response": "Filter genes in an expression matrix by mean expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfilter genes in an expression matrix by percentile expression.", "response": "def filter_percentile(matrix, top, percentile=50):\n    \"\"\"Filter genes in an expression matrix by percentile expression.\n\n    Parameters\n    ----------\n    matrix: ExpMatrix\n        The expression matrix.\n    top: int\n        The number of genes to retain.\n    percentile: int or float, optinonal\n        The percentile to use  Defaults to the median (50th percentile).\n\n    Returns\n    -------\n    ExpMatrix\n        The filtered expression matrix.\n    \"\"\"\n    assert isinstance(matrix, ExpMatrix)\n    assert isinstance(top, int)\n    assert isinstance(percentile, (int, float))\n\n    if top >= matrix.p:\n        logger.warning('Gene expression filter with `top` parameter that is '\n                       ' >= the number of genes!')\n        top = matrix.p\n\n    a = np.argsort(np.percentile(matrix.X, percentile, axis=1))\n    a = a[::-1]\n\n    sel = np.zeros(matrix.p, dtype=np.bool_)\n    sel[a[:top]] = True\n\n    matrix = matrix.loc[sel]\n    return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _transform_chrom(chrom):\n    try:\n        c = int(chrom)\n    except:\n        if chrom in ['X', 'Y']:\n            return chrom\n        elif chrom == 'MT':\n            return '_MT'  # sort to the end\n        else:\n            return '__' + chrom # sort to the very end\n    else:\n        # make sure numbered chromosomes are sorted numerically\n        return '%02d' % c", "response": "Helper function to obtain specific sort order."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_chromosome_lengths(fasta_file, fancy_sort=True):\n    chromlen = []\n    with gzip.open(fasta_file, 'rt', encoding='ascii') as fh:\n        fasta = SeqIO.parse(fh, 'fasta')\n        for i, f in enumerate(fasta):\n            chromlen.append((f.id, len(f.seq)))\n            _LOGGER.info('Processed chromosome \"%s\"...', f.id)\n            #print(dir(f))\n            #if i == 1: break\n            \n    # convert to pandas Series\n    chromlen = pd.Series(OrderedDict(chromlen))\n    chromlen.index.name = 'Chromosome'\n    chromlen.name = 'Length'\n\n    if fancy_sort:\n        # sort using fancy ordering\n        chrom_for_sorting = chromlen.index.to_series().apply(_transform_chrom)\n        a = chrom_for_sorting.argsort(kind='mergesort')\n        chromlen = chromlen.iloc[a]\n\n    return chromlen", "response": "Extract chromosome lengths from genome FASTA file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve_schema(schema):\n    def traverse(schema):\n        if isinstance(schema, dict):\n            if 'allOf' in schema:\n                for x in schema['allOf']:\n                    sub_schema = x\n                    sub_schema.pop('title', None)\n                    schema = _merge_dicts(schema, sub_schema)\n                schema.pop('allOf')\n                schema = traverse(schema)\n            elif 'properties' in schema:\n                for x in schema.get('properties', []):\n                    schema['properties'][x] = traverse(\n                        schema['properties'][x])\n            elif 'items' in schema:\n                schema['items'] = traverse(schema['items'])\n        return schema\n    return traverse(schema)", "response": "Transform JSON schemas allOf."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge the second multiple - dictionary into the first one.", "response": "def _merge_dicts(first, second):\n    \"\"\"Merge the 'second' multiple-dictionary into the 'first' one.\"\"\"\n    new = deepcopy(first)\n    for k, v in second.items():\n        if isinstance(v, dict) and v:\n            ret = _merge_dicts(new.get(k, dict()), v)\n            new[k] = ret\n        else:\n            new[k] = second[k]\n    return new"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a color scale from a plotly color map file.", "response": "def read_colorscale(cmap_file):\n    \"\"\"Return a colorscale in the format expected by plotly.\n\n    Parameters\n    ----------\n    cmap_file : str\n        Path of a plain-text file containing the colorscale. \n\n    Returns\n    -------\n    list\n        The colorscale.\n        \n    Notes\n    -----\n    A plotly colorscale is a list where each item is a pair\n    (i.e., a list with two elements) consisting of\n    a decimal number x between 0 and 1 and a corresponding \"rgb(r,g,b)\" string,\n    where r, g, and b are integers between 0 and 255.\n\n    The `cmap_file` is a tab-separated text file containing four columns\n    (x,r,g,b), so that each row corresponds to an entry in the list\n    described above.\n    \"\"\"\n    assert isinstance(cmap_file, str)\n\n    cm = np.loadtxt(cmap_file, delimiter='\\t', dtype=np.float64)\n    # x = cm[:, 0]\n    rgb = np.int64(cm[:, 1:])  # normalize to 0-1?\n    n = cm.shape[0]\n    colorscale = []\n    for i in range(n):\n        colorscale.append(\n            [i / float(n - 1),\n             'rgb(%d, %d, %d)' % (rgb[i, 0], rgb[i, 1], rgb[i, 2])]\n        )\n    return colorscale"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a WSGI application that searches requests to controllers", "response": "def make_router():\n    \"\"\"Return a WSGI application that searches requests to controllers \"\"\"\n    global router\n    routings = [\n        ('GET', '^/$', index),\n        ('GET', '^/api/?$', index),\n        ('POST', '^/api/1/calculate/?$', calculate.api1_calculate),\n        ('GET', '^/api/2/entities/?$', entities.api2_entities),\n        ('GET', '^/api/1/field/?$', field.api1_field),\n        ('GET', '^/api/1/formula/(?P<name>[^/]+)/?$', formula.api1_formula),\n        ('GET', '^/api/2/formula/(?:(?P<period>[A-Za-z0-9:-]*)/)?(?P<names>[A-Za-z0-9_+-]+)/?$', formula.api2_formula),\n        ('GET', '^/api/1/parameters/?$', parameters.api1_parameters),\n        ('GET', '^/api/1/reforms/?$', reforms.api1_reforms),\n        ('POST', '^/api/1/simulate/?$', simulate.api1_simulate),\n        ('GET', '^/api/1/swagger$', swagger.api1_swagger),\n        ('GET', '^/api/1/variables/?$', variables.api1_variables),\n        ]\n    router = urls.make_router(*routings)\n    return router"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_schema(self, directory, path):\n        self.schemas[path] = os.path.abspath(directory)", "response": "Register a json - schema."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the directory containing the given schema.", "response": "def get_schema_dir(self, path):\n        \"\"\"Retrieve the directory containing the given schema.\n\n        :param path: Schema path, relative to the directory where it was\n            registered.\n        :raises invenio_jsonschemas.errors.JSONSchemaNotFound: If no schema\n            was found in the specified path.\n        :returns: The schema directory.\n        \"\"\"\n        if path not in self.schemas:\n            raise JSONSchemaNotFound(path)\n        return self.schemas[path]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_schema_path(self, path):\n        if path not in self.schemas:\n            raise JSONSchemaNotFound(path)\n        return os.path.join(self.schemas[path], path)", "response": "Compute the schema s absolute path from a schema relative path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_schema(self, path, with_refs=False, resolved=False):\n        if path not in self.schemas:\n            raise JSONSchemaNotFound(path)\n        with open(os.path.join(self.schemas[path], path)) as file_:\n            schema = json.load(file_)\n            if with_refs:\n                schema = JsonRef.replace_refs(\n                    schema,\n                    base_uri=request.base_url,\n                    loader=self.loader_cls() if self.loader_cls else None,\n                )\n            if resolved:\n                schema = self.resolver_cls(schema)\n            return schema", "response": "Retrieve a schema from the specified path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert schema URL to path.", "response": "def url_to_path(self, url):\n        \"\"\"Convert schema URL to path.\n\n        :param url: The schema URL.\n        :returns: The schema path or ``None`` if the schema can't be resolved.\n        \"\"\"\n        parts = urlsplit(url)\n        try:\n            loader, args = self.url_map.bind(parts.netloc).match(parts.path)\n            path = args.get('path')\n            if loader == 'schema' and path in self.schemas:\n                return path\n        except HTTPException:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path_to_url(self, path):\n        if path not in self.schemas:\n            return None\n        return self.url_map.bind(\n            self.app.config['JSONSCHEMAS_HOST'],\n            url_scheme=self.app.config['JSONSCHEMAS_URL_SCHEME']\n        ).build(\n            'schema', values={'path': path}, force_external=True)", "response": "Build a URL from a relative path of the schema."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loader_cls(self):\n        cls = self.app.config['JSONSCHEMAS_LOADER_CLS']\n        if isinstance(cls, six.string_types):\n            return import_string(cls)\n        return cls", "response": "Loader class used in JSONRef. replace_refs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_app(self, app, entry_point_group=None, register_blueprint=True,\n                 register_config_blueprint=None):\n        \"\"\"Flask application initialization.\n\n        :param app: The Flask application.\n        :param entry_point_group: The group entry point to load extensions.\n            (Default: ``invenio_jsonschemas.schemas``)\n        :param register_blueprint: Register the blueprints.\n        :param register_config_blueprint: Register blueprint for the specific\n            app from a config variable.\n        \"\"\"\n        self.init_config(app)\n\n        if not entry_point_group:\n            entry_point_group = self.kwargs['entry_point_group'] \\\n                if 'entry_point_group' in self.kwargs \\\n                else 'invenio_jsonschemas.schemas'\n\n        state = InvenioJSONSchemasState(app)\n\n        # Load the json-schemas from extension points.\n        if entry_point_group:\n            for base_entry in pkg_resources.iter_entry_points(\n                    entry_point_group):\n                directory = os.path.dirname(base_entry.load().__file__)\n                state.register_schemas_dir(directory)\n\n        # Init blueprints\n        _register_blueprint = app.config.get(register_config_blueprint)\n        if _register_blueprint is not None:\n            register_blueprint = _register_blueprint\n\n        if register_blueprint:\n            app.register_blueprint(\n                create_blueprint(state),\n                url_prefix=app.config['JSONSCHEMAS_ENDPOINT']\n            )\n\n        self._state = app.extensions['invenio-jsonschemas'] = state\n        return state", "response": "Initializes the Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef alignmentGraph(titlesAlignments, title, addQueryLines=True,\n                   showFeatures=True, logLinearXAxis=False,\n                   logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE, rankScores=False,\n                   colorQueryBases=False, createFigure=True, showFigure=True,\n                   readsAx=None, imageFile=None, quiet=False, idList=False,\n                   xRange='subject', showOrfs=True):\n    \"\"\"\n    Align a set of matching reads against a BLAST or DIAMOND hit.\n\n    @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.\n    @param title: A C{str} sequence title that was matched. We plot the\n        reads that hit this title.\n    @param addQueryLines: if C{True}, draw query lines in full (these will then\n        be partly overdrawn by the HSP match against the subject). These are\n        the 'whiskers' that potentially protrude from each side of a query.\n    @param showFeatures: if C{True}, look online for features of the subject\n        sequence (given by hitId).\n    @param logLinearXAxis: if C{True}, convert read offsets so that empty\n        regions in the plot we're preparing will only be as wide as their\n        logged actual values.\n    @param logBase: The base of the logarithm to use if logLinearXAxis is\n        C{True}.\n    @param: rankScores: If C{True}, change the e-values and bit scores for the\n        reads for each title to be their rank (worst to best).\n    @param colorQueryBases: if C{True}, color each base of a query string. If\n        C{True}, then addQueryLines is meaningless since the whole query is\n        shown colored.\n    @param createFigure: If C{True}, create a figure and give it a title.\n    @param showFigure: If C{True}, show the created figure. Set this to\n        C{False} if you're creating a panel of figures or just want to save an\n        image (with C{imageFile}).\n    @param readsAx: If not None, use this as the subplot for displaying reads.\n    @param imageFile: If not None, specifies a filename to write the image to.\n    @param quiet: If C{True}, don't print progress / timing output.\n    @param idList: a dictionary. The keys is a color and the values is a list\n        of read identifiers that should be colored in the respective color.\n    @param xRange: set to either 'subject' or 'reads' to indicate the range of\n        the X axis.\n    @param showOrfs: If C{True}, open reading frames will be displayed.\n    \"\"\"\n\n    startTime = time()\n\n    assert xRange in ('subject', 'reads'), (\n        'xRange must be either \"subject\" or \"reads\".')\n\n    if createFigure:\n        width = 20\n        figure = plt.figure(figsize=(width, 20))\n\n    createdReadsAx = readsAx is None\n\n    if showFeatures:\n        if showOrfs:\n            gs = gridspec.GridSpec(4, 1, height_ratios=[3, 1, 1, 12])\n            featureAx = plt.subplot(gs[0, 0])\n            orfAx = plt.subplot(gs[1, 0])\n            orfReversedAx = plt.subplot(gs[2, 0])\n            readsAx = readsAx or plt.subplot(gs[3, 0])\n        else:\n            gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1])\n            featureAx = plt.subplot(gs[0, 0])\n            readsAx = readsAx or plt.subplot(gs[1, 0])\n    else:\n        if showOrfs:\n            gs = gridspec.GridSpec(3, 1, height_ratios=[1, 1, 12])\n            orfAx = plt.subplot(gs[0, 0])\n            orfReversedAx = plt.subplot(gs[1, 0])\n            readsAx = readsAx or plt.subplot(gs[2, 0])\n        else:\n            readsAx = readsAx or plt.subplot(111)\n\n    # Make a deep copy of the title alignments. We're potentially going to\n    # change the HSP scores, the X axis offsets, etc., and we don't want to\n    # interfere with the data we were passed.\n    titleAlignments = deepcopy(titlesAlignments[title])\n\n    readsAlignments = titlesAlignments.readsAlignments\n    subjectIsNucleotides = readsAlignments.params.subjectIsNucleotides\n\n    if showOrfs and not subjectIsNucleotides:\n        # We cannot show ORFs when displaying protein plots.\n        showOrfs = False\n\n    # Allow the class of titlesAlignments to adjust HSPs for plotting,\n    # if it has a method for doing so.\n    try:\n        adjuster = readsAlignments.adjustHspsForPlotting\n    except AttributeError:\n        pass\n    else:\n        adjuster(titleAlignments)\n\n    if rankScores:\n        reverse = titlesAlignments.scoreClass is not HigherIsBetterScore\n        for rank, hsp in enumerate(sorted(titleAlignments.hsps(),\n                                   reverse=reverse), start=1):\n            hsp.score.score = rank\n\n    if logLinearXAxis:\n        readIntervals = ReadIntervals(titleAlignments.subjectLength)\n        # Examine all HSPs so we can build an offset adjuster.\n        for hsp in titleAlignments.hsps():\n            readIntervals.add(hsp.readStartInSubject, hsp.readEndInSubject)\n        # Now adjust offsets in all HSPs.\n        offsetAdjuster = OffsetAdjuster(readIntervals, base=logBase)\n        for hsp in titleAlignments.hsps():\n            offsetAdjuster.adjustHSP(hsp)\n        # A function for adjusting other offsets, below.\n        adjustOffset = offsetAdjuster.adjustOffset\n    else:\n        def adjustOffset(offset):\n            return offset\n\n    # It would be more efficient to only walk through all HSPs once and\n    # compute these values all at once, but for now this is simple and clear.\n    maxY = int(ceil(titleAlignments.bestHsp().score.score))\n    minY = int(titleAlignments.worstHsp().score.score)\n    maxX = max(hsp.readEndInSubject for hsp in titleAlignments.hsps())\n    minX = min(hsp.readStartInSubject for hsp in titleAlignments.hsps())\n\n    if xRange == 'subject':\n        # We'll display a graph for the full subject range. Adjust X axis\n        # min/max to make sure we cover at least zero to the sequence length.\n        maxX = max(titleAlignments.subjectLength, maxX)\n        minX = min(0, minX)\n\n    # Swap min & max Y values, if needed, as it's possible we are dealing\n    # with LSPs but that the score adjuster made numerically greater values\n    # for those that were small.\n    if maxY < minY:\n        (maxY, minY) = (minY, maxY)\n\n    if logLinearXAxis:\n        # Adjust minX and maxX if we have gaps at the subject start or end.\n        gaps = list(readIntervals.walk())\n        if gaps:\n            # Check start of first gap:\n            intervalType, (start, stop) = gaps[0]\n            if intervalType == ReadIntervals.EMPTY:\n                adjustedStart = adjustOffset(start)\n                if adjustedStart < minX:\n                    minX = adjustedStart\n            # Check stop of last gap:\n            intervalType, (start, stop) = gaps[-1]\n            if intervalType == ReadIntervals.EMPTY:\n                adjustedStop = adjustOffset(stop)\n                if adjustedStop > maxX:\n                    maxX = adjustedStop\n\n    # We're all set up to start plotting the graph.\n\n    # Add light grey vertical rectangles to show the logarithmic gaps. Add\n    # these first so that reads will be plotted on top of them. Only draw\n    # gaps that are more than SMALLEST_LOGGED_GAP_TO_DISPLAY pixels wide as\n    # we could have millions of tiny gaps for a bacteria and drawing them\n    # all will be slow and only serves to make the entire background grey.\n    if logLinearXAxis and len(offsetAdjuster.adjustments()) < 100:\n        for (intervalType, interval) in readIntervals.walk():\n            if intervalType == ReadIntervals.EMPTY:\n                adjustedStart = adjustOffset(interval[0])\n                adjustedStop = adjustOffset(interval[1])\n                width = adjustedStop - adjustedStart\n                if width >= SMALLEST_LOGGED_GAP_TO_DISPLAY:\n                    readsAx.axvspan(adjustedStart, adjustedStop,\n                                    color='#f4f4f4')\n\n    if colorQueryBases:\n        # Color each query by its bases.\n        xScale = 3\n        yScale = 2\n        baseImage = BaseImage(\n            maxX - minX, maxY - minY + (1 if rankScores else 0),\n            xScale, yScale)\n        for alignment in titleAlignments:\n            for hsp in alignment.hsps:\n                y = hsp.score.score - minY\n                # If the product of the subject and read frame values is +ve,\n                # then they're either both +ve or both -ve, so we just use the\n                # read as is. Otherwise, we need to reverse complement it.\n                if hsp.subjectFrame * hsp.readFrame > 0:\n                    query = alignment.read.sequence\n                else:\n                    # One of the subject or query has negative sense.\n                    query = alignment.read.reverseComplement().sequence\n                readStartInSubject = hsp.readStartInSubject\n                # There are 3 parts of the query string we need to\n                # display. 1) the left part (if any) before the matched\n                # part of the subject.  2) the matched part (which can\n                # include gaps in the query and/or subject). 3) the right\n                # part (if any) after the matched part.  For each part,\n                # calculate the ranges in which we have to make the\n                # comparison between subject and query.\n\n                # NOTE: never use hsp['origHsp'].gaps to calculate the number\n                # of gaps, as this number contains gaps in both subject and\n                # query.\n\n                # 1. Left part:\n                leftRange = hsp.subjectStart - readStartInSubject\n\n                # 2. Match, middle part:\n                middleRange = len(hsp.readMatchedSequence)\n\n                # 3. Right part:\n                # Using hsp.readEndInSubject - hsp.subjectEnd to calculate the\n                # length of the right part leads to the part being too long.\n                # The number of gaps needs to be subtracted to get the right\n                # length.\n                origQuery = hsp.readMatchedSequence.upper()\n                rightRange = (hsp.readEndInSubject - hsp.subjectEnd -\n                              origQuery.count('-'))\n\n                # 1. Left part.\n                xOffset = readStartInSubject - minX\n                queryOffset = 0\n                for queryIndex in range(leftRange):\n                    color = QUERY_COLORS.get(query[queryOffset + queryIndex],\n                                             DEFAULT_BASE_COLOR)\n                    baseImage.set(xOffset + queryIndex, y, color)\n\n                # 2. Match part.\n                xOffset = hsp.subjectStart - minX\n                xIndex = 0\n                queryOffset = hsp.subjectStart - hsp.readStartInSubject\n                origSubject = hsp.subjectMatchedSequence\n                for matchIndex in range(middleRange):\n                    if origSubject[matchIndex] == '-':\n                        # A gap in the subject was needed to match the query.\n                        # In our graph we keep the subject the same even in the\n                        # case where BLAST opened gaps in it, so we compensate\n                        # for the gap in the subject by not showing this base\n                        # of the query.\n                        pass\n                    else:\n                        if origSubject[matchIndex] == origQuery[matchIndex]:\n                            # The query matched the subject at this location.\n                            # Matching bases are all colored in the same\n                            # 'match' color.\n                            color = QUERY_COLORS['match']\n                        else:\n                            if origQuery[matchIndex] == '-':\n                                # A gap in the query. All query gaps get the\n                                # same 'gap' color.\n                                color = QUERY_COLORS['gap']\n                            else:\n                                # Query doesn't match subject (and is not a\n                                # gap).\n                                color = QUERY_COLORS.get(origQuery[matchIndex],\n                                                         DEFAULT_BASE_COLOR)\n                        baseImage.set(xOffset + xIndex, y, color)\n                        xIndex += 1\n\n                # 3. Right part.\n                xOffset = hsp.subjectEnd - minX\n                backQuery = query[-rightRange:].upper()\n                for queryIndex in range(rightRange):\n                    color = QUERY_COLORS.get(backQuery[queryIndex],\n                                             DEFAULT_BASE_COLOR)\n                    baseImage.set(xOffset + queryIndex, y, color)\n\n        readsAx.imshow(baseImage.data, aspect='auto', origin='lower',\n                       interpolation='nearest',\n                       extent=[minX, maxX, minY, maxY])\n    else:\n        # Add horizontal lines for all the query sequences. These will be the\n        # grey 'whiskers' in the plots once we (below) draw the matched part\n        # on top of part of them.\n        if addQueryLines:\n            for hsp in titleAlignments.hsps():\n                y = hsp.score.score\n                line = Line2D([hsp.readStartInSubject, hsp.readEndInSubject],\n                              [y, y], color='#aaaaaa')\n                readsAx.add_line(line)\n\n        # Add the horizontal BLAST alignment lines.\n\n        # If an idList is given set things up to look up read colors.\n        readColor = {}\n        if idList:\n            for color, reads in idList.items():\n                for read in reads:\n                    if read in readColor:\n                        raise ValueError('Read %s is specified multiple '\n                                         'times in idList' % read)\n                    else:\n                        readColor[read] = color\n\n        # Draw the matched region.\n        for titleAlignment in titleAlignments:\n            readId = titleAlignment.read.id\n            for hsp in titleAlignment.hsps:\n                y = hsp.score.score\n                line = Line2D([hsp.subjectStart, hsp.subjectEnd], [y, y],\n                              color=readColor.get(readId, 'blue'))\n                readsAx.add_line(line)\n\n    if showOrfs:\n        subject = readsAlignments.getSubjectSequence(title)\n        orfs.addORFs(orfAx, subject.sequence, minX, maxX, adjustOffset)\n        orfs.addReversedORFs(orfReversedAx,\n                             subject.reverseComplement().sequence,\n                             minX, maxX, adjustOffset)\n\n    if showFeatures:\n        if subjectIsNucleotides:\n            featureAdder = NucleotideFeatureAdder()\n        else:\n            featureAdder = ProteinFeatureAdder()\n\n        features = featureAdder.add(featureAx, title, minX, maxX,\n                                    adjustOffset)\n\n        # If there are features and there weren't too many of them, add\n        # vertical feature lines to the reads and ORF axes.\n        if features and not featureAdder.tooManyFeaturesToPlot:\n            for feature in features:\n                start = feature.start\n                end = feature.end\n                color = feature.color\n                readsAx.axvline(x=start, color=color)\n                readsAx.axvline(x=end, color='#cccccc')\n                if showOrfs:\n                    orfAx.axvline(x=start, color=color)\n                    orfAx.axvline(x=end, color='#cccccc')\n                    orfReversedAx.axvline(x=start, color=color)\n                    orfReversedAx.axvline(x=end, color='#cccccc')\n    else:\n        features = None\n\n    # We'll return some information we've gathered.\n    result = {\n        'adjustOffset': adjustOffset,\n        'features': features,\n        'minX': minX,\n        'maxX': maxX,\n        'minY': minY,\n        'maxY': maxY,\n    }\n\n    # Allow the class of titlesAlignments to add to the plot, if it has a\n    # method for doing so.\n    try:\n        adjuster = readsAlignments.adjustPlot\n    except AttributeError:\n        pass\n    else:\n        adjuster(readsAx)\n\n    # Titles, axis, etc.\n    if createFigure:\n        readCount = titleAlignments.readCount()\n        hspCount = titleAlignments.hspCount()\n        figure.suptitle(\n            '%s\\nLength %d %s, %d read%s, %d HSP%s.' %\n            (\n                fill(titleAlignments.subjectTitle, 80),\n                titleAlignments.subjectLength,\n                'nt' if subjectIsNucleotides else 'aa',\n                readCount, '' if readCount == 1 else 's',\n                hspCount, '' if hspCount == 1 else 's'\n            ),\n            fontsize=20)\n\n    # Add a title and y-axis label, but only if we made the reads axes.\n    if createdReadsAx:\n        readsAx.set_title('Read alignments', fontsize=20)\n        ylabel = readsAlignments.params.scoreTitle\n        if rankScores:\n            ylabel += ' rank'\n        plt.ylabel(ylabel, fontsize=17)\n\n    # Set the x-axis limits.\n    readsAx.set_xlim([minX - 1, maxX + 1])\n\n    readsAx.set_ylim([0, int(maxY * Y_AXIS_UPPER_PADDING)])\n    readsAx.grid()\n    if createFigure:\n        if showFigure:\n            plt.show()\n        if imageFile:\n            figure.savefig(imageFile)\n    stop = time()\n    if not quiet:\n        report('Graph generated in %.3f mins.' % ((stop - startTime) / 60.0))\n\n    return result", "response": "Align a set of matching reads against a subject."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef alignmentPanel(titlesAlignments, sortOn='maxScore', idList=False,\n                   equalizeXAxes=False, xRange='subject', logLinearXAxis=False,\n                   rankScores=False, showFeatures=True,\n                   logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE):\n    \"\"\"\n    Produces a rectangular panel of graphs that each contain an alignment graph\n    against a given sequence.\n\n    @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.\n    @param sortOn: The attribute to sort subplots on. Either \"maxScore\",\n        \"medianScore\", \"readCount\", \"length\", or \"title\".\n    @param idList: A dictionary. Keys are colors and values are lists of read\n        ids that should be colored using that color.\n    @param equalizeXAxes: If C{True}, adjust the X axis on each alignment plot\n        to be the same.\n    @param xRange: Set to either 'subject' or 'reads' to indicate the range of\n        the X axis.\n    @param logLinearXAxis: If C{True}, convert read offsets so that empty\n        regions in the plots we're preparing will only be as wide as their\n        logged actual values.\n    @param logBase: The logarithm base to use if logLinearXAxis is C{True}.\n    @param: rankScores: If C{True}, change the scores for the reads for each\n        title to be their rank (worst to best).\n    @param showFeatures: If C{True}, look online for features of the subject\n        sequences.\n    @raise ValueError: If C{outputDir} exists but is not a directory or if\n        C{xRange} is not \"subject\" or \"reads\".\n    \"\"\"\n\n    if xRange not in ('subject', 'reads'):\n        raise ValueError('xRange must be either \"subject\" or \"reads\".')\n\n    start = time()\n    titles = titlesAlignments.sortTitles(sortOn)\n    cols = 5\n    rows = int(len(titles) / cols) + (0 if len(titles) % cols == 0 else 1)\n    figure, ax = plt.subplots(rows, cols, squeeze=False)\n    allGraphInfo = {}\n    coords = dimensionalIterator((rows, cols))\n\n    report('Plotting %d titles in %dx%d grid, sorted on %s' %\n           (len(titles), rows, cols, sortOn))\n\n    for i, title in enumerate(titles):\n        titleAlignments = titlesAlignments[title]\n        row, col = next(coords)\n        report('%d: %s %s' % (i, title, NCBISequenceLinkURL(title, '')))\n\n        # Add a small plot to the alignment panel.\n        graphInfo = alignmentGraph(\n            titlesAlignments, title, addQueryLines=True,\n            showFeatures=showFeatures, rankScores=rankScores,\n            logLinearXAxis=logLinearXAxis, logBase=logBase,\n            colorQueryBases=False, createFigure=False, showFigure=False,\n            readsAx=ax[row][col], quiet=True, idList=idList, xRange=xRange,\n            showOrfs=False)\n\n        allGraphInfo[title] = graphInfo\n        readCount = titleAlignments.readCount()\n        hspCount = titleAlignments.hspCount()\n\n        # Make a short title for the small panel blue plot, ignoring any\n        # leading NCBI gi / accession numbers.\n        if title.startswith('gi|') and title.find(' ') > -1:\n            shortTitle = title.split(' ', 1)[1][:40]\n        else:\n            shortTitle = title[:40]\n\n        plotTitle = ('%d: %s\\nLength %d, %d read%s, %d HSP%s.' % (\n            i, shortTitle, titleAlignments.subjectLength,\n            readCount, '' if readCount == 1 else 's',\n            hspCount, '' if hspCount == 1 else 's'))\n\n        if hspCount:\n            if rankScores:\n                plotTitle += '\\nY axis is ranked score'\n            else:\n                plotTitle += '\\nmax %.2f, median %.2f' % (\n                    titleAlignments.bestHsp().score.score,\n                    titleAlignments.medianScore())\n\n        ax[row][col].set_title(plotTitle, fontsize=10)\n\n    maxX = max(graphInfo['maxX'] for graphInfo in allGraphInfo.values())\n    minX = min(graphInfo['minX'] for graphInfo in allGraphInfo.values())\n    maxY = max(graphInfo['maxY'] for graphInfo in allGraphInfo.values())\n    minY = min(graphInfo['minY'] for graphInfo in allGraphInfo.values())\n\n    # Post-process graphs to adjust axes, etc.\n\n    coords = dimensionalIterator((rows, cols))\n    for title in titles:\n        titleAlignments = titlesAlignments[title]\n        row, col = next(coords)\n        a = ax[row][col]\n        a.set_ylim([0, int(maxY * Y_AXIS_UPPER_PADDING)])\n        if equalizeXAxes:\n            a.set_xlim([minX, maxX])\n        a.set_yticks([])\n        a.set_xticks([])\n\n        if xRange == 'subject' and minX < 0:\n            # Add a vertical line at x=0 so we can see the 'whiskers' of\n            # reads that extend to the left of the sequence we're aligning\n            # against.\n            a.axvline(x=0, color='#cccccc')\n\n        # Add a line on the right of each sub-plot so we can see where the\n        # sequence ends (as all panel graphs have the same width and we\n        # otherwise couldn't tell).\n        sequenceLen = titleAlignments.subjectLength\n        if logLinearXAxis:\n            sequenceLen = allGraphInfo[title]['adjustOffset'](sequenceLen)\n        a.axvline(x=sequenceLen, color='#cccccc')\n\n    # Hide the final panel graphs (if any) that have no content. We do this\n    # because the panel is a rectangular grid and some of the plots at the\n    # end of the last row may be unused.\n    for row, col in coords:\n        ax[row][col].axis('off')\n\n    # plt.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.93,\n    # wspace=0.1, hspace=None)\n    plt.subplots_adjust(hspace=0.4)\n    figure.suptitle('X: %d to %d, Y (%s): %d to %d' %\n                    (minX, maxX,\n                     titlesAlignments.readsAlignments.params.scoreTitle,\n                     int(minY), int(maxY)), fontsize=20)\n    figure.set_size_inches(5 * cols, 3 * rows, forward=True)\n    figure.show()\n    stop = time()\n    report('Alignment panel generated in %.3f mins.' % ((stop - start) / 60.0))", "response": "Generates a rectangular panel of graphs that each contain an alignment graph with a given set of titles."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate an alignment panel HTML file in the output directory and a collection of alignmentTrees and FASTA files.", "response": "def alignmentPanelHTML(titlesAlignments, sortOn='maxScore',\n                       outputDir=None, idList=False, equalizeXAxes=False,\n                       xRange='subject', logLinearXAxis=False,\n                       logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,\n                       rankScores=False, showFeatures=True, showOrfs=True):\n    \"\"\"\n    Produces an HTML index file in C{outputDir} and a collection of alignment\n    graphs and FASTA files to summarize the information in C{titlesAlignments}.\n\n    @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.\n    @param sortOn: The attribute to sort subplots on. Either \"maxScore\",\n        \"medianScore\", \"readCount\", \"length\", or \"title\".\n    @param outputDir: Specifies a C{str} directory to write the HTML to. If\n        the directory does not exist it will be created.\n    @param idList: A dictionary. Keys are colors and values are lists of read\n        ids that should be colored using that color.\n    @param equalizeXAxes: If C{True}, adjust the X axis on each alignment plot\n        to be the same.\n    @param xRange: Set to either 'subject' or 'reads' to indicate the range of\n        the X axis.\n    @param logLinearXAxis: If C{True}, convert read offsets so that empty\n        regions in the plots we're preparing will only be as wide as their\n        logged actual values.\n    @param logBase: The logarithm base to use if logLinearXAxis is C{True}.\n    @param: rankScores: If C{True}, change the scores for the reads for each\n        title to be their rank (worst to best).\n    @param showFeatures: If C{True}, look online for features of the subject\n        sequences.\n    @param showOrfs: If C{True}, open reading frames will be displayed.\n    @raise TypeError: If C{outputDir} is C{None}.\n    @raise ValueError: If C{outputDir} is None or exists but is not a\n        directory or if C{xRange} is not \"subject\" or \"reads\".\n    \"\"\"\n\n    if xRange not in ('subject', 'reads'):\n        raise ValueError('xRange must be either \"subject\" or \"reads\".')\n\n    if equalizeXAxes:\n        raise NotImplementedError('This feature is not yet implemented.')\n\n    titles = titlesAlignments.sortTitles(sortOn)\n\n    if os.access(outputDir, os.F_OK):\n        # outputDir exists. Check it's a directory.\n        if not S_ISDIR(os.stat(outputDir).st_mode):\n            raise ValueError(\"%r is not a directory.\" % outputDir)\n    else:\n        if outputDir is None:\n            raise ValueError(\"The outputDir needs to be specified.\")\n        else:\n            os.mkdir(outputDir)\n\n    htmlWriter = AlignmentPanelHTMLWriter(outputDir, titlesAlignments)\n\n    for i, title in enumerate(titles):\n        # titleAlignments = titlesAlignments[title]\n\n        # If we are writing data to a file too, create a separate file with\n        # a plot (this will be linked from the summary HTML).\n        imageBasename = '%d.png' % i\n        imageFile = '%s/%s' % (outputDir, imageBasename)\n        graphInfo = alignmentGraph(\n            titlesAlignments, title, addQueryLines=True,\n            showFeatures=showFeatures, rankScores=rankScores,\n            logLinearXAxis=logLinearXAxis, logBase=logBase,\n            colorQueryBases=False, showFigure=False, imageFile=imageFile,\n            quiet=True, idList=idList, xRange=xRange, showOrfs=showOrfs)\n\n        # Close the image plot to make sure memory is flushed.\n        plt.close()\n        htmlWriter.addImage(imageBasename, title, graphInfo)\n\n    htmlWriter.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a rectangular panel of graphs that shows the scores of each read sequence in a given set of titles.", "response": "def scoreGraph(titlesAlignments, find=None, showTitles=False, figureWidth=5,\n               figureHeight=5):\n    \"\"\"\n    NOTE: This function has probably bit rotted (but only a little).\n\n    Produce a rectangular panel of graphs, each of which shows sorted scores\n    for a title. Matches against a certain sequence title, as determined by\n    C{find}, (see below) are highlighted.\n\n    @param find: A function that can be passed a sequence title. If the\n        function returns C{True} a red dot is put into the graph at that point\n        to highlight the match.\n    @param showTitles: If C{True} display read sequence names. The panel tends\n        to look terrible when titles are displayed. If C{False}, show no title.\n    @param figureWidth: The C{float} width of the figure, in inches.\n    @param figureHeight: The C{float} height of the figure, in inches.\n    \"\"\"\n    maxScore = None\n    maxHsps = 0\n    cols = 5\n    rows = int(len(titlesAlignments) / cols) + (\n        0 if len(titlesAlignments) % cols == 0 else 1)\n    f, ax = plt.subplots(rows, cols)\n    coords = dimensionalIterator((rows, cols))\n\n    for title in titlesAlignments:\n        titleAlignments = titlesAlignments[title]\n        row, col = next(coords)\n        hspCount = titleAlignments.hspCount()\n        if hspCount > maxHsps:\n            maxHsps = hspCount\n        scores = []\n        highlightX = []\n        highlightY = []\n        for x, titleAlignment in enumerate(titleAlignments):\n            score = titleAlignment.hsps[0].score.score\n            scores.append(score)\n            if find and find(titleAlignment.subjectTitle):\n                highlightX.append(x)\n                highlightY.append(score)\n        a = ax[row][col]\n        if scores:\n            max_ = max(scores)\n            if maxScore is None or max_ > maxScore:\n                maxScore = max_\n            x = np.arange(0, len(scores))\n            a.plot(x, scores)\n        if highlightX:\n            a.plot(highlightX, highlightY, 'ro')\n        if showTitles:\n            a.set_title('%s' % title, fontsize=10)\n\n    # Adjust all plots to have the same dimensions.\n    coords = dimensionalIterator((rows, cols))\n    for _ in range(len(titlesAlignments)):\n        row, col = next(coords)\n        a = ax[row][col]\n        a.axis([0, maxHsps, 0, maxScore])\n        # a.set_yscale('log')\n        a.set_yticks([])\n        a.set_xticks([])\n\n    # Hide the final panel graphs (if any) that have no content. We do this\n    # because the panel is a rectangular grid and some of the plots at the\n    # end of the last row may be unused.\n    for row, col in coords:\n        ax[row][col].axis('off')\n\n    plt.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.93,\n                        wspace=0.1, hspace=None)\n    f.suptitle('max HSPs %d, max score %f' % (maxHsps, maxScore))\n    f.set_size_inches(figureWidth, figureHeight, forward=True)\n    # f.savefig('scores.png')\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plotAAProperties(sequence, propertyNames, showLines=True, showFigure=True):\n    MISSING_AA_VALUE = -1.1\n    propertyValues = propertiesForSequence(sequence, propertyNames,\n                                           missingAAValue=MISSING_AA_VALUE)\n    if showFigure:\n        legend = []\n        x = np.arange(0, len(sequence))\n        plot = plt.plot if showLines else plt.scatter\n\n        for index, propertyName in enumerate(propertyValues):\n            color = TABLEAU20[index]\n            plot(x, propertyValues[propertyName], color=color)\n            legend.append(patches.Patch(color=color, label=propertyName))\n\n        plt.legend(handles=legend, loc=(0, 1.1))\n        plt.xlim(-0.2, len(sequence) - 0.8)\n        plt.ylim(min(MISSING_AA_VALUE, -1.1), 1.1)\n        plt.xlabel('Sequence index')\n        plt.ylabel('Property value')\n        plt.title(sequence.id)\n        plt.show()\n\n    return propertyValues", "response": "Plots amino acid properties for a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plotAAClusters(sequence, propertyNames, showLines=True, showFigure=True):\n    MISSING_AA_VALUE = 0\n    propertyClusters = clustersForSequence(sequence, propertyNames,\n                                           missingAAValue=MISSING_AA_VALUE)\n    if showFigure:\n        minCluster = 1\n        maxCluster = -1\n        legend = []\n        x = np.arange(0, len(sequence))\n        plot = plt.plot if showLines else plt.scatter\n\n        for index, propertyName in enumerate(propertyClusters):\n            color = TABLEAU20[index]\n            clusterNumbers = propertyClusters[propertyName]\n            plot(x, clusterNumbers, color=color)\n            legend.append(patches.Patch(color=color, label=propertyName))\n\n            propertyMinCluster = min(clusterNumbers)\n            if propertyMinCluster < minCluster:\n                minCluster = propertyMinCluster\n\n            propertyMaxCluster = max(clusterNumbers)\n            if propertyMaxCluster > maxCluster:\n                maxCluster = propertyMaxCluster\n\n        plt.legend(handles=legend, loc=(0, 1.1))\n        plt.xlim(-0.2, len(sequence) - 0.8)\n        plt.ylim(minCluster - 0.5, maxCluster + 0.5)\n        plt.yticks(range(maxCluster + 1))\n        plt.xlabel('Sequence index')\n        plt.ylabel('Property cluster number')\n        plt.title(sequence.id)\n        plt.show()\n\n    return propertyClusters", "response": "Plots amino acid property cluster numbers for a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreversing the byte order of an input bit - vector bv_di and bv_do.", "response": "def byteorder(bv_di, bv_do, REVERSE=True):\n    \"\"\" Reverses the byte order of an input bit-vector\n            bv_di - (i) input bit-vector\n            bv_do - (o) output bit-vector\n    \"\"\"\n    BITS  = len(bv_di)\n\n    assert (BITS % 8)==0, \"byteorder: expects len(bv_in)=8*x, but len(bv_in)={}\".format(BITS)\n\n    if REVERSE:\n        BYTES = BITS//8\n        y = ConcatSignal(*[bv_di(8*(b+1),8*b) for b in range(BYTES)])\n\n        @always_comb\n        def _reverse():\n            bv_do.next = y\n\n    else:\n        @always_comb\n        def _pass():\n            bv_do.next = bv_di\n\n    return instances()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef task_loop(tasks, execute, wait=None, store=TaskStore()):\n    completed = set()\n    failed = set()\n    exceptions = []\n\n    def collect(task):\n        args = []\n        kwargs = {}\n\n        for arg in task.args:\n            if isinstance(arg, Task):\n                args.append(store.get(arg.name))\n            else:\n                args.append(arg)\n\n        for key in task.kwargs:\n            if isinstance(task.kwargs[key], Task):\n                kwargs[key] = store.get(task.kwargs[key].name)\n            else:\n                kwargs[key] = task.kwargs[key]\n\n        return args, kwargs\n\n    def complete(scheduler, result):\n        store.put(result.name, result.data)\n        scheduler.end_task(result.name, result.successful)\n        if result.exception:\n            exceptions.append(result.exception)\n\n    with Scheduler(tasks, completed=completed, failed=failed) as scheduler:\n        while not scheduler.is_finished():\n            task = scheduler.start_task()\n\n            while task is not None:\n                # Collect any dependent results\n                args, kwargs = collect(task)\n                func = partial(task.function, *args, **kwargs)\n                if task.handler:\n                    func = partial(task.handler, func)\n\n                result = execute(func, task.name)\n\n                # result exists iff execute is synchroous\n                if result:\n                    complete(scheduler, result)\n\n                task = scheduler.start_task()\n\n            if wait:\n                for result in wait():\n                    complete(scheduler, result)\n\n    # TODO: if in debug mode print out all failed tasks?\n    return Results(completed, failed, exceptions)", "response": "The inner task loop for a task runner."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef findOrDie(s):\n    aa = find(s)\n    if aa:\n        return aa\n    else:\n        print('Unknown amino acid or codon: %s' % s, file=sys.stderr)\n        print('Valid arguments are: %s.' % list(CODONS.keys()),\n              file=sys.stderr)\n        sys.exit(1)", "response": "Look up an amino acid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef http_download(url, download_file,\n                  overwrite=False, raise_http_exception=True):\n    \"\"\"Download a file over HTTP(S).\n    \n    See: http://stackoverflow.com/a/13137873/5651021 \n\n    Parameters\n    ----------\n    url : str\n        The URL.\n    download_file : str\n        The path of the local file to write to.\n    overwrite : bool, optional\n        Whether to overwrite an existing file (if present). [False]\n    raise_http_exception : bool, optional\n        Whether to raise an exception if there is an HTTP error. [True]\n\n    Raises\n    ------\n    OSError\n        If the file already exists and overwrite is set to False.\n    `requests.HTTPError`\n        If an HTTP error occurred and `raise_http_exception` was set to `True`.\n    \"\"\"\n\n    assert isinstance(url, (str, _oldstr))\n    assert isinstance(download_file, (str, _oldstr))\n    assert isinstance(overwrite, bool)\n    assert isinstance(raise_http_exception, bool)\n\n    u = urlparse.urlparse(url)\n    assert u.scheme in ['http', 'https']\n\n    if os.path.isfile(download_file) and not overwrite:\n        raise OSError('File \"%s\" already exists!' % download_file)\n    \n    r = requests.get(url, stream=True)\n    if raise_http_exception:\n        r.raise_for_status()\n    if r.status_code == 200:\n        with open(download_file, 'wb') as fh:\n            r.raw.decode_content = True\n            shutil.copyfileobj(r.raw, fh)\n        _logger.info('Downloaded file \"%s\".', download_file)\n    else:\n        _logger.error('Failed to download url \"%s\": HTTP status %d/%s',\n                      url, r.status_code, r.reason)", "response": "Download a file over HTTP."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ftp_download(url, download_file, if_exists='error',\n                 user_name='anonymous', password='', blocksize=4194304):\n    \"\"\"Downloads a file from an FTP server.\n\n    Parameters\n    ----------\n    url : str\n        The URL of the file to download.\n    download_file : str\n        The path of the local file to download to. \n    if_exists : str, optional\n        Desired behavior when the download file already exists. One of:\n          'error'     - Raise an OSError\n          'skip'      - Do nothing, only report a warning.\n          'overwrite' - Overwrite the file. reporting a warning.\n        Default: 'error'.\n    user_name : str, optional\n        The user name to use for logging into the FTP server. ['anonymous']\n    password : str, optional\n        The password to use for logging into the FTP server. ['']\n    blocksize : int, optional\n        The blocksize (in bytes) to use for downloading. [4194304]\n\n    Returns\n    -------\n    None\n    \"\"\"\n    assert isinstance(url, (str, _oldstr))\n    assert isinstance(download_file, (str, _oldstr))\n    assert isinstance(if_exists, (str, _oldstr))\n    assert isinstance(user_name, (str, _oldstr))\n    assert isinstance(password, (str, _oldstr))\n\n    u = urlparse.urlparse(url)\n    assert u.scheme == 'ftp'\n\n    if if_exists not in ['error', 'skip', 'overwrite']:\n        raise ValueError('\"if_exists\" must be \"error\", \"skip\", or \"overwrite\" '\n                         '(was: \"%s\").', str(if_exists))\n\n    if os.path.isfile(download_file):\n        if if_exists == 'error':\n            raise OSError('File \"%s\" already exists.' % download_file)\n        elif if_exists == 'skip':\n            _logger.warning('File \"%s\" already exists. Skipping...',\n                            download_file)\n            return\n        else:\n            _logger.warning('Overwriting file \"%s\"...', download_file)\n\n    ftp_server = u.netloc\n    ftp_path = u.path\n\n    if six.PY3:\n        with ftplib.FTP(ftp_server) as ftp:\n            ftp.login(user_name, password)\n            with open(download_file, 'wb') as ofh:\n                ftp.retrbinary('RETR %s' % ftp_path,\n                               callback=ofh.write, blocksize=blocksize)\n    else:\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(user_name, password)\n        with open(download_file, 'wb') as ofh:\n            ftp.retrbinary('RETR %s' % ftp_path,\n                           callback=ofh.write, blocksize=blocksize)\n        ftp.close()\n\n    _logger.info('Downloaded file \"%s\" over FTP.', download_file)", "response": "Downloads a file from an FTP server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cdna_url(species, release=None, ftp=None):\n    #species_list, release=None, ftp=None\n\n    # type checks\n    assert isinstance(species, (str, _oldstr))\n    if release is not None:\n        assert isinstance(release, int)\n    if ftp is not None:\n        assert isinstance(ftp, ftplib.FTP)\n\n    # open FTP connection, if necessary\n    close_connection = False\n    if ftp is None:\n        ftp_server = 'ftp.ensembl.org'\n        ftp_user = 'anonymous'\n        ftp = ftplib.FTP(ftp_server)\n        ftp.login(ftp_user)\n        close_connection = True\n\n    # determine latest release, if necessary\n    if release is None:\n        release = util.get_latest_release(ftp=ftp)\n    \n    # check if species exists\n    fasta_dir = '/pub/release-%d/fasta' % release \n    ftp.cwd(fasta_dir)\n    if not species in ftp.nlst():\n        logger.error('Species \"%s\" not found on Ensembl FTP server.', species)\n        fasta_url = 'ftp://%s%s' %(ftp_server, fasta_dir)\n        raise ValueError('Species \"%s\" not found. '\n                         'See %s for a list of species available.'\n                         % (species, fasta_url))\n\n    # determine URL of the cdna file\n    # (file names are not consistent across species)\n    cdna_dir = '/pub/release-%d/fasta/%s/cdna' %(release, species)\n    ftp.cwd(cdna_dir)\n    files = ftp.nlst()\n    cdna_file = [f for f in files if f.endswith('.cdna.all.fa.gz')][0]\n    cdna_url = 'ftp://%s%s/%s' %(ftp_server, cdna_dir, cdna_file)\n\n    # close FTP connection, if we opened it\n    if close_connection:\n        ftp.close()\n\n    return cdna_url", "response": "Returns the URL for a cDNA file hosted on the Ensembl FTP server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_pickle(self, path, compress=False):\n        logger.info('Writing pickle to \"%s\"...', path)\n        if compress:\n            with gzip.open(path, 'wb') as ofh:\n                pickle.dump(self, ofh, pickle.HIGHEST_PROTOCOL)\n        else:\n            with open(path, 'wb') as ofh:\n                pickle.dump(self, ofh, pickle.HIGHEST_PROTOCOL)", "response": "Serialize the current GOParser object and store it in a pickle file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_pickle(fn):\n        with misc.open_plain_or_gzip(fn, 'rb') as fh:\n            parser = pickle.load(fh)\n        return parser", "response": "Load a GOParser object from a pickle file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the GO term with the given name.", "response": "def get_term_by_name(self, name):\n        \"\"\"Get the GO term with the given GO term name.\n\n        If the given name is not associated with any GO term, the function will\n        search for it among synonyms.\n\n        Parameters\n        ----------\n        name: str\n            The name of the GO term.\n\n        Returns\n        -------\n        `GOTerm`\n            The GO term with the given name.\n\n        Raises\n        ------\n        ValueError\n            If the given name is found neither among the GO term names, nor\n            among synonyms.\n        \"\"\"\n        term = None\n        try:\n            term = self.terms[self.name2id[name]]\n        except KeyError:\n            try:\n                term = self.terms[self.syn2id[name]]\n            except KeyError:\n                pass\n            else:\n                logger.info('GO term name \"%s\" is a synonym for \"%s\".',\n                            name, term.name)\n\n        if term is None:\n            raise ValueError('GO term name \"%s\" not found!' % name)\n\n        return term"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an OBO file and store GO term information.", "response": "def read_obo(cls, path, flatten=True, part_of_cc_only=False):\n        \"\"\" Parse an OBO file and store GO term information.\n\n        Parameters\n        ----------\n        path: str\n            Path of the OBO file.\n        flatten: bool, optional\n            If set to False, do not generate a list of all ancestors and\n            descendants for each GO term.\n        part_of_cc_only: bool, optional\n            Legacy parameter for backwards compatibility. If set to True,\n            ignore ``part_of`` relations outside the ``cellular_component``\n            domain.\n\n        Notes\n        -----\n        The OBO file must end with a line break.\n        \"\"\"\n\n        name2id = {}\n        alt_id = {}\n        syn2id = {}\n        terms = []\n\n        with open(path) as fh:\n            n = 0\n            while True:\n                try:\n                    nextline = next(fh)\n                except StopIteration:\n                    break\n                if nextline == '[Term]\\n':\n                    n += 1\n                    id_ = next(fh)[4:-1]\n                    # acc = get_acc(id_)\n                    name = next(fh)[6:-1]\n                    name2id[name] = id_\n                    domain = next(fh)[11:-1]\n                    def_ = None\n                    is_a = set()\n                    part_of = set()\n                    l = next(fh)\n                    while l != '\\n':\n                        if l.startswith('alt_id:'):\n                            alt_id[l[8:-1]] = id_\n                        elif l.startswith('def: '):\n                            idx = l[6:].index('\"')\n                            def_ = l[6:(idx+6)]\n                        elif l.startswith('is_a:'):\n                            is_a.add(l[6:16])\n                        elif l.startswith('synonym:'):\n                            idx = l[10:].index('\"')\n                            if l[(10+idx+2):].startswith(\"EXACT\"):\n                                s = l[10:(10+idx)]\n                                syn2id[s] = id_\n                        elif l.startswith('relationship: part_of'):\n                            if part_of_cc_only:\n                                if domain == 'cellular_component':\n                                    part_of.add(l[22:32])\n                            else:\n                                part_of.add(l[22:32])\n                        l = next(fh)\n                    assert def_ is not None\n                    terms.append(GOTerm(id_, name, domain, def_, is_a, part_of))\n\n        logger.info('Parsed %d GO term definitions.', n)\n\n        ontology = cls(terms, syn2id, alt_id, name2id)\n\n        # store children and parts\n        logger.info('Adding child and part relationships...')\n        for term in ontology:\n            for parent in term.is_a:\n                ontology[parent].children.add(term.id)\n            for whole in term.part_of:\n                ontology[whole].parts.add(term.id)\n\n        if flatten:\n            logger.info('Flattening ancestors...')\n            ontology._flatten_ancestors()\n            logger.info('Flattening descendants...')\n            ontology._flatten_descendants()\n            ontology._flattened = True\n\n        return ontology"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _flatten_descendants(self, include_parts=True):\n        def get_all_descendants(term):\n            descendants = set()\n            for id_ in term.children:\n                descendants.add(id_)\n                descendants.update(get_all_descendants(self[id_]))\n            if include_parts:\n                for id_ in term.parts:\n                    descendants.add(id_)\n                    descendants.update(get_all_descendants(self[id_]))\n            return descendants\n\n        for term in self:\n            term.descendants = get_all_descendants(term)", "response": "Determines and stores all descendants of each GO term."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_instance(self, credentials, name, **kwargs):\n        op_name = create_instance(\n            credentials, self.project, self.zone, name,\n            machine_type=self.machine_type,\n            disk_size_gb=self.disk_size_gb,\n            **kwargs)\n        \n        return op_name", "response": "Create an instance based on the configuration data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting an instance based on the configuration data.", "response": "def delete_instance(self, credentials, name, **kwargs):\n        \"\"\"Delete an instance based on the configuration data.\n        \n        TODO: docstring\"\"\"\n        op_name = delete_instance(\n            credentials, self.project, self.zone, name, **kwargs)\n\n        return op_name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_for_instance_deletion(self, credentials, name, **kwargs):\n        op_name = wait_for_instance_deletion(\n            credentials, self.project, self.zone, name, **kwargs)\n\n        return op_name", "response": "Wait for deletion of an instance based on the configuration data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the names of available cytoband data files", "response": "def get_cytoband_names():\n    \"\"\"Returns the names of available cytoband data files\n\n    >> get_cytoband_names()\n    ['ucsc-hg38', 'ucsc-hg19']\n    \"\"\"\n    return [\n        n.replace(\".json.gz\", \"\")\n        for n in pkg_resources.resource_listdir(__name__, _data_dir)\n        if n.endswith(\".json.gz\")\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_cytoband_map(name):\n    fn = pkg_resources.resource_filename(\n        __name__, _data_path_fmt.format(name=name))\n    return json.load(gzip.open(fn, mode=\"rt\", encoding=\"utf-8\"))", "response": "Fetch one cytoband map by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cytoband_maps(names=[]):\n    if names == []:\n        names = get_cytoband_names()\n    return {name: get_cytoband_map(name) for name in names}", "response": "Load all cytoband maps"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_relative_file_path(absolute_file_path):\n    '''\n    Example:\n    absolute_file_path = \"/home/xxx/Dev/openfisca/openfisca-france/openfisca_france/param/param.xml\"\n    result = \"openfisca_france/param/param.xml\"\n    '''\n    global country_package_dir_path\n    assert country_package_dir_path is not None\n    relative_file_path = absolute_file_path[len(country_package_dir_path):]\n    if relative_file_path.startswith('/'):\n        relative_file_path = relative_file_path[1:]\n    return relative_file_path", "response": "Get the relative file path for the given absolute file path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_environment(global_conf, app_conf):\n    conf.update(strings.deep_decode(global_conf))\n    conf.update(strings.deep_decode(app_conf))\n    conf.update(conv.check(conv.struct(\n        {\n            'app_conf': conv.set_value(app_conf),\n            'app_dir': conv.set_value(app_dir),\n            'country_package': conv.pipe(\n                conv.make_input_to_slug(separator = u'_'),\n                conv.not_none,\n                ),\n            'debug': conv.pipe(conv.guess_bool, conv.default(False)),\n            'global_conf': conv.set_value(global_conf),\n            'i18n_dir': conv.default(os.path.join(app_dir, 'i18n')),\n            'load_alert': conv.pipe(conv.guess_bool, conv.default(False)),\n            'log_level': conv.pipe(\n                conv.default('WARNING'),\n                conv.function(lambda log_level: getattr(logging, log_level.upper())),\n                ),\n            'package_name': conv.default('openfisca-web-api'),\n            'realm': conv.default(u'OpenFisca Web API'),\n            'reforms': conv.ini_str_to_list,  # Another validation is done below.\n            'extensions': conv.ini_str_to_list,\n            },\n        default = 'drop',\n        ))(conf))\n\n    # Configure logging.\n    logging.basicConfig(level = conf['log_level'], stream = sys.stderr)\n\n    errorware = conf.setdefault('errorware', {})\n    errorware['debug'] = conf['debug']\n    if not errorware['debug']:\n        errorware['error_email'] = conf['email_to']\n        errorware['error_log'] = conf.get('error_log', None)\n        errorware['error_message'] = conf.get('error_message', 'An internal server error occurred')\n        errorware['error_subject_prefix'] = conf.get('error_subject_prefix', 'OpenFisca Web API Error: ')\n        errorware['from_address'] = conf['from_address']\n        errorware['smtp_server'] = conf.get('smtp_server', 'localhost')\n        errorware['show_exceptions_in_wsgi_errors'] = conf.get('show_exceptions_in_wsgi_errors', True)\n\n    # Initialize tax-benefit system.\n    country_package = importlib.import_module(conf['country_package'])\n    tax_benefit_system = country_package.CountryTaxBenefitSystem()\n\n    extensions = conf['extensions']\n    if extensions is not None:\n        for extension in extensions:\n            tax_benefit_system.load_extension(extension)\n\n    class Scenario(tax_benefit_system.Scenario):\n        instance_and_error_couple_cache = {} if conf['debug'] else weakref.WeakValueDictionary()  # class attribute\n\n        @classmethod\n        def make_json_to_cached_or_new_instance(cls, ctx, repair, tax_benefit_system):\n            def json_to_cached_or_new_instance(value, state = None):\n                key = (unicode(ctx.lang), unicode(value), repair, tax_benefit_system)\n                instance_and_error_couple = cls.instance_and_error_couple_cache.get(key)\n                if instance_and_error_couple is None:\n                    instance_and_error_couple = cls.make_json_to_instance(repair, tax_benefit_system)(\n                        value, state = state or conv.default_state)\n                    # Note: Call to ValueAndError() is needed below, otherwise it raises TypeError: cannot create\n                    # weak reference to 'tuple' object.\n                    cls.instance_and_error_couple_cache[key] = ValueAndError(instance_and_error_couple)\n                return instance_and_error_couple\n\n            return json_to_cached_or_new_instance\n\n    tax_benefit_system.Scenario = Scenario\n\n    model.tax_benefit_system = tax_benefit_system\n\n    log.debug(u'Pre-fill tax and benefit system cache.')\n    tax_benefit_system.prefill_cache()\n\n    log.debug(u'Initialize reforms.')\n    reforms = conv.check(\n        conv.uniform_sequence(\n            conv.module_and_function_str_to_function,\n            )\n        )(conf['reforms'])\n    model.reforms = {}\n    model.reformed_tbs = {}\n    if reforms is not None:\n        for reform in reforms:\n            reformed_tbs = reform(tax_benefit_system)\n            key = reformed_tbs.key\n            full_key = reformed_tbs.full_key\n            model.reforms[key] = reform\n            model.reformed_tbs[full_key] = reformed_tbs\n\n    log.debug(u'Cache default decomposition.')\n    if tax_benefit_system.decomposition_file_path is not None:\n        # Ignore the returned value, because we just want to pre-compute the cache.\n        model.get_cached_or_new_decomposition_json(tax_benefit_system)\n\n    log.debug(u'Initialize lib2to3-based input variables extractor.')\n\n    global country_package_dir_path\n    # - Do not use pkg_resources.get_distribution(conf[\"country_package\"]).location\n    #   because it returns a wrong path in virtualenvs (<venv>/lib versus <venv>/local/lib)\n    # - Use os.path.abspath because when the web API is runned in development with \"paster serve\",\n    #   __path__[0] == 'openfisca_france' for example. Then, get_relative_file_path won't be able\n    #   to find the relative path of an already relative path.\n    country_package_dir_path = os.path.abspath(country_package.__path__[0])\n\n    global api_package_version\n    api_package_version = pkg_resources.get_distribution('openfisca_web_api').version\n\n    global country_package_version\n    country_package_version = pkg_resources.get_distribution(conf[\"country_package\"]).version\n\n    log.debug(u'Cache legislation parmeters')\n    legislation = tax_benefit_system.parameters\n    parameters = []\n    walk_legislation(\n        legislation,\n        descriptions = [],\n        parameters = parameters,\n        path_fragments = [],\n        )\n    model.parameters_cache = parameters\n\n    if not conf['debug']:\n        # Do this after tax_benefit_system.get_legislation().\n        log.debug(u'Compute and cache compact legislation for each first day of month since at least 2 legal years.')\n        today = periods.instant(datetime.date.today())\n        first_day_of_year = today.offset('first-of', 'year')\n        instant = first_day_of_year.offset(-2, 'year')\n        two_years_later = first_day_of_year.offset(2, 'year')\n        while instant < two_years_later:\n            tax_benefit_system.get_parameters_at_instant(instant)\n            instant = instant.offset(1, 'month')\n\n    # Initialize multiprocessing and load_alert\n    if conf['load_alert']:\n        global cpu_count\n        cpu_count = multiprocessing.cpu_count()\n\n    if conf.get('tracker_url') and conf.get('tracker_idsite'):\n        wsgihelpers.init_tracker(conf['tracker_url'], conf['tracker_idsite'])", "response": "Configure the application environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_genes(self, gene_names : Iterable[str]):\n\n        filt = self.loc[self.index & gene_names]\n        return filt", "response": "Filter the expression matrix against a set of genes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_tsv(cls, filepath_or_buffer: str, gene_table: ExpGeneTable = None,\n                 encoding='UTF-8'):\n        \"\"\"Read expression profile from a tab-delimited text file.\n\n        Parameters\n        ----------\n        path: str\n            The path of the text file.\n        gene_table: `ExpGeneTable` object, optional\n            The set of valid genes. If given, the genes in the text file will\n            be filtered against this set of genes. (None)\n        encoding: str, optional\n            The file encoding. (\"UTF-8\")\n\n        Returns\n        -------\n        `ExpProfile`\n            The expression profile.\n        \"\"\"\n        # \"squeeze = True\" ensures that a pd.read_tsv returns a series\n        # as long as there is only one column\n        e = cls(pd.read_csv(filepath_or_buffer, sep='\\t',\n                            index_col=0, header=0,\n                            encoding=encoding, squeeze=True))\n\n        if gene_table is not None:\n            # filter genes\n            e = e.filter_genes(gene_table.gene_names)\n\n        return e", "response": "Read an expression profile from a tab - delimited text file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_tsv(self, path, encoding='UTF-8'):\n        assert isinstance(path, (str, _oldstr))\n        assert isinstance(encoding, (str, _oldstr))\n\n        sep = '\\t'\n        if six.PY2:\n            sep = sep.encode('UTF-8')\n\n        self.to_csv(\n            path, sep=sep, float_format='%.5f', mode='w',\n            encoding=encoding, header=True\n        )\n\n        logger.info('Wrote expression profile \"%s\" with %d genes to \"%s\".',\n                    self.name, self.p, path)", "response": "Write the expression matrix to a tab - delimited text file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_storage(self):\n        if self.storage_callable is not None and not self.storage_per_field:\n            self.storage = self.get_storage_from_callable(field=None)\n        super(override_storage, self).setup_storage()", "response": "Save existing FileField storages and patch them with test instance instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_fastqc(credentials, instance_config, instance_name,\n               script_dir, input_file, output_dir, self_destruct=True,\n               **kwargs):\n    \"\"\"Run FASTQC.\n\n    TODO: docstring\"\"\"\n    template = _TEMPLATE_ENV.get_template('fastqc.sh')\n    startup_script = template.render(\n        script_dir=script_dir,\n        input_file=input_file,\n        output_dir=output_dir,\n        self_destruct=self_destruct)\n\n    if len(startup_script) > 32768:\n        raise ValueError('Startup script larger than 32,768 bytes!')\n\n    #print(startup_script)\n\n    op_name = instance_config.create_instance(\n        credentials, instance_name, startup_script=startup_script, **kwargs)\n\n    return op_name", "response": "Run FASTQC.\n\n    TODO: docstring"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads paired - end reads from SRA and convert to gziped FASTQ files.", "response": "def sra_download_paired_end(credentials, instance_config, instance_name,\n                            script_dir, sra_run_acc, output_dir, **kwargs):    \n    \"\"\"Download paired-end reads from SRA and convert to gzip'ed FASTQ files.\n\n    TODO: docstring\"\"\"\n\n    template = _TEMPLATE_ENV.get_template('sra_download_paired-end.sh')\n    startup_script = template.render(\n        script_dir=script_dir,\n        sra_run_acc=sra_run_acc,\n        output_dir=output_dir)\n\n    if len(startup_script) > 32768:\n        raise ValueError('Startup script larger than 32,768 bytes!')\n\n    #print(startup_script)\n\n    instance_config.create_instance(\n        credentials, instance_name, startup_script=startup_script, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrimming a FASTQ file.", "response": "def trim_fastq(credentials, instance_config, instance_name,\n               script_dir, input_file, output_file,\n               trim_crop, trim_headcrop=0, self_destruct=True,\n               **kwargs):\n    \"\"\"Trims a FASTQ file.\n    \n    TODO: docstring\"\"\"\n    template = _TEMPLATE_ENV.get_template('trim_fastq.sh')\n    startup_script = template.render(\n        script_dir=script_dir,\n        input_file=input_file,\n        output_file=output_file,\n        trim_crop=trim_crop,\n        trim_headcrop=trim_headcrop,\n        self_destruct=self_destruct)\n\n    if len(startup_script) > 32768:\n        raise ValueError('Startup script larger than 32,768 bytes!')\n\n    #print(startup_script)\n\n    instance_config.create_instance(\n        credentials, instance_name, startup_script=startup_script, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a shell command.", "response": "def _runshell(cmd, exception):\n    \"\"\" Run a shell command. if fails, raise a proper exception. \"\"\"\n    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    if p.wait() != 0:\n        raise BridgeException(exception)\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addif(self, iname):\n        _runshell([brctlexe, 'addif', self.name, iname],\n            \"Could not add interface %s to %s.\" % (iname, self.name))", "response": "Add an interface to the bridge."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes an interface from the bridge.", "response": "def delif(self, iname):\n        \"\"\" Delete an interface from the bridge. \"\"\"\n        _runshell([brctlexe, 'delif', self.name, iname],\n            \"Could not delete interface %s from %s.\" % (iname, self.name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning harpin on a port.", "response": "def hairpin(self, port, val=True):\n        \"\"\" Turn harpin on/off on a port. \"\"\" \n        if val: state = 'on' \n        else: state = 'off'\n        _runshell([brctlexe, 'hairpin', self.name, port, state],\n            \"Could not set hairpin in port %s in %s.\" % (port, self.name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn STP protocol on or off.", "response": "def stp(self, val=True):\n        \"\"\" Turn STP protocol on/off. \"\"\"\n        if val: state = 'on' \n        else: state = 'off'\n        _runshell([brctlexe, 'stp', self.name, state],\n            \"Could not set stp on %s.\" % self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the bridge ageing time.", "response": "def setageing(self, time):\n        \"\"\" Set bridge ageing time. \"\"\"\n        _runshell([brctlexe, 'setageing', self.name, str(time)],\n            \"Could not set ageing time in %s.\" % self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the bridge priority value.", "response": "def setbridgeprio(self, prio):\n        \"\"\" Set bridge priority value. \"\"\"\n        _runshell([brctlexe, 'setbridgeprio', self.name, str(prio)],\n            \"Could not set bridge priority in %s.\" % self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets bridge forward delay time value.", "response": "def setfd(self, time):\n        \"\"\" Set bridge forward delay time value. \"\"\"\n        _runshell([brctlexe, 'setfd', self.name, str(time)],\n            \"Could not set forward delay in %s.\" % self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset bridge hello time value.", "response": "def sethello(self, time):\n        \"\"\" Set bridge hello time value. \"\"\"\n        _runshell([brctlexe, 'sethello', self.name, str(time)],\n            \"Could not set hello time in %s.\" % self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setmaxage(self, time):\n        _runshell([brctlexe, 'setmaxage', self.name, str(time)],\n            \"Could not set max message age in %s.\" % self.name)", "response": "Set max message age time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset port path cost value for STP protocol.", "response": "def setpathcost(self, port, cost):\n        \"\"\" Set port path cost value for STP protocol. \"\"\"\n        _runshell([brctlexe, 'setpathcost', self.name, port, str(cost)],\n            \"Could not set path cost in port %s in %s.\" % (port, self.name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setportprio(self, port, prio):\n        _runshell([brctlexe, 'setportprio', self.name, port, str(prio)],\n            \"Could not set priority in port %s in %s.\" % (port, self.name))", "response": "Set the priority value for a specific port."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of unsorted bridge details.", "response": "def _show(self):\n        \"\"\" Return a list of unsorted bridge details. \"\"\" \n        p = _runshell([brctlexe, 'show', self.name],\n            \"Could not show %s.\" % self.name)\n        return p.stdout.read().split()[7:]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addbr(self, name):\n        _runshell([brctlexe, 'addbr', name],\n            \"Could not create bridge %s.\" % name)\n        _runshell([ipexe, 'link', 'set', 'dev', name, 'up'],\n            \"Could not set link up for %s.\" % name)\n        return Bridge(name)", "response": "Create a new bridge and set the device up."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the device down and delete the bridge.", "response": "def delbr(self, name):\n        \"\"\" Set the device down and delete the bridge. \"\"\"\n        self.getbr(name) # Check if exists\n        _runshell([ipexe, 'link', 'set', 'dev', name, 'down'],\n            \"Could not set link down for %s.\" % name)\n        _runshell([brctlexe, 'delbr', name],\n            \"Could not delete bridge %s.\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all available bridges.", "response": "def showall(self):\n        \"\"\" Return a list of all available bridges. \"\"\"\n        p = _runshell([brctlexe, 'show'],\n            \"Could not show bridges.\")\n        wlist = map(str.split, p.stdout.read().splitlines()[1:])\n        brwlist = filter(lambda x: len(x) != 1, wlist)\n        brlist = map(lambda x: x[0], brwlist)\n        return map(Bridge, brlist)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getbr(self, name):\n        for br in self.showall():\n            if br.name == name:\n                return br\n        raise BridgeException(\"Bridge does not exist.\")", "response": "Return a bridge object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean(self, value):\n        if (\n            self.base_type is not None and\n            value is not None and\n            not isinstance(value, self.base_type)\n        ):\n            if isinstance(self.base_type, tuple):\n                allowed_types = [typ.__name__ for typ in self.base_type]\n                allowed_types_text = ' or '.join(allowed_types)\n            else:\n                allowed_types_text = self.base_type.__name__\n            err_msg = 'Value must be of %s type.' % allowed_types_text\n            raise ValidationError(err_msg)\n\n        if not self.has_value(value):\n            if self.default is not None:\n                raise StopValidation(self.default)\n\n            if self.required:\n                raise ValidationError('This field is required.')\n            else:\n                raise StopValidation(self.blank_value)\n\n        return value", "response": "Take a dirty value and clean it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new object instantiated with cleaned data.", "response": "def clean_new(self, value):\n        \"\"\"Return a new object instantiated with cleaned data.\"\"\"\n        value = self.schema_class(value).full_clean()\n        return self.object_class(**value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_existing(self, value):\n        existing_pk = value[self.pk_field]\n        try:\n            obj = self.fetch_existing(existing_pk)\n        except ReferenceNotFoundError:\n            raise ValidationError('Object does not exist.')\n        orig_data = self.get_orig_data_from_existing(obj)\n\n        # Clean the data (passing the new data dict and the original data to\n        # the schema).\n        value = self.schema_class(value, orig_data).full_clean()\n\n        # Set cleaned data on the object (except for the pk_field).\n        for field_name, field_value in value.items():\n            if field_name != self.pk_field:\n                setattr(obj, field_name, field_value)\n\n        return obj", "response": "Clean the data and return an existing document with its fields\n        updated based on the cleaned values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_fields(cls):\n        fields = {}\n        for field_name in dir(cls):\n            if isinstance(getattr(cls, field_name), Field):\n                field = getattr(cls, field_name)\n                field_name = field.field_name or field_name\n                fields[field_name] = field\n        return fields", "response": "Returns a dictionary of fields and field instances for this schema."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a model object and converts it into a dictionary suitable for passing to the constructor s data attribute.", "response": "def obj_to_dict(cls, obj):\n        \"\"\"\n        Takes a model object and converts it into a dictionary suitable for\n        passing to the constructor's data attribute.\n        \"\"\"\n        data = {}\n        for field_name in cls.get_fields():\n            try:\n                value = getattr(obj, field_name)\n            except AttributeError:\n                # If the field doesn't exist on the object, fail gracefully\n                # and don't include the field in the data dict at all. Fail\n                # loudly if the field exists but produces a different error\n                # (edge case: accessing an *existing* field could technically\n                # produce an unrelated AttributeError).\n                continue\n\n            if callable(value):\n                value = value()\n            data[field_name] = value\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef toarray(self):\n        return asarray([value.toarray() for (key, value) in sorted(self.transformations.items())])", "response": "Return the transformations as an array with shape n x1 x2 x3..."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies the transformation to an array - like object.", "response": "def transform(self, images):\n        \"\"\"\n        Apply the transformation to an Images object.\n\n        Will apply the underlying dictionary of transformations to\n        the images or volumes of the Images object. The dictionary acts as a lookup\n        table specifying which transformation should be applied to which record of the\n        Images object based on the key. Because transformations are small,\n        we broadcast the transformations rather than using a join.\n\n        Parameters\n        ----------\n        images : array-like or thunder images\n            The sequence of images / volumes to register.\n        \"\"\"\n        images = check_images(images)\n\n        def apply(item):\n            (k, v) = item\n            return self.transformations[k].apply(v)\n\n        return images.map(apply, value_shape=images.value_shape, dtype=images.dtype, with_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a module in the background thread.", "response": "def load_module_in_background(name, package=None, debug='DEBUG', env=None,\n                              replacements=None):\n    \"\"\"Entry point for loading modules in background thread.\n\n    Parameters\n    ----------\n    name : str\n        Module name to load in background thread.\n    package : str or None, optional\n        Package name, has the same meaning as in importlib.import_module().\n    debug : str, optional\n        Debugging symbol name to look up in the environment.\n    env : Mapping or None, optional\n        Environment this will default to __xonsh_env__, if available, and\n        os.environ otherwise.\n    replacements : Mapping or None, optional\n        Dictionary mapping fully qualified module names (eg foo.bar.baz) that\n        import the lazily loaded moudle, with the variable name in that\n        module. For example, suppose that foo.bar imports module a as b,\n        this dict is then {'foo.bar': 'b'}.\n\n    Returns\n    -------\n    module : ModuleType\n        This is either the original module that is found in sys.modules or\n        a proxy module that will block until delay attribute access until the\n        module is fully loaded.\n    \"\"\"\n    modname = resolve_name(name, package)\n    if modname in sys.modules:\n        return sys.modules[modname]\n    if env is None:\n        try:\n            import builtins\n            env = getattr(builtins, '__xonsh_env__', os.environ)\n        except:\n            return os.environ\n    if env.get(debug, None):\n        mod = importlib.import_module(name, package=package)\n        return mod\n    proxy = sys.modules[modname] = BackgroundModuleProxy(modname)\n    BackgroundModuleLoader(name, package, replacements or {})\n    return proxy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_token(self):\n    if self.__token is not None:\n      return self.__token\n\n    url = \"https://api.neur.io/v1/oauth2/token\"\n\n    creds = b64encode(\":\".join([self.__key,self.__secret]).encode()).decode()\n\n    headers = {\n      \"Authorization\": \" \".join([\"Basic\", creds]),\n    }\n    payload = {\n      \"grant_type\": \"client_credentials\"\n    }\n\n    r = requests.post(url, data=payload, headers=headers)\n\n    self.__token = r.json()[\"access_token\"]\n\n    return self.__token", "response": "Performs Neurio API token authentication using provided key and secret."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_appliance(self, appliance_id):\n    url = \"https://api.neur.io/v1/appliances/%s\"%(appliance_id)\n\n    headers = self.__gen_headers()\n    headers[\"Content-Type\"] = \"application/json\"\n\n    r = requests.get(url, headers=headers)\n    return r.json()", "response": "Get the information for a specified appliance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the appliances added for a specified location.", "response": "def get_appliances(self, location_id):\n    \"\"\"Get the appliances added for a specified location.\n\n    Args:\n      location_id (string): identifiying string of appliance\n\n    Returns:\n      list: dictionary objects containing appliances data\n    \"\"\"\n    url = \"https://api.neur.io/v1/appliances\"\n\n    headers = self.__gen_headers()\n    headers[\"Content-Type\"] = \"application/json\"\n\n    params = {\n      \"locationId\": location_id,\n    }\n    url = self.__append_url_params(url, params)\n\n    r = requests.get(url, headers=headers)\n    return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_appliance_event_after_time(self, location_id, since, per_page=None, page=None, min_power=None):\n    url = \"https://api.neur.io/v1/appliances/events\"\n\n    headers = self.__gen_headers()\n    headers[\"Content-Type\"] = \"application/json\"\n\n    params = {\n      \"locationId\": location_id,\n      \"since\": since\n    }\n    if min_power:\n      params[\"minPower\"] = min_power\n    if per_page:\n      params[\"perPage\"] = per_page\n    if page:\n      params[\"page\"] = page\n    url = self.__append_url_params(url, params)\n\n    r = requests.get(url, headers=headers)\n    return r.json()", "response": "This method returns the appliance events that have occurred after a given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets appliance usage data for a given location within a given time range. Stats are generated by fetching appliance events that match the supplied criteria and then aggregating them together based on the granularity specified with the request. Note: This endpoint uses the location's time zone when generating time intervals for the stats, which is relevant if that time zone uses daylight saving time (some days will be 23 or 25 hours long). Args: location_id (string): hexadecimal id of the sensor to query, e.g. ``0x0013A20040B65FAD`` start (string): ISO 8601 start time for getting the events of appliances. end (string): ISO 8601 stop time for getting the events of appliances. Cannot be larger than 1 month from start time granularity (string): granularity of stats. If the granularity is 'unknown', the stats for the appliances between the start and end time is returned.; must be one of \"minutes\", \"hours\", \"days\", \"weeks\", \"months\", or \"unknown\" (default: days) min_power (string): The minimum average power (in watts) for filtering. Only events with an average power above this value will be returned. (default: 400) per_page (string, optional): the number of returned results per page (min 1, max 500) (default: 10) page (string, optional): the page number to return (min 1, max 100000) (default: 1) Returns: list: dictionary objects containing appliance events meeting specified criteria", "response": "def get_appliance_stats_by_location(self, location_id, start, end, granularity=None, per_page=None, page=None,\n                                      min_power=None):\n    \"\"\"Get appliance usage data for a given location within a given time range.\n    Stats are generated by fetching appliance events that match the supplied\n    criteria and then aggregating them together based on the granularity\n    specified with the request.\n\n    Note:\n      This endpoint uses the location's time zone when generating time intervals\n      for the stats, which is relevant if that time zone uses daylight saving\n      time (some days will be 23 or 25 hours long).\n\n    Args:\n      location_id (string): hexadecimal id of the sensor to query, e.g.\n                          ``0x0013A20040B65FAD``\n      start (string): ISO 8601 start time for getting the events of appliances.\n      end (string): ISO 8601 stop time for getting the events of appliances.\n        Cannot be larger than 1 month from start time\n      granularity (string): granularity of stats. If the granularity is\n        'unknown', the stats for the appliances between the start and\n        end time is returned.;\n        must be one of  \"minutes\", \"hours\", \"days\", \"weeks\", \"months\", or \"unknown\"\n        (default: days)\n      min_power (string): The minimum average power (in watts) for filtering.\n        Only events with an average power above this value will be returned.\n        (default: 400)\n      per_page (string, optional): the number of returned results per page\n        (min 1, max 500) (default: 10)\n      page (string, optional): the page number to return (min 1, max 100000)\n        (default: 1)\n\n    Returns:\n      list: dictionary objects containing appliance events meeting specified criteria\n    \"\"\"\n    url = \"https://api.neur.io/v1/appliances/stats\"\n\n    headers = self.__gen_headers()\n    headers[\"Content-Type\"] = \"application/json\"\n\n    params = {\n      \"locationId\": location_id,\n      \"start\": start,\n      \"end\": end\n    }\n    if granularity:\n      params[\"granularity\"] = granularity\n    if min_power:\n      params[\"minPower\"] = min_power\n    if per_page:\n      params[\"perPage\"] = per_page\n    if page:\n      params[\"page\"] = page\n    url = self.__append_url_params(url, params)\n\n    r = requests.get(url, headers=headers)\n    return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_local_current_sample(ip):\n    valid_ip_pat = re.compile(\n      \"^((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$\"\n    )\n    if not valid_ip_pat.match(ip):\n      raise ValueError(\"ip address invalid\")\n\n    url = \"http://%s/current-sample\" % (ip)\n    headers = { \"Content-Type\": \"application/json\" }\n\n    r = requests.get(url, headers=headers)\n    return r.json()", "response": "This method retrieves the current sample from a local Neurio device IP address."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget recent samples for a given sensor", "response": "def get_samples_live(self, sensor_id, last=None):\n    \"\"\"Get recent samples, one sample per second for up to the last 2 minutes.\n\n    Args:\n      sensor_id (string): hexadecimal id of the sensor to query, e.g.\n        ``0x0013A20040B65FAD``\n      last (string): starting range, as ISO8601 timestamp\n\n    Returns:\n      list: dictionary objects containing sample data\n    \"\"\"\n    url = \"https://api.neur.io/v1/samples/live\"\n\n    headers = self.__gen_headers()\n    headers[\"Content-Type\"] = \"application/json\"\n\n    params = { \"sensorId\": sensor_id }\n    if last:\n      params[\"last\"] = last\n    url = self.__append_url_params(url, params)\n\n    r = requests.get(url, headers=headers)\n    return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_samples_live_last(self, sensor_id):\n    url = \"https://api.neur.io/v1/samples/live/last\"\n\n    headers = self.__gen_headers()\n    headers[\"Content-Type\"] = \"application/json\"\n\n    params = { \"sensorId\": sensor_id }\n    url = self.__append_url_params(url, params)\n\n    r = requests.get(url, headers=headers)\n    return r.json()", "response": "Get the last sample recorded by the sensor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_samples(self, sensor_id, start, granularity, end=None,\n                  frequency=None, per_page=None, page=None,\n                  full=False):\n    \"\"\"Get a sensor's samples for a specified time interval.\n\n    Args:\n      sensor_id (string): hexadecimal id of the sensor to query, e.g.\n                          ``0x0013A20040B65FAD``\n      start (string): ISO 8601 start time of sampling; depends on the\n        ``granularity`` parameter value, the maximum supported time ranges are:\n        1 day for minutes or hours granularities, 1 month for days,\n        6 months for weeks, 1 year for months granularity, and 10 years for\n        years granularity\n      granularity (string): granularity of the sampled data; must be one of\n        \"minutes\", \"hours\", \"days\", \"weeks\", \"months\", or \"years\"\n      end (string, optional): ISO 8601 stop time for sampling; should be later\n        than start time (default: the current time)\n      frequency (string, optional): frequency of the sampled data (e.g. with\n        granularity set to days, a value of 3 will result in a sample for every\n        third day, should be a multiple of 5 when using minutes granularity)\n        (default: 1) (example: \"1, 5\")\n      per_page (string, optional): the number of returned results per page\n        (min 1, max 500) (default: 10)\n      page (string, optional): the page number to return (min 1, max 100000)\n        (default: 1)\n      full (bool, optional): include additional information per sample\n        (default: False)\n\n    Returns:\n      list: dictionary objects containing sample data\n    \"\"\"\n    url = \"https://api.neur.io/v1/samples\"\n    if full:\n      url = \"https://api.neur.io/v1/samples/full\"\n\n    headers = self.__gen_headers()\n    headers[\"Content-Type\"] = \"application/json\"\n\n    params = {\n      \"sensorId\": sensor_id,\n      \"start\": start,\n      \"granularity\": granularity\n    }\n    if end:\n      params[\"end\"] = end\n    if frequency:\n      params[\"frequency\"] = frequency\n    if per_page:\n      params[\"perPage\"] = per_page\n    if page:\n      params[\"page\"] = page\n    url = self.__append_url_params(url, params)\n\n    r = requests.get(url, headers=headers)\n    return r.json()", "response": "This method returns a list of samples for a specified time interval."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the current user information including sensor ID", "response": "def get_user_information(self):\n    \"\"\"Gets the current user information, including sensor ID\n\n    Args:\n      None\n\n    Returns:\n      dictionary object containing information about the current user\n    \"\"\"\n    url = \"https://api.neur.io/v1/users/current\"\n\n    headers = self.__gen_headers()\n    headers[\"Content-Type\"] = \"application/json\"\n\n    r = requests.get(url, headers=headers)\n    return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_figure(\n            self, emin=None, emax=None,\n            width=800, height=400,\n            margin_left=100, margin_bottom=60, margin_top=30, margin_right=0,\n            colorbar_size=0.4,\n            xaxis_label=None, yaxis_label=None,\n            xaxis_nticks=None, yaxis_nticks=None,\n            xtick_angle=30,\n            font='\"Droid Serif\", \"Open Serif\", serif',\n            font_size=12, title_font_size=None,\n            show_sample_labels=True, **kwargs):\n        \"\"\"Generate a plotly figure of the heatmap.\n        \n        Parameters\n        ----------\n        emin : int, float, or None, optional\n            The expression value corresponding to the lower end of the\n            colorscale. If None, determine, automatically. [None]\n        emax : int, float, or None, optional\n            The expression value corresponding to the upper end of the\n            colorscale. If None, determine automatically. [None]\n        margin_left : int, optional\n            The size of the left margin (in px). [100]\n        margin_right : int, optional\n            The size of the right margin (in px). [0]\n        margin_top : int, optional\n            The size of the top margin (in px). [30]\n        margin_bottom : int, optional\n            The size of the bottom margin (in px). [60]\n        colorbar_size : int or float, optional\n            The sze of the colorbar, relative to the figure size. [0.4]\n        xaxis_label : str or None, optional\n            X-axis label. If None, use `ExpMatrix` default. [None]\n        yaxis_label : str or None, optional\n            y-axis label. If None, use `ExpMatrix` default. [None]\n        xtick_angle : int or float, optional\n            X-axis tick angle (in degrees). [30]\n        font : str, optional\n            Name of font to use. Can be multiple, separated by comma, to\n            specify a prioritized list.\n            [' \"Droid Serif\", \"Open Serif\", \"serif\"']\n        font_size : int or float, optional\n            Font size to use throughout the figure, in points. [12]\n        title_font_size : int or float or None, optional\n            Font size to use for labels on axes and the colorbar. If None,\n            use `font_size` value. [None]\n        show_sample_labels : bool, optional\n            Whether to show the sample labels. [True]\n\n        Returns\n        -------\n        `plotly.graph_objs.Figure`\n            The plotly figure.\n        \"\"\"\n\n        # emin and/or emax are unspecified, set to data min/max values\n        if emax is None:\n            emax = self.matrix.X.max()\n        if emin is None:\n            emin = self.matrix.X.min()\n\n        title = self.title\n\n        if title_font_size is None:\n            title_font_size = font_size\n\n        colorbar_label = self.colorbar_label or 'Expression'\n\n        colorbar = go.ColorBar(\n            lenmode='fraction',\n            len=colorbar_size,\n            title=colorbar_label,\n            titlefont=dict(\n                size=title_font_size,\n            ),\n            titleside='right',\n            xpad=0,\n            ypad=0,\n            outlinewidth=0,  # no border\n            thickness=20,  # in pixels\n            # outlinecolor = '#000000',\n        )\n\n        def fix_plotly_label_bug(labels):\n            \"\"\"\n            This fixes a bug whereby plotly treats labels that look\n            like numbers (integers or floats) as numeric instead of\n            categorical, even when they are passed as strings. The fix consists\n            of appending an underscore to any label that looks like a number.\n            \"\"\"\n            assert isinstance(labels, Iterable)\n            fixed_labels = []\n            for l in labels:\n                try:\n                    float(l)\n                except (ValueError, TypeError):\n                    fixed_labels.append(str(l))\n                else:\n                    fixed_labels.append(str(l) + '_')\n            return fixed_labels\n\n        x = fix_plotly_label_bug(self.matrix.samples)\n\n        gene_labels = self.matrix.genes.tolist()\n\n        if self.gene_aliases:\n            for i, gene in enumerate(gene_labels):\n                try:\n                    alias = self.gene_aliases[gene]\n                except KeyError:\n                    pass\n                else:\n                    gene_labels[i] = '%s/%s' % (gene, alias)\n            \n        gene_labels = fix_plotly_label_bug(gene_labels)\n\n\n        data = [\n            go.Heatmap(\n                z=self.matrix.X,\n                x=x,\n                y=gene_labels,\n                zmin=emin,\n                zmax=emax,\n                colorscale=self.colorscale,\n                colorbar=colorbar,\n                hoverinfo='x+y+z',\n                **kwargs\n            ),\n        ]\n\n        xticks = 'outside'\n        if not show_sample_labels:\n            xticks = ''\n\n        if xaxis_label is None:\n            if self.matrix.samples.name is not None:\n                xaxis_label = self.matrix.samples.name\n            else:\n                xaxis_label = 'Samples'\n            xaxis_label = xaxis_label + ' (n = %d)' % self.matrix.n\n\n        if yaxis_label is None:\n            if self.matrix.genes.name is not None:\n                yaxis_label = self.matrix.genes.name\n            else:\n                yaxis_label = 'Genes'\n            yaxis_label = yaxis_label + ' (p = %d)' % self.matrix.p\n\n        layout = go.Layout(\n            width=width,\n            height=height,\n            title=title,\n            titlefont=go.Font(\n                size=title_font_size\n            ),\n            font=go.Font(\n                size=font_size,\n                family=font\n            ),\n            xaxis=go.XAxis(\n                title=xaxis_label,\n                titlefont=dict(size=title_font_size),\n                showticklabels=show_sample_labels,\n                ticks=xticks,\n                nticks=xaxis_nticks,\n                tickangle=xtick_angle,\n                showline=True\n            ),\n            yaxis=go.YAxis(\n                title=yaxis_label,\n                titlefont=dict(size=title_font_size),\n                nticks=yaxis_nticks,\n                autorange='reversed',\n                showline=True\n            ),\n\n            margin=go.Margin(\n                l=margin_left,\n                t=margin_top,\n                b=margin_bottom,\n                r=margin_right,\n                pad=0\n            ),\n        )\n\n        # add annotations\n\n        # we need separate, but overlaying, axes to place the annotations\n        layout['xaxis2'] = go.XAxis(\n            overlaying = 'x',\n            showline = False,\n            tickfont = dict(size=0),\n            autorange=False,\n            range=[-0.5, self.matrix.n-0.5],\n            ticks='',\n            showticklabels=False\n        )\n\n        layout['yaxis2'] = go.YAxis(\n            overlaying='y',\n            showline=False,\n            tickfont=dict(size=0),\n            autorange=False,\n            range=[self.matrix.p-0.5, -0.5],\n            ticks='',\n            showticklabels=False\n        )\n\n        # gene (row) annotations\n        for ann in self.gene_annotations:\n            i = self.matrix.genes.get_loc(ann.gene)\n            xmn = -0.5\n            xmx = self.matrix.n-0.5\n            ymn = i-0.5\n            ymx = i+0.5\n            #logger.debug('Transparency is %.1f', ann.transparency)\n            data.append(\n                go.Scatter(\n                    x=[xmn, xmx, xmx, xmn, xmn],\n                    y=[ymn, ymn, ymx, ymx, ymn],\n                    mode='lines',\n                    hoverinfo='none',\n                    showlegend=False,\n                    line=dict(color=ann.color),\n                    xaxis='x2',\n                    yaxis='y2',\n                    #opacity=0.5,\n                    opacity=1-ann.transparency,\n                )\n            )\n            if ann.label is not None:\n                layout.annotations.append(\n                    go.Annotation(\n                        text=ann.label,\n                        x=0.01,\n                        y=i-0.5,\n                        #y=i+0.5,\n                        xref='paper',\n                        yref='y2',\n                        xanchor='left',\n                        yanchor='bottom',\n                        showarrow=False,\n                        bgcolor='white',\n                        #opacity=1-ann.transparency,\n                        opacity=0.8,\n                        borderpad=0,\n                        #textangle=30,\n                        font=dict(color=ann.color)\n                    )\n                )\n\n        # sample (column) annotations\n        for ann in self.sample_annotations:\n            j = self.matrix.samples.get_loc(ann.sample)\n            xmn = j-0.5\n            xmx = j+0.5\n            ymn = -0.5\n            ymx = self.matrix.p-0.5\n            data.append(\n                go.Scatter(\n                    x=[xmn, xmx, xmx, xmn, xmn],\n                    y=[ymn, ymn, ymx, ymx, ymn],\n                    mode='lines',\n                    hoverinfo='none',\n                    showlegend=False,\n                    line=dict(color=ann.color),\n                    xaxis='x2',\n                    yaxis='y2',\n                    opacity=1.0)\n            )\n            if ann.label is not None:\n                layout.annotations.append(\n                    go.Annotation(\n                        text=ann.label,\n                        y=0.99,\n                        x=j+0.5,\n                        #y=i+0.5,\n                        xref='x2',\n                        yref='paper',\n                        xanchor='left',\n                        yanchor='top',\n                        showarrow=False,\n                        bgcolor='white',\n                        opacity=1-ann.transparency,\n                        borderpad=0,\n                        textangle=90,\n                        font=dict(color=ann.color)\n                    )\n                )\n\n        fig = go.Figure(\n            data=data,\n            layout=layout\n        )\n\n        return fig", "response": "Generate a plotly figure of the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef api2_formula(req):\n    API_VERSION = '2.1.0'\n    wsgihelpers.track(req.url.decode('utf-8'))\n    params = dict(req.GET)\n    data = dict()\n\n    try:\n        extensions_header = req.headers.get('X-Openfisca-Extensions')\n\n        tax_benefit_system = model.get_cached_composed_reform(\n            reform_keys = extensions_header.split(','),\n            tax_benefit_system = model.tax_benefit_system,\n            ) if extensions_header is not None else model.tax_benefit_system\n\n        params = normalize(params, tax_benefit_system)\n        formula_names = req.urlvars.get('names').split('+')\n\n        data['values'] = dict()\n        data['period'] = parse_period(req.urlvars.get('period'))\n\n        simulation = create_simulation(params, data['period'], tax_benefit_system)\n\n        for formula_name in formula_names:\n            column = get_column_from_formula_name(formula_name, tax_benefit_system)\n            data['values'][formula_name] = compute(column.name, simulation)\n\n    except Exception as error:\n        if isinstance(error.args[0], dict):  # we raised it ourselves, in this controller\n            error = error.args[0]\n        else:\n            error = dict(\n                message = unicode(error),\n                code = 500\n                )\n\n        data['error'] = error\n    finally:\n        return respond(req, API_VERSION, data, params)", "response": "A simple API to OpenFisca 2. 1. 0 API to OpenFisca 2. 1. 0 API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the arithmetic mean of every 4 consecutive input numbers and outputs the arithmetic mean of every 4 consecutive input numbers.", "response": "def arithmetic_mean4(rst, clk, rx_rdy, rx_vld, rx_dat, tx_rdy, tx_vld, tx_dat):\n    ''' Calculates the arithmetic mean of every 4 consecutive input numbers\n\n        Input handshake & data\n            rx_rdy - (o) Ready\n            rx_vld - (i) Valid\n            rx_dat - (i) Data\n        Output handshake & data\n            tx_rdy - (i) Ready\n            tx_vld - (o) Valid\n            tx_dat - (o) Data\n\n        Implementation: 3-stage pipeline\n            stage 0: registers input data\n            stage 1: sum each 4 consecutive numbers and produce the sum as a single result\n            stage 2: divide the sum by 4\n\n            Each stage is implemented as a separate process controlled by a central pipeline control unit via an enable signal\n            The pipeline control unit manages the handshake and synchronizes the operation of the stages\n    '''\n\n    DATA_WIDTH = len(rx_dat)\n\n    NUM_STAGES = 3\n\n    stage_en = Signal(intbv(0)[NUM_STAGES:])\n\n    stop_tx = Signal(intbv(0)[NUM_STAGES:])\n\n    pipe_ctrl = pipeline_control( rst = rst,\n                                  clk = clk,\n                                  rx_vld = rx_vld,\n                                  rx_rdy = rx_rdy,\n                                  tx_vld = tx_vld,\n                                  tx_rdy = tx_rdy,\n                                  stage_enable = stage_en,\n                                  stop_tx = stop_tx)\n\n\n    s0_dat = Signal(intbv(0)[DATA_WIDTH:])\n\n    @always_seq(clk.posedge, reset=rst)\n    def stage_0():\n        ''' Register input data'''\n        if (stage_en[0]):\n            s0_dat.next = rx_dat\n\n\n    s1_sum = Signal(intbv(0)[DATA_WIDTH+2:])\n    s1_cnt = Signal(intbv(0, min=0, max=4))\n\n    @always(clk.posedge)\n    def stage_1():\n        ''' Sum each 4 consecutive data'''\n        if (rst):\n            s1_cnt.next = 0\n            stop_tx.next[1] = 1\n        elif (stage_en[1]):\n            # Count input data\n            s1_cnt.next = (s1_cnt + 1) % 4\n\n            if (s1_cnt == 0):\n                s1_sum.next = s0_dat\n            else:\n                s1_sum.next = s1_sum.next + s0_dat\n\n            # Produce result only after data 0, 1, 2, and 3 have been summed\n            if (s1_cnt == 3):\n                stop_tx.next[1] = 0\n            else:\n                stop_tx.next[1] = 1\n            ''' stop_tx[1] concerns the data currently registered in stage 1 - it determines whether \n                the data will be sent to the next pipeline stage (stop_tx==0) or will be dropped (stop_tx==1 ).\n                The signals stop_rx and stop_tx must be registered '''\n\n\n    s2_dat = Signal(intbv(0)[DATA_WIDTH:])\n\n    @always_seq(clk.posedge, reset=rst)\n    def stage_2():\n        ''' Divide by 4'''\n        if (stage_en[2]):\n            s2_dat.next = s1_sum // 4\n\n\n    @always_comb\n    def comb():\n        tx_dat.next = s2_dat\n\n    return instances()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pipeline_control_stop_tx():\n    ''' Instantiates the arithmetic_mean4 pipeline, feeds it with data and drains its output '''\n\n    clk = sim.Clock(val=0, period=10, units=\"ns\")\n    rst = sim.ResetSync(clk=clk, val=0, active=1)\n\n    rx_rdy, rx_vld, tx_rdy, tx_vld = [Signal(bool(0)) for _ in range(4)]\n    rx_dat = Signal(intbv(0)[8:])\n    tx_dat = Signal(intbv(0)[8:])\n\n    clkgen = clk.gen()\n    dut = arithmetic_mean4(rst, clk, rx_rdy, rx_vld, rx_dat, tx_rdy, tx_vld, tx_dat)\n#     dut = traceSignals(arithmetic_mean4, rst, clk, rx_rdy, rx_vld, rx_dat, tx_rdy, tx_vld, tx_dat)\n    drv = Driver(rst, clk, rx_rdy, rx_vld, rx_dat)\n    cap = Capture(rst, clk, tx_rdy, tx_vld, tx_dat)\n\n    data_in = []\n    data_out = []\n\n    def stim(GAP=0):\n        ''' Stimulates the pipeline input '''\n        @instance\n        def _stim():\n            yield rst.pulse(10)\n            yield clk.posedge\n            for i in range(5*4):\n                yield drv.write(i)\n                data_in.append(i)\n                for _ in range(GAP):\n                    yield clk.posedge\n            for _ in range(10):\n                yield clk.posedge\n            raise StopSimulation\n        return _stim\n\n\n    def drain(GAP=0):\n        ''' Drains the pipeline output '''\n        @instance\n        def _drain():\n            yield clk.posedge\n            while True:\n                yield cap.read()\n                data_out.append(cap.d)\n                for _ in range(GAP):\n                    yield clk.posedge\n        return _drain\n\n    # You can play with the gap size at the input and at the output to see how the pipeline responds (see time diagrams)\n    Simulation(clkgen, dut, stim(GAP=0), drain(GAP=0)).run()\n\n    print \"data_in ({}): {}\".format(len(data_in), data_in)\n    print \"data_out ({}): {}\".format(len(data_out), data_out)\n\n    data_out_expected = [sum(data_in[i:i+4])//4 for i in range(0, len(data_in), 4)]\n    assert cmp(data_out_expected, data_out)==0, \"expected: data_out ({}): {}\".format(len(data_out_expected), data_out_expected)", "response": "Instantiates the arithmetic_mean4 pipeline feeds it with data and drains its output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean(self, value):\n        value = super(MongoEmbedded, self).clean(value)\n        return self.document_class(**value)", "response": "Clean the provided dict of values and then return an an\n        EmbeddedDocument instantiated with them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching the object by its PK.", "response": "def fetch_object(self, doc_id):\n        \"\"\"Fetch the document by its PK.\"\"\"\n        try:\n            return self.object_class.objects.get(pk=doc_id)\n        except self.object_class.DoesNotExist:\n            raise ReferenceNotFoundError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_argument_parser():\n    desc = 'Generate a sample sheet based on a GEO series matrix.'\n    parser = cli.get_argument_parser(desc=desc)\n\n    g = parser.add_argument_group('Input and output files')\n\n    g.add_argument(\n        '-s', '--series-matrix-file', type=cli.str_type, required=True,\n        metavar=cli.file_mv, help='The GEO series matrix file.'\n    )\n\n    g.add_argument(\n        '-o', '--output-file', type=cli.str_type,\n        required=True,\n        metavar=cli.file_mv, help='The output file.'\n    )\n\n    g.add_argument(\n        '-e', '--encoding', type=cli.str_type,\n        metavar=cli.str_mv, default='UTF-8',\n        help='The encoding of the series matrix file. [UTF-8]'\n    )\n\n    cli.add_reporting_args(parser)\n\n    return parser", "response": "Create the argument parser for the script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_series_matrix(path, encoding):\n    assert isinstance(path, str)\n\n    accessions = None\n    titles = None\n    celfile_urls = None\n    with misc.smart_open_read(path, mode='rb', try_gzip=True) as fh:\n        reader = csv.reader(fh, dialect='excel-tab', encoding=encoding)\n        for l in reader:\n            if not l:\n                continue\n            if l[0] == '!Sample_geo_accession':\n                accessions = l[1:]\n            elif l[0] == '!Sample_title':\n                titles = l[1:]\n            elif l[0] == '!Sample_supplementary_file' and celfile_urls is None:\n                celfile_urls = l[1:]\n            elif l[0] == '!series_matrix_table_begin':\n                # we've read the end of the section containing metadata\n                break\n    return accessions, titles, celfile_urls", "response": "Read the series matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_sample_sheet(path, accessions, names, celfile_urls, sel=None):\n    with open(path, 'wb') as ofh:\n        writer = csv.writer(ofh, dialect='excel-tab',\n                            lineterminator=os.linesep,\n                            quoting=csv.QUOTE_NONE)\n        # write header\n        writer.writerow(['Accession', 'Name', 'CEL file', 'CEL file URL'])\n        n = len(names)\n        if sel is None:\n            sel = range(n)\n        for i in sel:\n            cf = celfile_urls[i].split('/')[-1]\n            # row = [accessions[i], names[i], cf, celfile_urls[i]]\n            writer.writerow([accessions[i], names[i], cf, celfile_urls[i]])", "response": "Write the sample sheet."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_blueprint(state):\n    blueprint = Blueprint(\n        'invenio_jsonschemas',\n        __name__,\n    )\n\n    @blueprint.route('/<path:schema_path>')\n    def get_schema(schema_path):\n        \"\"\"Retrieve a schema.\"\"\"\n        try:\n            schema_dir = state.get_schema_dir(schema_path)\n        except JSONSchemaNotFound:\n            abort(404)\n\n        resolved = request.args.get(\n            'resolved',\n            current_app.config.get('JSONSCHEMAS_RESOLVE_SCHEMA'),\n            type=int\n        )\n\n        with_refs = request.args.get(\n            'refs',\n            current_app.config.get('JSONSCHEMAS_REPLACE_REFS'),\n            type=int\n        ) or resolved\n\n        if resolved or with_refs:\n            schema = state.get_schema(\n                schema_path,\n                with_refs=with_refs,\n                resolved=resolved\n            )\n            return jsonify(schema)\n        else:\n            return send_from_directory(schema_dir, schema_path)\n\n    return blueprint", "response": "Create a blueprint serving the JSON schemas."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload files from GDC manifest.", "response": "def download_files(manifest, download_dir, auth_token=None,\n                       chunk_size=1048576, avoid_redownload=True):\n    \"\"\"Individually download files from GDC.\n    \n    Params\n    ------\n    manifest : `pandas.DataFrame`\n        GDC manifest that contains a list of files. The data frame should\n        have five columns: id, filename, md5, size, and state.\n    download_dir : str\n        The path of the download directory.\n    auth_token : str, optional\n        Authentication token for downloading protected data.\n        If None, do not send authentication header. [None]\n    chunk_size : int, optional\n        The chunk size (in bytes) to use for downloading data. [1048576]\n        \n    Returns\n    -------\n    None\n    \"\"\"\n    assert isinstance(manifest, pd.DataFrame)\n    assert isinstance(download_dir, str)\n    assert isinstance(chunk_size, int)\n    if auth_token is not None:\n        assert isinstance(auth_token, str)\n                       \n    def get_file_md5hash(path):\n        \"\"\"Calculate the MD5 hash for a file.\"\"\"\n        with open(path, 'rb') as fh:\n            h = hashlib.md5(fh.read()).hexdigest()\n        return h\n\n    headers = {}\n    if auth_token is not None:\n        headers['X-Auth-Token'] = auth_token\n        \n    #payload = {'ids': file_ids}    \n    #logger.info('Downloading data to \"%s\"...', download_dir)\n    num_files = manifest.shape[0]\n    logger.info('Downloading %d files to \"%s\"...', num_files, download_dir)\n    for i, row in manifest.iterrows():\n        #(uuid, (file_name, file_hash)) \n        success = False        \n        download_file = os.path.join(download_dir, row['filename'])\n        if ((i+1) % 100) == 0:\n            logger.info('Downloading file %d / %d...', i+1, num_files)\n        \n        if avoid_redownload and os.path.isfile(download_file) and \\\n                get_file_md5hash(download_file) == row['md5']:\n            logger.info('File %s already downloaded...skipping.',\n                        download_file)\n            success = True\n        \n        while not success:\n            with closing(\n                requests.get('https://gdc-api.nci.nih.gov/data/%s'\n                             % row['id'], headers=headers, stream=True)) \\\n                as r:\n                # get suggested file name from \"Content-Disposition\" header\n                # suggested_file_name = re.findall(\n                #       \"filename=(.+)\", r.headers['Content-Disposition'])[0]\n\n                r.raise_for_status()\n\n                with open(download_file, 'wb') as ofh:\n                    for chunk in r.iter_content(chunk_size=chunk_size): \n                        if chunk: # filter out keep-alive new chunks\n                            ofh.write(chunk)\n            with open(download_file, 'rb') as fh:\n                h = hashlib.md5(fh.read()).hexdigest()\n                if h == row['md5']:\n                    success = True\n            if not success:\n                logger.warning('Hash value mismatch (should be: %s; is: %s). '\n                               'Attempting to re-download file...',\n                               row['md5'], h)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting a BLAST record.", "response": "def printBlastRecord(record):\n    \"\"\"\n    Print a BLAST record.\n\n    @param record: A BioPython C{Bio.Blast.Record.Blast} instance.\n    \"\"\"\n    for key in sorted(record.__dict__.keys()):\n        if key not in ['alignments', 'descriptions', 'reference']:\n            print('%s: %r' % (key, record.__dict__[key]))\n    print('alignments: (%d in total):' % len(record.alignments))\n    for i, alignment in enumerate(record.alignments):\n        print('  description %d:' % (i + 1))\n        for attr in ['accession', 'bits', 'e', 'num_alignments', 'score']:\n            print('    %s: %s' % (attr, getattr(record.descriptions[i], attr)))\n        print('  alignment %d:' % (i + 1))\n        for attr in 'accession', 'hit_def', 'hit_id', 'length', 'title':\n            print('    %s: %s' % (attr, getattr(alignment, attr)))\n        print('    HSPs (%d in total):' % len(alignment.hsps))\n        for hspIndex, hsp in enumerate(alignment.hsps, start=1):\n            print('      hsp %d:' % hspIndex)\n            printHSP(hsp, '        ')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing an HSP and returns a dictionary with keys that allow the query subject match begins and ends.", "response": "def normalizeHSP(hsp, readLen, blastApplication):\n    \"\"\"\n    Examine an HSP and return information about where the query and subject\n    match begins and ends.  Return a dict with keys that allow the query to\n    be displayed against the subject. The returned readStartInSubject and\n    readEndInSubject indices are offsets into the subject. I.e., they\n    indicate where in the subject the query falls.\n\n    In the returned object, all indices are suitable for Python string\n    slicing etc.  We must be careful to convert from the 1-based offsets\n    found in BLAST output properly.\n\n    hsp['frame'] is a (query, subject) 2-tuple, with both values coming from\n    {-3, -2, -1, 1, 2, 3}. The sign indicates negative or positive sense\n    (i.e., the direction of reading through the query or subject to get the\n    alignment). The value is the nucleotide match offset modulo 3, plus one\n    (i.e., it tells us which of the 3 possible reading frames is used in\n    the match). The value is redundant because that information could also\n    be obtained from the mod 3 value of the match offset.\n\n    NOTE: the returned readStartInSubject value may be negative.  We consider\n    the hit sequence to start at offset 0.  So if the read string has\n    sufficient additional nucleotides before the start of the alignment\n    match, it may protrude to the left of the hit. Similarly, the returned\n    readEndInSubject can be greater than the subjectEnd.\n\n    @param hsp: an HSP in the form of a C{dict}, built from a BLAST record.\n        All passed hsp offsets are 1-based.\n    @param readLen: the length of the read sequence.\n    @param blastApplication: The C{str} command line program that was\n        run (e.g., 'blastn', 'blastx').\n\n    \"\"\"\n\n    def debugPrint(locals, msg=None):\n        \"\"\"\n        Print debugging information showing the local variables from\n        a call to normalizeHSP and then raise an C{AssertionError}.\n\n        @param locals: A C{dict} of local variables.\n        @param msg: A C{str} message to raise C{AssertionError} with.\n        \"\"\"\n        print('normalizeHSP error:')\n        print('  readLen: %d' % readLen)\n        for var in sorted(locals.keys()):\n            if var in ('debugPrint', 'hsp'):\n                continue\n            print('  %s: %s' % (var, locals[var]))\n        print('  Original HSP:')\n        printHSP(hsp, '    ')\n        if msg:\n            raise AssertionError(msg)\n        else:\n            raise AssertionError()\n\n    readPositive = hsp['frame'][0] > 0\n    hitPositive = hsp['frame'][1] > 0\n\n    # The following variable names with underscores match the names of\n    # attributes BioPython uses and the values (1-based) match those\n    # reported by BLAST.\n    read_start = hsp['query_start']\n    read_end = hsp['query_end']\n    sbjct_start = hsp['sbjct_start']\n    sbjct_end = hsp['sbjct_end']\n\n    # When the read is positive, BLASTN and TBLASTX give read offsets\n    # ascending.\n    #\n    # TBLASTX reports negative read sense with indices ascending.\n    # BLASTN does not report negative read sense.\n    #\n    # In all cases the read offsets should be ascending.\n    if read_start > read_end:\n        debugPrint(locals(),\n                   'Assertion \"read_start <= read_end\" failed. Read '\n                   'positive is %s. read_start = %d, read_end = %d' %\n                   (readPositive, read_start, read_end))\n\n    if hitPositive:\n        # Make sure indices are ascending.\n        if sbjct_start > sbjct_end:\n            debugPrint(locals())\n    else:\n        # Hit is negative. Its indices will be ascending for TBLASTX\n        # output but descending for BLASTN :-( Make sure we have them\n        # ascending.\n        if sbjct_start > sbjct_end:\n            sbjct_start, sbjct_end = sbjct_end, sbjct_start\n\n    # Now that we have asserted what we can about the original HSP values\n    # and gotten them into ascending order, make some sane 0-based offsets.\n    readStartInSubject = read_start - 1\n    readEndInSubject = read_end\n    subjectStart = sbjct_start - 1\n    subjectEnd = sbjct_end\n\n    if blastApplication == 'blastx':\n        # In Blastx output, hit offsets are based on protein sequence\n        # length but queries (and the reported offsets) are nucleotide.\n        # Convert the read offsets to protein because we will plot against\n        # the hit (protein).\n        #\n        # Note that readStartInSubject and readEndInSubject may not be 0 mod\n        # 3. They are offsets into the read string giving the position of\n        # the AA, which depends on the translation frame.\n        readStartInSubject = int(readStartInSubject / 3)\n        readEndInSubject = int(readEndInSubject / 3)\n\n    # No operations on original 1-based HSP variables (with underscores)\n    # should appear beyond this point.\n\n    subjectLength = subjectEnd - subjectStart\n    readLength = readEndInSubject - readStartInSubject\n\n    # NOTE: readLength (above) is a really bad name. It's actually going to\n    # hold the length of the match in the query. I don't know why\n    # readEndInSubject - readStartInSubject is used (I mean why those two\n    # variables are not named readEnd and readStart). Maybe someone made a\n    # find and replace editing error which changed their names. Anyway, the\n    # readLength variable is confusingly named because this function is\n    # passed a 'readLen' argument, which does happen to be the full length\n    # of the read.  This should be cleaned up. See ../diamond/hsp.py for\n    # something cleaner.\n\n    hitGaps = hsp['sbjct'].count('-')\n    readGaps = hsp['query'].count('-')\n\n    # Sanity check that the length of the matches in the hit and read\n    # are identical, taking into account gaps in either (indicated by '-'\n    # characters in the match sequences, as returned by BLAST).\n    subjectLengthWithGaps = subjectLength + hitGaps\n    readLengthWithGaps = readLength + readGaps\n    if subjectLengthWithGaps != readLengthWithGaps:\n        debugPrint(locals(),\n                   'Including gaps, hit match length (%d) != Read match '\n                   'length (%d)' % (subjectLengthWithGaps,\n                                    readLengthWithGaps))\n\n    # TODO: check the mod 3 value of the start offsets.\n\n    # Calculate read indices. These are indices relative to the hit!\n\n    # unmatchedReadLeft is the number of read bases that will be sticking\n    # out to the left of the start of the hit in our plots.\n    if readPositive:\n        unmatchedReadLeft = readStartInSubject\n    else:\n        unmatchedReadLeft = readLen - readEndInSubject\n\n    # Set the read offsets based on the direction the match with the\n    # hit takes.\n    if hitPositive:\n        readStartInSubject = subjectStart - unmatchedReadLeft\n        readEndInSubject = readStartInSubject + readLen + readGaps\n    else:\n        readEndInSubject = subjectEnd + unmatchedReadLeft\n\n        readStartInSubject = readEndInSubject - readLen - readGaps\n\n    # Final sanity checks.\n    if readStartInSubject > subjectStart:\n        debugPrint(locals(), 'readStartInSubject > subjectStart')\n    if readEndInSubject < subjectEnd:\n        debugPrint(locals(), 'readEndInSubject < subjectEnd')\n\n    return {\n        'readStart': read_start - 1,\n        'readEnd': read_end,\n        'readStartInSubject': readStartInSubject,\n        'readEndInSubject': readEndInSubject,\n        'subjectStart': subjectStart,\n        'subjectEnd': subjectEnd,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a GAF file containing GO annotations.", "response": "def parse_gaf(path_or_buffer, gene_ontology, valid_genes=None,\n              db=None, ev_codes=None):\n    \"\"\"Parse a GAF 2.1 file containing GO annotations.\n    \n    Parameters\n    ----------\n    path_or_buffer : str or buffer\n        The GAF file.\n    gene_ontology : `GeneOntology`\n        The Gene Ontology.\n    valid_genes : Iterable of str, optional\n        A list of valid gene names. [None]\n    db : str, optional\n        Select only annotations with this \"DB\"\" value. [None]\n    ev_codes : str or set of str, optional\n        Select only annotations with this/these evidence codes. [None]\n    \n    Returns\n    -------\n    list of `GOAnnotation`\n        The list of GO annotations.\n    \"\"\"\n    #if path == '-':\n    #    path = sys.stdin\n\n    assert isinstance(gene_ontology, GeneOntology)\n    if db is not None:\n        assert isinstance(db, (str, _oldstr))\n    if (ev_codes is not None) and ev_codes:\n        assert isinstance(ev_codes, (str, _oldstr)) or \\\n                isinstance(ev_codes, Iterable)\n\n    if isinstance(ev_codes, str):\n        ev_codes = set([ev_codes])\n    elif (ev_codes is not None) and ev_codes:\n        ev_codes = set(ev_codes)\n    else:\n        ev_codes = None\n\n    # open file, if necessary\n    if isinstance(path_or_buffer, (str, _oldstr)):\n        buffer = misc.gzip_open_text(path_or_buffer, encoding='ascii')\n    else:\n        buffer = path_or_buffer\n\n    if valid_genes is not None:\n        valid_genes = set(valid_genes)\n\n    # use pandas to parse the file quickly\n    df = pd.read_csv(buffer, sep='\\t', comment='!', header=None, dtype=_oldstr)\n\n    # replace pandas' NaNs with empty strings\n    df.fillna('', inplace=True)\n\n    # exclude annotations with unknown Gene Ontology terms\n    all_go_term_ids = set(gene_ontology._term_dict.keys())\n    sel = df.iloc[:, 4].isin(all_go_term_ids)\n    logger.info(\n        'Ignoring %d / %d annotations (%.1f %%) with unknown GO terms.',\n        (~sel).sum(), sel.size, 100*((~sel).sum()/float(sel.size)))\n    df = df.loc[sel]\n\n    # filter rows for valid genes\n    if valid_genes is not None:\n        sel = df.iloc[:, 2].isin(valid_genes)\n        logger.info(\n            'Ignoring %d / %d annotations (%.1f %%) with unknown genes.',\n            (~sel).sum(), sel.size, 100*((~sel).sum()/float(sel.size)))\n        df = df.loc[sel]\n\n    # filter rows for DB value\n    if db is not None:\n        sel = (df.iloc[:, 0] == db)\n        logger.info(\n            'Excluding %d / %d annotations (%.1f %%) with wrong DB values.',\n            (~sel).sum(), sel.size, 100*((~sel).sum()/float(sel.size)))\n        df = df.loc[sel]\n\n    # filter rows for evidence value\n    if ev_codes is not None:\n        sel = (df.iloc[:, 6].isin(ev_codes))\n        logger.info(\n            'Excluding %d / %d annotations (%.1f %%) based on evidence code.',\n            (~sel).sum(), sel.size, 100*((~sel).sum()/float(sel.size)))\n        df = df.loc[sel]\n\n    # convert each row into a GOAnnotation object\n    go_annotations = []\n    for i, l in df.iterrows():\n        ann = GOAnnotation.from_list(gene_ontology, l.tolist())\n        go_annotations.append(ann)\n    logger.info('Read %d GO annotations.', len(go_annotations))\n\n    return go_annotations"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_goa_gene_sets(go_annotations):\n    go_term_genes = OrderedDict()\n    term_ids = {}\n    for ann in go_annotations:\n        term_ids[ann.go_term.id] = ann.go_term\n        try:\n            go_term_genes[ann.go_term.id].append(ann.db_symbol)\n        except KeyError:\n            go_term_genes[ann.go_term.id] = [ann.db_symbol]\n    \n    go_term_genes = OrderedDict(sorted(go_term_genes.items()))\n    gene_sets = []\n    for tid, genes in go_term_genes.items():\n        go_term = term_ids[tid]\n        gs = GeneSet(id=tid, name=go_term.name, genes=genes,\n                     source='GO',\n                     collection=go_term.domain_short,\n                     description=go_term.definition)\n        gene_sets.append(gs)\n    gene_sets = GeneSetCollection(gene_sets)\n    return gene_sets", "response": "Generate a list of gene sets from a collection of GO annotations."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pipeline_control(rst, clk, rx_rdy, rx_vld, tx_rdy, tx_vld, stage_enable, stop_rx=None, stop_tx=None):\n\n    NUM_STAGES = len(stage_enable)\n\n    if (stop_rx == None):\n        stop_rx = Signal(intbv(0)[NUM_STAGES:])\n\n    if (stop_tx == None):\n        stop_tx = Signal(intbv(0)[NUM_STAGES:])\n\n    assert (len(stop_rx)==NUM_STAGES), \"pipeline_control: expects len(stop_rx)=len(stage_enable), but len(stop_rx)={} len(stage_enable)={}\".format(len(stop_rx),NUM_STAGES)\n    assert (len(stop_tx)==NUM_STAGES), \"pipeline_control: expects len(stop_tx)=len(stage_enable), but len(stop_tx)={} len(stage_enable)={}\".format(len(stop_tx),NUM_STAGES)\n\n    vld_reg = Signal(intbv(0)[NUM_STAGES:])\n    vld = Signal(intbv(0)[NUM_STAGES:])\n    rdy = Signal(intbv(0)[NUM_STAGES:])\n    rdy_s = Signal(intbv(0)[NUM_STAGES:])\n\n    @always_seq(clk.posedge, reset=rst)\n    def regs():\n        for s in range(NUM_STAGES):\n            if rdy[s]:\n                vld_reg.next[s] = vld[s]\n\n    @always_comb\n    def comb_chain():\n        vld.next[0] = rx_vld or stop_rx[0]\n        rdy.next[NUM_STAGES-1] = tx_rdy or stop_tx[NUM_STAGES-1] or not vld_reg[NUM_STAGES-1]\n        for i in range(1,NUM_STAGES):\n            vld.next[i] = (vld_reg[i-1] and not stop_tx[i-1]) or stop_rx[i]\n            rdy.next[NUM_STAGES-1-i] = (rdy_s[NUM_STAGES-1-i+1] and not stop_rx[NUM_STAGES-1-i+1]) or stop_tx[NUM_STAGES-1-i]\n\n    @always_comb\n    def comb_assign():\n        tx_vld.next = vld_reg[NUM_STAGES-1] and not stop_tx[NUM_STAGES-1]\n        rx_rdy.next = rdy[0] and not stop_rx[0]\n        stage_enable.next = vld[NUM_STAGES:] & rdy[NUM_STAGES:]\n        rdy_s.next = rdy\n\n\n    return instances()", "response": "Synchronizes data flow in a pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pipeline_control_new(rst, clk, rx_rdy, rx_vld, tx_rdy, tx_vld, stage_enable, stop_rx=None, stop_tx=None):\n\n    NUM_STAGES = len(stage_enable)\n\n    if (stop_rx == None):\n        stop_rx = Signal(intbv(0)[NUM_STAGES:])\n\n    if (stop_tx == None):\n        stop_tx = Signal(intbv(0)[NUM_STAGES:])\n\n    assert (len(stop_rx)==NUM_STAGES), \"pipeline_control: expects len(stop_rx)=len(stage_enable), but len(stop_rx)={} len(stage_enable)={}\".format(len(stop_rx),NUM_STAGES)\n    assert (len(stop_tx)==NUM_STAGES), \"pipeline_control: expects len(stop_tx)=len(stage_enable), but len(stop_tx)={} len(stage_enable)={}\".format(len(stop_tx),NUM_STAGES)\n\n    rdy = [Signal(bool(0)) for _ in range(NUM_STAGES+1)]\n    vld = [Signal(bool(0)) for _ in range(NUM_STAGES+1)]\n    BC = NUM_STAGES*[False]\n    en = [Signal(bool(0)) for _ in range(NUM_STAGES)]\n    stop_rx_s = [Signal(bool(0)) for _ in range(NUM_STAGES)]\n    stop_tx_s = [Signal(bool(0)) for _ in range(NUM_STAGES)]\n\n    rdy[0] = rx_rdy\n    vld[0] = rx_vld\n    rdy[-1] = tx_rdy\n    vld[-1] = tx_vld\n    BC[-1] = True\n\n    stg = [None for _ in range(NUM_STAGES)]\n\n    for i in range(NUM_STAGES):\n        stg[i] = _stage_ctrl(rst = rst,\n                             clk = clk,\n                             rx_rdy = rdy[i],\n                             rx_vld = vld[i],\n                             tx_rdy = rdy[i+1],\n                             tx_vld = vld[i+1],\n                             stage_en = en[i],\n                             stop_rx = stop_rx_s[i],\n                             stop_tx = stop_tx_s[i],\n                             BC = BC[i])\n\n    x = en[0] if NUM_STAGES==1 else ConcatSignal(*reversed(en))\n\n    @always_comb\n    def _comb():\n        stage_enable.next = x\n        for i in range(NUM_STAGES):\n            stop_rx_s[i].next = stop_rx[i]\n            stop_tx_s[i].next = stop_tx[i]\n\n    return instances()", "response": "This function is used to create a new pipeline control unit."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _stage_ctrl(rst, clk, rx_rdy, rx_vld, tx_rdy, tx_vld, stage_en, stop_rx=None, stop_tx=None, BC=False):\n    ''' Single stage control\n            BC - enable bubble compression\n    '''\n    if stop_rx==None:\n        stop_rx = False\n\n    if stop_tx==None:\n        stop_tx = False\n\n    state = Signal(bool(0))\n    a = Signal(bool(0))\n    b = Signal(bool(0))\n    bc_link = state if BC else True\n\n    @always_comb\n    def _comb1():\n        a.next = tx_rdy or stop_tx or not bc_link\n        b.next = rx_vld or stop_rx\n\n    @always_comb\n    def _comb2():\n        rx_rdy.next = a and not stop_rx\n        tx_vld.next = state and not stop_tx\n        stage_en.next = a and b\n\n    @always_seq(clk.posedge, reset=rst)\n    def _state():\n        if a:\n            state.next = b\n\n    return _comb1, _comb2, _state", "response": "Single stage control of a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint debugging information showing the local variables used during a HSP and the HSP.", "response": "def _debugPrint(hsp, queryLen, localDict, msg=''):\n    \"\"\"\n    Print debugging information showing the local variables used during\n    a call to normalizeHSP and the hsp and then raise an C{AssertionError}.\n\n    @param hsp: The HSP C{dict} passed to normalizeHSP.\n    @param queryLen: the length of the query sequence.\n    @param localDict: A C{dict} of local variables (as produced by locals()).\n    @param msg: A C{str} message to raise C{AssertionError} with.\n    @raise AssertionError: unconditionally.\n    \"\"\"\n    print('normalizeHSP error:', file=sys.stderr)\n    print('  queryLen: %d' % queryLen, file=sys.stderr)\n\n    print('  Original HSP:', file=sys.stderr)\n    for attr in ['bits', 'btop', 'expect', 'frame', 'query_end', 'query_start',\n                 'sbjct', 'query', 'sbjct_end', 'sbjct_start']:\n        print('    %s: %r' % (attr, hsp[attr]), file=sys.stderr)\n\n    print('  Local variables:', file=sys.stderr)\n    for var in sorted(localDict):\n        if var != 'hsp':\n            print('    %s: %s' % (var, localDict[var]), file=sys.stderr)\n\n    raise AssertionError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sanityCheck(subjectStart, subjectEnd, queryStart, queryEnd,\n                 queryStartInSubject, queryEndInSubject, hsp, queryLen,\n                 subjectGaps, queryGaps, localDict):\n    \"\"\"\n    Perform some sanity checks on an HSP. Call _debugPrint on any error.\n\n    @param subjectStart: The 0-based C{int} start offset of the match in the\n        subject.\n    @param subjectEnd: The 0-based C{int} end offset of the match in the\n        subject.\n    @param queryStart: The 0-based C{int} start offset of the match in the\n        query.\n    @param queryEnd: The 0-based C{int} end offset of the match in the query.\n    @param queryStartInSubject: The 0-based C{int} offset of where the query\n        starts in the subject.\n    @param queryEndInSubject: The 0-based C{int} offset of where the query\n        ends in the subject.\n    @param hsp: The HSP C{dict} passed to normalizeHSP.\n    @param queryLen: the C{int} length of the query sequence.\n    @param subjectGaps: the C{int} number of gaps in the subject.\n    @param queryGaps: the C{int} number of gaps in the query.\n    @param localDict: A C{dict} of local variables from our caller (as\n        produced by locals()).\n    \"\"\"\n    # Subject indices must always be ascending.\n    if subjectStart >= subjectEnd:\n        _debugPrint(hsp, queryLen, localDict, 'subjectStart >= subjectEnd')\n\n    subjectMatchLength = subjectEnd - subjectStart\n    queryMatchLength = queryEnd - queryStart\n\n    # Sanity check that the length of the matches in the subject and query\n    # are identical, taking into account gaps in both.\n    subjectMatchLengthWithGaps = subjectMatchLength + subjectGaps\n    queryMatchLengthWithGaps = queryMatchLength + queryGaps\n    if subjectMatchLengthWithGaps != queryMatchLengthWithGaps:\n        _debugPrint(hsp, queryLen, localDict,\n                    'Including gaps, subject match length (%d) != Query match '\n                    'length (%d)' % (subjectMatchLengthWithGaps,\n                                     queryMatchLengthWithGaps))\n\n    if queryStartInSubject > subjectStart:\n        _debugPrint(hsp, queryLen, localDict,\n                    'queryStartInSubject (%d) > subjectStart (%d)' %\n                    (queryStartInSubject, subjectStart))\n    if queryEndInSubject < subjectEnd:\n        _debugPrint(hsp, queryLen, localDict,\n                    'queryEndInSubject (%d) < subjectEnd (%d)' %\n                    (queryEndInSubject, subjectEnd))", "response": "Perform some sanity checks on an HSP."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalizing a HSP and returns a dictionary with keys that allow the query and subject match begins and ends.", "response": "def normalizeHSP(hsp, queryLen, diamondTask):\n    \"\"\"\n    Examine an HSP and return information about where the query and subject\n    match begins and ends.  Return a dict with keys that allow the query to\n    be displayed against the subject. The returned readStartInSubject and\n    readEndInSubject indices are offsets into the subject. I.e., they\n    indicate where in the subject the query falls.\n\n    In the returned object, all indices are suitable for Python string\n    slicing etc.  We must be careful to convert from the 1-based offsets\n    found in DIAMOND output properly.\n\n    hsp['frame'] is a value from {-3, -2, -1, 1, 2, 3}. The sign indicates\n    negative or positive sense (i.e., the direction of reading through the\n    query to get the alignment). The frame value is the nucleotide match offset\n    modulo 3, plus one (i.e., it tells us which of the 3 possible query reading\n    frames was used in the match).\n\n    NOTE: the returned readStartInSubject value may be negative.  We consider\n    the subject sequence to start at offset 0.  So if the query string has\n    sufficient additional nucleotides before the start of the alignment\n    match, it may protrude to the left of the subject. Similarly, the returned\n    readEndInSubject can be greater than the subjectEnd.\n\n    @param hsp: an HSP in the form of a C{dict}, built from a DIAMOND record.\n        All passed offsets are 1-based.\n    @param queryLen: the length of the query sequence.\n    @param diamondTask: The C{str} command-line matching algorithm that was\n        run (either 'blastx' or 'blastp').\n    @return: A C{dict} with C{str} keys and C{int} offset values. Keys are\n            readStart\n            readEnd\n            readStartInSubject\n            readEndInSubject\n            subjectStart\n            subjectEnd\n        The returned offset values are all zero-based.\n    \"\"\"\n\n    queryGaps, subjectGaps = countGaps(hsp['btop'])\n\n    # Make some variables using Python's standard string indexing (start\n    # offset included, end offset not). No calculations in this function\n    # are done with the original 1-based HSP variables.\n    queryStart = hsp['query_start'] - 1\n    queryEnd = hsp['query_end']\n    subjectStart = hsp['sbjct_start'] - 1\n    subjectEnd = hsp['sbjct_end']\n\n    queryReversed = hsp['frame'] < 0\n\n    # Query offsets must be ascending, unless we're looking at blastx output\n    # and the query was reversed for the match.\n    if queryStart >= queryEnd:\n        if diamondTask == 'blastx' and queryReversed:\n            # Compute new query start and end indices, based on their\n            # distance from the end of the string.\n            #\n            # Above we took one off the start index, so we need to undo\n            # that (because the start is actually the end). We didn't take\n            # one off the end index, and need to do that now (because the\n            # end is actually the start).\n            queryStart = queryLen - (queryStart + 1)\n            queryEnd = queryLen - (queryEnd - 1)\n        else:\n            _debugPrint(hsp, queryLen, locals(), 'queryStart >= queryEnd')\n\n    if diamondTask == 'blastx':\n        # In DIAMOND blastx output, subject offsets are based on protein\n        # sequence length but queries (and the reported offsets) are\n        # nucleotide.  Convert the query offsets to protein because we will\n        # plot against the subject (protein).\n        #\n        # Convert queryLen and the query nucleotide start and end offsets\n        # to be valid for the query after translation to AAs. When\n        # translating, DIAMOND may ignore some nucleotides at the start\n        # and/or the end of the original DNA query. At the start this is\n        # due to the frame in use, and at the end it is due to always using\n        # three nucleotides at a time to form codons.\n        #\n        # So, for example, a query of 6 nucleotides that is translated in\n        # frame 2 (i.e., the translation starts from the second nucleotide)\n        # will have length 1 as an AA sequence. The first nucleotide is\n        # ignored due to the frame and the last two due to there not being\n        # enough final nucleotides to make another codon.\n        #\n        # In the following, the subtraction accounts for the first form of\n        # loss and the integer division for the second.\n        initiallyIgnored = abs(hsp['frame']) - 1\n        queryLen = (queryLen - initiallyIgnored) // 3\n        queryStart = (queryStart - initiallyIgnored) // 3\n        queryEnd = (queryEnd - initiallyIgnored) // 3\n\n    # unmatchedQueryLeft is the number of query bases that will extend\n    # to the left of the start of the subject in our plots.\n    unmatchedQueryLeft = queryStart\n\n    # Set the query offsets into the subject.\n    queryStartInSubject = subjectStart - unmatchedQueryLeft\n    queryEndInSubject = queryStartInSubject + queryLen + queryGaps\n\n    _sanityCheck(subjectStart, subjectEnd, queryStart, queryEnd,\n                 queryStartInSubject, queryEndInSubject, hsp, queryLen,\n                 subjectGaps, queryGaps, locals())\n\n    return {\n        'readStart': queryStart,\n        'readEnd': queryEnd,\n        'readStartInSubject': queryStartInSubject,\n        'readEndInSubject': queryEndInSubject,\n        'subjectStart': subjectStart,\n        'subjectEnd': subjectEnd,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nauthenticating a service account for reading and write on a bucket.", "response": "def get_storage_credentials(key, read_only=False):\n    \"\"\"Authenticates a service account for reading and/or writing on a bucket.\n    \n    This uses the `google.oauth2.service_account` module to obtain \"scoped\n    credentials\". These can be used with the `google.storage` module.\n\n    TODO: docstring\"\"\"\n    if read_only:\n        scopes = ['https://www.googleapis.com/auth/devstorage.read_only']\n    else:\n        scopes = ['https://www.googleapis.com/auth/devstorage.read_write']\n\n    credentials = service_account.Credentials.from_service_account_info(key)\n    \n    scoped_credentials = credentials.with_scopes(scopes)\n    \n    return scoped_credentials"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_compute_credentials(key):\n    scopes = ['https://www.googleapis.com/auth/compute']\n\n    credentials = ServiceAccountCredentials.from_json_keyfile_dict(\n        key, scopes=scopes)\n    \n    return credentials", "response": "Authenticates a service account for the compute engine."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hash(self):\n        h = hash_pandas_object(self, index=True)\n        return hashlib.md5(h.values.tobytes()).hexdigest()", "response": "Generate a hash value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all genes.", "response": "def genes(self):\n        \"\"\"Return a list of all genes.\"\"\"\n        return [ExpGene.from_series(g)\n                for i, g in self.reset_index().iterrows()]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread genes from tab - delimited text file.", "response": "def read_tsv(cls, file_or_buffer: str):\n        \"\"\"Read genes from tab-delimited text file.\"\"\"\n        df = pd.read_csv(file_or_buffer, sep='\\t', index_col=0)\n        df = df.where(pd.notnull(df), None)\n        # Note: df.where(..., None) changes all column types to `object`.\n        return cls(df)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize instance using a list of ExpGene objects.", "response": "def from_genes(cls, genes: List[ExpGene]):\n        \"\"\"Initialize instance using a list of `ExpGene` objects.\"\"\"\n        data = [g.to_dict() for g in genes]\n        index = [d.pop('ensembl_id') for d in data]\n        table = cls(data, index=index)\n        return table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_gene_ids(cls, gene_ids: List[str]):\n        genes = [ExpGene(id_) for id_ in gene_ids]\n        return cls.from_genes(genes)", "response": "Initialize instance from gene IDs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_gene_ids_and_names(cls, gene_names: Dict[str, str]):\n        genes = [ExpGene(id_, name=name) for id_, name in gene_names.items()]\n        return cls.from_genes(genes)", "response": "Initialize instance from gene IDs and names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding gene by name.", "response": "def find_gene(self, name: str):\n        \"\"\"Find gene(s) by name.\"\"\"\n        result = [ExpGene.from_series(s)\n                  for i, s in self.loc[self['name'] == name].iterrows()]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_figure(self, **kwargs):\n\n        emin = kwargs.pop('emin', -1.0)\n        emax = kwargs.pop('emax', 1.0)\n        width = kwargs.pop('width', 800)\n        height = kwargs.pop('height', 600)\n        margin_left = kwargs.pop('margin_left', 100)\n        margin_bottom = kwargs.pop('margin_bottom', 60)\n        margin_top = kwargs.pop('margin_top', 30)\n        margin_right = kwargs.pop('margin_right', 0)\n        colorbar_size = kwargs.pop('colorbar_size', 0.4)\n\n        xaxis_label = kwargs.pop('xaxis_label', None)\n        yaxis_label = kwargs.pop('yaxis_label', None)\n        xticks_angle = kwargs.pop('xaxis_angle', 30)\n        font = kwargs.pop('font', '\"Droid Serif\", \"Open Serif\", serif')\n        font_size = kwargs.pop('font_size', 12)\n        title = kwargs.pop('title', None)\n        title_font_size = kwargs.pop('title_font_size', None)\n        annotation_font_size = kwargs.pop('annotation_font_size', None)\n        show_sample_labels = kwargs.pop('show_sample_labels', 'x')\n\n        if show_sample_labels not in ['none', 'x', 'y', 'both']:\n            raise ValueError('\"show_sample_labels\" must be \"none\", \"x\", \"y\", '\n                             'or \"both\".')\n\n        padding_top = kwargs.pop('padding_top', 0.1)\n        padding_right = kwargs.pop('padding_top', 0.1)\n\n        xaxis_nticks = kwargs.pop('xaxis_nticks', None)\n        #yaxis_nticks = kwargs.pop('yaxis_nticks', None)\n\n        if title_font_size is None:\n            title_font_size = font_size\n\n        if annotation_font_size is None:\n            annotation_font_size = font_size\n\n        colorbar_label = self.colorbar_label or 'Pearson Correlation'\n\n        ### set up heatmap\n\n        colorbar = go.ColorBar(\n            lenmode='fraction',\n            len=colorbar_size,\n            title=colorbar_label,\n            titlefont = dict(\n                size=title_font_size,\n            ),\n            titleside='right',\n            xpad=0,\n            ypad=0,\n            outlinewidth=0,  # no border\n            thickness=20,  # in pixels\n            # outlinecolor = '#000000',\n        )\n\n        def fix_plotly_label_bug(labels):\n            \"\"\"\n            This fixes a bug whereby plotly treats labels that look\n            like numbers (integers or floats) as numeric instead of\n            categorical, even when they are passed as strings. The fix consists\n            of appending an underscore to any label that looks like a number.\n            \"\"\"\n            assert isinstance(labels, Iterable)\n            fixed_labels = []\n            for l in labels:\n                try:\n                    float(l)\n                except ValueError:\n                    fixed_labels.append(str(l))\n                else:\n                    fixed_labels.append(str(l) + '_')\n            return fixed_labels\n\n        x = fix_plotly_label_bug(self.corr_matrix.samples)\n        y = x\n\n        data = [\n            go.Heatmap(\n                z=self.corr_matrix.X,\n                x=x,\n                y=y,\n                zmin=emin,\n                zmax=emax,\n                colorscale=self.colorscale,\n                colorbar=colorbar,\n                hoverinfo='x+y+z',\n                **kwargs\n            ),\n        ]\n\n        xshowticklabels = False\n        yshowticklabels = False\n\n        ### set up layout\n        if show_sample_labels == 'x':\n            xshowticklabels = True\n        elif show_sample_labels == 'y':\n            yshowticklabels = True\n        elif show_sample_labels == 'both':\n            xshowticklabels = True\n            yshowticklabels = True\n\n        xticks = 'outside'\n        yticks = 'outside'\n\n        if xaxis_label is None:\n            if self.corr_matrix.samples.name is not None:\n                xaxis_label = self.corr_matrix.samples.name\n            else:\n                xaxis_label = 'Samples'\n            xaxis_label = xaxis_label + ' (n = %d)' % self.corr_matrix.n\n\n        if yaxis_label is None:\n            yaxis_label = xaxis_label\n\n        layout = go.Layout(\n            width=width,\n            height=height,\n            title=title,\n            titlefont=go.Font(\n                size=title_font_size\n            ),\n            font=go.Font(\n                size=font_size,\n                family=font\n            ),\n            xaxis=go.XAxis(\n                title=xaxis_label,\n                titlefont=dict(size=title_font_size),\n                showticklabels=xshowticklabels,\n                ticks=xticks,\n                nticks=xaxis_nticks,\n                tickangle=xticks_angle,\n                #range=[-0.5, self.corr_matrix.n-0.5],\n                showline=True,\n                zeroline=False,\n                showgrid=False,\n            ),\n            yaxis=go.YAxis(\n                title=yaxis_label,\n                titlefont=dict(size=title_font_size),\n                showticklabels=yshowticklabels,\n                ticks=xticks,\n                nticks=xaxis_nticks,\n                autorange='reversed',\n                showline=True,\n                zeroline=False,\n                showgrid=False,\n            ),\n\n            margin=go.Margin(\n                l=margin_left,\n                t=margin_top,\n                b=margin_bottom,\n                r=margin_right,\n                pad=0\n            ),\n        )\n\n        ### add annotations\n\n        # we need separate, but overlaying, axes to place the annotations\n        layout['xaxis2'] = go.XAxis(\n            overlaying='x',\n            showline=False,\n            tickfont=dict(size=0),\n            autorange=False,\n            #range=[-0.5, self.corr_matrix.n-0.5],\n            range=[-0.5, self.corr_matrix.n-0.5],\n            ticks='',\n            showticklabels=False,\n            zeroline=False,\n            showgrid=False,\n        )\n\n        layout['yaxis2'] = go.YAxis(\n            overlaying='y',\n            showline=False,\n            tickfont=dict(size=0),\n            autorange=False,\n            range=[self.corr_matrix.n-0.5, -0.5],\n            ticks='',\n            showticklabels=False,\n            zeroline=False,\n            showgrid=False,\n        )\n\n        # generate coordinates and labels for the block annotations\n        k = len(self.block_annotations)\n        block_coords = np.zeros((k, 2), dtype=np.float64)\n        block_labels = []\n        for i, ann in enumerate(self.block_annotations):\n            block_coords[i, :] = [ann.start_index-0.5, ann.end_index+0.5]\n            block_labels.append(ann.label)\n\n        # this produces the squares for the block annotations\n        for i in range(k):\n            mn = block_coords[i, 0]\n            mx = block_coords[i, 1]\n            data.append(\n                go.Scatter(\n                    x=[mn, mx, mx, mn, mn],\n                    y=[mn, mn, mx, mx, mn],\n                    mode='lines',\n                    hoverinfo='none',\n                    showlegend=False,\n                    line=dict(color='black'),\n                    xaxis='x2',\n                    yaxis='y2',\n                )\n            )\n\n        # - this produces the square labels for the block annotations\n        # - we use plotly annotations, so that the labels are not limited\n        #   by the plotting area\n        for i in range(k):\n            mn = block_coords[i, 0]\n            mx = block_coords[i, 1]\n            layout.annotations.append(\n                dict(\n                    x=mx,\n                    y=(mn+mx)/2.0,\n                    text=block_labels[i],\n                    xref='x2',\n                    yref='y2',\n                    showarrow=False,\n                    #ax=20,\n                    #ay=-20,\n                    xanchor='left',\n                    yanchor='middle',\n                    font=dict(\n                        color='black',\n                        size=annotation_font_size,\n                        family='serif bold',\n                    ),\n                    bgcolor='white',\n                    opacity=0.7,\n                    #textanchor='top right'\n                )\n            )\n\n        fig = go.Figure(\n            data=data,\n            layout=layout\n        )\n\n        return fig", "response": "Get a plotly figure of the heatmap."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(src, trg, transform=None):\n    ''' copy items with optional fields transformation\n    '''\n    source = open(src[0], src[1])\n    target = open(trg[0], trg[1], autocommit=1000)\n\n    for item in source.get():\n        item = dict(item)\n        if '_id' in item:\n            del item['_id']\n\n        if transform:\n            item = transform(item)\n        target.put(trg[0](item))\n\n    source.close()\n    target.commit()\n    target.close()", "response": "copy items with optional fields transformation\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dict_factory(cursor, row):\n        ''' factory for sqlite3 to return results as dict\n        '''\n        d = {}\n        for idx, col in enumerate(cursor.description):\n            if col[0] == 'rowid':\n                d['_id'] = row[idx]\n            else:\n                d[col[0]] = row[idx]\n        return d", "response": "factory for sqlite3 to return results as dict\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fieldnames(self):\n        ''' return fieldnames\n        '''\n        if not self._fields:\n            if self._item_class is not None:\n                for m in inspect.getmembers(self._item_class):\n                    if m[0] == 'fields' and isinstance(m[1], dict):\n                        self._fields = m[1]\n                if not self._fields:\n                    raise RuntimeError('Unknown item type, no fields: %s' % self._item_class)\n            else:\n                raise RuntimeError('Item class is not defined, %s' % self._item_class)\n        return self._fields.keys()", "response": "Returns a list of fieldnames that are defined in the item class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_table(self, table_name):\n        ''' create sqlite's table for storing simple dictionaries\n        '''\n        if self.fieldnames:\n            sql_fields = []\n            for field in self._fields:\n                if field != '_id':\n                    if 'dblite' in self._fields[field]:\n                        sql_fields.append(' '.join([field, self._fields[field]['dblite']]))\n                    else:\n                        sql_fields.append(field)\n            sql_fields = ','.join(sql_fields)\n            SQL = 'CREATE TABLE IF NOT EXISTS %s (%s);' % (table_name, sql_fields)\n            try:\n                self._cursor.execute(SQL)\n            except sqlite3.OperationalError, err:\n                raise RuntimeError('Create table error, %s, SQL: %s' % (err, SQL))", "response": "create sqlite s table for storing simple dictionaries\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, criteria=None, offset=None, limit=None):\n        ''' returns items selected by criteria\n\n        If the criteria is not defined, get() returns all items.\n        '''\n        if criteria is None and limit is None:\n            return self._get_all()\n        elif limit is not None and limit == 1:\n            return self.get_one(criteria)\n        else:\n            return self._get_with_criteria(criteria, offset=offset, limit=limit)", "response": "returns items selected by criteria"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_all(self):\n        ''' return all items\n        '''\n        rowid = 0\n        while True:\n            SQL_SELECT_MANY = 'SELECT rowid, * FROM %s WHERE rowid > ? LIMIT ?;' % self._table\n            self._cursor.execute(SQL_SELECT_MANY, (rowid, ITEMS_PER_REQUEST))\n            items = self._cursor.fetchall()\n            if len(items) == 0:\n                break\n            for item in items:\n                rowid = item['_id']\n                yield self._make_item(item)", "response": "Returns all items in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_with_criteria(self, criteria, offset=None, limit=None):\n        ''' returns items selected by criteria\n        '''\n        SQL = SQLBuilder(self._table, criteria).select(offset=offset, limit=limit)\n        self._cursor.execute(SQL)\n        for item in self._cursor.fetchall():\n            yield self._make_item(item)", "response": "returns items selected by criteria"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting one item from the cache", "response": "def get_one(self, criteria):\n        ''' return one item\n        '''\n        try:\n            items = [item for item in self._get_with_criteria(criteria, limit=1)]\n            return items[0]\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _do_autocommit(self):\n        ''' perform autocommit\n        '''\n        # commit()\n        self._commit_counter += 1\n        # autocommit as boolean\n        if isinstance(self._autocommit, bool) and self._autocommit:\n            self.commit()\n            self._commit_counter = 0\n\n        # autocommit as counter\n        elif isinstance(self._autocommit, int) and self._autocommit > 0:\n            if (self._commit_counter % self._autocommit) == 0:\n                self.commit()\n                self._commit_counter = 0", "response": "perform autocommit as boolean\n            or counter\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore item in sqlite database", "response": "def put(self, item):\n        ''' store item in sqlite database\n        '''\n        if isinstance(item, self._item_class):\n            self._put_one(item)\n        elif isinstance(item, (list, tuple)):\n            self._put_many(item)\n        else:\n            raise RuntimeError('Unknown item(s) type, %s' % type(item))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore one item in database.", "response": "def _put_one(self, item):\n        ''' store one item in database\n        '''\n        # prepare values\n        values = []\n        for k, v in item.items():\n            if k == '_id':\n                continue\n            if 'dblite_serializer' in item.fields[k]:\n                serializer = item.fields[k]['dblite_serializer']\n                v = serializer.dumps(v)\n                if v is not None:\n                    v = sqlite3.Binary(buffer(v))\n            values.append(v)\n\n        # check if Item is new => update it\n        if '_id' in item:\n            fieldnames = ','.join(['%s=?' % f for f in item if f != '_id'])\n            values.append(item['_id'])\n            SQL = 'UPDATE %s SET %s WHERE rowid=?;' % (self._table, fieldnames)\n        # new Item\n        else:\n            fieldnames = ','.join([f for f in item if f != '_id'])\n            fieldnames_template = ','.join(['?' for f in item if f != '_id'])\n            SQL = 'INSERT INTO %s (%s) VALUES (%s);' % (self._table, fieldnames, fieldnames_template)\n\n        try:\n            self._cursor.execute(SQL, values)\n        except sqlite3.OperationalError, err:\n            raise RuntimeError('Item put() error, %s, SQL: %s, values: %s' % (err, SQL, values) )\n        except sqlite3.IntegrityError:\n            raise DuplicateItem('Duplicate item, %s' % item)\n        self._do_autocommit()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore multiple items in sqlite database.", "response": "def _put_many(self, items):\n        ''' store items in sqlite database\n        '''\n        for item in items:\n            if not isinstance(item, self._item_class):\n                raise RuntimeError('Items mismatch for %s and %s' % (self._item_class, type(item)))\n            self._put_one(item)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting sql request and return items alid", "response": "def sql(self, sql, params=()):\n        ''' execute sql request and return items\n        '''\n        def _items(items):\n            for item in items:\n                yield self._item_class(item)\n\n        sql = sql.strip()\n        try:\n            self._cursor.execute(sql, params)\n        except sqlite3.OperationalError, err:\n            raise SQLError('%s, SQL: %s, params: %s' % (err, sql, params) )\n        except sqlite3.IntegrityError:\n            raise DuplicateItem('Duplicate item, %s' % item)\n\n        if sql.upper().startswith('SELECT'):\n            return _items(self._cursor.fetchall())\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete items from the database.", "response": "def delete(self, criteria=None, _all=False):\n        ''' delete dictionary(ies) in sqlite database\n\n        _all = True - delete all items\n        '''\n        if isinstance(criteria, self._item_class):\n            criteria = {'_id': criteria['_id']}\n\n        if criteria is None and not _all:\n            raise RuntimeError('Criteria is not defined')\n\n        SQL = SQLBuilder(self._table, criteria).delete()\n        self._cursor.execute(SQL)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun an iterable of tasks.", "response": "def run_tasks(tasks, max_workers=None, use_processes=False):\n    \"\"\"\n    Run an iterable of tasks.\n\n    tasks: The iterable of tasks\n    max_workers: (optional, None) The maximum number of workers to use.\n        As of Python 3.5, if None is passed to the thread executor will\n        default to 5 * the number of processors and the process executor\n        will default to the number of processors. If you are running an\n        older version, consider this a non-optional value.\n    use_processes: (optional, False) use a process pool instead of a\n        thread pool.\n    \"\"\"\n    futures = set()\n\n    if use_processes:\n        get_executor = concurrent.futures.ProcessPoolExecutor\n    else:\n        get_executor = concurrent.futures.ThreadPoolExecutor\n\n    with get_executor(max_workers) as executor:\n        def execute(function, name):\n            \"\"\"\n            Submit a task to the pool\n            \"\"\"\n            future = executor.submit(function)\n            future.name = name\n\n            futures.add(future)\n\n        def wait():\n            \"\"\"\n            Wait for at least one task to complete\n            \"\"\"\n            results = []\n\n            waited = concurrent.futures.wait(\n                futures, return_when=concurrent.futures.FIRST_COMPLETED\n            )\n\n            for future in waited.done:\n                exc = future.exception()\n                if exc is None:\n                    results.append(\n                        TaskResult(\n                            future.name,\n                            True,\n                            None,\n                            future.result()\n                        )\n                    )\n                else:\n                    results.append(TaskResult(future.name, False, exc, None))\n\n                futures.remove(future)\n\n            return results\n\n        return task_loop(tasks, execute, wait)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting until a zone operation is finished.", "response": "def wait_for_zone_op(access_token, project, zone, name, interval=1.0):\n    \"\"\"Wait until a zone operation is finished.\n\n    TODO: docstring\"\"\"\n\n    assert isinstance(interval, (int, float))\n    assert interval >= 0.1\n    \n    status = 'RUNNING'\n    progress = 0\n\n    LOGGER.info('Waiting for zone operation \"%s\" to finish...', name)\n\n    while status != 'DONE':\n\n        # print('\\rRunning! Progress: %d %%' % progress, end='')\n        r = requests.get('https://www.googleapis.com/compute/v1/'\n                         'projects/%s/zones/%s/operations/%s?access_token=%s'\n                         % (project, zone, name, access_token.access_token))\n        r.raise_for_status()\n\n        # print(r.status_code)\n        #result = json.loads(r.content.decode('utf-8'))\n        result = r.json()\n        status = result['status']\n        progress = result['progress']\n\n        time.sleep(interval)\n\n    LOGGER.info('Zone operation \"%s\" done!', name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fillAndTraceback(self, table):\n        # Fill\n        max_score = 0\n        max_row = 0\n        max_col = 0\n\n        for row in range(1, len(self.seq2Seq) + 1):\n            for col in range(1, len(self.seq1Seq) + 1):\n                # Calculate match score\n                letter1 = self.seq1Seq[col - 1]\n                letter2 = self.seq2Seq[row - 1]\n                if letter1 == letter2:\n                    diagonal_score = (table[row - 1][col - 1]['score'] +\n                                      self.match)\n                else:\n                    diagonal_score = (table[row - 1][col - 1]['score'] +\n                                      self.mismatch)\n\n                ins_run = table[row - 1][col]['ins']\n                del_run = table[row][col - 1]['del']\n\n                # Calculate gap scores ensuring extension is not > 0\n                if table[row - 1][col]['ins'] <= 0:\n                    ins_score = table[row - 1][col]['score'] + self.gapOpen\n                else:\n                    if self.gapExtend + ins_run * self.gapExtendDecay <= 0.0:\n                        ins_score = (table[row - 1][col]['score'] +\n                                     self.gapExtend +\n                                     ins_run * self.gapExtendDecay)\n                    else:\n                        ins_score = table[row - 1][col]['score']\n\n                if table[row - 1][col]['del'] <= 0:\n                    del_score = table[row][col - 1]['score'] + self.gapOpen\n                else:\n                    if self.gapExtend + del_run * self.gapExtendDecay <= 0.0:\n                        del_score = (table[row][col - 1]['score'] +\n                                     self.gapExtend +\n                                     del_run * self.gapExtendDecay)\n                    else:\n                        del_score = table[row][col - 1]['score']\n\n                # Choose best score\n                if diagonal_score <= 0 and ins_score <= 0 and del_score <= 0:\n                    table[row][col] = {'score': 0, 'pointer': None, 'ins': 0,\n                                       'del': 0}\n                else:\n                    if diagonal_score >= ins_score:\n                        if diagonal_score >= del_score:  # diag lef/up\n                            diagonal = {'score': diagonal_score,\n                                        'pointer': 'diagonal', 'ins': 0,\n                                        'del': 0}\n                            table[row][col] = diagonal\n                        else:  # lef diag/up\n                            deletion = {'score': del_score, 'pointer': 'del',\n                                        'ins': 0, 'del': del_run + 1}\n                            table[row][col] = deletion\n                    else:  # up diag\n                        if ins_score >= del_score:  # up diag/lef\n                            insertion = {'score': ins_score, 'pointer': 'ins',\n                                         'ins': ins_run + 1, 'del': 0}\n                            table[row][col] = insertion\n                        else:  # lef up diag\n                            deletion = {'score': del_score, 'pointer': 'del',\n                                        'ins': 0, 'del': del_run + 1}\n                            table[row][col] = deletion\n\n                # Set max score - is this the best way of getting max score\n                # considering how the for loop iterates through the matrix?\n                if table[row][col]['score'] >= max_score:\n                    max_row = row\n                    max_col = col\n                    max_score = table[row][col]['score']\n\n        # Traceback\n        indexes = {'max_row': max_row, 'max_col': max_col}\n        align1 = ''\n        align2 = ''\n        align = ''\n\n        current_row = max_row\n        current_col = max_col\n\n        while True:\n            arrow = table[current_row][current_col]['pointer']\n            if arrow is None:\n                min_row = current_row + 1\n                min_col = current_col + 1\n                break\n            elif arrow == 'diagonal':\n                align1 += self.seq1Seq[current_col - 1]\n                align2 += self.seq2Seq[current_row - 1]\n                if self.seq1Seq[current_col - 1] == self.seq2Seq[\n                        current_row - 1]:\n                    align += '|'\n                else:\n                    align += ' '\n                current_row -= 1\n                current_col -= 1\n            elif arrow == 'del':\n                align1 += self.seq1Seq[current_col - 1]\n                align2 += '-'\n                align += ' '\n                current_col -= 1\n            elif arrow == 'ins':\n                align1 += '-'\n                align2 += self.seq2Seq[current_row - 1]\n                align += ' '\n                current_row -= 1\n            else:\n                raise ValueError('Invalid pointer: %s' % arrow)\n\n        indexes['min_row'] = min_row\n        indexes['min_col'] = min_col\n        align1 = align1[::-1]\n        align2 = align2[::-1]\n        align = align[::-1]\n\n        if len(align1) != len(align2):\n            raise ValueError(\n                'Lengths of locally aligned sequences differ (%d != %d).' % (\n                    len(align1), len(align2)))\n\n        return ([align1, align, align2], indexes)", "response": "Fills the table and then traces back from the highest score."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a cigar string of aligned sequences.", "response": "def _cigarString(self, output):\n        \"\"\"\n        Return a cigar string of aligned sequences.\n\n        @param output: a C{tup} of strings (align1, align, align2)\n        @return: a C{str} containing the cigar string. Eg with input:\n            'GGCCCGCA' and 'GG-CTGCA', return 2=1D1=1X3=\n        \"\"\"\n        cigar = []\n        count = 0\n        align1 = output[0]\n        align2 = output[2]\n        for nt1, nt2 in zip(align1, align2):\n            if nt1 == nt2:\n                cigar.append('=')\n            elif nt1 == '-':\n                cigar.append('I')\n            elif nt2 == '-':\n                cigar.append('D')\n            else:\n                cigar.append('X')\n        # Initially create a list of characters,\n        # eg ['=', '=', 'D', '=', 'X', '=', '=', '=']\n        cigar.append('*')\n        # Append an arbitrary character to ensure parsing below functions\n        cigarString = ''\n        previousCharacter = ''\n        count = 0\n        first = True\n        for character in cigar:\n            if first:\n                previousCharacter = character\n                count += 1\n                first = False\n            else:\n                if character == previousCharacter:\n                    count += 1\n                else:\n                    cigarString += (str(count) + str(previousCharacter))\n                    count = 1\n                previousCharacter = character\n        return cigarString"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a textual representation of an alignment result.", "response": "def _alignmentToStr(self, result):\n        \"\"\"\n        Make a textual representation of an alignment result.\n\n        @param result: A C{dict}, as returned by C{self.createAlignment}.\n        @return: A C{str} desription of a result. For every three lines the\n            first and third contain the input sequences, possibly padded\n            with '-'. The second contains '|' where the two sequences match,\n            and ' ' where not.\n            Format of the output is as follows:\n            Cigar: (Cigar string)\n            Evalue:\n            Bitscore:\n            Id1 Match start: (int) Match end: (int)\n            Id2 Match start: (int) Match end: (int)\n            Id1:  1 (seq) 50\n            [lines to show matches]\n            Id2:  1 (seq) 50\n        \"\"\"\n        if result is None:\n            return ('\\nNo alignment between %s and %s\\n' % (\n                self.seq1ID, self.seq2ID))\n        else:\n            header = (\n                '\\nCigar string of aligned region: %s\\n'\n                '%s Match start: %d Match end: %d\\n'\n                '%s Match start: %d Match end: %d\\n' %\n                (result['cigar'],\n                 self.seq1ID, result['sequence1Start'], result['sequence1End'],\n                 self.seq2ID, result['sequence2Start'], result['sequence2End'])\n            )\n            text = '\\n'.join(result['text'])\n\n            return header + text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createAlignment(self, resultFormat=dict):\n        table = self._initialise()\n        alignment = self._fillAndTraceback(table)\n        output = alignment[0]\n        if output[0] == '' or output[2] == '':\n            result = None\n        else:\n            indexes = alignment[1]\n            result = {\n                'cigar': self._cigarString(output),\n                'sequence1Start': indexes['min_col'],\n                'sequence1End': indexes['max_col'],\n                'sequence2Start': indexes['min_row'],\n                'sequence2End': indexes['max_row'],\n                'text': self._formatAlignment(output, indexes),\n            }\n\n        return self._alignmentToStr(result) if resultFormat is str else result", "response": "Run the alignment algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select(self, fields=['rowid', '*'], offset=None, limit=None):\n        ''' return SELECT SQL\n        '''\n        # base SQL\n        SQL = 'SELECT %s FROM %s' % (','.join(fields), self._table)\n        \n        # selectors\n        if self._selectors:\n            SQL = ' '.join([SQL, 'WHERE', self._selectors]).strip()\n        \n        # modifiers\n        if self._modifiers:\n            SQL = ' '.join([SQL, self._modifiers])\n\n        # limit\n        if limit is not None and isinstance(limit, int):\n            SQL = ' '.join((SQL, 'LIMIT %s' % limit))\n\n        # offset\n        if (limit is not None) and (offset is not None) and isinstance(offset, int):\n            SQL = ' '.join((SQL, 'OFFSET %s' % offset))\n\n        return ''.join((SQL, ';'))", "response": "Returns a SELECT statement that returns the table s fields."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing parameters and return SQL", "response": "def _parse(self, params):\n        ''' parse parameters and return SQL \n        '''\n        if not isinstance(params, dict):\n            return None, None\n\n        if len(params) == 0:\n            return None, None\n\n        selectors = list()\n        modifiers = list()\n        \n        for k in params.keys():\n\n            if k in LOGICAL_OPERATORS:\n                selectors.append(self._logical(k, params[k]))\n\n            elif k in QUERY_MODIFIERS:\n                modifiers.append(self._modifier(k, params[k]))\n\n            else:\n                if k == '_id':\n                    selectors.append(\"rowid%s\" % (self._value_wrapper(params[k])))\n                else:\n                    selectors.append(\"%s%s\" % (k, self._value_wrapper(params[k])))\n\n        _selectors = ' AND '.join(selectors).strip()\n        _modifiers = ' '.join(modifiers).strip()\n        return _selectors, _modifiers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _modifier(self, operator, params):\n        ''' \n        $orderby:   sorts the results of a query in ascending (1) or descending (-1) order.\n        '''\n\n        if operator == '$orderby':\n            order_types = {-1: 'DESC', 1: 'ASC'}\n            if not isinstance(params, dict):\n                raise RuntimeError('Incorrect parameter type, %s' % params) \n            return 'ORDER BY %s' % ','.join([\"%s %s\" % (p, order_types[params[p]]) for p in params])\n        else:\n            raise RuntimeError('Unknown operator, %s' % operator)", "response": "Returns the SQL modifier for the related resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a WSGI application that dispatches requests to controllers.", "response": "def make_router(*routings):\n    \"\"\"Return a WSGI application that dispatches requests to controllers \"\"\"\n    routes = []\n    for routing in routings:\n        methods, regex, app = routing[:3]\n        if isinstance(methods, basestring):\n            methods = (methods,)\n        vars = routing[3] if len(routing) >= 4 else {}\n        routes.append((methods, re.compile(unicode(regex)), app, vars))\n\n    def router(environ, start_response):\n        \"\"\"Dispatch request to controllers.\"\"\"\n        req = webob.Request(environ)\n        split_path_info = req.path_info.split('/')\n        if split_path_info[0]:\n            # When path_info doesn't start with a \"/\" this is an error or a attack => Reject request.\n            # An example of an URL with such a invalid path_info: http://127.0.0.1http%3A//127.0.0.1%3A80/result?...\n            ctx = contexts.Ctx(req)\n            headers = wsgihelpers.handle_cross_origin_resource_sharing(ctx)\n            return wsgihelpers.respond_json(ctx,\n                dict(\n                    apiVersion = 1,\n                    error = dict(\n                        code = 400,  # Bad Request\n                        message = ctx._(u\"Invalid path: {0}\").format(req.path_info),\n                        ),\n                    ),\n                headers = headers,\n                )(environ, start_response)\n        for methods, regex, app, vars in routes:\n            match = regex.match(req.path_info)\n            if match is not None:\n                if methods is not None and req.method not in methods:\n                    ctx = contexts.Ctx(req)\n                    headers = wsgihelpers.handle_cross_origin_resource_sharing(ctx)\n                    return wsgihelpers.respond_json(ctx,\n                        dict(\n                            apiVersion = 1,\n                            error = dict(\n                                code = 405,\n                                message = ctx._(u\"You cannot use HTTP {} to access this URL. Use one of {}.\").format(\n                                    req.method, methods),\n                                ),\n                            ),\n                        headers = headers,\n                        )(environ, start_response)\n                if getattr(req, 'urlvars', None) is None:\n                    req.urlvars = {}\n                req.urlvars.update(match.groupdict())\n                req.urlvars.update(vars)\n                req.script_name += req.path_info[:match.end()]\n                req.path_info = req.path_info[match.end():]\n                return app(req.environ, start_response)\n        ctx = contexts.Ctx(req)\n        headers = wsgihelpers.handle_cross_origin_resource_sharing(ctx)\n        return wsgihelpers.respond_json(ctx,\n            dict(\n                apiVersion = 1,\n                error = dict(\n                    code = 404,  # Not Found\n                    message = ctx._(u\"Path not found: {0}\").format(req.path_info),\n                    ),\n                ),\n            headers = headers,\n            )(environ, start_response)\n\n    return router"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconnecting to an nREPL endpoint identified by the given URL or URI.", "response": "def connect(uri):\n    \"\"\"\n    Connects to an nREPL endpoint identified by the given URL/URI.  Valid\n    examples include:\n\n      nrepl://192.168.0.12:7889\n      telnet://localhost:5000\n      http://your-app-name.heroku.com/repl\n\n    This fn delegates to another looked up in  that dispatches on the scheme of\n    the URI provided (which can be a string or java.net.URI).  By default, only\n    `nrepl` (corresponding to using the default bencode transport) is\n    supported. Alternative implementations may add support for other schemes,\n    such as http/https, JMX, various message queues, etc.\n    \"\"\"\n    #\n    uri = uri if isinstance(uri, ParseResult) else urlparse(uri)\n    if not uri.scheme:\n        raise ValueError(\"uri has no scheme: \" + uri)\n    f = _connect_fns.get(uri.scheme.lower(), None)\n    if not f:\n        err = \"No connect function registered for scheme `%s`\" % uri.scheme\n        raise Exception(err)\n    return f(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a new watch under key that filters messages using criteria.", "response": "def watch(self, key, criteria, callback):\n        \"\"\"\n        Registers a new watch under [key] (which can be used with `unwatch()`\n        to remove the watch) that filters messages using [criteria] (may be a\n        predicate or a 'criteria dict' [see the README for more info there]).\n        Matching messages are passed to [callback], which must accept three\n        arguments: the matched incoming message, this instance of\n        `WatchableConnection`, and the key under which the watch was\n        registered.\n        \"\"\"\n        if hasattr(criteria, '__call__'):\n            pred = criteria\n        else:\n            pred = lambda incoming: _match_criteria(criteria, incoming)\n        with self._watches_lock:\n            self._watches[key] = (pred, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fifo_async(wrst, rrst, wclk, rclk, wfull, we, wdata, rempty, re, rdata, depth=None, width=None):\n    ''' Asynchronous FIFO\n\n        Implements the design described in:\n            Clifford E. Cummings, \"Simulation and Synthesis Techniques for Asynchronous FIFO Design,\" SNUG 2002 (Synopsys\n            Users Group Conference, San Jose, CA, 2002) User Papers, March 2002, Section TB2, 2nd paper. Also available at\n            www.sunburst-design.com/papers\n\n        Write side interface:\n            wrst   - reset \n            wclk   - clock\n            wfull  - full flag, immediate set on 'write', delayed clear on 'read' due to clock domain synchronization\n            we     - write enable\n            wdata  - write data\n        Read side interface\n            rrst   - reset\n            cclk   - clock\n            rempty - empty flag, immediate set on 'read', delayed clear on 'write' due to clock domain synchronization\n            re     - read enable\n            rdata  - read data\n        Parameters\n            depth - fifo depth. If not set, default 4 is used. Must be >=4. Must be power of 2\n            width - data width. If not set, data with equals len(wdata). Can be [0,1,2,3...)\n                    It is possible to instantiate a fifo with data width 0 (no data) if width=0 or width=None and wdata=None\n    '''\n\n    if (width == None):\n        width = 0\n        if wdata is not None:\n            width = len(wdata)\n\n    if (depth == None):\n        depth = 4\n    assert depth >= 4, \"Fifo_async parameter 'depth' must be >= 4 , detected depth={}\".format(depth)\n    assert (depth & (depth-1)) == 0, \"Fifo_async parameter 'depth' must be 2**n, detected depth={}\".format(depth)\n\n\n    full_flg        = Signal(bool(1))\n    empty_flg       = Signal(bool(1))\n    full_val        = Signal(bool(1))\n    empty_val       = Signal(bool(1))\n    we_safe         = Signal(bool(0))\n    re_safe         = Signal(bool(0))\n    rd_ptr          = Signal(intbv(0, min=0, max=depth))\n    wr_ptr          = Signal(intbv(0, min=0, max=depth))\n\n    WIDTH = len(rd_ptr)\n\n    rd_ptr_bin          = Signal(intbv(0)[WIDTH+1:])\n    rd_ptr_bin_new      = Signal(intbv(0)[WIDTH+1:])\n    rd_ptr_gray         = Signal(intbv(0)[WIDTH+1:])\n    rd_ptr_gray_new     = Signal(intbv(0)[WIDTH+1:])\n    rd_ptr_gray_sync1   = Signal(intbv(0)[WIDTH+1:])\n    rd_ptr_gray_sync2   = Signal(intbv(0)[WIDTH+1:])\n    wr_ptr_bin          = Signal(intbv(0)[WIDTH+1:])\n    wr_ptr_bin_new      = Signal(intbv(0)[WIDTH+1:])\n    wr_ptr_gray         = Signal(intbv(0)[WIDTH+1:])\n    wr_ptr_gray_new     = Signal(intbv(0)[WIDTH+1:])\n    wr_ptr_gray_sync1   = Signal(intbv(0)[WIDTH+1:])\n    wr_ptr_gray_sync2   = Signal(intbv(0)[WIDTH+1:])\n\n    @always_comb\n    def safe_read_write():\n        wfull.next      = full_flg\n        rempty.next     = empty_flg\n        we_safe.next    = we and not full_flg\n        re_safe.next    = re and not empty_flg\n\n    @always(wclk.posedge)\n    def sync_r2w():\n        ''' Read-domain to write-domain synchronizer '''\n        if (wrst):\n            rd_ptr_gray_sync1.next = 0\n            rd_ptr_gray_sync2.next = 0\n        else:\n            rd_ptr_gray_sync1.next = rd_ptr_gray\n            rd_ptr_gray_sync2.next = rd_ptr_gray_sync1\n\n    @always(rclk.posedge)\n    def sync_w2r():\n        ''' Write-domain to read-domain synchronizer '''\n        if (rrst):\n            wr_ptr_gray_sync1.next = 0\n            wr_ptr_gray_sync2.next = 0\n        else:\n            wr_ptr_gray_sync1.next = wr_ptr_gray\n            wr_ptr_gray_sync2.next = wr_ptr_gray_sync1\n\n    @always_comb\n    def bin_comb():\n        wr_ptr_bin_new.next = wr_ptr_bin\n        rd_ptr_bin_new.next = rd_ptr_bin\n        if (we_safe):\n            wr_ptr_bin_new.next = (wr_ptr_bin + 1) % wr_ptr_bin.max\n        if (re_safe):\n            rd_ptr_bin_new.next = (rd_ptr_bin + 1) % rd_ptr_bin.max\n\n    @always_comb\n    def gray_comb():\n        wr_ptr_gray_new.next    = (wr_ptr_bin_new >> 1) ^ wr_ptr_bin_new\n        rd_ptr_gray_new.next    = (rd_ptr_bin_new >> 1) ^ rd_ptr_bin_new\n\n    @always_comb\n    def full_empty_comb():\n        empty_val.next  = (rd_ptr_gray_new == wr_ptr_gray_sync2)\n        full_val.next   = (wr_ptr_gray_new[WIDTH] != rd_ptr_gray_sync2[WIDTH]) and \\\n                          (wr_ptr_gray_new[WIDTH-1] != rd_ptr_gray_sync2[WIDTH-1]) and \\\n                          (wr_ptr_gray_new[WIDTH-1:] == rd_ptr_gray_sync2[WIDTH-1:])\n\n\n    @always(wclk.posedge)\n    def wptr_proc():\n        if (wrst):\n            wr_ptr_bin.next     = 0\n            wr_ptr_gray.next    = 0\n            full_flg.next       = 0\n        else:\n            wr_ptr_bin.next     = wr_ptr_bin_new\n            wr_ptr_gray.next    = wr_ptr_gray_new\n            full_flg.next       = full_val\n\n    @always(rclk.posedge)\n    def rptr_proc():\n        if (rrst):\n            rd_ptr_bin.next     = 0\n            rd_ptr_gray.next    = 0\n            empty_flg.next      = 1\n        else:\n            rd_ptr_bin.next     = rd_ptr_bin_new\n            rd_ptr_gray.next    = rd_ptr_gray_new\n            empty_flg.next      = empty_val\n\n\n    if width>0:\n        #===========================================================================\n        # Memory instance\n        #===========================================================================\n        mem_we      = Signal(bool(0))\n        mem_addrw   = Signal(intbv(0, min=0, max=depth))\n        mem_addrr   = Signal(intbv(0, min=0, max=depth))\n        mem_di      = Signal(intbv(0)[width:0])\n        mem_do      = Signal(intbv(0)[width:0])\n\n\n        # RAM: Simple-Dual-Port, Asynchronous read\n        mem = ram_sdp_ar(   clk     = wclk,\n                            we      = mem_we,\n                            addrw   = mem_addrw,\n                            addrr   = mem_addrr,\n                            di      = mem_di,\n                            do      = mem_do )\n\n        @always_comb\n        def mem_connect():\n            mem_we.next         = we_safe\n            mem_addrw.next      = wr_ptr_bin[WIDTH:]\n            mem_addrr.next      = rd_ptr_bin[WIDTH:]\n            mem_di.next         = wdata\n            rdata.next          = mem_do\n\n\n    return instances()", "response": "Asynchronous FIFO related functions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a JSON response.", "response": "def respond_json(ctx, data, code = None, headers = [], json_dumps_default = None, jsonp = None):\n    \"\"\"Return a JSON response.\n\n    This function is optimized for JSON following\n    `Google JSON Style Guide <http://google-styleguide.googlecode.com/svn/trunk/jsoncstyleguide.xml>`_, but will handle\n    any JSON except for HTTP errors.\n    \"\"\"\n    if isinstance(data, collections.Mapping):\n        # Remove null properties as recommended by Google JSON Style Guide.\n        data = type(data)(\n            (name, value)\n            for name, value in data.iteritems()\n            if value is not None\n            )\n        error = data.get('error')\n        if isinstance(error, collections.Mapping):\n            error = data['error'] = type(error)(\n                (name, value)\n                for name, value in error.iteritems()\n                if value is not None\n                )\n    else:\n        error = None\n    if jsonp:\n        content_type = 'application/javascript; charset=utf-8'\n    else:\n        content_type = 'application/json; charset=utf-8'\n    if error:\n        code = code or error['code']\n        assert isinstance(code, int)\n        response = webob.exc.status_map[code](headers = headers)\n        response.content_type = content_type\n        if code == 204:  # No content\n            return response\n        if error.get('code') is None:\n            error['code'] = code\n        if error.get('message') is None:\n            title = errors_title.get(code)\n            title = ctx._(title) if title is not None else response.status\n            error['message'] = title\n    else:\n        response = ctx.req.response\n        response.content_type = content_type\n        if code is not None:\n            response.status = code\n        response.headers.update(headers)\n    # try:\n    #     text = json.dumps(data, encoding = 'utf-8', ensure_ascii = False, indent = 2)\n    # except UnicodeDecodeError:\n    #     text = json.dumps(data, ensure_ascii = True, indent = 2)\n\n    if json_dumps_default is None:\n        text = json.dumps(data)\n    else:\n        text = json.dumps(data, default = json_dumps_default)\n    text = unicode(text)\n    if jsonp:\n        text = u'{0}({1})'.format(jsonp, text)\n    response.text = text\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls rar command line executable returns stdout pipe", "response": "def call_unrar(params):\n    \"\"\"Calls rar/unrar command line executable, returns stdout pipe\"\"\"\n    global rar_executable_cached\n    if rar_executable_cached is None:\n        for command in ('unrar', 'rar'):\n            try:\n                subprocess.Popen([command], stdout=subprocess.PIPE)\n                rar_executable_cached = command\n                break\n            except OSError:\n                pass\n        if rar_executable_cached is None:\n            raise UnpackerNotInstalled(\"No suitable RAR unpacker installed\")\n\n    assert type(params) == list, \"params must be list\"\n    args = [rar_executable_cached] + params\n    try:\n        gc.disable()  # See http://bugs.python.org/issue1336\n        return subprocess.Popen(args, stdout=subprocess.PIPE,\n                                stderr=subprocess.PIPE)\n    finally:\n        gc.enable()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list of available assemblies", "response": "def get_assembly_names():\n    \"\"\"return list of available assemblies\n    \n    >>> assy_names = get_assembly_names()\n\n    >>> 'GRCh37.p13' in assy_names\n    True\n\n    \"\"\"\n\n    return [\n        n.replace(\".json.gz\", \"\")\n        for n in pkg_resources.resource_listdir(__name__, _assy_dir)\n        if n.endswith(\".json.gz\")\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_assembly(name):\n\n    fn = pkg_resources.resource_filename(\n        __name__, _assy_path_fmt.format(name=name))\n    return json.load(gzip.open(fn, mode=\"rt\", encoding=\"utf-8\"))", "response": "read a single assembly by name returning a dictionary of assembly data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads specified assemblies or all if none specified returning a dictionary of assembly - name : assembly.", "response": "def get_assemblies(names=[]):\n    \"\"\"read specified assemblies, or all if none specified, returning a\n    dictionary of assembly-name: assembly.  See get_assembly()\n    function for the structure of assembly data.\n\n    >>> assemblies = get_assemblies(names=['GRCh37.p13'])\n    >>> assy = assemblies['GRCh37.p13']\n\n    >>> assemblies = get_assemblies()\n    >>> 'GRCh38.p2' in assemblies\n    True\n\n    \"\"\"\n\n    if names == []:\n        names = get_assembly_names()\n    return {a['name']: a for a in (get_assembly(n) for n in names)}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_name_ac_map(assy_name, primary_only=False):\n    return {\n        s['name']: s['refseq_ac']\n        for s in get_assembly(assy_name)['sequences']\n        if (not primary_only or _is_primary(s))\n    }", "response": "make map from sequence name to accession for given assembly name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_ac_name_map(assy_name, primary_only=False):\n\n    return {\n        s['refseq_ac']: s['name']\n        for s in get_assembly(assy_name)['sequences']\n        if (not primary_only or _is_primary(s))\n    }", "response": "make map from accession to sequence name for given assembly name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts all exon annotations of protein-coding genes.", "response": "def main(args=None):\n    \"\"\"Extract all exon annotations of protein-coding genes.\"\"\"\n\n    if args is None:\n        parser = get_argument_parser()\n        args = parser.parse_args()\n\n    input_file = args.annotation_file\n    output_file = args.output_file\n    species = args.species\n    chrom_pat = args.chromosome_pattern\n    field_name = args.field_name\n\n    log_file = args.log_file\n    quiet = args.quiet\n    verbose = args.verbose\n\n    # configure root logger\n    log_stream = sys.stdout\n    if output_file == '-':\n        # if we print output to stdout, redirect log messages to stderr\n        log_stream = sys.stderr\n\n    logger = misc.get_logger(log_stream = log_stream, log_file = log_file,\n            quiet = quiet, verbose = verbose)\n\n    if chrom_pat is None:\n        chrom_pat = re.compile(ensembl.SPECIES_CHROMPAT[species])\n    else:\n        chrom_pat = re.compile(chrom_pat)\n\n    logger.info('Regular expression used for filtering chromosome names: \"%s\"',\n            chrom_pat.pattern)\n\n    chromosomes = set()\n    excluded_chromosomes = set()\n    i = 0\n    exons = 0\n    logger.info('Parsing data...')\n    if input_file == '-':\n        input_file = None\n    with misc.smart_open_read(input_file, mode = 'rb', try_gzip = True) as fh, \\\n            misc.smart_open_write(output_file) as ofh:\n        #if i >= 500000: break\n        reader = csv.reader(fh, dialect = 'excel-tab')\n        writer = csv.writer(ofh, dialect = 'excel-tab', lineterminator = os.linesep,\n                quoting = csv.QUOTE_NONE , quotechar = '|')\n        for l in reader:\n            i += 1\n            #if i % int(1e5) == 0:\n            #   print '\\r%d...' %(i), ; sys.stdout.flush() # report progress\n            if len(l) > 1 and l[2] == field_name:\n                attr = parse_attributes(l[8])\n                type_ = attr['gene_biotype']\n                if type_ in ['protein_coding','polymorphic_pseudogene']:\n\n                    # test whether chromosome is valid\n                    chrom = l[0]\n                    m = chrom_pat.match(chrom)\n                    if m is None:\n                        excluded_chromosomes.add(chrom)\n                        continue\n\n                    chromosomes.add(chrom)\n                    writer.writerow(l)\n                    exons += 1\n\n    logger.info('Done! (Parsed %d lines.)', i)\n\n    logger.info('')\n    logger.info('Gene chromosomes (%d):', len(chromosomes))\n    logger.info('\\t' + ', '.join(sorted(chromosomes)))\n    logger.info('')\n    logger.info('Excluded chromosomes (%d):', len(excluded_chromosomes))\n    logger.info('\\t' + ', '.join(sorted(excluded_chromosomes)))\n    logger.info('')\n    logger.info('Total no. of exons: %d' %(exons))\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef titleCounts(readsAlignments):\n\n    titles = defaultdict(int)\n    for readAlignments in readsAlignments:\n        for alignment in readAlignments:\n            titles[alignment.subjectTitle] += 1\n    return titles", "response": "Counts the number of times each title in a readsAlignments instance is\n    matched."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef toDict(self):\n        return {\n            'hsps': [hsp.toDict() for hsp in self.hsps],\n            'read': self.read.toDict(),\n        }", "response": "Returns a C { dict representation of the title alignment as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hasScoreBetterThan(self, score):\n        # Note: Do not assume that HSPs in an alignment are sorted in\n        # decreasing order (as they are in BLAST output). If we could\n        # assume that, we could just check the first HSP in each alignment.\n        for hsp in self.hsps():\n            if hsp.betterThan(score):\n                return True\n        return False", "response": "Returns C { bool } if there is at least one HSP with a score better than a given value?"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef coverage(self):\n        intervals = ReadIntervals(self.subjectLength)\n        for hsp in self.hsps():\n            intervals.add(hsp.subjectStart, hsp.subjectEnd)\n        return intervals.coverage()", "response": "Get the fraction of this title sequence that is matched by its\n            reads."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef coverageInfo(self):\n        result = defaultdict(list)\n\n        for titleAlignment in self:\n            for hsp in titleAlignment.hsps:\n                score = hsp.score.score\n                for (subjectOffset, base, _) in titleAlignment.read.walkHSP(\n                        hsp, includeWhiskers=False):\n                    result[subjectOffset].append((score, base))\n\n        return result", "response": "Return information about the bases found at each location in our title\n            sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncounting the number of residue frequencies at all sequence locations matched by reads.", "response": "def residueCounts(self, convertCaseTo='upper'):\n        \"\"\"\n        Count residue frequencies at all sequence locations matched by reads.\n\n        @param convertCaseTo: A C{str}, 'upper', 'lower', or 'none'.\n            If 'none', case will not be converted (both the upper and lower\n            case string of a residue will be present in the result if they are\n            present in the read - usually due to low complexity masking).\n        @return: A C{dict} whose keys are C{int} offsets into the title\n            sequence and whose values are C{Counters} with the residue as keys\n            and the count of that residue at that location as values.\n        \"\"\"\n        if convertCaseTo == 'none':\n            def convert(x):\n                return x\n        elif convertCaseTo == 'lower':\n            convert = str.lower\n        elif convertCaseTo == 'upper':\n            convert = str.upper\n        else:\n            raise ValueError(\n                \"convertCaseTo must be one of 'none', 'lower', or 'upper'\")\n\n        counts = defaultdict(Counter)\n\n        for titleAlignment in self:\n            read = titleAlignment.read\n            for hsp in titleAlignment.hsps:\n                for (subjectOffset, residue, inMatch) in read.walkHSP(hsp):\n                    counts[subjectOffset][convert(residue)] += 1\n\n        return counts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef summary(self):\n        return {\n            'bestScore': self.bestHsp().score.score,\n            'coverage': self.coverage(),\n            'hspCount': self.hspCount(),\n            'medianScore': self.medianScore(),\n            'readCount': self.readCount(),\n            'subjectLength': self.subjectLength,\n            'subjectTitle': self.subjectTitle,\n        }", "response": "Summarize the alignments for this subject."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef toDict(self):\n        return {\n            'titleAlignments': [titleAlignment.toDict()\n                                for titleAlignment in self],\n            'subjectTitle': self.subjectTitle,\n            'subjectLength': self.subjectLength,\n        }", "response": "Returns a C { dict representation of the title s aligments as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addTitle(self, title, titleAlignments):\n        if title in self:\n            raise KeyError('Title %r already present in TitlesAlignments '\n                           'instance.' % title)\n        else:\n            self[title] = titleAlignments", "response": "Add a new title to the TitlesAlignments object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new TitlesAlignments instance with only the matching titles.", "response": "def filter(self, minMatchingReads=None, minMedianScore=None,\n               withScoreBetterThan=None, minNewReads=None, minCoverage=None,\n               maxTitles=None, sortOn='maxScore'):\n        \"\"\"\n        Filter the titles in self to create another TitlesAlignments.\n\n        @param minMatchingReads: titles that are matched by fewer reads\n            are unacceptable.\n        @param minMedianScore: sequences that are matched with a median\n            bit score that is less are unacceptable.\n        @param withScoreBetterThan: if the best score for a title is not\n            as good as this value, the title is not acceptable.\n        @param minNewReads: The C{float} fraction of its reads by which a new\n            title's read set must differ from the read sets of all previously\n            seen titles in order for this title to be considered acceptably\n            different (and therefore interesting).\n        @param minCoverage: The C{float} minimum fraction of the title sequence\n            that must be matched by at least one read.\n        @param maxTitles: A non-negative C{int} maximum number of titles to\n            keep. If more titles than this are present, titles will be sorted\n            (according to C{sortOn}) and only the best will be retained.\n        @param sortOn: A C{str} attribute to sort on, used only if C{maxTitles}\n            is not C{None}. See the C{sortTitles} method below for the legal\n            values.\n        @raise: C{ValueError} if C{maxTitles} is less than zero or the value of\n            C{sortOn} is unknown.\n        @return: A new L{TitlesAlignments} instance containing only the\n            matching titles.\n        \"\"\"\n        # Use a ReadSetFilter only if we're checking that read sets are\n        # sufficiently new.\n        if minNewReads is None:\n            readSetFilter = None\n        else:\n            if self.readSetFilter is None:\n                self.readSetFilter = ReadSetFilter(minNewReads)\n            readSetFilter = self.readSetFilter\n\n        result = TitlesAlignments(\n            self.readsAlignments, self.scoreClass, self.readSetFilter,\n            importReadsAlignmentsTitles=False)\n\n        if maxTitles is not None and len(self) > maxTitles:\n            if maxTitles < 0:\n                raise ValueError('maxTitles (%r) cannot be negative.' %\n                                 maxTitles)\n            else:\n                # There are too many titles. Make a sorted list of them so\n                # we loop through them (below) in the desired order and can\n                # break when/if we've reached the maximum. We can't just\n                # take the first maxTitles titles from the sorted list now,\n                # as some of those titles might later be discarded by the\n                # filter and then we'd return a result with fewer titles\n                # than we should.\n                titles = self.sortTitles(sortOn)\n        else:\n            titles = self.keys()\n\n        for title in titles:\n            # Test max titles up front, as it may be zero.\n            if maxTitles is not None and len(result) == maxTitles:\n                break\n\n            titleAlignments = self[title]\n            if (minMatchingReads is not None and\n                    titleAlignments.readCount() < minMatchingReads):\n                continue\n\n            # To compare the median score with another score, we must\n            # convert both values to instances of the score class used in\n            # this data set so they can be compared without us needing to\n            # know if numerically greater scores are considered better or\n            # not.\n            if (minMedianScore is not None and\n                    self.scoreClass(titleAlignments.medianScore()) <\n                    self.scoreClass(minMedianScore)):\n                continue\n\n            if (withScoreBetterThan is not None and not\n                    titleAlignments.hasScoreBetterThan(withScoreBetterThan)):\n                continue\n\n            if (minCoverage is not None and\n                    titleAlignments.coverage() < minCoverage):\n                continue\n\n            if (readSetFilter and not\n                    readSetFilter.accept(title, titleAlignments)):\n                continue\n\n            result.addTitle(title, titleAlignments)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hsps(self):\n        return (hsp for titleAlignments in self.values()\n                for alignment in titleAlignments for hsp in alignment.hsps)", "response": "Get all the HSPs for all the titles."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sortTitles(self, by):\n        # First sort titles by the secondary key, which is always the title.\n        titles = sorted(iter(self))\n\n        # Then sort on the primary key (if any).\n        if by == 'length':\n            return sorted(\n                titles, reverse=True,\n                key=lambda title: self[title].subjectLength)\n        if by == 'maxScore':\n            return sorted(\n                titles, reverse=True, key=lambda title: self[title].bestHsp())\n        if by == 'medianScore':\n            return sorted(\n                titles, reverse=True,\n                key=lambda title: self.scoreClass(self[title].medianScore()))\n        if by == 'readCount':\n            return sorted(\n                titles, reverse=True,\n                key=lambda title: self[title].readCount())\n        if by == 'title':\n            return titles\n\n        raise ValueError('Sort attribute must be one of \"length\", \"maxScore\", '\n                         '\"medianScore\", \"readCount\", \"title\".')", "response": "Sort titles by a given attribute and then by title."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a generator that yields all the alignments for this title.", "response": "def summary(self, sortOn=None):\n        \"\"\"\n        Summarize all the alignments for this title.\n\n        @param sortOn: A C{str} attribute to sort titles on. One of 'length',\n            'maxScore', 'medianScore', 'readCount', or 'title'.\n        @raise ValueError: If an unknown C{sortOn} value is given.\n        @return: A generator that yields C{dict} instances as produced by\n            C{TitleAlignments} (see class earlier in this file), sorted by\n            C{sortOn}.\n        \"\"\"\n        titles = self if sortOn is None else self.sortTitles(sortOn)\n\n        for title in titles:\n            yield self[title].summary()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a multi - line string with a summary of the a title.", "response": "def tabSeparatedSummary(self, sortOn=None):\n        \"\"\"\n        Summarize all the alignments for this title as multi-line string with\n        TAB-separated values on each line.\n\n        @param sortOn: A C{str} attribute to sort titles on. One of 'length',\n            'maxScore', 'medianScore', 'readCount', or 'title'.\n        @raise ValueError: If an unknown C{sortOn} value is given.\n        @return: A newline-separated C{str}, each line with a summary of a\n            title. Each summary line is TAB-separated.\n        \"\"\"\n        # The order of the fields returned here is somewhat arbitrary. The\n        # subject titles are last because they are so variable in length.\n        # Putting them last makes it more likely that the initial columns in\n        # printed output will be easier to read down.\n        #\n        # Note that post-processing scripts will be relying on the field\n        # ordering here.  So you can't just add fields. It's probably safe\n        # to add them at the end, but be careful / think.\n        #\n        # A TAB-separated file can easily be read by awk using e.g.,\n        # awk 'BEGIN {FS = \"\\t\"} ...'\n\n        result = []\n        for titleSummary in self.summary(sortOn):\n            result.append('\\t'.join([\n                '%(coverage)f',\n                '%(medianScore)f',\n                '%(bestScore)f',\n                '%(readCount)d',\n                '%(hspCount)d',\n                '%(subjectLength)d',\n                '%(subjectTitle)s',\n            ]) % titleSummary)\n        return '\\n'.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a C { dict representation of the titles aligments as a dictionary.", "response": "def toDict(self):\n        \"\"\"\n        Get information about the titles alignments as a dictionary.\n\n        @return: A C{dict} representation of the titles aligments.\n        \"\"\"\n        return {\n            'scoreClass': self.scoreClass.__name__,\n            'titles': dict((title, titleAlignments.toDict())\n                           for title, titleAlignments in self.items()),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addFASTAFilteringCommandLineOptions(parser):\n    parser.add_argument(\n        '--minLength', type=int,\n        help='The minimum sequence length')\n\n    parser.add_argument(\n        '--maxLength', type=int,\n        help='The maximum sequence length')\n\n    parser.add_argument(\n        '--whitelist', action='append',\n        help='Sequence titles (ids) that should be whitelisted')\n\n    parser.add_argument(\n        '--blacklist', action='append',\n        help='Sequence titles (ids) that should be blacklisted')\n\n    parser.add_argument(\n        '--whitelistFile',\n        help=('The name of a file that contains sequence titles (ids) that '\n              'should be whitelisted, one per line'))\n\n    parser.add_argument(\n        '--blacklistFile',\n        help=('The name of a file that contains sequence titles (ids) that '\n              'should be blacklisted, one per line'))\n\n    parser.add_argument(\n        '--titleRegex', help='A regex that sequence titles (ids) must match.')\n\n    parser.add_argument(\n        '--negativeTitleRegex',\n        help='A regex that sequence titles (ids) must not match.')\n\n    # A mutually exclusive group for --keepSequences and --removeSequences.\n    group = parser.add_mutually_exclusive_group()\n\n    group.add_argument(\n        '--keepSequences',\n        help=('Specify (1-based) ranges of sequence numbers that should be '\n              'kept. E.g., --keepSequences 1-3,5 will output just the 1st, '\n              '2nd, 3rd, and 5th sequences. All others will be omitted.'))\n\n    group.add_argument(\n        '--removeSequences',\n        help=('Specify (1-based) ranges of sequence numbers that should be '\n              'removed. E.g., --removeSequences 1-3,5 will output all but the '\n              '1st, 2nd, 3rd, and 5th sequences. All others will be ouput.'))\n\n    parser.add_argument(\n        '--head', type=int, metavar='N',\n        help='Only the first N sequences will be printed.')\n\n    parser.add_argument(\n        '--removeDuplicates', action='store_true', default=False,\n        help=('Duplicate reads will be removed, based only on '\n              'sequence identity. The first occurrence is kept.'))\n\n    parser.add_argument(\n        '--removeDuplicatesById', action='store_true', default=False,\n        help=('Duplicate reads will be removed, based only on '\n              'read id. The first occurrence is kept.'))\n\n    # See the docstring for dark.reads.Reads.filter for more detail on\n    # randomSubset.\n    parser.add_argument(\n        '--randomSubset', type=int,\n        help=('An integer giving the number of sequences that should be kept. '\n              'These will be selected at random.'))\n\n    # See the docstring for dark.reads.Reads.filter for more detail on\n    # trueLength.\n    parser.add_argument(\n        '--trueLength', type=int,\n        help=('The number of reads in the FASTA input. Only to be used with '\n              'randomSubset'))\n\n    parser.add_argument(\n        '--sampleFraction', type=float,\n        help=('A [0.0, 1.0] C{float} indicating a fraction of the reads that '\n              'should be allowed to pass through the filter. The sample size '\n              'will only be approximately the product of the sample fraction '\n              'and the number of reads. The sample is taken at random.'))\n\n    parser.add_argument(\n        '--sequenceNumbersFile',\n        help=('A file of (1-based) sequence numbers to retain. Numbers must '\n              'be one per line.'))", "response": "Adds standard FASTA filtering command - line options to an argparse parser."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexamining parsed FASTA filtering command - line options and return filtered version of the given reads.", "response": "def parseFASTAFilteringCommandLineOptions(args, reads):\n    \"\"\"\n    Examine parsed FASTA filtering command-line options and return filtered\n    reads.\n\n    @param args: An argparse namespace, as returned by the argparse\n        C{parse_args} function.\n    @param reads: A C{Reads} instance to filter.\n    @return: The filtered C{Reads} instance.\n    \"\"\"\n    keepSequences = (\n        parseRangeString(args.keepSequences, convertToZeroBased=True)\n        if args.keepSequences else None)\n\n    removeSequences = (\n        parseRangeString(args.removeSequences, convertToZeroBased=True)\n        if args.removeSequences else None)\n\n    return reads.filter(\n        minLength=args.minLength, maxLength=args.maxLength,\n        whitelist=set(args.whitelist) if args.whitelist else None,\n        blacklist=set(args.blacklist) if args.blacklist else None,\n        whitelistFile=args.whitelistFile, blacklistFile=args.blacklistFile,\n        titleRegex=args.titleRegex,\n        negativeTitleRegex=args.negativeTitleRegex,\n        keepSequences=keepSequences, removeSequences=removeSequences,\n        head=args.head, removeDuplicates=args.removeDuplicates,\n        removeDuplicatesById=args.removeDuplicatesById,\n        randomSubset=args.randomSubset, trueLength=args.trueLength,\n        sampleFraction=args.sampleFraction,\n        sequenceNumbersFile=args.sequenceNumbersFile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addFASTAEditingCommandLineOptions(parser):\n    # A mutually exclusive group for --keepSites, --keepSitesFile,\n    # --removeSites, and --removeSitesFile.\n    group = parser.add_mutually_exclusive_group()\n\n    # In the 4 options below, the 'indices' alternate names are kept for\n    # backwards compatibility.\n    group.add_argument(\n        '--keepSites', '--keepIndices',\n        help=('Specify 1-based sequence sites to keep. All other sites will '\n              'be removed. The sites must be given in the form e.g., '\n              '24,100-200,260. Note that the requested sites will be taken '\n              'from the input sequences in order, not in the order given by '\n              '--keepSites. I.e., --keepSites 5,8-10 will get you the same '\n              'result as --keepSites 8-10,5.'))\n\n    group.add_argument(\n        '--keepSitesFile', '--keepIndicesFile',\n        help=('Specify a file containing 1-based sites to keep. All other '\n              'sequence sites will be removed. Lines in the file must be '\n              'given in the form e.g., 24,100-200,260. See --keepSites for '\n              'more detail.'))\n\n    group.add_argument(\n        '--removeSites', '--removeIndices',\n        help=('Specify 1-based sites to remove. All other sequence sites will '\n              'be kept. The sites must be given in the form e.g., '\n              '24,100-200,260. See --keepSites for more detail.'))\n\n    group.add_argument(\n        '--removeSitesFile', '--removeIndicesFile',\n        help=('Specify a file containing 1-based sites to remove. All other '\n              'sequence sites will be kept. Lines in the file must be given '\n              'in the form e.g., 24,100-200,260. See --keepSites for more '\n              'detail.'))\n\n    parser.add_argument(\n        '--removeGaps', action='store_true', default=False,\n        help=\"If True, gap ('-') characters in sequences will be removed.\")\n\n    parser.add_argument(\n        '--truncateTitlesAfter',\n        help=('A string that sequence titles (ids) will be truncated beyond. '\n              'If the truncated version of a title has already been seen, '\n              'that title will be skipped.'))\n\n    parser.add_argument(\n        '--removeDescriptions', action='store_true', default=False,\n        help=('Read id descriptions will be removed. The '\n              'description is the part of a sequence id after the '\n              'first whitespace (if any).'))\n\n    parser.add_argument(\n        '--idLambda', metavar='LAMBDA-FUNCTION',\n        help=('A one-argument function taking and returning a read id. '\n              'E.g., --idLambda \"lambda id: id.split(\\'_\\')[0]\" or '\n              '--idLambda \"lambda id: id[:10]\". If the function returns None, '\n              'the read will be filtered out.'))\n\n    parser.add_argument(\n        '--readLambda', metavar='LAMBDA-FUNCTION',\n        help=('A one-argument function taking and returning a read. '\n              'E.g., --readLambda \"lambda r: Read(r.id.split(\\'_\\')[0], '\n              'r.sequence.strip(\\'-\\')\". Make sure to also modify the quality '\n              'string if you change the length of a FASTQ sequence. If the '\n              'function returns None, the read will be filtered out. The '\n              'function will be passed to eval with the dark.reads classes '\n              'Read, DNARead, AARead, etc. all in scope.'))\n\n    parser.add_argument(\n        '--reverse', action='store_true', default=False,\n        help=('Reverse the sequences. Note that this is NOT reverse '\n              'complementing.'))\n\n    parser.add_argument(\n        '--reverseComplement', action='store_true', default=False,\n        help='Reverse complement the sequences.')", "response": "Adds standard FASTA editing command - line options to an argparse parser."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexamining parsed FASTA editing command - line options and return information about kept sites and sequences.", "response": "def parseFASTAEditingCommandLineOptions(args, reads):\n    \"\"\"\n    Examine parsed FASTA editing command-line options and return information\n    about kept sites and sequences.\n\n    @param args: An argparse namespace, as returned by the argparse\n        C{parse_args} function.\n    @param reads: A C{Reads} instance to filter.\n    @return: The filtered C{Reads} instance.\n    \"\"\"\n    removeGaps = args.removeGaps\n    removeDescriptions = args.removeDescriptions\n    truncateTitlesAfter = args.truncateTitlesAfter\n    keepSites = (\n        parseRangeString(args.keepSites, convertToZeroBased=True)\n        if args.keepSites else None)\n\n    if args.keepSitesFile:\n        keepSites = keepSites or set()\n        with open(args.keepSitesFile) as fp:\n            for lineNumber, line in enumerate(fp):\n                try:\n                    keepSites.update(\n                        parseRangeString(line, convertToZeroBased=True))\n                except ValueError as e:\n                    raise ValueError(\n                        'Keep sites file %r line %d could not be parsed: '\n                        '%s' % (args.keepSitesFile, lineNumber, e))\n\n    removeSites = (\n        parseRangeString(args.removeSites, convertToZeroBased=True)\n        if args.removeSites else None)\n\n    if args.removeSitesFile:\n        removeSites = removeSites or set()\n        with open(args.removeSitesFile) as fp:\n            for lineNumber, line in enumerate(fp):\n                try:\n                    removeSites.update(\n                        parseRangeString(line, convertToZeroBased=True))\n                except ValueError as e:\n                    raise ValueError(\n                        'Remove sites file %r line %d parse error: %s'\n                        % (args.removeSitesFile, lineNumber, e))\n\n    return reads.filter(\n        removeGaps=removeGaps,\n        truncateTitlesAfter=truncateTitlesAfter,\n        removeDescriptions=removeDescriptions,\n        idLambda=args.idLambda, readLambda=args.readLambda,\n        keepSites=keepSites, removeSites=removeSites,\n        reverse=args.reverse, reverseComplement=args.reverseComplement)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a value to indicate if a title is acceptable or not.", "response": "def accept(self, title):\n        \"\"\"\n        Return a value (see below) to indicate if a title is acceptable (and,\n        if so, in what way).\n\n        @param title: A C{str} sequence title.\n        @return: An C{int} to indicate an acceptable title or not. This will be\n\n            C{self.REJECT} if the title is unacceptable.\n            C{self.WHITELIST_ACCEPT} if the title is whitelisted.\n            C{self.DEFAULT_ACCEPT} if the title is acceptable by default.\n\n            These three values are needed so our caller can distinguish between\n            the two reasons for acceptance.\n        \"\"\"\n        if self._whitelist and title in self._whitelist:\n            return self.WHITELIST_ACCEPT\n\n        if self._blacklist and title in self._blacklist:\n            return self.REJECT\n\n        # If we have a positive regex but we don't match it, reject.\n        if self._positiveRegex and self._positiveRegex.search(title) is None:\n            return self.REJECT\n\n        # If we have a negative regex and we do match it, reject.\n        if (self._negativeRegex and\n                self._negativeRegex.search(title) is not None):\n            return self.REJECT\n\n        if self._truncated is not None:\n            truncated = simplifyTitle(title, self._truncateAfter)\n            if truncated in self._truncated:\n                # We've already seen this (truncated) title. Reject unless\n                # this is the original title that we truncated to make this\n                # entry. That title must continue to be accepted.\n                if self._truncated[truncated] == title:\n                    return self.DEFAULT_ACCEPT\n                else:\n                    return self.REJECT\n            else:\n                self._truncated[truncated] = title\n\n        return self.DEFAULT_ACCEPT"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef accept(self, title, titleAlignments):\n\n        # Sanity check: titles can only be passed once.\n        assert title not in self._titles, (\n            'Title %r seen multiple times.' % title)\n\n        readIds = titleAlignments.readIds()\n        newReadsRequired = ceil(self._minNew * len(readIds))\n\n        for readSet, invalidatedTitles in self._titles.values():\n            if len(readIds - readSet) < newReadsRequired:\n                # Add this title to the set of titles invalidated by this\n                # previously seen read set.\n                invalidatedTitles.append(title)\n                return False\n\n        # Remember the new read set and an empty list of invalidated titles.\n        self._titles[title] = (readIds, [])\n\n        return True", "response": "Return C { True } if the read id set in titleAlignments is sufficiently\n        different from all previously seen read sets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convertBlastRecordToDict(self, record):\n        alignments = []\n        for alignment in record.alignments:\n            hsps = []\n            for hsp in alignment.hsps:\n                hsps.append({\n                    'bits': hsp.bits,\n                    'expect': hsp.expect,\n                    'frame': hsp.frame,\n                    'identicalCount': hsp.identities,\n                    'positiveCount': hsp.positives,\n                    'query': hsp.query,\n                    'query_start': hsp.query_start,\n                    'query_end': hsp.query_end,\n                    'sbjct': hsp.sbjct,\n                    'sbjct_start': hsp.sbjct_start,\n                    'sbjct_end': hsp.sbjct_end,\n                })\n\n            alignments.append({\n                'hsps': hsps,\n                'length': alignment.length,\n                'title': alignment.title,\n            })\n\n        return {\n            'alignments': alignments,\n            'query': record.query,\n        }", "response": "Convert a BLAST record into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convertBlastParamsToDict(self, record):\n        result = {}\n        for attr in (\n                # From Bio.Blast.Record.Header\n                'application',\n                'version',\n                'date',\n                'reference',\n                'query',\n                'query_letters',\n                'database',\n                'database_sequences',\n                'database_letters',\n                # From Bio.Blast.Record.DatabaseReport\n                'database_name',\n                'posted_date',\n                'num_letters_in_database',\n                'num_sequences_in_database',\n                'ka_params',\n                'gapped',\n                'ka_params_gap',\n                # From Bio.Blast.Record.Parameters\n                'matrix',\n                'gap_penalties',\n                'sc_match',\n                'sc_mismatch',\n                'num_hits',\n                'num_sequences',\n                'num_good_extends',\n                'num_seqs_better_e',\n                'hsps_no_gap',\n                'hsps_prelim_gapped',\n                'hsps_prelim_gapped_attemped',\n                'hsps_gapped',\n                'query_id',\n                'query_length',\n                'database_length',\n                'effective_hsp_length',\n                'effective_query_length',\n                'effective_database_length',\n                'effective_search_space',\n                'effective_search_space_used',\n                'frameshift',\n                'threshold',\n                'window_size',\n                'dropoff_1st_pass',\n                'gap_x_dropoff',\n                'gap_x_dropoff_final',\n                'gap_trigger',\n                'blast_cutoff'):\n            result[attr] = getattr(record, attr)\n        return result", "response": "Converts the global BLAST parameters into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef records(self):\n        first = True\n        with as_handle(self._filename) as fp:\n            for record in NCBIXML.parse(fp):\n                if first:\n                    self.params = self._convertBlastParamsToDict(record)\n                    first = False\n                yield record", "response": "Yields all records in the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the records out as JSON.", "response": "def saveAsJSON(self, fp):\n        \"\"\"\n        Write the records out as JSON. The first JSON object saved contains\n        the BLAST parameters.\n\n        @param fp: A C{str} file pointer to write to.\n        \"\"\"\n        first = True\n        for record in self.records():\n            if first:\n                print(dumps(self.params, separators=(',', ':')), file=fp)\n                first = False\n            print(dumps(self._convertBlastRecordToDict(record),\n                        separators=(',', ':')), file=fp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen the input file. Set self. _fp to point to it.", "response": "def _open(self, filename):\n        \"\"\"\n        Open the input file. Set self._fp to point to it. Read the first\n        line of parameters.\n\n        @param filename: A C{str} filename containing JSON BLAST records.\n        @raise ValueError: if the first line of the file isn't valid JSON,\n            if the input file is empty, or if the JSON does not contain an\n            'application' key.\n        \"\"\"\n        if filename.endswith('.bz2'):\n            if six.PY3:\n                self._fp = bz2.open(filename, mode='rt', encoding='UTF-8')\n            else:\n                self._fp = bz2.BZ2File(filename)\n        else:\n            self._fp = open(filename)\n\n        line = self._fp.readline()\n        if not line:\n            raise ValueError('JSON file %r was empty.' % self._filename)\n\n        try:\n            self.params = loads(line[:-1])\n        except ValueError as e:\n            raise ValueError(\n                'Could not convert first line of %r to JSON (%s). '\n                'Line is %r.' % (self._filename, e, line[:-1]))\n        else:\n            if 'application' not in self.params:\n                raise ValueError(\n                    '%r appears to be an old JSON file with no BLAST global '\n                    'parameters. Please re-run convert-blast-xml-to-json.py '\n                    'to convert it to the newest format.' % self._filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a BLAST record to a list of alignments.", "response": "def _dictToAlignments(self, blastDict, read):\n        \"\"\"\n        Take a dict (made by XMLRecordsReader._convertBlastRecordToDict)\n        and convert it to a list of alignments.\n\n        @param blastDict: A C{dict}, from convertBlastRecordToDict.\n        @param read: A C{Read} instance, containing the read that BLAST used\n            to create this record.\n        @raise ValueError: If the query id in the BLAST dictionary does not\n            match the id of the read.\n        @return: A C{list} of L{dark.alignment.Alignment} instances.\n        \"\"\"\n        if (blastDict['query'] != read.id and\n                blastDict['query'].split()[0] != read.id):\n            raise ValueError(\n                'The reads you have provided do not match the BLAST output: '\n                'BLAST record query id (%s) does not match the id of the '\n                'supposedly corresponding read (%s).' %\n                (blastDict['query'], read.id))\n\n        alignments = []\n        getScore = itemgetter('bits' if self._hspClass is HSP else 'expect')\n\n        for blastAlignment in blastDict['alignments']:\n            alignment = Alignment(blastAlignment['length'],\n                                  blastAlignment['title'])\n            alignments.append(alignment)\n            for blastHsp in blastAlignment['hsps']:\n                score = getScore(blastHsp)\n                normalized = normalizeHSP(blastHsp, len(read),\n                                          self.application)\n                hsp = self._hspClass(\n                    score,\n                    readStart=normalized['readStart'],\n                    readEnd=normalized['readEnd'],\n                    readStartInSubject=normalized['readStartInSubject'],\n                    readEndInSubject=normalized['readEndInSubject'],\n                    readFrame=blastHsp['frame'][0],\n                    subjectStart=normalized['subjectStart'],\n                    subjectEnd=normalized['subjectEnd'],\n                    subjectFrame=blastHsp['frame'][1],\n                    readMatchedSequence=blastHsp['query'],\n                    subjectMatchedSequence=blastHsp['sbjct'],\n                    # Use blastHsp.get on identicalCount and positiveCount\n                    # because they were added in version 2.0.3 and will not\n                    # be present in any of our JSON output generated before\n                    # that. Those values will be None for those JSON files,\n                    # but that's much better than no longer being able to\n                    # read all that data.\n                    identicalCount=blastHsp.get('identicalCount'),\n                    positiveCount=blastHsp.get('positiveCount'))\n\n                alignment.addHsp(hsp)\n\n        return alignments"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readAlignments(self, reads):\n        if self._fp is None:\n            self._open(self._filename)\n\n        reads = iter(reads)\n\n        try:\n            for lineNumber, line in enumerate(self._fp, start=2):\n                try:\n                    record = loads(line[:-1])\n                except ValueError as e:\n                    raise ValueError(\n                        'Could not convert line %d of %r to JSON (%s). '\n                        'Line is %r.' %\n                        (lineNumber, self._filename, e, line[:-1]))\n                else:\n                    try:\n                        read = next(reads)\n                    except StopIteration:\n                        raise ValueError(\n                            'Read generator failed to yield read number %d '\n                            'during parsing of BLAST file %r.' %\n                            (lineNumber - 1, self._filename))\n                    else:\n                        alignments = self._dictToAlignments(record, read)\n                        yield ReadAlignments(read, alignments)\n        finally:\n            self._fp.close()\n            self._fp = None", "response": "Read lines of JSON from self. _filename convert them to read alignments\n        and yield them."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _makeComplementTable(complementData):\n    table = list(range(256))\n    for _from, to in complementData.items():\n        table[ord(_from[0].lower())] = ord(to[0].lower())\n        table[ord(_from[0].upper())] = ord(to[0].upper())\n    return ''.join(map(chr, table))", "response": "Make a sequence complement table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addFASTACommandLineOptions(parser):\n\n    parser.add_argument(\n        '--fastaFile', type=open, default=sys.stdin, metavar='FILENAME',\n        help=('The name of the FASTA input file. Standard input will be read '\n              'if no file name is given.'))\n\n    parser.add_argument(\n        '--readClass', default='DNARead', choices=readClassNameToClass,\n        metavar='CLASSNAME',\n        help=('If specified, give the type of the reads in the input. '\n              'Possible choices: %s.' % ', '.join(readClassNameToClass)))\n\n    # A mutually exclusive group for either --fasta, --fastq, or --fasta-ss\n    group = parser.add_mutually_exclusive_group()\n\n    group.add_argument(\n        '--fasta', default=False, action='store_true',\n        help=('If specified, input will be treated as FASTA. This is the '\n              'default.'))\n\n    group.add_argument(\n        '--fastq', default=False, action='store_true',\n        help='If specified, input will be treated as FASTQ.')\n\n    group.add_argument(\n        '--fasta-ss', dest='fasta_ss', default=False, action='store_true',\n        help=('If specified, input will be treated as PDB FASTA '\n              '(i.e., regular FASTA with each sequence followed by its '\n              'structure).'))", "response": "Adds standard command - line options to an argparse parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parseFASTACommandLineOptions(args):\n    # Set default FASTA type.\n    if not (args.fasta or args.fastq or args.fasta_ss):\n        args.fasta = True\n\n    readClass = readClassNameToClass[args.readClass]\n\n    if args.fasta:\n        from dark.fasta import FastaReads\n        return FastaReads(args.fastaFile, readClass=readClass)\n    elif args.fastq:\n        from dark.fastq import FastqReads\n        return FastqReads(args.fastaFile, readClass=readClass)\n    else:\n        from dark.fasta_ss import SSFastaReads\n        return SSFastaReads(args.fastaFile, readClass=readClass)", "response": "Examine parsed command - line options and return a C { Reads } subclass instance depending on the type of FASTA file holding the given read class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield all six translations of a nucleotide sequence.", "response": "def translations(self):\n        \"\"\"\n        Yield all six translations of a nucleotide sequence.\n\n        @return: A generator that produces six L{TranslatedRead} instances.\n        \"\"\"\n        rc = self.reverseComplement().sequence\n        for reverseComplemented in False, True:\n            for frame in 0, 1, 2:\n                seq = rc if reverseComplemented else self.sequence\n                # Get the suffix of the sequence for translation. I.e.,\n                # skip 0, 1, or 2 initial bases, depending on the frame.\n                # Note that this makes a copy of the sequence, which we can\n                # then safely append 'N' bases to to adjust its length to\n                # be zero mod 3.\n                suffix = seq[frame:]\n                lengthMod3 = len(suffix) % 3\n                if lengthMod3:\n                    suffix += ('NN' if lengthMod3 == 1 else 'N')\n                yield TranslatedRead(self, translate(suffix), frame,\n                                     reverseComplemented)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new nucleotide sequence with the reverse complemented nucleotide sequence.", "response": "def reverseComplement(self):\n        \"\"\"\n        Reverse complement a nucleotide sequence.\n\n        @return: The reverse complemented sequence as an instance of the\n            current class.\n        \"\"\"\n        quality = None if self.quality is None else self.quality[::-1]\n        sequence = self.sequence.translate(self.COMPLEMENT_TABLE)[::-1]\n        return self.__class__(self.id, sequence, quality)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ORFs(self, openORFs=False):\n\n        # Return open ORFs to the left and right and closed ORFs within the\n        # sequence.\n        if openORFs:\n            ORFStart = 0\n            inOpenORF = True  # open on the left\n            inORF = False\n\n            for index, residue in enumerate(self.sequence):\n                if residue == '*':\n                    if inOpenORF:\n                        if index:\n                            yield AAReadORF(self, ORFStart, index, True, False)\n                        inOpenORF = False\n                    elif inORF:\n                        if ORFStart != index:\n                            yield AAReadORF(self, ORFStart, index,\n                                            False, False)\n                        inORF = False\n                elif residue == 'M':\n                    if not inOpenORF and not inORF:\n                        ORFStart = index + 1\n                        inORF = True\n\n            # End of sequence. Yield the final ORF, open to the right, if\n            # there is one and it has non-zero length.\n            length = len(self.sequence)\n            if inOpenORF and length > 0:\n                yield AAReadORF(self, ORFStart, length, True, True)\n            elif inORF and ORFStart < length:\n                yield AAReadORF(self, ORFStart, length, False, True)\n\n        # Return only closed ORFs.\n        else:\n            inORF = False\n\n            for index, residue in enumerate(self.sequence):\n                if residue == 'M':\n                    if not inORF:\n                        inORF = True\n                        ORFStart = index + 1\n                elif residue == '*':\n                    if inORF:\n                        if not ORFStart == index:\n                            yield AAReadORF(self, ORFStart,\n                                            index, False, False)\n                        inORF = False", "response": "Return an iterator that yields all ORFs in the AA sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary with keys and values for the attributes of this read.", "response": "def toDict(self):\n        \"\"\"\n        Get information about this read in a dictionary.\n\n        @return: A C{dict} with keys/values for the attributes of self.\n        \"\"\"\n        if six.PY3:\n            result = super().toDict()\n        else:\n            result = AARead.toDict(self)\n\n        result.update({\n            'start': self.start,\n            'stop': self.stop,\n            'openLeft': self.openLeft,\n            'openRight': self.openRight,\n        })\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance from a dictionary containing keys and values.", "response": "def fromDict(cls, d):\n        \"\"\"\n        Create a new instance from attribute values provided in a dictionary.\n\n        @param d: A C{dict} with keys/values for the attributes of a new\n            instance of this class. Keys 'id' and 'sequence' with C{str} values\n            must be provided. A 'quality' C{str} key is optional. Keys 'start'\n            and 'stop' must have C{int} values. Keys 'openLeft' and 'openRight'\n            are C{bool}, all keys are as described in the docstring for this\n            class.\n        @return: A new instance of this class, with values taken from C{d}.\n        \"\"\"\n        # Make a dummy instance whose attributes we can set explicitly.\n        new = cls(AARead('', ''), 0, 0, True, True)\n        new.id = d['id']\n        new.sequence = d['sequence']\n        new.quality = d.get('quality')\n        new.start = d['start']\n        new.stop = d['stop']\n        new.openLeft = d['openLeft']\n        new.openRight = d['openRight']\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the read to a string in PDB format.", "response": "def toString(self, format_='fasta-ss', structureSuffix=':structure'):\n        \"\"\"\n        Convert the read to a string in PDB format (sequence & structure). This\n        consists of two FASTA records, one for the sequence then one for the\n        structure.\n\n        @param format_: Either 'fasta-ss' or 'fasta'. In the former case, the\n            structure information is returned. Otherwise, plain FASTA is\n            returned.\n        @param structureSuffix: The C{str} suffix to append to the read id\n            for the second FASTA record, containing the structure information.\n        @raise ValueError: If C{format_} is not 'fasta'.\n        @return: A C{str} representing the read sequence and structure in PDB\n            FASTA format.\n        \"\"\"\n        if format_ == 'fasta-ss':\n            return '>%s\\n%s\\n>%s%s\\n%s\\n' % (\n                self.id, self.sequence, self.id, structureSuffix,\n                self.structure)\n        else:\n            if six.PY3:\n                return super().toString(format_=format_)\n            else:\n                return AARead.toString(self, format_=format_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef newFromSites(self, sites, exclude=False):\n        if exclude:\n            sites = set(range(len(self))) - sites\n\n        newSequence = []\n        newStructure = []\n        for index, (base, structure) in enumerate(zip(self.sequence,\n                                                      self.structure)):\n            if index in sites:\n                newSequence.append(base)\n                newStructure.append(structure)\n        read = self.__class__(self.id, ''.join(newSequence),\n                              ''.join(newStructure))\n\n        return read", "response": "Create a new read from self with only certain sites."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary with keys and values for the attributes of this read in a dictionary.", "response": "def toDict(self):\n        \"\"\"\n        Get information about this read in a dictionary.\n\n        @return: A C{dict} with keys/values for the attributes of self.\n        \"\"\"\n        if six.PY3:\n            result = super().toDict()\n        else:\n            result = AARead.toDict(self)\n\n        result.update({\n            'frame': self.frame,\n            'reverseComplemented': self.reverseComplemented,\n        })\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromDict(cls, d):\n        # Make a dummy instance whose attributes we can set explicitly.\n        new = cls(AARead('', ''), 0, True)\n        new.id = d['id']\n        new.sequence = d['sequence']\n        new.quality = d.get('quality')\n        new.frame = d['frame']\n        new.reverseComplemented = d['reverseComplemented']\n        return new", "response": "Create a new instance from a dictionary containing the keys and values of the new\n            attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the length of the maximum ORF in a translated read.", "response": "def maximumORFLength(self, openORFs=True):\n        \"\"\"\n        Return the length of the longest (possibly partial) ORF in a translated\n        read. The ORF may originate or terminate outside the sequence, which is\n        why the length is just a lower bound.\n        \"\"\"\n        return max(len(orf) for orf in self.ORFs(openORFs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a read passes the filter.", "response": "def filter(self, read):\n        \"\"\"\n        Check if a read passes the filter.\n\n        @param read: A C{Read} instance.\n        @return: C{read} if C{read} passes the filter, C{False} if not.\n        \"\"\"\n        self.readIndex += 1\n\n        if self.alwaysFalse:\n            return False\n\n        if self.wantedSequenceNumberGeneratorExhausted:\n            return False\n\n        if self.nextWantedSequenceNumber is not None:\n            if self.readIndex + 1 == self.nextWantedSequenceNumber:\n                # We want this sequence.\n                try:\n                    self.nextWantedSequenceNumber = next(\n                        self.wantedSequenceNumberGenerator)\n                except StopIteration:\n                    # The sequence number iterator ran out of sequence\n                    # numbers.  We must let the rest of the filtering\n                    # continue for the current sequence in case we\n                    # throw it out for other reasons (as we might have\n                    # done for any of the earlier wanted sequence\n                    # numbers).\n                    self.wantedSequenceNumberGeneratorExhausted = True\n            else:\n                # This sequence isn't one of the ones that's wanted.\n                return False\n\n        if (self.sampleFraction is not None and\n                uniform(0.0, 1.0) > self.sampleFraction):\n            # Note that we don't have to worry about the 0.0 or 1.0\n            # cases in the above 'if', as they have been dealt with\n            # in self.__init__.\n            return False\n\n        if self.randomSubset is not None:\n            if self.yieldCount == self.randomSubset:\n                # The random subset has already been fully returned.\n                # There's no point in going any further through the input.\n                self.alwaysFalse = True\n                return False\n            elif uniform(0.0, 1.0) > ((self.randomSubset - self.yieldCount) /\n                                      (self.trueLength - self.readIndex)):\n                return False\n\n        if self.head is not None and self.readIndex == self.head:\n            # We're completely done.\n            self.alwaysFalse = True\n            return False\n\n        readLen = len(read)\n        if ((self.minLength is not None and readLen < self.minLength) or\n                (self.maxLength is not None and readLen > self.maxLength)):\n            return False\n\n        if self.removeGaps:\n            if read.quality is None:\n                read = read.__class__(read.id, read.sequence.replace('-', ''))\n            else:\n                newSequence = []\n                newQuality = []\n                for base, quality in zip(read.sequence, read.quality):\n                    if base != '-':\n                        newSequence.append(base)\n                        newQuality.append(quality)\n                read = read.__class__(\n                    read.id, ''.join(newSequence), ''.join(newQuality))\n\n        if (self.titleFilter and\n                self.titleFilter.accept(read.id) == TitleFilter.REJECT):\n            return False\n\n        if (self.keepSequences is not None and\n                self.readIndex not in self.keepSequences):\n            return False\n\n        if (self.removeSequences is not None and\n                self.readIndex in self.removeSequences):\n            return False\n\n        if self.removeDuplicates:\n            if read.sequence in self.sequencesSeen:\n                return False\n            self.sequencesSeen.add(read.sequence)\n\n        if self.removeDuplicatesById:\n            if read.id in self.idsSeen:\n                return False\n            self.idsSeen.add(read.id)\n\n        if self.modifier:\n            modified = self.modifier(read)\n            if modified is None:\n                return False\n            else:\n                read = modified\n\n        # We have to use 'is not None' in the following tests so the empty set\n        # is processed properly.\n        if self.keepSites is not None:\n            read = read.newFromSites(self.keepSites)\n        elif self.removeSites is not None:\n            read = read.newFromSites(self.removeSites, exclude=True)\n\n        if self.idLambda:\n            newId = self.idLambda(read.id)\n            if newId is None:\n                return False\n            else:\n                read.id = newId\n\n        if self.readLambda:\n            newRead = self.readLambda(read)\n            if newRead is None:\n                return False\n            else:\n                read = newRead\n\n        if self.removeDescriptions:\n            read.id = read.id.split()[0]\n\n        if self.reverse:\n            read = read.reverse()\n        elif self.reverseComplement:\n            read = read.reverseComplement()\n\n        self.yieldCount += 1\n        return read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filterRead(self, read):\n        for filterFunc in self._filters:\n            filteredRead = filterFunc(read)\n            if filteredRead is False:\n                return False\n            else:\n                read = filteredRead\n        return read", "response": "Filter a read according to our set of filters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, filename, format_='fasta'):\n        format_ = format_.lower()\n        count = 0\n\n        if isinstance(filename, str):\n            try:\n                with open(filename, 'w') as fp:\n                    for read in self:\n                        fp.write(read.toString(format_))\n                        count += 1\n            except ValueError:\n                unlink(filename)\n                raise\n        else:\n            # We have a file-like object.\n            for read in self:\n                filename.write(read.toString(format_))\n                count += 1\n        return count", "response": "Write the reads in the current sequence to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a filter to this C { Reads instance.", "response": "def filter(self, **kwargs):\n        \"\"\"\n        Add a filter to this C{Reads} instance.\n\n        @param kwargs: Keyword arguments, as accepted by C{ReadFilter}.\n        @return: C{self}.\n        \"\"\"\n        readFilter = ReadFilter(**kwargs)\n        self._filters.append(readFilter.filter)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the count of too - short sequences at a specific sequence index.", "response": "def summarizePosition(self, index):\n        \"\"\"\n        Compute residue counts at a specific sequence index.\n\n        @param index: an C{int} index into the sequence.\n        @return: A C{dict} with the count of too-short (excluded) sequences,\n            and a Counter instance giving the residue counts.\n        \"\"\"\n        countAtPosition = Counter()\n        excludedCount = 0\n\n        for read in self:\n            try:\n                countAtPosition[read.sequence[index]] += 1\n            except IndexError:\n                excludedCount += 1\n\n        return {\n            'excludedCount': excludedCount,\n            'countAtPosition': countAtPosition\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds sites that match a given set of target sequence bases.", "response": "def sitesMatching(self, targets, matchCase, any_):\n        \"\"\"\n        Find sites (i.e., sequence indices) that match a given set of target\n        sequence bases.\n\n        @param targets: A C{set} of sequence bases to look for.\n        @param matchCase: If C{True}, case will be considered in matching.\n        @param any_: If C{True}, return sites that match in any read. Else\n            return sites that match in all reads.\n        @return: A C{set} of 0-based sites that indicate where the target\n            bases occur in our reads. An index will be in this set if any of\n            our reads has any of the target bases in that location.\n        \"\"\"\n        # If case is unimportant, we convert everything (target bases and\n        # sequences, as we read them) to lower case.\n        if not matchCase:\n            targets = set(map(str.lower, targets))\n\n        result = set() if any_ else None\n        for read in self:\n            sequence = read.sequence if matchCase else read.sequence.lower()\n            matches = set(index for (index, base) in enumerate(sequence)\n                          if base in targets)\n            if any_:\n                result |= matches\n            else:\n                if result is None:\n                    result = matches\n                else:\n                    result &= matches\n                # We can exit early if we run out of possible sites.\n                if not result:\n                    break\n\n        # Make sure we don't return None.\n        return result or set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert different condition types to callback", "response": "def condition2checker(condition):\n    \"\"\"Converts different condition types to callback\"\"\"\n    if isinstance(condition, string_types):\n        def smatcher(info):\n            return fnmatch.fnmatch(info.filename, condition)\n\n        return smatcher\n    elif isinstance(condition, (list, tuple)) and isinstance(condition[0],\n                                                             integer_types):\n        def imatcher(info):\n            return info.index in condition\n\n        return imatcher\n    elif callable(condition):\n        return condition\n    else:\n        raise TypeError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread specific files from archive into memory.", "response": "def read_files(self, condition='*'):\n        \"\"\"Read specific files from archive into memory.\n        If \"condition\" is a list of numbers, then return files which have those positions in infolist.\n        If \"condition\" is a string, then it is treated as a wildcard for names of files to extract.\n        If \"condition\" is a function, it is treated as a callback function, which accepts a RarInfo object \n            and returns boolean True (extract) or False (skip).\n        If \"condition\" is omitted, all files are returned.\n        \n        Returns list of tuples (RarInfo info, str contents)\n        \"\"\"\n        checker = condition2checker(condition)\n        return RarFileImplementation.read_files(self, checker)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting specific files from archive to disk.", "response": "def extract(self, condition='*', path='.', withSubpath=True,\n                overwrite=True):\n        \"\"\"Extract specific files from archive to disk.\n        \n        If \"condition\" is a list of numbers, then extract files which have those positions in infolist.\n        If \"condition\" is a string, then it is treated as a wildcard for names of files to extract.\n        If \"condition\" is a function, it is treated as a callback function, which accepts a RarInfo object\n            and returns either boolean True (extract) or boolean False (skip).\n        DEPRECATED: If \"condition\" callback returns string (only supported for Windows) - \n            that string will be used as a new name to save the file under.\n        If \"condition\" is omitted, all files are extracted.\n        \n        \"path\" is a directory to extract to\n        \"withSubpath\" flag denotes whether files are extracted with their full path in the archive.\n        \"overwrite\" flag denotes whether extracted files will overwrite old ones. Defaults to true.\n        \n        Returns list of RarInfos for extracted files.\"\"\"\n        checker = condition2checker(condition)\n        return RarFileImplementation.extract(self, checker, path, withSubpath,\n                                             overwrite)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all significantly enriched gene sets in a set of genes.", "response": "def get_static_enrichment(\n            self, genes: Iterable[str],\n            pval_thresh: float,\n            adjust_pval_thresh: bool = True,\n            K_min: int = 3,\n            gene_set_ids: Iterable[str] = None) -> StaticGSEResult:\n        \"\"\"Find enriched gene sets in a set of genes.\n\n        Parameters\n        ----------\n        genes : set of str\n            The set of genes to test for gene set enrichment.\n        pval_thresh : float\n            The significance level (p-value threshold) to use in the analysis.\n        adjust_pval_thresh : bool, optional\n            Whether to adjust the p-value threshold using a Bonferroni\n            correction. (Warning: This is a very conservative correction!)\n            [True]\n        K_min : int, optional\n            The minimum number of gene set genes present in the analysis. [3]\n        gene_set_ids : Iterable or None\n            A list of gene set IDs to test. If ``None``, all gene sets are\n            tested that meet the :attr:`K_min` criterion.\n\n        Returns\n        -------\n        list of `StaticGSEResult`\n            A list of all significantly enriched gene sets. \n        \"\"\"\n        genes = set(genes)\n        gene_set_coll = self._gene_set_coll\n        gene_sets = self._gene_set_coll.gene_sets\n        gene_memberships = self._gene_memberships\n        sorted_genes = sorted(genes)\n\n        # test only some terms?\n        if gene_set_ids is not None:\n            gs_indices = np.int64([self._gene_set_coll.index(id_)\n                                   for id_ in gene_set_ids])\n            gene_sets = [gene_set_coll[id_] for id_ in gene_set_ids]\n            # gene_set_coll = GeneSetCollection(gene_sets)\n            gene_memberships = gene_memberships[:, gs_indices]  # not a view!\n\n        # determine K's\n        K_vec = np.sum(gene_memberships, axis=0, dtype=np.int64)\n\n        # exclude terms with too few genes\n        sel = np.nonzero(K_vec >= K_min)[0]\n        K_vec = K_vec[sel]\n        gene_sets = [gene_sets[j] for j in sel]\n        gene_memberships = gene_memberships[:, sel]\n\n        # determine k's, ignoring unknown genes\n        unknown = 0\n        sel = []\n        filtered_genes = []\n        logger.debug('Looking up indices for %d genes...', len(sorted_genes))\n        for i, g in enumerate(sorted_genes):\n            try:\n                idx = self._gene_indices[g]\n            except KeyError:\n                unknown += 1\n            else:\n                sel.append(idx)\n                filtered_genes.append(g)\n\n        sel = np.int64(sel)\n        gene_indices = np.int64(sel)\n        # gene_memberships = gene_memberships[sel, :]\n        k_vec = np.sum(gene_memberships[sel, :], axis=0, dtype=np.int64)\n        if unknown > 0:\n            logger.warn('%d / %d unknown genes (%.1f %%), will be ignored.',\n                        unknown, len(genes),\n                        100 * (unknown / float(len(genes))))\n\n        # determine n and N\n        n = len(filtered_genes)\n        N, m = gene_memberships.shape\n        logger.info('Conducting %d tests.', m)\n\n        # correct p-value threshold, if specified\n        final_pval_thresh = pval_thresh\n        if adjust_pval_thresh:\n            final_pval_thresh /= float(m)\n            logger.info('Using Bonferroni-corrected p-value threshold: %.1e',\n                        final_pval_thresh)\n\n        # calculate p-values and get significantly enriched gene sets\n        enriched = []\n\n        logger.debug('N=%d, n=%d', N, n)\n        sys.stdout.flush()\n        genes = self._valid_genes\n        for j in range(m):\n            pval = hypergeom.sf(k_vec[j] - 1, N, K_vec[j], n)\n            if pval <= final_pval_thresh:\n                # found significant enrichment\n                # sel_genes = [filtered_genes[i] for i in np.nonzero(gene_memberships[:, j])[0]]\n                sel_genes = [genes[i] for i in\n                             np.nonzero(gene_memberships[gene_indices, j])[0]]\n                enriched.append(\n                    StaticGSEResult(gene_sets[j], N, n, set(sel_genes), pval))\n\n        return enriched"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_rank_based_enrichment(\n            self,\n            ranked_genes: List[str],\n            pval_thresh: float = 0.05,\n            X_frac: float = 0.25,\n            X_min: int = 5,\n            L: int = None,\n            adjust_pval_thresh: bool = True,\n            escore_pval_thresh: float = None,\n            exact_pval: str = 'always',\n            gene_set_ids: List[str] = None,\n            table: np.ndarray = None) -> RankBasedGSEResult:\n        \"\"\"Test for gene set enrichment at the top of a ranked list of genes.\n\n        This function uses the XL-mHG test to identify enriched gene sets.\n\n        This function also calculates XL-mHG E-scores for the enriched gene\n        sets, using ``escore_pval_thresh`` as the p-value threshold \"psi\".\n\n        Parameters\n        ----------\n        ranked_gene_ids : list of str\n            The ranked list of gene IDs.\n        pval_thresh : float, optional\n            The p-value threshold used to determine significance.\n            See also ``adjust_pval_thresh``. [0.05]\n        X_frac : float, optional\n            The min. fraction of genes from a gene set required for enrichment. [0.25]\n        X_min : int, optional\n            The min. no. of genes from a gene set required for enrichment. [5]\n        L : int, optional\n            The lowest cutoff to test for enrichment. If ``None``,\n            int(0.25*(no. of genes)) will be used. [None]\n        adjust_pval_thresh : bool, optional\n            Whether to adjust the p-value thershold for multiple testing,\n            using the Bonferroni method. [True]\n        escore_pval_thresh : float or None, optional\n            The \"psi\" p-value threshold used in calculating E-scores. If\n            ``None``, will be set to p-value threshold. [None]\n        exact_pval : str\n            Choices are: \"always\", \"if_significant\", \"if_necessary\". Parameter\n            will be passed to `xlmhg.get_xlmhg_test_result`. [\"always\"]\n        gene_set_ids : list of str or None, optional\n            A list of gene set IDs to specify which gene sets should be tested for enrichment. If ``None``, all gene sets will be tested. [None]\n        table : 2-dim numpy.ndarray of type numpy.longdouble or None, optional\n            The dynamic programming table used by the algorithm for calculating XL-mHG p-values. Passing this avoids memory re-allocation when calling this function repetitively. [None]\n\n        Returns\n        -------\n        list of `RankBasedGSEResult`\n            A list of all significantly enriched gene sets. \n        \"\"\"\n\n        # make sure X_frac is a float (e.g., if specified as 0)\n        X_frac = float(X_frac)\n\n        if table is not None:\n            if not np.issubdtype(table.dtype, np.longdouble):\n                raise TypeError('The provided array for storing the dynamic '\n                                'programming table must be of type '\n                                '\"longdouble\"!')\n\n        if L is None:\n            L = int(len(ranked_genes)/4.0)\n\n        gene_set_coll = self._gene_set_coll\n        gene_memberships = self._gene_memberships\n\n        # postpone this\n        if escore_pval_thresh is None:\n            # if no separate E-score p-value threshold is specified, use the\n            # p-value threshold (this results in conservative E-scores)\n            logger.warning('No E-score p-value threshold supplied. '\n                           'The E-score p-value threshold will be set to the'\n                           'global significance threshold. This will result '\n                           'in conservative E-scores.')\n\n        # test only some terms?\n        if gene_set_ids is not None:\n            gs_indices = np.int64([self._gene_set_coll.index(id_)\n                                   for id_ in gene_set_ids])\n            gene_sets = [gene_set_coll[id_] for id_ in gene_set_ids]\n            gene_set_coll = GeneSetCollection(gene_sets)\n            gene_memberships = gene_memberships[:, gs_indices]  # not a view!\n\n        # reorder rows in annotation matrix to match the given gene ranking\n        # also exclude genes not in the ranking\n        unknown = 0\n        L_adj = L\n        sel = []\n        filtered_genes = []\n        logger.debug('Looking up indices for %d genes...' % len(ranked_genes))\n        for i, g in enumerate(ranked_genes):\n            try:\n                idx = self._gene_indices[g]\n            except KeyError:\n                unknown += 1\n                # adjust L if the gene was above the original L cutoff\n                if i < L:\n                    L_adj -= 1\n            else:\n                sel.append(idx)\n                filtered_genes.append(g)\n        sel = np.int64(sel)\n        logger.debug('Adjusted L: %d', L_adj)\n\n        # the following also copies the data (not a view)\n        gene_memberships = gene_memberships[sel, :]\n        N, m = gene_memberships.shape\n        if unknown > 0:\n            # Some genes in the ranked list were unknown (i.e., not present in\n            # the specified genome).\n            logger.warn('%d / %d unknown genes (%.1f %%), will be ignored.',\n                        unknown, len(ranked_genes),\n                        100 * (unknown / float(len(ranked_genes))))\n\n\n        # Determine the number of gene set genes above the L'th cutoff,\n        # for all gene sets. This quantity is useful, because we don't need\n        # to perform any more work for gene sets that have less than X genes\n        # above the cutoff.\n        k_above_L = np.sum(gene_memberships[:L_adj, :], axis=0, dtype=np.int64)\n\n        # Determine the number of genes below the L'th cutoff, for all gene\n        # sets.\n        k_below_L = np.sum(gene_memberships[L_adj:, :], axis=0, dtype=np.int64)\n\n        # Determine the total number K of genes in each gene set that are\n        # present in the ranked list (this is equal to k_above_L + k_below_L)\n        K_vec = k_above_L + k_below_L\n\n        # Determine the largest K across all gene sets.\n        K_max = np.amax(K_vec)\n\n        # Determine X for all gene sets.\n        X = np.amax(\n            np.c_[np.tile(X_min, m), np.int64(np.ceil(X_frac * K_vec))],\n            axis=1)\n\n        # Determine the number of tests (we do not conduct a test if the\n        # total number of gene set genes in the ranked list is below X).\n        num_tests = np.sum(K_vec-X >= 0)\n        logger.info('Conducting %d tests.', num_tests)\n\n        # determine Bonferroni-corrected p-value, if desired\n        final_pval_thresh = pval_thresh\n        if adjust_pval_thresh and num_tests > 0:\n            final_pval_thresh /= float(num_tests)\n            logger.info('Using Bonferroni-corrected p-value threshold: %.1e',\n                        final_pval_thresh)\n\n        if escore_pval_thresh is None:\n            escore_pval_thresh = final_pval_thresh\n\n        elif escore_pval_thresh < final_pval_thresh:\n            logger.warning('The E-score p-value threshold is smaller than '\n                           'the p-value threshold. Setting E-score p-value '\n                           'threshold to the p-value threshold.')\n            escore_pval_thresh = final_pval_thresh\n\n        # Prepare the matrix that holds the dynamic programming table for\n        # the calculation of the XL-mHG p-value.\n        if table is None:\n            table = np.empty((K_max+1, N+1), dtype=np.longdouble)\n        else:\n            if table.shape[0] < K_max+1 or table.shape[1] < N+1:\n                raise ValueError(\n                    'The supplied array is too small (%d x %d) to hold the '\n                    'entire dynamic programming table. The required size is'\n                    '%d x %d (rows x columns).'\n                    % (table.shape[0], table.shape[1], K_max+1, N+1))\n\n        # find enriched GO terms\n        # logger.info('Testing %d gene sets for enrichment...', m)\n        logger.debug('(N=%d, X_frac=%.2f, X_min=%d, L=%d; K_max=%d)',\n                     len(ranked_genes), X_frac, X_min, L, K_max)\n\n        enriched = []\n        num_tests = 0  # number of tests conducted\n        for j in range(m):\n            # determine gene set-specific value for X\n            X = max(X_min, int(ceil(X_frac * float(K_vec[j]))))\n\n            # Determine significance of gene set enrichment using the XL-mHG\n            # test (only if there are at least X gene set genes in the list).\n            if K_vec[j] >= X:\n                num_tests += 1\n\n                # We only need to perform the XL-mHG test if there are enough\n                # gene set genes above the L'th cutoff (otherwise, pval = 1.0).\n                if k_above_L[j] >= X:\n                    # perform test\n\n                    # Determine the ranks of the gene set genes in the\n                    # ranked list.\n                    indices = np.uint16(np.nonzero(gene_memberships[:, j])[0])\n                    res = xlmhg.get_xlmhg_test_result(\n                        N, indices, X, L, pval_thresh=final_pval_thresh,\n                        escore_pval_thresh=escore_pval_thresh,\n                        exact_pval=exact_pval, table=table)\n\n                    # check if gene set is significantly enriched\n                    if res.pval <= final_pval_thresh:\n                        # generate RankedGSEResult\n                        ind_genes = [ranked_genes[i] for i in indices]\n                        gse_result = RankBasedGSEResult(\n                            gene_set_coll[j], N, indices, ind_genes,\n                            X, L, res.stat, res.cutoff, res.pval,\n                            escore_pval_thresh=escore_pval_thresh\n                        )\n                        enriched.append(gse_result)\n\n        # report results\n        q = len(enriched)\n        ignored = m - num_tests\n        if ignored > 0:\n            logger.debug('%d / %d gene sets (%.1f%%) had less than X genes '\n                         'annotated with them and were ignored.',\n                         ignored, m, 100 * (ignored / float(m)))\n\n        logger.info('%d / %d gene sets were found to be significantly '\n                    'enriched (p-value <= %.1e).', q, m, final_pval_thresh)\n\n        return enriched", "response": "This function test for the rank - based enrichment of a list of unranked genes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef authenticate_storage(client_secrets, read_only=False):\n    if read_only:\n        scopes = ['https://www.googleapis.com/auth/devstorage.read_only']\n    else:\n        scopes = ['https://www.googleapis.com/auth/devstorage.read_write']\n\n    credentials = service_account.Credentials.from_service_account_info(\n            client_secrets)\n    \n    scoped_credentials = credentials.with_scopes(scopes)\n    \n    return scoped_credentials", "response": "Authenticates a service account for reading and or write on a bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authenticate_compute(client_secrets):\n    scopes = ['https://www.googleapis.com/auth/compute']\n\n    credentials = ServiceAccountCredentials.from_json_keyfile_dict(\n            client_secrets, scopes=scopes)\n    \n    return credentials", "response": "Authenticates a service account for the compute engine."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting Ensembl IDs and store in tab-delimited text file. Parameters ---------- args: argparse.Namespace object, optional The argument values. If not specified, the values will be obtained by parsing the command line arguments using the `argparse` module. Returns ------- int Exit code (0 if no error occurred).", "response": "def main(args=None):\n    \"\"\"Extract Ensembl IDs and store in tab-delimited text file.\n\n    Parameters\n    ----------\n    args: argparse.Namespace object, optional\n        The argument values. If not specified, the values will be obtained by\n        parsing the command line arguments using the `argparse` module.\n\n    Returns\n    -------\n    int\n        Exit code (0 if no error occurred).\n    \"\"\"\n\n    if args is None:\n        # parse command-line arguments\n        parser = get_argument_parser()\n        args = parser.parse_args()\n\n    input_file = args.annotation_file\n    output_file = args.output_file\n    species = args.species\n    chrom_pat = args.chromosome_pattern\n    field_name = args.field_name\n    log_file = args.log_file\n    quiet = args.quiet\n    verbose = args.verbose\n\n    # configure logger\n    log_stream = sys.stdout\n    if output_file == '-':\n        # if we print output to stdout, redirect log messages to stderr\n        log_stream = sys.stderr\n\n    logger = misc.get_logger(log_stream = log_stream, log_file = log_file,\n            quiet = quiet, verbose = verbose)\n\n    if chrom_pat is None:\n        chrom_pat = re.compile(ensembl.SPECIES_CHROMPAT[species])\n    else:\n        chrom_pat = re.compile(chrom_pat)\n\n    logger.info('Regular expression used for filtering chromosome names: \"%s\"',\n            chrom_pat.pattern)\n\n    # for statistics\n    types = Counter()\n    sources = Counter()\n\n    # primary information\n    genes = Counter()\n    gene_chroms = dict()\n    gene_ids = dict()\n\n    # secondary information\n    genes2 = Counter()\n    polymorphic = set()\n\n    # list of chromosomes\n    chromosomes = set()\n    excluded_chromosomes = set()\n\n    transcripts = {}\n    gene_id = None\n    gene_name = None\n\n    i = 0\n    missing = 0\n    logger.info('Parsing data...')\n    if input_file == '-':\n        input_file = None\n    with misc.smart_open_read(input_file, mode = 'rb', try_gzip = True) as fh:\n        #if i >= 500000: break\n        reader = csv.reader(fh, dialect = 'excel-tab')\n        for l in reader:\n\n            i += 1\n            #if i % int(1e5) == 0:\n            #   print '\\r%d...' %(i), ; sys.stdout.flush() # report progress\n\n            if len(l) > 1 and l[2] == field_name:\n                attr = parse_attributes(l[8])\n                type_ = attr['gene_biotype']\n\n                if type_ not in ['protein_coding', 'polymorphic_pseudogene']:\n                    continue\n\n                chrom = l[0]\n\n                # test whether chromosome is valid\n                m = chrom_pat.match(chrom)\n                if m is None:\n                    excluded_chromosomes.add(chrom)\n                    continue\n\n                chromosomes.add(m.group())\n\n                source = l[1]\n                gene_id = attr['gene_id']\n                try:\n                    gene_name = attr['gene_name']\n                except KeyError as e:\n                    missing += 1\n                    continue\n\n                if gene_id in genes:\n                    if genes[gene_id] != gene_name:\n                        raise ValueError('Ensembl ID \"%s\" ' %(gene_id) +\n                                'associated with multiple gene symbols.')\n                else:\n                    genes[gene_id] = gene_name\n\n    logger.info('Done! (Parsed %d lines.)', i)\n\n    logger.info('Excluded %d chromosomes:', len(excluded_chromosomes))\n    logger.info(', '.join(sorted(excluded_chromosomes)))\n\n    n = len(genes)\n    m = len(set(genes.values()))\n\n    logger.info('No. of chromosomes: %d', len(chromosomes))\n    logger.info('No. of genes IDs: %d', n)\n    logger.info('No. of gene names: %d', m)\n\n    with misc.smart_open_write(output_file) as ofh:\n        writer = csv.writer(ofh, dialect = 'excel-tab',\n                lineterminator = os.linesep, quoting = csv.QUOTE_NONE)\n        for g in sorted(genes.keys()):\n            writer.writerow([g, genes[g]])\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the SQLAlchemy connection string if it is set", "response": "def get_connection_string(connection=None):\n    \"\"\"return SQLAlchemy connection string if it is set\n\n    :param connection: get the SQLAlchemy connection string #TODO\n    :rtype: str\n    \"\"\"\n    if not connection:\n        config = configparser.ConfigParser()\n        cfp = defaults.config_file_path\n        if os.path.exists(cfp):\n            log.info('fetch database configuration from %s', cfp)\n            config.read(cfp)\n            connection = config['database']['sqlalchemy_connection_string']\n            log.info('load connection string from %s: %s', cfp, connection)\n        else:\n            with open(cfp, 'w') as config_file:\n                connection = defaults.sqlalchemy_connection_string_default\n                config['database'] = {'sqlalchemy_connection_string': connection}\n                config.write(config_file)\n                log.info('create configuration file %s', cfp)\n\n    return connection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(connection=None, urls=None, force_download=False, taxids=None, silent=False):\n    if isinstance(taxids, int):\n        taxids = (taxids,)\n    db = DbManager(connection)\n    db.db_import_xml(urls, force_download, taxids, silent)\n    db.session.close()", "response": "Updates CTD database with NCBI XML data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexports database to obo file", "response": "def export_obo(path_to_file, connection=None):\n    \"\"\"export database to obo file\n\n    :param path_to_file: path to export file\n    :param connection: connection string (optional)\n    :return:\n    \"\"\"\n    db = DbManager(connection)\n    db.export_obo(path_to_export_file=path_to_file)\n    db.session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads gzipped XML file and creates all tables in database", "response": "def db_import_xml(self, url=None, force_download=False, taxids=None, silent=False):\n        \"\"\"Updates the CTD database\n        \n        1. downloads gzipped XML\n        2. drops all tables in database\n        3. creates all tables in database\n        4. import XML\n        5. close session\n\n        :param Optional[list[int]] taxids: list of NCBI taxonomy identifier\n        :param str url: iterable of URL strings\n        :param bool force_download: force method to download\n        :param bool silent:\n        \"\"\"\n        log.info('Update UniProt database from {}'.format(url))\n\n        self._drop_tables()\n        xml_gzipped_file_path, version_file_path = self.download(url, force_download)\n        self._create_tables()\n        self.import_version(version_file_path)\n        self.import_xml(xml_gzipped_file_path, taxids, silent)\n        self.session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimport XML file from gzipped file.", "response": "def import_xml(self, xml_gzipped_file_path, taxids=None, silent=False):\n        \"\"\"Imports XML\n\n        :param str xml_gzipped_file_path: path to XML file\n        :param Optional[list[int]] taxids: NCBI taxonomy identifier\n        :param bool silent: no output if True\n        \"\"\"\n        version = self.session.query(models.Version).filter(models.Version.knowledgebase == 'Swiss-Prot').first()\n        version.import_start_date = datetime.now()\n\n        entry_xml = '<entries>'\n        number_of_entries = 0\n        interval = 1000\n        start = False\n\n        if sys.platform in ('linux', 'linux2', 'darwin'):\n            log.info('Load gzipped XML from {}'.format(xml_gzipped_file_path))\n\n            zcat_command = 'gzcat' if sys.platform == 'darwin' else 'zcat'\n\n            number_of_lines = int(getoutput(\"{} {} | wc -l\".format(zcat_command, xml_gzipped_file_path)))\n\n            tqdm_desc = 'Import {} lines'.format(number_of_lines)\n\n        else:\n            print('bin was anderes')\n            number_of_lines = None\n            tqdm_desc = None\n\n        with gzip.open(xml_gzipped_file_path) as fd:\n\n            for line in tqdm(fd, desc=tqdm_desc, total=number_of_lines, mininterval=1, disable=silent):\n\n                end_of_file = line.startswith(b\"</uniprot>\")\n\n                if line.startswith(b\"<entry \"):\n                    start = True\n\n                elif end_of_file:\n                    start = False\n\n                if start:\n                    entry_xml += line.decode(\"utf-8\")\n\n                if line.startswith(b\"</entry>\") or end_of_file:\n                    number_of_entries += 1\n                    start = False\n\n                    if number_of_entries == interval or end_of_file:\n\n                        entry_xml += \"</entries>\"\n                        self.insert_entries(entry_xml, taxids)\n\n                        if end_of_file:\n                            break\n\n                        else:\n                            entry_xml = \"<entries>\"\n                            number_of_entries = 0\n\n        version.import_completed_date = datetime.now()\n        self.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert_entries(self, entries_xml, taxids=None):\n\n        entries = etree.fromstring(entries_xml)\n        del entries_xml\n\n        for entry in entries:\n            self.insert_entry(entry, taxids)\n            entry.clear()\n            del entry\n\n        entries.clear()\n        del entries\n\n        self.session.commit()", "response": "Inserts UniProt entries from XML string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert UniProt entry\" :param entry: XML node entry :param taxids: Optional[iter[int]] taxids: NCBI taxonomy IDs", "response": "def insert_entry(self, entry, taxids):\n        \"\"\"Insert UniProt entry\"\n\n        :param entry: XML node entry\n        :param taxids: Optional[iter[int]] taxids: NCBI taxonomy IDs\n        \"\"\"\n        entry_dict = entry.attrib\n        entry_dict['created'] = datetime.strptime(entry_dict['created'], '%Y-%m-%d')\n        entry_dict['modified'] = datetime.strptime(entry_dict['modified'], '%Y-%m-%d')\n\n        taxid = self.get_taxid(entry)\n\n        if taxids is None or taxid in taxids:\n            entry_dict = self.update_entry_dict(entry, entry_dict, taxid)\n            entry_obj = models.Entry(**entry_dict)\n            del entry_dict\n\n            self.session.add(entry_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget models. Sequence object from XML node entry", "response": "def get_sequence(cls, entry):\n        \"\"\"\n        get models.Sequence object from XML node entry\n\n        :param entry: XML node entry\n        :return: :class:`pyuniprot.manager.models.Sequence` object\n        \"\"\"\n        seq_tag = entry.find(\"./sequence\")\n        seq = seq_tag.text\n        seq_tag.clear()\n        return models.Sequence(sequence=seq)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tissue_in_references(self, entry):\n        tissue_in_references = []\n        query = \"./reference/source/tissue\"\n        tissues = {x.text for x in entry.iterfind(query)}\n\n        for tissue in tissues:\n\n            if tissue not in self.tissues:\n                self.tissues[tissue] = models.TissueInReference(tissue=tissue)\n            tissue_in_references.append(self.tissues[tissue])\n\n        return tissue_in_references", "response": "get list of models. TissueInReference from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_tissue_specificities(cls, entry):\n        tissue_specificities = []\n\n        query = \"./comment[@type='tissue specificity']/text\"\n\n        for ts in entry.iterfind(query):\n            tissue_specificities.append(models.TissueSpecificity(comment=ts.text))\n\n        return tissue_specificities", "response": "get list of models. TissueSpecificity objects from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_subcellular_locations(self, entry):\n        subcellular_locations = []\n        query = './comment/subcellularLocation/location'\n        sls = {x.text for x in entry.iterfind(query)}\n\n        for sl in sls:\n\n            if sl not in self.subcellular_locations:\n                self.subcellular_locations[sl] = models.SubcellularLocation(location=sl)\n            subcellular_locations.append(self.subcellular_locations[sl])\n\n        return subcellular_locations", "response": "get list of models. SubcellularLocation objects from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_keywords(self, entry):\n        keyword_objects = []\n\n        for keyword in entry.iterfind(\"./keyword\"):\n            identifier = keyword.get('id')\n            name = keyword.text\n            keyword_hash = hash(identifier)\n\n            if keyword_hash not in self.keywords:\n                self.keywords[keyword_hash] = models.Keyword(**{'identifier': identifier, 'name': name})\n\n            keyword_objects.append(self.keywords[keyword_hash])\n\n        return keyword_objects", "response": "get list of models. Keyword objects from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_disease_comments(self, entry):\n        disease_comments = []\n        query = \"./comment[@type='disease']\"\n\n        for disease_comment in entry.iterfind(query):\n            value_dict = {'comment': disease_comment.find('./text').text}\n\n            disease = disease_comment.find(\"./disease\")\n\n            if disease is not None:\n                disease_dict = {'identifier': disease.get('id')}\n\n                for element in disease:\n                    key = element.tag\n\n                    if key in ['acronym', 'description', 'name']:\n                        disease_dict[key] = element.text\n\n                    if key == 'dbReference':\n                        disease_dict['ref_id'] = element.get('id')\n                        disease_dict['ref_type'] = element.get('type')\n\n                disease_obj = models.get_or_create(self.session, models.Disease, **disease_dict)\n                self.session.add(disease_obj)\n                self.session.flush()\n                value_dict['disease_id'] = disease_obj.id\n\n            disease_comments.append(models.DiseaseComment(**value_dict))\n\n        return disease_comments", "response": "get list of models. Disease objects from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting list of models. AlternativeFullName objects from XML node entry", "response": "def get_alternative_full_names(cls, entry):\n        \"\"\"\n        get list of models.AlternativeFullName objects from XML node entry\n\n        :param entry: XML node entry\n        :return: list of :class:`pyuniprot.manager.models.AlternativeFullName` objects\n        \"\"\"\n        names = []\n        query = \"./protein/alternativeName/fullName\"\n        for name in entry.iterfind(query):\n            names.append(models.AlternativeFullName(name=name.text))\n\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets list of models. AlternativeShortName objects from XML node entry", "response": "def get_alternative_short_names(cls, entry):\n        \"\"\"\n        get list of models.AlternativeShortName objects from XML node entry\n\n        :param entry: XML node entry\n        :return: list of :class:`pyuniprot.manager.models.AlternativeShortName` objects\n        \"\"\"\n        names = []\n        query = \"./protein/alternativeName/shortName\"\n        for name in entry.iterfind(query):\n            names.append(models.AlternativeShortName(name=name.text))\n\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets list of models. ECNumber objects from XML node entry", "response": "def get_ec_numbers(cls, entry):\n        \"\"\"\n        get list of models.ECNumber objects from XML node entry\n\n        :param entry:  XML node entry\n        :return: list of models.ECNumber objects\n        \"\"\"\n        ec_numbers = []\n\n        for ec in entry.iterfind(\"./protein/recommendedName/ecNumber\"):\n            ec_numbers.append(models.ECNumber(ec_number=ec.text))\n        return ec_numbers"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting primary gene name from XML node entry", "response": "def get_gene_name(cls, entry):\n        \"\"\"\n        get primary gene name from XML node entry\n\n        :param entry: XML node entry\n        :return: str\n        \"\"\"\n        gene_name = entry.find(\"./gene/name[@type='primary']\")\n\n        return gene_name.text if gene_name is not None and gene_name.text.strip() else None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_other_gene_names(cls, entry):\n        alternative_gene_names = []\n\n        for alternative_gene_name in entry.iterfind(\"./gene/name\"):\n\n            if alternative_gene_name.attrib['type'] != 'primary':\n\n                alternative_gene_name_dict = {\n                    'type_': alternative_gene_name.attrib['type'],\n                    'name': alternative_gene_name.text\n                }\n\n                alternative_gene_names.append(models.OtherGeneName(**alternative_gene_name_dict))\n\n        return alternative_gene_names", "response": "get list of models. OtherGeneName objects from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget list of models. Accession objects from XML node entry", "response": "def get_accessions(cls, entry):\n        \"\"\"\n        get list of models.Accession from XML node entry\n\n        :param entry: XML node entry\n        :return: list of :class:`pyuniprot.manager.models.Accession` objects\n        \"\"\"\n        return [models.Accession(accession=x.text) for x in entry.iterfind(\"./accession\")]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_db_references(cls, entry):\n        db_refs = []\n\n        for db_ref in entry.iterfind(\"./dbReference\"):\n\n            db_ref_dict = {'identifier': db_ref.attrib['id'], 'type_': db_ref.attrib['type']}\n            db_refs.append(models.DbReference(**db_ref_dict))\n\n        return db_refs", "response": "get list of models. DbReference from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_features(cls, entry):\n        features = []\n\n        for feature in entry.iterfind(\"./feature\"):\n\n            feature_dict = {\n                'description': feature.attrib.get('description'),\n                'type_': feature.attrib['type'],\n                'identifier': feature.attrib.get('id')\n            }\n\n            features.append(models.Feature(**feature_dict))\n\n        return features", "response": "get list of models. Feature from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_recommended_protein_name(cls, entry):\n        query_full = \"./protein/recommendedName/fullName\"\n        full_name = entry.find(query_full).text\n\n        short_name = None\n        query_short = \"./protein/recommendedName/shortName\"\n        short_name_tag = entry.find(query_short)\n        if short_name_tag is not None:\n            short_name = short_name_tag.text\n\n        return full_name, short_name", "response": "get recommended full and short protein name as tuple from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_organism_hosts(cls, entry):\n\n        query = \"./organismHost/dbReference[@type='NCBI Taxonomy']\"\n        return [models.OrganismHost(taxid=x.get('id')) for x in entry.iterfind(query)]", "response": "get list of models. OrganismHost objects from XML node entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets list of models. Pmid objects from XML node entry", "response": "def get_pmids(self, entry):\n        \"\"\"\n        get `models.Pmid` objects from XML node entry\n\n        :param entry: XML node entry\n        :return: list of :class:`pyuniprot.manager.models.Pmid` objects\n        \"\"\"\n        pmids = []\n\n        for citation in entry.iterfind(\"./reference/citation\"):\n\n            for pubmed_ref in citation.iterfind('dbReference[@type=\"PubMed\"]'):\n\n                pmid_number = pubmed_ref.get('id')\n\n                if pmid_number in self.pmids:\n\n                    pmid_sqlalchemy_obj = self.session.query(models.Pmid)\\\n                        .filter(models.Pmid.pmid == pmid_number).one()\n\n                    pmids.append(pmid_sqlalchemy_obj)\n\n                else:\n                    pmid_dict = citation.attrib\n                    if not re.search('^\\d+$', pmid_dict['volume']):\n                        pmid_dict['volume'] = -1\n\n                    del pmid_dict['type'] # not needed because already filtered for PubMed\n\n                    pmid_dict.update(pmid=pmid_number)\n                    title_tag = citation.find('./title')\n\n                    if title_tag is not None:\n                        pmid_dict.update(title=title_tag.text)\n\n                    pmid_sqlalchemy_obj = models.Pmid(**pmid_dict)\n                    self.session.add(pmid_sqlalchemy_obj)\n                    self.session.flush()\n\n                    pmids.append(pmid_sqlalchemy_obj)\n\n                    self.pmids |= set([pmid_number, ]) # extend the cache of identifiers\n\n        return pmids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget list of models. Function objects from XML node entry", "response": "def get_functions(cls, entry):\n        \"\"\"\n        get `models.Function` objects from XML node entry\n\n        :param entry: XML node entry\n        :return: list of :class:`pyuniprot.manager.models.Function` objects\n        \"\"\"\n        comments = []\n        query = \"./comment[@type='function']\"\n        for comment in entry.iterfind(query):\n            text = comment.find('./text').text\n            comments.append(models.Function(text=text))\n\n        return comments"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download(cls, url=None, force_download=False):\n        if url:\n            version_url = os.path.join(os.path.dirname(url), defaults.VERSION_FILE_NAME)\n        else:\n            url = os.path.join(defaults.XML_DIR_NAME, defaults.SWISSPROT_FILE_NAME)\n            version_url = os.path.join(defaults.XML_DIR_NAME, defaults.VERSION_FILE_NAME)\n\n        xml_file_path = cls.get_path_to_file_from_url(url)\n        version_file_path = cls.get_path_to_file_from_url(version_url)\n\n        if force_download or not os.path.exists(xml_file_path):\n\n            log.info('download {} and {}'.format(xml_file_path, version_file_path))\n\n            scheme = urlsplit(url).scheme\n\n            if scheme in ('ftp', 'http'):\n                urlretrieve(version_url, version_file_path)\n                urlretrieve(url, xml_file_path)\n\n            elif not scheme and os.path.isfile(url):\n                shutil.copyfile(url, xml_file_path)\n                shutil.copyfile(version_url, version_file_path)\n\n        return xml_file_path, version_file_path", "response": "Downloads uniprot_sprot. xml. gz and reldate. txt from URL or file path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_path_to_file_from_url(cls, url):\n        file_name = urlparse(url).path.split('/')[-1]\n        return os.path.join(PYUNIPROT_DATA_DIR, file_name)", "response": "standard file path to store the log file from url"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting complete database to OBO file", "response": "def export_obo(self, path_to_export_file, name_of_ontology=\"uniprot\", taxids=None):\n        \"\"\"\n        export complete database to OBO (http://www.obofoundry.org/) file\n\n        :param path_to_export_file: path to export file\n        :param taxids: NCBI taxonomy identifiers to export (optional)\n        \"\"\"\n\n        fd = open(path_to_export_file, 'w')\n\n        header = \"format-version: 0.1\\ndata: {}\\n\".format(time.strftime(\"%d:%m:%Y %H:%M\"))\n        header += \"ontology: {}\\n\".format(name_of_ontology)\n        header += 'synonymtypedef: GENE_NAME \"GENE NAME\"\\nsynonymtypedef: ALTERNATIVE_NAME \"ALTERNATIVE NAME\"\\n'\n\n        fd.write(header)\n\n        query = self.session.query(models.Entry).limit(100)\n\n        if taxids:\n            query = query.filter(models.Entry.taxid.in_(taxids))\n\n        for entry in query.all():\n\n            fd.write('\\n[Term]\\nid: SWISSPROT:{}\\n'.format(entry.accessions[0]))\n\n            if len(entry.accessions) > 1:\n                for accession in entry.accessions[1:]:\n                    fd.write('alt_id: {}\\n'.format(accession))\n\n            fd.write('name: {}\\n'.format(entry.recommended_full_name))\n\n            for alternative_full_name in entry.alternative_full_names:\n                fd.write('synonym: \"{}\" EXACT ALTERNATIVE_NAME []\\n'.format(alternative_full_name.name))\n\n            for alternative_short_name in entry.alternative_short_names:\n                fd.write('synonym: \"{}\" EXACT ALTERNATIVE_NAME []\\n'.format(alternative_short_name.name))\n\n            fd.write('synonym: \"{}\" EXACT GENE_NAME []\\n'.format(entry.gene_name))\n\n            for xref in entry.db_references:\n                if xref.type_ in ['GO', 'HGNC']:\n                    xref.identifier = ':'.join(xref.identifier.split(':')[1:])\n                fd.write('xref: {}:{}\\n'.format(xref.type_, xref.identifier.replace('\\\\', '\\\\\\\\')))\n\n        fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nresolve a given set of nodes.", "response": "def resolve_nodes(self, nodes):\n        \"\"\"\n        Resolve a given set of nodes.\n\n        Dependencies of the nodes, even if they are not in the given list will\n        also be resolved!\n\n        :param list nodes: List of nodes to be resolved\n        :return: A list of resolved nodes\n        \"\"\"\n        if not nodes:\n            return []\n        resolved = []\n        for node in nodes:\n            if node in resolved:\n                continue\n            self.resolve_node(node, resolved)\n        return resolved"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolve_node(self, node=None, resolved=None, seen=None):\n        if seen is None:\n            seen = []\n        if resolved is None:\n            resolved = []\n        if node is None:\n            dependencies = sorted(self._nodes.keys())\n        else:\n            dependencies = self._nodes[node]\n            seen.append(node)\n        for dependency in dependencies:\n            if dependency in resolved:\n                continue\n            if dependency in seen:\n                raise Exception('Circular dependency %s > %s', str(node),\n                                str(dependency))\n            self.resolve_node(dependency, resolved, seen)\n        if node is not None:\n            resolved.append(node)\n        return resolved", "response": "Resolve a single node or all when node is omitted."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef findCodons(seq, codons):\n    seqLen = len(seq)\n    start = 0\n    while start < seqLen:\n        triplet = str(seq[start:start + 3])\n        if triplet in codons:\n            yield start\n        start = start + 3", "response": "Find all instances of the codons in codons in the given sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addORFs(fig, seq, minX, maxX, offsetAdjuster):\n    for frame in range(3):\n        target = seq[frame:]\n        for (codons, codonType, color) in (\n                (START_CODONS, 'start', 'green'),\n                (STOP_CODONS, 'stop', 'red')):\n            offsets = list(map(offsetAdjuster, findCodons(target, codons)))\n            if offsets:\n                fig.plot(offsets, np.tile(frame, len(offsets)), marker='.',\n                         markersize=4, color=color, linestyle='None')\n\n    fig.axis([minX, maxX, -1, 3])\n    fig.set_yticks(np.arange(3))\n    fig.set_ylabel('Frame', fontsize=17)\n    fig.set_title('Subject start (%s) and stop (%s) codons' % (\n        ', '.join(sorted(START_CODONS)), ', '.join(sorted(STOP_CODONS))),\n        fontsize=20)", "response": "Adds ORFs to a matplotlib figure."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef needle(reads):\n    from tempfile import mkdtemp\n    from shutil import rmtree\n\n    dir = mkdtemp()\n\n    file1 = join(dir, 'file1.fasta')\n    with open(file1, 'w') as fp:\n        print(reads[0].toString('fasta'), end='', file=fp)\n\n    file2 = join(dir, 'file2.fasta')\n    with open(file2, 'w') as fp:\n        print(reads[1].toString('fasta'), end='', file=fp)\n\n    out = join(dir, 'result.fasta')\n\n    Executor().execute(\"needle -asequence '%s' -bsequence '%s' -auto \"\n                       \"-outfile '%s' -aformat fasta\" % (\n                           file1, file2, out))\n\n    # Use 'list' in the following to force reading the FASTA from disk.\n    result = Reads(list(FastaReads(out)))\n    rmtree(dir)\n\n    return result", "response": "Run a Needleman - Wunsch alignment and return the two aligned sequences."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_until(stream, delimiter, max_bytes=16):\n\n    buf = bytearray()\n    delim_len = len(delimiter)\n\n    while len(buf) < max_bytes:\n        c = stream.read(1)\n\n        if not c:\n            break\n\n        buf += c\n        if buf[-delim_len:] == delimiter:\n            return bytes(buf[:-delim_len])", "response": "Read until we have found the given delimiter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dechunk(stream):\n\n    # TODO(vovan): Add support for chunk extensions:\n    # TODO(vovan): http://tools.ietf.org/html/rfc2616#section-3.6.1\n\n    while True:\n        chunk_len = read_until(stream, b'\\r\\n')\n\n        if chunk_len is None:\n            raise DechunkError(\n                'Could not extract chunk size: unexpected end of data.')\n\n        try:\n            chunk_len = int(chunk_len.strip(), 16)\n        except (ValueError, TypeError) as err:\n            raise DechunkError('Could not parse chunk size: %s' % (err,))\n\n        if chunk_len == 0:\n            break\n\n        bytes_to_read = chunk_len\n        while bytes_to_read:\n            chunk = stream.read(bytes_to_read)\n            bytes_to_read -= len(chunk)\n            yield chunk\n\n        # chunk ends with \\r\\n\n        crlf = stream.read(2)\n        if crlf != b'\\r\\n':\n            raise DechunkError('No CR+LF at the end of chunk!')", "response": "De - chunk HTTP body stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_chunks(stream_or_generator):\n\n    if isinstance(stream_or_generator, types.GeneratorType):\n        yield from stream_or_generator\n    elif hasattr(stream_or_generator, 'read'):\n        while True:\n            chunk = stream_or_generator.read(CHUNK_SIZE)\n            if not chunk:\n                break  # no more data\n\n            yield chunk\n\n    else:\n        raise TypeError('Input must be either readable or generator.')", "response": "This generator function returns a generator that yields from the given stream or generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decompress(chunks, compression):\n\n    if compression not in SUPPORTED_COMPRESSIONS:\n        raise TypeError('Unsupported compression type: %s' % (compression,))\n\n    de_compressor = DECOMPRESSOR_FACTORIES[compression]()\n    try:\n        for chunk in chunks:\n            try:\n                yield de_compressor.decompress(chunk)\n            except OSError as err:\n                # BZ2Decompressor: invalid data stream\n                raise DecompressError(err) from None\n\n        # BZ2Decompressor does not support flush() method.\n        if hasattr(de_compressor, 'flush'):\n            yield de_compressor.flush()\n\n    except zlib.error as err:\n        raise DecompressError(err) from None", "response": "Decompress a list of compressed chunks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread HTTP body stream yielding blocks of bytes.", "response": "def read_body_stream(stream, chunked=False, compression=None):\n    \"\"\"Read HTTP body stream, yielding blocks of bytes. De-chunk and\n    de-compress data if needed.\n\n    :param file stream: readable stream.\n    :param bool chunked: whether stream is chunked.\n    :param str|None compression: compression type is stream is\n           compressed, otherwise None.\n\n    :rtype: __generator[bytes]\n    :raise: TypeError, BodyStreamError\n    \"\"\"\n\n    if not (chunked or compression):\n        return to_chunks(stream)\n\n    generator = stream\n    if chunked:\n        generator = dechunk(generator)\n\n    if compression:\n        generator = decompress(to_chunks(generator), compression)\n\n    return generator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decompress(self, chunk):\n\n        try:\n            return self._decompressobj.decompress(chunk)\n        except zlib.error:\n            # ugly hack to work with raw deflate content that may\n            # be sent by microsoft servers. For more information, see:\n            # http://carsten.codimi.de/gzip.yaws/\n            # http://www.port80software.com/200ok/archive/2005/10/31/868.aspx\n            # http://www.gzip.org/zlib/zlib_faq.html#faq38\n            if self._first_chunk:\n                self._decompressobj = zlib.decompressobj(-zlib.MAX_WBITS)\n                return self._decompressobj.decompress(chunk)\n\n            raise\n        finally:\n            self._first_chunk = False", "response": "Decompress the chunk of data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef makeOuputDir(outputDir, force):\n    if outputDir:\n        if exists(outputDir):\n            if not force:\n                print('Will not overwrite pre-existing files. Use --force to '\n                      'make me.', file=sys.stderr)\n                sys.exit(1)\n        else:\n            mkdir(outputDir)\n    else:\n        outputDir = mkdtemp()\n        print('Writing output files to %s' % outputDir)\n\n    return outputDir", "response": "Create or check for an output directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing samtools mpileup to generate VCF.", "response": "def samtoolsMpileup(outFile, referenceFile, alignmentFile, executor):\n    \"\"\"\n    Use samtools mpileup to generate VCF.\n\n    @param outFile: The C{str} name to write the output to.\n    @param referenceFile: The C{str} name of the FASTA file with the reference\n        sequence.\n    @param alignmentFile: The C{str} name of the SAM or BAM alignment file.\n    @param executor: An C{Executor} instance.\n    \"\"\"\n    executor.execute(\n        'samtools mpileup -u -v -f %s %s > %s' %\n        (referenceFile, alignmentFile, outFile))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bcftoolsMpileup(outFile, referenceFile, alignmentFile, executor):\n    executor.execute(\n        'bcftools mpileup -Ov -f %s %s > %s' %\n        (referenceFile, alignmentFile, outFile))", "response": "Use bcftools mpileup to generate VCF."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse bcftools to extract consensus FASTA.", "response": "def bcftoolsConsensus(outFile, vcfFile, id_, referenceFile, executor):\n    \"\"\"\n    Use bcftools to extract consensus FASTA.\n\n    @param outFile: The C{str} name to write the output to.\n    @param vcfFile: The C{str} name of the VCF file with the calls from\n        the pileup.\n    @param id_: The C{str} identifier to use in the resulting FASTA sequence.\n    @param referenceFile: The C{str} name of the FASTA file with the reference\n        sequence.\n    @param executor: An C{Executor} instance.\n    \"\"\"\n    bgz = vcfFile + '.gz'\n    executor.execute('bgzip -c %s > %s' % (vcfFile, bgz))\n    executor.execute('tabix %s' % bgz)\n    executor.execute(\n        'bcftools consensus %s < %s | '\n        'filter-fasta.py --idLambda \\'lambda id: \"%s\"\\' > %s' %\n        (bgz, referenceFile, id_, outFile))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses vcftools to extract consensus FASTA.", "response": "def vcfutilsConsensus(outFile, vcfFile, id_, _, executor):\n    \"\"\"\n    Use vcftools to extract consensus FASTA.\n\n    @param outFile: The C{str} name to write the output to.\n    @param vcfFile: The C{str} name of the VCF file with the calls from\n        the pileup.\n    @param id_: The C{str} identifier to use in the resulting FASTA sequence.\n    @param executor: An C{Executor} instance.\n    \"\"\"\n    executor.execute(\n        'vcfutils.pl vcf2fq < %s | '\n        'filter-fasta.py --fastq --quiet --saveAs fasta '\n        '--idLambda \\'lambda id: \"%s\"\\' > %s' %\n        (vcfFile, id_, outFile))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the data at x y to value.", "response": "def set(self, x, y, value):\n        \"\"\"\n        Set the data at (x, y) to value.\n        \"\"\"\n        xBase = int(x) * self.xScale\n        yBase = int(y) * self.yScale\n        for xOffset in range(self.xScale):\n            for yOffset in range(self.yScale):\n                self.data[yBase + yOffset, xBase + xOffset] = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_argument_parser(prog=None, desc=None, formatter_class=None):\n    if formatter_class is None:\n        formatter_class = argparse.RawTextHelpFormatter\n\n    parser = argparse.ArgumentParser(\n        prog=prog, description=desc,\n        formatter_class=formatter_class, add_help=False\n    )\n\n    g = parser.add_argument_group('Help')\n    g.add_argument('-h', '--help', action='help',\n                   help='Show this help message and exit.')\n\n    v = genometools.__version__\n    g.add_argument('--version', action='version', version='GenomeTools ' + v,\n                   help='Output the GenomeTools version and exit.')\n\n    return parser", "response": "Create an argument parser."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd reporting arguments to an argument parser.", "response": "def add_reporting_args(parser):\n    \"\"\"Add reporting arguments to an argument parser.\n\n    Parameters\n    ----------\n    parser: `argparse.ArgumentParser`\n\n    Returns\n    -------\n    `argparse.ArgumentGroup`\n        The argument group created.\n    \"\"\"\n    g = parser.add_argument_group('Reporting options')\n\n    g.add_argument(\n        '-l', '--log-file', default=None,\n        type=str, metavar=file_mv,\n        help='Path of log file (if specified, report to stdout AND file.'\n    )\n\n    g.add_argument('-q', '--quiet', action='store_true',\n                   help='Only output errors and warnings.')\n\n    g.add_argument(\n        '-v', '--verbose', action='store_true',\n        help='Enable verbose output. Ignored if --quiet is specified.'\n    )\n\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of all resource groups.", "response": "def get_resource_groups(self):\n        \"\"\"\n        :return: dictionary {resource group id: object} of all resource groups.\n        \"\"\"\n\n        resource_groups = {r.index: r for r in self.get_objects_by_type('resourceGroupEx')}\n        return OrderedDict(sorted(resource_groups.items()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of all active ports.", "response": "def get_active_ports(self):\n        \"\"\"\n        :return: dictionary {index: object} of all ports.\n        \"\"\"\n\n        if not self.resource_groups:\n            return self.ports\n        else:\n            active_ports = OrderedDict()\n            for resource_group in self.resource_groups.values():\n                for active_port in resource_group.active_ports:\n                    active_ports[active_port] = self.ports[active_port]\n            return active_ports"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enable_capture_state(self, state, writeToHw=False):\n        if state:\n            activePorts = self.rePortInList.findall(self.activePortList)\n            self.activeCapturePortList = \"{{\" + activePorts[0] + \"}}\"\n        else:\n            self.activeCapturePortList = \"{{\"\"}}\"\n        if (writeToHw):\n            self.ix_command('write')", "response": "Enable or disable capture on the resource group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_containing(self, name, depth = 0):\n        ctx_dict = object.__getattribute__(self, '__dict__')\n        if name in ctx_dict:\n            if depth <= 0:\n                return self\n            depth -= 1\n        parent = ctx_dict.get('_parent')\n        if parent is None:\n            return None\n        return parent.get_containing(name, depth = depth)", "response": "Return the n - th context containing attribute named name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translator(self):\n        if self._translator is None:\n            languages = self.lang\n            if not languages:\n                return gettext.NullTranslations()\n            if not isinstance(languages, list):\n                languages = [languages]\n            translator = gettext.NullTranslations()\n            for name, i18n_dir in [\n                    (\n                        'biryani',\n                        os.path.join(pkg_resources.get_distribution('biryani').location, 'biryani', 'i18n'),\n                        ),\n                    (\n                        conf['country_package'].replace('_', '-'),\n                        os.path.join(pkg_resources.get_distribution(conf['country_package']).location,\n                            conf['country_package'], 'i18n'),\n                        ),\n                    ]:\n                if i18n_dir is not None:\n                    translator = new_translator(name, i18n_dir, languages, fallback = translator)\n            translator = new_translator(conf['package_name'], conf['i18n_dir'], languages, fallback = translator)\n            self._translator = translator\n        return self._translator", "response": "Get a valid translator object from one or several languages names."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lineage(self, title):\n        if title in self._cache:\n            return self._cache[title]\n\n        lineage = []\n        gi = int(title.split('|')[1])\n        query = 'SELECT taxID from gi_taxid where gi = %d' % gi\n\n        try:\n            while True:\n                self._cursor.execute(query)\n                taxID = self._cursor.fetchone()[0]\n                if taxID == 1:\n                    break\n                query = 'SELECT name from names where taxId = %s' % taxID\n                self._cursor.execute(query)\n                scientificName = self._cursor.fetchone()[0]\n                lineage.append((taxID, scientificName))\n                # Move up to the parent.\n                query = ('SELECT parent_taxID from nodes where taxID = %s' %\n                         taxID)\n        except TypeError:\n            lineage = []\n\n        self._cache[title] = lineage\n        return lineage", "response": "Get lineage information from the taxonomy database for a given title."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncloses the database connection and render self invalid.", "response": "def close(self):\n        \"\"\"\n        Close the database connection and render self invalid. Any subsequent\n        re-use of self will raise an error.\n        \"\"\"\n        self._cursor.close()\n        self._db.close()\n        self._cursor = self._db = self._cache = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retry(retries=0, delay=timedelta(), conditions=[]):\n    delay_in_seconds = delay.total_seconds()\n\n    def decorator(function):\n        \"\"\"\n        The actual decorator for retrying.\n        \"\"\"\n        @wraps(function)\n        def wrapper(*args, **kwargs):\n            \"\"\"\n            The actual wrapper for retrying.\n            \"\"\"\n            func = partial(function, *args, **kwargs)\n            return retry_loop(retries, delay_in_seconds, conditions, func)\n\n        return wrapper\n\n    return decorator", "response": "A decorator that creates a new function that retries on failure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_list(cls, gene_ontology, l):\n        assert isinstance(gene_ontology, GeneOntology)\n        assert isinstance(l, list)\n\n        assert len(l) == 17\n\n        go_term = gene_ontology[l[4]]\n\n        qualifier = l[3] or []\n        with_from = l[7] or None\n        db_name = l[9] or None\n        db_syn = l[10] or []\n        ext = l[15] or []\n        product_id = l[16] or None\n\n        annotation = cls(\n            db=l[0],\n            db_id=l[1],\n            db_symbol=l[2],\n            go_term=go_term,\n            db_ref=l[5],\n            ev_code=l[6],\n            db_type=l[11],\n            taxon=l[12],\n            date=l[13],\n            assigned_by=l[14],\n\n            qualifier=qualifier,\n            with_from=with_from,\n            db_name=db_name,\n            db_syn=db_syn,\n            ext=ext,\n            product_id=product_id,\n        )\n        return annotation", "response": "Initialize a GOAnnotation object from a list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the GO annotation as a flat list ( in GAF 2. 1 format order ).", "response": "def as_list(self):\n        \"\"\"Returns GO annotation as a flat list (in GAF 2.1 format order).\"\"\"\n        go_id = self.go_term.id\n        \n        qual_str = '|'.join(self.qualifier)\n        db_ref_str = '|'.join(self.db_ref)\n        taxon_str = '|'.join(self.taxon)\n\n        # with_from is currently left as a string\n        # with_from = '|'.join()\n        with_from_str = self.with_from or ''\n        db_name_str = self.db_name or ''\n        db_syn_str = '|'.join(self.db_syn)\n        ext_str = '|'.join(self.ext)\n        product_id_str = self.product_id or ''\n\n        l = [\n            self.db,\n            self.db_id,\n            self.db_symbol,\n            qual_str,\n            go_id,\n            db_ref_str,\n            self.ev_code,\n            with_from_str,\n            self.aspect,\n            db_name_str,\n            db_syn_str,\n            self.db_type,\n            taxon_str,\n            self.date,\n            self.assigned_by,\n            ext_str,\n            product_id_str,\n        ]\n        return l"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading DIAMOND tabular output and convert lines to dictionaries.", "response": "def diamondTabularFormatToDicts(filename, fieldNames=None):\n    \"\"\"\n    Read DIAMOND tabular (--outfmt 6) output and convert lines to dictionaries.\n\n    @param filename: Either a C{str} file name or an open file pointer.\n    @param fieldNames: A C{list} or C{tuple} of C{str} DIAMOND field names.\n        Run 'diamond -help' to see the full list. If C{None}, a default set of\n        fields will be used, as compatible with convert-diamond-to-sam.py\n    @raise ValueError: If a line of C{filename} does not have the expected\n        number of TAB-separated fields (i.e., len(fieldNames)). Or if\n        C{fieldNames} is empty or contains duplicates.\n    @return: A generator that yields C{dict}s with keys that are the DIAMOND\n        field names and values as converted by DIAMOND_FIELD_CONVERTER.\n    \"\"\"\n    fieldNames = fieldNames or FIELDS.split()\n    nFields = len(fieldNames)\n    if not nFields:\n        raise ValueError('fieldNames cannot be empty.')\n\n    c = Counter(fieldNames)\n    if c.most_common(1)[0][1] > 1:\n        raise ValueError(\n            'fieldNames contains duplicated names: %s.' %\n            (', '.join(sorted(x[0] for x in c.most_common() if x[1] > 1))))\n\n    def identity(x):\n        return x\n\n    convertFunc = DIAMOND_FIELD_CONVERTER.get\n\n    with as_handle(filename) as fp:\n        for count, line in enumerate(fp, start=1):\n            result = {}\n            line = line[:-1]\n            values = line.split('\\t')\n            if len(values) != nFields:\n                raise ValueError(\n                    'Line %d of %s had %d field values (expected %d). '\n                    'To provide input for this function, DIAMOND must be '\n                    'called with \"--outfmt 6 %s\" (without the quotes). '\n                    'The offending input line was %r.' %\n                    (count,\n                     (filename if isinstance(filename, six.string_types)\n                      else 'input'),\n                     len(values), nFields, FIELDS, line))\n            for fieldName, value in zip(fieldNames, values):\n                value = convertFunc(fieldName, identity)(value)\n                result[fieldName] = value\n            yield result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef records(self):\n        with as_handle(self._filename) as fp:\n            previousQtitle = None\n            subjectsSeen = {}\n            record = {}\n            for line in fp:\n                line = line[:-1]\n                try:\n                    (qtitle, stitle, bitscore, evalue, qframe, qseq,\n                     qstart, qend, sseq, sstart, send, slen, btop, nident,\n                     positive) = line.split('\\t')\n                except ValueError as e:\n                    # We may not be able to find 'nident' and 'positives'\n                    # because they were added in version 2.0.3 and will not\n                    # be present in any of our JSON output generated before\n                    # that. So those values will be None when reading\n                    # DIAMOND output without those fields, but that's much\n                    # better than no longer being able to read that data.\n                    if six.PY2:\n                        error = 'need more than 13 values to unpack'\n                    else:\n                        error = (\n                            'not enough values to unpack (expected 15, '\n                            'got 13)')\n                    if str(e) == error:\n                        (qtitle, stitle, bitscore, evalue, qframe,\n                         qseq, qstart, qend, sseq, sstart, send, slen,\n                         btop) = line.split('\\t')\n                        nident = positive = None\n                    else:\n                        raise\n                hsp = {\n                    'bits': float(bitscore),\n                    'btop': btop,\n                    'expect': float(evalue),\n                    'frame': int(qframe),\n                    'identicalCount': None if nident is None else int(nident),\n                    'positiveCount': (\n                        None if positive is None else int(positive)),\n                    'query': qseq,\n                    'query_start': int(qstart),\n                    'query_end': int(qend),\n                    'sbjct': sseq,\n                    'sbjct_start': int(sstart),\n                    'sbjct_end': int(send),\n                }\n                if previousQtitle == qtitle:\n                    # We have already started accumulating alignments for this\n                    # query.\n                    if stitle not in subjectsSeen:\n                        # We have not seen this subject before, so this is a\n                        # new alignment.\n                        subjectsSeen.add(stitle)\n                        alignment = {\n                            'hsps': [hsp],\n                            'length': int(slen),\n                            'title': stitle,\n                        }\n                        record['alignments'].append(alignment)\n                    else:\n                        # We have already seen this subject, so this is another\n                        # HSP in an already existing alignment.\n                        for alignment in record['alignments']:\n                            if alignment['title'] == stitle:\n                                alignment['hsps'].append(hsp)\n                                break\n                else:\n                    # All alignments for the previous query id (if any)\n                    # have been seen.\n                    if previousQtitle is not None:\n                        yield record\n\n                    # Start building up the new record.\n                    record = {}\n                    subjectsSeen = {stitle}\n                    alignment = {\n                        'hsps': [hsp],\n                        'length': int(slen),\n                        'title': stitle,\n                    }\n                    record['alignments'] = [alignment]\n                    record['query'] = qtitle\n\n                    previousQtitle = qtitle\n\n            # Yield the last record, if any.\n            if record:\n                yield record", "response": "Parse the DIAMOND output and yield records."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the records out as JSON.", "response": "def saveAsJSON(self, fp, writeBytes=False):\n        \"\"\"\n        Write the records out as JSON. The first JSON object saved contains\n        information about the DIAMOND algorithm.\n\n        @param fp: A C{str} file pointer to write to.\n        @param writeBytes: If C{True}, the JSON will be written out as bytes\n            (not strings). This is required when we are writing to a BZ2 file.\n        \"\"\"\n        if writeBytes:\n            fp.write(dumps(self.params, sort_keys=True).encode('UTF-8'))\n            fp.write(b'\\n')\n            for record in self.records():\n                fp.write(dumps(record, sort_keys=True).encode('UTF-8'))\n                fp.write(b'\\n')\n        else:\n            fp.write(six.u(dumps(self.params, sort_keys=True)))\n            fp.write(six.u('\\n'))\n            for record in self.records():\n                fp.write(six.u(dumps(record, sort_keys=True)))\n                fp.write(six.u('\\n'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a DIAMOND dictionary to a list of alignments.", "response": "def _dictToAlignments(self, diamondDict, read):\n        \"\"\"\n        Take a dict (made by DiamondTabularFormatReader.records)\n        and convert it to a list of alignments.\n\n        @param diamondDict: A C{dict}, from records().\n        @param read: A C{Read} instance, containing the read that DIAMOND used\n            to create this record.\n        @return: A C{list} of L{dark.alignment.Alignment} instances.\n        \"\"\"\n        alignments = []\n        getScore = itemgetter('bits' if self._hspClass is HSP else 'expect')\n\n        for diamondAlignment in diamondDict['alignments']:\n            alignment = Alignment(diamondAlignment['length'],\n                                  diamondAlignment['title'])\n            alignments.append(alignment)\n            for diamondHsp in diamondAlignment['hsps']:\n                score = getScore(diamondHsp)\n                normalized = normalizeHSP(diamondHsp, len(read),\n                                          self.diamondTask)\n                hsp = self._hspClass(\n                    score,\n                    readStart=normalized['readStart'],\n                    readEnd=normalized['readEnd'],\n                    readStartInSubject=normalized['readStartInSubject'],\n                    readEndInSubject=normalized['readEndInSubject'],\n                    readFrame=diamondHsp['frame'],\n                    subjectStart=normalized['subjectStart'],\n                    subjectEnd=normalized['subjectEnd'],\n                    readMatchedSequence=diamondHsp['query'],\n                    subjectMatchedSequence=diamondHsp['sbjct'],\n                    # Use blastHsp.get on identicalCount and positiveCount\n                    # because they were added in version 2.0.3 and will not\n                    # be present in any of our JSON output generated before\n                    # that. Those values will be None for those JSON files,\n                    # but that's much better than no longer being able to\n                    # read all that data.\n                    identicalCount=diamondHsp.get('identicalCount'),\n                    positiveCount=diamondHsp.get('positiveCount'))\n\n                alignment.addHsp(hsp)\n\n        return alignments"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef object_as_dict(obj):\n    return {c.key: getattr(obj, c.key)\n            for c in inspect(obj).mapper.column_attrs}", "response": "Turn an SQLAlchemy model into a dict of field names and values."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches the model by its ID.", "response": "def fetch_object(self, model_id):\n        \"\"\"Fetch the model by its ID.\"\"\"\n        pk_field_instance = getattr(self.object_class, self.pk_field)\n        qs = self.object_class.query.filter(pk_field_instance == model_id)\n        model = qs.one_or_none()\n        if not model:\n            raise ReferenceNotFoundError\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bytecount(rst, clk, rx_vld, rx_sop, rx_eop, rx_dat, rx_mty, count, MAX_BYTES=1500 ):\n\n    DATA_WIDTH    = len(rx_dat) \n\n    assert DATA_WIDTH%8==0, \"bytecount: expects len(rx_dat)=8*x, but len(rx_dat)={}\".format(DATA_WIDTH)\n\n    NUM_BYTES       = DATA_WIDTH // 8\n    MAX_BYTES_LG    = floor(log(MAX_BYTES,2))\n    MIN_COUNT_WIDTH = int(MAX_BYTES_LG) + 1\n\n    assert len(count)>=MIN_COUNT_WIDTH, \"bytecount: expects len(count)>={}, but len(count)={}\".format(MIN_COUNT_WIDTH, len(count))\n\n    count_s = Signal(intbv(0)[MIN_COUNT_WIDTH:])\n\n    @always_seq(clk.posedge, reset=rst)\n    def _count():\n        if (rx_vld):\n            x = NUM_BYTES\n            if (rx_eop==1):\n                x = x -rx_mty\n            if (rx_sop==1):\n                count_s.next = x\n            else:\n                count_s.next = count_s + x\n\n    @always_comb\n    def out_comb():\n        count.next = count_s\n\n    return instances()", "response": "Counts the number of bytes in a stream of packetised data structures."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the checksum of a single packet from the RST data.", "response": "def checksum(rst, clk, rx_vld, rx_sop, rx_eop, rx_dat, rx_mty, chksum, sum16=None, sumN=None, init_sum=None, MAX_BYTES=1500):\n    \"\"\" Calculates checksum on a stream of packetised data\n            rx_vld   - (i) valid data\n            rx_sop   - (i) start of packet\n            rx_eop   - (i) end of packet\n            rx_dat   - (i) data\n            rx_mty   - (i) empty bits when rx_eop\n            init_sum - (i) initial value for the sum (e.g. sum of the some fields from a packet header)\n            sumN     - (o) optional, plane sum\n            sum16    - (o) optional, 16 bit sum (every time the sum overflows, the overflow is added to the sum)\n            chksum   - (o) optional, checksum (~sum16)\n            MAX_BYTES - a limit: maximum number of bytes that may arrive in a single packet\n        Assumes Big-endian data.\n        The results are ready in the first clock cycle after rx_eop\n    \"\"\"\n\n    DATA_WIDTH = len(rx_dat) \n\n    assert DATA_WIDTH%16==0, \"checksum: expects len(rx_dat)=16*x, but len(tx_dat)={}\".format(DATA_WIDTH)\n\n    NUM_BYTES = DATA_WIDTH // 8\n    NUM_WORDS = DATA_WIDTH // 16\n\n    SUM_WIDTH    = 16 + int(ceil(log(MAX_BYTES/2,2))) + 1\n    SUM16_WIDTH  = 16 + int(ceil(log(NUM_WORDS,2))) + 1\n\n\n    if (init_sum != None):\n        assert len(init_sum)<=16, \"checksum: expects len(init_sum)<={}, but len(init_sum)={}\".format(16, len(init_sum))\n        SUM_WIDTH    += 1\n        SUM16_WIDTH  += 1\n    else:\n        init_sum = 0\n\n    FF_MASK = intbv(0)[DATA_WIDTH:].max-1\n    mdata = Signal(intbv(0)[DATA_WIDTH:])\n\n    @always_comb\n    def _mask_empty():\n        mdata.next = rx_dat\n        if rx_eop:\n            mdata.next = rx_dat & (FF_MASK<<(rx_mty*8))\n\n    # Slice masked data in 16 bit words\n    mdata16 = [Signal(intbv(0)[16:]) for _ in range(NUM_WORDS)]\n    _ass = [assign(mdata16[w], mdata((w+1)*16, w*16)) for w in range(NUM_WORDS)]\n\n    if sumN!=None:\n        assert len(sumN)>=SUM_WIDTH, \"checksum: expects len(sumN)>={}, but len(sumN)={}\".format(SUM_WIDTH, len(sumN))\n\n        sumN_reg = Signal(intbv(0)[SUM_WIDTH:])\n\n        @always_seq(clk.posedge, reset=rst)\n        def _accuN():\n            ''' Accumulate '''\n            if (rx_vld):\n                s = 0\n\n                if (rx_sop):\n                    s = int(init_sum)\n                else:\n                    s = int(sumN_reg)\n\n                for w in range(NUM_WORDS):\n                    s += mdata16[w]\n\n                sumN_reg.next = s\n\n        @always_comb\n        def _passN():\n            sumN.next = sumN_reg\n\n\n    if chksum!=None or sum16!=None:\n\n        sum16_reg = Signal(intbv(0)[SUM16_WIDTH:])\n\n        @always_seq(clk.posedge, reset=rst)\n        def _accu16():\n            ''' Accumulate 16 bit words'''\n            if (rx_vld):\n                s = 0\n\n                if (rx_sop):\n                    s = int(init_sum)\n                else:\n                    s = int(sum16_reg)\n\n                for w in range(NUM_WORDS):\n                    s += mdata16[w]\n\n                ss = intbv(s)[SUM16_WIDTH:]\n\n                sum16_reg.next = ss[:2*8] + ss[2*8:]\n\n        if sum16!=None:\n            assert len(sum16)>=16, \"checksum: expects len(sum16)>={}, but len(sum16)={}\".format(16, len(sum16))\n            @always_comb\n            def _pass16():\n                sum16.next = sum16_reg[16:]\n\n        if chksum!=None:\n            assert len(chksum)>=16, \"checksum: expects len(chksum)>={}, but len(chksum)={}\".format(16, len(chksum))\n            @always_comb\n            def _invert():\n                chksum.next = ~sum16_reg[16:] & 0xFFFF\n\n    return instances()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to obtain the argument parser.", "response": "def get_argument_parser():\n    \"\"\"Function to obtain the argument parser.\n\n    Returns\n    -------\n    A fully configured `argparse.ArgumentParser` object.\n\n    Notes\n    -----\n    This function is used by the `sphinx-argparse` extension for sphinx.\n\n    \"\"\"\n    file_mv = cli.file_mv\n\n    desc = 'Extracts gene-level expression data from StringTie output.'\n    parser = cli.get_argument_parser(desc)\n\n    parser.add_argument(\n        '-s', '--stringtie-file', type=str, required=True, metavar=file_mv,\n        help=\"\"\"Path of the StringTie output file .\"\"\"\n    )\n\n    parser.add_argument(\n        '-g', '--gene-file', type=str, required=True, metavar=file_mv,\n        help=\"\"\"File containing a list of protein-coding genes.\"\"\"\n    )\n\n    parser.add_argument(\n        '--no-novel-transcripts', action='store_true',\n        help=\"\"\"Ignore novel transcripts.\"\"\"\n    )\n\n    # parser.add_argument(\n    #     '--ambiguous-transcripts', default = 'ignore',\n    #      help='Strategy for counting expression of ambiguous novel '\n    #            'transcripts.'\n    # )\n    # possible strategies for ambiguous transcripts: 'ignore','highest','all'\n\n    parser.add_argument(\n        '-o', '--output-file', type=str, required=True, metavar=file_mv,\n        help=\"\"\"Path of output file.\"\"\"\n    )\n\n    cli.add_reporting_args(parser)\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(args=None):\n\n    if args is None:\n        # parse command-line arguments\n        parser = get_argument_parser()\n        args = parser.parse_args()\n\n    stringtie_file = args.stringtie_file\n    gene_file = args.gene_file\n    no_novel_transcripts = args.no_novel_transcripts\n    output_file = args.output_file\n\n    log_file = args.log_file\n    quiet = args.quiet\n    verbose = args.verbose\n\n    logger = misc.get_logger(log_file=log_file, quiet=quiet, verbose=verbose)\n\n    # read list of gene symbols\n    logger.info('Reading gene data...')\n    genes = misc.read_single(gene_file)\n\n    # read StringTie output file and summarize FPKM and TPM per gene\n    logger.info('Parsing StringTie output...')\n\n    logger.info('Associating StringTie gene IDs with gene symbols...')\n    stringtie_genes = {}\n    with open(stringtie_file) as fh:\n        reader = csv.reader(fh, dialect='excel-tab')\n        for l in reader:\n            if l[0][0] == '#':\n                continue\n            assert len(l) == 9\n            if l[2] != 'transcript':\n                continue\n            attr = parse_attributes(l[8])\n            try:\n                ref_gene = attr['ref_gene_name']\n            except KeyError:\n                continue\n            else:\n                # entry has a \"ref_gene_name\" attribute\n                try:\n                    g = stringtie_genes[attr['gene_id']]\n                except KeyError:\n                    stringtie_genes[attr['gene_id']] = {ref_gene, }\n                else:\n                    g.add(ref_gene)\n    logger.info('Associated %d gene IDs with gene symbols.',\n                len(stringtie_genes))\n    # C = Counter(len(v) for v in stringtie_genes.itervalues())\n    gene_ids_ambiguous = [k for k, v in stringtie_genes.items()\n                          if len(v) > 1]\n    n = len(gene_ids_ambiguous)\n    logger.info('%d / %d associated with multiple gene symbols (%.1f%%).',\n                n, len(stringtie_genes), 100*(n/float(len(stringtie_genes))))\n\n    # read StringTie output file and summarize FPKM and TPM per gene\n    n = len(genes)\n    fpkm = np.zeros(n, dtype=np.float64)\n    tpm = np.zeros(n, dtype=np.float64)\n    fpkm_novel_gene = 0\n    fpkm_unknown_gene_name = 0\n    fpkm_novel_trans = 0\n    fpkm_ambig = 0\n    with open(stringtie_file) as fh:\n        reader = csv.reader(fh, dialect='excel-tab')\n        for l in reader:\n            if l[0][0] == '#':\n                # skip header\n                continue\n            assert len(l) == 9\n\n            if l[2] != 'transcript':\n                # skip exon lines\n                continue\n\n            attr = parse_attributes(l[8])\n            f = float(attr['FPKM'])\n\n            try:\n                g = attr['ref_gene_name']\n            except KeyError:\n                if no_novel_transcripts:\n                    # ignore this transcript\n                    fpkm_novel_trans += f\n                    continue\n                else:\n                    # see if we can assign a gene name based on the gene ID\n                    try:\n                        assoc = stringtie_genes[attr['gene_id']]\n                    except KeyError:\n                        # gene_id not associated with any reference gene\n                        fpkm_novel_gene += f\n                        continue\n                    else:\n                        if len(assoc) > 1:\n                            # gene ID associated with multiple ref. genes\n                            # => ingored\n                            fpkm_ambig += f\n                            continue\n                        else:\n                            # gene ID associated with exactly one ref. gene\n                            g = list(assoc)[0]\n \n            try:\n                idx = misc.bisect_index(genes, g)\n            except ValueError:\n                fpkm_unknown_gene_name += f\n                logger.warning('Unknown gene name: \"%s\".', g)\n                continue\n\n            t = float(attr['TPM'])\n            fpkm[idx] += f\n            tpm[idx] += t\n\n    # ignored_fpkm = None\n    if no_novel_transcripts:\n        ignored_fpkm = fpkm_novel_trans + fpkm_unknown_gene_name\n    else:\n        ignored_fpkm = fpkm_novel_gene + fpkm_ambig + fpkm_unknown_gene_name\n    total_fpkm = np.sum(fpkm) + ignored_fpkm\n    logger.info('Ignored %.1f / %.1f FPKM (%.1f%%)', ignored_fpkm,\n                total_fpkm, 100*(ignored_fpkm/total_fpkm))\n\n    if no_novel_transcripts and fpkm_novel_trans > 0:\n        logger.info('Ignored %.1f FPKM from novel transcripts (%.1f%%).',\n                    fpkm_novel_trans, 100*(fpkm_novel_trans/total_fpkm))\n\n    else:\n        if fpkm_novel_gene > 0:\n            logger.info('Ignored %.1f FPKM from transcripts of novel genes '\n                        '(%.1f%%).',\n                        fpkm_novel_gene, 100*(fpkm_novel_gene/total_fpkm))\n\n        if fpkm_ambig > 0:\n            logger.info('Ignored %.1f FPKM from transcripts with ambiguous '\n                        'gene membership (%.1f%%).',\n                        fpkm_ambig, 100*(fpkm_ambig/total_fpkm))\n\n    if fpkm_unknown_gene_name > 0:\n        logger.info('Ignored %.1f FPKM from transcripts of genes with unknown '\n                    'names (%.1f%%).',\n                    fpkm_unknown_gene_name,\n                    100*(fpkm_unknown_gene_name/total_fpkm))\n\n    # write output file\n    E = np.c_[fpkm, tpm]\n    with open(output_file, 'w') as ofh:\n        writer = csv.writer(ofh, dialect='excel-tab',\n                            lineterminator=os.linesep,\n                            quoting=csv.QUOTE_NONE)\n        for i, g in enumerate(genes):\n            writer.writerow([g] + ['%.5f' % e for e in E[i, :]])\n\n    return 0", "response": "This function extracts gene - level expression data from the StringTie output file and outputs them as a list of gene - level expression data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to Tcl Server and Create IXE object.", "response": "def init_ixe(logger, host, port=4555, rsa_id=None):\n    \"\"\" Connect to Tcl Server and Create IxExplorer object.\n\n    :param logger: python logger object\n    :param host: host (IxTclServer) IP address\n    :param port: Tcl Server port\n    :param rsa_id: full path to RSA ID file for Linux based IxVM\n    :return: IXE object\n    \"\"\"\n\n    return IxeApp(logger, IxTclHalApi(TclClient(logger, host, port, rsa_id)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect(self, user=None):\n\n        self.api._tcl_handler.connect()\n        if user:\n            self.session.login(user)", "response": "Connect to host.\n\n        :param user: if user - login session."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, chassis):\n\n        self.chassis_chain[chassis] = IxeChassis(self.session, chassis, len(self.chassis_chain) + 1)\n        self.chassis_chain[chassis].connect()", "response": "add chassis.\n\n        :param chassis: chassis IP address."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reserve_ports(self, ports_locations, force=False, clear=True, phy_mode=IxePhyMode.ignore):\n\n        for port_location in ports_locations:\n            ip, card, port = port_location.split('/')\n            chassis = self.get_objects_with_attribute('chassis', 'ipAddress', ip)[0].id\n            uri = '{} {} {}'.format(chassis, card, port)\n            port = IxePort(parent=self, uri=uri)\n            port._data['name'] = port_location\n            port.reserve(force=force)\n            if clear:\n                port.clear()\n\n        return self.ports", "response": "Reserve ports and reset factory defaults."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting until all ports reach up state.", "response": "def wait_for_up(self, timeout=16, ports=None):\n        \"\"\" Wait until ports reach up state.\n\n        :param timeout: seconds to wait.\n        :param ports: list of ports to wait for.\n        :return:\n        \"\"\"\n        port_list = []\n        for port in ports:\n            port_list.append(self.set_ports_list(port))\n        t_end = time.time() + timeout\n        ports_not_in_up = []\n        ports_in_up = []\n        while time.time() < t_end:\n            # ixCheckLinkState can take few seconds on some ports when link is down.\n            for port in port_list:\n                call = self.api.call('ixCheckLinkState {}'.format(port))\n                if call == '0':\n                    ports_in_up.append(\"{}\".format(port))\n                else:\n                    pass\n            ports_in_up = list(set(ports_in_up))\n            if len(port_list) == len(ports_in_up):\n                return\n            time.sleep(1)\n        for port in port_list:\n            if port not in ports_in_up:\n                ports_not_in_up.append(port)\n        raise TgnError('{}'.format(ports_not_in_up))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear_all_stats(self, *ports):\n\n        port_list = self.set_ports_list(*ports)\n        self.api.call_rc('ixClearStats {}'.format(port_list))\n        self.api.call_rc('ixClearPacketGroups {}'.format(port_list))", "response": "Clear all statistic counters on list of ports."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting transmit on a list of ports.", "response": "def start_transmit(self, blocking=False, start_packet_groups=True, *ports):\n        \"\"\" Start transmit on ports.\n\n        :param blocking: True - wait for traffic end, False - return after traffic start.\n        :param start_packet_groups: True - clear time stamps and start collecting packet groups stats, False - don't.\n        :param ports: list of ports to start traffic on, if empty start on all ports.\n        \"\"\"\n\n        port_list = self.set_ports_list(*ports)\n        if start_packet_groups:\n            port_list_for_packet_groups = self.ports.values()\n            port_list_for_packet_groups = self.set_ports_list(*port_list_for_packet_groups)\n            self.api.call_rc('ixClearTimeStamp {}'.format(port_list_for_packet_groups))\n            self.api.call_rc('ixStartPacketGroups {}'.format(port_list_for_packet_groups))\n        self.api.call_rc('ixStartTransmit {}'.format(port_list))\n        time.sleep(0.2)\n\n        if blocking:\n            self.wait_transmit(*ports)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart packet groups on ports.", "response": "def start_packet_groups(self, clear_time_stamps=True, *ports):\n        \"\"\" Start packet groups on ports.\n\n        :param clear_time_stamps: True - clear time stamps, False - don't.\n        :param ports: list of ports to start traffic on, if empty start on all ports.\n        \"\"\"\n        port_list = self.set_ports_list(*ports)\n        if clear_time_stamps:\n            self.api.call_rc('ixClearTimeStamp {}'.format(port_list))\n        self.api.call_rc('ixStartPacketGroups {}'.format(port_list))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops traffic on the specified ports.", "response": "def stop_transmit(self, *ports):\n        \"\"\" Stop traffic on ports.\n\n        :param ports: list of ports to stop traffic on, if empty start on all ports.\n        \"\"\"\n\n        port_list = self.set_ports_list(*ports)\n        self.api.call_rc('ixStopTransmit {}'.format(port_list))\n        time.sleep(0.2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_transmit(self, *ports):\n\n        port_list = self.set_ports_list(*ports)\n        self.api.call_rc('ixCheckTransmitDone {}'.format(port_list))", "response": "Wait for traffic end on ports."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart capture on the specified ports.", "response": "def start_capture(self, *ports):\n        \"\"\" Start capture on ports.\n\n        :param ports: list of ports to start capture on, if empty start on all ports.\n        \"\"\"\n\n        IxeCapture.current_object = None\n        IxeCaptureBuffer.current_object = None\n        if not ports:\n            ports = self.ports.values()\n        for port in ports:\n            port.captureBuffer = None\n        port_list = self.set_ports_list(*ports)\n        self.api.call_rc('ixStartCapture {}'.format(port_list))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping capture on ports.", "response": "def stop_capture(self, cap_file_name=None, cap_file_format=IxeCapFileFormat.mem, *ports):\n        \"\"\" Stop capture on ports.\n\n        :param cap_file_name: prefix for the capture file name.\n            Capture files for each port are saved as individual pcap file named 'prefix' + 'URI'.pcap.\n        :param cap_file_format: exported file format\n        :param ports: list of ports to stop traffic on, if empty stop all ports.\n        :return: dictionary (port, nPackets)\n        \"\"\"\n\n        port_list = self.set_ports_list(*ports)\n        self.api.call_rc('ixStopCapture {}'.format(port_list))\n\n        nPackets = {}\n        for port in (ports if ports else self.ports.values()):\n            nPackets[port] = port.capture.nPackets\n            if nPackets[port]:\n                if cap_file_format is not IxeCapFileFormat.mem:\n                    port.cap_file_name = cap_file_name + '-' + port.uri.replace(' ', '_') + '.' + cap_file_format.name\n                    port.captureBuffer.export(port.cap_file_name)\n        return nPackets"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the capture files names for the given ports.", "response": "def get_cap_files(self, *ports):\n        \"\"\"\n        :param ports: list of ports to get capture files names for.\n        :return: dictionary (port, capture file)\n        \"\"\"\n        cap_files = {}\n        for port in ports:\n            if port.cap_file_name:\n                with open(port.cap_file_name) as f:\n                    cap_files[port] = f.read().splitlines()\n            else:\n                cap_files[port] = None\n        return cap_files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the ports and streams for stream statistics.", "response": "def set_stream_stats(self, rx_ports=None, tx_ports=None, start_offset=40,\n                         sequence_checking=True, data_integrity=True, timestamp=True):\n        \"\"\" Set TX ports and RX streams for stream statistics.\n\n        :param ports: list of ports to set RX pgs. If empty set for all ports.\n        :type ports: list[ixexplorer.ixe_port.IxePort]\n        :param tx_ports: list of streams to set TX pgs. If empty set for all streams.\n        :type tx_ports:  dict[ixexplorer.ixe_port.IxePort, list[ixexplorer.ixe_stream.IxeStream]]\n        :param sequence_checking: True - enable sequence checkbox, False - disable\n        :param data_integrity: True - enable data integrity checkbox, False - disable\n        :param timestamp: True - enable timestamp checkbox, False - disable\n        :param start_offset: start offset for signatures (group ID, signature, sequence)\n        \"\"\"\n\n        if not rx_ports:\n            rx_ports = self.ports.values()\n\n        if not tx_ports:\n            tx_ports = {}\n            for port in self.ports.values():\n                tx_ports[port] = port.streams.values()\n\n        groupIdOffset = start_offset\n        signatureOffset = start_offset + 4\n        next_offset = start_offset + 8\n        if sequence_checking:\n            sequenceNumberOffset = next_offset\n            next_offset += 4\n        if data_integrity:\n            di_signatureOffset = next_offset\n\n        for port in rx_ports:\n            modes = []\n            modes.append(IxeReceiveMode.widePacketGroup)\n            port.packetGroup.groupIdOffset = groupIdOffset\n            port.packetGroup.signatureOffset = signatureOffset\n            if sequence_checking and int(port.isValidFeature('portFeatureRxSequenceChecking')):\n                modes.append(IxeReceiveMode.sequenceChecking)\n                port.packetGroup.sequenceNumberOffset = sequenceNumberOffset\n            if data_integrity and int(port.isValidFeature('portFeatureRxDataIntegrity')):\n                modes.append(IxeReceiveMode.dataIntegrity)\n                port.dataIntegrity.signatureOffset = di_signatureOffset\n            if timestamp and int(port.isValidFeature('portFeatureRxFirstTimeStamp')):\n                port.dataIntegrity.enableTimeStamp = True\n            else:\n                port.dataIntegrity.enableTimeStamp = False\n            port.set_receive_modes(*modes)\n\n            port.write()\n\n        for port, streams in tx_ports.items():\n            for stream in streams:\n                stream.packetGroup.insertSignature = True\n                stream.packetGroup.groupIdOffset = groupIdOffset\n                stream.packetGroup.signatureOffset = signatureOffset\n                if sequence_checking:\n                    stream.packetGroup.insertSequenceSignature = True\n                    stream.packetGroup.sequenceNumberOffset = sequenceNumberOffset\n                if data_integrity and int(port.isValidFeature('portFeatureRxDataIntegrity')):\n                    stream.dataIntegrity.insertSignature = True\n                    stream.dataIntegrity.signatureOffset = di_signatureOffset\n                if timestamp:\n                    stream.enableTimestamp = True\n                else:\n                    stream.enableTimestamp = False\n\n            port.write()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset PRBS for ports and streams for stream statistics.", "response": "def set_prbs(self, rx_ports=None, tx_ports=None):\n        \"\"\" Set TX ports and RX streams for stream statistics.\n\n        :param ports: list of ports to set RX PRBS. If empty set for all ports.\n        :type ports: list[ixexplorer.ixe_port.IxePort]\n        :param tx_ports: list of streams to set TX PRBS. If empty set for all streams.\n        :type tx_ports:  dict[ixexplorer.ixe_port.IxePort, list[ixexplorer.ixe_stream.IxeStream]]\n        \"\"\"\n\n        if not rx_ports:\n            rx_ports = self.ports.values()\n\n        if not tx_ports:\n            tx_ports = {}\n            for port in self.ports.values():\n                tx_ports[port] = port.streams.values()\n\n        for port in rx_ports:\n            port.set_receive_modes(IxeReceiveMode.widePacketGroup, IxeReceiveMode.sequenceChecking,\n                                   IxeReceiveMode.prbs)\n            port.enableAutoDetectInstrumentation = True\n            port.autoDetectInstrumentation.ix_set_default()\n            port.write()\n\n        for port, streams in tx_ports.items():\n            for stream in streams:\n                stream.autoDetectInstrumentation.enableTxAutomaticInstrumentation = True\n                stream.autoDetectInstrumentation.enablePRBS = True\n            port.write()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chr22XY(c):\n    c = str(c)\n    if c[0:3] == 'chr':\n        c = c[3:]\n    if c == '23':\n        c = 'X'\n    if c == '24':\n        c = 'Y'\n    return 'chr' + c", "response": "force to name from 1.. 22 X Y M \n    to in chr1.. chr22 X Y M \n    to in chr1.. chr22 Y M \n    str or ints accepted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninfer the single namespace of the given accession", "response": "def infer_namespace(ac):\n    \"\"\"Infer the single namespace of the given accession\n\n    This function is convenience wrapper around infer_namespaces().\n    Returns:\n      * None if no namespaces are inferred\n      * The (single) namespace if only one namespace is inferred\n      * Raises an exception if more than one namespace is inferred\n\n    >>> infer_namespace(\"ENST00000530893.6\")\n    'ensembl'\n\n    >>> infer_namespace(\"NM_01234.5\")\n    'refseq'\n\n    >>> infer_namespace(\"A2BC19\")\n    'uniprot'\n\n    N.B. The following test is disabled because Python 2 and Python 3\n    handle doctest exceptions differently. :-(\n    X>>> infer_namespace(\"P12345\")\n    Traceback (most recent call last):\n    ...\n    bioutils.exceptions.BioutilsError: Multiple namespaces possible for P12345\n\n    >>> infer_namespace(\"BOGUS99\") is None\n    True\n\n    \"\"\"\n\n    namespaces = infer_namespaces(ac)\n    if not namespaces:\n        return None\n    if len(namespaces) > 1:\n        raise BioutilsError(\"Multiple namespaces possible for {}\".format(ac))\n    return namespaces[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef infer_namespaces(ac):\n    return [v for k, v in ac_namespace_regexps.items() if k.match(ac)]", "response": "infer possible namespaces of given accession based on syntax\n    Always returns a list possibly empty\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add(self, other):\n        if len([interval for interval in self if other in interval]) > 0:  # if other is already represented\n            return\n        # remove any intervals which are fully represented by the interval we are adding\n        to_remove = [interval for interval in self if interval in other]\n        self._data.difference_update(to_remove)\n        self._data.add(other)", "response": "Add an interval to the underlying IntervalSet data store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new IntervalSet which represents the intersection of each of the intervals in this IntervalSet with each of the intervals in other.", "response": "def intersection(self, other):\n        \"\"\"Returns a new IntervalSet which represents the intersection of each of the intervals in this IntervalSet\n        with each of the intervals in the other IntervalSet.\n        :param other: An IntervalSet to intersect with this one.\n        \"\"\"\n        # if self or other is empty the intersection will be empty\n        result = IntervalSet()\n        for other_inter in other:\n            for interval in self:\n                this_intervals_intersection = other_inter.intersect(interval)\n                if this_intervals_intersection is not None:\n                    result._add(this_intervals_intersection)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef union(self, other):\n        result = IntervalSet()\n        for el in self:\n            result.add(el)\n        for el in other:\n            result.add(el)\n        return result", "response": "Returns a new IntervalSet which represents the union of each of the intervals in this set with each of the intervals in the other set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, other):\n        if other.empty():\n            return\n\n        to_add = set()\n        for inter in self:\n            if inter.overlaps(other):  # if it overlaps with this interval then the union will be a single interval\n                to_add.add(inter.union(other))\n        if len(to_add) == 0:  # other must not overlap with any interval in self (self could be empty!)\n            to_add.add(other)\n        # Now add the intervals found to self\n        if len(to_add) > 1:\n            set_to_add = IntervalSet(to_add)  # creating an interval set unions any overlapping intervals\n            for el in set_to_add:\n                self._add(el)\n        elif len(to_add) == 1:\n            self._add(to_add.pop())", "response": "Add an Interval to the IntervalSet by taking the union of the existing Interval objects in self."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef difference(self, other):\n        intervals = other if isinstance(other, IntervalSet) else IntervalSet((other,))\n        result = IntervalSet()\n        for left in self:\n            for right in intervals:\n                left = left - right\n            if isinstance(left, IntervalSet):\n                for interval in left:\n                    result.add(interval)\n            else:\n                result.add(left)\n        return result", "response": "Subtract an Interval or IntervalSet from the intervals in the set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a notification. Blocks as long as necessary.", "response": "def send_notification(self, subject=\"\", message=\"\", sender=\"\", source=None, actions=None):\n        \"\"\"\n        Sends a notification. Blocks as long as necessary.\n\n        :param subject: The subject.\n        :type subject: str\n        :param message: The message.\n        :type message: str\n        :param sender: The sender.\n        :type sender: str\n        :param source: The source of the notification\n        :type source: .LegacyNotification.Source\n        :param actions Actions to be sent with a notification (list of TimelineAction objects)\n        :type actions list\n        \"\"\"\n        if self._pebble.firmware_version.major < 3:\n            self._send_legacy_notification(subject, message, sender, source)\n        else:\n            self._send_modern_notification(subject, message, sender, source, actions)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning random bytes format.", "response": "def randomBinaryField(self):\n        \"\"\"\n        Return random bytes format.\n        \"\"\"\n        lst = [\n            b\"hello world\",\n            b\"this is bytes\",\n            b\"awesome django\",\n            b\"djipsum is awesome\",\n            b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\",\n            b\"\\x0b\\x0c\\x0e\\x0f\"\n        ]\n        return self.randomize(lst)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef randomCharField(self, model_class, field_name):\n        try:\n            available_choices = model_class._meta.get_field(field_name).get_choices()[1:]\n            return self.randomize([ci[0] for ci in available_choices])\n\n        except AttributeError:\n            lst = [\n                \"Enthusiastically whiteboard synergistic methods\",\n                \"Authoritatively scale progressive meta-services through\",\n                \"Objectively implement client-centered supply chains via stand-alone\",\n                \"Phosfluorescently productize accurate products after cooperative results\",\n                \"Appropriately drive cutting-edge systems before optimal scenarios\",\n                \"Uniquely productize viral ROI for competitive e-markets\"\n                \"Uniquely repurpose high-quality models vis-a-vis\",\n                \"Django is Fucking Awesome? Yes\"\n            ]\n            return self.randomize(lst)", "response": "Returns a random value from the available choices for the given field_name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating if the field has a max_digits and decimal_places and generate a unique decimal number.", "response": "def randomDecimalField(self, model_class, field_name):\n        \"\"\"\n        Validate if the field has a `max_digits` and `decimal_places`\n        And generating the unique decimal number.\n        \"\"\"\n        decimal_field = model_class._meta.get_field(field_name)\n        max_digits = None\n        decimal_places = None\n\n        if decimal_field.max_digits is not None:\n            max_digits = decimal_field.max_digits\n        if decimal_field.decimal_places is not None:\n            decimal_places = decimal_field.decimal_places\n\n        digits = random.choice(range(100))\n        if max_digits is not None:\n            start = 0\n            if max_digits < start:\n                start = max_digits - max_digits\n            digits = int(\n                \"\".join([\n                    str(x) for x in random.sample(\n                        range(start, max_digits),\n                        max_digits - 1\n                    )\n                ])\n            )\n        places = random.choice(range(10, 99))\n        if decimal_places is not None:\n            places = str(\n                random.choice(range(9999 * 99999))\n            )[:decimal_places]\n\n        return float(\n            str(digits)[:decimal_places] + \".\" + str(places)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef randomSlugField(self):\n        lst = [\n            \"sample-slug-{}\".format(uuid.uuid4().hex),\n            \"awesome-djipsum-{}\".format(uuid.uuid4().hex),\n            \"unique-slug-{}\".format(uuid.uuid4().hex)\n        ]\n        return self.randomize(lst)", "response": "Return the unique slug by generating the uuid4\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef randomUUIDField(self):\n        uuid1 = uuid.uuid1().hex\n        uuid3 = uuid.uuid3(\n            uuid.NAMESPACE_URL,\n            self.randomize(['python', 'django', 'awesome'])\n        ).hex\n        uuid4 = uuid.uuid4().hex\n        uuid5 = uuid.uuid5(\n            uuid.NAMESPACE_DNS,\n            self.randomize(['python', 'django', 'awesome'])\n        ).hex\n        return self.randomize([uuid1, uuid3, uuid4, uuid5])", "response": "Return the unique uuid from uuid1 uuid3 uuid4 or uuid5."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the related random object to set as ForeignKey.", "response": "def getOrCreateForeignKey(self, model_class, field_name):\n        \"\"\"\n        Return related random object to set as ForeignKey.\n        \"\"\"\n        # Getting related object type\n        # Eg: <django.db.models.fields.related.ForeignKey: test_ForeignKey>\n        instance = getattr(model_class, field_name).field\n\n        # Getting the model name by instance to find/create first id/pk.\n        # Eg: <class 'django.contrib.auth.models.User'>\n        related_model = instance.related_model().__class__\n\n        # Trying to get random id from queryset.\n        objects = related_model.objects.all()\n        if objects.exists():\n            return self.randomize(objects)\n\n        # Returning first object from tuple `(<User: user_name>, False)`\n        return related_model.objects.get_or_create(pk=1)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates validated fields for the model.", "response": "def create_validated_fields(self):\n        \"\"\"\n        To generate lorem ipsum by validated fields for the model.\n        \"\"\"\n        model_class = self.model_class\n        fields = self.fields\n        maximum = self.maximum\n        objects = []\n\n        for n in range(maximum):\n            data_dict = {}\n            for field in fields:\n\n                def default_assign(func):\n                    data_dict[field['field_name']] = func\n\n                def string_assign(func):\n                    data_dict[field['field_name']] = str(func)\n\n                if field['field_type'] == 'BigIntegerField':  # values from -9223372036854775808 to 9223372036854775807\n                    default_assign(random.randint(-9223372036854775808, 9223372036854775807))\n                elif field['field_type'] == 'BinaryField':  # b'', self.randomBinaryField()\n                    default_assign(self.randomBinaryField())\n                elif field['field_type'] == 'BooleanField':  # True/False\n                    default_assign(self.randomize([True, False]))\n                elif field['field_type'] == 'CharField':  # self.randomCharField()\n                    string_assign(self.randomCharField(model_class, field['field_name']))\n                elif field['field_type'] == 'CommaSeparatedIntegerField':  # self.randomCommaSeparatedIntegerField()\n                    string_assign(self.randomCommaSeparatedIntegerField())\n                elif field['field_type'] == 'DateField':  # '2016-10-11'\n                    string_assign(str(datetime.datetime.now().date()))\n                elif field['field_type'] == 'DateTimeField':  # '2016-10-11 00:44:08.864285'\n                    string_assign(str(datetime.datetime.now()))\n                elif field['field_type'] == 'DecimalField':  # self.randomDecimalField()\n                    default_assign(self.randomDecimalField(model_class, field['field_name']))\n                elif field['field_type'] == 'DurationField':  # such as 1 day, 4 days or else.\n                    default_assign(datetime.timedelta(days=random.randint(1, 10)))\n                elif field['field_type'] == 'EmailField':  # self.randomEmailField()\n                    string_assign(self.randomEmailField())\n                elif field['field_type'] == 'FileField':  # self.randomFileField()\n                    string_assign(self.randomFileField())\n                elif field['field_type'] == 'FloatField':  # 1.92, 0.0, 5.0, or else.\n                    default_assign(float((\"%.2f\" % float(random.randint(0, 100) / 13))))\n                elif field['field_type'] == 'ImageField':  # self.randomImageField()\n                    string_assign(self.randomImageField())\n                elif field['field_type'] == 'IntegerField':  # values from -2147483648 to 2147483647\n                    default_assign(random.randint(-2147483648, 2147483647))\n                elif field['field_type'] == 'GenericIPAddressField':  # self.randomGenericIPAddressField()\n                    string_assign(self.randomGenericIPAddressField())\n                elif field['field_type'] == 'NullBooleanField':  # by Default is None/null\n                    default_assign(self.randomize([None, True, False]))\n                elif field['field_type'] == 'PositiveIntegerField':  # values from 0 to 2147483647\n                    default_assign(random.randint(0, 2147483647))\n                elif field['field_type'] == 'PositiveSmallIntegerField':  # values from 0 to 32767\n                    default_assign(random.randint(0, 32767))\n                elif field['field_type'] == 'SlugField':  # self.randomSlugField()\n                    string_assign(self.randomSlugField())\n                elif field['field_type'] == 'SmallIntegerField':  # values from -32768 to 32767\n                    default_assign(random.randint(-32768, 32767))\n                elif field['field_type'] == 'TextField':  # self.randomTextField()\n                    string_assign(self.randomTextField())\n                elif field['field_type'] == 'TimeField':  # accepts the same as DateField\n                    string_assign(str(datetime.datetime.now().date()))\n                elif field['field_type'] == 'URLField':  # self.randomURLField()\n                    string_assign(self.randomURLField())\n                elif field['field_type'] == 'UUIDField':  # self.randomUUIDField()\n                    string_assign(self.randomUUIDField())\n                elif field['field_type'] == 'ForeignKey':  # self.getOrCreateForeignKey()\n                    default_assign(self.getOrCreateForeignKey(model_class, field['field_name']))\n                # elif field['field_type'] == 'OneToOneField':  # pk/id -> not fixed yet.\n                #    default_assign(self.randomize([1, ]))\n                # Unsolved: need specific pk/id\n\n            obj = model_class.objects.create(**data_dict)\n\n            # Because the Relationship Model need specific id from the object,\n            # so, i handle it after created the object.\n            for field in fields:\n                if field['field_type'] == 'ManyToManyField':\n                    # Find the instance model field from `obj` already created before.\n                    instance_m2m = getattr(obj, field['field_name'])\n                    objects_m2m = instance_m2m.model.objects.all()\n\n                    # Djipsum only create the `ManyToManyField` if the related object is exists.\n                    if objects_m2m.exists():\n                        ids_m2m = [i.pk for i in objects_m2m]\n                        random_decission = random.sample(\n                            range(min(ids_m2m), max(ids_m2m)), max(ids_m2m) - 1\n                        )\n                        # Let me know if the `random_decission` has minimum objects to be choice.\n                        if len(random_decission) <= 2:\n                            random_decission = [self.randomize(ids_m2m)]\n                        related_objects = [\n                            rel_obj for rel_obj in objects_m2m\n                            if rel_obj.pk in random_decission\n                        ]\n                        # adding the `ManyToManyField`\n                        instance_m2m.add(*related_objects)\n            try:\n                obj.save_m2m()\n            except:\n                obj.save()\n            objects.append(obj)\n        return objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the contents of a flash region from the watch.", "response": "def get_flash_region(self, offset, length):\n        \"\"\"\n        Retrieves the contents of a region of flash from the watch. This only works on watches running\n        non-release firmware.\n        Raises :exc:`.GetBytesError` on failure.\n\n        :return: The retrieved data\n        :rtype: bytes\n        \"\"\"\n        return self._get(GetBytesFlashRequest(offset=offset, length=length))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a screenshot. Blocks until completion or raises a : exc :. ScreenshotError on failure.", "response": "def grab_image(self):\n        \"\"\"\n        Takes a screenshot. Blocks until completion, or raises a :exc:`.ScreenshotError` on failure.\n\n        While this method is executing, \"progress\" events will periodically be emitted with the following signature: ::\n\n           (downloaded_so_far, total_size)\n\n        :return: A list of bytearrays in RGB8 format, where each bytearray is one row of the image.\n        \"\"\"\n        # We have to open this queue before we make the request, to ensure we don't miss the response.\n        queue = self._pebble.get_endpoint_queue(ScreenshotResponse)\n        self._pebble.send_packet(ScreenshotRequest())\n        return self._read_screenshot(queue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trade_day(dt, cal='US'):\n    from xone import calendar\n\n    dt = pd.Timestamp(dt).date()\n    return calendar.trading_dates(start=dt - pd.Timedelta('10D'), end=dt, calendar=cal)[-1]", "response": "Returns the latest trading day w. r. t given dt\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cur_time(typ='date', tz=DEFAULT_TZ, trading=True, cal='US'):\n    dt = pd.Timestamp('now', tz=tz)\n\n    if typ == 'date':\n        if trading: return trade_day(dt=dt, cal=cal).strftime('%Y-%m-%d')\n        else: return dt.strftime('%Y-%m-%d')\n\n    if typ == 'time': return dt.strftime('%Y-%m-%d %H:%M:%S')\n    if typ == 'time_path': return dt.strftime('%Y-%m-%d/%H-%M-%S')\n    if typ == 'raw': return dt\n\n    return trade_day(dt).date() if trading else dt.date()", "response": "Current time is a naive version of time"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef align_data(*args):\n    res = pd.DataFrame(pd.concat([\n        d.loc[~d.index.duplicated(keep='first')].rename(\n            columns=lambda vv: '%s_%d' % (vv, i + 1)\n        ) for i, d in enumerate(args)\n    ], axis=1))\n    data_cols = [col for col in res.columns if col[-2:] == '_1']\n    other_cols = [col for col in res.columns if col[-2:] != '_1']\n    res.loc[:, other_cols] = res.loc[:, other_cols].fillna(method='pad')\n    return res.dropna(subset=data_cols)", "response": "Resample and aligh data for the frequency tree of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconcatenating data with ticker as sub column index", "response": "def cat_data(data_kw):\n    \"\"\"\n    Concatenate data with ticker as sub column index\n\n    Args:\n        data_kw: key = ticker, value = pd.DataFrame\n\n    Returns:\n        pd.DataFrame\n\n    Examples:\n        >>> start = '2018-09-10T10:10:00'\n        >>> tz = 'Australia/Sydney'\n        >>> idx = pd.date_range(start=start, periods=6, freq='min').tz_localize(tz)\n        >>> close_1 = [31.08, 31.10, 31.11, 31.07, 31.04, 31.04]\n        >>> vol_1 = [10166, 69981, 14343, 10096, 11506, 9718]\n        >>> d1 = pd.DataFrame(dict(price=close_1, volume=vol_1), index=idx)\n        >>> close_2 = [70.81, 70.78, 70.85, 70.79, 70.79, 70.79]\n        >>> vol_2 = [4749, 6762, 4908, 2002, 9170, 9791]\n        >>> d2 = pd.DataFrame(dict(price=close_2, volume=vol_2), index=idx)\n        >>> sample = cat_data({'BHP AU': d1, 'RIO AU': d2})\n        >>> sample.columns\n        MultiIndex(levels=[['BHP AU', 'RIO AU'], ['price', 'volume']],\n                   codes=[[0, 0, 1, 1], [0, 1, 0, 1]],\n                   names=['ticker', None])\n        >>> r = sample.transpose().iloc[:, :2]\n        >>> r.index.names = (None, None)\n        >>> r\n                       2018-09-10 10:10:00+10:00  2018-09-10 10:11:00+10:00\n        BHP AU price                       31.08                      31.10\n               volume                  10,166.00                  69,981.00\n        RIO AU price                       70.81                      70.78\n               volume                   4,749.00                   6,762.00\n    \"\"\"\n    if len(data_kw) == 0: return pd.DataFrame()\n    return pd.DataFrame(pd.concat([\n        data.assign(ticker=ticker).set_index('ticker', append=True)\n            .unstack('ticker').swaplevel(0, 1, axis=1)\n        for ticker, data in data_kw.items()\n    ], axis=1))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_frame(data_list, exc_cols=None, **kwargs):\n    from collections import OrderedDict\n\n    return pd.DataFrame(\n        pd.Series(data_list).apply(OrderedDict).tolist(), **kwargs\n    ).drop(columns=[] if exc_cols is None else exc_cols)", "response": "Convert a list of dicts into a Pandas DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfitting spline curve for given x y values.", "response": "def spline_curve(x, y, step, val_min=0, val_max=None, kind='quadratic', **kwargs):\n    \"\"\"\n    Fit spline curve for given x, y values\n\n    Args:\n        x: x-values\n        y: y-values\n        step: step size for interpolation\n        val_min: minimum value of result\n        val_max: maximum value of result\n        kind: for scipy.interpolate.interp1d\n        Specifies the kind of interpolation as a string (\u2018linear\u2019, \u2018nearest\u2019, \u2018zero\u2019, \u2018slinear\u2019,\n        \u2018quadratic\u2019, \u2018cubic\u2019, \u2018previous\u2019, \u2018next\u2019, where \u2018zero\u2019, \u2018slinear\u2019, \u2018quadratic\u2019 and \u2018cubic\u2019\n        refer to a spline interpolation of zeroth, first, second or third order; \u2018previous\u2019 and\n        \u2018next\u2019 simply return the previous or next value of the point) or as an integer specifying\n        the order of the spline interpolator to use. Default is \u2018linear\u2019.\n        **kwargs: additional parameters for interp1d\n\n    Returns:\n        pd.Series: fitted curve\n\n    Examples:\n        >>> x = pd.Series([1, 2, 3])\n        >>> y = pd.Series([np.exp(1), np.exp(2), np.exp(3)])\n        >>> r = spline_curve(x=x, y=y, step=.5, val_min=3, val_max=18, fill_value='extrapolate')\n        >>> r.round(2).index.tolist()\n        [1.0, 1.5, 2.0, 2.5, 3.0]\n        >>> r.round(2).tolist()\n        [3.0, 4.05, 7.39, 12.73, 18.0]\n        >>> y_df = pd.DataFrame(dict(a=[np.exp(1), np.exp(2), np.exp(3)], b=[2, 3, 4]))\n        >>> r_df = spline_curve(x=x, y=y_df, step=.5, val_min=3, fill_value='extrapolate')\n        >>> r_df.round(2)\n                 a    b\n        1.00  3.00 3.00\n        1.50  4.05 3.00\n        2.00  7.39 3.00\n        2.50 12.73 3.50\n        3.00 20.09 4.00\n    \"\"\"\n    from scipy.interpolate import interp1d\n    from collections import OrderedDict\n\n    if isinstance(y, pd.DataFrame):\n        return pd.DataFrame(OrderedDict([(col, spline_curve(\n            x, y.loc[:, col], step=step, val_min=val_min, val_max=val_max, kind=kind\n        )) for col in y.columns]))\n    fitted_curve = interp1d(x, y, kind=kind, **kwargs)\n    new_x = np.arange(x.min(), x.max() + step / 2., step=step)\n    return pd.Series(\n        new_x, index=new_x, name=y.name if hasattr(y, 'name') else None\n    ).apply(fitted_curve).clip(val_min, val_max)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_float(digit=0, is_pct=False):\n    if is_pct:\n        space = ' ' if digit < 0 else ''\n        fmt = f'{{:{space}.{abs(int(digit))}%}}'\n        return lambda vv: 'NaN' if np.isnan(vv) else fmt.format(vv)\n\n    else:\n        return lambda vv: 'NaN' if np.isnan(vv) else (\n            f'{{:,.{digit}f}}'.format(vv) if vv else '-' + ' ' * abs(digit)\n        )", "response": "Function to format float values for pandas\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inst_repr(instance, fmt='str', public_only=True):\n    if not hasattr(instance, '__dict__'): return ''\n\n    if public_only: inst_dict = {k: v for k, v in instance.__dict__.items() if k[0] != '_'}\n    else: inst_dict = instance.__dict__\n\n    if fmt == 'json': return json.dumps(inst_dict, indent=2)\n    elif fmt == 'str': return to_str(inst_dict, public_only=public_only)\n\n    return ''", "response": "Generate class instance signature from its __dict__"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconcatenate conditions with operator and wrap it by ().", "response": "def concat_expr(operator, conditions):\n    \"\"\"\n    Concatenate `conditions` with `operator` and wrap it by ().\n\n    It returns a string in a list or empty list, if `conditions` is empty.\n\n    \"\"\"\n    expr = \" {0} \".format(operator).join(conditions)\n    return [\"({0})\".format(expr)] if expr else []"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\njoins the table with the source table.", "response": "def join(self, source, op='LEFT JOIN', on=''):\n        \"\"\"\n        Join `source`.\n\n        >>> sc = SQLConstructor('main', ['c1', 'c2'])\n        >>> sc.join('sub', 'JOIN', 'main.id = sub.id')\n        >>> (sql, params, keys) = sc.compile()\n        >>> sql\n        'SELECT c1, c2 FROM main JOIN sub ON main.id = sub.id'\n\n        It is possible to pass another `SQLConstructor` as a source.\n\n        >>> sc = SQLConstructor('main', ['c1', 'c2'])\n        >>> sc.add_or_matches('{0} = {1}', 'c1', [111])\n        >>> subsc = SQLConstructor('sub', ['d1', 'd2'])\n        >>> subsc.add_or_matches('{0} = {1}', 'd1', ['abc'])\n        >>> sc.join(subsc, 'JOIN', 'main.id = sub.id')\n        >>> sc.add_column('d1')\n        >>> (sql, params, keys) = sc.compile()\n        >>> print(sql)                     # doctest: +NORMALIZE_WHITESPACE\n        SELECT c1, c2, d1 FROM main\n        JOIN ( SELECT d1, d2 FROM sub WHERE (d1 = ?) )\n        ON main.id = sub.id\n        WHERE (c1 = ?)\n\n        `params` is set appropriately to include parameters for joined\n        source:\n\n        >>> params\n        ['abc', 111]\n\n        Note that `subsc.compile` is called when `sc.join(subsc, ...)`\n        is called.  Therefore, calling `subsc.add_<predicate>` does not\n        effect `sc`.\n\n        :type source: str or SQLConstructor\n        :arg  source: table\n        :type     op: str\n        :arg      op: operation (e.g., 'JOIN')\n        :type     on: str\n        :arg      on: on clause.  `source` (\"right\" source) can be\n                      referred using `{r}` formatting field.\n\n        \"\"\"\n        if isinstance(source, SQLConstructor):\n            (sql, params, _) = source.compile()\n            self.join_params.extend(params)\n            jsrc = '( {0} )'.format(sql)\n            if source.table_alias:\n                jsrc += ' AS ' + source.table_alias\n                on = on.format(r=source.table_alias)\n        else:\n            jsrc = source\n            on = on.format(r=source)\n        constraint = 'ON {0}'.format(on) if on else ''\n        self.join_source = ' '.join([self.join_source, op, jsrc, constraint])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncompiling SQL and return 3 - tuple of records.", "response": "def compile(self):\n        \"\"\"\n        Compile SQL and return 3-tuple ``(sql, params, keys)``.\n\n        Example usage::\n\n            (sql, params, keys) = sc.compile()\n            for row in cursor.execute(sql, params):\n                record = dict(zip(keys, row))\n\n        \"\"\"\n        params = self.column_params + self.join_params + self.params\n        if self.limit and self.limit >= 0:\n            self.sql_limit = 'LIMIT ?'\n            params += [self.limit]\n        return (self.sql, params, self.keys)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_and_matches(self, matcher, lhs, params, numq=1, flatten=None):\n        params = self._adapt_params(params)\n        qs = ['?'] * numq\n        flatten = flatten or self._default_flatten(numq)\n        expr = repeat(adapt_matcher(matcher)(lhs, *qs), len(params))\n        self.conditions.extend(expr)\n        self.params.extend(flatten(params))", "response": "Add AND conditions to match to params."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngroups by column and run aggregate function on chooser column.", "response": "def uniquify_by(self, column, chooser=None, aggregate='MAX'):\n        \"\"\"\n        Group by `column` and run `aggregate` function on `chooser` column.\n        \"\"\"\n        self.group_by.append(column)\n        if chooser:\n            i = self.columns.index(chooser)\n            self.columns[i] = '{0}({1})'.format(aggregate, self.columns[i])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_where_clause_to_column(self, column='condition', key=None):\n        if self.conditions:\n            expr = \" AND \".join(self.conditions)\n            params = self.params\n            self.params = []\n            self.conditions = []\n        else:\n            expr = '1'\n            params = []\n        self.add_column('({0}) AS {1}'.format(expr, column),\n                        key or column,\n                        params)", "response": "Move whole WHERE clause to a column named column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving upper and right axis", "response": "def remove_axis_junk(ax, which=['right', 'top']):\n    '''remove upper and right axis'''\n    for loc, spine in ax.spines.items():\n        if loc in which:\n            spine.set_color('none')            \n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the signal contributions of the object with the given frequency.", "response": "def plot_signal_sum(ax, z, fname='LFPsum.h5', unit='mV',\n                    ylabels=True, scalebar=True, vlimround=None,\n                    T=[0, 1000], color='k',\n                    label=''):\n    '''\n    on axes plot the signal contributions\n    \n    args:\n    ::\n        ax : matplotlib.axes.AxesSubplot object\n        z : np.ndarray\n        T : list, [tstart, tstop], which timeinterval\n        ylims : list, set range of yaxis to scale with other plots\n        fancy : bool, \n        scaling_factor : float, scaling factor (e.g. to scale 10% data set up)\n    '''    \n    #open file and get data, samplingrate\n    f = h5py.File(fname)\n    data = f['data'].value\n    dataT = data.T - data.mean(axis=1)\n    data = dataT.T\n    srate = f['srate'].value\n    \n    #close file object\n    f.close()\n\n    # normalize data for plot\n    tvec = np.arange(data.shape[1]) * 1000. / srate\n    slica = (tvec <= T[1]) & (tvec >= T[0])\n    zvec = np.r_[z]\n    zvec = np.r_[zvec, zvec[-1] + np.diff(zvec)[-1]]\n    vlim = abs(data[:, slica]).max()\n    if vlimround is None:\n        vlimround = 2.**np.round(np.log2(vlim))\n    yticklabels=[]\n    yticks = []\n    \n    colors = [color]*data.shape[0]\n    \n    for i, z in enumerate(z):\n        if i == 0:\n            ax.plot(tvec[slica], data[i, slica] * 100 / vlimround + z,\n                    color=colors[i], rasterized=False, label=label,\n                    clip_on=False)\n        else: \n            ax.plot(tvec[slica], data[i, slica] * 100 / vlimround + z,\n                    color=colors[i], rasterized=False, clip_on=False)\n        yticklabels.append('ch. %i' % (i+1))\n        yticks.append(z)\n     \n    if scalebar:\n        ax.plot([tvec[slica][-1], tvec[slica][-1]],\n                [-0, -100], lw=2, color='k', clip_on=False)\n        ax.text(tvec[slica][-1]+np.diff(T)*0.02, -50,\n                r'%g %s' % (vlimround, unit),\n                color='k', rotation='vertical')\n\n    ax.axis(ax.axis('tight'))\n    ax.yaxis.set_ticks(yticks)\n    if ylabels:\n        ax.yaxis.set_ticklabels(yticklabels)\n    else:\n        ax.yaxis.set_ticklabels([])\n\n    for loc, spine in ax.spines.items():\n        if loc in ['right', 'top']:\n            spine.set_color('none')            \n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n    ax.set_xlabel(r'time (ms)', labelpad=0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_population(ax,\n                    populationParams,\n                    electrodeParams,\n                    layerBoundaries,\n                    aspect='equal',\n                    isometricangle=np.pi/12,\n                    X=['EX', 'IN'],\n                    markers=['^', 'o'],\n                    colors=['r', 'b'],\n                    layers = ['upper', 'lower'],\n                    title='positions'):\n    '''\n    Plot the geometry of the column model, optionally with somatic locations\n    and optionally with reconstructed neurons\n    \n    kwargs:\n    ::\n        ax : matplotlib.axes.AxesSubplot\n        aspect : str\n            matplotlib.axis argument\n        isometricangle : float\n            pseudo-3d view angle\n        plot_somas : bool\n            plot soma locations\n        plot_morphos : bool\n            plot full morphologies\n        num_unitsE : int\n            number of excitatory morphos plotted per population\n        num_unitsI : int\n            number of inhibitory morphos plotted per population\n        clip_dendrites : bool\n            draw dendrites outside of axis\n        mainpops : bool\n            if True, plot only main pops, e.g. b23 and nb23 as L23I\n    \n    return:\n    ::\n        axis : list\n            the plt.axis() corresponding to input aspect\n    '''\n\n    remove_axis_junk(ax, ['right', 'bottom', 'left', 'top'])\n\n    \n    # DRAW OUTLINE OF POPULATIONS \n    ax.xaxis.set_ticks([])\n    ax.yaxis.set_ticks([])\n\n    #contact points\n    ax.plot(electrodeParams['x'],\n            electrodeParams['z'],\n            '.', marker='o', markersize=5, color='k', zorder=0)\n\n    #outline of electrode       \n    x_0 = np.array(electrodeParams['r_z'])[1, 1:-1]\n    z_0 = np.array(electrodeParams['r_z'])[0, 1:-1]\n    x = np.r_[x_0[-1], x_0[::-1], -x_0[1:], -x_0[-1]]\n    z = np.r_[100, z_0[::-1], z_0[1:], 100]\n    ax.fill(x, z, color=(0.5, 0.5, 0.5), lw=None, zorder=-0.1)\n\n    #outline of populations:\n    #fetch the population radius from some population\n    r = populationParams[populationParams.keys()[0]]['radius']\n\n    theta0 = np.linspace(0, np.pi, 20)\n    theta1 = np.linspace(np.pi, 2*np.pi, 20)\n    \n    zpos = np.r_[np.array(layerBoundaries)[:, 0],\n                 np.array(layerBoundaries)[-1, 1]]\n    \n    for i, z in enumerate(np.mean(layerBoundaries, axis=1)):\n        ax.text(r, z, ' %s' % layers[i],\n                va='center', ha='left', rotation='vertical')\n\n    for i, zval in enumerate(zpos):\n        if i == 0:\n            ax.plot(r*np.cos(theta0),\n                    r*np.sin(theta0)*np.sin(isometricangle)+zval,\n                    color='k', zorder=-r, clip_on=False)\n            ax.plot(r*np.cos(theta1),\n                    r*np.sin(theta1)*np.sin(isometricangle)+zval,\n                    color='k', zorder=r, clip_on=False)\n        else:\n            ax.plot(r*np.cos(theta0),\n                    r*np.sin(theta0)*np.sin(isometricangle)+zval,\n                    color='gray', zorder=-r, clip_on=False)\n            ax.plot(r*np.cos(theta1),\n                    r*np.sin(theta1)*np.sin(isometricangle)+zval,\n                    color='k', zorder=r, clip_on=False)\n    \n    ax.plot([-r, -r], [zpos[0], zpos[-1]], 'k', zorder=0, clip_on=False)\n    ax.plot([r, r], [zpos[0], zpos[-1]], 'k', zorder=0, clip_on=False)\n    \n    #plot a horizontal radius scalebar\n    ax.plot([0, r], [z_0.min()]*2, 'k', lw=2, zorder=0, clip_on=False)\n    ax.text(r / 2., z_0.min()-100, 'r = %i $\\mu$m' % int(r), ha='center')\n    \n    #plot a vertical depth scalebar\n    ax.plot([-r]*2, [z_0.min()+50, z_0.min()-50],\n        'k', lw=2, zorder=0, clip_on=False)\n    ax.text(-r, z_0.min(), r'100 $\\mu$m', va='center', ha='right')\n    \n    ax.set_yticks([])\n    ax.set_yticklabels([])\n    \n    #fake ticks:\n    for pos in zpos:\n        ax.text(-r, pos, 'z=%i-' % int(pos), ha='right', va='center')\n \n    ax.set_title(title)\n   \n    axis = ax.axis(ax.axis(aspect))", "response": "Plots the electrode in the column model of the given population parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes x to have mean 0 and unity standard deviation", "response": "def normalize(x):\n    '''normalize x to have mean 0 and unity standard deviation'''\n    x = x.astype(float)\n    x -= x.mean()\n    return x / float(x.std())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_correlation(z_vec, x0, x1, ax, lag=20., title='firing_rate vs LFP'):\n    ''' mls\n    on axes plot the correlation between x0 and x1\n    \n    args:\n    ::\n        x0 : first dataset\n        x1 : second dataset - e.g., the multichannel LFP\n        ax : matplotlib.axes.AxesSubplot object\n        title : text to be used as current axis object title\n    '''\n    zvec = np.r_[z_vec]\n    zvec = np.r_[zvec, zvec[-1] + np.diff(zvec)[-1]]\n    \n    xcorr_all=np.zeros((np.size(z_vec), x0.shape[0]))\n    for i, z in enumerate(z_vec):\n        x2 = x1[i, ]\n        xcorr1 = np.correlate(normalize(x0),\n                              normalize(x2), 'same') / x0.size\n        xcorr_all[i,:]=xcorr1  \n\n    # Find limits for the plot\n    vlim = abs(xcorr_all).max()\n    vlimround = 2.**np.round(np.log2(vlim))\n    \n    yticklabels=[]\n    yticks = []\n    ylimfound=np.zeros((1,2))\n    for i, z in enumerate(z_vec):\n        ind = np.arange(x0.size) - x0.size/2\n        ax.plot(ind, xcorr_all[i,::-1] * 100. / vlimround + z, 'k',\n                clip_on=True, rasterized=False)\n        yticklabels.append('ch. %i' %(i+1))\n        yticks.append(z)    \n\n    remove_axis_junk(ax)\n    ax.set_title(title)\n    ax.set_xlabel(r'lag $\\tau$ (ms)')\n\n    ax.set_xlim(-lag, lag)\n    ax.set_ylim(z-100, 100)\n    \n    axis = ax.axis()\n    ax.vlines(0, axis[2], axis[3], 'r', 'dotted')\n\n    ax.yaxis.set_ticks(yticks)\n    ax.yaxis.set_ticklabels(yticklabels)\n\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n\n    # Create a scaling bar\n    ax.plot([lag, lag],\n        [0, 100], lw=2, color='k', clip_on=False)\n    ax.text(lag, 50, r'CC=%.2f' % vlimround,\n            rotation='vertical', va='center')", "response": "Function to plot the correlation between two datasets."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef true_lam_csd(cell, dr=100, z=None):\n    if type(z) != type(np.ndarray(shape=0)):\n        raise ValueError('type(z) should be a numpy.ndarray')\n\n    dz = abs(z[1] - z[0])\n    CSD = np.zeros((z.size, cell.tvec.size,))\n    r_end = np.sqrt(cell.xend**2 + cell.yend**2)\n    r_start = np.sqrt(cell.xstart**2 + cell.ystart**2)\n    volume = dz * np.pi * dr**2\n\n    for i in range(len(z)):\n        aa0 = cell.zstart < z[i] + dz/2\n        aa1 = cell.zend < z[i] + dz/2\n        bb0 = cell.zstart >= z[i] - dz/2\n        bb1 = cell.zend >= z[i] - dz/2\n        cc0 = r_start < dr\n        cc1 = r_end < dr\n        ii = aa0 & bb0 & cc0 # startpoint inside volume\n        jj = aa1 & bb1 & cc1 # endpoint inside volume\n\n        for j in range(cell.zstart.size):\n            # Calc fraction of source being inside control volume from 0-1\n            # both start and endpoint in volume\n            if ii[j] and jj[j]:\n                CSD[i,] = CSD[i, ] + cell.imem[j, ] / volume\n            # Startpoint in volume:\n            elif ii[j] and not jj[j]: \n                z0 = cell.zstart[j]\n                r0 = r_start[j]\n                \n                z1 = cell.zend[j]\n                r1 = r_end[j]\n\n                if r0 == r1:\n                    # Segment is parallel with z-axis\n                    frac = -(z0 - z[i]-dz/2) / (z1 - z0)\n                else:\n                    # Not parallel with z-axis                    \n                    L2 = (r1 - r0)**2 + (z1 - z0)**2\n    \n                    z2 = [z[i]-dz/2, z[i]+dz/2, z[i]-dz/2]\n                    r2 = [0, 0, dr]\n                    \n                    z3 = [z[i]-dz/2, z[i]+dz/2, z[i]+dz/2]\n                    r3 = [dr, dr, dr]\n    \n                    P = []\n                    for k in range(3):\n                        P.append(_PrPz(r0, z0, r1, z1, r2[k], z2[k], r3[k], z3[k]))\n                        if P[k][2]:\n                            vL2 = (P[k][0] - r0)**2 + (P[k][1] -z0)**2\n                            frac = np.sqrt(vL2 / L2)\n                CSD[i,] = CSD[i, ] + frac * cell.imem[j, ] / volume\n            # Endpoint in volume:\n            elif jj[j] and not ii[j]: \n                z0 = cell.zstart[j]\n                r0 = r_start[j]\n                \n                z1 = cell.zend[j]\n                r1 = r_end[j]\n                \n                if r0 == r1:\n                    # Segment is parallel with z-axis\n                    frac = (z1 - z[i]+dz/2) / (z1 - z0)\n                else:\n                    # Not parallel with z-axis\n                    L2 = (r1 - r0)**2 + (z1 - z0)**2\n    \n                    z2 = [z[i]-dz/2, z[i]+dz/2, z[i]-dz/2]\n                    r2 = [0, 0, dr]\n                    \n                    z3 = [z[i]-dz/2, z[i]+dz/2, z[i]+dz/2]\n                    r3 = [dr, dr, dr]\n    \n                    P = []\n                    for k in range(3):\n                        P.append(_PrPz(r0, z0, r1, z1, r2[k], z2[k], r3[k], z3[k]))\n                        if P[k][2]:\n                            vL2 = (r1 - P[k][0])**2 + (z1 - P[k][1])**2\n                            frac = np.sqrt(vL2 / L2)\n                CSD[i,] = CSD[i, ] + frac * cell.imem[j, ] / volume\n            else:\n                pass\n\n    return CSD", "response": "Returns the true laminear CSD of the currents of the given cell along the coordinates z - axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset up plot for introduction", "response": "def fig_intro(params, ana_params, T=[800, 1000], fraction=0.05, rasterized=False):\n    '''set up plot for introduction'''\n    ana_params.set_PLOS_2column_fig_style(ratio=0.5)\n    \n    #load spike as database\n    networkSim = CachedNetwork(**params.networkSimParams)\n    if analysis_params.bw:\n        networkSim.colors = phlp.get_colors(len(networkSim.X))\n\n    #set up figure and subplots\n    fig = plt.figure()\n    gs = gridspec.GridSpec(3, 4)\n    \n    \n    fig.subplots_adjust(left=0.05, right=0.95, wspace=0.5, hspace=0.)\n\n\n    #network diagram\n    ax0_1 = fig.add_subplot(gs[:, 0], frameon=False)\n    ax0_1.set_title('point-neuron network', va='bottom')\n\n    network_sketch(ax0_1, yscaling=1.3)\n    ax0_1.xaxis.set_ticks([])\n    ax0_1.yaxis.set_ticks([])\n    phlp.annotate_subplot(ax0_1, ncols=4, nrows=1, letter='A', linear_offset=0.065)\n   \n    \n    #network raster\n    ax1 = fig.add_subplot(gs[:, 1], frameon=True)\n    phlp.remove_axis_junk(ax1)\n    phlp.annotate_subplot(ax1, ncols=4, nrows=1, letter='B', linear_offset=0.065)\n       \n    x, y = networkSim.get_xy(T, fraction=fraction)\n    # networkSim.plot_raster(ax1, T, x, y, markersize=0.1, alpha=1.,legend=False, pop_names=True)\n    networkSim.plot_raster(ax1, T, x, y, markersize=0.2, marker='_', alpha=1.,legend=False, pop_names=True, rasterized=rasterized)\n    ax1.set_ylabel('')\n    ax1.xaxis.set_major_locator(plt.MaxNLocator(4))\n    ax1.set_title('spiking activity', va='bottom')\n    a = ax1.axis()\n    ax1.vlines(x['TC'][0], a[2], a[3], 'k', lw=0.25)\n\n\n    #population\n    ax2 = fig.add_subplot(gs[:, 2], frameon=False)\n    ax2.xaxis.set_ticks([])\n    ax2.yaxis.set_ticks([])\n    plot_population(ax2, params, isometricangle=np.pi/24, plot_somas=False,\n                    plot_morphos=True, num_unitsE=1, num_unitsI=1,\n                    clip_dendrites=True, main_pops=True, title='',\n                    rasterized=rasterized)\n    ax2.set_title('multicompartment\\nneurons', va='bottom', fontweight='normal')\n    phlp.annotate_subplot(ax2, ncols=4, nrows=1, letter='C', linear_offset=0.065)\n    \n\n    #LFP traces in all channels\n    ax3 = fig.add_subplot(gs[:, 3], frameon=True)\n    phlp.remove_axis_junk(ax3)\n    plot_signal_sum(ax3, params, fname=os.path.join(params.savefolder, 'LFPsum.h5'),\n                unit='mV', vlimround=0.8,\n                T=T, ylim=[ax2.axis()[2], ax2.axis()[3]],\n                rasterized=False)\n    ax3.set_title('LFP', va='bottom')\n    ax3.xaxis.set_major_locator(plt.MaxNLocator(4))\n    phlp.annotate_subplot(ax3, ncols=4, nrows=1, letter='D', linear_offset=0.065)\n    a = ax3.axis()\n    ax3.vlines(x['TC'][0], a[2], a[3], 'k', lw=0.25)\n    \n    \n    #draw some arrows:\n    ax = plt.gca()\n    ax.annotate(\"\", xy=(0.27, 0.5), xytext=(.24, 0.5),\n                xycoords=\"figure fraction\",\n            arrowprops=dict(facecolor='black', arrowstyle='simple'),\n            )\n    ax.annotate(\"\", xy=(0.52, 0.5), xytext=(.49, 0.5),\n                xycoords=\"figure fraction\",\n            arrowprops=dict(facecolor='black', arrowstyle='simple'),\n            )\n    ax.annotate(\"\", xy=(0.78, 0.5), xytext=(.75, 0.5),\n                xycoords=\"figure fraction\",\n            arrowprops=dict(facecolor='black', arrowstyle='simple'),\n            )\n\n    \n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef index_record(self, json_path):\n        self.logger.debug('Indexing record: %s', json_path)\n        json_path = os.path.abspath(json_path)\n        self.check_path(json_path, '`json_path`')\n\n        with open(json_path) as fp:\n            try:\n                dct = json.load(fp)\n            except ValueError:\n                warnings.warn(\n                    'Ignoring invalid JSON file at: {0}'.format(json_path))\n                return\n\n        record_type = self.get_record_type(json_path)\n        kwds = {}\n        if record_type == 'command':\n            importer = self.db.import_dict\n            kwds.update(check_duplicate=self.check_duplicate)\n        elif record_type == 'init':\n            importer = self.db.import_init_dict\n        elif record_type == 'exit':\n            importer = self.db.import_exit_dict\n        else:\n            raise ValueError(\"Unknown record type: {0}\".format(record_type))\n        importer(dct, **kwds)\n\n        if not self.keep_json:\n            self.logger.info('Removing JSON record: %s', json_path)\n            os.remove(json_path)", "response": "Index a single record in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield paths to record files.", "response": "def find_record_files(self):\n        \"\"\"\n        Yield paths to record files.\n        \"\"\"\n        for (root, _, files) in os.walk(self.record_path):\n            for f in (f for f in files if f.endswith('.json')):\n                yield os.path.join(root, f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index_all(self):\n        self.logger.debug('Start indexing all records under: %s',\n                          self.record_path)\n        with self.db.connection():\n            for json_path in sorted(self.find_record_files()):\n                self.index_record(json_path)", "response": "Index all records under the record_path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fig_lfp_corr(params, savefolders, transient=200,\n                 channels=[0,3,7,11,13], Df=None,\n                 mlab=True, NFFT=256, noverlap=128,\n                 window=plt.mlab.window_hanning,\n                 letterslist=['AB', 'CD'], data_type = 'LFP'):\n    '''This figure compares power spectra for correlated and uncorrelated signals \n\n    '''\n    ana_params.set_PLOS_2column_fig_style(ratio=0.5)\n    fig = plt.figure()\n    fig.subplots_adjust(left=0.07, right=0.95, bottom=0.1, wspace=0.3, hspace=0.1)\n\n    gs = gridspec.GridSpec(5, 4)\n\n\n    for i, (savefolder, letters) in enumerate(zip(savefolders, letterslist)):\n        # path to simulation files\n        params.savefolder = os.path.join(os.path.split(params.savefolder)[0],\n                                         savefolder)\n        params.figures_path = os.path.join(params.savefolder, 'figures')\n        params.spike_output_path = os.path.join(params.savefolder,\n                                                           'processed_nest_output')\n        params.networkSimParams['spike_output_path'] = params.spike_output_path\n\n\n        ## Including correlations\n        f = h5py.File(os.path.join(params.savefolder, ana_params.analysis_folder, data_type + ana_params.fname_psd),'r')\n        freqs = f['freqs'].value\n        LFP_PSD_corr = f['psd'].value\n        f.close()\n    \n        ## Excluding correlations\n        f = h5py.File(os.path.join(params.savefolder, ana_params.analysis_folder, data_type +  ana_params.fname_psd_uncorr),'r')\n        freqs = f['freqs'].value\n        LFP_PSD_uncorr = f['psd'].value\n        f.close()\n        \n     \n        ##################################\n        ###  Single channel LFP PSDs   ###\n        ##################################\n    \n        ax = fig.add_subplot(gs[0, (i % 2)*2]) \n        phlp.remove_axis_junk(ax)\n        ax.loglog(freqs,LFP_PSD_corr[channels[0]], color='k', label='$P$')\n        ax.loglog(freqs,LFP_PSD_uncorr[channels[0]],\n                  color='gray' if analysis_params.bw else analysis_params.colorP,\n                  lw=1,\n                  label='$\\tilde{P}$')\n        ax.xaxis.set_ticks_position('bottom')\n        ax.yaxis.set_ticks_position('left')\n        ax.text(0.80,0.82,'ch. %i' %(channels[0]+1),horizontalalignment='left',\n            verticalalignment='center',\n            fontsize=6, \n            transform=ax.transAxes)\n        ax.yaxis.set_minor_locator(plt.NullLocator())\n        ax.set_ylabel('(mV$^2$/Hz)', labelpad=0.)\n        ax.set_xticks([])\n        ax.set_xticklabels([])\n        ax.tick_params(axis='y',which='minor',bottom='off')\n        ax.set_xlim(4E0,4E2)\n        ax.set_ylim(1E-8,1.5E-4)\n        ax.set_yticks([1E-8,1E-6,1E-4])\n        ax.set_title('power spectra')\n        phlp.annotate_subplot(ax, ncols=4, nrows=5, letter=letters[0],\n                           linear_offset=0.065)       \n    \n        ax = fig.add_subplot(gs[1, (i % 2)*2])\n        phlp.remove_axis_junk(ax)\n        ax.loglog(freqs,LFP_PSD_corr[channels[1]], color='k', label='corr')\n        ax.loglog(freqs,LFP_PSD_uncorr[channels[1]],\n                  color='gray' if analysis_params.bw else analysis_params.colorP,\n                  lw=1,\n                  label='uncorr')\n        ax.xaxis.set_ticks_position('bottom')\n        ax.yaxis.set_ticks_position('left')\n        ax.text(0.80,0.82,'ch. %i' %(channels[1]+1),horizontalalignment='left',\n            verticalalignment='center',\n            fontsize=6, \n            transform=ax.transAxes)\n        ax.yaxis.set_minor_locator(plt.NullLocator())\n        ax.set_xticks([])\n        ax.set_xticklabels([])\n        ax.tick_params(axis='y',which='minor',bottom='off')\n        ax.set_xlim(4E0,4E2)\n        ax.set_ylim(1E-8,1.5E-4)\n        ax.set_yticks([1E-8,1E-6,1E-4])\n        ax.set_yticklabels([])\n    \n    \n        ax = fig.add_subplot(gs[2, (i % 2)*2])\n        phlp.remove_axis_junk(ax)\n        ax.loglog(freqs,LFP_PSD_corr[channels[2]], color='k', label='corr')\n        ax.loglog(freqs,LFP_PSD_uncorr[channels[2]],\n                  color='gray' if analysis_params.bw else analysis_params.colorP,\n                  lw=1,\n                  label='uncorr')   \n        ax.xaxis.set_ticks_position('bottom')\n        ax.yaxis.set_ticks_position('left')\n        ax.text(0.80,0.82,'ch. %i' %(channels[2]+1),horizontalalignment='left',\n            verticalalignment='center',\n            fontsize=6, \n            transform=ax.transAxes)\n        ax.yaxis.set_minor_locator(plt.NullLocator())\n        ax.set_xticks([])\n        ax.set_xticklabels([])\n        ax.tick_params(axis='y',which='minor',bottom='off')\n        ax.set_xlim(4E0,4E2)\n        ax.set_ylim(1E-8,1.5E-4)\n        ax.set_yticks([1E-8,1E-6,1E-4])\n        ax.set_yticklabels([])\n    \n    \n        ax = fig.add_subplot(gs[3, (i % 2)*2]) \n        phlp.remove_axis_junk(ax)\n        ax.loglog(freqs,LFP_PSD_corr[channels[3]], color='k', label='corr')\n        ax.loglog(freqs,LFP_PSD_uncorr[channels[3]],\n                  color='gray' if analysis_params.bw else analysis_params.colorP,\n                  lw=1,\n                  label='uncorr')   \n        ax.xaxis.set_ticks_position('bottom')\n        ax.yaxis.set_ticks_position('left')\n        ax.text(0.80,0.82,'ch. %i' %(channels[3]+1),horizontalalignment='left',\n            verticalalignment='center',\n            fontsize=6, \n            transform=ax.transAxes)\n        ax.yaxis.set_minor_locator(plt.NullLocator())\n        ax.set_xticks([])\n        ax.set_xticklabels([])\n        ax.tick_params(axis='y',which='minor',bottom='off')\n        ax.set_xlim(4E0,4E2)\n        ax.set_ylim(1E-8,1.5E-4)\n        ax.set_yticks([1E-8,1E-6,1E-4])\n        ax.set_yticklabels([])\n    \n    \n        ax = fig.add_subplot(gs[4, (i % 2)*2])\n        phlp.remove_axis_junk(ax)\n        ax.loglog(freqs,LFP_PSD_corr[channels[4]], color='k', label='corr')\n        ax.loglog(freqs,LFP_PSD_uncorr[channels[4]],\n                  color='gray' if analysis_params.bw else analysis_params.colorP,\n                  lw=1,\n                  label='uncorr')   \n        ax.xaxis.set_ticks_position('bottom')\n        ax.yaxis.set_ticks_position('left')\n        ax.set_xlabel(r'$f$ (Hz)', labelpad=0.2)\n        ax.text(0.80,0.82,'ch. %i' %(channels[4]+1),horizontalalignment='left',\n            verticalalignment='center',\n            fontsize=6, \n            transform=ax.transAxes)\n        ax.yaxis.set_minor_locator(plt.NullLocator())\n        ax.tick_params(axis='y',which='minor',bottom='off')\n        ax.set_xlim(4E0,4E2)\n        ax.set_ylim(1E-8,1.5E-4)\n        ax.set_yticks([1E-8,1E-6,1E-4])\n        ax.set_yticklabels([])\n    \n    \n        ##################################\n        ###  LFP PSD ratios            ###\n        ##################################\n    \n        ax = fig.add_subplot(gs[:, (i % 2)*2 + 1]) \n        phlp.annotate_subplot(ax, ncols=4, nrows=1, letter=letters[1],\n                           linear_offset=0.065)\n        phlp.remove_axis_junk(ax)\n        ax.set_title('power ratio')\n        PSD_ratio = LFP_PSD_corr/LFP_PSD_uncorr\n        \n        zvec = np.r_[params.electrodeParams['z']]\n        zvec = np.r_[zvec, zvec[-1] + np.diff(zvec)[-1]]\n        inds = freqs >= 1  # frequencies greater than 4 Hz  \n        im = ax.pcolormesh(freqs[inds], zvec+40, PSD_ratio[:, inds],\n                            rasterized=False,\n                            cmap=plt.get_cmap('gray_r', 12) if analysis_params.bw else plt.get_cmap('Reds', 12),\n                            vmin=10**-0.25,vmax=10**2.75,norm=LogNorm())\n        ax.set_xscale('log')\n    \n        ax.set_yticks(zvec)\n        yticklabels = ['ch. %i' %i for i in np.arange(len(zvec))+1]\n        ax.set_yticklabels(yticklabels)\n        ax.set_xlabel(r'$f$ (Hz)',labelpad=0.2)\n        plt.axis('tight')\n        ax.set_xlim([4E0, 4E2])\n    \n        cb = phlp.colorbar(fig, ax, im,\n                           width=0.05, height=0.5,\n                           hoffset=-0.05, voffset=0.0)\n        cb.set_label('(-)', labelpad=0.1)\n\n\n \n    return fig", "response": "This function calculates the correlated power spectra for the given set of signals."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the sli - script with the given parameters.", "response": "def sli_run(parameters=object(),\n            fname='microcircuit.sli',\n            verbosity='M_ERROR'):\n    '''\n    Takes parameter-class and name of main sli-script as input, initiating the\n    simulation.\n    \n    kwargs:\n    ::\n        parameters : object, parameter class instance\n        fname : str, path to sli codes to be executed\n        verbosity : 'str', nest verbosity flag\n    '''\n    # Load parameters from params file, and pass them to nest\n    # Python -> SLI\n    send_nest_params_to_sli(vars(parameters))\n    \n    #set SLI verbosity\n    nest.sli_run(\"%s setverbosity\" % verbosity)\n    \n    # Run NEST/SLI simulation\n    nest.sli_run('(%s) run' % fname)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the bytes in buffer at offset to a native Python value. Returns that value and the number of bytes consumed to create it.", "response": "def buffer_to_value(self, obj, buffer, offset, default_endianness=DEFAULT_ENDIANNESS):\n        \"\"\"\n        Converts the bytes in ``buffer`` at ``offset`` to a native Python value. Returns that value and the number of\n        bytes consumed to create it.\n\n        :param obj: The parent :class:`.PebblePacket` of this field\n        :type obj: .PebblePacket\n        :param buffer: The buffer from which to extract a value.\n        :type buffer: bytes\n        :param offset: The offset in the buffer to start at.\n        :type offset: int\n        :param default_endianness: The default endianness of the value. Used if ``endianness`` was not passed to the\n                                   :class:`Field` constructor.\n        :type default_endianness: str\n        :return: (value, length)\n        :rtype: (:class:`object`, :any:`int`)\n        \"\"\"\n        try:\n            value, length = struct.unpack_from(str(self.endianness or default_endianness)\n                                      + self.struct_format, buffer, offset)[0], struct.calcsize(self.struct_format)\n            if self._enum is not None:\n                try:\n                    return self._enum(value), length\n                except ValueError as e:\n                    raise PacketDecodeError(\"{}: {}\".format(self.type, e))\n            else:\n                return value, length\n        except struct.error as e:\n            raise PacketDecodeError(\"{}: {}\".format(self.type, e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef value_to_bytes(self, obj, value, default_endianness=DEFAULT_ENDIANNESS):\n        return struct.pack(str(self.endianness or default_endianness) + self.struct_format, value)", "response": "Converts the given value to an appropriately encoded string of bytes that represents it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rpc(self, cmd, **kwargs):\n\n        func = getattr(self.client, cmd)\n        try:\n            if self.credentials is None:\n                return func(kwargs)\n            else:\n                return func(self.credentials, kwargs)\n        except socket.error as e:\n            raise BackendConnectionError(e)\n        except (xmlrpclib.ProtocolError, BadStatusLine) as e:\n            log.error(e)\n            raise BackendError(\"Error reaching backend.\")", "response": "Generic helper function to call an RPC method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef message_user(self, username, domain, subject, message):\n\n        kwargs = {\n            'body': message,\n            'from': domain,\n            'to': '%s@%s' % (username, domain),\n        }\n\n        if self.api_version <= (14, 7):\n            # TODO: it's unclear when send_message was introduced\n            command = 'send_message_chat'\n        else:\n            command = 'send_message'\n            kwargs['subject'] = subject\n            kwargs['type'] = 'normal'\n        result = self.rpc(command, **kwargs)\n\n        if result['res'] == 0:\n            return\n        else:\n            raise BackendError(result.get('text', 'Unknown Error'))", "response": "Send a message to a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_rsa_public_key(cert):\n        openssl_pkey = cert.get_pubkey()\n        openssl_lib = _util.binding.lib\n        ffi = _util.binding.ffi\n        buf = ffi.new(\"unsigned char **\")\n        rsa = openssl_lib.EVP_PKEY_get1_RSA(openssl_pkey._pkey)\n        length = openssl_lib.i2d_RSAPublicKey(rsa, buf)\n        public_key = ffi.buffer(buf[0], length)[:]\n        ffi.gc(buf[0], openssl_lib.OPENSSL_free)\n        return public_key", "response": "Returns the RSA public key for the supplied certificate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing a state machine :return:", "response": "def _credssp_processor(self, context):\n        \"\"\"\n        Implements a state machine\n        :return:\n        \"\"\"\n        http_response = (yield)\n        credssp_context = self._get_credssp_header(http_response)\n\n        if credssp_context is None:\n            raise Exception('The remote host did not respond with a \\'www-authenticate\\' header containing '\n                            '\\'CredSSP\\' as an available authentication mechanism')\n\n        # 1. First, secure the channel with a TLS Handshake\n        if not credssp_context:\n            self.tls_connection = SSL.Connection(self.tls_context)\n            self.tls_connection.set_connect_state()\n            while True:\n                try:\n                    self.tls_connection.do_handshake()\n                except SSL.WantReadError:\n                    http_response = yield self._set_credssp_header(http_response.request, self.tls_connection.bio_read(4096))\n                    credssp_context = self._get_credssp_header(http_response)\n                    if credssp_context is None or not credssp_context:\n                        raise Exception('The remote host rejected the CredSSP TLS handshake')\n                    self.tls_connection.bio_write(credssp_context)\n                else:\n                    break\n\n        # add logging to display the negotiated cipher (move to a function)\n        openssl_lib = _util.binding.lib\n        ffi = _util.binding.ffi\n        cipher = openssl_lib.SSL_get_current_cipher(self.tls_connection._ssl)\n        cipher_name = ffi.string( openssl_lib.SSL_CIPHER_get_name(cipher))\n        log.debug(\"Negotiated TLS Cipher: %s\", cipher_name)\n\n        # 2. Send an TSRequest containing an NTLM Negotiate Request\n        context_generator = context.initialize_security_context()\n        negotiate_token = context_generator.send(None)\n        log.debug(\"NTLM Type 1: %s\", AsHex(negotiate_token))\n\n        ts_request = TSRequest()\n        ts_request['negoTokens'] = negotiate_token\n        self.tls_connection.send(ts_request.getData())\n\n        http_response = yield self._set_credssp_header(http_response.request, self.tls_connection.bio_read(4096))\n\n        # Extract and decrypt the encoded TSRequest response struct from the Negotiate header\n        authenticate_header = self._get_credssp_header(http_response)\n        if not authenticate_header or authenticate_header is None:\n            raise Exception(\"The remote host rejected the CredSSP negotiation token\")\n        self.tls_connection.bio_write(authenticate_header)\n\n        # NTLM Challenge Response and Server Public Key Validation\n        ts_request = TSRequest()\n        ts_request.fromString(self.tls_connection.recv(8192))\n        challenge_token = ts_request['negoTokens']\n        log.debug(\"NTLM Type 2: %s\", AsHex(challenge_token))\n        server_cert = self.tls_connection.get_peer_certificate()\n\n        # not using channel bindings\n        #certificate_digest = base64.b16decode(server_cert.digest('SHA256').replace(':', ''))\n        ## channel_binding_structure = gss_channel_bindings_struct()\n        ## channel_binding_structure['application_data'] = \"tls-server-end-point:\" + certificate_digest\n        public_key = HttpCredSSPAuth._get_rsa_public_key(server_cert)\n        # The _RSAPublicKey must be 'wrapped' using the negotiated GSSAPI mechanism and send to the server along with\n        # the final SPNEGO token. This step of the CredSSP protocol is designed to thwart 'man-in-the-middle' attacks\n\n        # Build and encrypt the response to the server\n        ts_request = TSRequest()\n        type3= context_generator.send(challenge_token)\n        log.debug(\"NTLM Type 3: %s\", AsHex(type3))\n        ts_request['negoTokens'] = type3\n        public_key_encrypted, signature = context.wrap_message(public_key)\n        ts_request['pubKeyAuth'] = signature + public_key_encrypted\n\n        self.tls_connection.send(ts_request.getData())\n        enc_type3 = self.tls_connection.bio_read(8192)\n        http_response = yield self._set_credssp_header(http_response.request, enc_type3)\n\n        # TLS decrypt the response, then ASN decode and check the error code\n        auth_response = self._get_credssp_header(http_response)\n        if not auth_response or auth_response is None:\n            raise Exception(\"The remote host rejected the challenge response\")\n\n        self.tls_connection.bio_write(auth_response)\n        ts_request = TSRequest()\n        ts_request.fromString(self.tls_connection.recv(8192))\n        # TODO: determine how to validate server certificate here\n        #a = ts_request['pubKeyAuth']\n        # print \":\".join(\"{:02x}\".format(ord(c)) for c in a)\n\n        # 4. Send the Credentials to be delegated, these are encrypted with both NTLM v2 and then by TLS\n        tsp = TSPasswordCreds()\n        tsp['domain'] = self.password_authenticator.get_domain()\n        tsp['username'] = self.password_authenticator.get_username()\n        tsp['password'] = self.password_authenticator.get_password()\n\n        tsc = TSCredentials()\n        tsc['type'] = 1\n        tsc['credentials'] = tsp.getData()\n\n        ts_request = TSRequest()\n        encrypted, signature = context.wrap_message(tsc.getData())\n        ts_request['authInfo'] = signature + encrypted\n\n        self.tls_connection.send(ts_request.getData())\n        token = self.tls_connection.bio_read(8192)\n\n        http_response.request.body = self.body\n        http_response = yield self._set_credssp_header(self._encrypt(http_response.request, self.tls_connection), token)\n\n        if http_response.status_code == 401:\n            raise Exception('Authentication Failed')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling an app. Blocks until the installation is complete.", "response": "def install(self, force_install=False):\n        \"\"\"\n        Installs an app. Blocks until the installation is complete, or raises :exc:`AppInstallError` if it fails.\n\n        While this method runs, \"progress\" events will be emitted regularly with the following signature: ::\n\n           (sent_this_interval, sent_total, total_size)\n\n        :param force_install: Install even if installing this pbw on this platform is usually forbidden.\n        :type force_install: bool\n        \"\"\"\n        if not (force_install or self._bundle.should_permit_install()):\n            raise AppInstallError(\"This pbw is not supported on this platform.\")\n        if self._pebble.firmware_version.major < 3:\n            self._install_legacy2()\n        else:\n            self._install_modern()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_chemical_equation(value):\n    arrow = _pp.oneOf('-> <- <=>').setResultsName('arrow')\n    species = _pp.Word(_pp.printables).setResultsName('species')\n    coefficient = (_pp.Optional(_pp.Word(_pp.nums), default=1)\n                   .setParseAction(_pp.tokenMap(int))\n                   .setResultsName('coefficient'))\n    group_ = _pp.Group(coefficient + _pp.Optional(_pp.Suppress('*')) + species)\n    reactants = ((group_ + _pp.ZeroOrMore(_pp.Suppress('+') + group_))\n                 .setResultsName('reactants'))\n    products = ((group_ + _pp.ZeroOrMore(_pp.Suppress('+') + group_))\n                .setResultsName('products'))\n\n    grammar = reactants + arrow + products\n    parsed = grammar.parseString(value).asDict()\n\n    if parsed['arrow'] == '<-':\n        parsed['reactants'], parsed['products'] \\\n            = parsed['products'], parsed['reactants']\n        parsed['arrow'] = '->'\n\n    return parsed", "response": "Parses the string value in chemical - equation mini - language."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_chemical_equation_piece(species_list, coefficients):\n    def _get_token(species, coefficient):\n        if coefficient == 1:\n            return '{}'.format(species)\n        else:\n            return '{:g} {}'.format(coefficient, species)\n\n    bag = []\n    for species, coefficient in zip(species_list, coefficients):\n        if coefficient < 0:\n            coefficient = -coefficient\n        if coefficient > 0:\n            bag.append(_get_token(species, coefficient))\n    return '{}'.format(' + '.join(bag))", "response": "Generates a string from a list of chemical species and their coefficients."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks a data object for inconsistencies.", "response": "def _check_data(data):\n    \"\"\"\n    Check a data object for inconsistencies.\n\n    Parameters\n    ----------\n    data : `pandas.DataFrame`\n        A `data` object, i.e., a table whose rows store information about\n        chemical species, indexed by chemical species.\n\n    Warns\n    -----\n    UserWarning\n        Warned if a ground state species has one or more imaginary vibrational\n        frequencies, or if a transition state species has zero, two or more\n        imaginary vibrational frequencies.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> from pyrrole.core import _check_data\n    >>> data = (pd.DataFrame([{'name': 'A', 'vibfreqs': [0., 1., 2.]},\n    ...                       {'name': 'B', 'vibfreqs': [0., -1., 2.]},\n    ...                       {'name': 'C', 'vibfreqs': [0., -1., -2.]},\n    ...                       {'name': 'A#', 'vibfreqs': [0., 1., 2.]},\n    ...                       {'name': 'C#', 'vibfreqs': [0., -2., -1.]},\n    ...                       {'name': 'B#', 'vibfreqs': [0., -1., 2.]}])\n    ...         .set_index('name'))\n    >>> _check_data(data)\n\n    \"\"\"\n    if \"vibfreqs\" in data.columns:\n        for species in data.index:\n            vibfreqs = data.loc[species, \"vibfreqs\"]\n            nimagvibfreqs = _np.sum(_np.array(vibfreqs) < 0)\n            if species[-1] == '#' and nimagvibfreqs != 1:\n                _warnings.warn(\"'{}' should have 1 imaginary vibfreqs but {} \"\n                               \"found\".format(species, nimagvibfreqs))\n            elif species[-1] != '#' and nimagvibfreqs != 0:\n                _warnings.warn(\"'{}' should have no imaginary vibfreqs but {} \"\n                               \"found\".format(species, nimagvibfreqs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _split_chemical_equations(value):\n    pieces = _split_arrows(value)\n    return [(pieces[i] +\n             pieces[i + 1] +\n             pieces[i + 2]).strip()\n            for i in range(0, len(pieces) - 2, 2)]", "response": "Splits a string with sequential chemical equations into separate strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a pandas. Series containing the canonicalized version of the data for the given entry.", "response": "def to_series(self, only=None,\n                  intensive_columns=[\"temperature\", \"pressure\"],\n                  check_data=True):\n        \"\"\"\n        Produce a data record for `ChemicalEquation`.\n\n        All possible linear differences for all numeric attributes are computed\n        and stored in the returned `pandas.Series` object (see examples below).\n        This allows for easy application and manipulation of\n        `Hess's law <https://en.wikipedia.org/wiki/Hess%27s_law>`_ to chemical\n        equations (see examples below).\n\n        Parameters\n        ----------\n        only : ``\"reactants\"``, ``\"products\"``, optional\n            Instead of the standard behaviour (difference of sums), sum numeric\n            attributes of either reactants or products only. If given, absolute\n            coefficients are used.\n        intensive_columns : iterable of `str`, optional\n            A set of column names representing intensive properties (e.g. bulk\n            properties) whose values are not summable. Those must be constant\n            throughout the chemical equation.\n        check_data : `bool`, optional\n            Whether to check data object for inconsistencies.\n\n        Returns\n        -------\n        series : `pandas.Series`\n            Data record of attribute differences, whose name is the canonical\n            string representation of the `ChemicalEquation` or, if `only` is\n            given, a string representing either reactants or products (see\n            examples below).\n\n        Raises\n        ------\n        ValueError\n            Raised if `self.data` wasn't defined (e.g. is `None`), if `only`\n            is something other than ``\"reactants\"`` or ``\"products\"``, or if\n            two or more distinct values for an intensive property have been\n            found.\n\n        Examples\n        --------\n        >>> from pyrrole import ChemicalEquation\n        >>> from pyrrole.atoms import create_data, read_cclib\n        >>> data = create_data(\n        ...     read_cclib(\"data/acetate/acetic_acid.out\",\n        ...                \"AcOH(g)\"),\n        ...     read_cclib(\"data/acetate/acetic_acid@water.out\",\n        ...                \"AcOH(aq)\"))\n        >>> equilibrium = ChemicalEquation(\"AcOH(g) <=> AcOH(aq)\",\n        ...                                data)\n        >>> equilibrium.to_series()\n        charge           0.000000\n        enthalpy        -0.010958\n        entropy         -0.000198\n        freeenergy      -0.010759\n        mult             0.000000\n        natom            0.000000\n        nbasis           0.000000\n        nmo              0.000000\n        pressure         1.000000\n        temperature    298.150000\n        Name: AcOH(g) <=> AcOH(aq), dtype: float64\n\n        Sums of either reactants or products can be computed:\n\n        >>> equilibrium.to_series(\"reactants\")\n        charge           0.000000\n        enthalpy      -228.533374\n        entropy          0.031135\n        freeenergy    -228.564509\n        mult             1.000000\n        natom            8.000000\n        nbasis          68.000000\n        nmo             68.000000\n        pressure         1.000000\n        temperature    298.150000\n        Name: AcOH(g), dtype: float64\n\n        \"\"\"\n        if self.data is None:\n            # TODO: should an empty Series be returned?\n            raise ValueError(\"data not defined\")\n\n        # TODO: find a way to keep categorical columns. Keep if they match?\n        columns = self.data.select_dtypes('number').columns\n        intensive_columns = [column for column in columns\n                             if column in intensive_columns]\n        extensive_columns = [column for column in columns\n                             if column not in intensive_columns]\n        columns = extensive_columns + intensive_columns\n\n        if only is None:\n            species = self.species\n        elif only == \"reactants\":\n            species = sorted(self.reactants)\n        elif only == \"products\":\n            species = sorted(self.products)\n        else:\n            raise ValueError(\"only must be either 'reactants' or 'products' \"\n                             \"('{}' given)\".format(only))\n\n        if check_data:\n            _check_data(self.data.loc[species])\n\n        if all([s in self.data.index for s in species]):\n            series = (self.data.loc[species, extensive_columns]\n                      .mul(self.coefficient, axis=\"index\").sum(\"index\"))\n            for column in intensive_columns:\n                vals = self.data[column].unique()\n                if len(vals) > 1:\n                    raise ValueError(\"different values for {}: \"\n                                     \"{}\".format(column, vals))\n                series[column] = vals[0]\n        else:\n            series = _pd.Series(_np.nan, index=columns)\n\n        if only is None:\n            name = self.__str__()\n        else:\n            coefficients = self.coefficient[species]\n            name = _get_chemical_equation_piece(species, coefficients)\n            if only == \"reactants\":\n                series[extensive_columns] = -series[extensive_columns]\n\n        # Avoid negative zero\n        # (see https://stackoverflow.com/a/11010791/4039050)\n        series = series + 0.\n\n        return series.rename(name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dataframe(self, *args, **kwargs):\n        dataframe = _pd.DataFrame([equation.to_series(*args, **kwargs)\n                                   for equation in self.equations])\n        dataframe.index.name = \"chemical_equation\"\n        return dataframe", "response": "Produce a data table with records of numeric attributes and values for every single chemical equation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_digraph(self, *args, **kwargs):\n        # TODO: make test for this\n        digraph = _nx.DiGraph()\n        for equation in self.equations:\n            reactants, arrow, products = [value.strip() for value\n                                          in _split_arrows(str(equation))]\n\n            try:\n                attr = equation.to_series(\"reactants\", *args,\n                                          **kwargs).to_dict()\n            except ValueError:\n                attr = dict()\n            digraph.add_node(reactants, **attr)\n\n            try:\n                attr = equation.to_series(\"products\", *args,\n                                          **kwargs).to_dict()\n            except ValueError:\n                attr = dict()\n            digraph.add_node(products, **attr)\n\n            try:\n                attr = equation.to_series(*args, **kwargs).to_dict()\n            except ValueError:\n                attr = dict()\n            digraph.add_edge(reactants, products, **attr)\n            if arrow == '<=>':\n                digraph.add_edge(products, reactants, **attr)\n\n        return digraph", "response": "Compute a directed graph of the chemical system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot time series LFPs and CSDs with signal variances as function of depth for the cases with all synapses intact, or knocking out excitatory input or inhibitory input to the postsynaptic target region args: :: fig : axes : savefolders : list of simulation output folders T : list of ints, first and last time sample transient : int, duration of transient period returns: :: matplotlib.figure.Figure object", "response": "def fig_exc_inh_contrib(fig, axes, params, savefolders, T=[800, 1000], transient=200,\n                        panel_labels = 'FGHIJ', show_xlabels=True):\n    '''\n    plot time series LFPs and CSDs with signal variances as function of depth\n    for the cases with all synapses intact, or knocking out excitatory\n    input or inhibitory input to the postsynaptic target region\n    \n    args:\n    ::\n        fig : \n        axes :  \n        savefolders : list of simulation output folders\n        T : list of ints, first and last time sample\n        transient : int, duration of transient period\n        \n    returns:\n    ::\n        \n        matplotlib.figure.Figure object\n    \n    '''\n    # params = multicompartment_params()\n    # ana_params = analysis_params.params()\n\n    \n    #file name types\n    file_names = ['CSDsum.h5', 'LFPsum.h5']\n    \n    #panel titles\n    panel_titles = [\n        'LFP&CSD\\nexc. syn.',\n        'LFP&CSD\\ninh. syn.',\n        'LFP&CSD\\ncompound',\n        'CSD variance',\n        'LFP variance',]\n    \n    #labels\n    labels = [\n        'exc. syn.',\n        'inh. syn.',\n        'SUM']\n    \n    #some colors for traces\n    if analysis_params.bw:\n        colors = ['k', 'gray', 'k']\n        # lws = [0.75, 0.75, 1.5]\n        lws = [1.25, 1.25, 1.25]\n    else:\n        colors = [analysis_params.colorE, analysis_params.colorI, 'k']\n        # colors = 'rbk'\n        # lws = [0.75, 0.75, 1.5]\n        lws = [1.25, 1.25, 1.25]\n\n    \n    #scalebar labels\n    units = ['$\\mu$A mm$^{-3}$', 'mV']\n    \n    #depth of each contact site\n    depth = params.electrodeParams['z']\n\n\n    # #set up figure\n    # #figure aspect\n    # ana_params.set_PLOS_2column_fig_style(ratio=0.5)\n    # fig, axes = plt.subplots(1,5)\n    # fig.subplots_adjust(left=0.06, right=0.96, wspace=0.4, hspace=0.2)\n    \n    #clean up\n    for ax in axes.flatten():\n        phlp.remove_axis_junk(ax)\n\n\n    for i, file_name in enumerate(file_names):\n        #get the global data scaling bar range for use in latter plots\n        #TODO: find nicer solution without creating figure\n        dum_fig, dum_ax = plt.subplots(1)\n        vlim_LFP = 0\n        vlim_CSD = 0\n        for savefolder in savefolders:\n            vlimround0 = plot_signal_sum(dum_ax, params,\n                                         os.path.join(os.path.split(params.savefolder)[0], savefolder, file_name),\n                                         rasterized=False)\n            if vlimround0 > vlim_LFP:\n                vlim_LFP = vlimround0\n            im = plot_signal_sum_colorplot(dum_ax, params, os.path.join(os.path.split(params.savefolder)[0], savefolder, file_name),\n                                           cmap=plt.get_cmap('gray', 21) if analysis_params.bw else plt.get_cmap('bwr_r', 21),\n                                           rasterized=False)\n            if abs(im.get_array()).max() > vlim_CSD:\n                vlim_CSD = abs(im.get_array()).max()\n                                                  \n        plt.close(dum_fig)\n\n\n        for j, savefolder in enumerate(savefolders):\n            ax = axes[j]\n            if i == 1:\n                plot_signal_sum(ax, params, os.path.join(os.path.split(params.savefolder)[0], savefolder, file_name),\n                            unit=units[i], T=T,\n                            color='k',\n                            # color='k' if analysis_params.bw else colors[j],\n                            vlimround=vlim_LFP, rasterized=False)\n            elif i == 0:\n                im = plot_signal_sum_colorplot(ax, params, os.path.join(os.path.split(params.savefolder)[0], savefolder, file_name),\n                              unit=r'($\\mu$Amm$^{-3}$)', T=T, ylabels=True,\n                              colorbar=False,\n                              fancy=False, cmap=plt.get_cmap('gray', 21) if analysis_params.bw else plt.get_cmap('bwr_r', 21),\n                              absmax=vlim_CSD,\n                              rasterized=False)\n            \n            \n            ax.axis((T[0], T[1], -1550, 50))\n            ax.set_title(panel_titles[j], va='baseline')\n            \n            if i == 0:\n                phlp.annotate_subplot(ax, ncols=1, nrows=1, letter=panel_labels[j])\n            if j != 0:\n                ax.set_yticklabels([])\n            \n            if i == 0:#and j == 2:\n                cb = phlp.colorbar(fig, ax, im,\n                                   width=0.05, height=0.5,\n                                   hoffset=-0.05, voffset=0.5)\n                cb.set_label('($\\mu$Amm$^{-3}$)', labelpad=0.)\n            ax.xaxis.set_major_locator(plt.MaxNLocator(3))\n            if show_xlabels:\n                ax.set_xlabel(r'$t$ (ms)', labelpad=0.)\n            else:\n                ax.set_xlabel('')\n\n            \n    #power in CSD\n    ax = axes[3]\n    datas = []    \n    for j, savefolder in enumerate(savefolders):\n        f = h5py.File(os.path.join(os.path.split(params.savefolder)[0], savefolder, 'CSDsum.h5'))\n        var = f['data'].value[:, transient:].var(axis=1)\n        ax.semilogx(var, depth,\n                    color=colors[j], label=labels[j], lw=lws[j], clip_on=False)\n        datas.append(f['data'].value[:, transient:])\n        f.close()\n    #control variances\n    vardiff = datas[0].var(axis=1) + datas[1].var(axis=1) + np.array([2*np.cov(x,y)[0,1] for (x,y) in zip(datas[0], datas[1])]) - datas[2].var(axis=1)\n    #ax.semilogx(abs(vardiff), depth, color='gray', lw=1, label='control')\n    ax.axis(ax.axis('tight'))\n    ax.set_ylim(-1550, 50)\n    ax.set_yticks(-np.arange(16)*100)\n    if show_xlabels:\n        ax.set_xlabel(r'$\\sigma^2$ ($(\\mu$Amm$^{-3})^2$)', labelpad=0.)\n    ax.set_title(panel_titles[3], va='baseline')\n    phlp.annotate_subplot(ax, ncols=1, nrows=1, letter=panel_labels[3])\n    ax.set_yticklabels([])\n\n\n    #power in LFP\n    ax = axes[4]\n\n    datas = []\n    for j, savefolder in enumerate(savefolders):\n        f = h5py.File(os.path.join(os.path.split(params.savefolder)[0], savefolder, 'LFPsum.h5'))\n        var = f['data'].value[:, transient:].var(axis=1)\n        ax.semilogx(var, depth,\n                    color=colors[j], label=labels[j], lw=lws[j], clip_on=False)\n        datas.append(f['data'].value[:, transient:])\n        f.close()\n    #control variances\n    vardiff = datas[0].var(axis=1) + datas[1].var(axis=1) + np.array([2*np.cov(x,y)[0,1] for (x,y) in zip(datas[0], datas[1])]) - datas[2].var(axis=1)\n    ax.axis(ax.axis('tight'))\n    ax.set_ylim(-1550, 50)\n    ax.set_yticks(-np.arange(16)*100)\n    if show_xlabels:\n        ax.set_xlabel(r'$\\sigma^2$ (mV$^2$)', labelpad=0.)\n    ax.set_title(panel_titles[4], va='baseline')\n    phlp.annotate_subplot(ax, ncols=1, nrows=1, letter=panel_labels[4])\n\n    ax.legend(bbox_to_anchor=(1.3, 1.0), frameon=False)\n    ax.set_yticklabels([])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a cclib file and returns an Atoms object.", "response": "def read_cclib(value, name=None):\n    \"\"\"\n    Create an `Atoms` object from data attributes parsed by cclib.\n\n    `cclib <https://cclib.github.io/>`_ is an open source library, written in\n    Python, for parsing and interpreting the results (logfiles) of\n    computational chemistry packages.\n\n    Parameters\n    ----------\n    value : `str`, `cclib.parser.logfileparser.Logfile`, `cclib.parser.data.ccData`\n        A path to a logfile, or either a cclib job object (i.e., from\n        `cclib.ccopen`), or cclib data object (i.e., from ``job.parse()``).\n    name : `str`, optional\n        Name for chemical species. If not given, this is set to the logfile\n        path, if known. Chemical equations mention this name when refering to\n        the returned object.\n\n    Returns\n    -------\n    molecule : `Atoms`\n        All attributes obtainable by cclib are made available as attributes in\n        the returned object.\n\n    Examples\n    --------\n    >>> from pyrrole.atoms import read_cclib\n    >>> molecule = read_cclib('data/pyrrolate/pyrrole.out')\n    >>> molecule.atomnos\n    array([6, 6, 6, 6, 7, 1, 1, 1, 1, 1], dtype=int32)\n    >>> molecule.charge\n    0\n\n    \"\"\"\n    if isinstance(value, _logfileparser.Logfile):\n        # TODO: test this case.\n        jobfilename = value.filename\n        ccdata = value.parse()\n    elif isinstance(value, _data.ccData):\n        # TODO: test this case.\n        jobfilename = None\n        ccdata = value\n    else:\n        # TODO: test this case.\n        ccobj = _cclib.ccopen(value)\n        jobfilename = ccobj.filename\n        ccdata = ccobj.parse()\n\n    if name is None:\n        name = jobfilename\n\n    attributes = ccdata.getattributes()\n    attributes.update({\n        'name': name,\n        'jobfilename': jobfilename,\n    })\n\n    return Atoms(attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a Pybel molecule from a string or file.", "response": "def read_pybel(value, name=None):\n    \"\"\"\n    Create an `Atoms` object from content parsed by Pybel.\n\n    `Pybel <https://openbabel.org/docs/dev/UseTheLibrary/Python_Pybel.html>`_\n    is a Python module that simplifies access to the OpenBabel API, a chemical\n    toolbox designed to speak the many languages of chemical data. It\u2019s an\n    open, collaborative project allowing anyone to search, convert, analyze, or\n    store data from molecular modeling, chemistry, solid-state materials,\n    biochemistry, and related areas.\n\n    Parameters\n    ----------\n    value : `str`, `pybel.Molecule`, `openbabel.OBMol`\n        A path to a file, or either a Pybel Molecule object, or OpenBabel\n        OBMol.\n    name : `str`, optional\n        Name for chemical species. If not given, this is set to the file path,\n        if known. Chemical equations mention this name when refering to the\n        returned object.\n\n    Returns\n    -------\n    molecule : `Atoms`\n        All attributes convertible from Pybel to cclib are made available as\n        attributes in the returned object.\n\n    Notes\n    -----\n    The following attributes are converted from Pybel to cclib: `atomcoords`,\n    `atommasses`, `atomnos`, `natom`, `charge` and `mult`. One must keep in\n    mind that `charge` and `mult` are not always reliable, since these are\n    often calculated from atomic formal charges.\n\n    Examples\n    --------\n    >>> from pyrrole.atoms import read_pybel\n    >>> molecule = read_pybel('data/pyrrolate/pyrrole.xyz')\n    >>> molecule.atomnos\n    array([6, 6, 6, 6, 7, 1, 1, 1, 1, 1], dtype=int32)\n    >>> molecule.natom\n    10\n    >>> molecule.charge\n    0\n\n    \"\"\"\n    if isinstance(value, _pb.Molecule):\n        # TODO: test this case.\n        jobfilename = None\n        charge, mult = value.charge, value.spin\n        ccdata = _makecclib(value.OBMol)\n    elif isinstance(value, _ob.OBMol):\n        # TODO: test this case.\n        jobfilename = None\n        charge, mult = value.GetTotalCharge(), value.GetTotalSpinMultiplicity()\n        ccdata = _makecclib(value)\n    else:\n        # TODO: test this case.\n        jobfilename = value\n        _, jobfilename_ext = _os.path.splitext(jobfilename)\n\n        # TODO: This only reads first structure.\n        mol = next(_pb.readfile(jobfilename_ext[1:], jobfilename))\n        charge, mult = mol.charge, mol.spin\n        ccdata = _makecclib(mol.OBMol)\n\n    if name is None:\n        name = jobfilename\n\n    attributes = ccdata.getattributes()\n    attributes.update({\n        'name': name,\n        'jobfilename': jobfilename,\n        'charge': charge,\n        'mult': mult\n    })\n\n    return Atoms(attributes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_data(*args):\n    def _prepare_data(data):\n        if not isinstance(data, _pd.DataFrame):\n            try:\n                data = _pd.DataFrame([data.to_series()])\n            except AttributeError:\n                data = _pd.DataFrame([Atoms(data).to_series()])\n        if data.index.name != \"name\":\n            if \"name\" not in data.columns:\n                data[\"name\"] = None\n            data = data.set_index(\"name\")\n        return data.reset_index()\n    args = map(_prepare_data, args)\n\n    dataframe = _pd.concat(args, sort=False)\n    return dataframe.set_index(\"name\")", "response": "Produce a single data object from an arbitrary number of different objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_pybel(self):\n        # TODO: This only exports last geometry by default.\n        obmol = _makeopenbabel(self.atomcoords, self.atomnos, self.charge,\n                               self.mult)\n\n        title = self.name or \"\"\n        if 'scfenergies' in self.attributes:\n            title += \", scfenergy={} eV\".format(self.scfenergies[-1])\n        obmol.SetTitle(title)\n\n        # TODO: make a test for this function.\n        return _pb.Molecule(obmol)", "response": "Produce a Pybel Molecule object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns a macro and returns a list of output_files.", "response": "def run(macro, output_files=[], force_close=True):\n    \"\"\"\n    Runs Fiji with the suplied macro. Output of Fiji can be viewed by\n    setting environment variable `DEBUG=fijibin`.\n\n    Parameters\n    ----------\n    macro : string or list of strings\n        IJM-macro(s) to run. If list of strings, it will be joined with\n        a space, so all statements should end with ``;``.\n    output_files : list\n        Files to check if exists after macro has been run. Files specified that\n        do not exist after macro is done will print a warning message.\n    force_close : bool\n        Will add ``eval(\"script\", \"System.exit(42);\");`` to end of macro. Exit\n        code 42 is used to overcome that errors in macro efficiently will exit\n        Fiji with error code 0. In other words, if this line in the macro is\n        reached, the macro has most probably finished without errors. This\n        is the default behaviour.\n\n        One should also note that Fiji doesn't terminate right away if\n        ``System.exit()`` is left out, and it may take several minutes for\n        Fiji to close.\n\n    Returns\n    -------\n    int\n        Files from output_files which exists after running macro.\n    \"\"\"\n    if type(macro) == list:\n        macro = ' '.join(macro)\n    if len(macro) == 0:\n        print('fijibin.macro.run got empty macro, not starting fiji')\n        return _exists(output_files)\n    if force_close:\n        # make sure fiji halts immediately when done\n        # hack: use error code 42 to check if macro has run sucessfully\n        macro = macro + 'eval(\"script\", \"System.exit(42);\");'\n\n    # escape backslashes (windows file names)\n    #                 not \\ \\  not \\      g1 \\\\ g2\n    macro = re.sub(r\"([^\\\\])\\\\([^\\\\])\", r\"\\1\\\\\\\\\\2\", macro)\n\n    debug('macro {}'.format(macro))\n\n    # avoid verbose output of Fiji when DEBUG environment variable set\n    env = os.environ.copy()\n    debugging = False\n    if 'DEBUG' in env:\n        if env['DEBUG'] == 'fijibin' or env['DEBUG'] == '*':\n            debugging = True\n        del env['DEBUG']\n\n    fptr, temp_filename = mkstemp(suffix='.ijm')\n    m = os.fdopen(fptr, 'w')\n    m.write(macro)\n    m.flush() # make sure macro is written before running Fiji\n    m.close()\n\n    cmd = [fijibin.BIN, '--headless', '-macro', temp_filename]\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                            stderr=subprocess.PIPE, env=env)\n    out, err = proc.communicate()\n\n    for line in out.decode('latin1', errors='ignore').splitlines():\n        debug('stdout:' + line)\n    for line in err.decode('latin1', errors='ignore').splitlines():\n        debug('stderr:' + line)\n\n    if force_close and proc.returncode != 42:\n        print('fijibin ERROR: Fiji did not successfully ' +\n              'run macro {}'.format(temp_filename))\n        if not debugging:\n            print('fijibin Try running script with ' +\n                  '`DEBUG=fijibin python your_script.py`')\n    else:\n        # only delete if everything is ok\n        os.remove(temp_filename)\n\n\n    # return output_files which exists\n    return _exists(output_files)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a Fiji Grid/Collection stitching macro. Parameters are the same as in the plugin and are described in further detail here: http://fiji.sc/Image_Stitching#Grid.2FCollection_Stitching. **Default stitch parameters:** * Filename defined positions * Compute overlap * Subpixel accurancy * Save computation time (but use more RAM) * Fusion method: Linear blending * Regression threshold: 0.30 * Max/avg displacement threshold: 2.50 * Absolute displacement threshold: 3.50 Parameters ---------- folder : string Path to folder with images or folders with images. Example: */path/to/slide--S00/chamber--U01--V02/* filenames : string Filenames of images. Example: *field-X{xx}-Y{yy}/image-X{xx}-Y{yy}.ome.tif* x_size : int Size of grid, number of images in x direction. y_size : int Size of grid, number of images in y direction. output_filename : string Where to store fused image. Should be `.png`. x_start : int Which x position grid start with. y_start : int Which y position grid start with. overlap : number Tile overlap in percent. Fiji will find the optimal overlap, but a precise overlap assumption will decrase computation time. Returns ------- string IJM-macro.", "response": "def stitch(folder, filenames, x_size, y_size, output_filename,\n                 x_start=0, y_start=0, overlap=10):\n    \"\"\"\n    Creates a Fiji Grid/Collection stitching macro. Parameters are the same as\n    in the plugin and are described in further detail here:\n    http://fiji.sc/Image_Stitching#Grid.2FCollection_Stitching.\n\n    **Default stitch parameters:**\n\n    * Filename defined positions\n    * Compute overlap\n    * Subpixel accurancy\n    * Save computation time (but use more RAM)\n    * Fusion method: Linear blending\n    * Regression threshold: 0.30\n    * Max/avg displacement threshold: 2.50\n    * Absolute displacement threshold: 3.50\n\n\n    Parameters\n    ----------\n    folder : string\n        Path to folder with images or folders with images.\n        Example: */path/to/slide--S00/chamber--U01--V02/*\n    filenames : string\n        Filenames of images.\n        Example: *field-X{xx}-Y{yy}/image-X{xx}-Y{yy}.ome.tif*\n    x_size : int\n        Size of grid, number of images in x direction.\n    y_size : int\n        Size of grid, number of images in y direction.\n    output_filename : string\n        Where to store fused image. Should be `.png`.\n    x_start : int\n        Which x position grid start with.\n    y_start : int\n        Which y position grid start with.\n    overlap : number\n        Tile overlap in percent. Fiji will find the optimal overlap, but a\n        precise overlap assumption will decrase computation time.\n\n    Returns\n    -------\n    string\n        IJM-macro.\n    \"\"\"\n\n    macro = []\n    macro.append('run(\"Grid/Collection stitching\",')\n    macro.append('\"type=[Filename defined position]')\n    macro.append('order=[Defined by filename         ]')\n    macro.append('grid_size_x={}'.format(x_size))\n    macro.append('grid_size_y={}'.format(y_size))\n    macro.append('tile_overlap={}'.format(overlap))\n    macro.append('first_file_index_x={}'.format(x_start))\n    macro.append('first_file_index_y={}'.format(y_start))\n    macro.append('directory=[{}]'.format(folder))\n    macro.append('file_names=[{}]'.format(filenames))\n    macro.append('output_textfile_name=TileConfiguration.txt')\n    macro.append('fusion_method=[Linear Blending]')\n    macro.append('regression_threshold=0.20')\n    macro.append('max/avg_displacement_threshold=2.50')\n    macro.append('absolute_displacement_threshold=3.50')\n    macro.append('compute_overlap')\n    macro.append('subpixel_accuracy')\n    macro.append('computation_parameters=[Save computation time (but use more RAM)]')\n    # use display, such that we can specify output filename\n    # this is 'Fused and display' for previous stitching version!!\n    macro.append('image_output=[Fuse and display]\");')\n    # save to png\n    macro.append('selectWindow(\"Fused\");')\n    macro.append('saveAs(\"PNG\", \"{}\");'.format(output_filename))\n    macro.append('close();')\n\n    return ' '.join(macro)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if every filename exists. If not print an error and remove the item from the list.", "response": "def _exists(filenames):\n    \"\"\"Check if every filename exists. If not, print an error\n    message and remove the item from the list.\n\n    Parameters\n    ----------\n    filenames : list\n        List of filenames to check for existence.\n\n    Returns\n    -------\n    list\n        Filtered list of filenames that exists.\n    \"\"\"\n    exists = []\n    for filename in filenames:\n        if os.path.isfile(filename):\n            exists.append(filename)\n        else:\n            print('fijibin ERROR missing output file {}'.format(filename))\n\n    return exists"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop an audio streaming session", "response": "def send_stop_audio(self):\n        '''\n        Stop an audio streaming session\n        '''\n        assert self._session_id != VoiceService.SESSION_ID_INVALID\n\n        self._pebble.send_packet(AudioStream(session_id=self._session_id, data=StopTransfer()))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend the result of setting up a dictation session requested by the watch .", "response": "def send_session_setup_result(self, result, app_uuid=None):\n        '''\n        Send the result of setting up a dictation session requested by the watch\n\n        :param result:  result of setting up the session\n        :type result: .SetupResult\n        :param app_uuid: UUID of app that initiated the session\n        :type app_uuid: uuid.UUID\n        '''\n        assert self._session_id != VoiceService.SESSION_ID_INVALID\n        assert isinstance(result, SetupResult)\n\n        flags = 0\n        if app_uuid is not None:\n            assert isinstance(app_uuid, uuid.UUID)\n            flags |= Flags.AppInitiated\n\n        logger.debug(\"Sending session setup result (result={}\".format(result) +\n                     \", app={})\".format(app_uuid) if app_uuid is not None else \")\")\n\n        self._pebble.send_packet(VoiceControlResult(flags=flags, data=SessionSetupResult(\n                session_type=SessionType.Dictation, result=result)))\n\n        if result != SetupResult.Success:\n            self._session_id = VoiceService.SESSION_ID_INVALID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_dictation_result(self, result, sentences=None, app_uuid=None):\n        '''\n        Send the result of a dictation session\n\n        :param result: Result of the session\n        :type result: DictationResult\n        :param sentences: list of sentences, each of which is a list of words and punctuation\n        :param app_uuid: UUID of app that initiated the session\n        :type app_uuid: uuid.UUID\n        '''\n\n        assert self._session_id != VoiceService.SESSION_ID_INVALID\n        assert isinstance(result, TranscriptionResult)\n\n        transcription = None\n        if result == TranscriptionResult.Success:\n            if len(sentences) > 0:\n                s_list = []\n                for s in sentences:\n                    words = [Word(confidence=100, data=w) for w in s]\n                    s_list.append(Sentence(words=words))\n                transcription = Transcription(transcription=SentenceList(sentences=s_list))\n\n        flags = 0\n        if app_uuid is not None:\n            assert isinstance(app_uuid, uuid.UUID)\n            flags |= Flags.AppInitiated\n\n        attributes = []\n        if app_uuid is not None:\n            assert isinstance(app_uuid, uuid.UUID)\n            attributes.append(Attribute(id=AttributeType.AppUuid, data=AppUuid(uuid=app_uuid)))\n\n        if transcription is not None:\n            attributes.append(Attribute(id=AttributeType.Transcription, data=transcription))\n\n        logger.debug(\"Sending dictation result (result={}\".format(result) +\n                     \", app={})\".format(app_uuid) if app_uuid is not None else \")\")\n        self._pebble.send_packet(VoiceControlResult(flags=flags, data=DictationResult(\n            session_id=self._session_id, result=result, attributes=AttributeList(dictionary=attributes))))\n        self._session_id = VoiceService.SESSION_ID_INVALID", "response": "Send dictation result to the client."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_ipython_extension(ip):\n    #ip = get_ipython()\n    ip.register_magics(CustomMagics)\n    # enable C# (CSHARP) highlight\n    patch = (\"IPython.config.cell_magic_highlight['clrmagic'] = \"\n             \"{'reg':[/^%%CS/]};\")\n    js = display.Javascript(data=patch,\n                            lib=[\"https://github.com/codemirror/CodeMirror/blob/master/mode/clike/clike.js\"])", "response": "load an IPython extension"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncache version of XmppBackendBase. get_api_version.", "response": "def api_version(self):\n        \"\"\"Cached version of :py:func:`~xmpp_backends.base.XmppBackendBase.get_api_version`.\"\"\"\n\n        now = datetime.utcnow()\n\n        if self.version_cache_timestamp and self.version_cache_timestamp + self.version_cache_timeout > now:\n            return self.version_cache_value  # we have a cached value\n\n        self.version_cache_value = self.get_api_version()\n\n        if self.minimum_version and self.version_cache_value < self.minimum_version:\n            raise NotSupportedError('%s requires ejabberd >= %s' % (self.__class__.__name__,\n                                                                    self.minimum_version))\n\n        self.version_cache_timestamp = now\n        return self.version_cache_value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_reservation(self, username, domain, email=None):\n        password = self.get_random_password()\n        self.create(username=username, domain=domain, password=password, email=email)", "response": "Reserve a new user account."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef confirm_reservation(self, username, domain, password, email=None):\n        self.set_password(username=username, domain=domain, password=password)\n        if email is not None:\n            self.set_email(username=username, domain=domain, email=email)", "response": "Confirm a reservation for a username."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef block_user(self, username, domain):\n        self.set_password(username, domain, self.get_random_password())", "response": "Block the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_connection_string(self, connection):\n        # TODO: Websockets, HTTP Polling\n        if connection == 'c2s_tls':\n            return CONNECTION_XMPP, True, False\n        elif connection == 'c2s_compressed_tls':\n            return CONNECTION_XMPP, True, True\n        elif connection == 'http_bind':\n            return CONNECTION_HTTP_BINDING, None, None\n        elif connection == 'c2s':\n            return CONNECTION_XMPP, False, False\n        log.warn('Could not parse connection string \"%s\"', connection)\n        return CONNECTION_UNKNOWN, True, True", "response": "Parse a connection string into a tuple of the appropriate type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_ip_address(self, ip_address):\n        if ip_address.startswith('::FFFF:'):\n            ip_address = ip_address[7:]\n        if six.PY2 and isinstance(ip_address, str):\n            # ipaddress constructor does not eat str in py2 :-/\n            ip_address = ip_address.decode('utf-8')\n\n        return ipaddress.ip_address(ip_address)", "response": "Parse an IP address as returned by the connected_users_info or user_sessions_info API calls."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads one message from the watch blocking until a message is available.", "response": "def pump_reader(self):\n        \"\"\"\n        Synchronously reads one message from the watch, blocking until a message is available.\n        All events caused by the message read will be processed before this method returns.\n\n        .. note::\n           You usually don't need to invoke this method manually; instead, see :meth:`run_sync` and :meth:`run_async`.\n        \"\"\"\n        origin, message = self.transport.read_packet()\n        if isinstance(origin, MessageTargetWatch):\n            self._handle_watch_message(message)\n        else:\n            self._broadcast_transport_message(origin, message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun the message loop until the Pebble disconnects.", "response": "def run_sync(self):\n        \"\"\"\n        Runs the message loop until the Pebble disconnects. This method will block until the watch disconnects or\n        a fatal error occurs.\n\n        For alternatives that don't block forever, see :meth:`pump_reader` and :meth:`run_async`.\n        \"\"\"\n        while self.connected:\n            try:\n                self.pump_reader()\n            except PacketDecodeError as e:\n                logger.warning(\"Packet decode failed: %s\", e)\n            except ConnectionError:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_async(self):\n        thread = threading.Thread(target=self.run_sync)\n        thread.daemon = True\n        thread.name = \"PebbleConnection\"\n        thread.start()\n        self.fetch_watch_info()", "response": "Runs the message loop until the Pebble disconnects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess a binary message received from the watch and broadcasts relevant events.", "response": "def _handle_watch_message(self, message):\n        \"\"\"\n        Processes a binary message received from the watch and broadcasts the relevant events.\n\n        :param message: A raw message from the watch, without any transport framing.\n        :type message: bytes\n        \"\"\"\n        if self.log_protocol_level is not None:\n            logger.log(self.log_protocol_level, \"<- %s\", hexlify(message).decode())\n        message = self.pending_bytes + message\n\n        while len(message) >= 4:\n            try:\n                packet, length = PebblePacket.parse_message(message)\n            except IncompleteMessage:\n                self.pending_bytes = message\n                break\n            except:\n                # At this point we've failed to deconstruct the message via normal means, but we don't want to end\n                # up permanently desynced (because we wiped a partial message), nor do we want to get stuck (because\n                # we didn't wipe anything). We therefore parse the packet length manually and skip ahead that far.\n                # If the expected length is 0, we wipe everything to ensure forward motion (but we are quite probably\n                # screwed).\n                expected_length, = struct.unpack('!H', message[:2])\n                if expected_length == 0:\n                    self.pending_bytes = b''\n                else:\n                    self.pending_bytes = message[expected_length + 4:]\n                raise\n\n            self.event_handler.broadcast_event(\"raw_inbound\", message[:length])\n            if self.log_packet_level is not None:\n                logger.log(self.log_packet_level, \"<- %s\", packet)\n            message = message[length:]\n            self.event_handler.broadcast_event((_EventType.Watch, type(packet)), packet)\n            if length == 0:\n                break\n        self.pending_bytes = message"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _broadcast_transport_message(self, origin, message):\n        self.event_handler.broadcast_event((_EventType.Transport, type(origin), type(message)), message)", "response": "Broadcasts an event originating from a transport that does not represent a message from the Pebble."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_transport_endpoint(self, origin, message_type, handler):\n        return self.event_handler.register_handler((_EventType.Transport, origin, message_type), handler)", "response": "Register a handler for a message received from a transport that does not indicate a message from the connected\n        Pebble."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a handler for a message received from the Pebble.", "response": "def register_endpoint(self, endpoint, handler):\n        \"\"\"\n        Register a handler for a message received from the Pebble.\n\n        :param endpoint: The type of :class:`.PebblePacket` that is being listened for.\n        :type endpoint: .PacketType\n        :param handler: A callback to be called when a message is received.\n        :type handler: callable\n        :return: A handle that can be passed to :meth:`unregister_endpoint` to remove the handler.\n        \"\"\"\n        return self.event_handler.register_handler((_EventType.Watch, endpoint), handler)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_from_endpoint(self, endpoint, timeout=15):\n        return self.event_handler.wait_for_event((_EventType.Watch, endpoint), timeout=timeout)", "response": "Blocking read from an endpoint. Will block until a message is received or the timeout is reached."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_transport_message(self, origin, message_type, timeout=15):\n        return self.event_handler.wait_for_event((_EventType.Transport, origin, message_type), timeout=timeout)", "response": "Blocking read of a transport message from the Pebble."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a message to the Pebble.", "response": "def send_packet(self, packet):\n        \"\"\"\n        Sends a message to the Pebble.\n\n        :param packet: The message to send.\n        :type packet: .PebblePacket\n        \"\"\"\n        if self.log_packet_level:\n            logger.log(self.log_packet_level, \"-> %s\", packet)\n        serialised = packet.serialise_packet()\n        self.event_handler.broadcast_event(\"raw_outbound\", serialised)\n        self.send_raw(serialised)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_and_read(self, packet, endpoint, timeout=15):\n        queue = self.get_endpoint_queue(endpoint)\n        self.send_packet(packet)\n        try:\n            return queue.get(timeout=timeout)\n        finally:\n            queue.close()", "response": "Sends a packet to the specified endpoint and returns the next response received from that endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_raw(self, message):\n        if self.log_protocol_level:\n            logger.log(self.log_protocol_level, \"-> %s\", hexlify(message).decode())\n        self.transport.send_packet(message)", "response": "Sends a raw binary message to the Pebble."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches the watch info from the watch server.", "response": "def fetch_watch_info(self):\n        \"\"\"\n        This method should be called before accessing :attr:`watch_info`, :attr:`firmware_version`\n        or :attr:`watch_platform`. Blocks until it has fetched the required information.\n        \"\"\"\n        self._watch_info = self.send_and_read(WatchVersion(data=WatchVersionRequest()), WatchVersion).data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproviding information on the connected Pebble including its firmware version language capabilities etc.", "response": "def firmware_version(self):\n        \"\"\"\n        Provides information on the connected Pebble, including its firmware version, language, capabilities, etc.\n\n        .. note:\n           This is a blocking call if :meth:`fetch_watch_info` has not yet been called, which could lead to deadlock\n           if called in an endpoint callback.\n\n        :rtype: .WatchVersionResponse\n        \"\"\"\n        version = self.watch_info.running.version_tag[1:]\n        parts = version.split('-', 1)\n        points = [int(x) for x in parts[0].split('.')]\n        while len(points) < 3:\n            points.append(0)\n        if len(parts) == 2:\n            suffix = parts[1]\n        else:\n            suffix = ''\n        return FirmwareVersion(*(points + [suffix]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating db from list of gdf files globaterater", "response": "def create(self, re='brunel-py-ex-*.gdf', index=True):\n        \"\"\"\n        Create db from list of gdf file glob\n\n\n        Parameters\n        ----------\n        re : str\n            File glob to load.\n        index : bool\n            Create index on neurons for speed.\n                    \n        \n        Returns\n        -------\n        None\n        \n        \n        See also\n        --------\n        sqlite3.connect.cursor, sqlite3.connect\n        \n        \"\"\"\n        self.cursor.execute('CREATE TABLE IF NOT EXISTS spikes (neuron INT UNSIGNED, time REAL)')\n\n        tic = now()\n        for f in glob.glob(re):\n            print(f)\n            while True:\n                try:\n                    for data in self._blockread(f):\n                        self.cursor.executemany('INSERT INTO spikes VALUES (?, ?)', data)\n                        self.conn.commit()\n                except:\n                    continue\n                break                \n\n        toc = now()\n        if self.debug: print('Inserts took %g seconds.' % (toc-tic))\n\n        # Optionally, create index for speed\n        if index:\n            tic = now()\n            self.cursor.execute('CREATE INDEX neuron_index on spikes (neuron)')\n            toc = now()\n            if self.debug: print('Indexed db in %g seconds.' % (toc-tic))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating db from list of arrays.", "response": "def create_from_list(self, re=[], index=True):\n        \"\"\"\n        Create db from list of arrays.\n\n\n        Parameters\n        ----------\n        re : list\n            Index of element is cell index, and element `i` an array of spike times in ms.\n        index : bool\n            Create index on neurons for speed.\n        \n        \n        Returns\n        -------\n        None\n        \n        \n        See also\n        --------\n        sqlite3.connect.cursor, sqlite3.connect\n        \n        \"\"\"\n        self.cursor.execute('CREATE TABLE IF NOT EXISTS spikes (neuron INT UNSIGNED, time REAL)')\n\n        tic = now()\n        i = 0\n        for x in re:\n            data = list(zip([i] * len(x), x))\n            self.cursor.executemany('INSERT INTO spikes VALUES (?, ?)', data)\n            i += 1\n        self.conn.commit()\n        toc = now()\n        if self.debug: print('Inserts took %g seconds.' % (toc-tic))\n\n        # Optionally, create index for speed\n        if index:\n            tic = now()\n            self.cursor.execute('CREATE INDEX neuron_index on spikes (neuron)')\n            toc = now()\n            if self.debug: print('Indexed db in %g seconds.' % (toc-tic))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select(self, neurons):\n        s = []\n        for neuron in neurons:\n            self.cursor.execute('SELECT time FROM spikes where neuron = %d' % neuron)\n            sel = self.cursor.fetchall()\n            spikes = np.array(sel).flatten()\n            s.append(spikes)\n        return s", "response": "Select spike trains.\n\n\n        Parameters\n        ----------\n        neurons : numpy.ndarray or list\n            Array of list of neurons.\n\n\n        Returns\n        -------\n        list\n            List of numpy.ndarray objects containing spike times.\n\n\n        See also\n        --------\n        sqlite3.connect.cursor"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef interval(self, T=[0, 1000]):\n        self.cursor.execute('SELECT * FROM spikes WHERE time BETWEEN %f AND %f' % tuple(T))\n        sel = self.cursor.fetchall()\n        return sel", "response": "Get all spikes in a time interval T."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of neuron indices.", "response": "def neurons(self):\n        \"\"\"\n        Return list of neuron indices.\n\n\n        Parameters\n        ----------\n        None\n        \n\n        Returns\n        -------\n        list\n            list of neuron indices\n        \n        \n        See also\n        --------\n        sqlite3.connect.cursor\n        \n        \"\"\"\n        self.cursor.execute('SELECT DISTINCT neuron FROM spikes ORDER BY neuron')\n        sel = self.cursor.fetchall()\n        return np.array(sel).flatten()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn total number of spikes in the database.", "response": "def num_spikes(self):\n        \"\"\"\n        Return total number of spikes.\n\n\n        Parameters\n        ----------\n        None\n        \n        \n        Returns\n        -------\n        list\n\n        \"\"\"\n        self.cursor.execute('SELECT Count(*) from spikes')\n        rows = self.cursor.fetchall()[0]\n        # Check against 'wc -l *ex*.gdf'\n        if self.debug: print('DB has %d spikes' % rows)\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a scatter plot of the contents of the database with entries on the interval T.", "response": "def plotstuff(self, T=[0, 1000]):\n        \"\"\"\n        Create a scatter plot of the contents of the database,\n        with entries on the interval T.\n\n\n        Parameters\n        ----------\n        T : list\n            Time interval.\n        \n        \n        Returns\n        -------\n        None\n        \n        \n        See also\n        --------\n        GDF.select_neurons_interval\n        \"\"\"\n\n        fig = plt.figure(figsize=(10,10))\n\n        ax = fig.add_subplot(111)\n\n        neurons = self.neurons()\n        i = 0\n        for x in self.select_neurons_interval(neurons, T):\n            ax.plot(x, np.zeros(x.size) + neurons[i], 'o',\n                    markersize=1, markerfacecolor='k', markeredgecolor='k',\n                    alpha=0.25)\n            i += 1\n        ax.set_xlabel('time (ms)')\n        ax.set_ylabel('neuron ID')\n        ax.set_xlim(T[0], T[1])\n        ax.set_ylim(neurons.min(), neurons.max())\n        ax.set_title('database content on T = [%.0f, %.0f]' % (T[0], T[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrepresenting a number - string in the form of a tuple of digits.", "response": "def represent_as_tuple(string):\r\n    \"\"\"\r\n    Represent a number-string in the form of a tuple of digits.\r\n    \"868.0F\" -> (8, 6, 8, '.', 0, 15)\r\n\r\n    Args:\r\n        string - Number represented as a string of digits.\r\n    Returns:\r\n        Number represented as an iterable container of digits\r\n\r\n    >>> represent_as_tuple('868.0F')\r\n    (8, 6, 8, '.', 0, 15)\r\n    \"\"\"\r\n    keep = (\".\", \"[\", \"]\")\r\n    return tuple(str_digit_to_int(c) if c not in keep else c for c in string)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef represent_as_string(iterable):\r\n    keep = (\".\", \"[\", \"]\")\r\n    return \"\".join(tuple(int_to_str_digit(i) if i not in keep\r\n                   else i for i in iterable))", "response": "Represent a number in the form of a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef digit(decimal, digit, input_base=10):\r\n    if decimal == 0:\r\n        return 0\r\n    if digit != 0:\r\n        return (decimal // (input_base ** digit)) % input_base\r\n    else:\r\n        return decimal % input_base", "response": "Returns the value of an integer at a specific digit when represented in base 10."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of digits in a specific base.", "response": "def digits(number, base=10):\r\n    \"\"\"\r\n    Determines the number of digits of a number in a specific base.\r\n\r\n    Args:\r\n        number(int): An integer number represented in base 10.\r\n        base(int): The base to find the number of digits.\r\n\r\n    Returns:\r\n        Number of digits when represented in a particular base (integer).\r\n\r\n    Examples:\r\n        >>> digits(255)\r\n        3\r\n        >>> digits(255, 16)\r\n        2\r\n        >>> digits(256, 16)\r\n        3\r\n        >>> digits(256, 2)\r\n        9\r\n        >>> digits(0, 678363)\r\n        0\r\n        >>> digits(-1, 678363)\r\n        0\r\n        >>> digits(12345, 10)\r\n        5\r\n    \"\"\"\r\n    if number < 1:\r\n        return 0\r\n    digits = 0\r\n    n = 1\r\n    while(number >= 1):\r\n        number //= base\r\n        digits += 1\r\n    return digits"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef integer_fractional_parts(number):\r\n    radix_point = number.index(\".\")\r\n    integer_part = number[:radix_point]\r\n    fractional_part = number[radix_point:]\r\n    return(integer_part, fractional_part)", "response": "Returns a tuple of the integer and fractional parts of a number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_base_10_int(decimal, output_base=10):\r\n    if decimal <= 0:\r\n        return (0,)\r\n    if output_base == 1:\r\n        return (1,) * decimal\r\n    length = digits(decimal, output_base)\r\n    converted = tuple(digit(decimal, i, output_base) for i in range(length))\r\n    return converted[::-1]", "response": "Converts a decimal integer to a specific base."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_base_10_int(n, input_base):\r\n    return sum(c * input_base ** i for i, c in enumerate(n[::-1]))", "response": "Converts an integer in any base into base 10."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a fractional part of a number from any base to any base.", "response": "def fractional_base(fractional_part, input_base=10, output_base=10,\r\n                    max_depth=100):\r\n    \"\"\"\r\n    Convert the fractional part of a number from any base to any base.\r\n\r\n    Args:\r\n        fractional_part(iterable container): The fractional part of a number in\r\n            the following form:    ( \".\", int, int, int, ...)\r\n        input_base(int): The base to convert from (defualt 10).\r\n        output_base(int): The base to convert to (default 10).\r\n        max_depth(int): The maximum number of decimal digits to output.\r\n\r\n    Returns:\r\n        The converted number as a tuple of digits.\r\n\r\n    Example:\r\n        >>> fractional_base((\".\", 6,),10,16,10)\r\n        ('.', 9, 9, 9, 9, 9, 9, 9, 9, 9, 9)\r\n    \"\"\"\r\n    fractional_part = fractional_part[1:]\r\n    fractional_digits = len(fractional_part)\r\n    numerator = 0\r\n    for i, value in enumerate(fractional_part, 1):\r\n        numerator += value * input_base ** (fractional_digits - i)\r\n    denominator = input_base ** fractional_digits\r\n    i = 1\r\n    digits = []\r\n    while(i < max_depth + 1):\r\n        numerator *= output_base ** i\r\n        digit = numerator // denominator\r\n        numerator -= digit * denominator\r\n        denominator *= output_base ** i\r\n        digits.append(digit)\r\n        i += 1\r\n        greatest_common_divisor = gcd(numerator, denominator)\r\n        numerator //= greatest_common_divisor\r\n        denominator //= greatest_common_divisor\r\n    return (\".\",) + tuple(digits)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef truncate(n):\r\n    count = 0\r\n    for digit in n[-1::-1]:\r\n        if digit != 0:\r\n            break\r\n        count += 1\r\n    return n[:-count] if count > 0 else n", "response": "Returns a new number n with all trailing zeros removed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a string character to an integer value.", "response": "def str_digit_to_int(chr):\r\n    \"\"\"\r\n    Converts a string character to a decimal number.\r\n    Where \"A\"->10, \"B\"->11, \"C\"->12, ...etc\r\n\r\n    Args:\r\n        chr(str): A single character in the form of a string.\r\n\r\n    Returns:\r\n        The integer value of the input string digit.\r\n    \"\"\"\r\n    # 0 - 9\r\n    if chr in (\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"):\r\n        n = int(chr)\r\n    else:\r\n        n = ord(chr)\r\n        # A - Z\r\n        if n < 91:\r\n            n -= 55\r\n        # a - z or higher\r\n        else:\r\n            n -= 61\r\n    return n"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a positive integer number to a single string character.", "response": "def int_to_str_digit(n):\r\n    \"\"\"\r\n    Converts a positive integer, to a single string character.\r\n    Where: 9 -> \"9\", 10 -> \"A\", 11 -> \"B\", 12 -> \"C\", ...etc\r\n\r\n    Args:\r\n        n(int): A positve integer number.\r\n\r\n    Returns:\r\n        The character representation of the input digit of value n (str).\r\n    \"\"\"\r\n    # 0 - 9\r\n    if n < 10:\r\n        return str(n)\r\n    # A - Z\r\n    elif n < 36:\r\n        return chr(n + 55)\r\n    # a - z or higher\r\n    else:\r\n        return chr(n + 61)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_recurring(number, min_repeat=5):\r\n    # Return number if it has no fractional part, or min_repeat value invalid.\r\n    if \".\" not in number or min_repeat < 1:\r\n        return number\r\n    # Seperate the number into integer and fractional parts.\r\n    integer_part, fractional_part = integer_fractional_parts(number)\r\n    # Reverse fractional part to get a sequence.\r\n    sequence = fractional_part[::-1]\r\n    # Initialize counters\r\n    # The 'period' is the number of digits in a pattern.\r\n    period = 0\r\n    # The best pattern found will be stored.\r\n    best = 0\r\n    best_period = 0\r\n    best_repeat = 0\r\n    # Find recurring pattern.\r\n    while (period < len(sequence)):\r\n        period += 1\r\n        pattern = sequence[:period]\r\n        repeat = 0\r\n        digit = period\r\n        pattern_match = True\r\n        while(pattern_match and digit < len(sequence)):\r\n            for i, pattern_digit in enumerate(pattern):\r\n                if sequence[digit + i] != pattern_digit:\r\n                    pattern_match = False\r\n                    break\r\n            else:\r\n                repeat += 1\r\n            digit += period\r\n        # Give each pattern found a rank and use the best.\r\n        rank = period * repeat\r\n        if rank > best:\r\n            best_period = period\r\n            best_repeat = repeat\r\n            best = rank\r\n    # If the pattern does not repeat often enough, return the original number.\r\n    if best_repeat < min_repeat:\r\n        return number\r\n    # Use the best pattern found.\r\n    pattern = sequence[:best_period]\r\n    # Remove the pattern from our original number.\r\n    number = integer_part + fractional_part[:-(best + best_period)]\r\n    # Ensure we are at the start of the pattern.\r\n    pattern_temp = pattern\r\n    for i, digit in enumerate(pattern):\r\n        if number[-1] == digit:\r\n                number = number[:-1]\r\n                pattern_temp = pattern_temp[1:] + (pattern_temp[0],)\r\n    pattern = pattern_temp\r\n    # Return the number with the recurring pattern enclosed with '[' and ']'.\r\n    return number + (\"[\",) + pattern[::-1] + (\"]\",)", "response": "Returns a new number that is a recurring pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expand_recurring(number, repeat=5):\r\n    if \"[\" in number:\r\n        pattern_index = number.index(\"[\")\r\n        pattern = number[pattern_index + 1:-1]\r\n        number = number[:pattern_index]\r\n        number = number + pattern * (repeat + 1)\r\n    return number", "response": "Returns a new number with the expanded recurring pattern."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if all digits in the input number are valid False otherwise.", "response": "def check_valid(number, input_base=10):\r\n    \"\"\"\r\n    Checks if there is an invalid digit in the input number.\r\n\r\n    Args:\r\n        number: An number in the following form:\r\n            (int, int, int, ... , '.' , int, int, int)\r\n            (iterable container) containing positive integers of the input base\r\n        input_base(int): The base of the input number.\r\n\r\n    Returns:\r\n        bool, True if all digits valid, else False.\r\n\r\n    Examples:\r\n        >>> check_valid((1,9,6,'.',5,1,6), 12)\r\n        True\r\n        >>> check_valid((8,1,15,9), 15)\r\n        False\r\n    \"\"\"\r\n    for n in number:\r\n        if n in (\".\", \"[\", \"]\"):\r\n            continue\r\n        elif n >= input_base:\r\n            if n == 1 and input_base == 1:\r\n                continue\r\n            else:\r\n                return False\r\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef base(number, input_base=10, output_base=10, max_depth=10,\r\n         string=False, recurring=True):\r\n    \"\"\"\r\n    Converts a number from any base to any another.\r\n\r\n    Args:\r\n        number(tuple|str|int): The number to convert.\r\n        input_base(int): The base to convert from (defualt 10).\r\n        output_base(int): The base to convert to (default 10).\r\n        max_depth(int): The maximum number of fractional digits (defult 10).\r\n        string(bool): If True output will be in string representation,\r\n            if False output will be in tuple representation (defult False).\r\n        recurring(bool): Attempt to find repeating digits in the fractional\r\n            part of a number. Repeated digits will be enclosed with \"[\" and \"]\"\r\n            (default True).\r\n    Returns:\r\n        A tuple of digits in the specified base:\r\n        (int, int, int, ... , '.' , int, int, int)\r\n        If the string flag is set to True,\r\n        a string representation will be used instead.\r\n\r\n    Raises:\r\n        ValueError if a digit value is too high for the input_base.\r\n\r\n    Example:\r\n        >>> base((1,9,6,'.',5,1,6), 17, 20)\r\n        (1, 2, 8, '.', 5, 19, 10, 7, 17, 2, 13, 13, 1, 8)\r\n    \"\"\"\r\n    # Convert number to tuple representation.\r\n    if type(number) == int or type(number) == float:\r\n        number = str(number)\r\n    if type(number) == str:\r\n        number = represent_as_tuple(number)\r\n    # Check that the number is valid for the input base.\r\n    if not check_valid(number, input_base):\r\n        raise ValueError\r\n    # Deal with base-1 special case\r\n    if input_base == 1:\r\n        number = (1,) * number.count(1)\r\n    # Expand any recurring digits.\r\n    number = expand_recurring(number, repeat=5)\r\n    # Convert a fractional number.\r\n    if \".\" in number:\r\n        radix_point = number.index(\".\")\r\n        integer_part = number[:radix_point]\r\n        fractional_part = number[radix_point:]\r\n        integer_part = integer_base(integer_part, input_base, output_base)\r\n        fractional_part = fractional_base(fractional_part, input_base,\r\n                                          output_base, max_depth)\r\n        number = integer_part + fractional_part\r\n        number = truncate(number)\r\n    # Convert an integer number.\r\n    else:\r\n        number = integer_base(number, input_base, output_base)\r\n    if recurring:\r\n        number = find_recurring(number, min_repeat=2)\r\n    # Return the converted number as a srring or tuple.\r\n    return represent_as_string(number) if string else number", "response": "Converts a number from any base to any base."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets OS - specific configuration directory.", "response": "def get_config_directory(appname):\n    \"\"\"\n    Get OS-specific configuration directory.\n\n    :type appname: str\n    :arg  appname: capitalized name of the application\n\n    \"\"\"\n    if platform.system().lower() == 'windows':\n        path = os.path.join(os.getenv('APPDATA') or '~', appname, appname)\n    elif platform.system().lower() == 'darwin':\n        path = os.path.join('~', 'Library', 'Application Support', appname)\n    else:\n        path = os.path.join(os.getenv('XDG_CONFIG_HOME') or '~/.config',\n                            appname.lower())\n    return os.path.expanduser(path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_model(self, request, obj, form, change):\n        email = message.EmailMessage(\n            subject=obj.subject,\n            body=obj.body,\n            from_email=obj.from_email,\n            to=[t.strip() for t in obj.to_emails.split(',')],\n            bcc=[t.strip() for t in obj.bcc_emails.split(',')],\n            cc=[t.strip() for t in obj.cc_emails.split(',')]\n        )\n        email.send()", "response": "Sends the email and does not save it\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_gdf(fname):\n    \n    gdf_file = open(fname, 'r')\n    gdf = []\n    for l in gdf_file:\n        data = l.split()\n        gdf += [data]\n\n    gdf = np.array(gdf, dtype=object)\n    \n    if gdf.size > 0:\n        gdf[:, 0] = gdf[:, 0].astype(int)\n        gdf[:, 1:] = gdf[:, 1:].astype(float)\n    \n    return np.array(gdf)", "response": "Reads a single file in a Fast line - by - line format and returns a numpy array of the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfast line-by-line gdf-file write function Parameters ---------- gdf : numpy.ndarray Column 0 is gids, columns 1: are values. fname : str Path to gdf-file. Returns ------- None", "response": "def write_gdf(gdf, fname):\n    \"\"\"\n    Fast line-by-line gdf-file write function\n    \n    \n    Parameters\n    ----------\n    gdf : numpy.ndarray\n        Column 0 is gids, columns 1: are values.\n    fname : str\n        Path to gdf-file.\n    \n    \n    Returns\n    -------\n    None\n    \n    \"\"\"\n    gdf_file = open(fname, 'w')\n    for line in gdf:\n        for i in np.arange(len(line)):\n            gdf_file.write(str(line[i]) + '\\t')\n        gdf_file.write('\\n')\n    \n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions loading results from hdf5 file and returns numpy array of single - cell data.", "response": "def load_h5_data(path='', data_type='LFP', y=None, electrode=None,\n                 warmup=0., scaling=1.):\n    \"\"\"\n    Function loading results from hdf5 file\n    \n    \n    Parameters\n    ----------\n    path : str\n        Path to hdf5-file\n    data_type : str\n        Signal types in ['CSD' , 'LFP', 'CSDsum', 'LFPsum'].\n    y : None or str\n        Name of population.\n    electrode : None or int\n        TODO: update, electrode is NOT USED\n    warmup : float\n        Lower cutoff of time series to remove possible transients\n    scaling : float,\n        Scaling factor for population size that determines the amount of loaded\n        single-cell signals\n                \n    \n    Returns\n    ----------\n    numpy.ndarray\n        [electrode id, compound signal] if `y` is None\n    numpy.ndarray\n        [cell id, electrode, single-cell signal] otherwise\n    \n    \"\"\"\n    assert y is not None or electrode is not None\n    \n    if y is not None:\n        f = h5py.File(os.path.join(path, '%s_%ss.h5' %(y,data_type)))\n        data = f['data'].value[:,:, warmup:]\n        if scaling != 1.:\n            np.random.shuffle(data)\n            num_cells = int(len(data)*scaling)\n            data = data[:num_cells,:, warmup:]\n    else:\n        f = h5py.File(os.path.join(path, '%ssum.h5' %data_type))\n        data = f['data'].value[:, warmup:]\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes nested list structure and dump it in hdf5 file.", "response": "def dump_dict_of_nested_lists_to_h5(fname, data):\n    \"\"\"\n    Take nested list structure and dump it in hdf5 file.\n\n\n    Parameters\n    ----------\n    fname : str \n        Filename\n    data : dict(list(numpy.ndarray))\n        Dict of nested lists with variable len arrays.\n    \n    \n    Returns\n    -------\n    None\n\n    \"\"\"\n    # Open file\n    print('writing to file: %s' % fname)\n    f = h5py.File(fname)\n    # Iterate over values\n    for i, ivalue in list(data.items()):\n        igrp = f.create_group(str(i))\n        for j, jvalue in enumerate(ivalue):\n            jgrp = igrp.create_group(str(j))\n            for k, kvalue in enumerate(jvalue):\n                if kvalue.size > 0:\n                    dset = jgrp.create_dataset(str(k), data=kvalue,\n                                               compression='gzip')\n                else:\n                    dset = jgrp.create_dataset(str(k), data=kvalue,\n                                               maxshape=(None, ),\n                                               compression='gzip')\n    # Close file\n    f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_dict_of_nested_lists_from_h5(fname, toplevelkeys=None):\n    \n    # Container:\n    data = {}\n\n    # Open file object\n    f = h5py.File(fname, 'r')\n\n    # Iterate over partial dataset\n    if toplevelkeys is not None:\n        for i in toplevelkeys:\n            ivalue = f[str(i)]\n            data[i] = []\n            for j, jvalue in enumerate(ivalue.values()):\n                data[int(i)].append([])\n                for k, kvalue in enumerate(jvalue.values()):\n                    data[i][j].append(kvalue.value)\n    else:\n        for i, ivalue in list(f.items()):\n            i = int(i)\n            data[i] = []\n            for j, jvalue in enumerate(ivalue.values()):\n                data[i].append([])\n                for k, kvalue in enumerate(jvalue.values()):\n                    data[i][j].append(kvalue.value)\n\n    # Close dataset\n    f.close()\n\n    return data", "response": "Loads nested list structure from hdf5 file fname."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to set up the file catalog structure for simulation output", "response": "def setup_file_dest(params, clearDestination=True):\n    \"\"\"\n    Function to set up the file catalog structure for simulation output\n    \n    \n    Parameters\n    ----------  \n    params : object \n        e.g., `cellsim16popsParams.multicompartment_params()`\n    clear_dest : bool \n        Savefolder will be cleared if already existing.\n    \n    \n    Returns\n    -------\n    None\n    \n    \"\"\"\n    if RANK == 0:\n        if not os.path.isdir(params.savefolder):\n            os.mkdir(params.savefolder)\n            assert(os.path.isdir(params.savefolder))\n        else:\n            if clearDestination:\n                print('removing folder tree %s' % params.savefolder)\n                while os.path.isdir(params.savefolder):\n                    try:\n                        os.system('find %s -delete' % params.savefolder)\n                    except:\n                        shutil.rmtree(params.savefolder)\n                os.mkdir(params.savefolder)\n                assert(os.path.isdir(params.savefolder))\n        \n        if not os.path.isdir(params.sim_scripts_path):\n            print('creating %s' % params.sim_scripts_path)\n            os.mkdir(params.sim_scripts_path)\n        \n        if not os.path.isdir(params.cells_path):\n            print('creating %s' % params.cells_path)\n            os.mkdir(params.cells_path)\n        \n        if not os.path.isdir(params.figures_path):\n            print('creating %s' % params.figures_path)\n            os.mkdir(params.figures_path)\n        \n        if not os.path.isdir(params.populations_path):\n            print('creating %s' % params.populations_path)\n            os.mkdir(params.populations_path)\n        \n        try:\n            if not os.path.isdir(params.raw_nest_output_path):\n                print('creating %s' % params.raw_nest_output_path)\n                os.mkdir(params.raw_nest_output_path)\n        except:\n            pass\n        \n        if not os.path.isdir(params.spike_output_path):\n            print('creating %s' % params.spike_output_path)\n            os.mkdir(params.spike_output_path)\n    \n        for f in ['cellsim16popsParams.py',\n                  'cellsim16pops.py',\n                  'example_brunel.py',\n                  'brunel_alpha_nest.py',\n                  'mesocircuit.sli',\n                  'mesocircuit_LFP_model.py',\n                  'binzegger_connectivity_table.json', \n                  'nest_simulation.py',\n                  'microcircuit.sli']:\n            if os.path.isfile(f):\n                if not os.path.exists(os.path.join(params.sim_scripts_path, f)):\n                    shutil.copy(f, os.path.join(params.sim_scripts_path, f))\n                    os.chmod(os.path.join(params.sim_scripts_path, f),\n                             stat.S_IREAD)\n       \n    COMM.Barrier()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to calculate the Fourier transform of data.", "response": "def calculate_fft(data, tbin):\n    \"\"\"\n    Function to calculate the Fourier transform of data.\n    \n    \n    Parameters\n    ----------\n    data : numpy.ndarray\n        1D or 2D array containing time series.\n    tbin : float\n        Bin size of time series (in ms).\n    \n    \n    Returns\n    -------\n    freqs : numpy.ndarray\n        Frequency axis of signal in Fourier space.         \n    fft : numpy.ndarray\n        Signal in Fourier space.\n        \n    \"\"\"\n    if len(np.shape(data)) > 1:\n        n = len(data[0])\n        return np.fft.fftfreq(n, tbin * 1e-3), np.fft.fft(data, axis=1)\n    else:\n        n = len(data)\n        return np.fft.fftfreq(n, tbin * 1e-3), np.fft.fft(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef centralize(data, time=False, units=False):\n    assert(time is not False or units is not False)\n    res = copy.copy(data)\n    \n    if time is True:\n        res = np.array([x - np.mean(x) for x in res])\n    \n    if units is True:\n        res = np.array(res - np.mean(res, axis=0))\n    \n    return res", "response": "Function to subtract the mean across time and or across units from data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to normalize data to have mean 0 and unity standard deviation", "response": "def normalize(data):\n    \"\"\"\n    Function to normalize data to have mean 0 and unity standard deviation\n    (also called z-transform)\n    \n    \n    Parameters\n    ----------\n    data : numpy.ndarray\n    \n    \n    Returns\n    -------\n    numpy.ndarray\n        z-transform of input array\n    \n    \"\"\"\n    data = data.astype(float)\n    data -= data.mean()\n    \n    return data / data.std()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef movav(y, Dx, dx):\n    if Dx <= dx:\n        return y\n    else:\n        ly = len(y)\n        r = np.zeros(ly)\n        n = np.int(np.round((Dx / dx)))\n        r[0:np.int(n / 2.)] = 1.0 / n\n        r[-np.int(n / 2.)::] = 1.0 / n\n        R = np.fft.fft(r)\n        Y = np.fft.fft(y)\n        yf = np.fft.ifft(Y * R)\n        return yf", "response": "Moving average rectangular window filter"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decimate(x, q=10, n=4, k=0.8, filterfun=ss.cheby1):\n    if not isinstance(q, int):\n        raise TypeError(\"q must be an integer\")\n\n    if n is None:\n        n = 1\n\n    if filterfun == ss.butter:\n        b, a = filterfun(n, k / q)\n    elif filterfun == ss.cheby1:\n        b, a = filterfun(n, 0.05, k / q)\n    else:\n        raise Exception('only ss.butter or ss.cheby1 supported')\n\n    try:\n        y = ss.filtfilt(b, a, x)\n    except: # Multidim array can only be processed at once for scipy >= 0.9.0\n        y = []\n        for data in x:\n            y.append(ss.filtfilt(b, a, data))\n        y = np.array(y)\n\n    try:\n        return y[:, ::q]\n    except:\n        return y[::q]", "response": "scipy. signal. decimate like downsampling using filtfilt instead of lfilter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to compute mean of data in a single segment", "response": "def mean(data, units=False, time=False):\n    \"\"\"\n    Function to compute mean of data\n\n\n    Parameters\n    ---------- \n    data : numpy.ndarray\n        1st axis unit, 2nd axis time\n    units : bool\n        Average over units\n    time : bool \n        Average over time\n\n\n    Returns\n    -------\n    if units=False and time=False: \n        error\n    if units=True: \n        1 dim numpy.ndarray; time series\n    if time=True: \n        1 dim numpy.ndarray; series of unit means across time\n    if units=True and time=True: \n        float; unit and time mean\n\n\n    Examples\n    --------\n    >>> mean(np.array([[1, 2, 3], [4, 5, 6]]), units=True)\n    array([ 2.5,  3.5,  4.5])\n\n    >>> mean(np.array([[1, 2, 3], [4, 5, 6]]), time=True)\n    array([ 2.,  5.])\n\n    >>> mean(np.array([[1, 2, 3], [4, 5, 6]]), units=True,time=True)\n    3.5\n\n    \"\"\"\n\n    assert(units is not False or time is not False)\n    if units is True and time is False:\n        return np.mean(data, axis=0)\n    elif units is False and time is True:\n        return np.mean(data, axis=1)\n    elif units is True and time is True:\n        return np.mean(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef powerspec(data, tbin, Df=None, units=False, pointProcess=False):\n\n    freq, DATA = calculate_fft(data, tbin)\n    df = freq[1] - freq[0]\n    T = tbin * len(freq)\n    POW = np.abs(DATA) ** 2\n    if Df is not None:\n        POW = [movav(x, Df, df) for x in POW]\n        cut = int(Df / df)\n        freq = freq[cut:]\n        POW = np.array([x[cut:] for x in POW])\n        POW = np.abs(POW)\n    assert(len(freq) == len(POW[0]))\n    if units is True:\n        POW = mean(POW, units=units)\n        assert(len(freq) == len(POW))\n    if pointProcess:\n        POW *= 1. / T * 1e3  # Normalization, power independent of T\n    return freq, POW", "response": "Returns a new object that is a new object with the same frequency and power spectra."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the power spectrum of the compound signal.", "response": "def compound_powerspec(data, tbin, Df=None, pointProcess=False):\n    \"\"\"\n    Calculate the power spectrum of the compound/sum signal.\n    data is first summed across units, then the power spectrum is calculated.\n\n    If pointProcess=True, power spectra are normalized by the length T of\n    the time series.\n\n    \n    Parameters\n    ----------\n    data : numpy.ndarray, \n        1st axis unit, 2nd axis time\n    tbin : float, \n        binsize in ms\n    Df : float/None, \n        window width of sliding rectangular filter (smoothing),\n        None -> no smoothing\n    pointProcess : bool, \n        if set to True, powerspectrum is normalized to signal length T\n                 \n\n\n    Returns\n    -------\n    freq : tuple\n        numpy.ndarray of frequencies\n    POW : tuple\n        1 dim numpy.ndarray, frequency series\n\n\n    Examples\n    --------\n    >>> compound_powerspec(np.array([analog_sig1, analog_sig2]), tbin, Df=Df)\n    Out[1]: (freq,POW)\n    >>> POW.shape\n    Out[2]: (len(analog_sig1),)\n\n    \"\"\"\n\n    return powerspec([np.sum(data, axis=0)], tbin, Df=Df, units=True,\n        pointProcess=pointProcess)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the cross - spectrum of data.", "response": "def crossspec(data, tbin, Df=None, units=False, pointProcess=False):\n    \"\"\"\n    Calculate (smoothed) cross spectra of data.\n    If `units`=True, cross spectra are averaged across units.\n    Note that averaging is done on cross spectra rather than data.\n\n    Cross spectra are normalized by the length T of the time series -> no\n    scaling with T.\n\n    If pointProcess=True, power spectra are normalized by the length T of the\n    time series.\n\n\n    Parameters\n    ----------\n    data : numpy.ndarray, \n        1st axis unit, 2nd axis time\n    tbin : float, \n        binsize in ms\n    Df : float/None, \n        window width of sliding rectangular filter (smoothing),\n        None -> no smoothing\n    units : bool, \n        average cross spectrum\n    pointProcess : bool, \n        if set to True, cross spectrum is normalized to signal length T\n\n    \n    Returns\n    -------\n    freq : tuple\n        numpy.ndarray of frequencies\n    CRO : tuple\n        if `units`=True: 1 dim numpy.ndarray; frequency series\n        if `units`=False:3 dim numpy.ndarray; 1st axis first unit,\n            2nd axis second unit, 3rd axis frequency\n\n\n    Examples\n    --------    \n    >>> crossspec(np.array([analog_sig1, analog_sig2]), tbin, Df=Df)\n    Out[1]: (freq,CRO)\n    >>> CRO.shape\n    Out[2]: (2,2,len(analog_sig1))\n\n    >>> crossspec(np.array([analog_sig1, analog_sig2]), tbin, Df=Df, units=True)\n    Out[1]: (freq,CRO)\n    >>> CRO.shape\n    Out[2]: (len(analog_sig1),)\n\n    \"\"\"\n\n    N = len(data)\n    if units is True:\n        # smoothing and normalization take place in powerspec\n        # and compound_powerspec\n        freq, POW = powerspec(data, tbin, Df=Df, units=True)\n        freq_com, CPOW = compound_powerspec(data, tbin, Df=Df)\n        assert(len(freq) == len(freq_com))\n        assert(np.min(freq) == np.min(freq_com))\n        assert(np.max(freq) == np.max(freq_com))\n        CRO = 1. / (1. * N * (N - 1.)) * (CPOW - 1. * N * POW)\n        assert(len(freq) == len(CRO))\n    else:\n        freq, DATA = calculate_fft(data, tbin)\n        T = tbin * len(freq)\n        df = freq[1] - freq[0]\n        if Df is not None:\n            cut = int(Df / df)\n            freq = freq[cut:]\n        CRO = np.zeros((N, N, len(freq)), dtype=complex)\n        for i in range(N):\n            for j in range(i + 1):\n                tempij = DATA[i] * DATA[j].conj()\n                if Df is not None:\n                    tempij = movav(tempij, Df, df)[cut:]\n                CRO[i, j] = tempij\n                CRO[j, i] = CRO[i, j].conj()\n        assert(len(freq) == len(CRO[0, 0]))\n        if pointProcess:\n            CRO *= 1. / T * 1e3  # normalization\n    return freq, CRO"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the cross - spectra between two sets of data.", "response": "def compound_crossspec(a_data, tbin, Df=None, pointProcess=False):\n    \"\"\"\n    Calculate cross spectra of compound signals.\n    a_data is a list of datasets (a_data = [data1,data2,...]).\n    For each dataset in a_data, the compound signal is calculated\n    and the crossspectra between these compound signals is computed.\n    \n    If pointProcess=True, power spectra are normalized by the length T of the\n    time series.\n\n\n    Parameters\n    ----------\n    a_data : list of numpy.ndarrays\n        Array: 1st axis unit, 2nd axis time.     \n    tbin : float\n        Binsize in ms.\n    Df : float/None, \n        Window width of sliding rectangular filter (smoothing),\n        None -> no smoothing.\n    pointProcess : bool\n        If set to True, crossspectrum is normalized to signal length `T`\n                \n    Returns\n    -------\n    freq : tuple\n        numpy.ndarray of frequencies.\n    CRO : tuple\n        3 dim numpy.ndarray; 1st axis first compound signal, 2nd axis second\n        compound signal, 3rd axis frequency.\n\n\n    Examples\n    --------\n    >>> compound_crossspec([np.array([analog_sig1, analog_sig2]),\n                            np.array([analog_sig3,analog_sig4])], tbin, Df=Df)\n    Out[1]: (freq,CRO)\n    >>> CRO.shape\n    Out[2]: (2,2,len(analog_sig1))\n\n    \"\"\"\n\n    a_mdata = []\n    for data in a_data:\n        a_mdata.append(np.sum(data, axis=0))  # calculate compound signals\n    return crossspec(np.array(a_mdata), tbin, Df, units=False,\n                     pointProcess=pointProcess)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef autocorrfunc(freq, power):\n    tbin = 1. / (2. * np.max(freq)) * 1e3  # tbin in ms\n    time = np.arange(-len(freq) / 2. + 1, len(freq) / 2. + 1) * tbin\n    # T = max(time)\n    multidata = False\n    if len(np.shape(power)) > 1:\n        multidata = True\n    if multidata:\n        N = len(power)\n        autof = np.zeros((N, len(freq)))\n        for i in range(N):\n            raw_autof = np.real(np.fft.ifft(power[i]))\n            mid = int(len(raw_autof) / 2.)\n            autof[i] = np.hstack([raw_autof[mid + 1:], raw_autof[:mid + 1]])\n        assert(len(time) == len(autof[0]))\n    else:\n        raw_autof = np.real(np.fft.ifft(power))\n        mid = int(len(raw_autof) / 2.)\n        autof = np.hstack([raw_autof[mid + 1:], raw_autof[:mid + 1]])\n        assert(len(time) == len(autof))\n    # autof *= T*1e-3 # normalization is done in powerspec()\n    return time, autof", "response": "Calculates autocorrelation function for given frequency and power spectrum."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef crosscorrfunc(freq, cross):\n\n    tbin = 1. / (2. * np.max(freq)) * 1e3  # tbin in ms\n    time = np.arange(-len(freq) / 2. + 1, len(freq) / 2. + 1) * tbin\n    # T = max(time)\n    multidata = False\n    # check whether cross contains many cross spectra\n    if len(np.shape(cross)) > 1:\n        multidata = True\n    if multidata:\n        N = len(cross)\n        crossf = np.zeros((N, N, len(freq)))\n        for i in range(N):\n            for j in range(N):\n                raw_crossf = np.real(np.fft.ifft(cross[i, j]))\n                mid = int(len(raw_crossf) / 2.)\n                crossf[i, j] = np.hstack(\n                    [raw_crossf[mid + 1:], raw_crossf[:mid + 1]])\n        assert(len(time) == len(crossf[0, 0]))\n    else:\n        raw_crossf = np.real(np.fft.ifft(cross))\n        mid = int(len(raw_crossf) / 2.)\n        crossf = np.hstack([raw_crossf[mid + 1:], raw_crossf[:mid + 1]])\n        assert(len(time) == len(crossf))\n    # crossf *= T*1e-3 # normalization happens in cross spectrum\n    return time, crossf", "response": "Calculates the crosscorrelation function for given frequency and cross spectra."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the correlation coefficient for given auto - and crosscorrelation functions.", "response": "def corrcoef(time, crossf, integration_window=0.):\n    \"\"\"\n    Calculate the correlation coefficient for given auto- and crosscorrelation\n    functions. Standard settings yield the zero lag correlation coefficient.\n    Setting integration_window > 0 yields the correlation coefficient of\n    integrated auto- and crosscorrelation functions. The correlation coefficient\n    between a zero signal with any other signal is defined as 0.\n\n\n    Parameters\n    ----------\n    time : numpy.ndarray\n        1 dim array of times corresponding to signal.\n    crossf : numpy.ndarray \n        Crosscorrelation functions, 1st axis first unit, 2nd axis second unit,\n        3rd axis times.\n    integration_window: float\n        Size of the integration window.\n\n\n    Returns\n    -------\n    cc : numpy.ndarray\n        2 dim array of correlation coefficient between two units.\n\n    \"\"\"\n\n    N = len(crossf)\n    cc = np.zeros(np.shape(crossf)[:-1])\n    tbin = abs(time[1] - time[0])\n    lim = int(integration_window / tbin)\n    \n    if len(time)%2 == 0:\n        mid = len(time)/2-1\n    else:\n        mid = np.floor(len(time)/2.)\n    \n    for i in range(N):\n        ai = np.sum(crossf[i, i][mid - lim:mid + lim + 1])\n        offset_autoi = np.mean(crossf[i,i][:mid-1])\n        for j in range(N):\n            cij = np.sum(crossf[i, j][mid - lim:mid + lim + 1])\n            offset_cross = np.mean(crossf[i,j][:mid-1])\n            aj = np.sum(crossf[j, j][mid - lim:mid + lim + 1])\n            offset_autoj = np.mean(crossf[j,j][:mid-1])\n            if ai > 0. and aj > 0.:\n                cc[i, j] = (cij-offset_cross) / np.sqrt((ai-offset_autoi) * \\\n                    (aj-offset_autoj))\n            else:\n                cc[i, j] = 0.\n    \n    return cc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef coherence(freq, power, cross):\n\n    N = len(power)\n    coh = np.zeros(np.shape(cross))\n    \n    for i in range(N):\n        for j in range(N):\n            coh[i, j] = cross[i, j] / np.sqrt(power[i] * power[j])\n    \n    assert(len(freq) == len(coh[0, 0]))\n    \n    return freq, coh", "response": "Calculates frequency resolved coherence for given power - and crossspectra."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate coefficient of variation of data across time.", "response": "def cv(data, units=False):\n    \"\"\"\n    Calculate coefficient of variation (cv) of data. Mean and standard deviation\n    are computed across time.\n\n\n    Parameters\n    ----------\n    data : numpy.ndarray\n        1st axis unit, 2nd axis time.\n    units : bool\n        Average `cv`.\n\n\n    Returns\n    -------\n    numpy.ndarray\n        If units=False, series of unit `cv`s.\n    float\n        If units=True, mean `cv` across units.\n\n\n    Examples\n    --------\n    >>> cv(np.array([[1, 2, 3, 4, 5, 6], [11, 2, 3, 3, 4, 5]]))\n    array([ 0.48795004,  0.63887656])\n\n    >>> cv(np.array([[1, 2, 3, 4, 5, 6], [11, 2, 3, 3, 4, 5]]), units=True)\n    0.56341330073710316\n\n    \"\"\"\n\n    mu = mean(data, time=True)\n    var = variance(data, time=True)\n    cv = np.sqrt(var) / mu\n    \n    if units is True:\n        return np.mean(cv)\n    else:\n        return cv"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fano(data, units=False):\n    mu = mean(data, time=True)\n    var = variance(data, time=True)\n    ff = var / mu\n    \n    if units is True:\n        return np.mean(ff)\n    else:\n        return ff", "response": "Calculates the fano factor of data across all units."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncollect the gdf - files from network sim in folder spike_output_path", "response": "def collect_gdf(self):\n        \"\"\"\n        Collect the gdf-files from network sim in folder `spike_output_path`\n        into sqlite database, using the GDF-class.\n        \n        \n        Parameters\n        ----------\n        None\n        \n        \n        Returns\n        -------\n        None\n        \n        \"\"\"\n        # Resync\n        COMM.Barrier()\n\n        # Raise Exception if there are no gdf files to be read\n        if len(glob.glob(os.path.join(self.spike_output_path,\n                                      self.label + '*.'+ self.ext))) == 0:\n            raise Exception('path to files contain no gdf-files!')\n\n        #create in-memory databases of spikes\n        if not hasattr(self, 'dbs'):\n            self.dbs = {}\n        \n        for X in self.X:\n            db = GDF(os.path.join(self.dbname),\n                     debug=True, new_db=True)\n            db.create(re=os.path.join(self.spike_output_path,\n                                      '{0}*{1}*{2}'.format(self.label, X,\n                                                           self.ext)),\n                      index=True)\n            self.dbs.update({\n                    X : db\n                })\n      \n        COMM.Barrier()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget pairs of node units and spike trains on specific time interval.", "response": "def get_xy(self, xlim, fraction=1.):\n        \"\"\"\n        Get pairs of node units and spike trains on specific time interval.\n        \n        \n        Parameters\n        ----------\n        xlim : list of floats\n            Spike time interval, e.g., [0., 1000.].\n        fraction : float in [0, 1.]\n            If less than one, sample a fraction of nodes in random order.\n        \n        \n        Returns\n        -------\n        x : dict\n            In `x` key-value entries are population name and neuron spike times.\n        y : dict\n            Where in `y` key-value entries are population name and neuron gid number.\n\n        \"\"\"\n        x = {}\n        y = {}\n\n        for X, nodes in self.nodes.items():\n            x[X] = np.array([])\n            y[X] = np.array([])\n\n            if fraction != 1:\n                nodes = np.random.permutation(nodes)[:int(nodes.size*fraction)]\n                nodes.sort()\n\n            spiketimes = self.dbs[X].select_neurons_interval(nodes, T=xlim)\n            i = 0\n            for times in spiketimes:\n                x[X] = np.r_[x[X], times]\n                y[X] = np.r_[y[X], np.zeros(times.size) + nodes[i]]\n                i += 1\n                \n        return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_raster(self, ax, xlim, x, y, pop_names=False,\n                    markersize=20., alpha=1., legend=True,\n                    marker='o', rasterized=True):\n        \"\"\"\n        Plot network raster plot in subplot object.\n        \n        \n        Parameters\n        ----------\n        ax : `matplotlib.axes.AxesSubplot` object\n            plot axes\n        xlim : list\n            List of floats. Spike time interval, e.g., [0., 1000.].\n        x : dict\n            Key-value entries are population name and neuron spike times.\n        y : dict\n            Key-value entries are population name and neuron gid number.\n        pop_names: bool\n            If True, show population names on yaxis instead of gid number.\n        markersize : float\n            raster plot marker size\n        alpha : float in [0, 1]\n            transparency of marker\n        legend : bool\n            Switch on axes legends.\n        marker : str\n            marker symbol for matplotlib.pyplot.plot\n        rasterized : bool\n            if True, the scatter plot will be treated as a bitmap embedded in\n            pdf file output\n\n\n        Returns\n        -------\n        None\n        \n        \"\"\"\n        yoffset = [sum(self.N_X) if X=='TC' else 0 for X in self.X]\n        for i, X in enumerate(self.X):\n            if y[X].size > 0:\n                ax.plot(x[X], y[X]+yoffset[i], marker,\n                    markersize=markersize,\n                    mfc=self.colors[i],\n                    mec='none' if marker in '.ov><v^1234sp*hHDd' else self.colors[i],\n                    alpha=alpha,\n                    label=X, rasterized=rasterized,\n                    clip_on=True)\n        \n        #don't draw anything for the may-be-quiet TC population\n        N_X_sum = 0\n        for i, X in enumerate(self.X):\n            if y[X].size > 0:\n                N_X_sum += self.N_X[i]\n        \n        ax.axis([xlim[0], xlim[1],\n                 self.GIDs[self.X[0]][0], self.GIDs[self.X[0]][0]+N_X_sum])\n        ax.set_ylim(ax.get_ylim()[::-1])\n        ax.set_ylabel('cell id', labelpad=0)\n        ax.set_xlabel('$t$ (ms)', labelpad=0)\n        if legend:\n            ax.legend()\n        if pop_names:\n            yticks = []\n            yticklabels = []\n            for i, X in enumerate(self.X):\n                if y[X] != []:\n                    yticks.append(y[X].mean()+yoffset[i])\n                    yticklabels.append(self.X[i])\n            ax.set_yticks(yticks)\n            ax.set_yticklabels(yticklabels)\n        \n        # Add some horizontal lines separating the populations\n        for i, X in enumerate(self.X):\n            if y[X].size > 0:\n                ax.plot([xlim[0], xlim[1]],\n                        [y[X].max()+yoffset[i], y[X].max()+yoffset[i]],\n                        'k', lw=0.25)", "response": "Plot network raster plot in subplot object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_f_rate(self, ax, X, i, xlim, x, y, binsize=1, yscale='linear',\n                    plottype='fill_between', show_label=False, rasterized=False):\n        \"\"\"\n        Plot network firing rate plot in subplot object.\n        \n        \n        Parameters\n        ----------\n        ax : `matplotlib.axes.AxesSubplot` object.\n        X : str\n            Population name.\n        i : int\n            Population index in class attribute `X`.\n        xlim : list of floats\n            Spike time interval, e.g., [0., 1000.].\n        x : dict\n            Key-value entries are population name and neuron spike times.\n        y : dict\n            Key-value entries are population name and neuron gid number.\n        yscale : 'str'\n            Linear, log, or symlog y-axes in rate plot.\n        plottype : str\n            plot type string in `['fill_between', 'bar']`\n        show_label : bool\n            whether or not to show labels\n        \n\n        Returns\n        -------\n        None\n        \n        \"\"\"\n        \n        bins = np.arange(xlim[0], xlim[1]+binsize, binsize)\n        (hist, bins) = np.histogram(x[X], bins=bins)\n        \n        if plottype == 'fill_between':\n            ax.fill_between(bins[:-1], hist * 1000. / self.N_X[i],\n                    color=self.colors[i], lw=0.5, label=X, rasterized=rasterized,\n                    clip_on=False)\n            ax.plot(bins[:-1], hist * 1000. / self.N_X[i],\n                    color='k', lw=0.5, label=X, rasterized=rasterized,\n                    clip_on=False)\n        elif plottype == 'bar':\n            ax.bar(bins[:-1], hist * 1000. / self.N_X[i],\n                    color=self.colors[i], label=X, rasterized=rasterized ,\n                    linewidth=0.25, width=0.9, clip_on=False)\n        else:\n            mssg = \"plottype={} not in ['fill_between', 'bar']\".format(plottype)\n            raise Exception(mssg)\n\n        remove_axis_junk(ax)\n\n        ax.axis(ax.axis('tight'))\n\n        ax.set_yscale(yscale)\n\n        ax.set_xlim(xlim[0], xlim[1])\n        if show_label:\n            ax.text(xlim[0] + .05*(xlim[1]-xlim[0]), ax.axis()[3]*1.5, X,\n                    va='center', ha='left')", "response": "Plot network firing rate plot in subplot object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef raster_plots(self, xlim=[0, 1000], markersize=1, alpha=1., marker='o'):\n        x, y = self.get_xy(xlim)\n\n        fig = plt.figure()\n        fig.subplots_adjust(left=0.12, hspace=0.15)\n\n        ax0 = fig.add_subplot(211)\n\n        self.plot_raster(ax0, xlim, x, y, markersize=markersize, alpha=alpha,\n                         marker=marker)\n        remove_axis_junk(ax0)\n        ax0.set_title('spike raster')\n        ax0.set_xlabel(\"\")\n\n        nrows = len(self.X)\n        bottom = np.linspace(0.1, 0.45, nrows+1)[::-1][1:]\n        thickn = np.abs(np.diff(bottom))[0]*0.9\n\n\n        for i, layer in enumerate(self.X):\n            ax1 = fig.add_axes([0.12, bottom[i], 0.78, thickn])\n\n            self.plot_f_rate(ax1, layer, i, xlim, x, y, )\n\n            if i == nrows-1:\n                ax1.set_xlabel('time (ms)')\n            else:\n                ax1.set_xticklabels([])\n\n            if i == 4:\n                ax1.set_ylabel(r'population rates ($s^{-1}$)')\n\n            if i == 0:\n                ax1.set_title(r'population firing rates ($s^{-1}$)')\n              \n        return fig", "response": "Pretty plot of the spiking output of each population as raster and rate."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting a single sst to a dot display.", "response": "def add_sst_to_dot_display(ax, sst, color= '0.',alpha= 1.):\n    '''\n    suitable for plotting fraction of neurons\n    '''\n    plt.sca(ax)\n    N = len(sst)\n    current_ymax = 0\n    counter = 0\n    while True:\n        if len(ax.get_lines()) !=0:\n            data = ax.get_lines()[-1-counter].get_data()[1]\n            if np.sum(data) != 0: # if not empty array \n                current_ymax = np.max(data)\n                break\n            counter +=1\n        else: \n            break\n    for i in np.arange(N):\n        plt.plot(sst[i],np.ones_like(sst[i])+i+current_ymax -1, 'k o',ms=0.5, mfc=color,mec=color, alpha=alpha)\n    plt.xlabel(r'time (ms)')\n    plt.ylabel(r'neuron id')\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef empty_bar_plot(ax):\n    ''' Delete all axis ticks and labels '''\n    plt.sca(ax)\n    plt.setp(plt.gca(),xticks=[],xticklabels=[]) \n    return ax", "response": "Delete all axis ticks and labels"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef colorbar(fig, ax, im,\n                 width=0.05,\n                 height=1.0,\n                 hoffset=0.01,\n                 voffset=0.0,\n                 orientation='vertical'):\n    '''\n    draw colorbar without resizing the axes object to make room\n\n    kwargs:\n    ::\n        fig : matplotlib.figure.Figure\n        ax : matplotlib.axes.AxesSubplot\n        im : matplotlib.image.AxesImage\n        width : float, colorbar width in fraction of ax width\n        height : float, colorbar height in fraction of ax height\n        hoffset : float, horizontal spacing to main axes in fraction of width\n        voffset : float, vertical spacing to main axis in fraction of height\n        orientation : str, 'horizontal' or 'vertical'\n\n    return:\n    ::\n        object : colorbar handle\n\n    '''\n    rect = np.array(ax.get_position().bounds)\n    \n    rect = np.array(ax.get_position().bounds)\n    caxrect = [0]*4\n    caxrect[0] = rect[0] + rect[2] + hoffset*rect[2]\n    caxrect[1] = rect[1] + voffset*rect[3]\n    caxrect[2] = rect[2]*width\n    caxrect[3] = rect[3]*height\n    \n    cax = fig.add_axes(caxrect)\n    cb = fig.colorbar(im, cax=cax, orientation=orientation)\n    \n    return cb", "response": "Function to draw colorbar with resizing the axes object to make room for the next time."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns Figure styles for frontiers", "response": "def frontiers_style():\n    '''\n    Figure styles for frontiers\n    '''\n    \n    inchpercm = 2.54\n    frontierswidth=8.5 \n    textsize = 5\n    titlesize = 7\n    plt.rcdefaults()\n    plt.rcParams.update({\n        'figure.figsize' : [frontierswidth/inchpercm, frontierswidth/inchpercm],\n        'figure.dpi' : 160,\n        'xtick.labelsize' : textsize,\n        'ytick.labelsize' : textsize,\n        'font.size' : textsize,\n        'axes.labelsize' : textsize,\n        'axes.titlesize' : titlesize,\n        'axes.linewidth': 0.75,\n        'lines.linewidth': 0.75,\n        'legend.fontsize' : textsize,\n    })\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a subplot annotation number", "response": "def annotate_subplot(ax, ncols=1, nrows=1, letter='a',\n                     linear_offset=0.075, fontsize=8):\n    '''add a subplot annotation number'''\n    ax.text(-ncols*linear_offset, 1+nrows*linear_offset, letter,\n        horizontalalignment='center',\n        verticalalignment='center',\n        fontsize=fontsize, fontweight='demibold',\n        transform=ax.transAxes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_colors(num=16, cmap=plt.cm.Set1):\n    '''return a list of color tuples to use in plots'''\n    colors = []\n    for i in xrange(num):\n        if analysis_params.bw:\n            colors.append('k' if i % 2 == 0 else 'gray')\n        else:\n            i *= 256.\n            if num > 1:\n                i /= num - 1.\n            else:\n                i /= num\n            colors.append(cmap(int(i)))\n    return colors", "response": "return a list of color tuples to use in plots"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompress text data using the LZ77 algorithm.", "response": "def compress(self, data, windowLength = None):\n\t\t\"\"\"Compresses text data using the LZ77 algorithm.\"\"\"\n\n\t\tif windowLength == None:\n\t\t\twindowLength = self.defaultWindowLength\n\n\t\tcompressed = \"\"\n\t\tpos = 0\n\t\tlastPos = len(data) - self.minStringLength\n\n\t\twhile pos < lastPos:\n\n\t\t\tsearchStart = max(pos - windowLength, 0);\n\t\t\tmatchLength = self.minStringLength\n\t\t\tfoundMatch = False\n\t\t\tbestMatchDistance = self.maxStringDistance\n\t\t\tbestMatchLength = 0\n\t\t\tnewCompressed = None\n\n\t\t\twhile (searchStart + matchLength) < pos:\n\n\t\t\t\tm1 = data[searchStart : searchStart + matchLength]\n\t\t\t\tm2 = data[pos : pos + matchLength]\n\t\t\t\tisValidMatch = (m1 == m2 and matchLength < self.maxStringLength)\n\n\t\t\t\tif isValidMatch:\n\t\t\t\t\tmatchLength += 1\n\t\t\t\t\tfoundMatch = True\n\t\t\t\telse:\n\t\t\t\t\trealMatchLength = matchLength - 1\n\n\t\t\t\t\tif foundMatch and realMatchLength > bestMatchLength:\n\t\t\t\t\t\tbestMatchDistance = pos - searchStart - realMatchLength\n\t\t\t\t\t\tbestMatchLength = realMatchLength\n\n\t\t\t\t\tmatchLength = self.minStringLength\n\t\t\t\t\tsearchStart += 1\n\t\t\t\t\tfoundMatch = False\n\n\t\t\tif bestMatchLength:\n\t\t\t\tnewCompressed = (self.referencePrefix + self.__encodeReferenceInt(bestMatchDistance, 2) + self.__encodeReferenceLength(bestMatchLength))\n\t\t\t\tpos += bestMatchLength\n\t\t\telse:\n\t\t\t\tif data[pos] != self.referencePrefix:\n\t\t\t\t\tnewCompressed = data[pos]\n\t\t\t\telse:\n\t\t\t\t\tnewCompressed = self.referencePrefix + self.referencePrefix\n\t\t\t\tpos += 1\n\n\t\t\tcompressed += newCompressed\n\n\t\treturn compressed + data[pos:].replace(\"`\", \"``\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecompressing LZ77 compressed text data", "response": "def decompress(self, data):\n\t\t\"\"\"Decompresses LZ77 compressed text data\"\"\"\n\n\t\tdecompressed = \"\"\n\t\tpos = 0\n\t\twhile pos < len(data):\n\t\t\tcurrentChar = data[pos]\n\t\t\tif currentChar != self.referencePrefix:\n\t\t\t\tdecompressed += currentChar\n\t\t\t\tpos += 1\n\t\t\telse:\n\t\t\t\tnextChar = data[pos + 1]\n\t\t\t\tif nextChar != self.referencePrefix:\n\t\t\t\t\tdistance = self.__decodeReferenceInt(data[pos + 1 : pos + 3], 2)\n\t\t\t\t\tlength = self.__decodeReferenceLength(data[pos + 3])\n\t\t\t\t\tstart = len(decompressed) - distance - length\n\t\t\t\t\tend = start + length\n\t\t\t\t\tdecompressed += decompressed[start : end]\n\t\t\t\t\tpos += self.minStringLength - 1\n\t\t\t\telse:\n\t\t\t\t\tdecompressed += self.referencePrefix\n\t\t\t\t\tpos += 2\n\n\t\treturn decompressed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef message_user(self, username, domain, subject, message):\n        jid = '%s@%s' % (username, domain)\n        if self.api_version <= (14, 7):\n            # TODO: it's unclear when send_message was introduced\n            command = 'send_message_chat'\n            args = domain, '%s@%s' % (username, domain), message\n        else:\n            command = 'send_message'\n            args = 'chat', domain, jid, subject, message\n\n        code, out, err = self.ctl(command, *args)\n        if code != 0:\n            raise BackendError(code)", "response": "Send a message to a user in a domain."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nincrements or decrement the value according to the given value s sign", "response": "def notify(self, value):\n        \"\"\"\n        Increment or decrement the value, according to the given value's sign\n\n        The value should be an integer, an attempt to cast it to integer will be made\n        \"\"\"\n        value = int(value)\n\n        with self.lock:\n            self.value += value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_config(self):\n        if not self._config:\n            namespace = {}\n            if os.path.exists(self.config_path):\n                execfile(self.config_path, namespace)\n            self._config = namespace.get('config') or Configuration()\n        return self._config", "response": "Load user configuration or return default when not found."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending the object to the watch. Block until completion.", "response": "def send(self):\n        \"\"\"\n        Sends the object to the watch. Block until completion, or raises :exc:`.PutBytesError` on failure.\n\n        During transmission, a \"progress\" event will be periodically emitted with the following signature: ::\n\n           (sent_this_interval, sent_so_far, total_object_size)\n        \"\"\"\n        # Prepare the watch to receive something.\n        cookie = self._prepare()\n\n        # Send it.\n        self._send_object(cookie)\n\n        # Commit it.\n        self._commit(cookie)\n\n        # Install it.\n        self._install(cookie)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens the remote shell and returns the remote shell id", "response": "def open(self, input_streams=['stdin'], output_streams=['stderr', 'stdout']):\n        \"\"\"\n        Opens the remote shell\n        \"\"\"\n        shell = dict()\n        shell['rsp:InputStreams'] = \" \".join(input_streams)\n        shell['rsp:OutputStreams'] = \" \".join(output_streams)\n        shell['rsp:IdleTimeout'] = str(self.idle_timeout)\n\n        if self.working_directory is not None:\n            shell['rsp:WorkingDirectory'] = str(self.working_directory)\n\n        if self.environment is not None:\n            variables = []\n            for key, value in self.environment.items():\n                variables.append({'#text': str(value), '@Name': key})\n            shell['rsp:Environment'] = {'Variable': variables}\n\n        response = self.session.create(self.resource, {'rsp:Shell': shell})\n        self.__shell_id = response['rsp:Shell']['rsp:ShellId']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, command, arguments=(), console_mode_stdin=True, skip_cmd_shell=False):\n        logging.info('running command: ' + command)\n        resource = ResourceLocator(CommandShell.ShellResource)\n        resource.add_selector('ShellId', self.__shell_id)\n        resource.add_option('WINRS_SKIP_CMD_SHELL', ['FALSE', 'TRUE'][bool(skip_cmd_shell)], True)\n        resource.add_option('WINRS_CONSOLEMODE_STDIN', ['FALSE', 'TRUE'][bool(console_mode_stdin)], True)\n\n        command = OrderedDict([('rsp:Command', command)])\n        command['rsp:Arguments'] = list(arguments)\n\n        response = self.session.command(resource, {'rsp:CommandLine': command})\n        command_id = response['rsp:CommandResponse']['rsp:CommandId']\n        logging.info('receive command: ' + command_id)\n        return command_id", "response": "This function executes a command in the current session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receive(self, command_id, streams=('stdout', 'stderr'), command_timeout=60):\n        logging.info('receive command: ' + command_id)\n        response_streams = dict.fromkeys(streams, '')\n        (complete, exit_code) = self._receive_poll(command_id, response_streams)\n        while not complete:\n            (complete, exit_code) = self._receive_poll(command_id, response_streams)\n\n        # This retains some compatibility with pywinrm\n        if sorted(response_streams.keys()) == sorted(['stderr', 'stdout']):\n            return response_streams['stdout'], response_streams['stderr'], exit_code\n        else:\n            return response_streams, exit_code", "response": "Receive a set of data from the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the current session.", "response": "def close(self):\n        \"\"\"\n        Closes pipe\n        :return:\n        \"\"\"\n        resource = ResourceLocator(CommandShell.ShellResource)\n        resource.add_selector('ShellId', self.__shell_id)\n        self.session.delete(resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef change_dict_keys(self, data_dict, prefix):\n\n        keys = data_dict.keys()\n        dummy_dict = copy.deepcopy(data_dict)\n        changed_dict = {}\n        for key in keys:\n            changed_dict[prefix + str(key)] = dummy_dict.pop(key)\n        return changed_dict", "response": "Change the keys of the dictionary to include the prefix L_ and R_."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the final list of docs", "response": "def merge_join_docs(self, keys):\n        \"\"\"\n            Merges the final list of docs\n            :param left_collection_list: \n            :type  left_collection_list: MongoCollection\n\n            :return join: dict\n        \"\"\"\n\n        join = defaultdict(list)\n\n        for key in keys:\n            join[key] = self.generate_join_docs_list(\n                self.collections_data['left'].get(key, []), self.collections_data['right'].get(key, []))\n        return join"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms Inner Join :return inner_join: dict", "response": "def inner(self):\n        \"\"\"\n            Performs Inner Join\n            :return inner_join: dict\n        \"\"\"\n        self.get_collections_data()\n\n        inner_join = self.merge_join_docs(set(self.collections_data['left'].keys()) & set(\n            self.collections_data['right'].keys()))\n\n        return inner_join"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef left_outer(self):\n        self.get_collections_data()\n        left_outer_join = self.merge_join_docs(\n            set(self.collections_data['left'].keys()))\n        return left_outer_join", "response": "Returns the left outer join of the catalyms."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef right_outer(self):\n        self.get_collections_data()\n        right_outer_join = self.merge_join_docs(\n            set(self.collections_data['right'].keys()))\n        return right_outer_join", "response": "Returns the right outer join of the catalyms."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef full_outer(self):\n        self.get_collections_data()\n        full_outer_join = self.merge_join_docs(\n            set(self.collections_data['left'].keys()) | set(self.collections_data['right'].keys()))\n        return full_outer_join", "response": "Returns a dict of full outer join docs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef needs_auth(meth):\n    @functools.wraps(meth)\n    def wrapped(*args, **kwargs):\n        if not args[0].authorized:\n            raise exceptions.NotAuthorizedError('Please login first!')\n        return meth(*args, **kwargs)\n    return wrapped", "response": "Wraps a method of TwitchSession and\n    raises an exception if the session isn t authorized."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct a requests. Request object and sends it. Raises HTTPErrors by default.", "response": "def request(self, method, url, **kwargs):\n        \"\"\"Constructs a :class:`requests.Request`, prepares it and sends it.\n        Raises HTTPErrors by default.\n\n        :param method: method for the new :class:`Request` object.\n        :type method: :class:`str`\n        :param url: URL for the new :class:`Request` object.\n        :type url: :class:`str`\n        :param kwargs: keyword arguments of :meth:`requests.Session.request`\n        :returns: a resonse object\n        :rtype: :class:`requests.Response`\n        :raises: :class:`requests.HTTPError`\n        \"\"\"\n        if oauthlib.oauth2.is_secure_transport(url):\n            m = super(OAuthSession, self).request\n        else:\n            m = super(requests_oauthlib.OAuth2Session, self).request\n        log.debug(\"%s \\\"%s\\\" with %s\", method, url, kwargs)\n        response = m(method, url, **kwargs)\n        response.raise_for_status()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a login server that will get a request from a user logging in to twitch and grant PyTwitcher authorization.", "response": "def start_login_server(self, ):\n        \"\"\"Start a server that will get a request from a user logging in.\n\n        This uses the Implicit Grant Flow of OAuth2. The user is asked\n        to login to twitch and grant PyTwitcher authorization.\n        Once the user agrees, he is redirected to an url.\n        This server will respond to that url and get the oauth token.\n\n        The server serves in another thread. To shut him down, call\n        :meth:`TwitchSession.shutdown_login_server`.\n\n        This sets the :data:`TwitchSession.login_server`,\n        :data:`TwitchSession.login_thread` variables.\n\n        :returns: The created server\n        :rtype: :class:`BaseHTTPServer.HTTPServer`\n        :raises: None\n        \"\"\"\n        self.login_server = oauth.LoginServer(session=self)\n        target = self.login_server.serve_forever\n        self.login_thread = threading.Thread(target=target)\n        self.login_thread.setDaemon(True)\n        log.debug('Starting login server thread.')\n        self.login_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshuts down the login server and thread.", "response": "def shutdown_login_server(self, ):\n        \"\"\"Shutdown the login server and thread\n\n        :returns: None\n        :rtype: None\n        :raises: None\n        \"\"\"\n        log.debug('Shutting down the login server thread.')\n        self.login_server.shutdown()\n        self.login_server.server_close()\n        self.login_thread.join()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef token(self, token):\n        self._token = token\n        if token:\n            self.current_user = self.query_login_user()", "response": "Set the oauth token and the current_user_\n"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kraken_request(self, method, endpoint, **kwargs):\n        url = TWITCH_KRAKENURL + endpoint\n        headers = kwargs.setdefault('headers', {})\n        headers['Accept'] = TWITCH_HEADER_ACCEPT\n        headers['Client-ID'] = CLIENT_ID  # https://github.com/justintv/Twitch-API#rate-limits\n        return self.request(method, url, **kwargs)", "response": "Make a request to one of the kraken api endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef usher_request(self, method, endpoint, **kwargs):\n        url = TWITCH_USHERURL + endpoint\n        return self.request(method, url, **kwargs)", "response": "Make a request to one of the usher api endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a request to one of the old api endpoints.", "response": "def oldapi_request(self, method, endpoint, **kwargs):\n        \"\"\"Make a request to one of the old api endpoints.\n\n        The url will be constructed of :data:`TWITCH_APIURL` and\n        the given endpoint.\n\n        :param method: the request method\n        :type method: :class:`str`\n        :param endpoint: the endpoint of the old api.\n                         The base url is automatically provided.\n        :type endpoint: :class:`str`\n        :param kwargs: keyword arguments of :meth:`requests.Session.request`\n        :returns: a resonse object\n        :rtype: :class:`requests.Response`\n        :raises: :class:`requests.HTTPError`\n        \"\"\"\n        headers = kwargs.setdefault('headers', {})\n        headers['Client-ID'] = CLIENT_ID  # https://github.com/justintv/Twitch-API#rate-limits\n        url = TWITCH_APIURL + endpoint\n        return self.request(method, url, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the viewers and channels of the given game andset them on the object", "response": "def fetch_viewers(self, game):\n        \"\"\"Query the viewers and channels of the given game and\n        set them on the object\n\n        :returns: the given game\n        :rtype: :class:`models.Game`\n        :raises: None\n        \"\"\"\n        r = self.kraken_request('GET', 'streams/summary',\n                                params={'game': game.name}).json()\n        game.viewers = r['viewers']\n        game.channels = r['channels']\n        return game"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for games that are similar to the query string", "response": "def search_games(self, query, live=True):\n        \"\"\"Search for games that are similar to the query\n\n        :param query: the query string\n        :type query: :class:`str`\n        :param live: If true, only returns games that are live on at least one\n                     channel\n        :type live: :class:`bool`\n        :returns: A list of games\n        :rtype: :class:`list` of :class:`models.Game` instances\n        :raises: None\n        \"\"\"\n        r = self.kraken_request('GET', 'search/games',\n                                params={'query': query,\n                                        'type': 'suggest',\n                                        'live': live})\n        games = models.Game.wrap_search(r)\n        for g in games:\n            self.fetch_viewers(g)\n        return games"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef top_games(self, limit=10, offset=0):\n        r = self.kraken_request('GET', 'games/top',\n                                params={'limit': limit,\n                                        'offset': offset})\n        return models.Game.wrap_topgames(r)", "response": "Return the current top games in the current project."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_game(self, name):\n        games = self.search_games(query=name, live=False)\n        for g in games:\n            if g.name == name:\n                return g", "response": "Get the game instance for a game name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_channel(self, name):\n        r = self.kraken_request('GET', 'channels/' + name)\n        return models.Channel.wrap_get_channel(r)", "response": "Return the channel for the given name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches for channels and return them", "response": "def search_channels(self, query, limit=25, offset=0):\n        \"\"\"Search for channels and return them\n\n        :param query: the query string\n        :type query: :class:`str`\n        :param limit: maximum number of results\n        :type limit: :class:`int`\n        :param offset: offset for pagination\n        :type offset: :class:`int`\n        :returns: A list of channels\n        :rtype: :class:`list` of :class:`models.Channel` instances\n        :raises: None\n        \"\"\"\n        r = self.kraken_request('GET', 'search/channels',\n                                params={'query': query,\n                                        'limit': limit,\n                                        'offset': offset})\n        return models.Channel.wrap_search(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_stream(self, channel):\n        if isinstance(channel, models.Channel):\n            channel = channel.name\n\n        r = self.kraken_request('GET', 'streams/' + channel)\n        return models.Stream.wrap_get_stream(r)", "response": "Returns the stream of the given channel or None if the given channel is offline."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_streams(self, game=None, channels=None, limit=25, offset=0):\n        if isinstance(game, models.Game):\n            game = game.name\n\n        channelnames = []\n        cparam = None\n        if channels:\n            for c in channels:\n                if isinstance(c, models.Channel):\n                    c = c.name\n                channelnames.append(c)\n            cparam = ','.join(channelnames)\n\n        params = {'limit': limit,\n                  'offset': offset,\n                  'game': game,\n                  'channel': cparam}\n\n        r = self.kraken_request('GET', 'streams', params=params)\n        return models.Stream.wrap_search(r)", "response": "Returns a list of models. Stream objects for a given game or list of models. Channel objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_streams(self, query, hls=False, limit=25, offset=0):\n        r = self.kraken_request('GET', 'search/streams',\n                                params={'query': query,\n                                        'hls': hls,\n                                        'limit': limit,\n                                        'offset': offset})\n        return models.Stream.wrap_search(r)", "response": "Search for streams and return them"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of streams the current user follows.", "response": "def followed_streams(self, limit=25, offset=0):\n        \"\"\"Return the streams the current user follows.\n\n        Needs authorization ``user_read``.\n\n        :param limit: maximum number of results\n        :type limit: :class:`int`\n        :param offset: offset for pagination\n        :type offset: :class:`int`\n        :returns: A list of streams\n        :rtype: :class:`list`of :class:`models.Stream` instances\n        :raises: :class:`exceptions.NotAuthorizedError`\n        \"\"\"\n        r = self.kraken_request('GET', 'streams/followed',\n                                params={'limit': limit,\n                                        'offset': offset})\n        return models.Stream.wrap_search(r)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_user(self, name):\n        r = self.kraken_request('GET', 'user/' + name)\n        return models.User.wrap_get_user(r)", "response": "Get the user for the given name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the playlist for the given channel", "response": "def get_playlist(self, channel):\n        \"\"\"Return the playlist for the given channel\n\n        :param channel: the channel\n        :type channel: :class:`models.Channel` | :class:`str`\n        :returns: the playlist\n        :rtype: :class:`m3u8.M3U8`\n        :raises: :class:`requests.HTTPError` if channel is offline.\n        \"\"\"\n        if isinstance(channel, models.Channel):\n            channel = channel.name\n\n        token, sig = self.get_channel_access_token(channel)\n        params = {'token': token, 'sig': sig,\n                  'allow_audio_only': True,\n                  'allow_source': True}\n        r = self.usher_request(\n            'GET', 'channel/hls/%s.m3u8' % channel, params=params)\n        playlist = m3u8.loads(r.text)\n        return playlist"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the available quality options for a given channel.", "response": "def get_quality_options(self, channel):\n        \"\"\"Get the available quality options for streams of the given channel\n\n        Possible values in the list:\n\n          * source\n          * high\n          * medium\n          * low\n          * mobile\n          * audio\n\n        :param channel: the channel or channel name\n        :type channel: :class:`models.Channel` | :class:`str`\n        :returns: list of quality options\n        :rtype: :class:`list` of :class:`str`\n        :raises: :class:`requests.HTTPError` if channel is offline.\n        \"\"\"\n        optionmap = {'chunked': 'source',\n                     'high': 'high',\n                     'medium': 'medium',\n                     'low': 'low',\n                     'mobile': 'mobile',\n                     'audio_only': 'audio'}\n        p = self.get_playlist(channel)\n        options = []\n        for pl in p.playlists:\n            q = pl.media[0].group_id\n            options.append(optionmap[q])\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_channel_access_token(self, channel):\n        if isinstance(channel, models.Channel):\n            channel = channel.name\n        r = self.oldapi_request(\n            'GET', 'channels/%s/access_token' % channel).json()\n        return r['token'], r['sig']", "response": "Get the token and sig for the given channel"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_chat_server(self, channel):\n        r = self.oldapi_request(\n            'GET', 'channels/%s/chat_properties' % channel.name)\n        json = r.json()\n        servers = json['chat_servers']\n\n        try:\n            r = self.get(TWITCH_STATUSURL)\n        except requests.HTTPError:\n            log.debug('Error getting chat server status. Using random one.')\n            address = servers[0]\n        else:\n            stats = [client.ChatServerStatus(**d) for d in r.json()]\n            address = self._find_best_chat_server(servers, stats)\n\n        server, port = address.split(':')\n        return server, int(port)", "response": "Get an appropriate chat server for the given channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _find_best_chat_server(servers, stats):\n        best = servers[0]  # In case we sind no match with any status\n        stats.sort()  # gets sorted for performance\n        for stat in stats:\n            for server in servers:\n                if server == stat:\n                    # found a chatserver that has the same address\n                    # than one of the chatserverstats.\n                    # since the stats are sorted for performance\n                    # the first hit is the best, thus break\n                    best = server\n                    break\n            if best:\n                # already found one, so no need to check the other\n                # statuses, which are worse\n                break\n        return best", "response": "Find the best chat server from a list of servers by comparing with the stats\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the picture for the given emote", "response": "def get_emote_picture(self, emote, size=1.0):\n        \"\"\"Return the picture for the given emote\n\n        :param emote: the emote object\n        :type emote: :class:`pytwitcherapi.chat.message.Emote`\n        :param size: the size of the picture.\n                     Choices are: 1.0, 2.0, 3.0\n        :type size: :class:`float`\n        :returns: A string resembling the picturedata of the emote\n        :rtype: :class:`str`\n        :raises: None\n        \"\"\"\n        r = self.get('http://static-cdn.jtvnw.net/emoticons/v1/%s/%s' %\n                     (emote.emoteid, size))\n        return r.content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nescaping a string which should be syntactically valid JSON.", "response": "def escapejson(string):\n    '''\n    Escape `string`, which should be syntactically valid JSON (this is not\n    verified), so that it is safe for inclusion in HTML <script> environments\n    and as literal javascript.\n    '''\n    for fro, to in replacements:\n        string = string.replace(fro, to)\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_glob(string, split_str=' '):\n    string = _GLOB_PORTION_RE.sub(split_str, string)\n    return string.strip()", "response": "Strip glob portion in string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef daterange(start, end, delta=timedelta(days=1), lower=Interval.CLOSED, upper=Interval.OPEN):\n    date_interval = Interval(lower=lower, lower_value=start, upper_value=end, upper=upper)\n    current = start if start in date_interval else start + delta\n    while current in date_interval:\n        yield current\n        current = current + delta", "response": "Returns a generator which creates the next value in the range on demand"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_message(self, target_app, dictionary):\n        tid = self._get_txid()\n        message = self._message_type(transaction_id=tid)\n        tuples = []\n        for k, v in iteritems(dictionary):\n            if isinstance(v, AppMessageNumber):\n                tuples.append(AppMessageTuple(key=k, type=v.type,\n                                data=struct.pack(self._type_mapping[v.type, v.length], v.value)))\n            elif v.type == AppMessageTuple.Type.CString:\n                tuples.append(AppMessageTuple(key=k, type=v.type, data=v.value.encode('utf-8') + b'\\x00'))\n            elif v.type == AppMessageTuple.Type.ByteArray:\n                tuples.append(AppMessageTuple(key=k, type=v.type, data=v.value))\n        message.data = AppMessagePush(uuid=target_app, dictionary=tuples)\n        self._pending_messages[tid] = target_app\n        self._pebble.send_packet(message)\n        return tid", "response": "Send a message to the given app."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_metric(name, class_, *args, **kwargs):\n\n    with LOCK:\n        try:\n            item = REGISTRY[name]\n        except KeyError:\n            item = REGISTRY[name] = class_(*args, **kwargs)\n            return item\n\n    raise DuplicateMetricError(\"Metric {} already exists of type {}\".format(name, type(item).__name__))", "response": "Create a new metric of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_metric(name):\n\n    with LOCK:\n        old_metric = REGISTRY.pop(name, None)\n\n        # look for the metric name in the tags and remove it\n        for _, tags in py3comp.iteritems(TAGS):\n            if name in tags:\n                tags.remove(name)\n\n    return old_metric", "response": "Remove the named metric from the registry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_histogram(name, reservoir=None):\n\n    if reservoir is None:\n        reservoir = histogram.UniformReservoir(histogram.DEFAULT_UNIFORM_RESERVOIR_SIZE)\n\n    return new_metric(name, histogram.Histogram, reservoir)", "response": "Build a new histogram metric with a given reservoir"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_histogram_with_implicit_reservoir(name, reservoir_type='uniform', *reservoir_args, **reservoir_kwargs):\n\n    reservoir = new_reservoir(reservoir_type, *reservoir_args, **reservoir_kwargs)\n    return new_histogram(name, reservoir)", "response": "Create a new histogram with an implicit reservoir."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_reservoir(reservoir_type='uniform', *reservoir_args, **reservoir_kwargs):\n\n    try:\n        reservoir_cls = RESERVOIR_TYPES[reservoir_type]\n    except KeyError:\n        raise InvalidMetricError(\"Unknown reservoir type: {}\".format(reservoir_type))\n\n    return reservoir_cls(*reservoir_args, **reservoir_kwargs)", "response": "Build a new reservoir of the given type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a histogram with the given name or raises DuplicateMetricError", "response": "def get_or_create_histogram(name, reservoir_type, *reservoir_args, **reservoir_kwargs):\n    \"\"\"\n    Will return a histogram matching the given parameters or raise\n    DuplicateMetricError if it can't be created due to a name collision\n    with another histogram with different parameters.\n    \"\"\"\n    reservoir = new_reservoir(reservoir_type, *reservoir_args, **reservoir_kwargs)\n\n    try:\n        hmetric = new_histogram(name, reservoir)\n    except DuplicateMetricError:\n        hmetric = metric(name)\n        if not isinstance(hmetric, histogram.Histogram):\n            raise DuplicateMetricError(\n                \"Metric {!r} already exists of type {!r}\".format(name, type(hmetric).__name__))\n\n        if not hmetric.reservoir.same_kind(reservoir):\n            raise DuplicateMetricError(\n                \"Metric {!r} already exists with a different reservoir: {}\".format(name, hmetric.reservoir))\n\n    return hmetric"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef with_histogram(name, reservoir_type=\"uniform\", *reservoir_args, **reservoir_kwargs):\n\n    hmetric = get_or_create_histogram(name, reservoir_type, *reservoir_args, **reservoir_kwargs)\n\n    def wrapper(f):\n\n        @functools.wraps(f)\n        def fun(*args, **kwargs):\n            t1 = time.time()\n            res = f(*args, **kwargs)\n            t2 = time.time()\n\n            hmetric.notify(t2-t1)\n            return res\n\n        return fun\n\n    return wrapper", "response": "Decorator to add a histogram to a new node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef timer(name, reservoir_type=\"uniform\", *reservoir_args, **reservoir_kwargs):\n\n    hmetric = get_or_create_histogram(name, reservoir_type, *reservoir_args, **reservoir_kwargs)\n\n    t1 = time.time()\n    yield\n    t2 = time.time()\n    hmetric.notify(t2 - t1)", "response": "Context manager that returns a timer that updates the time spent in the wrapped block\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tag(name, tag_name):\n\n    with LOCK:\n        # just to check if <name> exists\n        metric(name)\n\n        TAGS.setdefault(tag_name, set()).add(name)", "response": "Tag the named metric with the given tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the given tag from the given metric.", "response": "def untag(name, tag_name):\n    \"\"\"\n    Remove the given tag from the given metric.\n    Return True if the metric was tagged, False otherwise\n    \"\"\"\n\n    with LOCK:\n        by_tag = TAGS.get(tag_name, None)\n        if not by_tag:\n            return False\n        try:\n            by_tag.remove(name)\n\n            # remove the tag if no associations left\n            if not by_tag:\n                TAGS.pop(tag_name)\n\n            return True\n        except KeyError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef metrics_by_name_list(names):\n    results = {}\n\n    for name in names:\n        # no lock - a metric could have been removed in the meanwhile\n        try:\n            results[name] = get(name)\n        except InvalidMetricError:\n            continue\n\n    return results", "response": "Returns a dictionary with all the metrics with the given names."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake an imshow of the intranetwork connectivity", "response": "def connectivity(ax):\n\n    '''make an imshow of the intranetwork connectivity'''\n    masked_array = np.ma.array(params.C_YX, mask=params.C_YX==0)\n    # if analysis_params.bw:\n    #     cmap = plt.get_cmap(gray, 20)\n    #     cmap.set_bad('k', 1.)\n    # else:\n    #     cmap = plt.get_cmap('hot', 20)\n    #     cmap.set_bad('k', 0.5)\n    # im = ax.imshow(masked_array, cmap=cmap, vmin=0, interpolation='nearest')\n    im = ax.pcolormesh(masked_array, cmap=cmap, vmin=0, ) #interpolation='nearest')\n    ax.axis(ax.axis('tight'))\n    ax.invert_yaxis()\n    ax.xaxis.set_ticks_position('top')\n    ax.set_xticks(np.arange(9)+0.5)\n    ax.set_yticks(np.arange(8)+0.5)\n    ax.set_xticklabels(params.X, rotation=270)\n    ax.set_yticklabels(params.Y, )\n    ax.xaxis.set_label_position('top')\n    ax.set_xlabel(r'$X$', labelpad=-1,fontsize=8)\n    ax.set_ylabel(r'$Y$', labelpad=0, rotation=0,fontsize=8)\n\n    rect = np.array(ax.get_position().bounds)\n    rect[0] += rect[2] + 0.01\n    rect[2] = 0.01\n    fig = plt.gcf()\n    cax = fig.add_axes(rect)\n\n    cbar = plt.colorbar(im, cax=cax)\n    #cbar.set_label(r'$C_{YX}$', ha='center')\n    cbar.set_label(r'$C_{YX}$', labelpad=0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cell_type_specificity(ax):\n    '''make an imshow of the intranetwork connectivity'''\n    masked_array = np.ma.array(params.T_yX, mask=params.T_yX==0)\n    # cmap = plt.get_cmap('hot', 20)\n    # cmap.set_bad('k', 0.5)\n    # im = ax.imshow(masked_array, cmap=cmap, vmin=0, interpolation='nearest')\n    im = ax.pcolormesh(masked_array, cmap=cmap, vmin=0, ) #interpolation='nearest')\n    ax.axis(ax.axis('tight'))\n    ax.invert_yaxis()\n    ax.xaxis.set_ticks_position('top')\n    ax.set_xticks(np.arange(9)+0.5)\n    ax.set_yticks(np.arange(16)+0.5)\n    ax.set_xticklabels(params.X, rotation=270)\n    ax.set_yticklabels(params.y, )\n    ax.xaxis.set_label_position('top')\n    ax.set_xlabel(r'$X$', labelpad=-1,fontsize=8)\n    ax.set_ylabel(r'$y$', labelpad=0, rotation=0,fontsize=8)\n\n    rect = np.array(ax.get_position().bounds)\n    rect[0] += rect[2] + 0.01\n    rect[2] = 0.01\n    fig = plt.gcf()\n    cax = fig.add_axes(rect)\n\n    cbar = plt.colorbar(im, cax=cax)\n    #cbar.set_label(r'$\\mathcal{T}_{yX}$', ha='center')\n    cbar.set_label(r'$\\mathcal{T}_{yX}$', labelpad=0)", "response": "make an imshow of the intranetwork connectivity"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quantity_yXL(fig, left, bottom, top, quantity=params.L_yXL, label=r'$\\mathcal{L}_{yXL}$'):\n                            \n    '''make a bunch of image plots, each showing the spatial normalized\n    connectivity of synapses'''\n    \n \n    layers = ['L1', 'L2/3', 'L4', 'L5', 'L6']\n    ncols = len(params.y) / 4\n    \n    #assess vlims\n    vmin = 0\n    vmax = 0\n    for y in params.y:\n        if quantity[y].max() > vmax:\n            vmax = quantity[y].max()\n    \n    gs = gridspec.GridSpec(4, 4, left=left, bottom=bottom, top=top)\n    \n    for i, y in enumerate(params.y):\n        ax = fig.add_subplot(gs[i/4, i%4])\n\n        masked_array = np.ma.array(quantity[y], mask=quantity[y]==0)\n        # cmap = plt.get_cmap('hot', 20)\n        # cmap.set_bad('k', 0.5)\n        \n        # im = ax.imshow(masked_array,\n        im = ax.pcolormesh(masked_array,\n                            vmin=vmin, vmax=vmax,\n                            cmap=cmap,\n                            #interpolation='nearest',\n                            )\n        ax.invert_yaxis()\n\n        ax.axis(ax.axis('tight'))\n        ax.xaxis.set_ticks_position('top')\n        ax.set_xticks(np.arange(9)+0.5)\n        ax.set_yticks(np.arange(5)+0.5)\n        \n        #if divmod(i, 4)[1] == 0:\n        if i % 4 == 0:\n            ax.set_yticklabels(layers, )\n            ax.set_ylabel('$L$', labelpad=0.)\n        else:\n            ax.set_yticklabels([])\n        if i < 4:\n            ax.set_xlabel(r'$X$', labelpad=-1,fontsize=8)\n            ax.set_xticklabels(params.X, rotation=270)\n        else:\n            ax.set_xticklabels([])\n        ax.xaxis.set_label_position('top')\n        \n        ax.text(0.5, -0.13, r'$y=$'+y,\n            horizontalalignment='center',\n            verticalalignment='center',\n            #\n                transform=ax.transAxes,fontsize=5.5)\n    \n    #colorbar\n    rect = np.array(ax.get_position().bounds)\n    rect[0] += rect[2] + 0.01\n    rect[1] = bottom\n    rect[2] = 0.01\n    rect[3] = top-bottom\n    cax = fig.add_axes(rect)\n    cbar = plt.colorbar(im, cax=cax)\n    #cbar.set_label(label, ha='center')\n    cbar.set_label(label, labelpad=0)", "response": "make a bunch of image plots each showing the spatial normalized synapses connectivity of synapses"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, url, proto='http'):\n        self.last_response = self.session.get(proto + self.base_uri + url,\n                                              headers=self.headers,\n                                              cookies=self.cookies,\n                                              allow_redirects=True,\n                                              verify=self.verify)\n        return self.last_response_soup", "response": "Load an url using the GET method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post(self, url, data, proto='http', form_name=None):\n        form = self.translator.fill_form(self.last_response_soup,\n                                         form_name if form_name else url, data)\n        self.last_response = self.session.post(proto + self.base_uri + url,\n                                               headers=self.headers,\n                                               cookies=self.cookies,\n                                               data=form,\n                                               allow_redirects=True,\n                                               verify=self.verify)\n        return self.last_response_soup", "response": "Load an url using the POST method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction that calculates the STA of LFP and recontructs the LFP from kernels.", "response": "def fig_kernel_lfp_CINPLA(savefolders, params, transient=200, X='L5E', lags=[20, 20]):\n\n    '''\n    This function calculates the  STA of LFP, extracts kernels and recontructs the LFP from kernels.\n    \n    kwargs:\n    ::\n      transient : the time in milliseconds, after which the analysis should begin\n                so as to avoid any starting transients\n      X : id of presynaptic trigger population\n       \n    '''\n\n    # Electrode geometry\n    zvec = np.r_[params.electrodeParams['z']]\n\n    alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n\n\n\n    ana_params.set_PLOS_2column_fig_style(ratio=0.5)\n    # Start the figure\n    fig = plt.figure()\n    fig.subplots_adjust(left=0.06, right=0.95, bottom=0.075, top=0.925, hspace=0.23, wspace=0.55) \n\n    # create grid_spec\n    gs = gridspec.GridSpec(1, 7)\n\n\n    ###########################################################################\n    # Part A: spikegen \"network\" activity\n    ############################################################################\n        \n    # path to simulation files\n    params.savefolder = 'simulation_output_spikegen'\n    params.figures_path = os.path.join(params.savefolder, 'figures')\n    params.spike_output_path = os.path.join(params.savefolder,\n                                                       'processed_nest_output')\n    params.networkSimParams['spike_output_path'] = params.spike_output_path\n    \n    \n    # Get the spikegen LFP:\n    f = h5py.File(os.path.join('simulation_output_spikegen', 'LFPsum.h5'))\n    srate = f['srate'].value\n    tvec = np.arange(f['data'].shape[1]) * 1000. / srate\n    \n    # slice\n    inds = (tvec < params.tstop) & (tvec >= transient)\n    \n    data_sg_raw = f['data'].value.astype(float)\n    f.close()\n    #\n    # kernel width\n    kwidth = 20\n    \n    # extract kernels\n    kernels = np.zeros((len(params.N_X), 16, 100))\n    for j in range(len(params.X)):\n        kernels[j] = data_sg_raw[:, 100+kwidth+j*100:100+kwidth+(j+1)*100] / params.N_X[j]\n    \n    \n    # create some dummy spike times\n    activationtimes = np.array([x*100 for x in range(3,11)] + [200])\n    networkSimSpikegen = CachedNetwork(**params.networkSimParams)\n\n    x, y = networkSimSpikegen.get_xy([transient, params.tstop])\n\n    ###########################################################################\n    # Part A: spatiotemporal kernels, all presynaptic populations\n    ############################################################################\n    \n    titles = ['TC',\n              'L23E/I',\n              'LFP kernels \\n L4E/I',\n              'L5E/I',\n              'L6E/I',\n              ]\n    \n    COUNTER = 0 \n    for i, X__ in enumerate(([['TC']]) + zip(params.X[1::2], params.X[2::2])):        \n        ax = fig.add_subplot(gs[0, i])\n        if i == 0:\n            phlp.annotate_subplot(ax, ncols=7, nrows=4, letter=alphabet[0], linear_offset=0.02)\n    \n        for j, X_ in enumerate(X__):\n            # create spikegen histogram for population Y\n            cinds = np.arange(activationtimes[np.arange(-1, 8)][COUNTER]-kwidth,\n                              activationtimes[np.arange(-1, 8)][COUNTER]+kwidth+2)\n            x0_sg = np.histogram(x[X_], bins=tvec[cinds])[0].astype(float)\n        \n            if X_ == ('TC'):\n                color='r'\n            else:\n                color=('r', 'b')[j]\n            \n            \n            # plot kernel as correlation of spikegen LFP signal with delta spike train\n            xcorr, vlimround = plotting_correlation(x0_sg/x0_sg.sum()**2, \n                                 data_sg_raw[:, cinds[:-1]]*1E3,\n                                 ax, normalize=False,\n                                 lag=kwidth,\n                                 color=color,\n                                 scalebar=False)\n            if i > 0:\n                ax.set_yticklabels([])\n            \n            ## Create scale bar\n            ax.plot([kwidth, kwidth],\n                [-1500 + j*3*100, -1400 + j*3*100], lw=2, color=color,\n                clip_on=False)\n            ax.text(kwidth*1.08, -1450 + j*3*100, '%.1f $\\mu$V' % vlimround,\n                        rotation='vertical', va='center')\n    \n            ax.set_xlim((-5, kwidth))\n            ax.set_xticks([-20, 0, 20])\n            ax.set_xticklabels([-20, 0, 20])\n            \n            COUNTER += 1\n            \n        ax.set_title(titles[i])\n\n\n    for i, (savefolder, lag) in enumerate(zip(savefolders, lags)):\n        \n        # path to simulation files\n        params.savefolder = os.path.join(os.path.split(params.savefolder)[0],\n                                         savefolder)\n        params.figures_path = os.path.join(params.savefolder, 'figures')\n        params.spike_output_path = os.path.join(params.savefolder,\n                                                'processed_nest_output')\n        params.networkSimParams['spike_output_path'] = params.spike_output_path\n\n        #load spike as database inside function to avoid buggy behaviour\n        networkSim = CachedNetwork(**params.networkSimParams)\n\n    \n    \n        # Get the Compound LFP: LFPsum : data[nchannels, timepoints ]\n        f = h5py.File(os.path.join(params.savefolder, 'LFPsum.h5'))\n        data_raw = f['data'].value\n        srate = f['srate'].value\n        tvec = np.arange(data_raw.shape[1]) * 1000. / srate\n        # slice\n        inds = (tvec < params.tstop) & (tvec >= transient)\n        data = data_raw[:,inds]\n        # subtract mean\n        dataT = data.T - data.mean(axis=1)\n        data = dataT.T\n        f.close()\n    \n        # Get the spikegen LFP:\n        f = h5py.File(os.path.join('simulation_output_spikegen', 'LFPsum.h5'))\n        data_sg_raw = f['data'].value\n        # slice\n        data_sg = data_sg_raw[:,inds[data_sg_raw.shape[1]]]\n        f.close()\n    \n    \n    \n    \n        ########################################################################\n        # Part B: STA LFP\n        ########################################################################\n        \n        ax = fig.add_subplot(gs[0, 5 + i])\n        phlp.annotate_subplot(ax, ncols=15, nrows=4, letter=alphabet[i+1],\n                              linear_offset=0.02)\n          \n        # collect the spikes x is the times, y is the id of the cell.\n        x, y = networkSim.get_xy([0,params.tstop])\n        \n        # Get the spikes for the population of interest given as 'Y'\n        bins = np.arange(0, params.tstop+2)\n        x0_raw = np.histogram(x[X], bins=bins)[0]\n        x0 = x0_raw[inds].astype(float)\n    \n        # correlation between firing rate and LFP deviation\n        # from mean normalized by the number of spikes  \n        xcorr, vlimround = plotting_correlation(x0/x0.sum(), \n                             data*1E3,\n                             ax, normalize=False, \n                             #unit='%.3f mV',\n                             lag=lag,\n                             scalebar=False,\n                             color='k',\n                             title='stLFP\\n(trigger %s)' %X,\n                             )\n\n        # Create scale bar\n        ax.plot([lag, lag],\n            [-1500, -1400], lw=2, color='k',\n            clip_on=False)\n        ax.text(lag*1.04, -1450, '%.1f $\\mu$V' % vlimround,\n                    rotation='vertical', va='center')\n\n\n        [Xind] = np.where(np.array(networkSim.X) == X)[0]        \n                \n        # create spikegen histogram for population Y\n        x0_sg = np.zeros(x0.shape, dtype=float)\n        x0_sg[activationtimes[Xind]] += params.N_X[Xind]\n        \n        ax.set_yticklabels([])\n        ax.set_xticks([-lag, 0, lag])\n        ax.set_xticklabels([-lag, 0, lag])\n        \n\n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fig_kernel_lfp_EITN_II(savefolders, params, transient=200, T=[800., 1000.], X='L5E',\n                   lags=[20, 20], channels=[0,3,7,11,13]):\n\n    '''\n    This function calculates the  STA of LFP, extracts kernels and recontructs the LFP from kernels.\n    \n    Arguments\n    ::\n      transient : the time in milliseconds, after which the analysis should begin\n                so as to avoid any starting transients\n      X : id of presynaptic trigger population\n       \n    '''\n\n    # Electrode geometry\n    zvec = np.r_[params.electrodeParams['z']]\n\n    alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n\n\n\n    ana_params.set_PLOS_2column_fig_style(ratio=0.5)\n    # Start the figure\n    fig = plt.figure()\n    fig.subplots_adjust(left=0.06, right=0.95, bottom=0.08, top=0.9, hspace=0.23, wspace=0.55) \n\n    # create grid_spec\n    gs = gridspec.GridSpec(len(channels), 7)\n\n\n    ###########################################################################\n    # spikegen \"network\" activity\n    ############################################################################\n    \n    \n    # path to simulation files\n    savefolder = 'simulation_output_spikegen'\n    params.savefolder = os.path.join(os.path.split(params.savefolder)[0],\n                                         savefolder)\n    params.figures_path = os.path.join(params.savefolder, 'figures')\n    params.spike_output_path = os.path.join(params.savefolder,\n                                                       'processed_nest_output')\n    params.networkSimParams['spike_output_path'] = params.spike_output_path\n    \n    \n    # Get the spikegen LFP:\n    f = h5py.File(os.path.join('simulation_output_spikegen', 'LFPsum.h5'))\n    srate = f['srate'].value\n    tvec = np.arange(f['data'].shape[1]) * 1000. / srate\n    \n    # slice\n    inds = (tvec < params.tstop) & (tvec >= transient)\n    \n    data_sg_raw = f['data'].value.astype(float)\n    data_sg = data_sg_raw[:, inds]\n    f.close()\n    \n    # kernel width\n    kwidth = 20\n    \n    # create some dummy spike times\n    activationtimes = np.array([x*100 for x in range(3,11)] + [200])\n    networkSimSpikegen = CachedNetwork(**params.networkSimParams)\n\n    x, y = networkSimSpikegen.get_xy([transient, params.tstop])\n\n    \n    ############################################################################\n    ## Part A: spatiotemporal kernels, all presynaptic populations\n    #############################################################################\n    #\n    #titles = ['TC',\n    #          'L23E/I',\n    #          'LFP kernels \\n L4E/I',\n    #          'L5E/I',\n    #          'L6E/I',\n    #          ]\n    #\n    #COUNTER = 0 \n    #for i, X__ in enumerate(([['TC']]) + zip(params.X[1::2], params.X[2::2])):        \n    #    ax = fig.add_subplot(gs[:len(channels), i])\n    #    if i == 0:\n    #        phlp.annotate_subplot(ax, ncols=7, nrows=4, letter=alphabet[0], linear_offset=0.02)\n    #\n    #    for j, X_ in enumerate(X__):\n    #        # create spikegen histogram for population Y\n    #        cinds = np.arange(activationtimes[np.arange(-1, 8)][COUNTER]-kwidth,\n    #                          activationtimes[np.arange(-1, 8)][COUNTER]+kwidth+2)\n    #        x0_sg = np.histogram(x[X_], bins=cinds)[0].astype(float)\n    #        \n    #        if X_ == ('TC'):\n    #            color='r'\n    #        else:\n    #            color=('r', 'b')[j]\n    #        \n    #        \n    #        # plot kernel as correlation of spikegen LFP signal with delta spike train\n    #        xcorr, vlimround = plotting_correlation(params,\n    #                                                x0_sg/x0_sg.sum()**2, \n    #                                                data_sg_raw[:, cinds[:-1]]*1E3,\n    #                                                ax, normalize=False,\n    #                                                lag=kwidth,\n    #                                                color=color,\n    #                                                scalebar=False)\n    #        if i > 0:\n    #            ax.set_yticklabels([])\n    #        \n    #        ## Create scale bar\n    #        ax.plot([kwidth, kwidth],\n    #            [-1500 + j*3*100, -1400 + j*3*100], lw=2, color=color,\n    #            clip_on=False)\n    #        ax.text(kwidth*1.08, -1450 + j*3*100, '%.1f $\\mu$V' % vlimround,\n    #                    rotation='vertical', va='center')\n    #\n    #        ax.set_xlim((-5, kwidth))\n    #        ax.set_xticks([-20, 0, 20])\n    #        ax.set_xticklabels([-20, 0, 20])\n    #        \n    #        COUNTER += 1\n    #        \n    #    ax.set_title(titles[i])\n    \n\n    ################################################\n    # Iterate over savefolders\n    ################################################\n\n    for i, (savefolder, lag) in enumerate(zip(savefolders, lags)):\n        \n        # path to simulation files\n        params.savefolder = os.path.join(os.path.split(params.savefolder)[0],\n                                         savefolder)\n        params.figures_path = os.path.join(params.savefolder, 'figures')\n        params.spike_output_path = os.path.join(params.savefolder,\n                                                'processed_nest_output')\n        params.networkSimParams['spike_output_path'] = params.spike_output_path\n        \n        #load spike as database inside function to avoid buggy behaviour\n        networkSim = CachedNetwork(**params.networkSimParams)\n        \n        \n        \n        # Get the Compound LFP: LFPsum : data[nchannels, timepoints ]\n        f = h5py.File(os.path.join(params.savefolder, 'LFPsum.h5'))\n        data_raw = f['data'].value\n        srate = f['srate'].value\n        tvec = np.arange(data_raw.shape[1]) * 1000. / srate\n        # slice\n        inds = (tvec < params.tstop) & (tvec >= transient)\n        data = data_raw[:, inds]\n        # subtract mean\n        dataT = data.T - data.mean(axis=1)\n        data = dataT.T\n        f.close()\n        \n        # Get the spikegen LFP:\n        f = h5py.File(os.path.join('simulation_output_spikegen', 'LFPsum.h5'))\n        data_sg_raw = f['data'].value\n        \n        f.close()\n        #\n        #\n        #\n        #\n        #########################################################################\n        ## Part B: STA LFP\n        #########################################################################\n        #\n        #titles = ['staLFP(%s)\\n(spont.)' % X, 'staLFP(%s)\\n(AC. mod.)' % X]\n        #ax = fig.add_subplot(gs[:len(channels), 5 + i])\n        #if i == 0:\n        #    phlp.annotate_subplot(ax, ncols=15, nrows=4, letter=alphabet[i+1],\n        #                          linear_offset=0.02)\n        #  \n        #collect the spikes x is the times, y is the id of the cell.\n        x, y = networkSim.get_xy([0,params.tstop])\n        #\n        ## Get the spikes for the population of interest given as 'Y'\n        bins = np.arange(0, params.tstop+2) + 0.5\n        x0_raw = np.histogram(x[X], bins=bins)[0]\n        x0 = x0_raw[inds].astype(float)\n        #\n        ## correlation between firing rate and LFP deviation\n        ## from mean normalized by the number of spikes  \n        #xcorr, vlimround = plotting_correlation(params,\n        #                                        x0/x0.sum(), \n        #                                        data*1E3,\n        #                                        ax, normalize=False, \n        #                                        #unit='%.3f mV',\n        #                                        lag=lag,\n        #                                        scalebar=False,\n        #                                        color='k',\n        #                                        title=titles[i],\n        #                                        )\n        #\n        ## Create scale bar\n        #ax.plot([lag, lag],\n        #    [-1500, -1400], lw=2, color='k',\n        #    clip_on=False)\n        #ax.text(lag*1.08, -1450, '%.1f $\\mu$V' % vlimround,\n        #            rotation='vertical', va='center')\n        #\n        #\n        #[Xind] = np.where(np.array(networkSim.X) == X)[0]        \n        #        \n        ## create spikegen histogram for population Y\n        #x0_sg = np.zeros(x0.shape, dtype=float)\n        #x0_sg[activationtimes[Xind]] += params.N_X[Xind]\n        #\n        #\n        #ax.set_yticklabels([])\n        #ax.set_xticks([-lag, 0, lag])\n        #ax.set_xticklabels([-lag, 0, lag])\n\n        \n        ###########################################################################\n        # Part C, F: LFP and reconstructed LFP\n        ############################################################################\n\n        # create grid_spec\n        gsb = gridspec.GridSpec(len(channels), 8)\n\n      \n        ax = fig.add_subplot(gsb[:, (i*4):(i*4+2)])\n        phlp.annotate_subplot(ax, ncols=8/2., nrows=4, letter=alphabet[i*3+2],\n                              linear_offset=0.02)\n          \n        # extract kernels, force negative lags to be zero\n        kernels = np.zeros((len(params.N_X), 16, kwidth*2))\n        for j in range(len(params.X)):\n            kernels[j, :, kwidth:] = data_sg_raw[:, (j+2)*100:kwidth+(j+2)*100]/params.N_X[j]\n    \n        LFP_reconst_raw = np.zeros(data_raw.shape)\n    \n        for j, pop in enumerate(params.X):\n            x0_raw = np.histogram(x[pop], bins=bins)[0].astype(float)\n            for ch in range(kernels.shape[1]):\n                LFP_reconst_raw[ch] += np.convolve(x0_raw, kernels[j, ch],\n                                                   'same')\n        \n        # slice\n        LFP_reconst = LFP_reconst_raw[:, inds]\n        # subtract mean\n        LFP_reconstT = LFP_reconst.T - LFP_reconst.mean(axis=1)\n        LFP_reconst = LFP_reconstT.T\n        vlimround = plot_signal_sum(ax, params,\n                                    fname=os.path.join(params.savefolder,\n                                                           'LFPsum.h5'),\n                    unit='mV', scalebar=True,\n                        T=T, ylim=[-1550, 50],\n                        color='k', label='$real$',\n                        rasterized=False)\n    \n        plot_signal_sum(ax, params, fname=LFP_reconst_raw,\n                    unit='mV', scaling_factor= 1., scalebar=False,\n                        vlimround=vlimround,\n                        T=T, ylim=[-1550, 50],\n                        color='r', label='$reconstr$',\n                        rasterized=False)\n        ax.set_title('LFP & population \\n rate predictor')\n        if i > 0:\n            ax.set_yticklabels([])\n\n\n        \n        ###########################################################################\n        # Part D,G: Correlation coefficient\n        ############################################################################\n        \n        ax = fig.add_subplot(gsb[:, i*4+2:i*4+3])\n        phlp.remove_axis_junk(ax)\n        phlp.annotate_subplot(ax, ncols=8./1, nrows=4, letter=alphabet[i*3+3],\n                              linear_offset=0.02)\n            \n        cc = np.zeros(len(zvec))\n        for ch in np.arange(len(zvec)):\n            cc[ch] = np.corrcoef(data[ch], LFP_reconst[ch])[1, 0]\n        \n        ax.barh(zvec, cc, height=90, align='center', color='1', linewidth=0.5)\n        ax.set_ylim([-1550, 50])\n        ax.set_yticklabels([])\n        ax.set_yticks(zvec)\n        ax.set_xlim([0.0, 1.])\n        ax.set_xticks([0.0, 0.5, 1])\n        ax.yaxis.tick_left()\n        ax.set_xlabel('$cc$ (-)', labelpad=0.1)\n        ax.set_title('corr. \\n coef.')\n    \n        print 'correlation coefficients:'\n        print cc\n\n\n        ###########################################################################\n        # Part E,H: Power spectra\n        ############################################################################\n        \n\n        #compute PSDs ratio between ground truth and estimate\n        freqs, PSD_data = calc_signal_power(params, fname=data,\n                                            transient=transient, Df=None, mlab=True,\n                                            NFFT=256, noverlap=128,\n                                            window=plt.mlab.window_hanning)\n        freqs, PSD_LFP_reconst = calc_signal_power(params, fname=LFP_reconst,\n                                            transient=transient, Df=None, mlab=True,\n                                            NFFT=256, noverlap=128,\n                                            window=plt.mlab.window_hanning)\n\n        zv = np.r_[params.electrodeParams['z']]\n        zv = np.r_[zv, zv[-1] + np.diff(zv)[-1]]\n        inds = freqs >= 1  # frequencies greater than 1 Hz  \n\n        for j, ch in enumerate(channels):\n        \n            ax = fig.add_subplot(gsb[j, (i*4+3):(i*4+4)])\n            if j == 0:\n                phlp.annotate_subplot(ax, ncols=8./1, nrows=4.5*len(channels),\n                                      letter=alphabet[i*3+4], linear_offset=0.02)\n                ax.set_title('PSD')\n                \n\n            phlp.remove_axis_junk(ax)\n            ax.loglog(freqs[inds], PSD_data[ch, inds], 'k', label='LFP', clip_on=True)\n            ax.loglog(freqs[inds], PSD_LFP_reconst[ch, inds], 'r', label='predictor', clip_on=True)\n            ax.set_xlim([4E0,4E2])\n            ax.set_ylim([1E-8, 1E-4])\n            ax.tick_params(axis='y', which='major', pad=0)\n            ax.set_yticks([1E-8,1E-6,1E-4])\n            ax.yaxis.set_minor_locator(plt.NullLocator())\n            ax.text(0.8, 0.9, 'ch. %i' % (ch+1),\n                    horizontalalignment='left',\n                    verticalalignment='center',\n                    fontsize=6, \n                    transform=ax.transAxes)\n            \n            if j == 0:\n                ax.set_ylabel('(mV$^2$/Hz)', labelpad=0.)\n            if j > 0:\n                ax.set_yticklabels([])\n            if j == len(channels)-1:\n                ax.set_xlabel(r'$f$ (Hz)', labelpad=0.)\n            else:\n                ax.set_xticklabels([])\n\n\n\n    return fig, PSD_LFP_reconst, PSD_data", "response": "This function calculates the STA of LFP and returns the LFP from the kernels."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef watch_record(indexer, use_polling=False):\n    if use_polling:\n        from watchdog.observers.polling import PollingObserver as Observer\n        Observer  # fool pyflakes\n    else:\n        from watchdog.observers import Observer\n\n    event_handler = RecordHandler(indexer)\n    observer = Observer()\n    observer.schedule(event_handler, path=indexer.record_path, recursive=True)\n    indexer.logger.debug('Start observer.')\n    observer.start()\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        indexer.logger.debug('Got KeyboardInterrupt. Stopping observer.')\n        observer.stop()\n    indexer.logger.debug('Joining observer.')\n    observer.join()\n    indexer.logger.debug('Finish watching record.')", "response": "Start watching cfstore. record_path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun simulation with simple cell simulation with LFPs in the plane", "response": "def run_sim(morphology='patdemo/cells/j4a.hoc',\n            cell_rotation=dict(x=4.99, y=-4.33, z=3.14),\n            closest_idx=dict(x=-200., y=0., z=800.)):\n    '''set up simple cell simulation with LFPs in the plane'''\n\n    # Create cell\n    cell = LFPy.Cell(morphology=morphology, **cell_parameters)\n    # Align cell\n    cell.set_rotation(**cell_rotation)\n    \n    # Define synapse parameters\n    synapse_parameters = {\n        'idx' : cell.get_closest_idx(**closest_idx),\n        'e' : 0.,                   # reversal potential\n        'syntype' : 'ExpSynI',       # synapse type\n        'tau' : 0.5,                 # synaptic time constant\n        'weight' : 0.0878,            # synaptic weight\n        'record_current' : True,    # record synapse current\n    }\n    \n    # Create synapse and set time of synaptic input\n    synapse = LFPy.Synapse(cell, **synapse_parameters)\n    synapse.set_spike_times(np.array([1.]))\n\n    \n    # Create electrode object\n    \n    # Run simulation, electrode object argument in cell.simulate\n    print \"running simulation...\"\n    cell.simulate(rec_imem=True,rec_isyn=True)\n    \n    grid_electrode = LFPy.RecExtElectrode(cell,**grid_electrode_parameters)\n    point_electrode = LFPy.RecExtElectrode(cell,**point_electrode_parameters)\n    \n    grid_electrode.calc_lfp()\n    point_electrode.calc_lfp()\n    \n    print \"done\"\n    \n    return cell, synapse, grid_electrode, point_electrode"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_sim(ax, cell, synapse, grid_electrode, point_electrode, letter='a'):\n    '''create a plot'''\n    \n    fig = plt.figure(figsize = (3.27*2/3, 3.27*2/3))\n    \n    ax = fig.add_axes([.1,.05,.9,.9], aspect='equal', frameon=False)\n    \n    phlp.annotate_subplot(ax, ncols=1, nrows=1, letter=letter, fontsize=16)\n    \n    cax = fig.add_axes([0.8, 0.2, 0.02, 0.2], frameon=False)\n    \n    \n    LFP = np.max(np.abs(grid_electrode.LFP),1).reshape(X.shape)\n    im = ax.contour(X, Z, np.log10(LFP), \n               50,\n               cmap='RdBu',\n               linewidths=1.5,\n               zorder=-2)\n    cbar = fig.colorbar(im, cax=cax)\n    cbar.set_label('$|\\phi(\\mathbf{r}, t)|_\\mathrm{max}$ (nV)')\n    cbar.outline.set_visible(False)\n    #get some log-linear tickmarks and ticklabels\n    ticks = np.arange(np.ceil(np.log10(LFP.min())), np.ceil(np.log10(LFP.max())))\n    cbar.set_ticks(ticks)\n    cbar.set_ticklabels(10.**ticks * 1E6) #mv -> nV\n    \n    zips = []\n    for x, z in cell.get_idx_polygons():\n        zips.append(zip(x, z))\n    polycol = PolyCollection(zips,\n                             edgecolors='k',\n                             linewidths=0.5,\n                             facecolors='k')\n    ax.add_collection(polycol)\n    \n    ax.plot([100, 200], [-400, -400], 'k', lw=1, clip_on=False)\n    ax.text(150, -470, r'100$\\mu$m', va='center', ha='center')\n    \n    ax.axis('off')\n    \n    \n    ax.plot(cell.xmid[cell.synidx],cell.zmid[cell.synidx], 'o', ms=5,\n            markeredgecolor='k',\n            markerfacecolor='r')\n    \n    color_vec = ['blue','green']\n    for i in xrange(2):\n        ax.plot(point_electrode_parameters['x'][i],\n                        point_electrode_parameters['z'][i],'o',ms=6,\n                        markeredgecolor='none',\n                        markerfacecolor=color_vec[i])\n    \n    \n    plt.axes([.11, .075, .25, .2])\n    plt.plot(cell.tvec,point_electrode.LFP[0]*1e6,color=color_vec[0], clip_on=False)\n    plt.plot(cell.tvec,point_electrode.LFP[1]*1e6,color=color_vec[1], clip_on=False)\n    plt.axis('tight')\n    ax = plt.gca()\n    ax.set_ylabel(r'$\\phi(\\mathbf{r}, t)$ (nV)') #rotation='horizontal')\n    ax.set_xlabel('$t$ (ms)', va='center')\n    for loc, spine in ax.spines.iteritems():\n        if loc in ['right', 'top']:\n            spine.set_color('none')            \n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n    \n    plt.axes([.11, 0.285, .25, .2])\n    plt.plot(cell.tvec,synapse.i*1E3, color='red', clip_on=False)\n    plt.axis('tight')\n    ax = plt.gca()\n    ax.set_ylabel(r'$I_{i, j}(t)$ (pA)', ha='center', va='center') #, rotation='horizontal')\n    for loc, spine in ax.spines.iteritems():\n        if loc in ['right', 'top']:\n            spine.set_color('none')            \n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n    ax.set_xticklabels([])\n\n    return fig", "response": "plot a single synapse and a point electrode"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots a single simulation tstep", "response": "def plot_sim_tstep(fig, ax, cell, synapse, grid_electrode, point_electrode, tstep=0,\n                   letter='a',title='', cbar=True, show_legend=False):\n    '''create a plot'''\n    ax.set_title(title)\n    \n    if letter != None:\n        phlp.annotate_subplot(ax, ncols=3, nrows=1, letter=letter, linear_offset=0.05, fontsize=16)\n\n    \n    \n    LFP = grid_electrode.LFP[:, tstep].reshape(X.shape).copy()\n    LFP *= 1E6 #mv -> nV\n    vlim = 50\n    levels = np.linspace(-vlim*2, vlim*2, 401)\n    cbarticks = np.mgrid[-50:51:20]\n    #cbarticks = [-10**np.floor(np.log10(vlim)),\n    #             0,\n    #             10**np.floor(np.log10(vlim)),]\n    #force dashed for negative values\n    linestyles = []\n    for level in levels:\n        if analysis_params.bw:\n            if level > 0:\n                linestyles.append('-')\n            elif level == 0:\n                linestyles.append((0, (5, 5)))\n            else:\n                linestyles.append((0, (1.0, 1.0)))\n        else:\n            # linestyles.append('-')\n            if level > 0:\n                linestyles.append('-')\n            elif level == 0:\n                linestyles.append((0, (5, 5)))\n            else:\n                linestyles.append('-')\n    if np.any(LFP != np.zeros(LFP.shape)):\n        im = ax.contour(X, Z, LFP,\n                   levels=levels,\n                   cmap='gray' if analysis_params.bw else 'RdBu',\n                   vmin=-vlim,\n                   vmax=vlim,\n                   linewidths=3,\n                   linestyles=linestyles,\n                   zorder=-2,\n                   rasterized=False)\n        \n\n        bbox = np.array(ax.get_position()).flatten()\n        if cbar:\n            cax = fig.add_axes((bbox[2]-0.01, 0.2, 0.01, 0.4), frameon=False)\n            cbar = fig.colorbar(im, cax=cax, format=FormatStrFormatter('%i'), values=[-vlim, vlim])\n            cbar.set_ticks(cbarticks)\n            cbar.set_label('$\\phi(\\mathbf{r}, t)$ (nV)', labelpad=0)\n            cbar.outline.set_visible(False)\n        \n        if show_legend:\n            proxy = [plt.Line2D((0,1),(0,1), color='gray' if analysis_params.bw else plt.get_cmap('RdBu', 3)(2), ls='-', lw=3),\n                     plt.Line2D((0,1),(0,1), color='gray' if analysis_params.bw else plt.get_cmap('RdBu', 3)(1), ls=(0, (5, 5)), lw=3),\n                     plt.Line2D((0,1),(0,1), color='gray' if analysis_params.bw else plt.get_cmap('RdBu', 3)(0), ls=(0, (1, 1)), lw=3), ]\n            \n            ax.legend(proxy, [r'$\\phi(\\mathbf{r}, t) > 0$ nV',\n                               r'$\\phi(\\mathbf{r}, t) = 0$ nV',\n                               r'$\\phi(\\mathbf{r}, t) < 0$ nV'],\n                      loc=1,\n                      bbox_to_anchor=(1.2, 1),\n                      fontsize=10,\n                      frameon=False)\n        \n    zips = []\n    for x, z in cell.get_idx_polygons():\n        zips.append(zip(x, z))\n    polycol = PolyCollection(zips,\n                             edgecolors='k',\n                             linewidths=0.5,\n                             facecolors='k')\n    ax.add_collection(polycol)\n    \n    ax.plot([100, 200], [-400, -400], 'k', lw=2, clip_on=False)\n    ax.text(150, -470, r'100$\\mu$m', va='center', ha='center')\n    \n    ax.axis('off')\n    \n    \n    ax.plot(cell.xmid[cell.synidx],cell.zmid[cell.synidx], 'o', ms=6,\n            markeredgecolor='k',\n            markerfacecolor='w' if analysis_params.bw else 'r')\n    \n    color_vec = ['k' if analysis_params.bw else 'b', 'gray' if analysis_params.bw else 'g']\n    for i in xrange(2):\n        ax.plot(point_electrode_parameters['x'][i],\n                        point_electrode_parameters['z'][i],'o',ms=6,\n                        markeredgecolor='k',\n                        markerfacecolor=color_vec[i])\n    \n    \n    bbox = np.array(ax.get_position()).flatten()\n    ax1 = fig.add_axes((bbox[0], bbox[1], 0.05, 0.2))\n    ax1.plot(cell.tvec,point_electrode.LFP[0]*1e6,color=color_vec[0], clip_on=False)\n    ax1.plot(cell.tvec,point_electrode.LFP[1]*1e6,color=color_vec[1], clip_on=False)\n    axis = ax1.axis(ax1.axis('tight'))\n    ax1.yaxis.set_major_locator(MaxNLocator(4))\n    ax1.vlines(cell.tvec[tstep], axis[2], axis[3], lw=0.2)\n    ax1.set_ylabel(r'$\\phi(\\mathbf{r}, t)$ (nV)', labelpad=0) #rotation='horizontal')\n    ax1.set_xlabel('$t$ (ms)', labelpad=0)\n    for loc, spine in ax1.spines.iteritems():\n        if loc in ['right', 'top']:\n            spine.set_color('none')            \n    ax1.xaxis.set_ticks_position('bottom')\n    ax1.yaxis.set_ticks_position('left')\n    \n    ax2 = fig.add_axes((bbox[0], bbox[1]+.6, 0.05, 0.2))\n    ax2.plot(cell.tvec,synapse.i*1E3, color='k' if analysis_params.bw else 'r',\n             clip_on=False)\n    axis = ax2.axis(ax2.axis('tight'))\n    ax2.yaxis.set_major_locator(MaxNLocator(4))\n    ax2.vlines(cell.tvec[tstep], axis[2], axis[3])\n    ax2.set_ylabel(r'$I_{i, j}(t)$ (pA)', labelpad=0) #, rotation='horizontal')\n    for loc, spine in ax2.spines.iteritems():\n        if loc in ['right', 'top']:\n            spine.set_color('none')            \n    ax2.xaxis.set_ticks_position('bottom')\n    ax2.yaxis.set_ticks_position('left')\n    ax2.set_xticklabels([])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_F_y(fname='binzegger_connectivity_table.json', y=['p23']): \n    '''\n    Extract frequency of occurrences of those cell types that are modeled.\n    The data set contains cell types that are not modeled (TCs etc.)\n    The returned percentages are renormalized onto modeled cell-types, i.e. they sum up to 1 \n    '''\n    # Load data from json dictionary\n    f = open(fname,'r')\n    data = json.load(f)\n    f.close()\n    \n    occurr = []\n    for cell_type in y:\n        occurr += [data['data'][cell_type]['occurrence']]\n    return list(np.array(occurr)/np.sum(occurr))", "response": "Returns the frequency of occurrences of each cell type in the data set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the layer specificity of a single neuron", "response": "def get_L_yXL(fname, y, x_in_X, L):\n    '''\n    compute the layer specificity, defined as:\n    ::\n    \n        L_yXL = k_yXL / k_yX\n    '''\n    def _get_L_yXL_per_yXL(fname, x_in_X, X_index,\n                                  y, layer):\n        # Load data from json dictionary\n        f = open(fname, 'r')\n        data = json.load(f)\n        f.close()\n    \n        \n        # Get number of synapses\n        if layer in [str(key) for key in data['data'][y]['syn_dict'].keys()]:\n            #init variables\n            k_yXL = 0\n            k_yX = 0\n            \n            for x in x_in_X[X_index]:\n                p_yxL = data['data'][y]['syn_dict'][layer][x] / 100.\n                k_yL = data['data'][y]['syn_dict'][layer]['number of synapses per neuron']\n                k_yXL += p_yxL * k_yL\n                \n            for l in [str(key) for key in data['data'][y]['syn_dict'].keys()]:\n                for x in x_in_X[X_index]:\n                    p_yxL = data['data'][y]['syn_dict'][l][x] / 100.\n                    k_yL = data['data'][y]['syn_dict'][l]['number of synapses per neuron']\n                    k_yX +=  p_yxL * k_yL\n            \n            if k_yXL != 0.:\n                return k_yXL / k_yX\n            else:\n                return 0.\n        else:\n            return 0.\n\n\n    #init dict\n    L_yXL = {}\n\n    #iterate over postsynaptic cell types\n    for y_value in y:\n        #container\n        data = np.zeros((len(L), len(x_in_X)))\n        #iterate over lamina\n        for i, Li in enumerate(L):\n            #iterate over presynapse population inds\n            for j in range(len(x_in_X)):\n                data[i][j]= _get_L_yXL_per_yXL(fname, x_in_X,\n                                                          X_index=j,\n                                                          y=y_value,\n                                                          layer=Li)\n        L_yXL[y_value] = data\n\n    return L_yXL"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the cell type specificity", "response": "def get_T_yX(fname, y, y_in_Y, x_in_X, F_y):\n    '''\n    compute the cell type specificity, defined as:\n    ::\n    \n        T_yX = K_yX / K_YX\n            = F_y * k_yX / sum_y(F_y*k_yX) \n    \n    '''\n    def _get_k_yX_mul_F_y(y, y_index, X_index):\n        # Load data from json dictionary\n        f = open(fname, 'r')\n        data = json.load(f)\n        f.close()\n    \n        #init variables\n        k_yX = 0.\n        \n        for l in [str(key) for key in data['data'][y]['syn_dict'].keys()]:\n            for x in x_in_X[X_index]:\n                p_yxL = data['data'][y]['syn_dict'][l][x] / 100.\n                k_yL = data['data'][y]['syn_dict'][l]['number of synapses per neuron']\n                k_yX +=  p_yxL * k_yL\n        \n        return k_yX * F_y[y_index]\n\n\n    #container\n    T_yX = np.zeros((len(y), len(x_in_X)))\n    \n    #iterate over postsynaptic cell types\n    for i, y_value in enumerate(y):\n        #iterate over presynapse population inds\n        for j in range(len(x_in_X)):\n            k_yX_mul_F_y = 0\n            for k, yy in enumerate(sum(y_in_Y, [])):                \n                if y_value in yy:\n                    for yy_value in yy:\n                        ii = np.where(np.array(y) == yy_value)[0][0]\n                        k_yX_mul_F_y += _get_k_yX_mul_F_y(yy_value, ii, j)\n            \n            \n            if k_yX_mul_F_y != 0:\n                T_yX[i, j] = _get_k_yX_mul_F_y(y_value, i, j) / k_yX_mul_F_y\n            \n    return T_yX"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _compute_J(self):\n        '''\n        Compute the current amplitude corresponding to the exponential\n        synapse model PSP amplitude\n        \n        Derivation using sympy:\n        ::\n            from sympy import *\n            #define symbols\n            t, tm, Cm, ts, Is, Vmax = symbols('t tm Cm ts Is Vmax')\n            \n            #assume zero delay, t >= 0\n            #using eq. 8.10 in Sterrat et al\n            V = tm*ts*Is*(exp(-t/tm) - exp(-t/ts)) / (tm-ts) / Cm\n            print 'V = %s' % V\n            \n            #find time of V == Vmax\n            dVdt = diff(V, t)\n            print 'dVdt = %s' % dVdt\n            \n            [t] = solve(dVdt, t)\n            print 't(t@dVdT==Vmax) = %s' % t\n            \n            #solve for Is at time of maxima\n            V = tm*ts*Is*(exp(-t/tm) - exp(-t/ts)) / (tm-ts) / Cm\n            print 'V(%s) = %s' % (t, V)\n            \n            [Is] = solve(V-Vmax, Is)\n            print 'Is = %s' % Is\n        \n        resulting in:\n        ::\n            Cm*Vmax*(-tm + ts)/(tm*ts*(exp(tm*log(ts/tm)/(tm - ts))\n                                     - exp(ts*log(ts/tm)/(tm - ts))))\n        \n        '''\n        #LIF params\n        tm = self.model_params['tau_m']\n        Cm = self.model_params['C_m']\n        \n        #synapse\n        ts = self.model_params['tau_syn_ex']\n        Vmax = self.PSP_e\n        \n        #max current amplitude\n        J = Cm*Vmax*(-tm + ts)/(tm*ts*(np.exp(tm*np.log(ts/tm)/(tm - ts))\n                                     - np.exp(ts*np.log(ts/tm)/(tm - ts))))\n        \n        #unit conversion pF*mV -> nA\n        J *= 1E-3\n        \n        return J", "response": "Compute the current amplitude corresponding to the exponential exponential\n            synapse model PSP and the exponential\n            maxima\n           ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _synDelayParams(self):\n        '''\n        set up the detailed synaptic delay parameters,\n        loc is mean delay,\n        scale is std with low bound cutoff,\n        assumes numpy.random.normal is used later\n        '''\n        delays = {}\n        #mean delays\n        loc = np.zeros((len(self.y), len(self.X)))\n        loc[:, 0] = self.delays[0]\n        loc[:, 1::2] = self.delays[0]\n        loc[:, 2::2] = self.delays[1]\n        #standard deviations\n        scale = loc * self.delay_rel_sd\n        \n        #prepare output\n        delay_loc = {}\n        for i, y in enumerate(self.y):\n            delay_loc.update({y : loc[i]})\n        \n        delay_scale = {}\n        for i, y in enumerate(self.y):\n            delay_scale.update({y : scale[i]})\n                \n        return delay_loc, delay_scale", "response": "set up the detailed synaptic delay parameters loc and scale"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _calcDepths(self):\n        '''\n        return the cortical depth of each subpopulation\n        '''\n        depths = self.layerBoundaries.mean(axis=1)[1:]\n\n        depth_y = []\n        for y in self.y:\n            if y in ['p23', 'b23', 'nb23']:\n                depth_y = np.r_[depth_y, depths[0]]\n            elif y in ['p4', 'ss4(L23)', 'ss4(L4)', 'b4', 'nb4']:\n                depth_y = np.r_[depth_y, depths[1]]\n            elif y in ['p5(L23)', 'p5(L56)', 'b5', 'nb5']:\n                depth_y = np.r_[depth_y, depths[2]]\n            elif y in ['p6(L4)', 'p6(L56)', 'b6', 'nb6']:\n                depth_y = np.r_[depth_y, depths[3]]\n            else:\n                raise Exception, 'this aint right'\n                \n        return depth_y", "response": "Calculates the cortical depth of each subpopulation in the order of the y - axis"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _yCellParams(self):\n        '''\n        Return dict with parameters for each population.\n        The main operation is filling in cell type specific morphology\n        '''\n        #cell type specific parameters going into LFPy.Cell        \n        yCellParams = {}\n        for layer, morpho, _, _ in self.y_zip_list:\n            yCellParams.update({layer : self.cellParams.copy()})\n            yCellParams[layer].update({\n                'morphology' : os.path.join(self.PATH_m_y, morpho),\n            })\n        return yCellParams", "response": "Return dict with parameters for each population."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating catalogs for different file output to clean up savefolder.", "response": "def _set_up_savefolder(self):\n        \"\"\"\n        Create catalogs for different file output to clean up savefolder.\n\n        Non-public method\n\n\n        Parameters\n        ----------\n        None\n\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        if self.savefolder == None:\n            return\n\n        self.cells_path = os.path.join(self.savefolder, 'cells')\n        if RANK == 0:\n            if not os.path.isdir(self.cells_path):\n                os.mkdir(self.cells_path)\n\n        self.figures_path = os.path.join(self.savefolder, 'figures')\n        if RANK == 0:\n            if not os.path.isdir(self.figures_path):\n                os.mkdir(self.figures_path)\n\n        self.populations_path = os.path.join(self.savefolder, 'populations')\n        if RANK == 0:\n            if not os.path.isdir(self.populations_path):\n                os.mkdir(self.populations_path)\n\n        COMM.Barrier()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self):\n        for cellindex in self.RANK_CELLINDICES:\n            self.cellsim(cellindex)\n\n        COMM.Barrier()", "response": "This method runs the individual cell simulations across ranks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset `pop_soma_pos` using draw_rand_pos(). This method takes no keyword arguments. Parameters ---------- None Returns ------- numpy.ndarray (x,y,z) coordinates of each neuron in the population See also -------- PopulationSuper.draw_rand_pos", "response": "def set_pop_soma_pos(self):\n        \"\"\"\n        Set `pop_soma_pos` using draw_rand_pos().\n\n        This method takes no keyword arguments.\n\n\n        Parameters\n        ----------\n        None\n\n\n        Returns\n        -------\n        numpy.ndarray\n            (x,y,z) coordinates of each neuron in the population\n\n\n        See also\n        --------\n        PopulationSuper.draw_rand_pos\n\n        \"\"\"\n        tic = time()\n        if RANK == 0:\n            pop_soma_pos = self.draw_rand_pos(\n                min_r = self.electrodeParams['r_z'],\n                **self.populationParams)\n        else:\n            pop_soma_pos = None\n\n        if RANK == 0:\n            print('found cell positions in %.2f s' % (time()-tic))\n\n        return COMM.bcast(pop_soma_pos, root=0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the minimum cell interdistance from input coordinates.", "response": "def calc_min_cell_interdist(self, x, y, z):\n        \"\"\"\n        Calculate cell interdistance from input coordinates.\n\n\n        Parameters\n        ----------\n        x, y, z : numpy.ndarray\n            xyz-coordinates of each cell-body.\n\n\n        Returns\n        -------\n        min_cell_interdist : np.nparray\n            For each cell-body center, the distance to nearest neighboring cell\n\n        \"\"\"\n        min_cell_interdist = np.zeros(self.POPULATION_SIZE)\n\n        for i in range(self.POPULATION_SIZE):\n            cell_interdist = np.sqrt((x[i] - x)**2\n                    + (y[i] - y)**2\n                    + (z[i] - z)**2)\n            cell_interdist[i] = np.inf\n            min_cell_interdist[i] = cell_interdist.min()\n\n        return min_cell_interdist"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw some random location within radius z_min z_max and constrained by min_r and the minimum cell interdistance.", "response": "def draw_rand_pos(self, radius, z_min, z_max,\n                      min_r=np.array([0]), min_cell_interdist=10., **args):\n        \"\"\"\n        Draw some random location within radius, z_min, z_max,\n        and constrained by min_r and the minimum cell interdistance.\n        Returned argument is a list of dicts [{'xpos', 'ypos', 'zpos'},].\n\n\n        Parameters\n        ----------\n        radius : float\n            Radius of population.\n        z_min : float\n            Lower z-boundary of population.\n        z_max : float\n            Upper z-boundary of population.\n        min_r : numpy.ndarray\n            Minimum distance to center axis as function of z.\n        min_cell_interdist : float\n            Minimum cell to cell interdistance.\n        **args : keyword arguments\n            Additional inputs that is being ignored.\n\n\n        Returns\n        -------\n        soma_pos : list\n            List of dicts of len population size\n            where dict have keys xpos, ypos, zpos specifying\n            xyz-coordinates of cell at list entry `i`.\n\n\n        See also\n        --------\n        PopulationSuper.calc_min_cell_interdist\n\n        \"\"\"\n        x = (np.random.rand(self.POPULATION_SIZE)-0.5)*radius*2\n        y = (np.random.rand(self.POPULATION_SIZE)-0.5)*radius*2\n        z = np.random.rand(self.POPULATION_SIZE)*(z_max - z_min) + z_min\n        min_r_z = {}\n        min_r = np.array(min_r)\n        if min_r.size > 0:\n            if type(min_r) == type(np.array([])):\n                j = 0\n                for j in range(min_r.shape[0]):\n                    min_r_z[j] = np.interp(z, min_r[0,], min_r[1,])\n                    if j > 0:\n                        [w] = np.where(min_r_z[j] < min_r_z[j-1])\n                        min_r_z[j][w] = min_r_z[j-1][w]\n                minrz = min_r_z[j]\n        else:\n            minrz = np.interp(z, min_r[0], min_r[1])\n\n        R_z = np.sqrt(x**2 + y**2)\n\n        #want to make sure that no somas are in the same place.\n        cell_interdist = self.calc_min_cell_interdist(x, y, z)\n\n        [u] = np.where(np.logical_or((R_z < minrz) != (R_z > radius),\n            cell_interdist < min_cell_interdist))\n\n        while len(u) > 0:\n            for i in range(len(u)):\n                x[u[i]] = (np.random.rand()-0.5)*radius*2\n                y[u[i]] = (np.random.rand()-0.5)*radius*2\n                z[u[i]] = np.random.rand()*(z_max - z_min) + z_min\n                if type(min_r) == type(()):\n                    for j in range(np.shape(min_r)[0]):\n                        min_r_z[j][u[i]] = \\\n                                np.interp(z[u[i]], min_r[0,], min_r[1,])\n                        if j > 0:\n                            [w] = np.where(min_r_z[j] < min_r_z[j-1])\n                            min_r_z[j][w] = min_r_z[j-1][w]\n                        minrz = min_r_z[j]\n                else:\n                    minrz[u[i]] = np.interp(z[u[i]], min_r[0,], min_r[1,])\n            R_z = np.sqrt(x**2 + y**2)\n\n            #want to make sure that no somas are in the same place.\n            cell_interdist = self.calc_min_cell_interdist(x, y, z)\n\n            [u] = np.where(np.logical_or((R_z < minrz) != (R_z > radius),\n                cell_interdist < min_cell_interdist))\n\n        \n        soma_pos = []\n        for i in range(self.POPULATION_SIZE):\n            soma_pos.append({'xpos' : x[i], 'ypos' : y[i], 'zpos' : z[i]})\n\n        return soma_pos"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_signal_sum(self, measure='LFP'):\n        #compute the total LFP of cells on this RANK\n        if self.RANK_CELLINDICES.size > 0:\n            for i, cellindex in enumerate(self.RANK_CELLINDICES):\n                if i == 0:\n                    data = self.output[cellindex][measure]\n                else:\n                    data += self.output[cellindex][measure]\n        else:\n            data = np.zeros((len(self.electrodeParams['x']),\n                             self.cellParams['tstopms']/self.dt_output + 1),\n                dtype=np.float32)\n\n        #container for full LFP on RANK 0\n        if RANK == 0:\n            DATA = np.zeros_like(data, dtype=np.float32)\n        else:\n            DATA = None\n\n        #sum to RANK 0 using automatic type discovery with MPI\n        COMM.Reduce(data, DATA, op=MPI.SUM, root=0)\n\n        return DATA", "response": "Calculates the sum of the population signal for each cell in the RANK."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollects single cell data and save them to HDF5 file.", "response": "def collectSingleContribs(self, measure='LFP'):\n        \"\"\"\n        Collect single cell data and save them to HDF5 file.\n        The function will also return signals generated by all cells\n\n\n        Parameters\n        ----------\n        measure : str\n            {'LFP', 'CSD'}: Either 'LFP' or 'CSD'.\n\n\n        Returns\n        -------\n        numpy.ndarray\n            output of all neurons in population, axis 0 correspond to neuron ind\n\n        \"\"\"\n        try:\n            assert(self.recordSingleContribFrac <= 1 and\n                   self.recordSingleContribFrac >= 0)\n        except AssertionError as ae:\n            raise ae, 'recordSingleContribFrac {} not in [0, 1]'.format(\n                                                self.recordSingleContribFrac)\n\n        if not self.recordSingleContribFrac:\n            return\n        else:\n            #reconstruct RANK_CELLINDICES of all RANKs for controlling\n            #communication\n            if self.recordSingleContribFrac == 1.:\n                SAMPLESIZE = self.POPULATION_SIZE\n                RANK_CELLINDICES = []\n                for i in range(SIZE):\n                    RANK_CELLINDICES += [self.CELLINDICES[\n                        self.CELLINDICES % SIZE == i]]\n            else:\n                SAMPLESIZE = int(self.recordSingleContribFrac *\n                                 self.POPULATION_SIZE)\n                RANK_CELLINDICES = []\n                for i in range(SIZE):\n                    ids = self.CELLINDICES[self.CELLINDICES % SIZE == i]\n                    RANK_CELLINDICES += [ids[ids < SAMPLESIZE]]\n\n            #gather data on this RANK\n            if RANK_CELLINDICES[RANK].size > 0:\n                for i, cellindex in enumerate(RANK_CELLINDICES[RANK]):\n                    if i == 0:\n                        data_temp = np.zeros([RANK_CELLINDICES[RANK].size] +\n                                            list(self.output[cellindex\n                                                             ][measure].shape),\n                                            dtype=np.float32)\n                    data_temp[i, ] = self.output[cellindex][measure]\n\n            if RANK == 0:\n                #container of all output\n                data = np.zeros([SAMPLESIZE] +\n                                 list(self.output[cellindex][measure].shape),\n                                 dtype=np.float32)\n\n                #fill in values from this RANK\n                if RANK_CELLINDICES[0].size > 0:\n                    for j, k in enumerate(RANK_CELLINDICES[0]):\n                        data[k, ] = data_temp[j, ]\n\n                #iterate over all other RANKs\n                for i in range(1, len(RANK_CELLINDICES)):\n                    if RANK_CELLINDICES[i].size > 0:\n                        #receive on RANK 0 from all other RANK\n                        data_temp = np.zeros([RANK_CELLINDICES[i].size] +\n                                        list(self.output[cellindex\n                                                         ][measure].shape),\n                                        dtype=np.float32)\n                        COMM.Recv([data_temp, MPI.FLOAT], source=i, tag=13)\n\n                        #fill in values\n                        for j, k in enumerate(RANK_CELLINDICES[i]):\n                            data[k, ] = data_temp[j, ]\n            else:\n                data = None\n                if RANK_CELLINDICES[RANK].size > 0:\n                    #send to RANK 0\n                    COMM.Send([data_temp, MPI.FLOAT], dest=0, tag=13)\n\n            if RANK == 0:\n                #save all single-cell data to file\n                fname = os.path.join(self.populations_path,\n                                     '%s_%ss.h5' % (self.y, measure))\n                f = h5py.File(fname, 'w')\n                f.create_dataset('data', data=data, compression=4)\n                f['srate'] = self.output[0]['srate']\n                f.close()\n                assert(os.path.isfile(fname))\n\n                print('file %s_%ss.h5 ok' % (self.y, measure))\n\n            COMM.Barrier()\n\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collect_data(self):\n        #collect some measurements resolved per file and save to file\n        for measure in ['LFP', 'CSD']:\n            if measure in self.savelist:\n                self.collectSingleContribs(measure)\n\n\n        #calculate lfp from all cell contribs\n        lfp = self.calc_signal_sum(measure='LFP')\n\n        #calculate CSD in every lamina\n        if self.calculateCSD:\n            csd = self.calc_signal_sum(measure='CSD')\n\n        if RANK == 0 and self.POPULATION_SIZE > 0:\n            #saving LFPs\n            if 'LFP' in self.savelist:\n                fname = os.path.join(self.populations_path,\n                                     self.output_file.format(self.y,\n                                                             'LFP')+'.h5')\n                f = h5py.File(fname, 'w')\n                f['srate'] = 1E3 / self.dt_output\n                f.create_dataset('data', data=lfp, compression=4)\n                f.close()\n                del lfp\n                assert(os.path.isfile(fname))\n                print('save lfp ok')\n\n\n            #saving CSDs\n            if 'CSD' in self.savelist and self.calculateCSD:\n                fname = os.path.join(self.populations_path,\n                                     self.output_file.format(self.y,\n                                                             'CSD')+'.h5')\n                f = h5py.File(fname, 'w')\n                f['srate'] = 1E3 / self.dt_output\n                f.create_dataset('data', data=csd, compression=4)\n                f.close()\n                del csd\n                assert(os.path.isfile(fname))\n                print('save CSD ok')\n\n\n            #save the somatic placements:\n            pop_soma_pos = np.zeros((self.POPULATION_SIZE, 3))\n            keys = ['xpos', 'ypos', 'zpos']\n            for i in range(self.POPULATION_SIZE):\n                for j in range(3):\n                    pop_soma_pos[i, j] = self.pop_soma_pos[i][keys[j]]\n            fname = os.path.join(self.populations_path,\n                                 self.output_file.format(self.y, 'somapos.gdf'))\n            np.savetxt(fname, pop_soma_pos)\n            assert(os.path.isfile(fname))\n            print('save somapos ok')\n\n            #save rotations using hdf5\n            fname = os.path.join(self.populations_path,\n                                    self.output_file.format(self.y, 'rotations.h5'))\n            f = h5py.File(fname, 'w')\n            f.create_dataset('x', (len(self.rotations),))\n            f.create_dataset('y', (len(self.rotations),))\n            f.create_dataset('z', (len(self.rotations),))\n\n            for i, rot in enumerate(self.rotations):\n                for key, value in list(rot.items()):\n                    f[key][i] = value\n            f.close()\n            assert(os.path.isfile(fname))\n            print('save rotations ok')\n\n\n        #resync threads\n        COMM.Barrier()", "response": "Collect some measurements resolved per file and save to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates and load arrays of synaptic delays per connection on this rank and return them as a dictionary of lists of connection delays per connection on this rank.", "response": "def get_all_synDelays(self):\n        \"\"\"\n        Create and load arrays of connection delays per connection on this rank\n\n        Get random normally distributed synaptic delays,\n        returns dict of nested list of same shape as SpCells.\n\n        Delays are rounded to dt.\n\n        This function takes no kwargs.\n\n\n        Parameters\n        ----------\n        None\n\n\n        Returns\n        -------\n        dict\n            output[cellindex][populationname][layerindex]`, np.array of\n            delays per connection.\n\n\n        See also\n        --------\n        numpy.random.normal\n\n        \"\"\"\n        tic = time()\n\n        #ok then, we will draw random numbers across ranks, which have to\n        #be unique per cell. Now, we simply record the random state,\n        #change the seed per cell, and put the original state back below.\n        randomstate = np.random.get_state()\n\n        #container\n        delays = {}\n\n        for cellindex in self.RANK_CELLINDICES:\n            #set the random seed on for each cellindex\n            np.random.seed(self.POPULATIONSEED + cellindex + 2*self.POPULATION_SIZE)\n\n            delays[cellindex] = {}\n            for j, X in enumerate(self.X):\n                delays[cellindex][X] = []\n                for i in self.k_yXL[:, j]:\n                    loc = self.synDelayLoc[j]\n                    loc /= self.dt\n                    scale = self.synDelayScale[j]\n                    if scale is not None:\n                        scale /= self.dt\n                        delay = np.random.normal(loc, scale, i).astype(int)\n                        while np.any(delay < 1):\n                            inds = delay < 1\n                            delay[inds] = np.random.normal(loc, scale,\n                                                        inds.sum()).astype(int)\n                        delay = delay.astype(float)\n                        delay *= self.dt\n                    else:\n                        delay = np.zeros(i) + self.synDelayLoc[j]\n                    delays[cellindex][X].append(delay)\n\n        #reset the random number generator\n        np.random.set_state(randomstate)\n\n        if RANK == 0:\n            print('found delays in %.2f seconds' % (time()-tic))\n\n        return delays"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_synidx(self, cellindex):\n        #create a cell instance\n        cell = self.cellsim(cellindex, return_just_cell=True)\n\n\n        #local containers\n        synidx = {}\n\n        #get synaptic placements and cells from the network,\n        #then set spike times,\n        for i, X in enumerate(self.X):\n            synidx[X] = self.fetchSynIdxCell(cell=cell,\n                                             nidx=self.k_yXL[:, i],\n                                             synParams=self.synParams.copy())\n\n        return synidx", "response": "Local function draw and return synapse locations corresponding\n        to a single cell using a random seed set as\n            PopulationSEED + cellindex."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds possible synaptic placements for each cell As synapses are placed within layers with bounds determined by self.layerBoundaries, it will check this matrix accordingly, and use the probabilities from `self.connProbLayer to distribute. For each layer, the synapses are placed with probability normalized by membrane area of each compartment Parameters ---------- cell : `LFPy.Cell` instance nidx : numpy.ndarray Numbers of synapses per presynaptic population X. synParams : which `LFPy.Synapse` parameters to use. Returns ------- syn_idx : list List of arrays of synapse placements per connection. See also -------- Population.get_all_synIdx, Population.get_synIdx, LFPy.Synapse", "response": "def fetchSynIdxCell(self, cell, nidx, synParams):\n        \"\"\"\n        Find possible synaptic placements for each cell\n        As synapses are placed within layers with bounds determined by\n        self.layerBoundaries, it will check this matrix accordingly, and\n        use the probabilities from `self.connProbLayer to distribute.\n\n        For each layer, the synapses are placed with probability normalized\n        by membrane area of each compartment\n\n\n        Parameters\n        ----------\n        cell : `LFPy.Cell` instance\n        nidx : numpy.ndarray\n            Numbers of synapses per presynaptic population X.\n        synParams : which `LFPy.Synapse` parameters to use.\n\n\n        Returns\n        -------\n        syn_idx : list\n            List of arrays of synapse placements per connection.\n\n\n        See also\n        --------\n        Population.get_all_synIdx, Population.get_synIdx, LFPy.Synapse\n\n        \"\"\"\n\n        #segment indices in each layer is stored here, list of np.array\n        syn_idx = []\n        #loop over layer bounds, find synapse locations\n        for i, zz in enumerate(self.layerBoundaries):\n            if nidx[i] == 0:\n                syn_idx.append(np.array([], dtype=int))\n            else:\n                syn_idx.append(cell.get_rand_idx_area_norm(\n                                section=synParams['section'],\n                                nidx=nidx[i],\n                                z_min=zz.min(),\n                                z_max=zz.max()).astype('int16'))\n\n        return syn_idx"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndoing the actual simulations of LFP, using synaptic spike times from network simulation. Parameters ---------- cellindex : int cell index between 0 and population size-1. return_just_cell : bool If True, return only the `LFPy.Cell` object if False, run full simulation, return None. Returns ------- None or `LFPy.Cell` object See also -------- hybridLFPy.csd, LFPy.Cell, LFPy.Synapse, LFPy.RecExtElectrode", "response": "def cellsim(self, cellindex, return_just_cell = False):\n        \"\"\"\n        Do the actual simulations of LFP, using synaptic spike times from\n        network simulation.\n\n\n        Parameters\n        ----------\n        cellindex : int\n            cell index between 0 and population size-1.\n        return_just_cell : bool\n            If True, return only the `LFPy.Cell` object\n            if False, run full simulation, return None.\n\n\n        Returns\n        -------\n        None or `LFPy.Cell` object\n\n\n        See also\n        --------\n        hybridLFPy.csd, LFPy.Cell, LFPy.Synapse, LFPy.RecExtElectrode\n        \"\"\"\n        tic = time()\n        \n        cell = LFPy.Cell(**self.cellParams)\n        cell.set_pos(**self.pop_soma_pos[cellindex])\n        cell.set_rotation(**self.rotations[cellindex])\n\n        if return_just_cell:\n            #with several cells, NEURON can only hold one cell at the time\n            allsecnames = []\n            allsec = []\n            for sec in cell.allseclist:\n                allsecnames.append(sec.name())\n                for seg in sec:\n                    allsec.append(sec.name())\n            cell.allsecnames = allsecnames\n            cell.allsec = allsec\n            return cell\n        else:\n            self.insert_all_synapses(cellindex, cell)\n\n            #electrode object where LFPs are calculated\n            electrode = LFPy.RecExtElectrode(**self.electrodeParams)\n\n            if self.calculateCSD:\n                cell.tvec = np.arange(cell.totnsegs)\n                cell.imem = np.eye(cell.totnsegs)\n                csdcoeff = csd.true_lam_csd(cell,\n                                self.populationParams['radius'], electrode.z)\n                csdcoeff *= 1E6 #nA mum^-3 -> muA mm^-3 conversion\n                del cell.tvec, cell.imem\n                cell.simulate(electrode, dotprodcoeffs=[csdcoeff],\n                              **self.simulationParams)\n                cell.CSD = helpers.decimate(cell.dotprodresults[0],\n                                            q=self.decimatefrac)\n            else:\n                cell.simulate(electrode,\n                              **self.simulationParams)\n\n            cell.LFP = helpers.decimate(electrode.LFP,\n                                        q=self.decimatefrac)\n\n\n            cell.x = electrode.x\n            cell.y = electrode.y\n            cell.z = electrode.z\n\n            cell.electrodecoeff = electrode.electrodecoeff\n\n            #put all necessary cell output in output dict\n            for attrbt in self.savelist:\n                attr = getattr(cell, attrbt)\n                if type(attr) == np.ndarray:\n                    self.output[cellindex][attrbt] = attr.astype('float32')\n                else:\n                    try:\n                        self.output[cellindex][attrbt] = attr\n                    except:\n                        self.output[cellindex][attrbt] = str(attr)\n                self.output[cellindex]['srate'] = 1E3 / self.dt_output\n\n            print('cell %s population %s in %.2f s' % (cellindex, self.y,\n                                                              time()-tic))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert all synaptic events from all presynaptic layers on the specified cell.", "response": "def insert_all_synapses(self, cellindex, cell):\n\n        \"\"\"\n        Insert all synaptic events from all presynaptic layers on\n        cell object with index `cellindex`.\n\n\n        Parameters\n        ----------\n        cellindex : int\n            cell index in the population.\n        cell : `LFPy.Cell` instance\n            Postsynaptic target cell.\n\n\n        Returns\n        -------\n        None\n\n\n        See also\n        --------\n        Population.insert_synapse\n\n        \"\"\"\n        for i, X in enumerate(self.X): #range(self.k_yXL.shape[1]):\n            synParams = self.synParams\n            synParams.update({\n                'weight' : self.J_yX[i],\n                'tau' : self.tau_yX[i],\n                })\n            for j in range(len(self.synIdx[cellindex][X])):\n                if self.synDelays is not None:\n                    synDelays = self.synDelays[cellindex][X][j]\n                else:\n                    synDelays = None\n                self.insert_synapses(cell = cell,\n                                cellindex = cellindex,\n                                synParams = synParams,\n                                idx = self.synIdx[cellindex][X][j],\n                                X=X,\n                                SpCell = self.SpCells[cellindex][X][j],\n                                synDelays = synDelays)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts synapses into a single object in a single iterative fashion.", "response": "def insert_synapses(self, cell, cellindex, synParams, idx = np.array([]),\n                        X='EX', SpCell = np.array([]),\n                        synDelays = None):\n        \"\"\"\n        Insert synapse with `parameters`=`synparams` on cell=cell, with\n        segment indexes given by `idx`. `SpCell` and `SpTimes` picked from\n        Brunel network simulation\n\n\n        Parameters\n        ----------\n        cell : `LFPy.Cell` instance\n            Postsynaptic target cell.\n        cellindex : int\n            Index of cell in population.\n        synParams : dict\n            Parameters passed to `LFPy.Synapse`.\n        idx : numpy.ndarray\n            Postsynaptic compartment indices.\n        X : str\n            presynaptic population name\n        SpCell : numpy.ndarray\n            Presynaptic spiking cells.\n        synDelays : numpy.ndarray\n            Per connection specific delays.\n\n\n        Returns\n        -------\n        None\n\n\n        See also\n        --------\n        Population.insert_all_synapses\n\n        \"\"\"\n        #Insert synapses in an iterative fashion\n        try:\n            spikes = self.networkSim.dbs[X].select(SpCell[:idx.size])\n        except AttributeError as ae:\n            raise ae, 'could not open CachedNetwork database objects'\n\n\n        #apply synaptic delays\n        if synDelays is not None and idx.size > 0:\n            for i, delay in enumerate(synDelays):\n                if spikes[i].size > 0:\n                    spikes[i] += delay\n\n        #create synapse events:\n        for i in range(idx.size):\n            if len(spikes[i]) == 0:\n                pass\n                #print 'no spike times, skipping network cell #%i' % SpCell[i]\n            else:\n                synParams.update({'idx' : idx[i]})\n                # Create synapse(s) and setting times using class LFPy.Synapse\n                synapse = LFPy.Synapse(cell, **synParams)\n                #SpCell is a vector, or do not exist\n                synapse.set_spike_times(spikes[i] + cell.tstartms)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetchSpCells(self, nodes, numSyn):\n        SpCell = []\n        for size in numSyn:\n            SpCell.append(np.random.randint(nodes.min(), nodes.max(),\n                                            size=size).astype('int32'))\n        return SpCell", "response": "Returns a list of random cells for each node in nodes and broadcast these as SpCell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a function on the n - term process pool.", "response": "def run(func, keys, max_procs=None, show_proc=False, affinity=None, **kwargs):\n    \"\"\"\n    Provide interface for multiprocessing\n\n    Args:\n        func: callable functions\n        keys: keys in kwargs that want to use process\n        max_procs: max number of processes\n        show_proc: whether to show process\n        affinity: CPU affinity\n        **kwargs: kwargs for func\n    \"\"\"\n    if max_procs is None: max_procs = cpu_count()\n    kw_arr = saturate_kwargs(keys=keys, **kwargs)\n    if len(kw_arr) == 0: return\n\n    if isinstance(affinity, int):\n        win32process.SetProcessAffinityMask(win32api.GetCurrentProcess(), affinity)\n\n    task_queue = queue.Queue()\n    while len(kw_arr) > 0:\n        for _ in range(max_procs):\n            if len(kw_arr) == 0: break\n            kw = kw_arr.pop(0)\n            p = Process(target=func, kwargs=kw)\n            p.start()\n            sys.stdout.flush()\n            task_queue.put(p)\n            if show_proc:\n                signature = ', '.join([f'{k}={v}' for k, v in kw.items()])\n                print(f'[{func.__name__}] ({signature})')\n        while not task_queue.empty():\n            p = task_queue.get()\n            p.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaturates all combinations of kwargs for the", "response": "def saturate_kwargs(keys, **kwargs):\n    \"\"\"\n    Saturate all combinations of kwargs\n\n    Args:\n        keys: keys in kwargs that want to use process\n        **kwargs: kwargs for func\n    \"\"\"\n    # Validate if keys are in kwargs and if they are iterable\n    if isinstance(keys, str): keys = [keys]\n    keys = [k for k in keys if k in kwargs and hasattr(kwargs.get(k, None), '__iter__')]\n    if len(keys) == 0: return []\n\n    # Saturate coordinates of kwargs\n    kw_corr = list(product(*(range(len(kwargs[k])) for k in keys)))\n\n    # Append all possible values\n    kw_arr = []\n    for corr in kw_corr: kw_arr.append(\n        dict(zip(keys, [kwargs[keys[i]][corr[i]] for i in range(len(keys))]))\n    )\n\n    # All combinations of kwargs of inputs\n    for k in keys: kwargs.pop(k, None)\n    kw_arr = [{**k, **kwargs} for k in kw_arr]\n\n    return kw_arr"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quick_idw(input_geojson_points, variable_name, power, nb_class,\n              nb_pts=10000, resolution=None, disc_func=None,\n              mask=None, user_defined_breaks=None,\n              variable_name2=None, output='GeoJSON', **kwargs):\n    \"\"\"\n    Function acting as a one-shot wrapper around SmoothIdw object.\n    Read a file of point values and optionnaly a mask file,\n    return the smoothed representation as GeoJSON or GeoDataFrame.\n\n    Parameters\n    ----------\n    input_geojson_points : str\n        Path to file to use as input (Points/Polygons) or GeoDataFrame object,\n        must contains a relevant numerical field.\n    variable_name : str\n        The name of the variable to use (numerical field only).\n    power : int or float\n        The power of the function.\n    nb_class : int, optionnal\n        The number of class, if unset will most likely be 8.\n        (default: None)\n    nb_pts: int, optionnal\n        The number of points to use for the underlying grid.\n        (default: 10000)\n    resolution : int, optionnal\n        The resolution to use (in meters), if not set a default\n        resolution will be used in order to make a grid containing around\n        10000 pts (default: None).\n    disc_func: str, optionnal\n        The name of the classification function to be used to decide on which\n        break values to use to create the contour layer.\n        (default: None)\n    mask : str, optionnal\n        Path to the file (Polygons only) to use as clipping mask,\n        can also be a GeoDataFrame (default: None).\n    user_defined_breaks : list or tuple, optionnal\n        A list of ordered break to use to construct the contours\n        (overrides `nb_class` and `disc_func` values if any, default: None).\n    variable_name2 : str, optionnal\n        The name of the 2nd variable to use (numerical field only); values\n        computed from this variable will be will be used as to divide\n        values computed from the first variable (default: None)\n    output : string, optionnal\n        The type of output expected (not case-sensitive)\n        in {\"GeoJSON\", \"GeoDataFrame\"} (default: \"GeoJSON\").\n\n    Returns\n    -------\n    smoothed_result : bytes or GeoDataFrame,\n        The result, dumped as GeoJSON (utf-8 encoded) or as a GeoDataFrame.\n\n\n    Examples\n    --------\n    Basic usage, output to raw geojson (bytes):\n\n    >>> result = quick_idw(\"some_file.geojson\", \"some_variable\", power=2)\n\n    More options, returning a GeoDataFrame:\n\n    >>> smooth_gdf = quick_stewart(\"some_file.geojson\", \"some_variable\",\n                                   nb_class=8, disc_func=\"percentiles\",\n                                   output=\"GeoDataFrame\")\n    \"\"\"\n\n    return SmoothIdw(input_geojson_points,\n                    variable_name,\n                    power,\n                    nb_pts,\n                    resolution,\n                    variable_name2,\n                    mask,\n                    **kwargs\n                    ).render(nb_class=nb_class,\n                      disc_func=disc_func,\n                      user_defined_breaks=user_defined_breaks,\n                      output=output)", "response": "Function acting as a one - shot wrapper around SmoothIdw."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions acting as a one-shot wrapper around SmoothStewart object. Read a file of point values and optionnaly a mask file, return the smoothed representation as GeoJSON or GeoDataFrame. Parameters ---------- input_geojson_points : str Path to file to use as input (Points/Polygons) or GeoDataFrame object, must contains a relevant numerical field. variable_name : str The name of the variable to use (numerical field only). span : int The span (meters). beta : float The beta! typefct : str, optionnal The type of function in {\"exponential\", \"pareto\"} (default: \"exponential\"). nb_class : int, optionnal The number of class, if unset will most likely be 8 (default: None) nb_pts: int, optionnal The number of points to use for the underlying grid. (default: 10000) resolution : int, optionnal The resolution to use (in meters), if not set a default resolution will be used in order to make a grid containing around 10000 pts (default: None). mask : str, optionnal Path to the file (Polygons only) to use as clipping mask, can also be a GeoDataFrame (default: None). user_defined_breaks : list or tuple, optionnal A list of ordered break to use to construct the contours (override `nb_class` value if any, default: None). variable_name2 : str, optionnal The name of the 2nd variable to use (numerical field only); values computed from this variable will be will be used as to divide values computed from the first variable (default: None) output : string, optionnal The type of output expected (not case-sensitive) in {\"GeoJSON\", \"GeoDataFrame\"} (default: \"GeoJSON\"). Returns ------- smoothed_result : bytes or GeoDataFrame, The result, dumped as GeoJSON (utf-8 encoded) or as a GeoDataFrame. Examples -------- Basic usage, output to raw geojson (bytes): >>> result = quick_stewart(\"some_file.geojson\", \"some_variable\", span=12500, beta=3, typefct=\"exponential\") More options, returning a GeoDataFrame: >>> smooth_gdf = quick_stewart(\"some_file.geojson\", \"some_variable\", span=12500, beta=3, typefct=\"pareto\", output=\"GeoDataFrame\")", "response": "def quick_stewart(input_geojson_points, variable_name, span,\n                  beta=2, typefct='exponential',nb_class=None,\n                  nb_pts=10000, resolution=None, mask=None,\n                  user_defined_breaks=None, variable_name2=None,\n                  output=\"GeoJSON\", **kwargs):\n    \"\"\"\n    Function acting as a one-shot wrapper around SmoothStewart object.\n    Read a file of point values and optionnaly a mask file,\n    return the smoothed representation as GeoJSON or GeoDataFrame.\n\n    Parameters\n    ----------\n    input_geojson_points : str\n        Path to file to use as input (Points/Polygons) or GeoDataFrame object,\n        must contains a relevant numerical field.\n    variable_name : str\n        The name of the variable to use (numerical field only).\n    span : int\n        The span (meters).\n    beta : float\n        The beta!\n    typefct : str, optionnal\n        The type of function in {\"exponential\", \"pareto\"} (default: \"exponential\").\n    nb_class : int, optionnal\n        The number of class, if unset will most likely be 8\n        (default: None)\n    nb_pts: int, optionnal\n        The number of points to use for the underlying grid.\n        (default: 10000)\n    resolution : int, optionnal\n        The resolution to use (in meters), if not set a default\n        resolution will be used in order to make a grid containing around\n        10000 pts (default: None).\n    mask : str, optionnal\n        Path to the file (Polygons only) to use as clipping mask,\n        can also be a GeoDataFrame (default: None).\n    user_defined_breaks : list or tuple, optionnal\n        A list of ordered break to use to construct the contours\n        (override `nb_class` value if any, default: None).\n    variable_name2 : str, optionnal\n        The name of the 2nd variable to use (numerical field only); values\n        computed from this variable will be will be used as to divide\n        values computed from the first variable (default: None)\n    output : string, optionnal\n        The type of output expected (not case-sensitive)\n        in {\"GeoJSON\", \"GeoDataFrame\"} (default: \"GeoJSON\").\n\n    Returns\n    -------\n    smoothed_result : bytes or GeoDataFrame,\n        The result, dumped as GeoJSON (utf-8 encoded) or as a GeoDataFrame.\n\n\n    Examples\n    --------\n    Basic usage, output to raw geojson (bytes):\n\n    >>> result = quick_stewart(\"some_file.geojson\", \"some_variable\",\n                               span=12500, beta=3, typefct=\"exponential\")\n\n    More options, returning a GeoDataFrame:\n\n    >>> smooth_gdf = quick_stewart(\"some_file.geojson\", \"some_variable\",\n                                   span=12500, beta=3, typefct=\"pareto\",\n                                   output=\"GeoDataFrame\")\n    \"\"\" \n    return SmoothStewart(\n            input_geojson_points,\n            variable_name,\n            span,\n            beta,\n            typefct,\n            nb_pts,\n            resolution,\n            variable_name2,\n            mask,\n            **kwargs\n            ).render(\n                nb_class=nb_class,\n                user_defined_breaks=user_defined_breaks,\n                output=output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_regular_points_with_no_res(bounds, nb_points=10000):\n    minlon, minlat, maxlon, maxlat = bounds\n    minlon, minlat, maxlon, maxlat = bounds\n    offset_lon = (maxlon - minlon) / 8\n    offset_lat = (maxlat - minlat) / 8\n    minlon -= offset_lon\n    maxlon += offset_lon\n    minlat -= offset_lat\n    maxlat += offset_lat\n\n    nb_x = int(nb_points**0.5)\n    nb_y = int(nb_points**0.5)\n\n    return (\n        np.linspace(minlon, maxlon, nb_x),\n        np.linspace(minlat, maxlat, nb_y),\n        (nb_y, nb_x)\n        )", "response": "Returns a regular grid of points within bounds with the specified number of points or a close approximate value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_regular_points(bounds, resolution, longlat=True):\n#    xmin, ymin, xmax, ymax = bounds\n    minlon, minlat, maxlon, maxlat = bounds\n    offset_lon = (maxlon - minlon) / 8\n    offset_lat = (maxlat - minlat) / 8\n    minlon -= offset_lon\n    maxlon += offset_lon\n    minlat -= offset_lat\n    maxlat += offset_lat\n\n    if longlat:\n        height = hav_dist(\n                np.array([(maxlon + minlon) / 2, minlat]),\n                np.array([(maxlon + minlon) / 2, maxlat])\n                )\n        width = hav_dist(\n                np.array([minlon, (maxlat + minlat) / 2]),\n                np.array([maxlon, (maxlat + minlat) / 2])\n                )\n    else:\n        height = np.linalg.norm(\n            np.array([(maxlon + minlon) / 2, minlat])\n            - np.array([(maxlon + minlon) / 2, maxlat]))\n        width = np.linalg.norm(\n            np.array([minlon, (maxlat + minlat) / 2])\n            - np.array([maxlon, (maxlat + minlat) / 2]))\n\n    nb_x = int(round(width / resolution))\n    nb_y = int(round(height / resolution))\n    if nb_y * 0.6 > nb_x:\n        nb_x = int(nb_x + nb_x / 3)\n    elif nb_x * 0.6 > nb_y:\n        nb_y = int(nb_y + nb_y / 3)\n    return (\n        np.linspace(minlon, maxlon, nb_x),\n        np.linspace(minlat, maxlat, nb_y),\n        (nb_y, nb_x)\n        )", "response": "Returns a regular grid of points within the specified bounds with the specified resolution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_dist_mat(xy1, xy2, longlat=True):\n    if longlat:\n        return hav_dist(xy1[:, None], xy2)\n    else:\n        d0 = np.subtract.outer(xy1[:, 0], xy2[:, 0])\n        d1 = np.subtract.outer(xy1[:, 1], xy2[:, 1])\n        return np.hypot(d0, d1)", "response": "Returns a distance matrix between two set of coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hav_dist(locs1, locs2):\n#    locs1 = np.radians(locs1)\n#    locs2 = np.radians(locs2)\n    cos_lat1 = np.cos(locs1[..., 0])\n    cos_lat2 = np.cos(locs2[..., 0])\n    cos_lat_d = np.cos(locs1[..., 0] - locs2[..., 0])\n    cos_lon_d = np.cos(locs1[..., 1] - locs2[..., 1])\n    return 6367000 * np.arccos(\n        cos_lat_d - cos_lat1 * cos_lat2 * (1 - cos_lon_d))", "response": "Returns a distance matrix between two set of coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isopoly_to_gdf(collec_poly, levels, field_name=\"levels\"):\n    polygons, data = [], []\n\n    for i, polygon in enumerate(collec_poly.collections):\n        mpoly = []\n        for path in polygon.get_paths():\n            path.should_simplify = False\n            poly = path.to_polygons()\n            exterior, holes = [], []\n            if len(poly) > 0 and len(poly[0]) > 3:\n                exterior = poly[0]\n                if len(poly) > 1:\n                    holes = [h for h in poly[1:] if len(h) > 3]\n            mpoly.append(Polygon(exterior, holes))\n        if len(mpoly) > 1:\n            mpoly = MultiPolygon(mpoly)\n            polygons.append(mpoly)\n            data.append(levels[i])\n        elif len(mpoly) == 1:\n            polygons.append(mpoly[0])\n            data.append(levels[i])\n\n    return GeoDataFrame(geometry=polygons,\n                        data=data,\n                        columns=[field_name])", "response": "Convert a collection of matplotlib. contour. QuadContourSet to a GeoDataFrame."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render(self, nb_class=8, disc_func=None, user_defined_breaks=None,\n               output=\"GeoJSON\", new_mask=False):\n        \"\"\"\n        Parameters\n        ----------\n        nb_class : int, optionnal\n            The number of class (default: 8).\n        disc_func : str, optionnal\n            The kind of data classification to be used (to be choosed in\n            \"equal_interval\", \"jenks\", \"percentiles, \"head_tail_breaks\"\n            and \"prog_geom\"), default: None.\n        user_defined_breaks : list or tuple, optionnal\n            A list of ordered break to use to construct the contours\n            (override `nb_class` and `disc_func` values if any)\n            (default: None).\n        output : string, optionnal\n            The type of output expected (not case-sensitive)\n            in {\"GeoJSON\", \"GeoDataFrame\"} (default: \"GeoJSON\").\n        new_mask : str, optionnal\n            Use a new mask by giving the path to the file (Polygons only)\n            to use as clipping mask, can also be directly a GeoDataFrame\n            (default: False).\n\n        Returns\n        -------\n        smoothed_result : bytes or GeoDataFrame\n            The result, dumped as GeoJSON (utf-8 encoded) or as a GeoDataFrame.\n        \"\"\"\n        if disc_func and 'jenks' in disc_func and not jenks_breaks:\n            raise ValueError(\n                \"Missing jenkspy package - could not use jenks breaks\")\n\n        zi = self.zi\n\n        if isinstance(new_mask, (type(False), type(None))):\n            if not self.use_mask:\n                self.use_mask = False\n                self.mask = None\n        else:\n            self.open_mask(new_mask, None)\n\n        # We want levels with the first break value as the minimum of the\n        # interpolated values and the last break value as the maximum of theses\n        # values:\n        if user_defined_breaks:\n            levels = user_defined_breaks\n            if levels[len(levels) - 1] < np.nanmax(zi):\n                levels = levels + [np.nanmax(zi)]\n            if levels[0] > np.nanmin(zi):\n                levels = [np.nanmin(zi)] + levels\n        else:\n            levels = self.define_levels(nb_class, disc_func)\n\n        # Ensure that the levels are unique/increasing\n        #  to avoid error from `contourf` :\n        s_levels = set(levels)\n        if len(s_levels) != len(levels):\n            levels = list(s_levels)\n        levels.sort()\n\n        try:\n            collec_poly = contourf(\n                self.XI, self.YI,\n                zi.reshape(tuple(reversed(self.shape))).T,\n                levels,\n                vmax=abs(np.nanmax(zi)), vmin=-abs(np.nanmin(zi)))\n        # Retry without setting the levels :\n        except ValueError:\n            collec_poly = contourf(\n                self.XI, self.YI,\n                zi.reshape(tuple(reversed(self.shape))).T,\n                vmax=abs(np.nanmax(zi)), vmin=-abs(np.nanmin(zi)))\n\n        # Fetch the levels returned by contourf:\n        levels = collec_poly.levels\n        # Set the maximum value at the maximum value of the interpolated values:\n        levels[-1] = np.nanmax(zi)\n        # Transform contourf contours into a GeoDataFrame of (Multi)Polygons:\n        res = isopoly_to_gdf(collec_poly, levels=levels[1:], field_name=\"max\")\n\n        if self.longlat:\n            def f(x, y, z=None):\n                return (x / 0.017453292519943295,\n                        y / 0.017453292519943295)\n            res.geometry = [transform(f, g) for g in res.geometry]\n\n        res.crs = self.proj_to_use\n        # Set the min/max/center values of each class as properties\n        # if this contour layer:\n        res[\"min\"] = [np.nanmin(zi)] + res[\"max\"][0:len(res)-1].tolist()\n        res[\"center\"] = (res[\"min\"] + res[\"max\"]) / 2\n\n        # Compute the intersection between the contour layer and the mask layer:\n        ix_max_ft = len(res) - 1\n        if self.use_mask:\n            res.loc[0:ix_max_ft, \"geometry\"] = res.geometry.buffer(\n                0).intersection(unary_union(self.mask.geometry.buffer(0)))\n\n        # res.loc[0:ix_max_ft, \"geometry\"] = res.geometry.buffer(\n        #     0).intersection(self.poly_max_extend.buffer(-0.1))\n\n        # Repair geometries if necessary :\n        if not all(t in (\"MultiPolygon\", \"Polygon\") for t in res.geom_type):\n            res.loc[0:ix_max_ft, \"geometry\"] = \\\n                [geom if geom.type in (\"Polygon\", \"MultiPolygon\")\n                 else MultiPolygon(\n                     [j for j in geom if j.type in ('Polygon', 'MultiPolygon')]\n                     )\n                 for geom in res.geometry]\n\n        if \"geojson\" in output.lower():\n            return res.to_crs({\"init\": \"epsg:4326\"}).to_json().encode()\n        else:\n            return res", "response": "Renders the data for the specified number of classes and returns the resulting data as GeoJSON."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef identify(s):\n    chinese = _get_hanzi(s)\n    if not chinese:\n        return UNKNOWN\n    if chinese.issubset(_SHARED_CHARACTERS):\n        return BOTH\n    if chinese.issubset(_TRADITIONAL_CHARACTERS):\n        return TRADITIONAL\n    if chinese.issubset(_SIMPLIFIED_CHARACTERS):\n        return SIMPLIFIED\n    return MIXED", "response": "Identify what kind of Chinese characters a string contains."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_traditional(s):\n    chinese = _get_hanzi(s)\n    if not chinese:\n        return False\n    elif chinese.issubset(_SHARED_CHARACTERS):\n        return True\n    elif chinese.issubset(_TRADITIONAL_CHARACTERS):\n        return True\n    return False", "response": "Check if a string s Chinese characters are Traditional."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a string s Chinese characters are simplified.", "response": "def is_simplified(s):\n    \"\"\"Check if a string's Chinese characters are Simplified.\n\n    This is equivalent to:\n        >>> identify('foo') in (SIMPLIFIED, BOTH)\n\n    \"\"\"\n    chinese = _get_hanzi(s)\n    if not chinese:\n        return False\n    elif chinese.issubset(_SHARED_CHARACTERS):\n        return True\n    elif chinese.issubset(_SIMPLIFIED_CHARACTERS):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresourcing can be a URL or a ResourceLocator", "response": "def get(self, resource, operation_timeout=None, max_envelope_size=None, locale=None):\n        \"\"\"\n        resource can be a URL or a ResourceLocator\n        \"\"\"\n        if isinstance(resource, str):\n            resource = ResourceLocator(resource)\n\n        headers = self._build_headers(resource, Session.GetAction, operation_timeout, max_envelope_size, locale)\n        self.service.invoke.set_options(tsoapheaders=headers)\n        return self.service.invoke"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nputs an object into the cache.", "response": "def put(self, resource, obj,\n            operation_timeout=None, max_envelope_size=None, locale=None):\n        \"\"\"\n        resource can be a URL or a ResourceLocator\n        \"\"\"\n        headers = None\n        return self.service.invoke(headers, obj)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the specified resource from the cache.", "response": "def delete(self, resource, operation_timeout=None, max_envelope_size=None, locale=None):\n        \"\"\"\n        resource can be a URL or a ResourceLocator\n        \"\"\"\n        if isinstance(resource, str):\n            resource = ResourceLocator(resource)\n\n        headers = self._build_headers(resource, Session.DeleteAction,\n                                      operation_timeout, max_envelope_size, locale)\n        return self.service.invoke(headers, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new object in the cache.", "response": "def create(self, resource, obj,\n               operation_timeout=None, max_envelope_size=None, locale=None):\n        \"\"\"\n        resource can be a URL or a ResourceLocator\n        \"\"\"\n        if isinstance(resource, str):\n            resource = ResourceLocator(resource)\n\n        headers = self._build_headers(resource, Session.CreateAction,\n                                      operation_timeout, max_envelope_size, locale)\n        return self.service.invoke(headers, obj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresourcing can be a URL or a ResourceLocator", "response": "def command(self, resource, obj,\n                operation_timeout=None, max_envelope_size=None, locale=None):\n        \"\"\"\n        resource can be a URL or a ResourceLocator\n        \"\"\"\n        if isinstance(resource, str):\n            resource = ResourceLocator(resource)\n\n        headers = self._build_headers(resource, Session.CommandAction,\n                                      operation_timeout, max_envelope_size, locale)\n        return self.service.invoke(headers, obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresourcing can be a URL or a ResourceLocator", "response": "def recieve(self, resource, obj,\n                operation_timeout=None, max_envelope_size=None, locale=None):\n        \"\"\"\n        resource can be a URL or a ResourceLocator\n        \"\"\"\n        if isinstance(resource, str):\n            resource = ResourceLocator(resource)\n\n        headers = self._build_headers(resource, Session.ReceiveAction,\n                                      operation_timeout, max_envelope_size, locale)\n        return self.service.invoke(headers, obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets default figure size", "response": "def set_default_fig_style(self):\n        '''default figure size'''\n        plt.rcParams.update({\n            'figure.figsize' : [self.frontierswidth/self.inchpercm, self.frontierswidth/self.inchpercm],\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_large_fig_style(self):\n        '''twice width figure size'''\n        plt.rcParams.update({\n            'figure.figsize' : [self.frontierswidth/self.inchpercm*2, self.frontierswidth/self.inchpercm],\n        })", "response": "twice width figure size"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_broad_fig_style(self):\n        '''4 times width, 1.5 times height'''\n        plt.rcParams.update({\n            'figure.figsize' : [self.frontierswidth/self.inchpercm*4, self.frontierswidth/self.inchpercm*1.5],\n        })", "response": "set the broad figure size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset matplotlib figure size to enormous", "response": "def set_enormous_fig_style(self):\n        '''2 times width, 2 times height'''\n\n        plt.rcParams.update({\n            'figure.figsize' : [self.frontierswidth/self.inchpercm*2, self.frontierswidth/self.inchpercm*2],\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting figure size corresponding to Plos 1 column", "response": "def set_PLOS_1column_fig_style(self, ratio=1):\n        '''figure size corresponding to Plos 1 column'''\n        plt.rcParams.update({\n            'figure.figsize' : [self.PLOSwidth1Col,self.PLOSwidth1Col*ratio],\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets figure size corresponding to Plos 2 columns", "response": "def set_PLOS_2column_fig_style(self, ratio=1):\n        '''figure size corresponding to Plos 2 columns'''\n        plt.rcParams.update({\n            'figure.figsize' : [self.PLOSwidth2Col, self.PLOSwidth2Col*ratio],\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        if RANK == 0:\n            if 'LFP' in self.savelist:\n                #get the per population LFPs and total LFP from all populations:\n                self.LFPdict, self.LFPsum = self.calc_lfp()\n                self.LFPdictLayer = self.calc_lfp_layer()\n    \n                #save global LFP sum, and from L23E, L4I etc.:\n                f = h5py.File(os.path.join(self.savefolder,\n                                           self.compound_file.format('LFP')\n                                           ), 'w')\n                f['srate'] = 1E3 / self.dt_output\n                f.create_dataset('data', data=self.LFPsum, compression=4)\n                f.close()\n    \n                for key, value in list(self.LFPdictLayer.items()):\n                    f = h5py.File(os.path.join(self.populations_path,\n                                               self.output_file.format(key,\n                                                                       'LFP.h5')\n                                               ), 'w')\n                    f['srate'] = 1E3 / self.dt_output\n                    f.create_dataset('data', data=value, compression=4)\n                    f.close()\n\n            if 'CSD' in self.savelist:\n                #get the per population CSDs and total CSD from all populations:\n                self.CSDdict, self.CSDsum = self.calc_csd()\n                self.CSDdictLayer = self.calc_csd_layer()\n    \n                #save global CSD sum, and from L23E, L4I etc.:\n                f = h5py.File(os.path.join(self.savefolder,\n                                           self.compound_file.format('CSD')),\n                              'w')\n                f['srate'] = 1E3 / self.dt_output\n                f.create_dataset('data', data=self.CSDsum, compression=4)\n                f.close()\n    \n                for key, value in list(self.CSDdictLayer.items()):\n                    f = h5py.File(os.path.join(self.populations_path,\n                                               self.output_file.format(key,\n                                                                       'CSD.h5')\n                                               ), 'w')\n                    f['srate'] = 1E3 / self.dt_output\n                    f.create_dataset('data', data=value, compression=4)\n                    f.close()\n\n        else:\n            pass", "response": "Perform the postprocessing steps computing compound signals from the cell - specific output files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_up_savefolder(self):\n        if not os.path.isdir(self.cells_path):\n            os.mkdir(self.cells_path)\n\n        if not os.path.isdir(self.figures_path):\n            os.mkdir(self.figures_path)\n\n        if not os.path.isdir(self.populations_path):\n            os.mkdir(self.populations_path)", "response": "Create the savefolder for different file output to clean up savefolder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsumming all the LFP contributions from every cell type.", "response": "def calc_lfp(self):\n        \"\"\" Sum all the LFP contributions from every cell type.\n        \"\"\"\n\n        LFParray = np.array([])\n        LFPdict = {}\n\n        i = 0\n        for y in self.y:\n            fil = os.path.join(self.populations_path,\n                               self.output_file.format(y, 'LFP.h5'))\n\n            f = h5py.File(fil)\n\n            if i == 0:\n                LFParray = np.zeros((len(self.y),\n                                    f['data'].shape[0], f['data'].shape[1]))\n\n            #fill in\n            LFParray[i, ] = f['data'].value\n\n            LFPdict.update({y : f['data'].value})\n\n            f.close()\n\n            i += 1\n\n        return LFPdict,  LFParray.sum(axis=0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calc_csd(self):\n\n        CSDarray = np.array([])\n        CSDdict = {}\n\n        i = 0\n        for y in self.y:\n            fil = os.path.join(self.populations_path,\n                               self.output_file.format(y, 'CSD.h5'))\n\n            f = h5py.File(fil)\n\n            if i == 0:\n                CSDarray = np.zeros((len(self.y),\n                                    f['data'].shape[0], f['data'].shape[1]))\n\n            #fill in\n            CSDarray[i, ] = f['data'].value\n\n            CSDdict.update({y : f['data'].value})\n\n            f.close()\n\n            i += 1\n\n        return CSDdict,  CSDarray.sum(axis=0)", "response": "Sum all the CSD contributions from every layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the LFP from concatenated subpopulations residing in a certain layer.", "response": "def calc_lfp_layer(self):\n        \"\"\"\n        Calculate the LFP from concatenated subpopulations residing in a\n        certain layer, e.g all L4E pops are summed, according to the `mapping_Yy`\n        attribute of the `hybridLFPy.Population` objects.\n        \"\"\"\n        LFPdict = {}\n\n        lastY = None\n        for Y, y in self.mapping_Yy:\n            if lastY != Y:\n                try:\n                    LFPdict.update({Y : self.LFPdict[y]})\n                except KeyError:\n                    pass\n            else:\n                try:\n                    LFPdict[Y] += self.LFPdict[y]\n                except KeyError:\n                    pass\n            lastY = Y\n\n        return LFPdict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_csd_layer(self):\n        CSDdict = {}\n\n        lastY = None\n        for Y, y in self.mapping_Yy:\n            if lastY != Y:\n                try:\n                    CSDdict.update({Y : self.CSDdict[y]})\n                except KeyError:\n                    pass\n            else:\n                try:\n                    CSDdict[Y] += self.CSDdict[y]\n                except KeyError:\n                    pass\n            lastY = Y\n\n        return CSDdict", "response": "Calculates the CSD for a particular level of interest in a certain layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a tar archive of the main simulation outputs.", "response": "def create_tar_archive(self):\n        \"\"\" Create a tar archive of the main simulation outputs.\n        \"\"\"\n        #file filter\n        EXCLUDE_FILES = glob.glob(os.path.join(self.savefolder, 'cells'))\n        EXCLUDE_FILES += glob.glob(os.path.join(self.savefolder,\n                                                'populations', 'subsamples'))\n        EXCLUDE_FILES += glob.glob(os.path.join(self.savefolder,\n                                                'raw_nest_output'))\n\n        def filter_function(tarinfo):\n            print(tarinfo.name)\n            if len([f for f in EXCLUDE_FILES if os.path.split(tarinfo.name)[-1]\n                    in os.path.split(f)[-1]]) > 0 or \\\n               len([f for f in EXCLUDE_FILES if os.path.split(tarinfo.path)[-1]\n                    in os.path.split(f)[-1]]) > 0:\n                print('excluding %s' % tarinfo.name)\n\n                return None\n            else:\n                return tarinfo\n\n        if RANK == 0:\n            print('creating archive %s' % (self.savefolder + '.tar'))\n            #open file\n            f = tarfile.open(self.savefolder + '.tar', 'w')\n            #avoid adding files to repo as /scratch/$USER/hybrid_model/...\n            arcname = os.path.split(self.savefolder)[-1]\n\n            f.add(name=self.savefolder,\n                  arcname=arcname,\n                  filter=filter_function)\n            f.close()\n\n        #resync\n        COMM.Barrier()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a sorted queryset of the current object.", "response": "def sort_queryset(queryset, request, context=None):\n    \"\"\" Returns a sorted queryset\n    The context argument is only used in the template tag\n    \"\"\"\n    sort_by = request.GET.get('sort_by')\n    if sort_by:\n        if sort_by in [el.name for el in queryset.model._meta.fields]:\n            queryset = queryset.order_by(sort_by)\n        else:\n            if sort_by in request.session:\n                sort_by = request.session[sort_by]\n                try:\n                    queryset = queryset.order_by(sort_by)\n                except:\n                    raise\n            # added else to fix a bug when using changelist\n            # TODO: use less ifs and more standard sorting\n            elif context is not None:\n                # sorted ascending\n                if sort_by[0] != '-':\n                    sort_by = context['cl'].list_display[int(sort_by) - 1]\n                # sorted descending\n                else: \n                    sort_by = '-' + context['cl'].list_display[abs(int(sort_by)) - 1]\n                queryset = queryset.order_by(sort_by)\n    return queryset"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn elements in iterative including num - before elements.", "response": "def include_before(predicate, num, iterative):\n    \"\"\"\n    Return elements in `iterative` including `num`-before elements.\n\n    >>> list(include_before(lambda x: x == 'd', 2, 'abcded'))\n    ['b', 'c', 'd', 'e', 'd']\n\n    \"\"\"\n    (it0, it1) = itertools.tee(iterative)\n    ps = _backward_shifted_predicate(predicate, num, it1)\n    return (e for (e, p) in zip(it0, ps) if p)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef include_after(predicate, num, iterative):\n    (it0, it1) = itertools.tee(iterative)\n    ps = _forward_shifted_predicate(predicate, num, it1)\n    return (e for (e, p) in zip(it0, ps) if p)", "response": "Return elements in iterative including num - after elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn elements in iterative including num before and after elements.", "response": "def include_context(predicate, num, iterative):\n    \"\"\"\n    Return elements in `iterative` including `num` before and after elements.\n\n    >>> ''.join(include_context(lambda x: x == '!', 2, 'bb!aa__bb!aa'))\n    'bb!aabb!aa'\n\n    \"\"\"\n    (it0, it1, it2) = itertools.tee(iterative, 3)\n    psf = _forward_shifted_predicate(predicate, num, it1)\n    psb = _backward_shifted_predicate(predicate, num, it2)\n    return (e for (e, pf, pb) in zip(it0, psf, psb) if pf or pb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates one CSD or LFP file with downsampled data per cell type and populations.", "response": "def create_downsampled_data(params):\n    '''\n    Creates one CSD or LFP file with downsampled data per cell type\n    '''\n    maxsamples = 1\n\n    for data_type in ['LFP','CSD']:\n\n        if RANK == 0:\n            if not os.path.isdir(os.path.join(params.savefolder, 'populations', 'subsamples')):\n                os.mkdir((os.path.join(params.savefolder,'populations','subsamples')))\n        COMM.Barrier()\n\n        try:\n            assert(ana_params.scaling <= params.recordSingleContribFrac)\n        except AssertionError as ae:\n            raise ae, 'scaling parameter must be less than simulation recordSingleContribFrac'\n        \n        samples = int(1. / ana_params.scaling)\n        if samples > maxsamples:\n            samples = maxsamples\n        \n        COUNTER = 0\n        for j, layer in enumerate(params.y_in_Y): # loop over layers\n            for k, pop in enumerate(layer): # loop over populations\n                for i, y in enumerate(pop): # loop over cell types\n                    if COUNTER % SIZE == RANK:\n                        # Load data\n                        fname = os.path.join(params.savefolder, 'populations', '%s_%ss.h5' \\\n                                             % (y, data_type))\n                        f = h5py.File(fname)\n                        print 'Load %s' % str(f.filename)\n                        raw_data = f['data'].value\n                        srate = f['srate'].value\n                        f.close()\n\n                        ## shuffle data\n                        #np.random.shuffle(raw_data)\n\n                        # sample size\n                        N = int(params.N_y[np.array(params.y) == y]*ana_params.scaling)\n                        try:\n                            assert(N <= raw_data.shape[0])\n                        except AssertionError as ae:\n                            raise ae, 'shape mismatch with sample size'\n\n\n                        for sample in range(samples): # loop over samples\n\n                            # slice data\n                            data = raw_data[sample*N:(sample+1)*N]\n\n                            # create cell resolved file\n                            fname = os.path.join(params.savefolder,'populations','subsamples',\n                                                 '%s_%ss_%i_%i.h5' \\\n                                                 % (y, data_type, ana_params.scaling*100, sample))\n                            f = h5py.File(fname, 'w')\n                            print 'Write %s' % str(f.filename)\n                            f['data'] = data\n                            f['srate'] = srate\n                            f.close()\n\n                            # create cell type resolved file\n                            fname = os.path.join(params.savefolder,'populations','subsamples',\n                                                 '%s_population_%s_%i_%i.h5' \\\n                                                 % (y,data_type,ana_params.scaling*100,sample))\n                            f = h5py.File(fname, 'w')\n                            print 'Write %s' % str(f.filename)\n                            f['data'] = data.sum(axis=0)\n                            f['srate'] = srate\n                            f.close()\n\n                    COUNTER += 1\n\n        COMM.Barrier()\n        f = h5py.File(os.path.join(params.savefolder,'populations', '%s_%ss.h5' % (y,data_type)), 'r')\n        datashape = f['data'].shape\n        f.close()\n\n        COUNTER = 0\n        for sample in range(samples): # loop over samples\n            if COUNTER % SIZE == RANK:\n                # initialize full sum signal\n                data_full = np.zeros(datashape[1:])\n                for j,layer in enumerate(params.y_in_Y): # loop over layers\n                    for k,pop in enumerate(layer): # loop over populations\n\n                        # initialize population resolved sum signal\n                        data_Y = np.zeros(datashape[1:])\n\n                        for i,y in enumerate(pop): # loop over cell types\n\n                            # Load data\n                            fname = os.path.join(params.savefolder, 'populations',\n                                                 'subsamples', '%s_population_%s_%i_%i.h5' \\\n                                                 % (y, data_type, ana_params.scaling*100,\n                                                    sample))\n                            f = h5py.File(fname, 'r')    \n                            # Update population sum:\n                            data_Y += f['data'].value\n                            srate = f['srate'].value\n                            f.close()\n\n                        # write population sum\n                        fname = os.path.join(params.savefolder,'populations','subsamples',\n                                             '%s_population_%s_%i_%i.h5' \\\n                                             % (params.Y[2*j+k], data_type,\n                                                ana_params.scaling*100, sample))\n                        f = h5py.File(fname,'w')\n                        print 'Write %s' % str(f.filename)\n                        f['data'] = data_Y\n                        f['srate'] = srate\n                        f.close() \n\n                        # update full sum\n                        data_full += data_Y\n\n                # write sum\n                fname = os.path.join(params.savefolder,'populations','subsamples',\n                                     '%ssum_%i_%i.h5' % (data_type,ana_params.scaling*100,sample))\n                f = h5py.File(fname,'w')\n                print 'Write %s' % str(f.filename)\n                f['data'] = data_full\n                f['srate'] = srate\n                f.close()\n\n            COUNTER += 1\n\n        COMM.Barrier()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating power spectrum of sum signal for all channels and returns the power spectrum of sum signal for all channels", "response": "def calc_signal_power(params):\n\n    '''\n    calculates power spectrum of sum signal for all channels\n\n    '''\n\n    for i, data_type in enumerate(['CSD','LFP','CSD_10_0', 'LFP_10_0']):\n        if i % SIZE == RANK:\n\n            # Load data\n            if data_type in ['CSD','LFP']:\n                fname=os.path.join(params.savefolder, data_type+'sum.h5')\n            else:\n                fname=os.path.join(params.populations_path, 'subsamples',\n                                   str.split(data_type,'_')[0] + 'sum_' +\n                                   str.split(data_type,'_')[1] + '_' +\n                                   str.split(data_type,'_')[2] + '.h5')\n            #open file\n            f = h5py.File(fname)\n            data = f['data'].value\n            srate = f['srate'].value \n            tvec = np.arange(data.shape[1]) * 1000. / srate\n        \n            # slice\n            slica = (tvec >= ana_params.transient)\n            data = data[:,slica]\n    \n            # subtract mean\n            dataT = data.T - data.mean(axis=1)\n            data = dataT.T\n            f.close()\n    \n            #extract PSD\n            PSD=[]\n            for i in np.arange(len(params.electrodeParams['z'])):\n                if ana_params.mlab:\n                    Pxx, freqs=plt.mlab.psd(data[i], NFFT=ana_params.NFFT,\n                                        Fs=srate, noverlap=ana_params.noverlap,\n                                        window=ana_params.window)\n                else:\n                    [freqs, Pxx] = hlp.powerspec([data[i]], tbin= 1.,\n                                             Df=ana_params.Df, pointProcess=False)\n                    mask = np.where(freqs >= 0.)\n                    freqs = freqs[mask]\n                    Pxx = Pxx.flatten()\n                    Pxx = Pxx[mask]\n                    Pxx = Pxx/tvec[tvec >= ana_params.transient].size**2\n                PSD +=[Pxx.flatten()]\n                \n            PSD=np.array(PSD)\n    \n            # Save data\n            f = h5py.File(os.path.join(params.savefolder, ana_params.analysis_folder,\n                                       data_type + ana_params.fname_psd),'w')\n            f['freqs']=freqs\n            f['psd']=PSD\n            f['transient']=ana_params.transient\n            f['mlab']=ana_params.mlab\n            f['NFFT']=ana_params.NFFT\n            f['noverlap']=ana_params.noverlap\n            f['window']=str(ana_params.window)\n            f['Df']=str(ana_params.Df)\n            f.close()\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_join(self, connection, event):\n        target = event.source\n        self.privmsg(target, 'Hello %s!' % target)", "response": "Handles the join event and greets everone\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun RASH index daemon. This daemon watches the directory ``~/.config/rash/data/record`` and translate the JSON files dumped by ``record`` command into sqlite3 DB at ``~/.config/rash/data/db.sqlite``. ``rash init`` will start RASH automatically by default. But there are alternative ways to start daemon. If you want to organize background process in one place such as supervisord_, it is good to add `--restart` option to force stop other daemon process if you accidentally started it in other place. Here is an example of supervisord_ setup:: [program:rash-daemon] command=rash daemon --restart .. _supervisord: http://supervisord.org/ Alternatively, you can call ``rash index`` in cron job to avoid using daemon. It is useful if you want to use RASH on NFS, as it looks like watchdog does not work on NFS.:: # Refresh RASH DB every 10 minutes */10 * * * * rash index", "response": "def daemon_run(no_error, restart, record_path, keep_json, check_duplicate,\n               use_polling, log_level):\n    \"\"\"\n    Run RASH index daemon.\n\n    This daemon watches the directory ``~/.config/rash/data/record``\n    and translate the JSON files dumped by ``record`` command into\n    sqlite3 DB at ``~/.config/rash/data/db.sqlite``.\n\n    ``rash init`` will start RASH automatically by default.\n    But there are alternative ways to start daemon.\n\n    If you want to organize background process in one place such\n    as supervisord_, it is good to add `--restart` option to force\n    stop other daemon process if you accidentally started it in\n    other place.  Here is an example of supervisord_ setup::\n\n      [program:rash-daemon]\n      command=rash daemon --restart\n\n    .. _supervisord: http://supervisord.org/\n\n    Alternatively, you can call ``rash index`` in cron job to\n    avoid using daemon.  It is useful if you want to use RASH\n    on NFS, as it looks like watchdog does not work on NFS.::\n\n      # Refresh RASH DB every 10 minutes\n      */10 * * * * rash index\n\n    \"\"\"\n    # Probably it makes sense to use this daemon to provide search\n    # API, so that this daemon is going to be the only process that\n    # is connected to the DB?\n    from .config import ConfigStore\n    from .indexer import Indexer\n    from .log import setup_daemon_log_file, LogForTheFuture\n    from .watchrecord import watch_record, install_sigterm_handler\n\n    install_sigterm_handler()\n    cfstore = ConfigStore()\n    if log_level:\n        cfstore.daemon_log_level = log_level\n    flogger = LogForTheFuture()\n\n    # SOMEDAY: make PID checking/writing atomic if possible\n    flogger.debug('Checking old PID file %r.', cfstore.daemon_pid_path)\n    if os.path.exists(cfstore.daemon_pid_path):\n        flogger.debug('Old PID file exists.  Reading from it.')\n        with open(cfstore.daemon_pid_path, 'rt') as f:\n            pid = int(f.read().strip())\n        flogger.debug('Checking if old process with PID=%d is alive', pid)\n        try:\n            os.kill(pid, 0)     # check if `pid` is alive\n        except OSError:\n            flogger.info(\n                'Process with PID=%d is already dead.  '\n                'So just go on and use this daemon.', pid)\n        else:\n            if restart:\n                flogger.info('Stopping old daemon with PID=%d.', pid)\n                stop_running_daemon(cfstore, pid)\n            else:\n                message = ('There is already a running daemon (PID={0})!'\n                           .format(pid))\n                if no_error:\n                    flogger.debug(message)\n                    # FIXME: Setup log handler and flogger.dump().\n                    # Note that using the default log file is not safe\n                    # since it has already been used.\n                    return\n                else:\n                    raise RuntimeError(message)\n    else:\n        flogger.debug('Daemon PID file %r does not exists.  '\n                      'So just go on and use this daemon.',\n                      cfstore.daemon_pid_path)\n\n    with open(cfstore.daemon_pid_path, 'w') as f:\n        f.write(str(os.getpid()))\n\n    try:\n        setup_daemon_log_file(cfstore)\n        flogger.dump()\n        indexer = Indexer(cfstore, check_duplicate, keep_json, record_path)\n        indexer.index_all()\n        watch_record(indexer, use_polling)\n    finally:\n        os.remove(cfstore.daemon_pid_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts daemon in a subprocess.", "response": "def start_daemon_in_subprocess(options, outpath=os.devnull):\n    \"\"\"\n    Run `rash daemon --no-error` in background.\n\n    :type options: list of str\n    :arg  options: options for \"rash daemon\" command\n    :type outpath: str\n    :arg  outpath: path to redirect daemon output\n\n    \"\"\"\n    import subprocess\n    import sys\n    from .utils.py3compat import nested\n    from .utils.pathutils import mkdirp\n    if outpath != os.devnull:\n        mkdirp(os.path.dirname(outpath))\n    with nested(open(os.devnull),\n                open(outpath, 'w')) as (stdin, stdout):\n        subprocess.Popen(\n            [os.path.abspath(sys.executable), '-m', 'rash.cli',\n             'daemon', '--no-error'] + options,\n            preexec_fn=os.setsid,\n            stdin=stdin, stdout=stdout, stderr=subprocess.STDOUT)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshow detailed command history by its ID.", "response": "def show_run(command_history_id):\n    \"\"\"\n    Show detailed command history by its ID.\n    \"\"\"\n    from pprint import pprint\n    from .config import ConfigStore\n    from .database import DataBase\n    db = DataBase(ConfigStore().db_path)\n    with db.connection():\n        for ch_id in command_history_id:\n            crec = db.get_full_command_record(ch_id)\n            pprint(crec.__dict__)\n            print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts an item into the given database.", "response": "def insert(self, database, key, value, callback=None):\n        \"\"\"\n        Insert an item into the given database.\n\n        :param database: The database into which to insert the value.\n        :type database: .BlobDatabaseID\n        :param key: The key to insert.\n        :type key: uuid.UUID\n        :param value: The value to insert.\n        :type value: bytes\n        :param callback: A callback to be called on success or failure.\n        \"\"\"\n        token = self._get_token()\n        self._enqueue(self._PendingItem(token, BlobCommand(token=token, database=database,\n                                                           content=InsertCommand(key=key.bytes, value=value)),\n                                        callback))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete an item from the given database.", "response": "def delete(self, database, key, callback=None):\n        \"\"\"\n        Delete an item from the given database.\n\n        :param database: The database from which to delete the value.\n        :type database: .BlobDatabaseID\n        :param key: The key to delete.\n        :type key: uuid.UUID\n        :param callback: A callback to be called on success or failure.\n        \"\"\"\n        token = self._get_token()\n        self._enqueue(self._PendingItem(token, BlobCommand(token=token, database=database,\n                                                           content=DeleteCommand(key=key.bytes)),\n                                        callback))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear(self, database, callback=None):\n        token = self._get_token()\n        self._enqueue(self._PendingItem(token, BlobCommand(token=token, database=database,\n                                                           content=ClearCommand()),\n                                        callback))", "response": "Wipe the given database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef invoke(self, headers, body):\n        xml = Service._create_request(headers, body)\n\n        try:\n            response = self.session.post(self.endpoint, verify=False, data=xml)\n            logging.debug(response.content)\n        except Exception as e:\n            traceback.print_exc()\n            raise WSManException(e)\n\n        if response.status_code == 200:\n            return Service._parse_response(response.content)\n\n        if response.status_code == 401:\n            raise WSManAuthenticationException('the remote host rejected authentication')\n\n        raise WSManException('the remote host returned an unexpected http status code: %s' % response.status_code)", "response": "Invoke the soap service"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _determine_auth_mechanism(username, password, delegation):\n        if re.match('(.*)@(.+)', username) is not None:\n            if delegation is True:\n                raise Exception('Kerberos is not yet supported, specify the username in <domain>\\<username> form for NTLM')\n            else:\n                raise Exception('Kerberos is not yet supported, specify the username in <domain>>\\<username> form for NTLM')\n\n        # check for NT format 'domain\\username' a blank domain or username is invalid\n        legacy = re.match('(.*)\\\\\\\\(.*)', username)\n        if legacy is not None:\n            if not legacy.group(1):\n                raise Exception('Please specify the Windows domain for user in <domain>\\<username> format')\n            if not legacy.group(2):\n                raise Exception('Please specify the Username of the user in <domain>\\<username> format')\n            if delegation is True:\n                return HttpCredSSPAuth(legacy.group(1), legacy.group(2), password)\n            else:\n                return HttpNtlmAuth(legacy.group(1), legacy.group(2), password)\n\n        #return HttpCredSSPAuth(\"SERVER2012\", \"Administrator\", password)\n        # attempt NTLM (local account, not domain) - if username is '' then we try anonymous NTLM auth\n        # as if anyone will configure that - uf!\n        return HttpNtlmAuth('', username, password)", "response": "Determine the authentication mechanism for the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the SOAP 1. 2 Envelope", "response": "def _create_request(headers, body):\n        \"\"\"\n        Create the SOAP 1.2 Envelope\n        An ordered dictionary is required to ensure the same order is reflected in the XML, otherwise the\n        SOAP Body element would appear before the Header element.\n        \"\"\"\n        envelope = OrderedDict()\n        for (namespace, alias) in Service.Namespaces.items():\n            envelope['@xmlns:' + alias] = namespace\n        envelope['soap:Header'] = headers\n        envelope['soap:Body'] = body\n        return xmltodict.unparse({'soap:Envelope': envelope}, encoding='utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nattempting to parse the SOAP response and return a python object", "response": "def _parse_response(xml):\n        \"\"\"\n        Attempt to parse the SOAP response and return a python object\n        Raise a WSManException if a Fault is found\n        \"\"\"\n        try:\n            soap_response = xmltodict.parse(xml, process_namespaces=True, namespaces=Service.Namespaces)\n        except Exception:\n            logging.debug('unable to parse the xml response: %s', xml)\n            raise WSManException(\"the remote host returned an invalid soap response\")\n\n        # the delete response has an empty body\n        body = soap_response['soap:Envelope']['soap:Body']\n        if body is not None and 'soap:Fault' in body:\n            raise WSManOperationException(body['soap:Fault']['soap:Reason']['soap:Text']['#text'])\n        return body"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch and extract latest Life - Line version of Fiji from URL and return the full path to the image.", "response": "def fetch(force=False):\n    \"\"\"Fetch and extract latest Life-Line version of Fiji is just ImageJ\n    to *~/.bin*.\n\n    Parameters\n    ----------\n    force : bool\n        Force overwrite of existing Fiji in *~/.bin*.\n\n    \"\"\"\n    try:\n        # python 2\n        from urllib2 import urlopen, HTTPError, URLError\n    except ImportError:\n        # python 3\n        from urllib.request import urlopen, HTTPError, URLError\n\n    if os.path.isdir(FIJI_ROOT) and not force:\n        return\n    elif not os.path.isdir(FIJI_ROOT):\n        print('Fiji missing in %s' % FIJI_ROOT)\n\n    if force:\n        print('Deleting %s' % FIJI_ROOT)\n        shutil.rmtree(FIJI_ROOT, ignore_errors=True)\n\n    print('Downloading fiji from %s' % URL)\n    try:\n        req = urlopen(URL)\n        try:\n            size = int(req.info()['content-length'])\n        except AttributeError:\n            size = -1\n\n        chunk = 512*1024\n        fp = BytesIO()\n        i = 0\n        while 1:\n            data = req.read(chunk)\n            if not data:\n                break\n            fp.write(data)\n            if size > 0:\n                percent = fp.tell() // (size/100)\n                msg = 'Downloaded %d percent      \\r' % percent\n            else:\n                msg = 'Downloaded %d bytes\\r' % fp.tell()\n            sys.stdout.write(msg)\n    except (HTTPError, URLError) as e:\n        print('Error getting fiji: {}'.format(e))\n        sys.exit(1)\n\n    try:\n        print('\\nExtracting zip')\n        z = ZipFile(fp)\n        z.extractall(BIN_FOLDER)\n        # move to Fiji-VERSION.app to easily check if it exists (upon fijibin upgrade)\n        os.rename(EXTRACT_FOLDER, FIJI_ROOT)\n    except (BadZipFile, IOError) as e:\n        print('Error extracting zip: {}'.format(e))\n        sys.exit(1)\n\n    for path in BIN_NAMES.values():\n        st = os.stat(path)\n        os.chmod(path, st.st_mode | stat.S_IEXEC)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nescape value to prevent script and unicode whitespace attacks.", "response": "def escapejson_filter(value):\n    \"\"\"\n    Escape `value` to prevent </script> and unicode whitespace attacks. If\n    `value` is not a string, JSON-encode it first.\n    \"\"\"\n    if isinstance(value, six.string_types):\n        string = value\n    else:\n        string = json.dumps(value, cls=DjangoJSONEncoder)\n    return mark_safe(escapejson(string))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Mongo cursor using the class variables", "response": "def get_mongo_cursor(self, bulk=False):\n        \"\"\"\n            Returns Mongo cursor using the class variables\n\n            :param bulk: bulk writer option\n            :type bulk: boolean\n\n            :return: mongo collection for which cursor will be created\n            :rtype: mongo colection object\n        \"\"\"\n        try:\n            if self.host:\n                if self.port:\n                    client = MongoClient(self.host, self.port)\n                else:\n                    client = MongoClient(\n                        self.host, MongoCollection.DEFAULT_PORT)\n            else:\n\n                client = MongoClient(self.mongo_uri)\n\n            db = client[self.db_name]\n            cursor = db[self.collection]\n\n            if bulk:\n                try:\n                    return cursor.initialize_unordered_bulk_op()\n                except Exception as e:\n                    msg = \"Mongo Bulk cursor could not be fetched, Error: {error}\".format(\n                        error=str(e))\n                    raise Exception(msg)\n\n            return cursor\n\n        except Exception as e:\n            msg = \"Mongo Connection could not be established for Mongo Uri: {mongo_uri}, Database: {db_name}, Collection {col}, Error: {error}\".format(\n                mongo_uri=self.mongo_uri, db_name=self.db_name, col=self.collection, error=str(e))\n            raise Exception(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bulk_cursor_execute(self, bulk_cursor):\n        try:\n            result = bulk_cursor.execute()\n        except BulkWriteError as bwe:\n            msg = \"bulk_cursor_execute: Exception in executing Bulk cursor to mongo with {error}\".format(\n                error=str(bwe))\n            raise Exception(msg)\n        except Exception as e:\n            msg = \"Mongo Bulk cursor could not be fetched, Error: {error}\".format(\n                error=str(e))\n            raise Exception(msg)", "response": "Executes the bulk cursor and returns the result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef detect_terminal(_environ=os.environ):\n    if _environ.get('TMUX'):\n        return 'tmux'\n    elif subdict_by_key_prefix(_environ, 'BYOBU'):\n        return 'byobu'\n    elif _environ.get('TERM').startswith('screen'):\n        return _environ['TERM']\n    elif _environ.get('COLORTERM'):\n        return _environ['COLORTERM']\n    else:\n        return _environ.get('TERM')", "response": "Detects the terminal you are using."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_waittime(self):\n        now = time.time()\n        self.sentmessages.appendleft(now)\n        if len(self.sentmessages) == self.sentmessages.maxlen:\n            # check if the oldes message is older than\n            # limited by self.limitinterval\n            oldest = self.sentmessages[-1]\n            waittime = self.limitinterval - (now - oldest)\n            if waittime > 0:\n                return waittime + 1  # add a little buffer\n        return 0", "response": "Return the appropriate time to wait in seconds if we sent too many messages\n        is set to 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a raw string to the server.", "response": "def send_raw(self, string):\n        \"\"\"Send raw string to the server.\n\n        The string will be padded with appropriate CR LF.\n        If too many messages are sent, this will call\n        :func:`time.sleep` until it is allowed to send messages again.\n\n        :param string: the raw string to send\n        :type string: :class:`str`\n        :returns: None\n        :raises: :class:`irc.client.InvalidCharacters`,\n                 :class:`irc.client.MessageTooLong`,\n                 :class:`irc.client.ServerNotConnectedError`\n        \"\"\"\n        waittime = self.get_waittime()\n        if waittime:\n            log.debug('Sent too many messages. Waiting %s seconds',\n                      waittime)\n            time.sleep(waittime)\n        return super(ServerConnection3, self).send_raw(string)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing the given line and handle the events", "response": "def _process_line(self, line):\n        \"\"\"Process the given line and handle the events\n\n        :param line: the raw message\n        :type line: :class:`str`\n        :returns: None\n        :rtype: None\n        :raises: None\n        \"\"\"\n        m = self._rfc_1459_command_regexp.match(line)\n        prefix = m.group('prefix')\n        tags = self._process_tags(m.group('tags'))\n        source = self._process_prefix(prefix)\n        command = self._process_command(m.group('command'))\n        arguments = self._process_arguments(m.group('argument'))\n        if not self.real_server_name:\n            self.real_server_name = prefix\n\n        # Translate numerics into more readable strings.\n        command = irc.events.numeric.get(command, command)\n        if command not in [\"privmsg\", \"notice\"]:\n            return super(ServerConnection3, self)._process_line(line)\n\n        event = Event3(\"all_raw_messages\", self.get_server_name(),\n                       None, [line], tags=tags)\n        self._handle_event(event)\n\n        target, msg = arguments[0], arguments[1]\n        messages = irc.ctcp.dequote(msg)\n        command = self._resolve_command(command, target)\n        for m in messages:\n            self._handle_message(tags, source, command, target, m)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _resolve_command(self, command, target):\n        if command == \"privmsg\":\n            if irc.client.is_channel(target):\n                command = \"pubmsg\"\n        else:\n            if irc.client.is_channel(target):\n                command = \"pubnotice\"\n            else:\n                command = \"privnotice\"\n        return command", "response": "Resolves the command string to the correct event type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_message(self, tags, source, command, target, msg):\n        if isinstance(msg, tuple):\n            if command in [\"privmsg\", \"pubmsg\"]:\n                command = \"ctcp\"\n            else:\n                command = \"ctcpreply\"\n\n            msg = list(msg)\n            log.debug(\"tags: %s, command: %s, source: %s, target: %s, \"\n                      \"arguments: %s\", tags, command, source, target, msg)\n            event = Event3(command, source, target, msg, tags=tags)\n            self._handle_event(event)\n            if command == \"ctcp\" and msg[0] == \"ACTION\":\n                event = Event3(\"action\", source, target, msg[1:], tags=tags)\n                self._handle_event(event)\n        else:\n            log.debug(\"tags: %s, command: %s, source: %s, target: %s, \"\n                      \"arguments: %s\", tags, command, source, target, [msg])\n            event = Event3(command, source, target, [msg], tags=tags)\n            self._handle_event(event)", "response": "Construct the correct events and handle them"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the tags of the message", "response": "def _process_tags(self, tags):\n        \"\"\"Process the tags of the message\n\n        :param tags: the tags string of a message\n        :type tags: :class:`str` | None\n        :returns: list of tags\n        :rtype: :class:`list` of :class:`message.Tag`\n        :raises: None\n        \"\"\"\n        if not tags:\n            return []\n        return [message.Tag.from_str(x) for x in tags.split(';')]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_arguments(self, arguments):\n        if not arguments:\n            return None\n        a = arguments.split(\" :\", 1)\n        arglist = a[0].split()\n        if len(a) == 2:\n            arglist.append(a[1])\n        return arglist", "response": "Process the arguments string of a message\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_mongo_doc(self, key_list):\n        mongo_doc = {}\n\n        if isinstance(key_list, list) and key_list:\n\n            for key in key_list:\n                mongo_doc[key] = \"$\" + str(key)\n        return mongo_doc", "response": "Builds the mongo document for the n - item cluster items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating aggregation pipeline for aggregation", "response": "def build_pipeline(self, collection):\n        \"\"\"\n            Creates aggregation pipeline for aggregation\n            :param collection: Mongo collection for aggregation\n            :type  collection: MongoCollection\n\n            :return pipeline: list of dicts\n        \"\"\"\n        pipeline = []\n\n        if isinstance(collection.where_dict, dict) and collection.where_dict:\n            match_dict = {\n                \"$match\": collection.where_dict\n            }\n            pipeline.append(match_dict)\n\n        group_keys_dict = self.build_mongo_doc(self.join_keys)\n        push_dict = self.build_mongo_doc(collection.select_keys)\n\n        group_by_dict = {\n            \"$group\":\n                {\n                    \"_id\": group_keys_dict,\n                    \"docs\": {\n                        \"$push\": push_dict\n                    }\n                }\n        }\n\n        pipeline.append(group_by_dict)\n\n        return pipeline"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch and processes the data from the input collection using the pipeline.", "response": "def fetch_and_process_data(self, collection, pipeline):\n        \"\"\"\n            Fetches and Processess data from the input collection by aggregating using the pipeline\n\n            :param collection: The collection object for which mongo connection has to be made\n            :type  collection: MongoCollection\n\n            :param pipeline: The pipeline using which aggregation will be performed\n            :type  pipeline: list of dicts\n\n            :return grouped_docs_dict: dict of property_id,metric_count\n        \"\"\"\n        collection_cursor = collection.get_mongo_cursor()\n        grouped_docs = list(collection_cursor.aggregate(pipeline))\n        grouped_docs_dict = {}\n\n        while grouped_docs:\n            doc = grouped_docs.pop()\n            keys_list = []\n\n            for group_by_key in self.join_keys:\n                keys_list.append(doc[\"_id\"].get(group_by_key, None))\n            grouped_docs_dict[tuple(keys_list)] = doc['docs']\n\n        return grouped_docs_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_collections_data(self):\n\n        collections = {\n            'left': self.left_collection,\n            'right': self.right_collection\n        }\n        for collection_type, collection in collections.iteritems():\n            pipeline = self.build_pipeline(collection)\n            self.collections_data[collection_type] = self.fetch_and_process_data(\n                collection, pipeline)", "response": "Function to fetch the data from the two collections"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_duration(string):\n    if string.isdigit():\n        return int(string)\n    try:\n        return float(string)\n    except ValueError:\n        pass\n    string = string.rstrip()\n    for (suf, mult) in DURATION_SUFFIX_MAP.items():\n        if string.lower().endswith(suf):\n            try:\n                return parse_duration(string[:-len(suf)].strip()) * mult\n            except TypeError:\n                return", "response": "Parse human readable duration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new session and return the session id", "response": "def create_session():\n        \"\"\"\n        shell = CommandShell('http://192.168.145.132:5985/wsman', 'Administrator', 'Pa55w0rd')\n        \"\"\"\n        shell = CommandShell('http://192.168.137.238:5985/wsman', 'Administrator', 'Pa55w0rd')\n        shell.open()\n        command_id = shell.run('ipconfig', ['/all'])\n        (stdout, stderr, exit_code) = shell.receive(command_id)\n        sys.stdout.write(stdout.strip() + '\\r\\n')\n        shell.close()\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fake_chars_or_choice(self, field_name):\n        return self.djipsum_fields().randomCharField(\n            self.model_class(),\n            field_name=field_name\n        )", "response": "Return fake chars or choice of a field."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fake_decimal(self, field_name):\n        return self.djipsum_fields().randomDecimalField(\n            self.model_class(),\n            field_name=field_name\n        )", "response": "Validate if the field has a max_digits and decimal_places and generate a unique decimal number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fake_fk(self, field_name):\n        return self.djipsum_fields().getOrCreateForeignKey(\n            model_class=self.model_class(),\n            field_name=field_name\n        )", "response": "Returns related random object to set as ForeignKey.\n            Example Output :\n            <User username >"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the random objects from m2m relationship.", "response": "def fake_m2m(self, obj, field_name):\n        \"\"\"\n        Return the random objects from m2m relationship.\n        The ManyToManyField need specific object,\n        so i handle it after created the object.\n        \"\"\"\n        instance_m2m = getattr(obj, field_name)\n        objects_m2m = instance_m2m.model.objects.all()\n\n        if objects_m2m.exists():\n            ids_m2m = [i.pk for i in objects_m2m]\n            random_decission = random.sample(\n                range(min(ids_m2m), max(ids_m2m)), max(ids_m2m) - 1\n            )\n            if len(random_decission) <= 2:\n                random_decission = [\n                    self.djipsum_fields().randomize(ids_m2m)\n                ]\n            related_objects = [\n                rel_obj for rel_obj in objects_m2m\n                if rel_obj.pk in random_decission\n            ]\n            instance_m2m.add(*related_objects)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating the object only once.", "response": "def create(self, fields):\n        \"\"\"\n        Create the object only once.\n        So, you need loop to usage.\n\n        :param `fields` is dictionary fields.\n        \"\"\"\n        try:\n            # Cleaning the fields, and check if has `ForeignKey` type.\n            cleaned_fields = {}\n            for key, value in fields.items():\n                if type(value) is dict:\n                    try:\n                        if value['type'] == 'fk':\n                            fake_fk = self.fake_fk(value['field_name'])\n                            cleaned_fields.update({key: fake_fk})\n                    except:\n                        pass\n                else:\n                    cleaned_fields.update({key: value})\n\n            # Creating the object from dictionary fields.\n            model_class = self.model_class()\n            obj = model_class.objects.create(**cleaned_fields)\n\n            # The `ManyToManyField` need specific object,\n            # so i handle it after created the object.\n            for key, value in fields.items():\n                if type(value) is dict:\n                    try:\n                        if value['type'] == 'm2m':\n                            self.fake_m2m(obj, value['field_name'])\n                    except:\n                        pass\n            try:\n                obj.save_m2m()\n            except:\n                obj.save()\n            return obj\n        except Exception as e:\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trading_dates(start, end, calendar='US'):\n    kw = dict(start=pd.Timestamp(start, tz='UTC').date(), end=pd.Timestamp(end, tz='UTC').date())\n    us_cal = getattr(sys.modules[__name__], f'{calendar}TradingCalendar')()\n    return pd.bdate_range(**kw).drop(us_cal.holidays(**kw))", "response": "Returns a pandas. DatetimeIndex containing trading dates for given exchange."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating logger for a specific log file.", "response": "def get_logger(\n        name_or_func, log_file='', level=logging.INFO, types='stream', **kwargs\n):\n    \"\"\"\n    Generate logger\n\n    Args:\n        name_or_func: logger name or current running function\n        log_file: logger file\n        level: level of logs - debug, info, error\n        types: file or stream, or both\n\n    Returns:\n        logger\n\n    Examples:\n        >>> get_logger(name_or_func='download_data', level='debug', types='stream')\n        <Logger download_data (DEBUG)>\n        >>> get_logger(name_or_func='preprocess', log_file='pre.log', types='file|stream')\n        <Logger preprocess (INFO)>\n    \"\"\"\n    if isinstance(level, str): level = getattr(logging, level.upper())\n    log_name = name_or_func if isinstance(name_or_func, str) else utils.func_scope(name_or_func)\n    logger = logging.getLogger(name=log_name)\n    logger.setLevel(level=level)\n\n    if not len(logger.handlers):\n        formatter = logging.Formatter(fmt=kwargs.get('fmt', LOG_FMT))\n\n        if 'file' in types:\n            file_handler = logging.FileHandler(log_file)\n            file_handler.setFormatter(fmt=formatter)\n            logger.addHandler(file_handler)\n\n        if 'stream' in types:\n            stream_handler = logging.StreamHandler()\n            stream_handler.setFormatter(fmt=formatter)\n            logger.addHandler(stream_handler)\n\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_password(self, raw_password):\n        if raw_password is None:\n            self.set_unusable_password()\n        else:\n            xmpp_backend.set_password(self.node, self.domain, raw_password)", "response": "Sets the password for the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling XmppBackendBase. check_password for the user.", "response": "def check_password(self, raw_password):\n        \"\"\"Calls :py:func:`~xmpp_backends.base.XmppBackendBase.check_password` for the user.\"\"\"\n        return xmpp_backend.check_password(self.node, self.domain, raw_password)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of clients.", "response": "def get_clients(self, limit=None, offset=None):\n        \"\"\"\n        Returns a list of clients.\n        \"\"\"\n        data = {}\n        if limit:\n            data['limit'] = limit\n        if offset:\n            data['offset'] = offset\n        result = self._request('GET', '/clients', data=json.dumps(data))\n        return result.json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a client s data", "response": "def get_client_data(self, client):\n        \"\"\"\n        Returns a client.\n        \"\"\"\n        data = self._request('GET', '/clients/{}'.format(client))\n        return data.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the history for a client.", "response": "def get_client_history(self, client):\n        \"\"\"\n        Returns the history for a client.\n        \"\"\"\n        data = self._request('GET', '/clients/{}/history'.format(client))\n        return data.json()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_client_events(self, client):\n        data = self._request('GET', '/events/{}'.format(client))\n        return data.json()", "response": "Returns the list of all events for a given client"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an event for a given client & check name.", "response": "def get_event(self, client, check):\n        \"\"\"\n        Returns an event for a given client & check name.\n        \"\"\"\n        data = self._request('GET', '/events/{}/{}'.format(client, check))\n        return data.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_event(self, client, check):\n        self._request('DELETE', '/events/{}/{}'.format(client, check))\n        return True", "response": "Delete an event for a given check on a given client."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post_event(self, client, check):\n        self._request('POST', '/resolve',\n                      data=json.dumps({'client': client, 'check': check}))\n        return True", "response": "Post an event to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nissues a check execution request.", "response": "def post_check_request(self, check, subscribers):\n        \"\"\"\n        Issues a check execution request.\n        \"\"\"\n        data = {\n            'check': check,\n            'subscribers': [subscribers]\n        }\n        self._request('POST', '/request', data=json.dumps(data))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a silence entry.", "response": "def post_silence_request(self, kwargs):\n        \"\"\"\n        Create a silence entry.\n        \"\"\"\n        self._request('POST', '/silenced', data=json.dumps(kwargs))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear_silence(self, kwargs):\n        self._request('POST', '/silenced/clear', data=json.dumps(kwargs))\n        return True", "response": "Clear a silence entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_aggregate_check(self, check, age=None):\n        data = {}\n        if age:\n            data['max_age'] = age\n\n        result = self._request('GET', '/aggregates/{}'.format(check),\n                               data=json.dumps(data))\n        return result.json()", "response": "Returns the list of aggregates for a given check"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning health information on transport & Redis connections.", "response": "def get_health(self, consumers=2, messages=100):\n        \"\"\"\n        Returns health information on transport & Redis connections.\n        \"\"\"\n        data = {'consumers': consumers, 'messages': messages}\n\n        try:\n            self._request('GET', '/health', data=json.dumps(data))\n            return True\n        except SensuAPIException:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_result(self, client, check):\n        data = self._request('GET', '/results/{}/{}'.format(client, check))\n        return data.json()", "response": "Returns an event for a given client & result name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a check result for a given client.", "response": "def delete_result(self, client, check):\n        \"\"\"\n        Deletes an check result data for a given check on a given client.\n        \"\"\"\n        self._request('DELETE', '/results/{}/{}'.format(client, check))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nposts check result data.", "response": "def post_result_data(self, client, check, output, status):\n        \"\"\"\n        Posts check result data.\n        \"\"\"\n        data = {\n            'source': client,\n            'name': check,\n            'output': output,\n            'status': status,\n        }\n        self._request('POST', '/results', data=json.dumps(data))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a stash. (JSON document)", "response": "def create_stash(self, payload, path=None):\n        \"\"\"\n        Create a stash. (JSON document)\n        \"\"\"\n        if path:\n            self._request('POST', '/stashes/{}'.format(path),\n                          json=payload)\n        else:\n            self._request('POST', '/stashes', json=payload)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_subscriptions(self, nodes=[]):\n        if len(nodes) > 0:\n            data = [node for node in self.get_clients() if node['name'] in nodes]\n        else:\n            data = self.get_clients()\n        channels = []\n        for client in data:\n            if 'subscriptions' in client:\n                if isinstance(client['subscriptions'], list):\n                    for channel in client['subscriptions']:\n                        if channel not in channels:\n                            channels.append(channel)\n                else:\n                    if client['subscriptions'] not in channels:\n                        channels.append(client['subscriptions'])\n        return channels", "response": "Returns all the channels where nodes are subscribed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_subscriptions_channel(self, search_channel):\n        data = self.get_clients()\n        clients = []\n        for client in data:\n            if 'subscriptions' in client:\n                if isinstance(client['subscriptions'], list):\n                    if search_channel in client['subscriptions']:\n                        clients.append(client['name'])\n                else:\n                    if search_channel == client['subscriptions']:\n                        clients.append(client['name'])\n        return clients", "response": "Return all the nodes that are subscribed to the specified channel"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_extension(self, ext):\n        if sys.platform == \"win32\":\n            _clr_compiler = \"C:\\\\Windows\\\\Microsoft.NET\\\\Framework\\\\v4.0.30319\\\\csc.exe\"\n        else:\n            _clr_compiler = \"mcs\"\n        cmd = [ \n            _clr_compiler,\n            \"/target:library\",\n            \"clrmagic.cs\"\n        ]\n        check_call(\" \".join(cmd), shell=True)", "response": "build clrmagic. dll using csc or mcs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait_for_event(self, event, timeout=10):\n        return self.__handler.wait_for_event(event, timeout=timeout)", "response": "Block waiting for the given event. Returns the event params."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching the first index for which target is greater than the first item of the tuple found in values", "response": "def search_greater(values, target):\n    \"\"\"\n    Return the first index for which target is greater or equal to the first\n    item of the tuple found in values\n    \"\"\"\n    first = 0\n    last = len(values)\n\n    while first < last:\n        middle = (first + last) // 2\n        if values[middle][0] < target:\n            first = middle + 1\n        else:\n            last = middle\n\n    return first"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a value to the reservoir s set of keys.", "response": "def add(self, value):\n        \"\"\"\n        Add a value to the reservoir\n        The value will be casted to a floating-point, so a TypeError or a\n        ValueError may be raised.\n        \"\"\"\n\n        if not isinstance(value, float):\n            value = float(value)\n\n        return self._do_add(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if self and other are of the same type and the same parameters.", "response": "def same_kind(self, other):\n        \"\"\"\n        Return True if \"other\" is an object of the same type and it was\n        instantiated with the same parameters\n        \"\"\"\n\n        return type(self) is type(other) and self._same_parameters(other)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _lookup(self, timestamp):\n\n        idx = search_greater(self._values, timestamp)\n        if (idx < len(self._values)\n                and math.fabs(self._values[idx][0] - timestamp) < self.EPSILON):\n            return idx\n        return None", "response": "Return the index of the value associated with timestamp if any else None."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace the value associated with timestamp or add the new value", "response": "def _put(self, timestamp, value):\n        \"\"\"Replace the value associated with \"timestamp\" or add the new value\"\"\"\n\n        idx = self._lookup(timestamp)\n        if idx is not None:\n            self._values[idx] = (timestamp, value)\n        else:\n            self._values.append((timestamp, value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the computed statistics over the gathered data", "response": "def get(self):\n        \"\"\"Return the computed statistics over the gathered data\"\"\"\n\n        values = self.reservoir.sorted_values\n\n        def safe(f, *args):\n            try:\n                return f(values, *args)\n            except exceptions.StatisticsError:\n                return 0.0\n\n        plevels = [50, 75, 90, 95, 99, 99.9]\n        percentiles = [safe(statistics.percentile, p) for p in plevels]\n\n        try:\n            histogram = statistics.get_histogram(values)\n        except exceptions.StatisticsError:\n            histogram = [(0, 0)]\n\n        res = dict(\n            kind=\"histogram\",\n            min=values[0] if values else 0,\n            max=values[-1] if values else 0,\n            arithmetic_mean=safe(statistics.mean),\n            geometric_mean=safe(statistics.geometric_mean),\n            harmonic_mean=safe(statistics.harmonic_mean),\n            median=safe(statistics.median),\n            variance=safe(statistics.variance),\n            standard_deviation=safe(statistics.stdev),\n            skewness=safe(statistics.skewness),\n            kurtosis=safe(statistics.kurtosis),\n            percentile=py3comp.zip(plevels, percentiles),\n            histogram=histogram,\n            n=len(values))\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreloading an app s glance. Blocks as long as necessary.", "response": "def reload_glance(self, target_app, slices=None):\n        \"\"\"\n        Reloads an app's glance. Blocks as long as necessary.\n\n        :param target_app: The UUID of the app for which to reload its glance.\n        :type target_app: ~uuid.UUID\n        :param slices: The slices with which to reload the app's glance.\n        :type slices: list[.AppGlanceSlice]\n        \"\"\"\n        glance = AppGlance(\n            version=1,\n            creation_time=time.time(),\n            slices=(slices or [])\n        )\n        SyncWrapper(self._blobdb.insert, BlobDatabaseID.AppGlance, target_app, glance.serialise()).wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef network_sketch(ax, highlight=None, labels=True, yscaling=1.):    \n    '''\n    highlight : None or string\n         if string, then only the label of this population is set and the box is highlighted\n    '''\n\n    name_to_id_mapping={'L6E':(0,0),\n                        'L6I':(0,1),\n                        'L5E':(1,0),\n                        'L5I':(1,1),\n                        'L4E':(2,0),\n                        'L4I':(2,1),\n                        'L23E':(3,0),\n                        'L23I':(3,1)\n    } \n    \n    showgrid=False  ## switch on/off grid\n\n    ## sketch parameters\n    layer_x=0.1                            ## x position of left boundary of cortex layers\n    layer6_y=0.2*yscaling                           ## y position of lower boundary of layer 6\n    layer_width=0.65                       ## width of cortex layers\n    layer_height=0.21*yscaling                      ## height of cortex layers\n    layer_colors=['0.9','0.8','0.9','0.8'] ## layer colors\n    c_pop_size=0.15                        ## cortex population size\n    c_pop_dist=0.17                        ## distance between cortex populations\n    t_pop_size=0.15                        ## thalamus population size\n    t_pop_y=0.0                         ## y position of lower thalamus boundary\n    axon_cell_sep=0.04                     ## distance between axons and popualations\n    cc_input_y=0.6*yscaling                        ## y position of cortico-cortical synapses (relative to cortex population)\n    tc_input_y=0.4*yscaling                         ## y position of thalamo-cortical synapses (relative to cortex population)\n\n    exc_clr = 'k' if analysis_params.bw else analysis_params.colorE                            ## color of excitatory axons/synapses\n    inh_clr = 'gray' if analysis_params.bw else analysis_params.colorI                            ## color of inhibitory axons/synapses\n\n    lw_pop=0.5                              ## linewidth for populations\n    lw_axons=0.4                           ## linewidth for axons\n\n    arrow_size=0.013                       ## arrow size\n    conn_radius=0.005                      ## radius of connector marker\n\n    legend_length=0.07                     ## length of legend arrows\n    \n    colors = phlp.get_colors(8)[::-1]            ## colors of each population\n\n    fontdict1={'fontsize': 6, ## population name \n              'weight':'normal',\n              'horizontalalignment':'center',\n              'verticalalignment':'center'}\n\n    fontdict2={'fontsize': 6, ## cortico-cortical input\n              'weight':'normal',\n              'horizontalalignment':'center',\n              'verticalalignment':'center'}\n\n    fontdict3={'fontsize': 6, ## legend \n              'weight':'normal',\n              'horizontalalignment':'left',\n              'verticalalignment':'center'}\n\n    ######################################################################################\n\n    def draw_box(ax,pos,lw=1.,ls='solid',eclr='k',fclr='w',zorder=0, clip_on=False,\n                 boxstyle=patches.BoxStyle(\"Round\", pad=0.0), padadjust=0.):\n        '''Draws a rectangle.'''    \n        rect = patches.FancyBboxPatch((pos[0]+padadjust, pos[1]+padadjust),\n            pos[2]-2*padadjust, pos[3]-2*padadjust, ec=eclr, fc=fclr,\n            lw=lw, ls=ls, zorder=zorder, clip_on=clip_on,\n            boxstyle=boxstyle)\n        ax.add_patch(rect)\n\n    def draw_circle(ax,xy,radius,lw=1.,ls='solid',eclr='k',fclr='w',zorder=0):\n        '''Draws a circle.'''    \n        circ = plt.Circle((xy[0],xy[1]),radius=radius, ec=eclr,fc=fclr,lw=lw,ls=ls,zorder=zorder)\n        ax.add_patch(circ)\n\n    def put_text(ax,xy,txt,clr,fontdict,zorder=10):\n        '''Puts text to a specific position.'''\n        ax.text(xy[0],xy[1],txt,fontdict=fontdict,color=clr,zorder=zorder)\n\n    def draw_line(ax,path,lw=1.,ls='solid',lclr='k',zorder=0):\n        '''Draws a path.'''\n        #pth = path.Path(np.array(path))\n        pth = Path(np.array(path))        \n        patch = patches.PathPatch(pth, fill=False, lw=lw,ls=ls,ec=lclr,fc=lclr,zorder=zorder)\n        ax.add_patch(patch)\n\n    def draw_arrow(ax,path,lw=1.0,ls='solid',lclr='k',arrow_size=0.025,zorder=0):\n        '''Draws a path with an arrow at the end. '''\n        x=path[-2][0]\n        y=path[-2][1]\n        dx=path[-1][0]-path[-2][0]\n        dy=path[-1][1]-path[-2][1]\n\n        D=np.array([dx,dy])\n        D=D/np.sqrt(D[0]**2+D[1]**2)\n        path2=np.array(path).copy()\n        path2[-1,:]=path2[-1,:]-arrow_size*D\n\n        pth = Path(np.array(path2))\n        patch = patches.PathPatch(pth, fill=False, lw=lw,ls=ls,ec=lclr,fc=lclr,zorder=zorder)\n        ax.add_patch(patch)\n\n        arr=patches.FancyArrow(\\\n            x,y,dx,dy,\\\n                length_includes_head=True,width=0.0,head_width=arrow_size,\\\n                overhang=0.2,ec=lclr,fc=lclr,linewidth=0)\n        ax.add_patch(arr)\n\n\n    ##################################################\n    ## populations\n\n    ## cortex\n    layer_pos=[]\n    c_pop_pos=[]\n    for i in xrange(4):\n\n        ## cortex layers\n        layer_pos+=[[layer_x,layer6_y+i*layer_height*yscaling,layer_width,layer_height]] ## layer positions\n        draw_box(ax,layer_pos[i],lw=0.,fclr=layer_colors[i],zorder=0)\n\n        ## cortex populations\n        l_margin=(layer_width-2.*c_pop_size-c_pop_dist)/2.\n        b_margin=(layer_height-c_pop_size)/2.\n\n        ## positions of cortex populations\n        c_pop_pos+=[[ [layer_pos[i][0] + l_margin,\n                       layer_pos[i][1] + b_margin,\n                       c_pop_size, c_pop_size], ## E\n                      [layer_pos[i][0] + l_margin + c_pop_size + c_pop_dist,\n                       layer_pos[i][1] + b_margin,\n                       c_pop_size, c_pop_size]  ]] ## I\n\n        #draw_box(ax,c_pop_pos[i][0],lw=lw_pop,eclr='k',fclr='w',zorder=2) ## E\n        #draw_box(ax,c_pop_pos[i][1],lw=lw_pop,eclr='k',fclr='w',zorder=2) ## I    \n        draw_box(ax,c_pop_pos[i][0],lw=lw_pop,eclr='k',fclr=colors[i*2+1],zorder=2,\n                 boxstyle=patches.BoxStyle(\"Round\", pad=0.02), padadjust=0.02) ## E\n        draw_box(ax,c_pop_pos[i][1],lw=lw_pop,eclr='k',fclr=colors[i*2],zorder=2,\n                 boxstyle=patches.BoxStyle(\"Round\", pad=0.02), padadjust=0.02) ## I    \n\n\n    ## thalamus\n    c_center_x=layer_x+layer_width/2. ## x position of cortex center\n    t_pos=[c_center_x-t_pop_size/2.,t_pop_y*yscaling,t_pop_size,t_pop_size] ## thalamus position\n    #draw_box(ax,t_pos,lw=lw_pop,eclr='k',fclr='w',zorder=2) ## Th\n    draw_box(ax,t_pos,lw=lw_pop,eclr='k',fclr='k',zorder=2,\n             boxstyle=patches.BoxStyle(\"Round\", pad=0.02), padadjust=0.02) ## Th\n\n    ##################################################\n    ## intracortical axons\n\n    axon_x_dist=(c_pop_dist-2.*axon_cell_sep)/7.\n    assert(axon_x_dist>0.)\n    axon_y_dist=c_pop_size/9.#*yscaling\n    c_axon_x=[]\n    c_axon_y=[]\n\n    # x positions of vertical intracortical axons\n    for i in xrange(4): # pre layer\n        exc=c_pop_pos[i][0][0]+c_pop_size+axon_cell_sep+i*axon_x_dist ## E\n        inh=exc+4.*axon_x_dist ## I\n        c_axon_x+=[[exc,inh]]\n\n    # y positions of horizontal intracortical axons\n    for i in xrange(4): ## post layer\n        c_axon_y+=[[]]\n        for j in xrange(4): ## pre layer\n            exc=c_pop_pos[i][0][1]+(j+1.)*axon_y_dist ## E\n            inh=c_pop_pos[i][0][1]+c_pop_size-(j+1.)*axon_y_dist ## I        \n            c_axon_y[i]+=[[exc,inh]]\n\n    ## vertical intracortical axons\n    for i in xrange(4):\n        draw_line(ax,[[c_axon_x[i][0],c_axon_y[0][i][0]],[c_axon_x[i][0],c_axon_y[-1][i][0]]],lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1)\n        draw_line(ax,[[c_axon_x[i][1],c_axon_y[0][i][1]],[c_axon_x[i][1],c_axon_y[-1][i][1]]],lw=lw_axons,ls='solid',lclr=inh_clr,zorder=0)\n\n    ## horizontal intracortical axons\n    for i in xrange(4): ## post layer\n        for j in xrange(4): ## pre layer\n            path=[[c_axon_x[j][0],c_axon_y[i][j][0]],[c_pop_pos[i][0][0]+c_pop_size,c_axon_y[i][j][0]]]        \n            draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=1)\n\n            path=[[c_axon_x[j][0],c_axon_y[i][j][0]],[c_pop_pos[i][1][0],c_axon_y[i][j][0]]]        \n            draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=1)\n\n            path=[[c_axon_x[j][1],c_axon_y[i][j][1]],[c_pop_pos[i][1][0],c_axon_y[i][j][1]]]\n            draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=inh_clr,arrow_size=arrow_size,zorder=0)\n\n            path=[[c_axon_x[j][1],c_axon_y[i][j][1]],[c_pop_pos[i][0][0]+c_pop_size,c_axon_y[i][j][1]]]\n            draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=inh_clr,arrow_size=arrow_size,zorder=0)\n\n            ## connector markers\n            draw_circle(ax,[c_axon_x[j][0],c_axon_y[i][j][0]],conn_radius,lw=0,fclr=exc_clr,zorder=0)\n            draw_circle(ax,[c_axon_x[j][1],c_axon_y[i][j][1]],conn_radius,lw=0,fclr=inh_clr,zorder=0)        \n\n    ## cell outputs\n    for i in xrange(4):\n\n        path=[[c_pop_pos[i][0][0]+c_pop_size/2.,c_pop_pos[i][0][1]],\n              [c_pop_pos[i][0][0]+c_pop_size/2.,c_pop_pos[i][0][1]-axon_y_dist],\n              [c_axon_x[i][0],c_pop_pos[i][0][1]-axon_y_dist]]\n        draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1)  ## excitatory\n        draw_circle(ax,path[-1],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n        path=[[c_pop_pos[i][1][0]+c_pop_size/2.,c_pop_pos[i][1][1]],\n              [c_pop_pos[i][1][0]+c_pop_size/2.,c_pop_pos[i][1][1]-axon_y_dist],\n              [c_axon_x[-1-i][1],c_pop_pos[i][1][1]-axon_y_dist]]\n        draw_line(ax,path,lw=lw_axons,ls='solid',lclr=inh_clr,zorder=1)  ## inhibitory\n        draw_circle(ax,path[-1],conn_radius,lw=0,fclr=inh_clr,zorder=0) ## connector\n\n    ## remaining first segments for L6\n    path=[[c_axon_x[0][0],c_pop_pos[0][0][1]-axon_y_dist],[c_axon_x[0][0],c_axon_y[0][0][0]]]        \n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=0)        \n    path=[[c_axon_x[-1][1],c_pop_pos[0][1][1]-axon_y_dist],[c_axon_x[-1][1],c_axon_y[0][0][1]]]        \n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=inh_clr,zorder=0)        \n\n    ##################################################\n    ## cortico-cortical axons\n\n    ## horizontal branch in L1\n    path=[[0.,c_pop_pos[-1][0][1]+c_pop_size+axon_cell_sep],\n          [c_pop_pos[-1][1][0]+c_pop_size+axon_cell_sep,c_pop_pos[-1][0][1]+c_pop_size+axon_cell_sep]]\n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1)\n\n    ## vertical branches\n    path=[[c_pop_pos[-1][0][0]-axon_cell_sep,c_pop_pos[-1][0][1]+c_pop_size+axon_cell_sep],\n          [c_pop_pos[-1][0][0]-axon_cell_sep,c_pop_pos[0][0][1]+cc_input_y*c_pop_size]]\n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1) ## cc input to exc pop\n    draw_circle(ax,path[0],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n    path=[[c_pop_pos[-1][1][0]+c_pop_size+axon_cell_sep,c_pop_pos[-1][0][1]+c_pop_size+axon_cell_sep],\n          [c_pop_pos[-1][1][0]+c_pop_size+axon_cell_sep,c_pop_pos[0][0][1]+cc_input_y*c_pop_size]]\n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1) ## cc input to inh pop\n    draw_circle(ax,path[0],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n    ## horizontal branches (arrows)\n    for i in xrange(4):\n        ## cc input to excitatory populations\n        path=[[c_pop_pos[-1][0][0]-axon_cell_sep,c_pop_pos[i][0][1]+cc_input_y*c_pop_size],\n              [c_pop_pos[-1][0][0],c_pop_pos[i][0][1]+cc_input_y*c_pop_size],]\n        draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=0)\n        draw_circle(ax,path[0],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n        ## cc input to inhibitory populations\n        path=[[c_pop_pos[-1][1][0]+c_pop_size+axon_cell_sep,c_pop_pos[i][0][1]+cc_input_y*c_pop_size],\n              [c_pop_pos[-1][1][0]+c_pop_size,c_pop_pos[i][0][1]+cc_input_y*c_pop_size]]\n        draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=0)\n        draw_circle(ax,path[0],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n    ##################################################\n    ## thalamo-cortical axons\n\n    path=[[t_pos[0]+t_pop_size/2.,t_pos[1]+t_pop_size],\n          [t_pos[0]+t_pop_size/2.,t_pos[1]+t_pop_size+axon_y_dist]]\n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1) ## thalamic output\n    draw_circle(ax,path[-1],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n    path=[[c_pop_pos[0][0][0]-(axon_cell_sep+axon_y_dist),t_pos[1]+t_pop_size+axon_y_dist],\n          [c_pop_pos[0][1][0]+c_pop_size+(axon_cell_sep+axon_y_dist),t_pos[1]+t_pop_size+axon_y_dist]]\n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1) ## horizontal branch\n\n    path=[[c_pop_pos[0][0][0]-(axon_cell_sep+axon_y_dist),t_pos[1]+t_pop_size+axon_y_dist],\n          [c_pop_pos[0][0][0]-(axon_cell_sep+axon_y_dist),c_pop_pos[2][0][1]+tc_input_y*c_pop_size]]\n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1) ## left vertical branch\n\n    path=[[c_pop_pos[0][1][0]+c_pop_size+(axon_cell_sep+axon_y_dist),t_pos[1]+t_pop_size+axon_y_dist],\n          [c_pop_pos[0][1][0]+c_pop_size+(axon_cell_sep+axon_y_dist),c_pop_pos[2][0][1]+tc_input_y*c_pop_size]]\n    draw_line(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,zorder=1) ## right vertical branch\n\n    path=[[c_pop_pos[0][0][0]-(axon_cell_sep+axon_y_dist),c_pop_pos[2][0][1]+tc_input_y*c_pop_size],\n          [c_pop_pos[0][0][0],c_pop_pos[2][0][1]+tc_input_y*c_pop_size],]\n    draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=1) ## Th -> L4E synapses (arrows)\n    draw_circle(ax,path[0],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n    path=[[c_pop_pos[0][0][0]-(axon_cell_sep+axon_y_dist),c_pop_pos[0][0][1]+tc_input_y*c_pop_size],\n          [c_pop_pos[0][0][0],c_pop_pos[0][0][1]+tc_input_y*c_pop_size],]\n    draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=1) ## Th -> L6E synapses (arrows)\n    draw_circle(ax,path[0],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n    path=[[c_pop_pos[0][1][0]+c_pop_size+(axon_cell_sep+axon_y_dist),c_pop_pos[2][0][1]+tc_input_y*c_pop_size],\n          [c_pop_pos[0][1][0]+c_pop_size,c_pop_pos[2][0][1]+tc_input_y*c_pop_size],]\n    draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=1) ## Th -> L4I synapses (arrows)\n    draw_circle(ax,path[0],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n    path=[[c_pop_pos[0][1][0]+c_pop_size+(axon_cell_sep+axon_y_dist),c_pop_pos[0][0][1]+tc_input_y*c_pop_size],\n          [c_pop_pos[0][1][0]+c_pop_size,c_pop_pos[0][0][1]+tc_input_y*c_pop_size],]\n    draw_arrow(ax,path,lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=1) ## Th -> L6I synapses (arrows)\n    draw_circle(ax,path[0],conn_radius,lw=0,fclr=exc_clr,zorder=0) ## connector\n\n    if labels:\n        ##################################################\n        ## legend\n        legend_x=[t_pos[0]+t_pop_size+axon_cell_sep,t_pos[0]+t_pop_size+axon_cell_sep+legend_length]\n        legend_y=[t_pos[1],(t_pos[1]+2*t_pop_size/3)]\n        draw_arrow(ax,[[legend_x[0],legend_y[1]],[legend_x[1],legend_y[1]]],lw=lw_axons,ls='solid',lclr=exc_clr,arrow_size=arrow_size,zorder=1)\n        draw_arrow(ax,[[legend_x[0],legend_y[0]],[legend_x[1],legend_y[0]]],lw=lw_axons,ls='solid',lclr=inh_clr,arrow_size=arrow_size,zorder=1)\n\n        ##################################################\n        ## population names\n\n        put_text(ax,[t_pos[0]+t_pop_size/2.,(t_pos[1]+t_pop_size/2.)],r'TC','w',fontdict1)\n\n        put_text(ax,[c_pop_pos[0][0][0]+c_pop_size/2.,c_pop_pos[0][0][1]+c_pop_size/2.],r'L6E','w' if analysis_params.bw else 'k',fontdict1)\n        put_text(ax,[c_pop_pos[0][1][0]+c_pop_size/2.,c_pop_pos[0][1][1]+c_pop_size/2.],r'L6I','w' if analysis_params.bw else 'k',fontdict1)\n        \n        put_text(ax,[c_pop_pos[1][0][0]+c_pop_size/2.,c_pop_pos[1][0][1]+c_pop_size/2.],r'L5E','w' if analysis_params.bw else 'k',fontdict1)\n        put_text(ax,[c_pop_pos[1][1][0]+c_pop_size/2.,c_pop_pos[1][1][1]+c_pop_size/2.],r'L5I','w' if analysis_params.bw else 'k',fontdict1)\n        \n        put_text(ax,[c_pop_pos[2][0][0]+c_pop_size/2.,c_pop_pos[2][0][1]+c_pop_size/2.],r'L4E','w' if analysis_params.bw else 'k',fontdict1)\n        put_text(ax,[c_pop_pos[2][1][0]+c_pop_size/2.,c_pop_pos[2][1][1]+c_pop_size/2.],r'L4I','w' if analysis_params.bw else 'k',fontdict1)\n    \n        put_text(ax,[c_pop_pos[3][0][0]+c_pop_size/2.,c_pop_pos[3][0][1]+c_pop_size/2.],r'L23E','w' if analysis_params.bw else 'k',fontdict1)\n        put_text(ax,[c_pop_pos[3][1][0]+c_pop_size/2.,c_pop_pos[3][1][1]+c_pop_size/2.],r'L23I','w' if analysis_params.bw else 'k',fontdict1)\n        \n        put_text(ax,[c_pop_pos[-1][0][0],\n                 c_pop_pos[-1][0][1]+c_pop_size+1.7*axon_cell_sep + 0.01],\n                 r'cortico-cortical input','k',fontdict2)\n\n        put_text(ax,[legend_x[1]+axon_y_dist,legend_y[1]],r'excitatory','k',fontdict3)\n        put_text(ax,[legend_x[1]+axon_y_dist,legend_y[0]],r'inhibitory','k',fontdict3)\n\n        ##################################################\n        ## layer names\n\n        put_text(ax,[0.2*c_pop_pos[0][0][0],c_pop_pos[0][1][1]+c_pop_size/2.],r'L6','k',fontdict1)\n        put_text(ax,[0.2*c_pop_pos[1][0][0],c_pop_pos[1][1][1]+c_pop_size/2.],r'L5','k',fontdict1)\n        put_text(ax,[0.2*c_pop_pos[2][0][0],c_pop_pos[2][1][1]+c_pop_size/2.],r'L4','k',fontdict1)\n        put_text(ax,[0.2*c_pop_pos[3][0][0],c_pop_pos[3][1][1]+c_pop_size/2.],r'L2/3','k',fontdict1)\n        \n                \n    if highlight is not None:\n        ids = name_to_id_mapping[highlight]\n        fontdict1['fontsize']=4\n        put_text(ax,[c_pop_pos[ids[0]][ids[1]][0]+c_pop_size/2.,c_pop_pos[ids[0]][ids[1]][1]+c_pop_size/2.],highlight,'k',fontdict1)\n\n    ax.xaxis.set_ticks([])\n    ax.yaxis.set_ticks([])\n    ax.axis(ax.axis('equal'))\n    \n    return ax", "response": "This function creates a sketch of the cortex layers in a network."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the population of the neurons of the current object.", "response": "def plot_population(ax,\n                    params,\n                    aspect='tight',\n                    isometricangle=0,\n                    plot_somas = True, plot_morphos = False,\n                    num_unitsE = 1, num_unitsI=1,\n                    clip_dendrites=False,\n                    main_pops=True, \n                    Y = None,\n                    big=True,\n                    title='cell positions',\n                    rasterized=True):\n    '''\n    Plot the geometry of the column model, optionally with somatic locations\n    and optionally with reconstructed neurons\n    \n    kwargs:\n    ::\n        ax : matplotlib.axes.AxesSubplot\n        aspect : str\n            matplotlib.axis argument\n        isometricangle : float\n            pseudo-3d view angle\n        plot_somas : bool\n            plot soma locations\n        plot_morphos : bool\n            plot full morphologies\n        num_unitsE : int\n            number of excitatory morphos plotted per population\n        num_unitsI : int\n            number of inhibitory morphos plotted per population\n        clip_dendrites : bool\n            draw dendrites outside of axis\n        mainpops : bool\n            if True, plot only main pops, e.g. b23 and nb23 as L23I\n        Y : None, or string\n            if not None, plot only soma locations of Y\n        big : bool\n            if False: leave out labels and reduce marker size\n    \n    return:\n    ::\n        axis : list\n            the plt.axis() corresponding to input aspect\n    '''\n\n    name_to_id_mapping={'L6E':(3,0),\n                        'L6I':(3,1),\n                        'L5E':(2,0),\n                        'L5I':(2,1),\n                        'L4E':(1,0),\n                        'L4I':(1,1),\n                        'L23E':(0,0),\n                        'L23I':(0,1)\n    } \n    \n    \n    # DRAW OUTLINE OF POPULATIONS \n    \n    ax.xaxis.set_ticks([])\n    ax.yaxis.set_ticks([])\n\n    #contact points\n    if big:\n        ax.plot(params.electrodeParams['x'],\n            params.electrodeParams['z'],\n            '.', marker='o', markersize=2, color='k', zorder=0)\n    else: \n        ax.plot(params.electrodeParams['x'],\n            params.electrodeParams['z'],\n            '.', marker='o', markersize=0.5, color='k', zorder=0)\n\n    #outline of electrode       \n    x_0 = params.electrodeParams['r_z'][1, 1:-1]\n    z_0 = params.electrodeParams['r_z'][0, 1:-1]\n    x = np.r_[x_0[-1], x_0[::-1], -x_0[1:], -x_0[-1]]\n    z = np.r_[100, z_0[::-1], z_0[1:], 100]\n    ax.fill(x, z, fc='w', lw=0.1, ec='k', zorder=-0.1, clip_on=False)\n\n    #outline of populations:\n    #fetch the population radius from some population\n    r = params.populationParams['p23']['radius']\n\n    theta0 = np.linspace(0, np.pi, 20)\n    theta1 = np.linspace(np.pi, 2*np.pi, 20)\n    \n    zpos = np.r_[params.layerBoundaries[:, 0],\n                 params.layerBoundaries[-1, 1]]\n    \n    layers = ['L1', 'L2/3', 'L4', 'L5', 'L6']\n    for i, z in enumerate(params.layerBoundaries.mean(axis=1)):\n        if big:\n            ax.text(r, z, ' %s' % layers[i], va='center', ha='left')\n\n    for i, zval in enumerate(zpos):\n        if i == 0:\n            ax.plot(r*np.cos(theta0),\n                    r*np.sin(theta0)*np.sin(isometricangle)+zval,\n                    color='k', zorder=-r, clip_on=False)\n            ax.plot(r*np.cos(theta1),\n                    r*np.sin(theta1)*np.sin(isometricangle)+zval,\n                    color='k', zorder=r, clip_on=False)\n        else:\n            ax.plot(r*np.cos(theta0),\n                    r*np.sin(theta0)*np.sin(isometricangle)+zval,\n                    color='gray', zorder=-r, clip_on=False)\n            ax.plot(r*np.cos(theta1),\n                    r*np.sin(theta1)*np.sin(isometricangle)+zval,\n                    color='k', zorder=r, clip_on=False)\n    \n    ax.plot([-r, -r], [zpos[0], zpos[-1]], 'k', zorder=0, clip_on=False)\n    ax.plot([r, r], [zpos[0], zpos[-1]], 'k', zorder=0, clip_on=False)\n    \n    if big:\n        #plot a horizontal radius scalebar\n        ax.plot([0, r], [z_0.min()]*2, 'k', lw=1, zorder=0, clip_on=False)\n        ax.text(r / 2., z_0.min()-100, '$r$ = %i $\\mu$m' % int(r), ha='center')\n    \n        #plot a vertical depth scalebar\n        ax.plot([-r]*2, [z_0.min()+50, z_0.min()-50],\n                'k', lw=1, zorder=0, clip_on=False)\n        ax.text(-r, z_0.min(), r'100 $\\mu$m', va='center', ha='right')\n    \n    ax.set_yticks([])\n    ax.set_yticklabels([])\n    \n    #fake ticks:\n    if big:\n        for pos in zpos:\n            ax.text(-r, pos, '$z$=%i-' % int(pos), ha='right', va='center')\n        ax.set_title(title, va='bottom')\n   \n    axis = ax.axis(ax.axis(aspect))\n\n\n    def plot_pop_scatter(somapos, marker, colors, i):\n        #scatter plot setting appropriate zorder for each datapoint by binning\n        pitch = 100\n        for lower in np.arange(-600, 601, pitch):\n            upper = lower + pitch\n            inds = (somapos[:, 1] >= lower) & (somapos[:, 1] < upper)\n            if np.any(inds):\n                if big:\n                    ax.scatter(somapos[inds, 0],\n                               somapos[inds, 2] - somapos[inds, 1] * np.sin(isometricangle),\n                               s=10, facecolors=colors[i], edgecolors='gray', linewidths=0.1, zorder=lower,\n                               marker = marker, clip_on=False, rasterized=rasterized)\n                else:\n                    ax.scatter(somapos[inds, 0],\n                               somapos[inds, 2] - somapos[inds, 1] * np.sin(isometricangle),\n                               s=3, facecolors=colors[i], edgecolors='gray', linewidths=0.1, zorder=lower,\n                               marker = marker, clip_on=False, rasterized=rasterized)\n                    \n\n\n\n    # DRAW UNITS\n    pop = zip(*params.mapping_Yy)[0]\n    \n    #plot a symbol in each location with a unit \n    if plot_somas:\n        if main_pops:\n            colors = phlp.get_colors(np.unique(pop).size)\n\n            #restructure \n            E, I = zip(*params.y_in_Y)\n            pops_ = []\n\n            if Y is None:\n                for i in xrange(len(E)):\n                    pops_.append(E[i])\n                    pops_.append(I[i])\n            else:\n                ids = name_to_id_mapping[Y]\n                if ids[1] == 0:\n                    pops_.append(E[ids[0]])\n                if ids[1] == 1:\n                    pops_.append(I[ids[0]])\n\n            for i, pops in enumerate(pops_):\n                layer = np.unique(pop)[i]\n\n                if layer.rfind('p') >= 0 or layer.rfind('E') >= 0:\n                    marker = '^'\n                elif layer.rfind('b') >= 0 or layer.rfind('I') >= 0:\n                    marker = '*'\n                elif layer.rfind('ss') >= 0:\n                    marker = 'o'\n                else:\n                    raise Exception\n                \n                #get the somapos\n                somapos = []\n                for j, lname in enumerate(pops):\n                    fname = glob.glob(os.path.join(params.populations_path, '%s*somapos.gdf' % lname))[0]\n                    if j == 0:\n                        somapos = np.loadtxt(fname).reshape((-1, 3))\n                    else:\n                        somapos = np.r_['0, 2', somapos, np.loadtxt(fname).reshape((-1, 3))]\n                somapos = somapos[::5, :]\n                if Y is None:\n                    plot_pop_scatter(somapos, marker, colors, i)\n                else:\n                    plot_pop_scatter(somapos, marker, colors, ids[0]*2+ids[1])\n            \n        else:\n            colors = phlp.get_colors(len(pop))\n            i = 0\n            for layer, _, _, _ in params.y_zip_list:\n                \n                #assign symbol\n                if layer.rfind('p') >= 0 or layer.rfind('E') >= 0:\n                    marker = '^'\n                elif layer.rfind('b') >= 0 or layer.rfind('I') >= 0:\n                    marker = '*'\n                elif layer.rfind('ss') >= 0:\n                    marker = 'x'\n                else:\n                    raise Exception\n                    \n                #get the somapos\n                fname = glob.glob(os.path.join(params.populations_path, '%s*somapos.gdf' % layer))[0]\n                somapos = np.loadtxt(fname).reshape((-1, 3))\n            \n                plot_pop_scatter(somapos, marker, colors, i)\n                \n                i += 1\n    \n\n    #plot morphologies in their appropriate locations\n    if plot_morphos:\n        if main_pops:\n            colors = phlp.get_colors(np.unique(pop).size)\n\n            #restructure \n            E, I = zip(*params.y_in_Y)\n            pops_ = []\n            for i in xrange(len(E)):\n                pops_.append(E[i])\n                pops_.append(I[i])\n\n            for i, pops in enumerate(pops_):\n                layer = np.unique(pop)[i]\n                \n                #get the somapos and morphos\n                somapos = []\n                for j, lname in enumerate(pops):\n                    fname = glob.glob(os.path.join(params.populations_path, '%s*somapos.gdf' % lname))[0]\n                    if j == 0:\n                        somapos = np.loadtxt(fname).reshape((-1, 3))\n                    else:\n                        somapos = np.r_['0, 2', somapos, np.loadtxt(fname).reshape((-1, 3))]\n\n\n                #add num_units morphologies per population with a random z-rotation\n                if layer.rfind('p') >= 0 or layer.rfind('ss') >= 0 or layer.rfind('E') >= 0:\n                    num_units = num_unitsE\n                else:\n                    num_units = num_unitsI            \n                \n                if num_units > somapos.shape[0]:\n                    n = somapos.shape[0]\n                else:\n                    n = num_units\n\n                #find some morphos for this population:\n                morphos = []\n                for fname in params.m_y:\n                    if fname.rfind(layer) >= 0:\n                        morphos.append(fname)\n                                \n                #plot some units\n                for j in range(n):\n                    cell = LFPy.Cell(morphology=os.path.join(params.PATH_m_y,\n                                            np.random.permutation(morphos)[0]),\n                                     nsegs_method='lambda_f',\n                                     lambda_f=10,\n                                     extracellular=False\n                                    )\n                    cell.set_pos(somapos[j, 0], somapos[j, 1], somapos[j, 2])\n                    cell.set_rotation(z=np.random.rand()*np.pi*2)\n    \n                    #set up a polycollection\n                    zips = []\n                    for x, z in cell.get_idx_polygons():\n                        zips.append(zip(x, z-somapos[j, 1] * np.sin(isometricangle)))\n                    \n                    polycol = PolyCollection(zips,\n                                             edgecolors=colors[i],\n                                             facecolors=colors[i],\n                                             linewidths=(0.5),\n                                             zorder=somapos[j, 1],\n                                             clip_on=clip_dendrites,\n                                             rasterized=rasterized)\n    \n                    ax.add_collection(polycol)\n                \n                i += 1\n\n\n        else:\n            colors = phlp.get_colors(len(pop))\n            i = 0\n            for layer, morpho, depth, size in params.y_zip_list:\n    \n    \n                #get the somapos\n                fname = glob.glob(os.path.join(params.populations_path, '%s*somapos.gdf' % layer))[0]\n                somapos = np.loadtxt(fname).reshape((-1, 3))\n    \n                \n                #add num_units morphologies per population with a random z-rotation\n                if layer.rfind('p') >= 0 or layer.rfind('ss') >= 0 or layer.rfind('E') >= 0:\n                    num_units = num_unitsE\n                else:\n                    num_units = num_unitsI            \n                \n                if num_units > somapos.shape[0]:\n                    n = somapos.shape[0]\n                else:\n                    n = num_units\n                \n                #plot some units\n                for j in range(n):\n                    cell = LFPy.Cell(morphology=os.path.join(params.PATH_m_y, morpho),\n                                     nsegs_method='lambda_f',\n                                     lambda_f=10,\n                                     extracellular=False\n                                    )\n                    cell.set_pos(somapos[j, 0], somapos[j, 1], somapos[j, 2])\n                    cell.set_rotation(z=np.random.rand()*np.pi*2)\n    \n                    #set up a polycollection\n                    zips = []\n                    for x, z in cell.get_idx_polygons():\n                        zips.append(zip(x, z-somapos[j, 1] * np.sin(isometricangle)))\n                    \n                    polycol = PolyCollection(zips,\n                                             edgecolors=colors[i],\n                                             facecolors=colors[i],\n                                             linewidths=(0.5),\n                                             zorder=somapos[j, 1],\n                                             clip_on=clip_dendrites,\n                                             rasterized=rasterized)\n    \n                    ax.add_collection(polycol)\n                \n                i += 1\n    \n    return axis"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_signal_sum(ax, params, fname='LFPsum.h5', unit='mV', scaling_factor=1.,\n                    ylabels=True, scalebar=True, vlimround=None,\n                    T=[800, 1000], ylim=[-1500, 0], color='k', fancy=False,\n                    label='', transient=200, clip_on=False, rasterized=True,\n                    **kwargs):\n    '''\n    on axes plot the summed LFP contributions\n    \n    args:\n    ::\n        \n        ax : matplotlib.axes.AxesSubplot object\n        fname : str/np.ndarray, path to h5 file or ndim=2 numpy.ndarray \n        unit : str, scalebar unit\n        scaling_factor : float, scaling factor (e.g. to scale 10% data set up)\n        ylabels : bool, show labels on y-axis\n        scalebar : bool, show scalebar in plot\n        vlimround : None/float, override autoscaling of data and scalebar\n        T : list, [tstart, tstop], which timeinterval\n        ylim : list of floats, see plt.gca().set_ylim\n        color : str/colorspec tuple, color of shown lines\n        fancy : bool,\n        label : str, line labels\n        rasterized : bool, rasterize line plots if true\n        kwargs : additional keyword arguments passed to ax.plot()\n    \n    \n    returns:\n    ::\n        \n        vlimround : float, scalebar scaling factor, i.e., to match up plots\n    \n    '''\n\n    if type(fname) == str and os.path.isfile(fname):\n        f = h5py.File(fname)\n        #load data\n        data = f['data'].value\n            \n        tvec = np.arange(data.shape[1]) * 1000. / f['srate'].value    \n\n        #for mean subtraction\n        datameanaxis1 = f['data'].value[:, tvec >= transient].mean(axis=1)\n        \n        #close dataset\n        f.close()\n    elif type(fname) == np.ndarray and fname.ndim==2:\n        data = fname\n        tvec = np.arange(data.shape[1]) * params.dt_output\n        datameanaxis1 = data[:, tvec >= transient].mean(axis=1)\n    else:\n        raise Exception, 'type(fname)={} not str or numpy.ndarray'.format(type(fname))\n\n    # slice\n    slica = (tvec <= T[1]) & (tvec >= T[0])\n    data = data[:,slica]\n    \n    #subtract mean in each channel\n    #dataT = data.T - data.mean(axis=1)\n    dataT = data.T - datameanaxis1\n    data = dataT.T\n\n    # normalize\n    data = data*scaling_factor\n    \n    zvec = np.r_[params.electrodeParams['z']]\n    zvec = np.r_[zvec, zvec[-1] + np.diff(zvec)[-1]]\n    vlim = abs(data).max()\n    if vlimround is None:\n        vlimround = 2.**np.round(np.log2(vlim))\n    else:\n        pass\n    yticklabels=[]\n    yticks = []\n    \n    if fancy:\n        colors=phlp.get_colors(data.shape[0])\n    else:\n        colors = [color]*data.shape[0]\n    \n    for i, z in enumerate(params.electrodeParams['z']):\n        if i == 0:\n            ax.plot(tvec[slica], data[i] * 100 / vlimround + z,\n                    color=colors[i], rasterized=rasterized, label=label,\n                    clip_on=clip_on, **kwargs)\n        else: \n            ax.plot(tvec[slica], data[i] * 100 / vlimround + z,\n                    color=colors[i], rasterized=rasterized, clip_on=clip_on,\n                    **kwargs)\n        yticklabels.append('ch. %i' % (i+1))\n        yticks.append(z)\n     \n    if scalebar:\n        ax.plot([tvec[slica][-1], tvec[slica][-1]],\n                [-1300, -1400], lw=2, color='k', clip_on=False)\n        ax.text(tvec[slica][-1]+np.diff(T)*0.02, -1350,\n                r'%g %s' % (vlimround, unit),\n                color='k', rotation='vertical',\n                va='center')\n\n    ax.axis(ax.axis('tight'))\n    ax.yaxis.set_ticks(yticks)\n    if ylabels:\n        ax.yaxis.set_ticklabels(yticklabels)\n    else:\n        ax.yaxis.set_ticklabels([])\n\n    for loc, spine in ax.spines.iteritems():\n        if loc in ['right', 'top']:\n            spine.set_color('none')            \n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n    ax.set_xlabel(r'$t$ (ms)', labelpad=0.1)\n    ax.set_ylim(ylim)\n    \n    return vlimround", "response": "Plots the signal sum of the LFP contributions of the object with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake an imshow of the intranetwork connectivity", "response": "def plotConnectivity(ax):\n    '''make an imshow of the intranetwork connectivity'''\n    im = ax.pcolor(params.C_YX, cmap='hot')\n    ax.axis(ax.axis('tight'))\n    ax.invert_yaxis()\n    ax.xaxis.set_ticks_position('top')\n    ax.set_xticks(np.arange(9)+0.5)\n    ax.set_yticks(np.arange(8)+0.5)\n    ax.set_xticklabels(params.X, rotation=270)\n    ax.set_yticklabels(params.Y, )\n    #ax.set_ylabel(r'to ($Y$)', ha='center')\n    #ax.set_xlabel(r'from ($X$)', va='center')\n    ax.xaxis.set_label_position('top')\n\n    rect = np.array(ax.get_position().bounds)\n    rect[0] += rect[2] + 0.01\n    rect[2] = 0.01\n    fig = plt.gcf()\n    cax = fig.add_axes(rect)\n\n    cbar = plt.colorbar(im, cax=cax)\n    cbar.set_label('connectivity', ha='center')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getMeanInpCurrents(params, numunits=100,\n                       filepattern=os.path.join('simulation_output_default',\n                                                'population_input_spikes*')):\n    '''return a dict with the per population mean and std synaptic current,\n    averaging over numcells recorded units from each population in the\n    network\n    \n    Returned currents are in unit of nA.\n    \n    '''\n    #convolution kernels\n    x = np.arange(100) * params.dt\n    kernel = np.exp(-x / params.model_params['tau_syn_ex'])\n\n\n    #number of external inputs:\n    K_bg = np.array(sum(params.K_bg, []))\n\n    #compensate for DC CC connections if we're using that\n    iDC =  K_bg * params.dc_amplitude * 1E-3 # unit ????\n    \n    data = {}\n    \n    #loop over network-populations\n    for i, Y in enumerate(params.Y):\n        if i % SIZE == RANK:\n            #file to open\n            fname = glob.glob(filepattern+'*' + Y + '*')[0]\n            print fname\n            #read in read data and assess units, up to numunits\n            rawdata = np.array(helpers.read_gdf(fname))\n            units = np.unique(rawdata[:, 0])\n            if numunits > units.size:\n                numcells = units.size\n            else:\n                numcells = numunits\n            units = units[:numcells]\n            \n            #churn through data and extract the input currents per cell\n            for j, unit in enumerate(units):\n                slc = rawdata[:, 0] == unit\n                #just the spikes:\n                if j == 0:\n                    dataslc = rawdata[slc, 2:]\n                else:\n                    dataslc = np.r_['0,3', dataslc, rawdata[slc, 2:]]\n            \n            #fix the datatype, it may be object\n            dataslc = dataslc.astype(float)\n                   \n            #fill in data-structure\n            data.update({\n                Y : {\n                    'E' : np.convolve(dataslc[:, :, 0].mean(axis=0),\n                                      kernel, 'same')*1E-3 + float(iDC[i]),\n                    'I' : np.convolve(dataslc[:, :, 1].mean(axis=0),\n                                      kernel, 'same')*1E-3,\n                    'tvec' : rawdata[slc, 1],\n                    'numunits' : numunits,\n                }\n            })\n    \n    \n    data = COMM.allgather(data)\n    \n    return {k: v for d in data for k, v in d.items()}", "response": "get the mean and std synaptic currents for each population in the nA network"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting mean and std synaptic current from each population in the nA", "response": "def getMeanVoltages(params, numunits=100,\n                   filepattern=os.path.join('simulation_output_default',\n                                            'voltages')):\n    '''return a dict with the per population mean and std synaptic current,\n    averaging over numcells recorded units from each population in the\n    network\n    \n    Returned currents are in unit of nA.\n    \n    '''    \n    data = {}\n    \n    #loop over network-populations\n    for i, Y in enumerate(params.Y):\n        if i % SIZE == RANK:\n            #read in read data and assess units, up to numunits\n            fname = glob.glob(filepattern+'*' + Y + '*')[0]\n            print fname\n            rawdata = np.array(helpers.read_gdf(fname))\n            units = np.unique(rawdata[:, 0])\n            if numunits > units.size:\n                numcells = units.size\n            else:\n                numcells = numunits\n            units = units[:numcells]\n            \n            #churn through data and extract the per cell voltages\n            for j, unit in enumerate(units):\n                slc = rawdata[:, 0] == unit\n                #just the spikes:\n                if j == 0:\n                    dataslc = rawdata[slc, 2:]\n                else:\n                    dataslc = np.r_['0,3', dataslc, rawdata[slc, 2:]]\n            \n            #fix the datatype, it may be object\n            dataslc = dataslc.astype(float)\n                   \n            #fill in data-structure\n            data.update({\n                Y : {\n                    'data' : dataslc[:, :, 0].mean(axis=0),\n                    'std' : dataslc[:, :, 0].std(axis=0),\n                    'sample' : dataslc[0, :, 0],\n                    'tvec' : rawdata[slc, 1],\n                    'numunits' : numunits,\n                }\n            })\n            \n    \n    data = COMM.allgather(data)\n    \n    return {k: v for d in data for k, v in d.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the signal summed CSD contributions on colorplot and as background plot", "response": "def plot_signal_sum_colorplot(ax, params, fname='LFPsum.h5', unit='mV', N=1, ylabels = True,\n                              T=[800, 1000], ylim=[-1500, 0], fancy=False, colorbar=True,\n                              cmap='spectral_r', absmax=None, transient=200, rasterized=True):\n    '''\n    on colorplot and as background plot the summed CSD contributions\n    \n    args:\n    ::\n        ax : matplotlib.axes.AxesSubplot object\n        T : list, [tstart, tstop], which timeinterval\n        ylims : list, set range of yaxis to scale with other plots\n        fancy : bool, \n        N : integer, set to number of LFP generators in order to get the normalized signal\n    '''\n    f = h5py.File(fname)\n    data = f['data'].value\n    tvec = np.arange(data.shape[1]) * 1000. / f['srate'].value\n    \n    #for mean subtraction\n    datameanaxis1 = f['data'].value[:, tvec >= transient].mean(axis=1)\n    \n    # slice\n    slica = (tvec <= T[1]) & (tvec >= T[0])\n    data = data[:,slica]\n\n    # subtract mean\n    #dataT = data.T - data.mean(axis=1)\n    dataT = data.T - datameanaxis1\n    data = dataT.T\n\n    # normalize\n    data = data/N\n    zvec = params.electrodeParams['z']\n    \n    if fancy:\n        colors = phlp.get_colors(data.shape[0])\n    else:\n        colors = ['k']*data.shape[0]\n    \n    if absmax == None:\n        absmax=abs(np.array([data.max(), data.min()])).max()  \n    im = ax.pcolormesh(tvec[slica], np.r_[zvec, zvec[-1] + np.diff(zvec)[-1]] + 50, data,\n                           rasterized=rasterized, vmax=absmax, vmin=-absmax, cmap=cmap)\n    ax.set_yticks(params.electrodeParams['z'])\n    if ylabels:\n        yticklabels = ['ch. %i' %(i+1) for i in np.arange(len(params.electrodeParams['z']))]\n        ax.set_yticklabels(yticklabels)\n    else:\n        ax.set_yticklabels([])\n\n    if colorbar:\n        #colorbar\n        divider=make_axes_locatable(ax)\n        cax=divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n        cbar=plt.colorbar(im, cax=cax)\n        cbar.set_label(unit,labelpad=0.1)\n        \n    plt.axis('tight')\n\n    ax.set_ylim(ylim)\n\n    \n    f.close()\n    \n    return im"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_signal_power(params, fname, transient=200, Df=None, mlab=True, NFFT=1000,\n                      noverlap=0, window=plt.mlab.window_hanning):\n    '''\n    calculates power spectrum of sum signal for all channels\n\n    '''\n\n\n    if type(fname) is str and os.path.isfile(fname):\n        #open file\n        f = h5py.File(fname)\n        data = f['data'].value\n        srate = f['srate'].value \n        tvec = np.arange(data.shape[1]) * 1000. / srate\n        f.close()\n    elif type(fname) is np.ndarray:\n        data = fname\n        srate = 1000.\n        tvec = np.arange(data.shape[1]) * 1000. / srate\n    else:\n        raise Exception, '{} not a file or array'.format(fname)\n    \n    # slice\n    slica = (tvec >= transient)\n    data = data[:,slica]\n\n    # subtract mean\n    dataT = data.T - data.mean(axis=1)\n    data = dataT.T\n    \n    #extract PSD\n    PSD=[]\n    for i in np.arange(len(params.electrodeParams['z'])):\n        if mlab:\n            Pxx, freqs=plt.mlab.psd(data[i], NFFT=NFFT,\n                                    Fs=srate, noverlap=noverlap, window=window)\n        else:\n            [freqs, Pxx] = helpers.powerspec([data[i,]], tbin= 1.,\n                                        Df=Df, pointProcess=False)\n            mask = np.where(freqs >= 0.)\n            freqs = freqs[mask]\n            Pxx = Pxx.flatten()\n            Pxx = Pxx[mask]\n            Pxx = Pxx/tvec[tvec >= transient].size**2\n        PSD +=[Pxx.flatten()]\n        \n    PSD=np.array(PSD)\n\n    return freqs, PSD", "response": "Calculates power spectrum of sum signal for all channels in the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_signal_power_colorplot(ax, params, fname, transient=200, Df=None,\n                                mlab=True, NFFT=1000,\n                                window=plt.mlab.window_hanning,\n                                noverlap=0,\n                                cmap = plt.cm.get_cmap('jet', 21),\n                                vmin=None,\n                                vmax=None):\n    '''\n    on axes plot the LFP power spectral density  \n    The whole signal duration is used.\n    args:\n    ::\n        ax : matplotlib.axes.AxesSubplot object\n        fancy : bool, \n    '''\n  \n    zvec = np.r_[params.electrodeParams['z']]\n    zvec = np.r_[zvec, zvec[-1] + np.diff(zvec)[-1]]\n    \n    #labels\n    yticklabels=[]\n    yticks = []\n\n    for i, kk in enumerate(params.electrodeParams['z']):\n        yticklabels.append('ch. %i' % (i+1))\n        yticks.append(kk)\n\n    \n    freqs, PSD = calc_signal_power(params, fname=fname, transient=transient,Df=Df,\n                                   mlab=mlab, NFFT=NFFT,\n                                   window=window, noverlap=noverlap)\n\n    #plot only above 1 Hz\n    inds = freqs >= 1  # frequencies greater than 4 Hz  \n    im = ax.pcolormesh(freqs[inds], zvec+50, PSD[:, inds],\n                       rasterized=True, norm=LogNorm(),\n                       vmin=vmin,vmax=vmax,\n                       cmap=cmap, )\n    \n    ax.yaxis.set_ticks(yticks)\n    ax.yaxis.set_ticklabels(yticklabels)\n    ax.semilogx()\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n    ax.set_xlabel(r'$f$ (Hz)', labelpad=0.1)\n    ax.axis(ax.axis('tight'))\n\n\n    return im", "response": "Function to plot LFP power spectral density of signal duration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plotPowers(ax, params, popkeys, dataset, linestyles, linewidths, transient=200, SCALING_POSTFIX='', markerstyles=None):\n    '''plot power (variance) as function of depth for total and separate\n    contributors\n\n    Plot variance of sum signal\n    '''\n    \n    colors = phlp.get_colors(len(popkeys))\n    \n    depth = params.electrodeParams['z']\n    zpos = np.r_[params.layerBoundaries[:, 0],\n                 params.layerBoundaries[-1, 1]]\n\n    for i, layer in enumerate(popkeys):\n        f = h5py.File(os.path.join(params.populations_path,\n                                   '%s_population_%s' % (layer, dataset) + SCALING_POSTFIX + '.h5' ))\n        ax.semilogx(f['data'].value[:, transient:].var(axis=1), depth,\n                 color=colors[i],\n                 ls=linestyles[i],\n                 lw=linewidths[i],\n                 marker=None if markerstyles is None else markerstyles[i],\n                 markersize=2.5,\n                 markerfacecolor=colors[i],\n                 markeredgecolor=colors[i],\n                 label=layer,\n                 clip_on=True\n                 )\n    \n        f.close()\n    \n    f = h5py.File(os.path.join(params.savefolder, '%ssum' % dataset + SCALING_POSTFIX + '.h5' ))\n    ax.plot(f['data'].value[:, transient:].var(axis=1), depth,\n                 'k', label='SUM', lw=1.25, clip_on=False)\n    \n    f.close()\n\n    ax.set_yticks(zpos)\n    ax.set_yticklabels([])\n    #ax.set_xscale('log')\n    try: # numticks arg only exists for latest matplotlib version\n        ax.xaxis.set_major_locator(plt.LogLocator(base=10,\n                                    subs=np.linspace(-10, 10, 2), numticks=6))\n    except:\n        ax.xaxis.set_major_locator(plt.LogLocator(base=10,\n                                    subs=np.linspace(-10, 10, 2)))\n    ax.xaxis.set_minor_locator(plt.LogLocator(base=10, subs=[1.]))\n    ax.axis('tight')", "response": "plot power for total and separate signal"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plotting_correlation(params, x0, x1, ax, lag=20., scaling=None, normalize=True,\n                         color='k', unit=r'$cc=%.3f$' , title='firing_rate vs LFP',\n                         scalebar=True, **kwargs):\n    ''' mls\n    on axes plot the correlation between x0 and x1\n    \n    args:\n    ::\n        x0 : first dataset\n        x1 : second dataset - the LFP usually here\n        ax : matplotlib.axes.AxesSubplot object\n        title : text to be used as current axis object title\n        normalize : if True, signals are z-scored before applying np.correlate\n        unit : unit for scalebar\n    '''\n    zvec = np.r_[params.electrodeParams['z']]\n    zvec = np.r_[zvec, zvec[-1] + np.diff(zvec)[-1]]\n    \n    xcorr_all=np.zeros((params.electrodeParams['z'].size, x0.shape[-1]))\n    \n    if normalize:\n        for i, z in enumerate(params.electrodeParams['z']):\n            if x0.ndim == 1:\n                x2 = x1[i, ]\n                xcorr1 = np.correlate(helpers.normalize(x0),\n                                      helpers.normalize(x2), 'same') / x0.size\n            elif x0.ndim == 2:\n                xcorr1 = np.correlate(helpers.normalize(x0[i, ]),\n                                      helpers.normalize(x1[i, ]), 'same') / x0.shape[-1]\n            \n            xcorr_all[i,:]=xcorr1\n    else:\n        for i, z in enumerate(params.electrodeParams['z']):\n            if x0.ndim == 1:\n                x2 = x1[i, ]\n                xcorr1 = np.correlate(x0,x2, 'same')\n            elif x0.ndim == 2:\n                xcorr1 = np.correlate(x0[i, ],x1[i, ], 'same')\n                \n            xcorr_all[i,:]=xcorr1\n    \n\n    # Find limits for the plot\n    if scaling is None:\n        vlim = abs(xcorr_all).max()\n        vlimround = 2.**np.round(np.log2(vlim))\n    else:\n        vlimround = scaling\n    \n    yticklabels=[]\n    yticks = []\n    \n    #temporal slicing\n    lagvector = np.arange(-lag, lag+1).astype(int)\n    inds = lagvector + x0.shape[-1] / 2\n    \n    \n    for i, z in enumerate(params.electrodeParams['z']):\n        ax.plot(lagvector, xcorr_all[i,inds[::-1]] * 100. / vlimround + z, 'k',\n                clip_on=True, rasterized=False, color=color, **kwargs)\n        yticklabels.append('ch. %i' %(i+1))\n        yticks.append(z)    \n\n    phlp.remove_axis_junk(ax)\n    ax.set_title(title, va='center')\n    ax.set_xlabel(r'$\\tau$ (ms)', labelpad=0.1)\n\n    ax.set_xlim(-lag, lag)\n    ax.set_ylim(z-100, 100)\n    \n    axis = ax.axis()\n    ax.vlines(0, axis[2], axis[3], 'k' if analysis_params.bw else 'k', 'dotted', lw=0.25)\n\n    ax.yaxis.set_ticks(yticks)\n    ax.yaxis.set_ticklabels(yticklabels)\n\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n\n    ## Create a scaling bar\n    if scalebar:\n        ax.plot([lag, lag],\n            [-1500, -1400], lw=2, color='k', clip_on=False)\n        ax.text(lag*1.04, -1450, unit % vlimround,\n                    rotation='vertical', va='center')\n    \n    return xcorr_all[:, inds[::-1]], vlimround", "response": "Function that plots the correlation between two datasets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle GET requests If the path is '/', a site which extracts the token will be generated. This will redirect the user to the '/sucess' page, which shows a success message. :returns: None :rtype: None :raises: None", "response": "def do_GET(self, ):\n        \"\"\"Handle GET requests\n\n        If the path is '/', a site which extracts the token will be generated.\n        This will redirect the user to the '/sucess' page, which shows\n        a success message.\n\n        :returns: None\n        :rtype: None\n        :raises: None\n        \"\"\"\n        urld = {self.extract_site_url: 'extract_token_site.html',\n                self.success_site_url: 'success_site.html'}\n        site = urld.get(self.path)\n        if not site:\n            log.debug(\"Requesting false url on login server.\")\n            self.send_error(404)\n            return\n        log.debug('Requesting the login server. Responding with %s.', urld)\n        self._set_headers()\n        self._write_html(site)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _write_html(self, filename):\n        datapath = os.path.join('html', filename)\n        sitepath = pkg_resources.resource_filename('pytwitcherapi', datapath)\n        with open(sitepath, 'r') as f:\n            html = f.read()\n        self.wfile.write(html.encode('utf-8'))", "response": "Read the html site with the given filename and write it to self. wfile."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_POST(self, ):\n        log.debug('POST')\n        self._set_headers()\n        # convert the parameters back to the original fragment\n        # because we need to send the original uri to set_token\n        # url fragments will not show up in self.path though.\n        # thats why we make the hassle to send it as a post request.\n        # Note: oauth does not allow for http connections\n        # but twitch does, so we fake it\n        ruri = constants.REDIRECT_URI.replace('http://', 'https://')\n        self.server.set_token(ruri + self.path.replace('?', '#'))", "response": "Handle POST requests\n\n        When the user is redirected, this handler will respond with a website\n        which will send a post request with the url fragment as parameters.\n        This will get the parameters and store the original redirection\n        url and fragments in :data:`LoginServer.tokenurl`.\n\n        :returns: None\n        :rtype: None\n        :raises: None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_token(self, redirecturl):\n        log.debug('Setting the token on %s.' % self.session)\n        self.session.token_from_fragment(redirecturl)", "response": "Set the token on the session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a bearer token to the request uri headers and body.", "response": "def _add_bearer_token(self, *args, **kwargs):\n        \"\"\"Add a bearer token to the request uri, body or authorization header.\n\n        This is overwritten to change the headers slightly.\n        \"\"\"\n        s = super(TwitchOAuthClient, self)\n        uri, headers, body = s._add_bearer_token(*args, **kwargs)\n        authheader = headers.get('Authorization')\n        if authheader:\n            headers['Authorization'] = authheader.replace('Bearer', 'OAuth')\n        return uri, headers, body"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninstalling a Blended template from GitHub", "response": "def install_template(username, repo):\n    \"\"\"Installs a Blended template from GitHub\"\"\"\n    print(\"Installing template from \" + username + \"/\" + repo)\n\n    dpath = os.path.join(cwd, \"templates\")\n    getunzipped(username, repo, dpath)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_wp(filepath):\n\n    print(\"\\nBlended: Static Website Generator -\\n\")\n\n    checkConfig()\n    print(\"Importing from WordPress...\")\n\n    wp = parseXML(filepath)\n\n    wname = wp.rss.channel.title.cdata\n    wdesc = wp.rss.channel.description.cdata\n    wlan = wp.rss.channel.language.cdata\n    wurl = wp.rss.channel.link.cdata\n    aname = wp.rss.channel.wp_author.wp_author_display_name.cdata.strip()\n\n    createBlendedFolders()\n\n    # Populate the configuration file\n    createConfig(app_version=app_version, wname=wname,\n                 wdesc=wdesc, wlan=wlan, wurl=wurl, aname=aname)\n\n    for item in wp.rss.channel.item:\n        with open(os.path.join(cwd, \"content\", item.title.cdata.replace(\" \", \"_\") + \".html\"), 'w') as wfile:\n            wfile.write(item.content_encoded.cdata.strip())\n\n    print(\"\\nYour website has been imported from WordPress.\")", "response": "Imports A WordPress export and converts it to a Blended site"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_blogger(filepath):\n\n    print(\"\\nBlended: Static Website Generator -\\n\")\n\n    checkConfig()\n    print(\"Importing from Blogger...\")\n\n    blogger = parseXML(filepath)\n\n    wname = blogger.feed.title.cdata\n    aname = blogger.feed.author.name.cdata.strip()\n\n    createBlendedFolders()\n\n    # Populate the configuration file\n    createConfig(app_version=app_version, wname=wname, aname=aname)\n\n    for entry in blogger.feed.entry:\n        if \"post\" in entry.id.cdata:\n            with open(os.path.join(cwd, \"content\", entry.title.cdata.replace(\" \", \"_\") + \".html\"), 'w') as wfile:\n                wfile.write(entry.content.cdata.strip())\n\n    print(\"\\nYour website has been imported from Blogger.\")", "response": "Imports A Blogger export and converts it to a Blended site"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall a Blended plugin from GitHub", "response": "def install_plugin(username, repo):\n    \"\"\"Installs a Blended plugin from GitHub\"\"\"\n    print(\"Installing plugin from \" + username + \"/\" + repo)\n\n    pip.main(['install', '-U', \"git+git://github.com/\" +\n              username + \"/\" + repo + \".git\"])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init():\n\n    print(\"Blended: Static Website Generator -\\n\")\n\n    checkConfig()\n\n    if (sys.version_info > (3, 0)):\n        wname = input(\"Website Name: \")\n        wdesc = input(\"Website Description: \")\n        wlan = input(\"Website Language: \")\n        wlic = input(\"Website License: \")\n        aname = input(\"Author(s) Name(s): \")\n    else:\n        wname = raw_input(\"Website Name: \")\n        wdesc = raw_input(\"Website Description: \")\n        wlan = raw_input(\"Website Language: \")\n        wlic = raw_input(\"Website License: \")\n        aname = raw_input(\"Author(s) Name(s): \")\n\n    createBlendedFolders()\n\n    # Populate the configuration file\n    createConfig(app_version=app_version, wname=wname,\n                 wdesc=wdesc, wlic=wlic, wlan=wlan, aname=aname)\n\n    print(\"\\nThe required files for your website have been generated.\")", "response": "Initiates a new website"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef placeFiles(ftp, path):\n    for name in os.listdir(path):\n        if name != \"config.py\" and name != \"config.pyc\" and name != \"templates\" and name != \"content\":\n            localpath = os.path.join(path, name)\n            if os.path.isfile(localpath):\n                print(\"STOR\", name, localpath)\n                ftp.storbinary('STOR ' + name, open(localpath, 'rb'))\n            elif os.path.isdir(localpath):\n                print(\"MKD\", name)\n\n                try:\n                    ftp.mkd(name)\n\n                # ignore \"directory already exists\"\n                except error_perm as e:\n                    if not e.args[0].startswith('550'):\n                        raise\n\n                print(\"CWD\", name)\n                ftp.cwd(name)\n                placeFiles(ftp, localpath)\n                print(\"CWD\", \"..\")\n                ftp.cwd(\"..\")", "response": "Upload the built files to FTP"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nuploading the built website to FTP", "response": "def send_ftp(outdir):\n    \"\"\"Upload the built website to FTP\"\"\"\n    print(\"Uploading the files in the \" + outdir + \"/ directory!\\n\")\n\n    # Make sure there is actually a configuration file\n    config_file_dir = os.path.join(cwd, \"config.py\")\n    if not os.path.exists(config_file_dir):\n        sys.exit(\n            \"There dosen't seem to be a configuration file. Have you run the init command?\")\n    else:\n        sys.path.insert(0, cwd)\n        try:\n            from config import ftp_server, ftp_username, ftp_password, ftp_port, ftp_upload_path\n        except:\n            sys.exit(\n                \"The FTP settings could not be found. Maybe your config file is too old. Re-run 'blended init' to fix it.\")\n\n    server = ftp_server\n    username = ftp_username\n    password = ftp_password\n    port = ftp_port\n\n    ftp = FTP()\n    ftp.connect(server, port)\n    ftp.login(username, password)\n    filenameCV = os.path.join(cwd, outdir)\n\n    try:\n        ftp.cwd(ftp_upload_path)\n        placeFiles(ftp, filenameCV)\n    except:\n        ftp.quit()\n        sys.exit(\"Files not able to be uploaded! Are you sure the directory exists?\")\n\n    ftp.quit()\n\n    print(\"\\nFTP Done!\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_built(outdir):\n    print(\"Removing the built files!\")\n\n    # Remove the  build folder\n    build_dir = os.path.join(cwd, outdir)\n    if os.path.exists(build_dir):\n        shutil.rmtree(build_dir)", "response": "Removes all built files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zip_built(outdir):\n    print(\"Zipping the built files!\")\n\n    config_file_dir = os.path.join(cwd, \"config.py\")\n    if not os.path.exists(config_file_dir):\n        sys.exit(\n            \"There dosen't seem to be a configuration file. Have you run the init command?\")\n    else:\n        sys.path.insert(0, cwd)\n        try:\n            from config import website_name\n        except:\n            sys.exit(\n                \"Some of the configuration values could not be found! Maybe your config.py is too old. Run 'blended init' to fix.\")\n\n    # Remove the  build folder\n    build_dir = os.path.join(cwd, outdir)\n    zip_dir = os.path.join(cwd, website_name.replace(\" \", \"_\") + \"-build-\" +\n                           str(datetime.now().date()))\n    if os.path.exists(build_dir):\n        shutil.make_archive(zip_dir, 'zip', build_dir)\n    else:\n        print(\"The \" + outdir +\n              \"/ folder could not be found! Have you run 'blended build' yet?\")", "response": "Packages the build folder into a zip"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef purge():\n    print(\"Purging the Blended files!\")\n\n    # Remove the templates folder\n    templ_dir = os.path.join(cwd, \"templates\")\n    if os.path.exists(templ_dir):\n        shutil.rmtree(templ_dir)\n\n    # Remove the content folder\n    cont_dir = os.path.join(cwd, \"content\")\n    if os.path.exists(cont_dir):\n        shutil.rmtree(cont_dir)\n\n    # Remove the  build folder\n    build_dir = os.path.join(cwd, \"build\")\n    if os.path.exists(build_dir):\n        shutil.rmtree(build_dir)\n\n    # Remove config.py\n    config_file_dir = os.path.join(cwd, \"config.py\")\n    if os.path.exists(config_file_dir):\n        os.remove(config_file_dir)\n\n    # Remove config.pyc\n    config2_file_dir = os.path.join(cwd, \"config.pyc\")\n    if os.path.exists(config2_file_dir):\n        os.remove(config2_file_dir)\n\n    # Remove config.py\n    config3_file_dir = os.path.join(cwd, \"config.py.oldbak\")\n    if os.path.exists(config3_file_dir):\n        os.remove(config3_file_dir)", "response": "Removes all files generated by Blended"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the text file into a single page.", "response": "def convert_text(filename):\n    \"\"\"Convert the post/page content using the converters\"\"\"\n    text_content = open(filename, \"r\")\n    if \".md\" in filename:\n        text_cont1 = \"\\n\" + markdown.markdown(text_content.read()) + \"\\n\"\n    elif \".docx\" in filename:\n        with open(os.path.join(cwd, \"content\", filename), \"rb\") as docx_file:\n            result = mammoth.convert_to_html(docx_file)\n            final_docx_html = result.value\n        text_cont1 = \"\\n\" + final_docx_html + \"\\n\"\n    elif \".tile\" in filename:\n        text_cont1 = \"\\n\" + textile.textile(text_content.read()) + \"\\n\"\n    elif \".jade\" in filename:\n        text_cont1 = \"\\n\" + pyjade.simple_convert(text_content.read()) + \"\\n\"\n    elif \".rst\" in filename:\n        text_cont1 = \"\\n\" + \\\n            publish_parts(text_content.read(), writer_name='html')[\n                'html_body'] + \"\\n\"\n    elif \".html\" in filename:\n        text_cont1 = text_content.read()\n    elif \".txt\" in filename:\n        text_cont1 = text_content.read()\n    else:\n        print(filename + \" is not a valid file type!\")\n        text_cont1 = \"NULL\"\n\n    return text_cont1 + \"\\n\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the files for the current page.", "response": "def build_files(outdir):\n    \"\"\"Build the files!\"\"\"\n    # Make sure there is actually a configuration file\n    config_file_dir = os.path.join(cwd, \"config.py\")\n    if not os.path.exists(config_file_dir):\n        sys.exit(\n            \"There dosen't seem to be a configuration file. Have you run the init command?\")\n    else:\n        sys.path.insert(0, cwd)\n        try:\n            from config import website_name, website_description, website_language, home_page_list\n        except:\n            sys.exit(\n                \"ERROR: Some of the crucial configuration values could not be found! Maybe your config.py is too old. Run 'blended init' to fix.\")\n        try:\n            from config import website_description_long, website_license, website_url, author_name, author_bio, plugins, minify_css, minify_js, custom_variables\n        except:\n            website_description_long = \"\"\n            website_license = \"\"\n            website_url = \"\"\n            author_name = \"\"\n            author_bio = \"\"\n            plugins = []\n            custom_variables = {}\n            minify_css = False\n            minify_js = False\n            print(\"WARNING: Some of the optional configuration values could not be found! Maybe your config.py is too old. Run 'blended init' to fix.\\n\")\n\n    # Create the build folder\n    build_dir = os.path.join(cwd, outdir)\n    if \".\" not in outdir and \"..\" not in outdir and \"...\" not in outdir and \"....\" not in outdir and \".....\" not in outdir:\n        replace_folder(build_dir)\n\n    # Make sure there is actually a header template file\n    header_file_dir = os.path.join(cwd, \"templates\", \"header.html\")\n    if not os.path.exists(header_file_dir):\n        sys.exit(\n            \"There dosen't seem to be a header template file. You need one to generate.\")\n\n    # Make sure there is actually a footer template file\n    footer_file_dir = os.path.join(cwd, \"templates\", \"footer.html\")\n    if not os.path.exists(footer_file_dir):\n        sys.exit(\n            \"There dosen't seem to be a footer template file. You need one to generate.\")\n\n    # Open the header and footer files for reading\n    header_file = open(header_file_dir, \"r\")\n    footer_file = open(footer_file_dir, \"r\")\n\n    # Create the HTML page listing\n    page_list_item_file = os.path.join(cwd, \"templates\", \"page_list_item.html\")\n    if not os.path.exists(page_list_item_file):\n        page_list = '<ul class=\"page-list\">\\n'\n        for root, dirs, files in os.walk(os.path.join(cwd, \"content\")):\n            for filename in files:\n                top = os.path.dirname(os.path.join(root, filename))\n                top2 = top.replace(os.path.join(cwd, \"content\"), \"\", 1)\n                if platform != \"win32\":\n                    subfolder = top2.replace(\"/\", \"\", 1)\n                else:\n                    subfolder = top2.replace(\"\\\\\", \"\", 1)\n\n                if subfolder == \"\":\n                    subfolder_link = \"\"\n                else:\n                    subfolder_link = subfolder + \"/\"\n                file_modified = time.ctime(\n                    os.path.getmtime(os.path.join(root, filename)))\n                newFilename = get_html_filename(filename)\n                newFilename2 = get_html_clear_filename(filename)\n                page_list = page_list + '<li class=\"page-list-item\"><a href=\"' + subfolder_link + newFilename + \\\n                    '\">' + newFilename2 + '</a><span class=\"page-list-item-time\"> - ' + \\\n                    str(file_modified) + '</span></li>\\n'\n        page_list = page_list + '</ul>'\n    else:\n        with open(page_list_item_file, 'r') as f:\n            page_list_item = f.read()\n\n        page_list = \"\"\n        for root, dirs, files in os.walk(os.path.join(cwd, \"content\")):\n            dirs[:] = [d for d in dirs if \"_\" not in d]\n            for filename in files:\n                p_content = convert_text(os.path.join(root, filename))\n                top = os.path.dirname(os.path.join(root, filename))\n                top2 = top.replace(os.path.join(cwd, \"content\"), \"\", 1)\n                if platform != \"win32\":\n                    subfolder = top2.replace(\"/\", \"\", 1)\n                else:\n                    subfolder = top2.replace(\"\\\\\", \"\", 1)\n\n                if subfolder == \"\":\n                    subfolder_link = \"\"\n                else:\n                    subfolder_link = subfolder + \"/\"\n                file_modified = time.ctime(\n                    os.path.getmtime(os.path.join(root, filename)))\n                file_modified_day = str(datetime.strptime(\n                file_modified, \"%a %b %d %H:%M:%S %Y\"))[8:10]\n                file_modified_year = str(datetime.strptime(\n                    file_modified, \"%a %b %d %H:%M:%S %Y\"))[:4]\n                file_modified_month = str(datetime.strptime(\n                    file_modified, \"%a %b %d %H:%M:%S %Y\"))[5:7]\n                month_name = calendar.month_name[int(file_modified_month)]\n                newFilename = get_html_filename(filename)\n                newFilename2 = get_html_clear_filename(filename)\n\n                page_list = page_list + page_list_item.replace(\"{path}\", subfolder_link + newFilename).replace(\"{name}\", newFilename2).replace(\n                    \"{date}\", str(file_modified)).replace(\"{content}\", p_content).replace(\"{content_short}\", p_content[:250] + \"...\").replace(\"{day}\", file_modified_day).replace(\"{month}\", file_modified_month).replace(\"{month_name}\", month_name).replace(\"{year}\", file_modified_year)\n\n    if home_page_list == \"yes\" or home_page_list:\n        # Open the home page file (index.html) for writing\n        home_working_file = open(os.path.join(cwd, outdir, \"index.html\"), \"w\")\n\n        home_working_file.write(header_file.read())\n\n        # Make sure there is actually a home page template file\n        home_templ_dir = os.path.join(cwd, \"templates\", \"home_page.html\")\n        if os.path.exists(home_templ_dir):\n            home_templ_file = open(home_templ_dir, \"r\")\n            home_working_file.write(home_templ_file.read())\n        else:\n            print(\"\\nNo home page template file found. Writing page list to index.html\")\n            home_working_file.write(page_list)\n\n        home_working_file.write(footer_file.read())\n\n        home_working_file.close()\n\n    for root, dirs, files in os.walk(os.path.join(cwd, \"content\")):\n        dirs[:] = [d for d in dirs if \"_\" not in d]\n        for filename in files:\n            if not filename.startswith(\"_\"):\n                header_file = open(header_file_dir, \"r\")\n                footer_file = open(footer_file_dir, \"r\")\n                newFilename = get_html_filename(filename)\n\n                top = os.path.dirname(os.path.join(root, filename))\n                top2 = top.replace(os.path.join(cwd, \"content\"), \"\", 1)\n                if platform != \"win32\":\n                    subfolder = top2.replace(\"/\", \"\", 1)\n                else:\n                    subfolder = top2.replace(\"\\\\\", \"\", 1)\n\n                if subfolder == \"\":\n                    currents_working_file = open(\n                        os.path.join(cwd, outdir, newFilename), \"w\")\n                else:\n                    create_folder(os.path.join(cwd, outdir, subfolder))\n                    currents_working_file = open(os.path.join(\n                        cwd, outdir, subfolder, newFilename), \"w\")\n\n                # Write the header\n                currents_working_file.write(header_file.read())\n\n                text_cont1 = convert_text(os.path.join(root, filename))\n\n                if \"+++++\" in text_cont1.splitlines()[1]:\n                    page_template_file = text_cont1.splitlines()[0]\n                    text_cont1 = text_cont1.replace(\n                        text_cont1.splitlines()[0], \"\")\n                    text_cont1 = text_cont1.replace(\n                        text_cont1.splitlines()[1], \"\")\n                else:\n                    page_template_file = \"content_page\"\n\n                # Write the text content into the content template and onto the\n                # build file\n                content_templ_dir = os.path.join(\n                    cwd, \"templates\", page_template_file + \".html\")\n                if os.path.exists(content_templ_dir):\n                    content_templ_file = open(content_templ_dir, \"r\")\n                    content_templ_file1 = content_templ_file.read()\n                    content_templ_file2 = content_templ_file1.replace(\n                        \"{page_content}\", text_cont1)\n                    currents_working_file.write(content_templ_file2)\n                else:\n                    currents_working_file.write(text_cont1)\n\n                # Write the footer to the build file\n                currents_working_file.write(\"\\n\" + footer_file.read())\n\n                # Close the build file\n                currents_working_file.close()\n\n    # Find all the nav(something) templates in the `templates` folder and\n    # Read their content to the dict\n    navs = {}\n\n    for file in os.listdir(os.path.join(cwd, \"templates\")):\n        if \"nav\" in file:\n            nav_cont = open(os.path.join(cwd, \"templates\", file), \"r\")\n            navs[file.replace(\".html\", \"\")] = nav_cont.read()\n            nav_cont.close()\n\n    forbidden_dirs = set([\"assets\", \"templates\"])\n    blended_version_message = \"Built with Blended v\" + \\\n        str(app_version)\n    build_date = str(datetime.now().date())\n    build_time = str(datetime.now().time())\n    build_datetime = str(datetime.now())\n\n    # Replace global variables such as site name and language\n    for root, dirs, files in os.walk(os.path.join(cwd, outdir)):\n        dirs[:] = [d for d in dirs if d not in forbidden_dirs]\n        for filename in files:\n            if filename != \"config.pyc\" and filename != \"config.py\":\n                newFilename = get_html_clear_filename(filename)\n                page_file = filename.replace(\".html\", \"\")\n                page_folder = os.path.basename(os.path.dirname(os.path.join(\n                    root, filename))).replace(\"-\", \"\").replace(\"_\", \"\").title()\n                page_folder_orig = os.path.basename(\n                    os.path.dirname(os.path.join(root, filename)))\n                top = os.path.dirname(os.path.join(root, filename))\n                top2 = top.replace(os.path.join(cwd, outdir), \"\", 1)\n                if platform != \"win32\":\n                    subfolder = top2.replace(\"/\", \"\", 1)\n                else:\n                    subfolder = top2.replace(\"\\\\\", \"\", 1)\n                if subfolder == \"\":\n                    subfolder_folder = os.path.join(cwd, outdir, filename)\n                else:\n                    subfolder_folder = os.path.join(\n                        cwd, outdir, subfolder, filename)\n                file_modified = time.ctime(\n                    os.path.getmtime(os.path.join(root, filename)))\n                file_modified_day = str(datetime.strptime(\n                    file_modified, \"%a %b %d %H:%M:%S %Y\"))[8:10]\n                file_modified_year = str(datetime.strptime(\n                    file_modified, \"%a %b %d %H:%M:%S %Y\"))[:4]\n                file_modified_month = str(datetime.strptime(\n                file_modified, \"%a %b %d %H:%M:%S %Y\"))[5:7]\n                month_name = calendar.month_name[int(file_modified_month)]\n\n                # The Loop!\n                for line in fileinput.input(subfolder_folder, inplace=1):\n                    for var in custom_variables:\n                        line = line.replace(\n                            \"{\" + var + \"}\", custom_variables[var])\n                    if len(plugins) != 0:\n                        for i in range(len(plugins)):\n                            if sys.version_info[0] < 2:\n                                main = importlib.import_module(plugins[i])\n                            elif sys.version_info[0] < 3:\n                                main = __import__(plugins[i])\n                            content = main.main()\n                            line = line.replace(\n                                \"{\" + plugins[i] + \"}\", content)\n                    if \"{nav\" in line:\n                        navname = line.split(\"{\")[1].split(\"}\")[0]\n                        line = line.replace(\n                            \"{\" + navname + \"}\", navs[(line.split(\"{\"))[1].split(\"}\")[0]])\n                    line = line.replace(\n                        \"{website_description}\", website_description)\n                    line = line.replace(\n                        \"{website_description_long}\", website_description_long)\n                    line = line.replace(\"{website_license}\", website_license)\n                    line = line.replace(\"{website_language}\", website_language)\n                    line = line.replace(\"{website_url}\", website_url)\n                    line = line.replace(\"{author_name}\", author_name)\n                    line = line.replace(\"{author_bio}\", author_bio)\n                    line = line.replace(\"{random_number}\",\n                                        str(randint(0, 100000000)))\n                    line = line.replace(\"{build_date}\", build_date)\n                    line = line.replace(\"{build_time}\", build_time)\n                    line = line.replace(\"{build_datetime}\", build_datetime)\n                    line = line.replace(\"{page_list}\", page_list)\n                    line = line.replace(\"{page_name}\", newFilename)\n                    line = line.replace(\"{page_filename}\", page_file)\n                    line = line.replace(\"{page_file}\", filename)\n                    line = line.replace(\"{\" + filename + \"_active}\", \"active\")\n                    if page_folder != outdir.title():\n                        line = line.replace(\"{page_folder}\", page_folder)\n                    else:\n                        line = line.replace(\"{page_folder}\", \"\")\n                    if page_folder_orig != outdir:\n                        line = line.replace(\n                            \"{page_folder_orig}\", page_folder_orig)\n                    else:\n                        line = line.replace(\"{page_folder_orig}\", \"\")\n                    line = line.replace(\"{page_date}\", str(file_modified))\n                    line = line.replace(\"{page_day}\", str(file_modified_day))\n                    line = line.replace(\"{page_year}\", str(file_modified_year))\n                    line = line.replace(\n                        \"{page_month}\", str(file_modified_month))\n                    line = line.replace(\n                        \"{page_month_name}\", str(month_name))\n                    line = line.replace(\"{blended_version}\", str(app_version))\n                    line = line.replace(\n                        \"{blended_version_message}\", blended_version_message)\n                    line = line.replace(\"{website_name}\", website_name)\n                    top = os.path.join(cwd, outdir)\n                    startinglevel = top.count(os.sep)\n                    relative_path = \"\"\n                    level = root.count(os.sep) - startinglevel\n                    for i in range(level):\n                        relative_path = relative_path + \"../\"\n                    line = line.replace(\"{relative_root}\", relative_path)\n                    print(line.rstrip('\\n'))\n                fileinput.close()\n\n    # Copy the asset folder to the build folder\n    if os.path.exists(os.path.join(cwd, \"templates\", \"assets\")):\n        if os.path.exists(os.path.join(cwd, outdir, \"assets\")):\n            shutil.rmtree(os.path.join(cwd, outdir, \"assets\"))\n        shutil.copytree(os.path.join(cwd, \"templates\", \"assets\"),\n                        os.path.join(cwd, outdir, \"assets\"))\n\n    for root, dirs, files in os.walk(os.path.join(cwd, outdir, \"assets\")):\n        for file in files:\n            if not file.startswith(\"_\"):\n                if (file.endswith(\".sass\")) or (file.endswith(\".scss\")):\n                    sass_text = open(os.path.join(root, file)).read()\n                    text_file = open(os.path.join(\n                        root, file[:-4] + \"css\"), \"w\")\n                    if sass_text != \"\":\n                        text_file.write(sass.compile(string=sass_text))\n                    else:\n                        print(file + \" is empty! Not compiling Sass.\")\n                    text_file.close()\n                if file.endswith(\".less\"):\n                    less_text = open(os.path.join(root, file)).read()\n                    text_file = open(os.path.join(\n                        root, file[:-4] + \"css\"), \"w\")\n                    if less_text != \"\":\n                        text_file.write(lesscpy.compile(StringIO(less_text)))\n                    else:\n                        print(file + \" is empty! Not compiling Less.\")\n                    text_file.close()\n                if file.endswith(\".styl\"):\n                    try:\n                        styl_text = open(os.path.join(root, file)).read()\n                        text_file = open(os.path.join(\n                            root, file[:-4] + \"css\"), \"w\")\n                        if styl_text != \"\":\n                            text_file.write(Stylus().compile(styl_text))\n                        else:\n                            print(file + \" is empty! Not compiling Styl.\")\n                        text_file.close()\n                    except:\n                        print(\"Not able to build with Stylus! Is it installed?\")\n                        try:\n                            subprocess.call[\"npm\", \"install\", \"-g\", \"stylus\"]\n                        except:\n                            print(\"NPM (NodeJS) not working. Is it installed?\")\n                if file.endswith(\".coffee\"):\n                    coffee_text = open(os.path.join(root, file)).read()\n                    text_file = open(os.path.join(root, file[:-6] + \"js\"), \"w\")\n                    if coffee_text != \"\":\n                        text_file.write(coffeescript.compile(coffee_text))\n                    else:\n                        print(file + \" is empty! Not compiling CoffeeScript.\")\n                    text_file.close()\n                if minify_css:\n                    if file.endswith(\".css\"):\n                        css_text = open(os.path.join(root, file)).read()\n                        text_file = open(os.path.join(root, file), \"w\")\n                        if css_text != \"\":\n                            text_file.write(cssmin(css_text))\n                        text_file.close()\n                if minify_js:\n                    if file.endswith(\".js\"):\n                        js_text = open(os.path.join(root, file)).read()\n                        text_file = open(os.path.join(root, file), \"w\")\n                        if js_text != \"\":\n                            text_file.write(jsmin(js_text))\n                        text_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build(outdir):\n\n    print(\"Building your Blended files into a website!\")\n\n    reload(sys)\n    sys.setdefaultencoding('utf8')\n\n    build_files(outdir)\n\n    print(\"The files are built! You can find them in the \" + outdir +\n          \"/ directory. Run the view command to see what you have created in a web browser.\")", "response": "Blends the generated files and outputs a HTML website"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interactive(outdir):\n\n    print(\"Building your Blended files into a website!\")\n\n    global outdir_type\n    outdir_type = outdir\n\n    reload(sys)\n    sys.setdefaultencoding('utf8')\n\n    build_files(outdir)\n\n    print(\"Watching the content and templates directories for changes, press CTRL+C to stop...\\n\")\n\n    w = Watcher()\n    w.run()", "response": "Blends the generated files and outputs a HTML website on file change"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef view(outdir):\n\n    index_path = os.path.realpath(os.path.join(cwd, outdir, \"index.html\"))\n    if os.path.exists(index_path):\n        webbrowser.open('file://' + index_path)\n    else:\n        print(\"The index.html file could not be found in the \" + outdir +\n              \"/ folder! Have you deleted it or have you built with home_page_list set to 'no' in config.py?\")", "response": "Opens the built index. html file in a web browser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the builder on changes", "response": "def run(self):\n        \"\"\"Run the builder on changes\"\"\"\n        event_handler = Handler()\n        threads = []\n        paths = [os.path.join(cwd, \"content\"), os.path.join(cwd, \"templates\")]\n\n        for i in paths:\n            targetPath = str(i)\n            self.observer.schedule(event_handler, targetPath, recursive=True)\n            threads.append(self.observer)\n\n        self.observer.start()\n\n        try:\n            while True:\n                time.sleep(5)\n        except:\n            self.observer.stop()\n            print(\"\\nObserver stopped.\")\n\n        self.observer.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts strings to integers", "response": "def _sanitize_numbers(uncleaned_numbers):\n    \"\"\"\n        Convert strings to integers if possible\n    \"\"\"\n    cleaned_numbers = []\n    for x in uncleaned_numbers:\n        try:\n            cleaned_numbers.append(int(x))\n        except ValueError:\n            cleaned_numbers.append(x)\n    return cleaned_numbers"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the minimum negative number to all the numbers in the", "response": "def _handle_negatives(numbers):\n    \"\"\"\n        Add the minimum negative number to all the numbers in the\n        such that all the elements become >= 0\n    \"\"\"\n    min_number = min(filter(lambda x : type(x)==int,numbers))\n    if min_number < 0:\n        return [x+abs(min_number) if type(x)==int else x for x in numbers]\n    else:\n        return numbers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _draw_tickgram(numbers):\n    max_number = max(filter(lambda x : type(x)==int,numbers))\n    # If the maxium number is 0, then all the numbers should be 0\n    # coz we have called handle_negatives prior to this function\n    if max_number == 0 :\n        return upticks[0]*len(numbers)\n    else:\n        normalized_numbers = [ float(x)/max_number if type(x)==int else x for x in numbers ]\n        upticks_indexes = [ int(math.ceil(x*len(upticks))) if type(x)==float else x for x in normalized_numbers ]\n        return ''.join([ ' ' if type(x)==str else upticks[x-1] if x != 0 else upticks[0] for x in upticks_indexes ])", "response": "Takes a list of integers and generates the equivalent list \n        of ticks corresponding to each of the number\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the multi - scale output of a single - scale output of a single - scale output of a single - scale output of a single - scale output of a single - scale output of a single - scale output of a single - scale output of a single - scale output of a single - scale output of a single - scale output.", "response": "def plot_multi_scale_output_b(fig, X='L5E'):\n    '''docstring me'''\n\n    show_ax_labels = True\n    show_insets = False\n    show_images = False\n\n    T=[800, 1000]\n    T_inset=[900, 920]\n\n    \n    left = 0.075\n    bottom = 0.05\n    top = 0.475\n    right = 0.95\n    axwidth = 0.16\n    numcols = 4\n    insetwidth = axwidth/2\n    insetheight = 0.5\n    \n    lefts = np.linspace(left, right-axwidth, numcols)\n    lefts += axwidth/2\n\n\n\n    #lower row of panels\n    #fig = plt.figure()\n    #fig.subplots_adjust(left=0.12, right=0.9, bottom=0.36, top=0.9, wspace=0.2, hspace=0.3)\n\n    ############################################################################    \n    # E part, soma locations\n    ############################################################################\n\n    ax4 = fig.add_axes([lefts[0], bottom, axwidth, top-bottom], frameon=False)\n    plt.locator_params(nbins=4)\n    ax4.xaxis.set_ticks([])\n    ax4.yaxis.set_ticks([])\n    if show_ax_labels:\n        phlp.annotate_subplot(ax4, ncols=4, nrows=1, letter='E')\n    plot_population(ax4, params, isometricangle=np.pi/24, rasterized=False)\n    \n    \n    ############################################################################    \n    # F part, CSD\n    ############################################################################\n\n    ax5 = fig.add_axes([lefts[1], bottom, axwidth, top-bottom])\n    plt.locator_params(nbins=4)\n    phlp.remove_axis_junk(ax5)\n    if show_ax_labels:\n        phlp.annotate_subplot(ax5, ncols=4, nrows=1, letter='F')\n    plot_signal_sum(ax5, params, fname=os.path.join(params.savefolder, 'CSDsum.h5'),\n                        unit='$\\mu$A mm$^{-3}$',\n                        T=T,\n                        ylim=[ax4.axis()[2], ax4.axis()[3]],\n                        rasterized=False)\n    ax5.set_title('CSD', va='center')\n    \n    # Inset\n    if show_insets:\n        ax6 = fig.add_axes([lefts[1]+axwidth-insetwidth, top-insetheight, insetwidth, insetheight])\n        plt.locator_params(nbins=4)\n        phlp.remove_axis_junk(ax6)\n        plot_signal_sum_colorplot(ax6, params, os.path.join(params.savefolder, 'CSDsum.h5'),\n                                  unit=r'$\\mu$Amm$^{-3}$', T=T_inset,\n                                  ylim=[ax4.axis()[2], ax4.axis()[3]],\n                                  fancy=False,colorbar=False,cmap='bwr_r')\n        ax6.set_xticks(T_inset)\n        ax6.set_yticklabels([])\n\n    #show traces superimposed on color image\n    if show_images:\n        plot_signal_sum_colorplot(ax5, params, os.path.join(params.savefolder, 'CSDsum.h5'),\n                                  unit=r'$\\mu$Amm$^{-3}$', T=T,\n                                  ylim=[ax4.axis()[2], ax4.axis()[3]],\n                                  fancy=False,colorbar=False,cmap='jet_r')\n        \n\n    \n    ############################################################################\n    # G part, LFP \n    ############################################################################\n\n    ax7 = fig.add_axes([lefts[2], bottom, axwidth, top-bottom])\n    plt.locator_params(nbins=4)\n    if show_ax_labels:\n        phlp.annotate_subplot(ax7, ncols=4, nrows=1, letter='G')\n    phlp.remove_axis_junk(ax7)\n    plot_signal_sum(ax7, params, fname=os.path.join(params.savefolder, 'LFPsum.h5'),\n                    unit='mV', T=T, ylim=[ax4.axis()[2], ax4.axis()[3]],\n                    rasterized=False)\n    ax7.set_title('LFP',va='center')\n    \n    # Inset\n    if show_insets:\n        ax8 = fig.add_axes([lefts[2]+axwidth-insetwidth, top-insetheight, insetwidth, insetheight])\n        plt.locator_params(nbins=4)\n        phlp.remove_axis_junk(ax8)\n        plot_signal_sum_colorplot(ax8, params, os.path.join(params.savefolder, 'LFPsum.h5'),\n                                  unit='mV', T=T_inset,\n                                  ylim=[ax4.axis()[2], ax4.axis()[3]],\n                                  fancy=False,colorbar=False,cmap='bwr_r')   \n        ax8.set_xticks(T_inset)\n        ax8.set_yticklabels([])\n\n    #show traces superimposed on color image\n    if show_images:\n        plot_signal_sum_colorplot(ax7, params, os.path.join(params.savefolder, 'LFPsum.h5'),\n                                  unit='mV', T=T,\n                                  ylim=[ax4.axis()[2], ax4.axis()[3]],\n                                  fancy=False,colorbar=False,cmap='bwr_r')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_raw_gids(model_params):\n    '''\n    Reads text file containing gids of neuron populations as created within the\n    NEST simulation. These gids are not continuous as in the simulation devices\n    get created in between.\n    '''\n    gidfile = open(os.path.join(model_params.raw_nest_output_path,\n                                model_params.GID_filename), 'r') \n    gids = [] \n    for l in gidfile :\n        a = l.split()\n        gids.append([int(a[0]),int(a[1])])\n    return gids", "response": "Reads the raw text file containing gids of neuron populations as created within the\n    NEST simulation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_folder(path):\n    if os.path.exists(path):\n        shutil.rmtree(path)\n        os.makedirs(path)\n    else:\n        os.makedirs(path)", "response": "Removes the specified folder if it exists and recreated"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the filename to a. html extension", "response": "def get_html_filename(filename):\n    \"\"\"Converts the filename to a .html extension\"\"\"\n    if \".html\" in filename:\n        newFilename = filename\n    elif \".md\" in filename:\n        newFilename = filename.replace(\".md\", \".html\")\n    elif \".tile\" in filename:\n        newFilename = filename.replace(\".tile\", \".html\")\n    elif \".jade\" in filename:\n        newFilename = filename.replace(\".jade\", \".html\")\n    elif \".txt\" in filename:\n        newFilename = filename.replace(\".txt\", \".html\")\n    elif \".rst\" in filename:\n        newFilename = filename.replace(\".rst\", \".html\")\n    elif \".docx\" in filename:\n        newFilename = filename.replace(\".docx\", \".html\")\n    else:\n        print(filename + \" is not a valid file type!\")\n\n    return newFilename"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_html_clear_filename(filename):\n    newFilename = filename.replace(\".html\", \"\")\n    newFilename = newFilename.replace(\".md\", \"\")\n    newFilename = newFilename.replace(\".txt\", \"\")\n    newFilename = newFilename.replace(\".tile\", \"\")\n    newFilename = newFilename.replace(\".jade\", \"\")\n    newFilename = newFilename.replace(\".rst\", \"\")\n    newFilename = newFilename.replace(\".docx\", \"\")\n    newFilename = newFilename.replace(\"index\", \"home\")\n    newFilename = newFilename.replace(\"-\", \" \")\n    newFilename = newFilename.replace(\"_\", \" \")\n    newFilename = newFilename.title()\n\n    return newFilename", "response": "Clears the file extension from the filename and makes it nice looking"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload and unzips a zip file", "response": "def getunzipped(username, repo, thedir):\n    \"\"\"Downloads and unzips a zip file\"\"\"\n    theurl = \"https://github.com/\" + username + \"/\" + repo + \"/archive/master.zip\"\n    name = os.path.join(thedir, 'temp.zip')\n    try:\n        name = urllib.urlretrieve(theurl, name)\n        name = os.path.join(thedir, 'temp.zip')\n    except IOError as e:\n        print(\"Can't retrieve %r to %r: %s\" % (theurl, thedir, e))\n        return\n    try:\n        z = zipfile.ZipFile(name)\n    except zipfile.error as e:\n        print(\"Bad zipfile (from %r): %s\" % (theurl, e))\n        return\n    z.extractall(thedir)\n    z.close()\n    os.remove(name)\n\n    copy_tree(os.path.join(thedir, repo + \"-master\"), thedir)\n    shutil.rmtree(os.path.join(thedir, repo + \"-master\"))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the config. py file exists and copy it up", "response": "def checkConfig():\n    \"\"\"If the config.py file exists, back it up\"\"\"\n    config_file_dir = os.path.join(cwd, \"config.py\")\n    if os.path.exists(config_file_dir):\n        print(\"Making a backup of your config file!\")\n        config_file_dir2 = os.path.join(cwd, \"config.py.oldbak\")\n        copyfile(config_file_dir, config_file_dir2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createConfig(app_version=5.0, wname=\"\", wdesc=\"\", wdescl=\"\", wlic=\"\", wlan=\"\", wurl=\"\", aname=\"\", abio=\"\"):\n    config_file_dir = os.path.join(cwd, \"config.py\")\n\n    config_file = open(config_file_dir, \"w\")\n    config_file.write('blended_version = ' + app_version + '\\n')\n    config_file.write('\\n')\n    config_file.write(\n        '# Configuration is automatically generated by Blended (http://jmroper.com/blended), feel free to edit any values below')\n    config_file.write('\\n')\n    config_file.write('website_name = \"' + wname + '\"\\n')\n    config_file.write('website_description = \"' + wdesc + '\"\\n')\n    config_file.write(\n        'website_description_long = \"' + wdescl + '\"\\n')\n    config_file.write('website_license = \"' + wlic + '\"\\n')\n    config_file.write('website_language = \"' + wlan + '\"\\n')\n    config_file.write('website_url = \"' + wurl + '\"\\n')\n    config_file.write('\\n')\n    config_file.write('author_name = \"' + aname + '\"\\n')\n    config_file.write('author_bio = \"' + abio + '\"\\n')\n    config_file.write('\\n')\n    config_file.write('home_page_list = True\\n')\n    config_file.write('\\n')\n    config_file.write('plugins = [] # Place all needed plugins in here\\n')\n    config_file.write(\n        'custom_variables = {} # Place all custom variables in here\\n')\n    config_file.write('\\n')\n    config_file.write('minify_css = False\\n')\n    config_file.write('minify_js = False\\n')\n    config_file.write('\\n')\n    config_file.write('# The following values are used for FTP uploads')\n    config_file.write('\\n')\n    config_file.write('ftp_server = \"localhost\"\\n')\n    config_file.write('ftp_username = \"user\"\\n')\n    config_file.write('ftp_password = \"pass\"\\n')\n    config_file.write('ftp_port = 21\\n')\n    config_file.write('ftp_upload_path = \"public_html/myWebsite\"\\n')\n    config_file.close()", "response": "Generates a config file from the information"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the standard folders for a Blended website", "response": "def createBlendedFolders():\n    \"\"\"Creates the standard folders for a Blended website\"\"\"\n    # Create the templates folder\n    create_folder(os.path.join(cwd, \"templates\"))\n\n    # Create the templates/assets folder\n    create_folder(os.path.join(cwd, \"templates\", \"assets\"))\n\n    # Create the templates/assets/css folder\n    create_folder(os.path.join(cwd, \"templates\", \"assets\", \"css\"))\n\n    # Create the templates/assets/js folder\n    create_folder(os.path.join(cwd, \"templates\", \"assets\", \"js\"))\n\n    # Create the templates/assets/img folder\n    create_folder(os.path.join(cwd, \"templates\", \"assets\", \"img\"))\n\n    # Create the content folder\n    create_folder(os.path.join(cwd, \"content\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_environ(keys):\n    items = ((k, os.environ.get(k)) for k in keys)\n    subenv = dict((k, v) for (k, v) in items if v is not None)\n    needset = lambda k: k in keys and not subenv.get(k)\n\n    def setifnonempty(key, value):\n        if value:\n            subenv[key] = value\n\n    if needset('HOST'):\n        import platform\n        subenv['HOST'] = platform.node()\n    if needset('TTY'):\n        setifnonempty('TTY', get_tty())\n    if needset('RASH_SPENV_TERMINAL'):\n        from .utils.termdetection import detect_terminal\n        setifnonempty('RASH_SPENV_TERMINAL', detect_terminal())\n    return subenv", "response": "Get environment variables from os. environ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_session_id(data):\n    host = data['environ']['HOST']\n    tty = data['environ'].get('TTY') or 'NO_TTY'\n    return ':'.join(map(str, [\n        host, tty, os.getppid(), data['start']]))", "response": "Generate session ID based on HOST TTY PID and start time."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends \"/\" to `path` if needed.", "response": "def normalize_directory(path):\n    \"\"\"\n    Append \"/\" to `path` if needed.\n    \"\"\"\n    if path is None:\n        return None\n    if path.endswith(os.path.sep):\n        return path\n    else:\n        return path + os.path.sep"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts program name from command.", "response": "def sql_program_name_func(command):\n    \"\"\"\n    Extract program name from `command`.\n\n    >>> sql_program_name_func('ls')\n    'ls'\n    >>> sql_program_name_func('git status')\n    'git'\n    >>> sql_program_name_func('EMACS=emacs make')\n    'make'\n\n    :type command: str\n\n    \"\"\"\n    args = command.split(' ')\n    for prog in args:\n        if '=' not in prog:\n            return prog\n    return args[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a distance between path1 and path2.", "response": "def sql_pathdist_func(path1, path2, sep=os.path.sep):\n    \"\"\"\n    Return a distance between `path1` and `path2`.\n\n    >>> sql_pathdist_func('a/b/', 'a/b/', sep='/')\n    0\n    >>> sql_pathdist_func('a/', 'a/b/', sep='/')\n    1\n    >>> sql_pathdist_func('a', 'a/', sep='/')\n    0\n\n    \"\"\"\n    seq1 = path1.rstrip(sep).split(sep)\n    seq2 = path2.rstrip(sep).split(sep)\n    return sum(1 for (p1, p2) in zip_longest(seq1, seq2) if p1 != p2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _init_db(self):\n        with self._get_db() as db:\n            with open(self.schemapath) as f:\n                db.cursor().executescript(f.read())\n            db.commit()", "response": "Creates the database tables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclosing the connection kept by the database.", "response": "def close_connection(self):\n        \"\"\"\n        Close connection kept by :meth:`connection`.\n\n        If commit is needed, :meth:`sqlite3.Connection.commit`\n        is called first and then :meth:`sqlite3.Connection.interrupt`\n        is called.\n\n        A few methods/generators support :meth:`close_connection`:\n\n        - :meth:`search_command_record`\n        - :meth:`select_by_command_record`\n\n        \"\"\"\n        if self._db:\n            db = self._db\n            try:\n                if self._need_commit:\n                    db.commit()\n            finally:\n                db.interrupt()\n                self._db = None\n                self._need_commit = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _executing(self, sql, params=[]):\n        with self.connection() as connection:\n            for row in connection.execute(sql, params):\n                yield row\n                if not self._db:\n                    return", "response": "Execute and yield rows in a way that can be used to handle the connection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_version_records(self):\n        keys = ['id', 'rash_version', 'schema_version', 'updated']\n        sql = \"\"\"\n        SELECT id, rash_version, schema_version, updated\n        FROM rash_info\n        ORDER BY id DESC\n        \"\"\"\n        with self.connection() as connection:\n            for row in connection.execute(sql):\n                yield VersionRecord(**dict(zip(keys, row)))", "response": "Yields all version records stored in DB. Latest first."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate rash_info table if necessary.", "response": "def update_version_records(self):\n        \"\"\"\n        Update rash_info table if necessary.\n        \"\"\"\n        from .__init__ import __version__ as version\n        with self.connection(commit=True) as connection:\n            for vrec in self.get_version_records():\n                if (vrec.rash_version == version and\n                    vrec.schema_version == schema_version):\n                    return  # no need to insert the new one!\n            connection.execute(\n                'INSERT INTO rash_info (rash_version, schema_version) '\n                'VALUES (?, ?)',\n                [version, schema_version])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select_by_command_record(self, crec):\n        keys = ['command_history_id', 'command', 'session_history_id',\n                'cwd', 'terminal',\n                'start', 'stop', 'exit_code']\n        sql = \"\"\"\n        SELECT\n            command_history.id, CL.command, session_id,\n            DL.directory, TL.terminal,\n            start_time, stop_time, exit_code\n        FROM command_history\n        LEFT JOIN command_list AS CL ON command_id = CL.id\n        LEFT JOIN directory_list AS DL ON directory_id = DL.id\n        LEFT JOIN terminal_list AS TL ON terminal_id = TL.id\n        WHERE\n            (CL.command   = ? OR (CL.command   IS NULL AND ? IS NULL)) AND\n            (DL.directory = ? OR (DL.directory IS NULL AND ? IS NULL)) AND\n            (TL.terminal  = ? OR (TL.terminal  IS NULL AND ? IS NULL)) AND\n            (start_time   = ? OR (start_time   IS NULL AND ? IS NULL)) AND\n            (stop_time    = ? OR (stop_time    IS NULL AND ? IS NULL)) AND\n            (exit_code    = ? OR (exit_code    IS NULL AND ? IS NULL))\n        \"\"\"\n        desired_row = [\n            crec.command, normalize_directory(crec.cwd), crec.terminal,\n            convert_ts(crec.start), convert_ts(crec.stop), crec.exit_code]\n        params = list(itertools.chain(*zip(desired_row, desired_row)))\n        return self._select_rows(CommandRecord, keys, sql, params)", "response": "Yields all records that match to crec."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch command history. :rtype: [CommandRecord]", "response": "def search_command_record(\n            self,\n            after_context, before_context, context, context_type,\n            **kwds):\n        \"\"\"\n        Search command history.\n\n        :rtype: [CommandRecord]\n\n        \"\"\"\n        if after_context or before_context or context:\n            kwds['condition_as_column'] = True\n            limit = kwds['limit']\n            kwds['limit'] = -1\n            kwds['unique'] = False\n            kwds['sort_by'] = {\n                'session': ['session_start_time', 'start_time'],\n                'time': ['start_time'],\n            }[context_type]\n            if not kwds['reverse']:\n                # Default (reverse=False) means latest history comes first.\n                after_context, before_context = before_context, after_context\n\n        (sql, params, keys) = self._compile_sql_search_command_record(**kwds)\n        records = self._select_rows(CommandRecord, keys, sql, params)\n\n        # SOMEDAY: optimize context search;  do not create CommandRecord\n        #          object for all (including non-matching) records.\n        predicate = lambda r: r.condition\n        if context:\n            records = include_context(predicate, context, records)\n        elif before_context:\n            records = include_before(predicate, before_context, records)\n        elif after_context:\n            records = include_after(predicate, after_context, records)\n        if after_context or before_context or context and limit >= 0:\n            records = itertools.islice(records, limit)\n        # NOTE: as SQLite does not support row_number function, let's\n        #       do the filtering at Python side when context modifier\n        #       is given.  This is *very* inefficient but at least it\n        #       works..\n\n        return records"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the full command record by ID.", "response": "def get_full_command_record(self, command_history_id,\n                                merge_session_environ=True):\n        \"\"\"\n        Get fully retrieved :class:`CommandRecord` instance by ID.\n\n        By \"fully\", it means that complex slots such as `environ` and\n        `pipestatus` are available.\n\n        :type    command_history_id: int\n        :type merge_session_environ: bool\n\n        \"\"\"\n        with self.connection() as db:\n            crec = self._select_command_record(db, command_history_id)\n            crec.pipestatus = self._get_pipestatus(db, command_history_id)\n            # Set environment variables\n            cenv = self._select_environ(db, 'command', command_history_id)\n            crec.environ.update(cenv)\n            if merge_session_environ:\n                senv = self._select_environ(\n                    db, 'session', crec.session_history_id)\n                crec.environ.update(senv)\n        return crec"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_user_session(self, username, domain, resource, **kwargs):\n\n        kwargs.setdefault('uptime', pytz.utc.localize(datetime.utcnow()))\n        kwargs.setdefault('priority', 0)\n        kwargs.setdefault('status', 'online')\n        kwargs.setdefault('status_text', '')\n        kwargs.setdefault('connection_type', CONNECTION_XMPP)\n        kwargs.setdefault('encrypted', True)\n        kwargs.setdefault('compressed', False)\n        kwargs.setdefault('ip_address', '127.0.0.1')\n        if six.PY2 and isinstance(kwargs['ip_address'], str):\n            # ipaddress constructor does not eat str in py2 :-/\n            kwargs['ip_address'] = kwargs['ip_address'].decode('utf-8')\n        if isinstance(kwargs['ip_address'], six.string_types):\n            kwargs['ip_address'] = ipaddress.ip_address(kwargs['ip_address'])\n\n        user = '%s@%s' % (username, domain)\n        session = UserSession(self, username, domain, resource, **kwargs)\n\n        data = self.module.get(user)\n        if data is None:\n            raise UserNotFound(username, domain, resource)\n\n        data.setdefault('sessions', set())\n        if isinstance(data['sessions'], list):\n            # Cast old data to set\n            data['sessions'] = set(data['sessions'])\n\n        data['sessions'].add(session)\n        self.module.set(user, data)\n\n        all_sessions = self.module.get('all_sessions', set())\n        all_sessions.add(session)\n        self.module.set('all_sessions', all_sessions)", "response": "Method to add a user session for debugging."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_gdf(model_params, raw_label='spikes_', file_type='gdf',\n              fileprefix='spikes'):\n    '''\n    NEST produces one file per virtual process containing recorder output. \n    This function gathers and combines them into one single file per \n    network population.\n    \n    Parameters\n    ----------\n    model_params : object\n        network parameters object\n    \n    Returns\n    -------\n    None\n    \n    '''\n    def get_raw_gids(model_params):\n        '''\n        Reads text file containing gids of neuron populations as created within\n        the NEST simulation. These gids are not continuous as in the simulation\n        devices get created in between.\n        \n        Parameters\n        ----------\n        model_params : object\n            network parameters object\n        \n        \n        Returns\n        -------\n        gids : list\n            list of neuron ids and value (spike time, voltage etc.)\n        \n        '''\n        gidfile = open(os.path.join(model_params.raw_nest_output_path,\n                                    model_params.GID_filename),'r') \n        gids = [] \n        for l in gidfile :\n            a = l.split()\n            gids.append([int(a[0]),int(a[1])])\n        return gids\n    \n    #some preprocessing\n    raw_gids = get_raw_gids(model_params)\n    pop_sizes = [raw_gids[i][1]-raw_gids[i][0]+1\n                 for i in np.arange(model_params.Npops)]\n    raw_first_gids =  [raw_gids[i][0] for i in np.arange(model_params.Npops)]\n    converted_first_gids = [int(1 + np.sum(pop_sizes[:i]))\n                            for i in np.arange(model_params.Npops)]\n\n    for pop_idx in np.arange(model_params.Npops):\n        if pop_idx % SIZE == RANK:\n            files = glob(os.path.join(model_params.raw_nest_output_path,\n                                      raw_label + str(pop_idx) +\n                                      '*.' + file_type))\n            gdf = [] # init\n            for f in files:\n                new_gdf = helpers.read_gdf(f)\n                for line in new_gdf:\n                    line[0] = line[0] - raw_first_gids[pop_idx] + \\\n                              converted_first_gids[pop_idx]\n                    gdf.append(line)\n            \n            print 'writing: %s' % os.path.join(model_params.spike_output_path,\n                                            fileprefix +\n                                            '_%s.gdf' % model_params.X[pop_idx])\n            helpers.write_gdf(gdf, os.path.join(model_params.spike_output_path,\n                                        fileprefix +\n                                        '_%s.gdf' % model_params.X[pop_idx]))\n    \n    COMM.Barrier()\n\n    return", "response": "This function takes a model parameters and creates a single file per virtual process containing recorder output."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dict_of_numpyarray_to_dict_of_list(d):\n    '''\n    Convert dictionary containing numpy arrays to dictionary containing lists\n    \n    Parameters\n    ----------\n    d : dict\n        sli parameter name and value as dictionary key and value pairs\n    \n    Returns\n    -------\n    d : dict\n        modified dictionary\n    \n    '''\n    for key,value in d.iteritems():\n        if isinstance(value,dict):  # if value == dict \n            # recurse\n            d[key] = dict_of_numpyarray_to_dict_of_list(value)\n        elif isinstance(value,np.ndarray): # or isinstance(value,list) :\n            d[key] = value.tolist()\n    return d", "response": "Convert numpy arrays to dictionary containing lists\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads parameters and send them to SLI", "response": "def send_nest_params_to_sli(p):\n    '''\n    Read parameters and send them to SLI\n    \n    Parameters\n    ----------\n    p : dict\n        sli parameter name and value as dictionary key and value pairs\n    \n    Returns\n    -------\n    None\n    '''\n    for name in p.keys():\n        value = p[name]\n        if type(value) == np.ndarray:\n            value = value.tolist()\n        if type(value) == dict:\n            value = dict_of_numpyarray_to_dict_of_list(value)\n        if name == 'neuron_model': # special case as neuron_model is a\n                                   # NEST model and not a string\n            try:\n                nest.sli_run('/'+name)\n                nest.sli_push(value)\n                nest.sli_run('eval')\n                nest.sli_run('def')\n            except: \n                print 'Could not put variable %s on SLI stack' % (name)\n                print type(value)\n        else:\n            try:\n                nest.sli_run('/'+name)\n                nest.sli_push(value)\n                nest.sli_run('def')\n            except: \n                print 'Could not put variable %s on SLI stack' % (name)\n                print type(value)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a sensible label for a field name.", "response": "def label_for_field(name, model, return_attr=False):\n    \"\"\"\n    Returns a sensible label for a field name. The name can be a callable,\n    property (but not created with @property decorator) or the name of an\n    object's attribute, as well as a genuine fields. If return_attr is\n    True, the resolved attribute (which could be a callable) is also returned.\n    This will be None if (and only if) the name refers to a field.\n    \"\"\"\n    attr = None\n    try:\n        field = model._meta.get_field_by_name(name)[0]\n        if isinstance(field, RelatedObject):\n            label = field.opts.verbose_name\n        else:\n            label = field.verbose_name\n    except models.FieldDoesNotExist:\n        if name == \"__unicode__\":\n            label = force_text(model._meta.verbose_name)\n            attr = six.text_type\n        elif name == \"__str__\":\n            label = force_str(model._meta.verbose_name)\n            attr = bytes\n        else:\n            if callable(name):\n                attr = name\n            elif hasattr(model, name):\n                attr = getattr(model, name)\n            else:\n                message = \"Unable to lookup '%s' on %s\" % (name, model._meta.object_name)\n                raise AttributeError(message)\n\n            if hasattr(attr, \"short_description\"):\n                label = attr.short_description\n            elif (isinstance(attr, property) and\n                  hasattr(attr, \"fget\") and\n                  hasattr(attr.fget, \"short_description\")):\n                label = attr.fget.short_description\n            elif callable(attr):\n                if attr.__name__ == \"<lambda>\":\n                    label = \"--\"\n                else:\n                    label = pretty_name(attr.__name__)\n            else:\n                label = pretty_name(name)\n    if return_attr:\n        return (label, attr)\n    else:\n        return label"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the current rate with the given value.", "response": "def update(self, value):\n        \"\"\"\n        Update the current rate with the given value.\n        The value must be an integer.\n        \"\"\"\n\n        value = int(value)\n\n        with self.lock:\n            self.value += value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tick(self):\n\n        instant_rate = float(self.value) / float(self.tick_interval)\n\n        with self.lock:\n            if self.initialized:\n                self.rate += (self.alpha * (instant_rate - self.rate))\n            else:\n                self.initialized = True\n                self.rate = instant_rate\n\n            self.value = 0", "response": "Decay the current rate according to the elapsed time"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new observation to the metric", "response": "def notify(self, value):\n        \"\"\"Add a new observation to the metric\"\"\"\n\n        with self.lock:\n            #TODO: this could slow down slow-rate incoming updates\n            # since the number of ticks depends on the actual time\n            # passed since the latest notification. Consider using\n            # a real timer to tick the EWMA.\n\n            self.tick()\n\n            for avg in (self.m1, self.m5, self.m15, self.day):\n                avg.update(value)\n            self.count += value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tick_all(self, times):\n\n        for i in range(times):\n            for avg in (self.m1, self.m5, self.m15, self.day):\n                avg.tick()", "response": "Tick all the EWMAs for the given number of times"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tick(self):\n\n        now = time.time()\n\n        elapsed = now - self.latest_tick\n\n        if elapsed > self.tick_interval:\n            ticks = int(elapsed / self.tick_interval)\n\n            self.tick_all(ticks)\n\n            self.latest_tick = now", "response": "Emulate a timer that tickes a number of times depending on the elapsed time passed since the last tick."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self):\n\n        with self.lock:\n            self.tick()\n\n            data = dict(\n                kind=\"meter\",\n                count=self.count,\n                mean=self.count / (time.time() - self.started_on),\n                one=self.m1.rate,\n                five=self.m5.rate,\n                fifteen=self.m15.rate,\n                day=self.day.rate)\n\n        return data", "response": "Return the computed statistics over the gathered data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef closed(lower_value, upper_value):\n    return Interval(Interval.CLOSED, lower_value, upper_value, Interval.CLOSED)", "response": "Helper function to construct an interval object with closed lower and upper values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef openclosed(lower_value, upper_value):\n    return Interval(Interval.OPEN, lower_value, upper_value, Interval.CLOSED)", "response": "Helper function to construct an interval object with a open lower and closed upper."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new : class : ~pyinter. Interval object with the same bounds and values.", "response": "def copy(self):\n        \"\"\"Returns a new :class:`~pyinter.Interval` object with the same bounds and values.\"\"\"\n        return Interval(self._lower, self._lower_value, self._upper_value, self._upper)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _contains_value(self, value):\n        g = operator.gt if self._lower is self.OPEN else operator.ge\n        l = operator.lt if self._upper is self.OPEN else operator.le\n        return g(value, self.lower_value) and l(value, self._upper_value)", "response": "Helper function for __contains__ to check if a single value is contained within the interval"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if self and other have any overlapping values returns False otherwise returns False", "response": "def overlaps(self, other):\n        \"\"\"If self and other have any overlapping values returns True, otherwise returns False\"\"\"\n        if self > other:\n            smaller, larger = other, self\n        else:\n            smaller, larger = self, other\n        if larger.empty():\n            return False\n        if smaller._upper_value == larger._lower_value:\n            return smaller._upper == smaller.CLOSED and larger._lower == smaller.CLOSED\n        return larger._lower_value < smaller._upper_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef intersect(self, other):\n        if self.overlaps(other):\n            newlower_value = max(self.lower_value, other.lower_value)\n            new_upper_value = min(self._upper_value, other._upper_value)\n            new_lower, new_upper = self._get_new_lower_upper(other, self.intersect)\n            return Interval(new_lower, newlower_value, new_upper_value, new_upper)\n        else:\n            return None", "response": "Returns a new : class : ~pyinter. Interval representing the intersection of this and other."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new Interval or an IntervalSet representing the difference of this and other.", "response": "def difference(self, other):\n        \"\"\"Returns a new Interval or an :class:`~pyinter.IntervalSet` representing the subtraction of this\n        :class:`~pyinter.Interval` with the other :class:`~pyinter.Interval`.\n\n        The result will contain everything that is contained by the left interval but not contained\n        by the second interval.\n\n        If the `other` interval is enclosed in this one then this will return a\n        :class:`~pyinter.IntervalSet`, otherwise this returns a :class:`~pyinter.Interval`.\n        \"\"\"\n        if other.empty():\n            return self\n        if self in other:\n            return open(self._lower_value, self._lower_value)\n        if self._lower == other._lower and self._lower_value == other._lower_value:\n            return Interval(self._opposite_boundary_type(other._upper), other._upper_value, self._upper_value, self._upper)\n        if self._upper == other._upper and self._upper_value == other._upper_value:\n            return Interval(self._lower, self._lower_value, other._lower_value, self._opposite_boundary_type(other._lower))\n        if other in self:\n            return IntervalSet([\n                Interval(self._lower, self._lower_value, other.lower_value, self._opposite_boundary_type(other._lower)),\n                Interval(self._opposite_boundary_type(other._upper), other._upper_value, self.upper_value, self._upper),\n            ])\n        if other.lower_value in self:\n            return Interval(self._lower, self._lower_value, other._lower_value, self._opposite_boundary_type(other._lower))\n        if other.upper_value in self:\n            return Interval(self._opposite_boundary_type(other._upper), other._upper_value, self._upper_value, self._upper)\n        return Interval(self._lower, self._lower_value, self._upper_value, self._upper)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a callback which will be called at scheduled intervals with the metrics that have the given tag.", "response": "def register(callback, schedule, tag=None):\n    \"\"\"\n    Register a callback which will be called at scheduled intervals with\n    the metrics that have the given tag (or all the metrics if None).\n    Return an identifier which can be used to access the registered callback later.\n    \"\"\"\n\n    try:\n        iter(schedule)\n    except TypeError:\n        raise TypeError(\"{} is not iterable\".format(schedule))\n\n    if not callable(callback):\n        raise TypeError(\"{} is not callable\".format(callback))\n\n    thread = Timer(schedule, callback, tag)\n\n    id_ = str(uuid.uuid4())\n    with LOCK:\n        REGISTRY[id_] = thread\n\n    thread.start()\n\n    return id_"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the callback and its schedule", "response": "def remove(id_):\n    \"\"\"\n    Remove the callback and its schedule\n    \"\"\"\n    with LOCK:\n        thread = REGISTRY.pop(id_, None)\n        if thread is not None:\n            thread.cancel()\n\n    return thread"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_metrics(tag):\n    if tag is None:\n        return metrics.metrics_by_name_list(metrics.metrics())\n    else:\n        return metrics.metrics_by_tag(tag)", "response": "Returns the metrics with the given tag or all the available metrics"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps the response from a game search into instances and return them", "response": "def wrap_search(cls, response):\n        \"\"\"Wrap the response from a game search into instances\n        and return them\n\n        :param response: The response from searching a game\n        :type response: :class:`requests.Response`\n        :returns: the new game instances\n        :rtype: :class:`list` of :class:`Game`\n        :raises: None\n        \"\"\"\n        games = []\n        json = response.json()\n        gamejsons = json['games']\n        for j in gamejsons:\n            g = cls.wrap_json(j)\n            games.append(g)\n        return games"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wrap_topgames(cls, response):\n        games = []\n        json = response.json()\n        topjsons = json['top']\n        for t in topjsons:\n            g = cls.wrap_json(json=t['game'],\n                              viewers=t['viewers'],\n                              channels=t['channels'])\n            games.append(g)\n        return games", "response": "Wrap the response from quering the top games into instances\n        and return them\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a Game instance for the given json.", "response": "def wrap_json(cls, json, viewers=None, channels=None):\n        \"\"\"Create a Game instance for the given json\n\n        :param json: the dict with the information of the game\n        :type json: :class:`dict`\n        :param viewers: The viewer count\n        :type viewers: :class:`int`\n        :param channels: The viewer count\n        :type channels: :class:`int`\n        :returns: the new game instance\n        :rtype: :class:`Game`\n        :raises: None\n        \"\"\"\n        g = Game(name=json.get('name'),\n                 box=json.get('box'),\n                 logo=json.get('logo'),\n                 twitchid=json.get('_id'),\n                 viewers=viewers,\n                 channels=channels)\n        return g"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping the response from a channel search into instances and return them", "response": "def wrap_search(cls, response):\n        \"\"\"Wrap the response from a channel search into instances\n        and return them\n\n        :param response: The response from searching a channel\n        :type response: :class:`requests.Response`\n        :returns: the new channel instances\n        :rtype: :class:`list` of :class:`channel`\n        :raises: None\n        \"\"\"\n        channels = []\n        json = response.json()\n        channeljsons = json['channels']\n        for j in channeljsons:\n            c = cls.wrap_json(j)\n            channels.append(c)\n        return channels"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap the response from getting a channel into an instance and return it", "response": "def wrap_get_channel(cls, response):\n        \"\"\"Wrap the response from getting a channel into an instance\n        and return it\n\n        :param response: The response from getting a channel\n        :type response: :class:`requests.Response`\n        :returns: the new channel instance\n        :rtype: :class:`list` of :class:`channel`\n        :raises: None\n        \"\"\"\n        json = response.json()\n        c = cls.wrap_json(json)\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a Channel instance for the given json.", "response": "def wrap_json(cls, json):\n        \"\"\"Create a Channel instance for the given json\n\n        :param json: the dict with the information of the channel\n        :type json: :class:`dict`\n        :returns: the new channel instance\n        :rtype: :class:`Channel`\n        :raises: None\n        \"\"\"\n        c = Channel(name=json.get('name'),\n                    status=json.get('status'),\n                    displayname=json.get('display_name'),\n                    game=json.get('game'),\n                    twitchid=json.get('_id'),\n                    views=json.get('views'),\n                    followers=json.get('followers'),\n                    url=json.get('url'),\n                    language=json.get('language'),\n                    broadcaster_language=json.get('broadcaster_language'),\n                    mature=json.get('mature'),\n                    logo=json.get('logo'),\n                    banner=json.get('banner'),\n                    video_banner=json.get('video_banner'),\n                    delay=json.get('delay'))\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wrap_search(cls, response):\n        streams = []\n        json = response.json()\n        streamjsons = json['streams']\n        for j in streamjsons:\n            s = cls.wrap_json(j)\n            streams.append(s)\n        return streams", "response": "Wrap the response from a stream search into instances\n        and return them\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps the response from getting a stream into an instance and return it", "response": "def wrap_get_stream(cls, response):\n        \"\"\"Wrap the response from getting a stream into an instance\n        and return it\n\n        :param response: The response from getting a stream\n        :type response: :class:`requests.Response`\n        :returns: the new stream instance\n        :rtype: :class:`list` of :class:`stream`\n        :raises: None\n        \"\"\"\n        json = response.json()\n        s = cls.wrap_json(json['stream'])\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new Stream instance for the given json.", "response": "def wrap_json(cls, json):\n        \"\"\"Create a Stream instance for the given json\n\n        :param json: the dict with the information of the stream\n        :type json: :class:`dict` | None\n        :returns: the new stream instance\n        :rtype: :class:`Stream` | None\n        :raises: None\n        \"\"\"\n        if json is None:\n            return None\n        channel = Channel.wrap_json(json.get('channel'))\n        s = Stream(game=json.get('game'),\n                   channel=channel,\n                   twitchid=json.get('_id'),\n                   viewers=json.get('viewers'),\n                   preview=json.get('preview'))\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap the response from getting a user into an instance and return it", "response": "def wrap_get_user(cls, response):\n        \"\"\"Wrap the response from getting a user into an instance\n        and return it\n\n        :param response: The response from getting a user\n        :type response: :class:`requests.Response`\n        :returns: the new user instance\n        :rtype: :class:`list` of :class:`User`\n        :raises: None\n        \"\"\"\n        json = response.json()\n        u = cls.wrap_json(json)\n        return u"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wrap_json(cls, json):\n        u = User(usertype=json['type'],\n                 name=json['name'],\n                 logo=json['logo'],\n                 twitchid=json['_id'],\n                 displayname=json['display_name'],\n                 bio=json['bio'])\n        return u", "response": "Create a User instance for the given json."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap a method of IRCCLient. out_connection so it gets executed by the reactor", "response": "def _wrap_execute_after(funcname):\n    \"\"\"Warp the given method, so it gets executed by the reactor\n\n    Wrap a method of :data:`IRCCLient.out_connection`.\n\n    The returned function should be assigned to a :class:`irc.client.SimpleIRCClient` class.\n\n    :param funcname: the name of a :class:`irc.client.ServerConnection` method\n    :type funcname: :class:`str`\n    :returns: a new function, that executes the given one via :class:`irc.schedule.IScheduler.execute_after`\n    :raises: None\n    \"\"\"\n    def method(self, *args, **kwargs):\n        f = getattr(self.out_connection, funcname)\n        p = functools.partial(f, *args, **kwargs)\n        self.reactor.scheduler.execute_after(0, p)\n    method.__name__ = funcname\n    return method"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds methods to an IRCClient class.", "response": "def add_serverconnection_methods(cls):\n    \"\"\"Add a bunch of methods to an :class:`irc.client.SimpleIRCClient`\n    to send commands and messages.\n\n    Basically it wraps a bunch of methdos from\n    :class:`irc.client.ServerConnection` to be\n    :meth:`irc.schedule.IScheduler.execute_after`.\n    That way, you can easily send, even if the IRCClient is running in\n    :class:`IRCClient.process_forever` in another thread.\n\n    On the plus side you can use positional and keyword arguments instead of just positional ones.\n\n    :param cls: The class to add the methods do.\n    :type cls: :class:`irc.client.SimpleIRCClient`\n    :returns: None\n    \"\"\"\n    methods = ['action', 'admin', 'cap', 'ctcp', 'ctcp_reply',\n               'globops', 'info', 'invite', 'ison', 'join',\n               'kick', 'links', 'list', 'lusers', 'mode',\n               'motd', 'names', 'nick', 'notice', 'oper', 'part',\n               'part', 'pass_', 'ping', 'pong', 'privmsg',\n               'privmsg_many', 'quit', 'send_raw', 'squit',\n               'stats', 'time', 'topic', 'trace', 'user', 'userhost',\n               'users', 'version', 'wallops', 'who', 'whois', 'whowas']\n    for m in methods:\n        method = _wrap_execute_after(m)\n        f = getattr(irc.client.ServerConnection, m)\n        method.__doc__ = f.__doc__\n        setattr(cls, method.__name__, method)\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_forever(self, timeout=0.2):\n        # This loop should specifically *not* be mutex-locked.\n        # Otherwise no other thread would ever be able to change\n        # the shared state of a Reactor object running this function.\n        log.debug(\"process_forever(timeout=%s)\", timeout)\n        self._looping.set()\n        while self._looping.is_set():\n            self.process_once(timeout)", "response": "This method runs an infinite loop processing data from connections."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisconnecting all connections and end the loop", "response": "def shutdown(self):\n        \"\"\"Disconnect all connections and end the loop\n\n        :returns: None\n        :rtype: None\n        :raises: None\n        \"\"\"\n        log.debug('Shutting down %s' % self)\n        self.disconnect_all()\n        self._looping.clear()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate and returns a ServerConnection3 object.", "response": "def server(self, ):\n        \"\"\"Creates and returns a ServerConnection\n\n        :returns: a server connection\n        :rtype: :class:`connection.ServerConnection3`\n        :raises: None\n        \"\"\"\n        c = connection.ServerConnection3(self)\n        with self.mutex:\n            self.connections.append(c)\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_run(shell, no_daemon, daemon_options, daemon_outfile):\n    import sys\n    from .__init__ import __version__\n    init_file = find_init(shell)\n    if os.path.exists(init_file):\n        sys.stdout.write(INIT_TEMPLATE.format(\n            file=init_file, version=__version__))\n    else:\n        raise RuntimeError(\n            \"Shell '{0}' is not supported.\".format(shell_name(shell)))\n\n    if not no_daemon:\n        from .daemon import start_daemon_in_subprocess\n        start_daemon_in_subprocess(daemon_options, daemon_outfile)", "response": "Configure your shell.\n\n    Add the following line in your shell RC file and then you are\n    ready to go::\n\n      eval $(%(prog)s)\n\n    To check if your shell is supported, simply run::\n\n      %(prog)s --no-daemon\n\n    If you want to specify shell other than $SHELL, you can give\n    --shell option::\n\n      eval $(%(prog)s --shell zsh)\n\n    By default, this command also starts daemon in background to\n    automatically index shell history records.  To not start daemon,\n    use --no-daemon option like this::\n\n      eval $(%(prog)s --no-daemon)\n\n    To see the other methods to launch the daemon process, see\n    ``rash daemon --help``."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to categorize data file in a node", "response": "def cache_file(symbol, func, has_date, root, date_type='date'):\n    \"\"\"\n    Data file\n\n    Args:\n        symbol: symbol\n        func: use function to categorize data\n        has_date: contains date in data file\n        root: root path\n        date_type: parameters pass to utils.cur_time, [date, time, time_path, ...]\n\n    Returns:\n        str: date file\n    \"\"\"\n    cur_mod = sys.modules[func.__module__]\n    data_tz = getattr(cur_mod, 'DATA_TZ') if hasattr(cur_mod, 'DATA_TZ') else 'UTC'\n    cur_dt = utils.cur_time(typ=date_type, tz=data_tz, trading=False)\n\n    if has_date:\n        if hasattr(cur_mod, 'FILE_WITH_DATE'):\n            file_fmt = getattr(cur_mod, 'FILE_WITH_DATE')\n        else:\n            file_fmt = '{root}/{typ}/{symbol}/{cur_dt}.parq'\n    else:\n        if hasattr(cur_mod, 'FILE_NO_DATE'):\n            file_fmt = getattr(cur_mod, 'FILE_NO_DATE')\n        else:\n            file_fmt = '{root}/{typ}/{symbol}.parq'\n\n    return data_file(\n        file_fmt=file_fmt, root=root, cur_dt=cur_dt, typ=func.__name__, symbol=symbol\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving data to file in terms of f - strings.", "response": "def save_data(data, file_fmt, append=False, drop_dups=None, info=None, **kwargs):\n    \"\"\"\n    Save data to file\n\n    Args:\n        data: pd.DataFrame\n        file_fmt: data file format in terms of f-strings\n        append: if append data to existing data\n        drop_dups: list, drop duplicates in columns\n        info: dict, infomation to be hashed and passed to f-strings\n        **kwargs: additional parameters for f-strings\n\n    Examples:\n        >>> data = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n        >>> # save_data(\n        >>>     # data, '{ROOT}/daily/{typ}.parq',\n        >>>     # ROOT='tests/data', typ='earnings'\n        >>> # )\n    \"\"\"\n    d_file = data_file(file_fmt=file_fmt, info=info, **kwargs)\n    if append and files.exists(d_file):\n        data = pd.DataFrame(pd.concat([pd.read_parquet(d_file), data], sort=False))\n        if drop_dups is not None:\n            data.drop_duplicates(subset=utils.tolist(drop_dups), inplace=True)\n\n    if not data.empty: data.to_parquet(d_file)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef data_file(file_fmt, info=None, **kwargs):\n    if isinstance(info, dict):\n        kwargs['hash_key'] = hashlib.sha256(json.dumps(info).encode('utf-8')).hexdigest()\n        kwargs.update(info)\n\n    return utils.fstr(fmt=file_fmt, **kwargs)", "response": "Returns the name of the data file for given infomation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_multi(data, cols=None, spacing=.06, color_map=None, plot_kw=None, **kwargs):\n    import matplotlib.pyplot as plt\n    from pandas import plotting\n\n    if cols is None: cols = data.columns\n    if plot_kw is None: plot_kw = [{}] * len(cols)\n    if len(cols) == 0: return\n    num_colors = len(utils.flatten(cols))\n\n    # Get default color style from pandas\n    colors = getattr(getattr(plotting, '_style'), '_get_standard_colors')(num_colors=num_colors)\n    if color_map is None: color_map = dict()\n\n    fig = plt.figure()\n    ax, lines, labels, c_idx = None, [], [], 0\n    for n, col in enumerate(cols):\n        if isinstance(col, (list, tuple)):\n            ylabel = ' / '.join(cols[n])\n            color = [\n                color_map.get(cols[n][_ - c_idx], colors[_ % len(colors)])\n                for _ in range(c_idx, c_idx + len(cols[n]))\n            ]\n            c_idx += len(col)\n        else:\n            ylabel = col\n            color = color_map.get(col, colors[c_idx % len(colors)])\n            c_idx += 1\n        if 'color' in plot_kw[n]: color = plot_kw[n].pop('color')\n\n        if ax is None:\n            # First y-axes\n            legend = plot_kw[0].pop('legend', kwargs.pop('legend', False))\n            ax = data.loc[:, col].plot(\n                label=col, color=color, legend=legend, zorder=n, **plot_kw[0], **kwargs\n            )\n            ax.set_ylabel(ylabel=ylabel)\n            line, label = ax.get_legend_handles_labels()\n            ax.spines['left'].set_edgecolor('#D5C4A1')\n            ax.spines['left'].set_alpha(.5)\n\n        else:\n            # Multiple y-axes\n            legend = plot_kw[n].pop('legend', False)\n            ax_new = ax.twinx()\n            ax_new.spines['right'].set_position(('axes', 1 + spacing * (n - 1)))\n            data.loc[:, col].plot(\n                ax=ax_new, label=col, color=color, legend=legend, zorder=n, **plot_kw[n]\n            )\n            ax_new.set_ylabel(ylabel=ylabel)\n            line, label = ax_new.get_legend_handles_labels()\n            ax_new.spines['right'].set_edgecolor('#D5C4A1')\n            ax_new.spines['right'].set_alpha(.5)\n            ax_new.grid(False)\n\n        # Proper legend position\n        lines += line\n        labels += label\n\n    fig.legend(lines, labels, loc=8, prop=dict(), ncol=num_colors).set_zorder(len(cols))\n    ax.set_xlabel(' \\n ')\n\n    return ax", "response": "Plot data with multiple scaels together"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting horizontally the data for the available base classes.", "response": "def plot_h(data, cols, wspace=.1, plot_kw=None, **kwargs):\n    \"\"\"\n    Plot horizontally\n\n    Args:\n        data: DataFrame of data\n        cols: columns to be plotted\n        wspace: spacing between plots\n        plot_kw: kwargs for each plot\n        **kwargs: kwargs for the whole plot\n\n    Returns:\n        axes for plots\n\n    Examples:\n        >>> import pandas as pd\n        >>> import numpy as np\n        >>>\n        >>> idx = range(5)\n        >>> data = pd.DataFrame(dict(a=np.exp(idx), b=idx), index=idx)\n        >>> # plot_h(data=data, cols=['a', 'b'], wspace=.2, plot_kw=[dict(style='.-'), dict()])\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if plot_kw is None: plot_kw = [dict()] * len(cols)\n\n    _, axes = plt.subplots(nrows=1, ncols=len(cols), **kwargs)\n    plt.subplots_adjust(wspace=wspace)\n    for n, col in enumerate(cols):\n        data.loc[:, col].plot(ax=axes[n], **plot_kw[n])\n\n    return axes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nindex raw JSON records into sqlite3 DB.", "response": "def index_run(record_path, keep_json, check_duplicate):\n    \"\"\"\n    Convert raw JSON records into sqlite3 DB.\n\n    Normally RASH launches a daemon that takes care of indexing.\n    See ``rash daemon --help``.\n\n    \"\"\"\n    from .config import ConfigStore\n    from .indexer import Indexer\n    cfstore = ConfigStore()\n    indexer = Indexer(cfstore, check_duplicate, keep_json, record_path)\n    indexer.index_all()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all available data logging sessions.", "response": "def list(self):\n        \"\"\"\n        List all available data logging sessions\n        \"\"\"\n\n        # We have to open this queue before we make the request, to ensure we don't miss the response.\n        queue = self._pebble.get_endpoint_queue(DataLogging)\n\n        self._pebble.send_packet(DataLogging(data=DataLoggingReportOpenSessions(sessions=[])))\n\n        sessions = []\n        while True:\n            try:\n                result = queue.get(timeout=2).data\n            except TimeoutError:\n                break\n            if isinstance(result, DataLoggingDespoolOpenSession):\n                self._pebble.send_packet(DataLogging(data=DataLoggingACK(\n                                                     session_id=result.session_id)))\n                sessions.append(result.__dict__)\n\n        queue.close()\n        return sessions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading a specific session.", "response": "def download(self, session_id):\n        \"\"\"\n        Download a specific session. \n        Returns (session_info, data)\n        \"\"\"\n\n        # We have to open this queue before we make the request, to ensure we don't miss the response.\n        queue = self._pebble.get_endpoint_queue(DataLogging)\n\n        # First, we need to open up all sessions\n        self._pebble.send_packet(DataLogging(data=DataLoggingReportOpenSessions(sessions=[])))\n\n        session = None\n        while True:\n            try:\n                result = queue.get(timeout=2).data\n            except TimeoutError:\n                break\n\n            if isinstance(result, DataLoggingDespoolOpenSession):\n                self._pebble.send_packet(DataLogging(data=DataLoggingACK(\n                                                          session_id=result.session_id)))\n                if session is None and result.session_id == session_id:\n                    session = result\n\n        if session is None:\n            queue.close()\n            return (None, None)\n\n\n        # -----------------------------------------------------------------------------\n        # Request an empty of this session\n        logger.info(\"Requesting empty of session {}\".format(session_id))\n        self._pebble.send_packet(DataLogging(data=DataLoggingEmptySession(session_id=session_id)))\n        data = None\n        timeout_count = 0\n        while True:\n            logger.debug(\"Looping again. Time: {}\".format(datetime.datetime.now()))\n            try:\n                result = queue.get(timeout=5).data\n                timeout_count = 0\n            except TimeoutError:\n                logger.debug(\"Got timeout error Time: {}\".format(datetime.datetime.now()))\n                timeout_count += 1\n                if timeout_count >= 2:\n                    break\n                else:\n                    self._pebble.send_packet(DataLogging(data=DataLoggingEmptySession(\n                                             session_id=session_id)))\n                    continue\n\n            if isinstance(result, DataLoggingDespoolSendData):\n                if result.session_id != session_id:\n                    self._pebble.send_packet(DataLogging(\n                        data=DataLoggingNACK(session_id=result.session_id)))\n                else:\n                    logger.info(\"Received {} bytes of data: {}\".format(len(result.data), result))\n                    if data is None:\n                        data = result.data\n                    else:\n                        data += result.data\n                    self._pebble.send_packet(DataLogging(\n                                             data=DataLoggingACK(session_id=session_id)))\n\n        queue.close()\n        return (session, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_send_enable(self):\n\n        # We have to open this queue before we make the request, to ensure we don't miss the response.\n        queue = self._pebble.get_endpoint_queue(DataLogging)\n\n        self._pebble.send_packet(DataLogging(data=DataLoggingGetSendEnableRequest()))\n        enabled = False\n        while True:\n            result = queue.get().data\n            if isinstance(result, DataLoggingGetSendEnableResponse):\n                enabled = result.enabled\n                break\n\n        queue.close()\n        return enabled", "response": "Return true if sending of sessions is enabled on the watch\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_send_enable(self, setting):\n        self._pebble.send_packet(DataLogging(data=DataLoggingSetSendEnable(enabled=setting)))", "response": "Set the send enable setting on the watch\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert any representation of level to an int appropriately.", "response": "def loglevel(level):\n    \"\"\"\n    Convert any representation of `level` to an int appropriately.\n\n    :type level: int or str\n    :rtype: int\n\n    >>> loglevel('DEBUG') == logging.DEBUG\n    True\n    >>> loglevel(10)\n    10\n    >>> loglevel(None)\n    Traceback (most recent call last):\n      ...\n    ValueError: None is not a proper log level.\n\n    \"\"\"\n    if isinstance(level, str):\n        level = getattr(logging, level.upper())\n    elif isinstance(level, int):\n        pass\n    else:\n        raise ValueError('{0!r} is not a proper log level.'.format(level))\n    return level"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattaches file handler to RASH logger. :type cfstore: rash.config.ConfigStore", "response": "def setup_daemon_log_file(cfstore):\n    \"\"\"\n    Attach file handler to RASH logger.\n\n    :type cfstore: rash.config.ConfigStore\n\n    \"\"\"\n    level = loglevel(cfstore.daemon_log_level)\n    handler = logging.FileHandler(filename=cfstore.daemon_log_path)\n    handler.setLevel(level)\n    logger.setLevel(level)\n    logger.addHandler(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserializes an argument tuple or Fault instance to an XML - RPC data structure.", "response": "def dumps(params, methodname=None, methodresponse=None, encoding=None,\n          allow_none=0, utf8_encoding='standard'):\n    \"\"\"data [,options] -> marshalled data\n\n    Convert an argument tuple or a Fault instance to an XML-RPC\n    request (or response, if the methodresponse option is used).\n\n    In addition to the data object, the following options can be given\n    as keyword arguments:\n\n        methodname: the method name for a methodCall packet\n\n        methodresponse: true to create a methodResponse packet.\n        If this option is used with a tuple, the tuple must be\n        a singleton (i.e. it can contain only one element).\n\n        encoding: the packet encoding (default is UTF-8)\n\n    All 8-bit strings in the data structure are assumed to use the\n    packet encoding.  Unicode strings are automatically converted,\n    where necessary.\n    \"\"\"\n\n    assert isinstance(params, TupleType) or isinstance(params, Fault),\\\n           \"argument must be tuple or Fault instance\"\n\n    if isinstance(params, Fault):\n        methodresponse = 1\n    elif methodresponse and isinstance(params, TupleType):\n        assert len(params) == 1, \"response tuple must be a singleton\"\n\n    if not encoding:\n        encoding = \"utf-8\"\n\n    if FastMarshaller:\n        m = FastMarshaller(encoding)\n    else:\n        m = Marshaller(encoding, allow_none)\n\n    data = m.dumps(params)\n\n    if encoding != \"utf-8\":\n        xmlheader = \"<?xml version='1.0' encoding='%s'?>\\n\" % str(encoding)\n    else:\n        xmlheader = \"<?xml version='1.0'?>\\n\" # utf-8 is default\n\n    # standard XML-RPC wrappings\n    if methodname:\n        # a method call\n        if not isinstance(methodname, StringType):\n            methodname = methodname.encode(encoding)\n        data = (\n            xmlheader,\n            \"<methodCall>\\n\"\n            \"<methodName>\", methodname, \"</methodName>\\n\",\n            data,\n            \"</methodCall>\\n\"\n            )\n    elif methodresponse:\n        # a method response, or a fault structure\n        data = (\n            xmlheader,\n            \"<methodResponse>\\n\",\n            data,\n            \"</methodResponse>\\n\"\n            )\n    else:\n        return data # return as is\n    return string.join(data, \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gzip_encode(data):\n    if not gzip:\n        raise NotImplementedError\n    f = StringIO.StringIO()\n    gzf = gzip.GzipFile(mode=\"wb\", fileobj=f, compresslevel=1)\n    gzf.write(data)\n    gzf.close()\n    encoded = f.getvalue()\n    f.close()\n    return encoded", "response": "Encode data using the gzip content encoding as described in RFC 1952\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode gzip encoded data using the RFC 1952", "response": "def gzip_decode(data, max_decode=20971520):\n    \"\"\"gzip encoded data -> unencoded data\n\n    Decode data using the gzip content encoding as described in RFC 1952\n    \"\"\"\n    if not gzip:\n        raise NotImplementedError\n    f = StringIO.StringIO(data)\n    gzf = gzip.GzipFile(mode=\"rb\", fileobj=f)\n    try:\n        if max_decode < 0: # no limit\n            decoded = gzf.read()\n        else:\n            decoded = gzf.read(max_decode + 1)\n    except IOError:\n        raise ValueError(\"invalid data\")\n    f.close()\n    gzf.close()\n    if max_decode >= 0 and len(decoded) > max_decode:\n        raise ValueError(\"max gzipped payload length exceeded\")\n    return decoded"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the list column headers.", "response": "def result_headers(context, cl): \n    \"\"\"\n    Generates the list column headers.\n    \"\"\"\n    for i, field_name in enumerate(cl.list_display):\n        text, attr = label_for_field(field_name, cl.model, return_attr=True)\n        if attr:\n            # Potentially not sortable\n\n            # if the field is the action checkbox: no sorting and special class\n            if field_name == 'action_checkbox':\n                yield {\n                    \"text\": text,\n                    \"class_attrib\": mark_safe(' class=\"action-checkbox-column\"'),\n                    \"sortable\": False,\n                }\n                continue\n\n#            if other_fields like Edit, Visualize, etc:\n                # Not sortable\n#                yield {\n#                    \"text\": text,\n#                    \"class_attrib\": format_html(' class=\"column-{0}\"', field_name),\n#                    \"sortable\": False,\n#                }\n#                continue\n\n        # OK, it is sortable if we got this far\n        th_classes = ['sortable', 'column-{0}'.format(field_name)]\n        ascending = None\n        is_sorted = False\n        # Is it currently being sorted on?\n        if context.get('current_sort_field') == str(i + 1):\n            is_sorted = True\n            ascending = False\n            th_classes.append('sorted descending')\n        elif context.get('current_sort_field') == '-'+str(i + 1):\n            is_sorted = True\n            ascending = True\n            th_classes.append('sorted ascending')\n\n        if 'request' in context:\n            url = context['request'].path\n        else:\n            url = \"./\"\n\n### TODO: when start using action_checkbox use i instead of i + 1. This +1 is to correct enumerate index\n        # builds url\n        url += \"?sort_by=\"\n\n        if ascending is False:\n            url += \"-\"\n        url += str(i + 1)\n\n        if 'getsortvars' in context:\n            extra_vars = context['getsortvars']\n        else:\n            if 'request' in context:\n                request = context['request']\n                getvars = request.GET.copy()\n                if 'sort_by' in getvars:\n                    del getvars['sort_by']\n                if len(getvars.keys()) > 0:\n                    context['getsortvars'] = \"&%s\" % getvars.urlencode()\n                else:\n                    context['getsortvars'] = ''\n                extra_vars = context['getsortvars']\n\n        # append other vars to url\n        url += extra_vars\n\n        yield {\n            \"text\": text,\n            \"url\": url,\n            \"sortable\": True,\n            \"sorted\": is_sorted,\n            \"ascending\": ascending,\n            \"class_attrib\": format_html(' class=\"{0}\"', ' '.join(th_classes)) if th_classes else '',\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sort_headers(context, cl):\n    headers = list(result_headers(context, cl))\n    sorted_fields = False\n    for h in headers:\n        if h['sortable'] and h['sorted']:\n            sorted_fields = True\n    return {'cl': cl,\n            'result_headers': headers,\n            'sorted_fields': sorted_fields}", "response": "Displays the headers and data list together"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef auto_sort(parser, token):\n    \"usage: {% auto_sort queryset %}\"\n    try:\n        tag_name, queryset = token.split_contents()\n    except ValueError:\n        raise template.TemplateSyntaxError(\"{0} tag requires a single argument\".format(token.contents.split()[0]))\n    return SortedQuerysetNode(queryset)", "response": "usage : auto_sort queryset"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a tag object from a string representation of the irc protocol.", "response": "def from_str(cls, tagstring):\n        \"\"\"Create a tag by parsing the tag of a message\n\n        :param tagstring: A tag string described in the irc protocol\n        :type tagstring: :class:`str`\n        :returns: A tag\n        :rtype: :class:`Tag`\n        :raises: None\n        \"\"\"\n        m = cls._parse_regexp.match(tagstring)\n        return cls(name=m.group('name'), value=m.group('value'), vendor=m.group('vendor'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_str(cls, emotestr):\n        emoteid, occstr = emotestr.split(':')\n        occurences = []\n        for occ in occstr.split(','):\n            start, end = occ.split('-')\n            occurences.append((int(start), int(end)))\n        return cls(int(emoteid), occurences)", "response": "Create an emote from a string representation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a message from an event object.", "response": "def from_event(cls, event):\n        \"\"\"Create a message from an event\n\n        :param event: the event that was received of type ``pubmsg`` or ``privmsg``\n        :type event: :class:`Event3`\n        :returns: a message that resembles the event\n        :rtype: :class:`Message3`\n        :raises: None\n        \"\"\"\n        source = Chatter(event.source)\n        return cls(source, event.target, event.arguments[0], event.tags)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the appropriate attribute for each known tag.", "response": "def set_tags(self, tags):\n        \"\"\"For every known tag, set the appropriate attribute.\n\n        Known tags are:\n\n            :color: The user color\n            :emotes: A list of emotes\n            :subscriber: True, if subscriber\n            :turbo: True, if turbo user\n            :user_type: None, mod, staff, global_mod, admin\n\n        :param tags: a list of tags\n        :type tags: :class:`list` of :class:`Tag` | None\n        :returns: None\n        :rtype: None\n        :raises: None\n        \"\"\"\n        if tags is None:\n            return\n        attrmap = {'color': 'color', 'emotes': 'emotes',\n                   'subscriber': 'subscriber',\n                   'turbo': 'turbo', 'user-type': 'user_type'}\n        for t in tags:\n            attr = attrmap.get(t.name)\n            if not attr:\n                continue\n            else:\n                setattr(self, attr, t.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef emotes(self, emotes):\n        if emotes is None:\n            self._emotes = []\n            return\n        es = []\n        for estr in emotes.split('/'):\n            es.append(Emote.from_str(estr))\n        self._emotes = es", "response": "Set the emotes of a tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsumming of a list of numeric data.", "response": "def sum(data, start=0):\n    \"\"\"sum(data [, start]) -> value\n\n    Return a high-precision sum of the given numeric data. If optional\n    argument ``start`` is given, it is added to the total. If ``data`` is\n    empty, ``start`` (defaulting to 0) is returned.\n    \"\"\"\n    n, d = exact_ratio(start)\n    T = type(start)\n    partials = {d: n}  # map {denominator: sum of numerators}\n    # Micro-optimizations.\n    coerce_types_ = coerce_types\n    exact_ratio_ = exact_ratio\n    partials_get = partials.get\n    # Add numerators for each denominator, and track the \"current\" type.\n    for x in data:\n        T = coerce_types_(T, type(x))\n        n, d = exact_ratio_(x)\n        partials[d] = partials_get(d, 0) + n\n    if None in partials:\n        assert issubclass(T, (float, Decimal))\n        assert not isfinite(partials[None])\n        return T(partials[None])\n    total = Fraction()\n    for d, n in sorted(partials.items()):\n        total += Fraction(n, d)\n    if issubclass(T, int):\n        assert total.denominator == 1\n        return T(total.numerator)\n    if issubclass(T, Decimal):\n        return T(total.numerator) / total.denominator\n    return T(total)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts Real number x exactly to numerator denominator pair.", "response": "def exact_ratio(x):\n    \"\"\"Convert Real number x exactly to (numerator, denominator) pair.\n\n    x is expected to be an int, Fraction, Decimal or float.\n    \"\"\"\n    try:\n        try:\n            # int, Fraction\n            return x.numerator, x.denominator\n        except AttributeError:\n            # float\n            try:\n                return x.as_integer_ratio()\n            except AttributeError:\n                # Decimal\n                try:\n                    return decimal_to_ratio(x)\n                except AttributeError:\n                    msg = \"can't convert type '{}' to numerator/denominator\"\n                    raise TypeError(msg.format(type(x).__name__))\n    except (OverflowError, ValueError):\n        # INF or NAN\n        return (x, None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a decimal number to an exact integer ratio.", "response": "def decimal_to_ratio(d):\n    \"\"\"Convert Decimal d to exact integer ratio (numerator, denominator).\n    \"\"\"\n    sign, digits, exp = d.as_tuple()\n    if exp in ('F', 'n', 'N'):  # INF, NAN, sNAN\n        assert not d.is_finite()\n        raise ValueError\n    num = 0\n    for digit in digits:\n        num = num * 10 + digit\n    if sign:\n        num = -num\n    den = 10 ** -exp\n    return (num, den)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncoerce types T1 and T2 to a common type.", "response": "def coerce_types(T1, T2):\n    \"\"\"Coerce types T1 and T2 to a common type.\n\n    Coercion is performed according to this table, where \"N/A\" means\n    that a TypeError exception is raised.\n\n    +----------+-----------+-----------+-----------+----------+\n    |          | int       | Fraction  | Decimal   | float    |\n    +----------+-----------+-----------+-----------+----------+\n    | int      | int       | Fraction  | Decimal   | float    |\n    | Fraction | Fraction  | Fraction  | N/A       | float    |\n    | Decimal  | Decimal   | N/A       | Decimal   | float    |\n    | float    | float     | float     | float     | float    |\n    +----------+-----------+-----------+-----------+----------+\n\n    Subclasses trump their parent class; two subclasses of the same\n    base class will be coerced to the second of the two.\n\n    \"\"\"\n    # Get the common/fast cases out of the way first.\n    if T1 is T2: return T1\n    if T1 is int: return T2\n    if T2 is int: return T1\n    # Subclasses trump their parent class.\n    if issubclass(T2, T1): return T2\n    if issubclass(T1, T2): return T1\n    # Floats trump everything else.\n    if issubclass(T2, float): return T2\n    if issubclass(T1, float): return T1\n    # Subclasses of the same base class give priority to the second.\n    if T1.__base__ is T2.__base__: return T2\n    # Otherwise, just give up.\n    raise TypeError('cannot coerce types %r and %r' % (T1, T2))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a table of sorted ( value frequency ) pairs.", "response": "def counts(data):\n    \"\"\"\n    Generate a table of sorted (value, frequency) pairs.\n    \"\"\"\n    if data is None:\n        raise TypeError('None is not iterable')\n    table = collections.Counter(data).most_common()\n    if not table:\n        return table\n        # Extract the values with the highest frequency.\n    maxfreq = table[0][1]\n    for i in range(1, len(table)):\n        if table[i][1] != maxfreq:\n            table = table[:i]\n            break\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mean(data):\n    if iter(data) is data:\n        data = list(data)\n    n = len(data)\n    if n < 1:\n        raise StatisticsError('mean requires at least one data point')\n    return sum(data) / n", "response": "Return the sample arithmetic mean of data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef median(data):\n    data = sorted(data)\n    n = len(data)\n    if n == 0:\n        raise StatisticsError(\"no median for empty data\")\n    if n % 2 == 1:\n        return data[n // 2]\n    else:\n        i = n // 2\n        return (data[i - 1] + data[i]) / 2", "response": "Return the median of numeric data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the low median of numeric data.", "response": "def median_low(data):\n    \"\"\"Return the low median of numeric data.\n\n    When the number of data points is odd, the middle value is returned.\n    When it is even, the smaller of the two middle values is returned.\n    \"\"\"\n    data = sorted(data)\n    n = len(data)\n    if n == 0:\n        raise StatisticsError(\"no median for empty data\")\n    if n % 2 == 1:\n        return data[n // 2]\n    else:\n        return data[n // 2 - 1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the high median of data.", "response": "def median_high(data):\n    \"\"\"Return the high median of data.\n\n    When the number of data points is odd, the middle value is returned.\n    When it is even, the larger of the two middle values is returned.\n\n    \"\"\"\n    data = sorted(data)\n    n = len(data)\n    if n == 0:\n        raise StatisticsError(\"no median for empty data\")\n    return data[n // 2]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mode(data):\n    # Generate a table of sorted (value, frequency) pairs.\n    table = counts(data)\n    if len(table) == 1:\n        return table[0][0]\n    elif table:\n        raise StatisticsError(\n            'no unique mode; found %d equally common values' % len(table)\n        )\n    else:\n        raise StatisticsError('no mode for empty data')", "response": "Return the most common data point from discrete or nominal data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ss(data, c=None):\n    if c is None:\n        c = mean(data)\n    ss = sum((x - c) ** 2 for x in data)\n    # The following sum should mathematically equal zero, but due to rounding\n    # error may not.\n    ss -= sum((x - c) for x in data) ** 2 / len(data)\n    assert not ss < 0, 'negative sum of square deviations: %f' % ss\n    return ss", "response": "Calculate the sum of square deviations of sequence data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef variance(data, xbar=None):\n    if iter(data) is data:\n        data = list(data)\n    n = len(data)\n    if n < 2:\n        raise StatisticsError('variance requires at least two data points')\n    ss = _ss(data, xbar)\n    return ss / (n - 1)", "response": "Return the sample variance of data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the population variance of data.", "response": "def pvariance(data, mu=None):\n    \"\"\"Return the population variance of ``data``.\n\n    data should be an iterable of Real-valued numbers, with at least one\n    value. The optional argument mu, if given, should be the mean of\n    the data. If it is missing or None, the mean is automatically calculated.\n\n    Use this function to calculate the variance from the entire population.\n    To estimate the variance from a sample, the ``variance`` function is\n    usually a better choice.\n\n    If you have already calculated the mean of the data, you can pass it as\n    the optional second argument to avoid recalculating it:\n\n\n    This function does not check that ``mu`` is actually the mean of ``data``.\n    Giving arbitrary values for ``mu`` may lead to invalid or impossible\n    results.\n\n    Decimals and Fractions are supported:\n\n\n    \"\"\"\n    if iter(data) is data:\n        data = list(data)\n    n = len(data)\n    if n < 1:\n        raise StatisticsError('pvariance requires at least one data point')\n    ss = _ss(data, mu)\n    return ss / n"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the square root of the sample variance.", "response": "def stdev(data, xbar=None):\n    \"\"\"Return the square root of the sample variance.\n\n    See ``variance`` for arguments and other details.\n\n    \"\"\"\n    var = variance(data, xbar)\n    try:\n        return var.sqrt()\n    except AttributeError:\n        return math.sqrt(var)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the square root of the population variance.", "response": "def pstdev(data, mu=None):\n    \"\"\"Return the square root of the population variance.\n\n    See ``pvariance`` for arguments and other details.\n\n    \"\"\"\n    var = pvariance(data, mu)\n    try:\n        return var.sqrt()\n    except AttributeError:\n        return math.sqrt(var)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the geometric mean of data", "response": "def geometric_mean(data):\n    \"\"\"Return the geometric mean of data\n    \"\"\"\n\n    if not data:\n        raise StatisticsError('geometric_mean requires at least one data point')\n\n    # in order to support negative or null values\n    data = [x if x > 0 else math.e if x == 0 else 1.0 for x in data]\n\n    return math.pow(math.fabs(functools.reduce(operator.mul, data)), 1.0 / len(data))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef harmonic_mean(data):\n\n    if not data:\n        raise StatisticsError('harmonic_mean requires at least one data point')\n\n    divisor = sum(map(lambda x: 1.0 / x if x else 0.0, data))\n    return len(data) / divisor if divisor else 0.0", "response": "Return the harmonic mean of data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kurtosis(data):\n\n    if not data:\n        raise StatisticsError('kurtosis requires at least one data point')\n\n    size = len(data)\n    sd = stdev(data) ** 4\n\n    if not sd:\n        return 0.0\n\n    mn = mean(data)\n    return sum(map(lambda x: ((x - mn) ** 4 / sd), data)) / size - 3", "response": "Return the kurtosis of the data s distribution"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the n - th percentile of the given data", "response": "def percentile(data, n):\n    \"\"\"Return the n-th percentile of the given data\n\n    Assume that the data are already sorted\n\n    \"\"\"\n\n    size = len(data)\n    idx = (n / 100.0) * size - 0.5\n\n    if idx < 0 or idx > size:\n        raise StatisticsError(\"Too few data points ({}) for {}th percentile\".format(size, n))\n\n    return data[int(idx)]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_histogram(data):\n\n    count = len(data)\n\n    if count < 2:\n        raise StatisticsError('Too few data points ({}) for get_histogram'.format(count))\n\n    min_ = data[0]\n    max_ = data[-1]\n    std = stdev(data)\n\n    bins = get_histogram_bins(min_, max_, std, count)\n\n    res = {x: 0 for x in bins}\n\n    for value in data:\n        for bin_ in bins:\n            if value <= bin_:\n                res[bin_] += 1\n                break\n\n    return sorted(iteritems(res))", "response": "Return the histogram relative to the given data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_histogram_bins(min_, max_, std, count):\n\n    width = _get_bin_width(std, count)\n    count = int(round((max_ - min_) / width) + 1)\n\n    if count:\n        bins = [i * width + min_ for i in xrange(1, count + 1)]\n    else:\n        bins = [min_]\n\n    return bins", "response": "Return optimal bins given the input parameters min_ max_ std count"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_bin_width(stdev, count):\n\n    w = int(round((3.5 * stdev) / (count ** (1.0 / 3))))\n    if w:\n        return w\n    else:\n        return 1", "response": "Return the optimal bin width based on Sturges\n    http://www. jstor. org / pss / 2965501"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _longest_common_subsequence(x, y):\n    m = len(x)\n    n = len(y)\n\n    # L[i, j] will contain the length of the longest common subsequence of\n    # x[0..i - 1] and y[0..j - 1].\n    L = _np.zeros((m + 1, n + 1), dtype=int)\n\n    for i in range(m + 1):\n        for j in range(n + 1):\n            if i == 0 or j == 0:\n                continue\n            elif x[i - 1] == y[j - 1]:\n                L[i, j] = L[i - 1, j - 1] + 1\n            else:\n                L[i, j] = max(L[i - 1, j], L[i, j - 1])\n\n    ret = []\n\n    i, j = m, n\n    while i > 0 and j > 0:\n        # If current character in x and y are same, then current character is\n        # part of the longest common subsequence.\n        if x[i - 1] == y[j - 1]:\n            ret.append(x[i - 1])\n            i, j = i - 1, j - 1\n        # If not same, then find the larger of two and go in the direction of\n        # larger value.\n        elif L[i - 1, j] > L[i, j - 1]:\n            i -= 1\n        else:\n            j -= 1\n\n    return ret[::-1]", "response": "Returns the longest common subsequence between two sequences."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nposition all nodes of graph stacked on top of each other. Parameters ---------- graph : `networkx.Graph` or `list` of nodes A position will be assigned to every node in graph. height : `str` or `None`, optional The node attribute that holds the numerical value used for the node height. This defaults to ``'freeenergy'``. If `None`, all node heights are set to zero. scale : number, optional Scale factor for positions. center : array-like, optional Coordinate pair around which to center the layout. Default is the origin. dim : `int` Dimension of layout. If `dim` > 2, the remaining dimensions are set to zero in the returned positions. Returns ------- pos : mapping A mapping of positions keyed by node. Examples -------- >>> from pyrrole import ChemicalSystem >>> from pyrrole.atoms import create_data, read_cclib >>> from pyrrole.drawing import tower_layout >>> data = create_data( ... read_cclib(\"data/acetate/acetic_acid.out\", \"AcOH(g)\"), ... read_cclib(\"data/acetate/acetic_acid@water.out\", \"AcOH(aq)\")) >>> digraph = (ChemicalSystem(\"AcOH(g) <=> AcOH(aq)\", data) ... .to_digraph()) >>> layout = tower_layout(digraph) >>> layout['AcOH(g)'] array([ 0. , -228.56450866]) Passing ``scale=1`` means scaling positions to ``(-1, 1)`` in all axes: >>> layout = tower_layout(digraph, scale=1) >>> layout['AcOH(g)'][1] <= 1. True", "response": "def tower_layout(graph, height='freeenergy', scale=None, center=None, dim=2):\n    \"\"\"\n    Position all nodes of graph stacked on top of each other.\n\n    Parameters\n    ----------\n    graph : `networkx.Graph` or `list` of nodes\n        A position will be assigned to every node in graph.\n    height : `str` or `None`, optional\n        The node attribute that holds the numerical value used for the node\n        height. This defaults to ``'freeenergy'``. If `None`, all node heights\n        are set to zero.\n    scale : number, optional\n        Scale factor for positions.\n    center : array-like, optional\n        Coordinate pair around which to center the layout. Default is the\n        origin.\n    dim : `int`\n        Dimension of layout. If `dim` > 2, the remaining dimensions are set to\n        zero in the returned positions.\n\n    Returns\n    -------\n    pos : mapping\n        A mapping of positions keyed by node.\n\n    Examples\n    --------\n    >>> from pyrrole import ChemicalSystem\n    >>> from pyrrole.atoms import create_data, read_cclib\n    >>> from pyrrole.drawing import tower_layout\n    >>> data = create_data(\n    ...     read_cclib(\"data/acetate/acetic_acid.out\", \"AcOH(g)\"),\n    ...     read_cclib(\"data/acetate/acetic_acid@water.out\", \"AcOH(aq)\"))\n    >>> digraph = (ChemicalSystem(\"AcOH(g) <=> AcOH(aq)\", data)\n    ...            .to_digraph())\n    >>> layout = tower_layout(digraph)\n    >>> layout['AcOH(g)']\n    array([   0.        , -228.56450866])\n\n    Passing ``scale=1`` means scaling positions to ``(-1, 1)`` in all axes:\n\n    >>> layout = tower_layout(digraph, scale=1)\n    >>> layout['AcOH(g)'][1] <= 1.\n    True\n\n    \"\"\"\n    # TODO: private function of packages should not be used.\n    graph, center = _nx.drawing.layout._process_params(graph, center, dim)\n\n    num_nodes = len(graph)\n    if num_nodes == 0:\n        return {}\n    elif num_nodes == 1:\n        return {_nx.utils.arbitrary_element(graph): center}\n\n    paddims = max(0, (dim - 2))\n\n    if height is None:\n        y = _np.zeros(len(graph))\n    else:\n        y = _np.array([data for node, data in graph.nodes(data=height)])\n    pos_arr = _np.column_stack([_np.zeros((num_nodes, 1)), y,\n                                _np.zeros((num_nodes, paddims))])\n\n    if scale is not None:\n        pos_arr = _nx.drawing.layout.rescale_layout(pos_arr,\n                                                    scale=scale) + center\n    pos = dict(zip(graph, pos_arr))\n\n    # TODO: make test\n    return pos"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef diagram_layout(graph, height='freeenergy', sources=None, targets=None,\n                   pos=None, scale=None, center=None, dim=2):\n    \"\"\"\n    Position nodes such that paths are highlighted, from left to right.\n\n    Parameters\n    ----------\n    graph : `networkx.Graph` or `list` of nodes\n        A position will be assigned to every node in graph.\n    height : `str` or `None`, optional\n        The node attribute that holds the numerical value used for the node\n        height. This defaults to ``'freeenergy'``. If `None`, all node heights\n        are set to zero.\n    sources : `list` of `str`\n        All simple paths starting at members of `sources` are considered.\n        Defaults to all nodes of graph.\n    targets : `list` of `str`\n        All simple paths ending at members of `targets` are considered.\n        Defaults to all nodes of graph.\n    pos : mapping, optional\n        Initial positions for nodes as a mapping with node as keys and\n        values as a coordinate `list` or `tuple`. If not specified (default),\n        initial positions are computed with `tower_layout`.\n    scale : number, optional\n        Scale factor for positions.\n    center : array-like, optional\n        Coordinate pair around which to center the layout. Default is the\n        origin.\n    dim : `int`\n        Dimension of layout. If `dim` > 2, the remaining dimensions are set to\n        zero in the returned positions.\n\n    Returns\n    -------\n    pos : mapping\n        A mapping of positions keyed by node.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> from pyrrole import ChemicalSystem\n    >>> from pyrrole.drawing import diagram_layout\n    >>> data = pd.DataFrame(\n    ...     [{\"name\": \"Separated_Reactants\", \"freeenergy\": 0.},\n    ...      {\"name\": \"mlC1\", \"freeenergy\": -5.4},\n    ...      {\"name\": \"mlC2\", \"freeenergy\": -15.6},\n    ...      {\"name\": \"mTS1\", \"freeenergy\": 28.5, \"color\": \"g\"},\n    ...      {\"name\": \"mCARB1\", \"freeenergy\": -9.7},\n    ...      {\"name\": \"mCARB2\", \"freeenergy\": -19.8},\n    ...      {\"name\": \"mCARBX\", \"freeenergy\": 20}]).set_index(\"name\")\n    >>> system = ChemicalSystem(\n    ...     [\"Separated_Reactants -> mlC1 -> mTS1\",\n    ...      \"Separated_Reactants -> mlC2 -> mTS1\",\n    ...      \"mCARB2 <- mTS1 -> mCARB1\",\n    ...      \"Separated_Reactants -> mCARBX\"], data)\n    >>> digraph = system.to_digraph()\n    >>> layout = diagram_layout(digraph)\n    >>> layout['mCARB2']\n    array([  3. , -19.8])\n\n    Passing ``scale=1`` means scaling positions to ``(-1, 1)`` in all axes:\n\n    >>> layout = diagram_layout(digraph, scale=1)\n    >>> layout['mTS1'][1] <= 1.\n    True\n\n    \"\"\"\n    # TODO: private function of packages should not be used.\n    graph, center = _nx.drawing.layout._process_params(graph, center, dim)\n\n    num_nodes = len(graph)\n    if num_nodes == 0:\n        return {}\n    elif num_nodes == 1:\n        return {_nx.utils.arbitrary_element(graph): center}\n\n    if sources is None:\n        sources = graph.nodes()\n    if targets is None:\n        targets = graph.nodes()\n    simple_paths = [path for source in set(sources) for target in set(targets)\n                    for path in _nx.all_simple_paths(graph, source, target)]\n\n    if pos is None:\n        pos = tower_layout(graph, height=height, scale=None, center=center,\n                           dim=dim)\n\n    for path in simple_paths:\n        for n, step in enumerate(path):\n            if pos[step][0] < n:\n                pos[step][0] = n\n\n    if scale is not None:\n        pos_arr = _np.array([pos[node] for node in graph])\n        pos_arr = _nx.drawing.layout.rescale_layout(pos_arr,\n                                                    scale=scale) + center\n        pos = dict(zip(graph, pos_arr))\n\n    # TODO: make test\n    return pos", "response": "Returns a ChemicalSystem containing the layout of the nodes in a graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_diagram_nodes(graph, pos=None, nodelist=None, node_size=.7,\n                       node_color='k', style='solid', alpha=1.0, cmap=None,\n                       vmin=None, vmax=None, ax=None, label=None):\n    \"\"\"\n    Draw nodes of graph.\n\n    This draws only the nodes of graph as horizontal lines at each\n    ``y = pos[1]`` from ``x - node_size/2`` to ``x + node_size/2``, where\n    ``x = pos[0]``.\n\n    Parameters\n    ----------\n    graph : `networkx.Graph`\n        A NetworkX graph.\n    pos : mapping, optional\n        A mapping with nodes as keys and positions as values. Positions should\n        be sequences of length 2. If not specified (default), a diagram layout\n        positioning will be computed. See `networkx.layout` and\n        `pyrrole.drawing` for functions that compute node positions.\n    nodelist : `list`, optional\n        Draw only specified nodes (default is ``graph.nodes()``).\n    node_size : scalar or array\n        Size of nodes (default is ``.7``). If an array is specified it must be\n        the same length as nodelist.\n    node_color : color `str`, or array of `float`\n        Node color. Can be a single color format `str` (default is ``'k'``), or\n        a  sequence of colors with the same length as nodelist. If numeric\n        values are specified they will be mapped to colors using the `cmap` and\n        `vmin`, `vmax` parameters. See `matplotlib.hlines` for more details.\n    style : `str` (``'solid'``, ``'dashed'``, ``'dotted'``, ``'dashdot'``)\n        Edge line style (default is ``'solid'``). See `matplotlib.hlines` for\n        more details.\n    alpha : `float` or array of `float`, optional\n        The node transparency. This can be a single alpha value (default is\n        ``'1.0'``), in which case it will be applied to all the nodes of color.\n        Otherwise, if it is an array, the elements of alpha will be applied to\n        the colors in order (cycling through alpha multiple times if\n        necessary).\n    cmap : Matplotlib colormap, optional\n        Colormap name or Colormap instance for mapping intensities of nodes.\n    vmin : `float`, optional\n        Minimum for node colormap scaling.\n    vmax : `float`, optional\n        Maximum for node colormap scaling.\n    ax : `matplotlib.axes.Axes`, optional\n        Draw the graph in the specified Matplotlib axes.\n    label : `str`,  optional\n        Label for legend.\n\n    Returns\n    -------\n    `matplotlib.collections.LineCollection`\n        `LineCollection` of the nodes.\n\n    Raises\n    ------\n    networkx.NetworkXError\n        Raised if a node has no position or one with bad value.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> from pyrrole import ChemicalSystem\n    >>> from pyrrole.drawing import draw_diagram_nodes\n    >>> data = pd.DataFrame(\n    ...     [{\"name\": \"Separated_Reactants\", \"freeenergy\": 0.},\n    ...      {\"name\": \"mlC1\", \"freeenergy\": -5.4},\n    ...      {\"name\": \"mlC2\", \"freeenergy\": -15.6},\n    ...      {\"name\": \"mTS1\", \"freeenergy\": 28.5, \"color\": \"g\"},\n    ...      {\"name\": \"mCARB1\", \"freeenergy\": -9.7},\n    ...      {\"name\": \"mCARB2\", \"freeenergy\": -19.8},\n    ...      {\"name\": \"mCARBX\", \"freeenergy\": 20}]).set_index(\"name\")\n    >>> system = ChemicalSystem(\n    ...     [\"Separated_Reactants -> mlC1 -> mTS1\",\n    ...      \"Separated_Reactants -> mlC2 -> mTS1\",\n    ...      \"mCARB2 <- mTS1 -> mCARB1\",\n    ...      \"Separated_Reactants -> mCARBX\"], data)\n    >>> digraph = system.to_digraph()\n    >>> nodes = draw_diagram_nodes(digraph)\n\n    \"\"\"\n    if ax is None:\n        ax = _plt.gca()\n\n    if nodelist is None:\n        nodelist = list(graph.nodes())\n\n    if not nodelist or len(nodelist) == 0:  # empty nodelist, no drawing\n        return None\n\n    if pos is None:\n        pos = diagram_layout(graph)\n\n    try:\n        xy = _np.asarray([pos[v] for v in nodelist])\n    except KeyError as e:\n        raise _nx.NetworkXError('Node {} has no position.'.format(e))\n    except ValueError:\n        raise _nx.NetworkXError('Bad value in node positions.')\n\n    if isinstance(alpha, _collections.Iterable):\n        node_color = _nx.drawing.apply_alpha(node_color, alpha, nodelist, cmap,\n                                             vmin, vmax)\n        alpha = None\n\n    node_collection = ax.hlines(xy[:, 1],\n                                xy[:, 0] - node_size/2.,\n                                xy[:, 0] + node_size/2.,\n                                colors=node_color,\n                                linestyles=style,\n                                label=label,\n                                cmap=cmap)\n\n    node_collection.set_zorder(2)\n    return node_collection", "response": "Draw the nodes of a diagram."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing the edges of a diagram.", "response": "def draw_diagram_edges(graph, pos=None, edgelist=None, width=1.0,\n                       edge_color='k', style='dashed', alpha=1.0,\n                       edge_cmap=None, edge_vmin=None, edge_vmax=None, ax=None,\n                       label=None, nodelist=None, node_size=.7):\n    \"\"\"\n    Draw edges of graph.\n\n    This draws only the edges of a graph.\n\n    Parameters\n    ----------\n    graph : `networkx.Graph`\n        A NetworkX graph.\n    pos : mapping, optional\n        A mapping with nodes as keys and positions as values. Positions should\n        be sequences of length 2. If not specified (default), a diagram layout\n        positioning will be computed. See `networkx.layout` and\n        `pyrrole.drawing` for functions that compute node positions.\n    edgelist : collection of edge `tuple`\n        Draw only specified edges (default is ``graph.edges()``).\n    width : `float`, or array of `float`\n        Line width of edges (default is ``1.0``).\n    edge_color : color `str`, or array of `float`\n        Edge color. Can be a single color format `str` (default is ``'r'``),\n        or a sequence of colors with the same length as edgelist. If numeric\n        values are specified they will be mapped to colors using the\n        `edge_cmap` and `edge_vmin`, `edge_vmax` parameters.\n    style : `str` (``'solid'``, ``'dashed'``, ``'dotted'``, ``'dashdot'``)\n        Edge line style (default is ``'dashed'``). See `matplotlib.hlines` for\n        more details.\n    alpha : `float`, optional\n        The edge transparency (default is ``1.0``).\n    edge_cmap : Matplotlib colormap, optional\n        Colormap for mapping intensities of edges.\n    edge_vmin : `float`, optional\n        Minimum for edge colormap scaling.\n    edge_vmax : `float`, optional\n        Maximum for edge colormap scaling.\n    ax : `matplotlib.axes.Axes`, optional\n        Draw the graph in the specified Matplotlib axes.\n    label : `str`,  optional\n        Label for legend.\n    nodelist : `list`, optional\n        Draw only specified nodes (default is ``graph.nodes()``).\n    node_size : scalar or array\n        Size of nodes (default is ``.7``). If an array is specified it must be\n        the same length as nodelist.\n\n    Returns\n    -------\n    `matplotlib.collections.LineCollection`\n        `LineCollection` of the edges.\n\n    Raises\n    ------\n    networkx.NetworkXError\n        Raised if a node has no position or one with bad value.\n    ValueError\n        Raised if `edge_color` contains something other than color names (one\n        or a list of one per edge) or numbers.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> from pyrrole import ChemicalSystem\n    >>> from pyrrole.drawing import draw_diagram_edges\n    >>> data = pd.DataFrame(\n    ...     [{\"name\": \"Separated_Reactants\", \"freeenergy\": 0.},\n    ...      {\"name\": \"mlC1\", \"freeenergy\": -5.4},\n    ...      {\"name\": \"mlC2\", \"freeenergy\": -15.6},\n    ...      {\"name\": \"mTS1\", \"freeenergy\": 28.5, \"color\": \"g\"},\n    ...      {\"name\": \"mCARB1\", \"freeenergy\": -9.7},\n    ...      {\"name\": \"mCARB2\", \"freeenergy\": -19.8},\n    ...      {\"name\": \"mCARBX\", \"freeenergy\": 20}]).set_index(\"name\")\n    >>> system = ChemicalSystem(\n    ...     [\"Separated_Reactants -> mlC1 -> mTS1\",\n    ...      \"Separated_Reactants -> mlC2 -> mTS1\",\n    ...      \"mCARB2 <- mTS1 -> mCARB1\",\n    ...      \"Separated_Reactants -> mCARBX\"], data)\n    >>> digraph = system.to_digraph()\n    >>> edges = draw_diagram_edges(digraph)\n\n    \"\"\"\n    if ax is None:\n        ax = _plt.gca()\n\n    if edgelist is None:\n        edgelist = list(graph.edges())\n\n    if not edgelist or len(edgelist) == 0:  # no edges!\n        return None\n\n    if nodelist is None:\n        nodelist = list(graph.nodes())\n\n    if pos is None:\n        pos = diagram_layout(graph)\n\n    try:\n        # set edge positions\n        edge_pos = _np.asarray([(pos[e[0]] + node_size/2.,\n                                 pos[e[1]] - node_size/2.) for e in edgelist])\n    except KeyError as e:\n        raise _nx.NetworkXError('Node {} has no position.'.format(e))\n    except ValueError:\n        raise _nx.NetworkXError('Bad value in node positions.')\n\n    if not _cb.iterable(width):\n        lw = (width,)\n    else:\n        lw = width\n\n    if not isinstance(edge_color, str) \\\n            and _cb.iterable(edge_color) \\\n            and len(edge_color) == len(edge_pos):\n        if _np.alltrue([isinstance(c, str) for c in edge_color]):\n            # (should check ALL elements)\n            # list of color letters such as ['k','r','k',...]\n            edge_colors = tuple([_colorConverter.to_rgba(c, alpha)\n                                 for c in edge_color])\n        elif _np.alltrue([not isinstance(c, str) for c in edge_color]):\n            # If color specs are given as (rgb) or (rgba) tuples, we're OK\n            if _np.alltrue([_cb.iterable(c) and len(c) in (3, 4)\n                            for c in edge_color]):\n                edge_colors = tuple(edge_color)\n            else:\n                # numbers (which are going to be mapped with a colormap)\n                edge_colors = None\n        else:\n            raise ValueError('edge_color must contain color names or numbers')\n    else:\n        if isinstance(edge_color, str) or len(edge_color) == 1:\n            edge_colors = (_colorConverter.to_rgba(edge_color, alpha), )\n        else:\n            raise ValueError('edge_color must be a color or list of one color '\n                             ' per edge')\n\n    edge_collection = _LineCollection(edge_pos,\n                                      colors=edge_colors,\n                                      linewidths=lw,\n                                      antialiaseds=(1,),\n                                      linestyle=style,\n                                      transOffset=ax.transData)\n\n    edge_collection.set_zorder(1)  # edges go behind nodes\n    edge_collection.set_label(label)\n    ax.add_collection(edge_collection)\n\n    if _cb.is_numlike(alpha):\n        edge_collection.set_alpha(alpha)\n\n    if edge_colors is None:\n        if edge_cmap is not None:\n            assert(isinstance(edge_cmap, _Colormap))\n        edge_collection.set_array(_np.asarray(edge_color))\n        edge_collection.set_cmap(edge_cmap)\n        if edge_vmin is not None or edge_vmax is not None:\n            edge_collection.set_clim(edge_vmin, edge_vmax)\n        else:\n            edge_collection.autoscale()\n\n    ax.autoscale_view()\n    return edge_collection"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing node labels of a networkx graph in a diagram.", "response": "def draw_diagram_labels(graph, pos=None, labels=None, font_size=12,\n                        font_color='k', font_family='sans-serif',\n                        font_weight='normal', alpha=1.0, bbox=None, ax=None,\n                        offset=None, **kwds):\n    \"\"\"\n    Draw node labels of graph.\n\n    This draws only the node labels of a graph.\n\n    Parameters\n    ----------\n    graph : `networkx.Graph`\n        A NetworkX graph.\n    pos : mapping, optional\n        A mapping with nodes as keys and positions as values. Positions should\n        be sequences of length 2. If not specified (default), a diagram layout\n        positioning will be computed. See `networkx.layout` and\n        `pyrrole.drawing` for functions that compute node positions.\n    labels : mapping, optional\n        Node labels in a mapping keyed by node of text labels.\n    font_size : `int`, optional\n       Font size for text labels (default is ``12``).\n    font_color : `str`, optional\n       Font color `str` (default is ``'k'``, i.e., black).\n    font_family : `str`, optional\n       Font family (default is ``'sans-serif'``).\n    font_weight : `str`, optional\n       Font weight (default is ``'normal'``).\n    alpha : `float`, optional\n        The text transparency (default is ``1.0``).\n    ax : `matplotlib.axes.Axes`, optional\n        Draw the graph in the specified Matplotlib axes.\n    offset : array-like or `str`, optional\n        Label positions are summed to this before drawing. Defaults to zero\n        vector. If `str`, can be either ``'above'`` (equivalent to\n        ``(0, 1.5)``) or ``'below'`` (equivalent to ``(0, -1.5)``).\n\n    Returns\n    -------\n    mapping\n        Mapping of labels keyed on the nodes.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> from pyrrole import ChemicalSystem\n    >>> from pyrrole.drawing import draw_diagram_labels\n    >>> data = pd.DataFrame(\n    ...     [{\"name\": \"Separated_Reactants\", \"freeenergy\": 0.},\n    ...      {\"name\": \"mlC1\", \"freeenergy\": -5.4},\n    ...      {\"name\": \"mlC2\", \"freeenergy\": -15.6},\n    ...      {\"name\": \"mTS1\", \"freeenergy\": 28.5, \"color\": \"g\"},\n    ...      {\"name\": \"mCARB1\", \"freeenergy\": -9.7},\n    ...      {\"name\": \"mCARB2\", \"freeenergy\": -19.8},\n    ...      {\"name\": \"mCARBX\", \"freeenergy\": 20}]).set_index(\"name\")\n    >>> system = ChemicalSystem(\n    ...     [\"Separated_Reactants -> mlC1 -> mTS1\",\n    ...      \"Separated_Reactants -> mlC2 -> mTS1\",\n    ...      \"mCARB2 <- mTS1 -> mCARB1\",\n    ...      \"Separated_Reactants -> mCARBX\"], data)\n    >>> digraph = system.to_digraph()\n    >>> edges = draw_diagram_labels(digraph, font_color='blue',\n    ...                             offset=\"below\")\n    >>> labels = {k: \"{:g}\".format(v)\n    ...           for k, v in digraph.nodes(data='freeenergy')}\n    >>> edges = draw_diagram_labels(digraph, labels=labels,\n    ...                             offset=\"above\")\n\n    \"\"\"\n    if ax is None:\n        ax = _plt.gca()\n\n    if labels is None:\n        labels = dict((n, n) for n in graph.nodes())\n\n    if pos is None:\n        pos = diagram_layout(graph)\n\n    if offset is None:\n        offset = _np.array([0., 0.])\n    elif offset == \"above\":\n        offset = _np.array([0., 1.5])\n    elif offset == \"below\":\n        offset = _np.array([0., -1.5])\n\n    # set optional alignment\n    horizontalalignment = kwds.get('horizontalalignment', 'center')\n    verticalalignment = kwds.get('verticalalignment', 'center')\n\n    text_items = {}  # there is no text collection so we'll fake one\n    for n, label in labels.items():\n        (x, y) = _np.asanyarray(pos[n]) + _np.asanyarray(offset)\n        if not isinstance(label, str):\n            label = str(label)  # this makes \"1\" and 1 labeled the same\n        t = ax.text(x, y, label,\n                    size=font_size,\n                    color=font_color,\n                    family=font_family,\n                    weight=font_weight,\n                    alpha=alpha,\n                    horizontalalignment=horizontalalignment,\n                    verticalalignment=verticalalignment,\n                    transform=ax.transData,\n                    bbox=bbox,\n                    clip_on=True)\n        text_items[n] = t\n\n    return text_items"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndraws a diagram for a node in a network.", "response": "def draw_diagram(graph, pos=None, with_labels=True, offset=None, **kwds):\n    \"\"\"\n    Draw a diagram for graph using Matplotlib.\n\n    Draw graph as a simple energy diagram with Matplotlib with options for node\n    positions, labeling, titles, and many other drawing features. See examples\n    below.\n\n    Parameters\n    ----------\n    graph : `networkx.Graph`\n        A NetworkX graph.\n    pos : mapping, optional\n        A mapping with nodes as keys and positions as values. Positions should\n        be sequences of length 2. If not specified (default) a diagram layout\n        positioning will be computed. See `networkx.drawing.layout` and\n        `pyrrole.drawing` for functions that compute node positions.\n    with_labels : `bool`, optional\n       Set to `True` (default) to draw labels on the nodes.\n    offset : array-like or `str`, optional\n        Label positions are summed to this before drawing. Defaults to\n        ``'below'``. See `draw_diagram_labels` for more.\n\n    Notes\n    -----\n    Further keywords are passed to `draw_diagram_nodes` and\n    `draw_diagram_edges`. If `pos` is `None`, `diagram_layout` is also called\n    and have keywords passed as well. The same happens with\n    `draw_diagram_labels` if `with_labels` is `True`.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> from pyrrole import ChemicalSystem\n    >>> from pyrrole.drawing import draw_diagram, draw_diagram_labels\n    >>> data = pd.DataFrame(\n    ...     [{\"name\": \"Separated_Reactants\", \"freeenergy\": 0.},\n    ...      {\"name\": \"mlC1\", \"freeenergy\": -5.4},\n    ...      {\"name\": \"mlC2\", \"freeenergy\": -15.6},\n    ...      {\"name\": \"mTS1\", \"freeenergy\": 28.5, \"color\": \"g\"},\n    ...      {\"name\": \"mCARB1\", \"freeenergy\": -9.7},\n    ...      {\"name\": \"mCARB2\", \"freeenergy\": -19.8},\n    ...      {\"name\": \"mCARBX\", \"freeenergy\": 20}]).set_index(\"name\")\n    >>> system = ChemicalSystem(\n    ...     [\"Separated_Reactants -> mlC1 -> mTS1\",\n    ...      \"Separated_Reactants -> mlC2 -> mTS1\",\n    ...      \"mCARB2 <- mTS1 -> mCARB1\",\n    ...      \"Separated_Reactants -> mCARBX\"], data)\n    >>> digraph = system.to_digraph()\n    >>> draw_diagram(digraph)\n    >>> labels = {k: \"{:g}\".format(v)\n    ...           for k, v in digraph.nodes(data='freeenergy')}\n    >>> edges = draw_diagram_labels(digraph, labels=labels,\n    ...                             offset=\"above\")\n\n    \"\"\"\n    if pos is None:\n        pos = diagram_layout(graph, **kwds)  # default to diagram layout\n\n    node_collection = draw_diagram_nodes(graph, pos, **kwds)  # noqa\n    edge_collection = draw_diagram_edges(graph, pos, **kwds)  # noqa\n    if with_labels:\n        if offset is None:\n            # TODO: This changes the default behaviour of draw_diagram_labels.\n            offset = \"below\"\n        draw_diagram_labels(graph, pos, offset=offset, **kwds)\n    _plt.draw_if_interactive()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserialising a message with including any framing.", "response": "def serialise(self, default_endianness=None):\n        \"\"\"\n        Serialise a message, without including any framing.\n\n        :param default_endianness: The default endianness, unless overridden by the fields or class metadata.\n                                   Should usually be left at ``None``. Otherwise, use ``'<'`` for little endian and\n                                   ``'>'`` for big endian.\n        :type default_endianness: str\n        :return: The serialised message.\n        :rtype: bytes\n        \"\"\"\n        # Figure out an endianness.\n        endianness = (default_endianness or DEFAULT_ENDIANNESS)\n        if hasattr(self, '_Meta'):\n            endianness = self._Meta.get('endianness', endianness)\n\n        inferred_fields = set()\n        for k, v in iteritems(self._type_mapping):\n            inferred_fields |= {x._name for x in v.dependent_fields()}\n        for field in inferred_fields:\n            setattr(self, field, None)\n\n        # Some fields want to manipulate other fields that appear before them (e.g. Unions)\n        for k, v in iteritems(self._type_mapping):\n            v.prepare(self, getattr(self, k))\n\n        message = b''\n        for k, v in iteritems(self._type_mapping):\n            message += v.value_to_bytes(self, getattr(self, k), default_endianness=endianness)\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialise_packet(self):\n        if not hasattr(self, '_Meta'):\n            raise ReferenceError(\"Can't serialise a packet that doesn't have an endpoint ID.\")\n        serialised = self.serialise()\n        return struct.pack('!HH', len(serialised), self._Meta['endpoint']) + serialised", "response": "Serialise a message including framing information inferred from the Meta. endpoint attribute of the packet."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a message received from the Pebble and returns the corresponding Packet instance.", "response": "def parse_message(cls, message):\n        \"\"\"\n        Parses a message received from the Pebble. Uses Pebble Protocol framing to figure out what sort of packet\n        it is. If the packet is registered (has been defined and imported), returns the deserialised packet, which will\n        not necessarily be the same class as this. Otherwise returns ``None``.\n\n        Also returns the length of the message consumed during deserialisation.\n\n        :param message: A serialised message received from the Pebble.\n        :type message: bytes\n        :return: ``(decoded_message, decoded length)``\n        :rtype: (:class:`PebblePacket`, :any:`int`)\n        \"\"\"\n        length = struct.unpack_from('!H', message, 0)[0] + 4\n        if len(message) < length:\n            raise IncompleteMessage()\n        command, = struct.unpack_from('!H', message, 2)\n        if command in _PacketRegistry:\n            return _PacketRegistry[command].parse(message[4:length])[0], length\n        else:\n            return None, length"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(cls, message, default_endianness=DEFAULT_ENDIANNESS):\n        obj = cls()\n        offset = 0\n        if hasattr(cls, '_Meta'):\n            default_endianness = cls._Meta.get('endianness', default_endianness)\n        for k, v in iteritems(cls._type_mapping):\n            try:\n                value, length = v.buffer_to_value(obj, message, offset, default_endianness=default_endianness)\n            except Exception:\n                logger.warning(\"Exception decoding {}.{}\".format(cls.__name__, k))\n                raise\n            offset += length\n            setattr(obj, k, value)\n        return obj, offset", "response": "Parses a message without any framing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expand_query(config, kwds):\n    pattern = []\n    for query in kwds.pop('pattern', []):\n        expansion = config.search.alias.get(query)\n        if expansion is None:\n            pattern.append(query)\n        else:\n            parser = SafeArgumentParser()\n            search_add_arguments(parser)\n            ns = parser.parse_args(expansion)\n            for (key, value) in vars(ns).items():\n                if isinstance(value, (list, tuple)):\n                    if not kwds.get(key):\n                        kwds[key] = value\n                    else:\n                        kwds[key].extend(value)\n                else:\n                    kwds[key] = value\n    kwds['pattern'] = pattern\n    return config.search.kwds_adapter(kwds)", "response": "Expand kwds based on config. search. query_expander."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preprocess_kwds(kwds):\n    from .utils.timeutils import parse_datetime, parse_duration\n\n    for key in ['output', 'format', 'format_level',\n                'with_command_id', 'with_session_id']:\n        kwds.pop(key, None)\n\n    for key in ['time_after', 'time_before']:\n        val = kwds[key]\n        if val:\n            dt = parse_datetime(val)\n            if dt:\n                kwds[key] = dt\n\n    for key in ['duration_longer_than', 'duration_less_than']:\n        val = kwds[key]\n        if val:\n            dt = parse_duration(val)\n            if dt:\n                kwds[key] = dt\n\n    # interpret \"pattern\" (currently just copying to --include-pattern)\n    less_strict_pattern = list(map(\"*{0}*\".format, kwds.pop('pattern', [])))\n    kwds['match_pattern'] = kwds['match_pattern'] + less_strict_pattern\n\n    if not kwds['sort_by']:\n        kwds['sort_by'] = ['count']\n    kwds['sort_by'] = [SORT_KEY_SYNONYMS[k] for k in kwds['sort_by']]\n    return kwds", "response": "Preprocess keyword arguments for DataBase. search_command_record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __fix_args(kwargs):\n    kwargs.setdefault('fixed_strings', kwargs.get('F'))\n    kwargs.setdefault('basic_regexp', kwargs.get('G'))\n    kwargs.setdefault('extended_regexp', kwargs.get('E'))\n    kwargs.setdefault('ignore_case', kwargs.get('i'))\n    kwargs.setdefault('invert', kwargs.get('v'))\n    kwargs.setdefault('words', kwargs.get('w'))\n    kwargs.setdefault('line', kwargs.get('x'))\n    kwargs.setdefault('count', kwargs.get('c'))\n    kwargs.setdefault('max_count', kwargs.get('m'))\n    kwargs.setdefault('after_context', kwargs.get('A'))\n    kwargs.setdefault('before_context', kwargs.get('B'))\n    kwargs.setdefault('quiet', kwargs.get('q'))\n    kwargs.setdefault('byte_offset', kwargs.get('b'))\n    kwargs.setdefault('only_matching', kwargs.get('o'))\n    kwargs.setdefault('line_number', kwargs.get('n'))\n    kwargs.setdefault('regex_flags', kwargs.get('r'))\n    kwargs.setdefault('keep_eol', kwargs.get('k'))\n    kwargs.setdefault('trim', kwargs.get('t'))", "response": "Set all named arguments shortcuts and flags."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a single line value.", "response": "def __process_line(line, strip_eol, strip):\n    \"\"\"\n    process a single line value.\n    \"\"\"\n    if strip:\n        line = line.strip()\n    elif strip_eol and line.endswith('\\n'):\n        line = line[:-1]\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __do_grep(curr_line, pattern, **kwargs):\n    # currently found position\n    position = -1\n    end_pos = -1\n\n    # check if fixed strings mode\n    if kwargs.get('fixed_strings'):\n\n        # if case insensitive fix case\n        if kwargs.get('ignore_case'):\n            pattern = pattern.lower()\n            curr_line = curr_line.lower()\n\n        # if pattern is a single string, match it:\n        pattern_len = 0\n        if isinstance(pattern, _basestring):\n            position = curr_line.find(pattern)\n            pattern_len = len(pattern)\n\n        # if not, treat it as a list of strings and match any\n        else:\n            for p in pattern:\n                position = curr_line.find(p)\n                pattern_len = len(p)\n                if position != -1:\n                    break\n\n        # calc end position\n        end_pos = position + pattern_len\n\n        # check if need to match whole words\n        if kwargs.get('words') and position != -1:\n\n            foundpart = (' ' + curr_line + ' ')[position:position+len(pattern)+2]\n            if _is_part_of_word(foundpart[0]):\n                position = -1\n            elif _is_part_of_word(foundpart[-1]):\n                position = -1\n\n    # if not fixed string, it means its a regex\n    else:\n\n        # set regex flags\n        flags = kwargs.get('regex_flags') or 0\n        flags |= re.IGNORECASE if kwargs.get('ignore_case') else 0\n\n        # add whole-words option\n        if kwargs.get('words'):\n            pattern = r'\\b' + pattern + r'\\b'\n\n        # do search\n        result = re.search(pattern, curr_line, flags)\n\n        # if found, set position\n        if result:\n            position = result.start()\n            end_pos = result.end()\n\n    # check if need to match whole line\n    if kwargs.get('line') and (position != 0 or end_pos != len(curr_line)):\n        position = -1\n\n    # parse return value\n    matched = position != -1\n\n    # if invert flag is on, invert value\n    if kwargs.get('invert'):\n        matched = not matched\n\n    # if position is -1 reset end pos as well\n    if not matched:\n        end_pos = -1\n\n    # return result\n    return matched, position, end_pos", "response": "Do grep on a single string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate argument parser given a list of subcommand specifications.", "response": "def get_parser(commands):\n    \"\"\"\n    Generate argument parser given a list of subcommand specifications.\n\n    :type commands: list of (str, function, function)\n    :arg  commands:\n        Each element must be a tuple ``(name, adder, runner)``.\n\n        :param   name: subcommand\n        :param  adder: a function takes one object which is an instance\n                       of :class:`argparse.ArgumentParser` and add\n                       arguments to it\n        :param runner: a function takes keyword arguments which must be\n                       specified by the arguments parsed by the parser\n                       defined by `adder`.  Docstring of this function\n                       will be the description of the subcommand.\n\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        formatter_class=Formatter,\n        description=__doc__,\n        epilog=EPILOG,\n    )\n    subparsers = parser.add_subparsers()\n\n    for (name, adder, runner) in commands:\n        subp = subparsers.add_parser(\n            name,\n            formatter_class=Formatter,\n            description=runner.__doc__ and textwrap.dedent(runner.__doc__))\n        adder(subp)\n        subp.set_defaults(func=runner)\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints location of RASH related file.", "response": "def locate_run(output, target, no_newline):\n    \"\"\"\n    Print location of RASH related file.\n    \"\"\"\n    from .config import ConfigStore\n    cfstore = ConfigStore()\n    path = getattr(cfstore, \"{0}_path\".format(target))\n    output.write(path)\n    if not no_newline:\n        output.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering a TDB of local users.", "response": "def userBrowser(self, request, tag):\n        \"\"\"\n        Render a TDB of local users.\n        \"\"\"\n        f = LocalUserBrowserFragment(self.browser)\n        f.docFactory = webtheme.getLoader(f.fragmentName)\n        f.setFragmentParent(self)\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender a liveform for creating new users.", "response": "def userCreate(self, request, tag):\n        \"\"\"\n        Render a form for creating new users.\n        \"\"\"\n        userCreator = liveform.LiveForm(\n            self.createUser,\n            [liveform.Parameter(\n                    \"localpart\",\n                    liveform.TEXT_INPUT,\n                    unicode,\n                    \"localpart\"),\n             liveform.Parameter(\n                    \"domain\",\n                    liveform.TEXT_INPUT,\n                    unicode,\n                    \"domain\"),\n             liveform.Parameter(\n                    \"password\",\n                    liveform.PASSWORD_INPUT,\n                    unicode,\n                    \"password\")])\n        userCreator.setFragmentParent(self)\n        return userCreator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new blank user account with the given name and domain and with the given password.", "response": "def createUser(self, localpart, domain, password=None):\n        \"\"\"\n        Create a new, blank user account with the given name and domain and, if\n        specified, with the given password.\n\n        @type localpart: C{unicode}\n        @param localpart: The local portion of the username.  ie, the\n        C{'alice'} in C{'alice@example.com'}.\n\n        @type domain: C{unicode}\n        @param domain: The domain portion of the username.  ie, the\n        C{'example.com'} in C{'alice@example.com'}.\n\n        @type password: C{unicode} or C{None}\n        @param password: The password to associate with the new account.  If\n        C{None}, generate a new password automatically.\n        \"\"\"\n        loginSystem = self.browser.store.parent.findUnique(userbase.LoginSystem)\n        if password is None:\n            password = u''.join([random.choice(string.ascii_letters + string.digits) for i in xrange(8)])\n        loginSystem.addAccount(localpart, domain, password)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef doAction(self, loginMethod, actionClass):\n        loginAccount = loginMethod.account\n        return actionClass(\n            self,\n            loginMethod.localpart + u'@' + loginMethod.domain,\n            loginAccount)", "response": "Show the form for the requested action."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a liveform. LiveForm that will endow or deprive existing users using Products.", "response": "def productForm(self, request, tag):\n        \"\"\"\n        Render a L{liveform.LiveForm} -- the main purpose of this fragment --\n        which will allow the administrator to endow or deprive existing users\n        using Products.\n        \"\"\"\n\n        def makeRemover(i):\n            def remover(s3lected):\n                if s3lected:\n                    return self.products[i]\n                return None\n            return remover\n\n        f = liveform.LiveForm(\n            self._endow,\n            [liveform.Parameter(\n                    'products' + str(i),\n                    liveform.FORM_INPUT,\n                    liveform.LiveForm(\n                        makeRemover(i),\n                        [liveform.Parameter(\n                                's3lected',\n                                liveform.RADIO_INPUT,\n                                bool,\n                                repr(p),\n                                )],\n                        '',\n                        ),\n                    )\n             for (i, p)\n             in enumerate(self.products)],\n            self.which.capitalize() + u' ' + self.username)\n        f.setFragmentParent(self)\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getStore(self, name, domain):\n        return IRealm(self.original.store.parent).accountByAddress(name, domain).avatars.open()", "response": "Convenience method for the REPL. I got tired of typing this string every time I logged in in."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createPort(self, portNumber, ssl, certPath, factory, interface=u''):\n        store = self.store.parent\n        if ssl:\n            port = SSLPort(store=store, portNumber=portNumber,\n                           certificatePath=FilePath(certPath), factory=factory,\n                           interface=interface)\n        else:\n            port = TCPPort(store=store, portNumber=portNumber, factory=factory,\n                           interface=interface)\n        installOn(port, store)", "response": "Creates a new listening port."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extractValue(self, model, item):\n        factory = super(FactoryColumn, self).extractValue(model, item)\n        return factory.__class__.__name__.decode('ascii')", "response": "Extract the class name of the factory referenced by a port."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the path referenced by this column s attribute.", "response": "def extractValue(self, model, item):\n        \"\"\"\n        Get the path referenced by this column's attribute.\n\n        @param model: Either a TabularDataModel or a ScrollableView, depending\n        on what this column is part of.\n\n        @param item: A port item instance (as defined by L{xmantissa.port}).\n\n        @rtype: C{unicode}\n        \"\"\"\n        certPath = super(CertificateColumn, self).extractValue(model, item)\n        return certPath.path.decode('utf-8', 'replace')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef itemFromLink(self, link):\n        return self.siteStore.getItemByID(self.webTranslator.linkFrom(link))", "response": "Returns the item which the given link referred to."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and return a L{PortScrollingFragment for the TCPPorts items", "response": "def tcpPorts(self, req, tag):\n        \"\"\"\n        Create and return a L{PortScrollingFragment} for the L{TCPPort} items\n        in site store.\n        \"\"\"\n        f = PortScrollingFragment(\n            self.store,\n            TCPPort,\n            (TCPPort.portNumber,\n             TCPPort.interface,\n             FactoryColumn(TCPPort.factory)))\n        f.setFragmentParent(self)\n        f.docFactory = webtheme.getLoader(f.fragmentName)\n        return tag[f]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate and return a L{PortScrollingFragment for the SSLPorts in the site store.", "response": "def sslPorts(self, req, tag):\n        \"\"\"\n        Create and return a L{PortScrollingFragment} for the L{SSLPort} items\n        in the site store.\n        \"\"\"\n        f = PortScrollingFragment(\n            self.store,\n            SSLPort,\n            (SSLPort.portNumber,\n             SSLPort.interface,\n             CertificateColumn(SSLPort.certificatePath),\n             FactoryColumn(SSLPort.factory)))\n        f.setFragmentParent(self)\n        f.docFactory = webtheme.getLoader(f.fragmentName)\n        return tag[f]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates and return a L{LiveForm} for adding a new TCP port to the site store.", "response": "def createPortForm(self, req, tag):\n        \"\"\"\n        Create and return a L{LiveForm} for adding a new L{TCPPort} or\n        L{SSLPort} to the site store.\n        \"\"\"\n        def port(s):\n            n = int(s)\n            if n < 0 or n > 65535:\n                raise ValueError(s)\n            return n\n\n        factories = []\n        for f in self.store.parent.powerupsFor(IProtocolFactoryFactory):\n            factories.append((f.__class__.__name__.decode('ascii'),\n                              f,\n                              False))\n\n        f = LiveForm(\n            self.portConf.createPort,\n            [Parameter('portNumber', TEXT_INPUT, port, 'Port Number',\n                       'Integer 0 <= n <= 65535 giving the TCP port to bind.'),\n\n             Parameter('interface', TEXT_INPUT, unicode, 'Interface',\n                       'Hostname to bind to, or blank for all interfaces.'),\n\n             Parameter('ssl', CHECKBOX_INPUT, bool, 'SSL',\n                       'Select to indicate port should use SSL.'),\n\n             # Text area?  File upload?  What?\n             Parameter('certPath', TEXT_INPUT, unicode, 'Certificate Path',\n                       'Path to a certificate file on the server, if SSL is to be used.'),\n\n             ChoiceParameter('factory', factories, 'Protocol Factory',\n                             'Which pre-existing protocol factory to associate with this port.')])\n        f.setFragmentParent(self)\n        # f.docFactory = webtheme.getLoader(f.fragmentName)\n        return tag[f]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconnect the given receiver to a new box receiver for the given protocol.", "response": "def connectRoute(amp, router, receiver, protocol):\n    \"\"\"\n    Connect the given receiver to a new box receiver for the given\n    protocol.\n\n    After connecting this router to an AMP server, use this method\n    similarly to how you would use C{reactor.connectTCP} to establish a new\n    connection to an HTTP, SMTP, or IRC server.\n\n    @param receiver: An L{IBoxReceiver} which will be started when a route\n        to a receiver for the given protocol is found.\n\n    @param protocol: The name of a protocol which the AMP peer to which\n        this router is connected has an L{IBoxReceiverFactory}.\n\n    @return: A L{Deferred} which fires with C{receiver} when the route is\n        established.\n    \"\"\"\n    route = router.bindRoute(receiver)\n    d = amp.callRemote(\n        Connect,\n        origin=route.localRouteName,\n        protocol=protocol)\n    def cbGotRoute(result):\n        route.connectTo(result['route'])\n        return receiver\n    d.addCallback(cbGotRoute)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generateOneTimePad(self, userStore):\n        pad = secureRandom(16).encode('hex')\n        self._oneTimePads[pad] = userStore.idInParent\n        def expirePad():\n            self._oneTimePads.pop(pad, None)\n        self.callLater(self.ONE_TIME_PAD_DURATION, expirePad)\n        return pad", "response": "Generate a pad which can be used to authenticate via AMP."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getFactory(self):\n        factory = ServerFactory()\n        def protocol():\n            proto = CredReceiver()\n            proto.portal = Portal(\n                self.loginSystem,\n                [self.loginSystem,\n                 OneTimePadChecker(self._oneTimePads)])\n            return proto\n        factory.protocol = protocol\n        return factory", "response": "Returns a server factory which creates AMP protocol instances."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new route attached to a box receiver with the specified protocol.", "response": "def accept(self, origin, protocol):\n        \"\"\"\n        Create a new route attached to a L{IBoxReceiver} created by the\n        L{IBoxReceiverFactory} with the indicated protocol.\n\n        @type origin: C{unicode}\n        @param origin: The identifier of a route on the peer which will be\n            associated with this connection.  Boxes sent back by the protocol\n            which is created in this call will be sent back to this route.\n\n        @type protocol: C{unicode}\n        @param protocol: The name of the protocol to which to establish a\n            connection.\n\n        @raise ProtocolUnknown: If no factory can be found for the named\n            protocol.\n\n        @return: A newly created C{unicode} route identifier for this\n            connection (as the value of a C{dict} with a C{'route'} key).\n        \"\"\"\n        for factory in self.store.powerupsFor(IBoxReceiverFactory):\n            # XXX What if there's a duplicate somewhere?\n            if factory.protocol == protocol:\n                receiver = factory.getBoxReceiver()\n                route = self.router.bindRoute(receiver)\n                # This might be better implemented using a hook on the box.\n                # See Twisted ticket #3479.\n                self.reactor.callLater(0, route.connectTo, origin)\n                return {'route': route.localRouteName}\n        raise ProtocolUnknown()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a router that handles AMP boxes received over an AMP connection.", "response": "def indirect(self, interface):\n        \"\"\"\n        Create a L{Router} to handle AMP boxes received over an AMP connection.\n        \"\"\"\n        if interface is IBoxReceiver:\n            router = Router()\n            connector = self.connectorFactory(router)\n            router.bindRoute(connector, None).connectTo(None)\n            return router\n        raise NotImplementedError()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getfirstline(file, default):\n    with open(file, 'rb') as fh:\n        content = fh.readlines()\n        if len(content) == 1:\n            return content[0].decode('utf-8').strip('\\n')\n\n    return default", "response": "Returns the first line of a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef job_stats_enhanced(job_id):\n    stats_dict = {}\n    with os.popen('sacct --noheader --format JobId,Elapsed,TotalCPU,Partition,NTasks,AveRSS,State,ExitCode,start,end -P -j ' + str(job_id)) as f:\n        try:\n            line = f.readline()\n            if line in [\"SLURM accounting storage is disabled\",\n                        \"slurm_load_job error: Invalid job id specified\"]:\n                raise\n            cols = line.split('|')\n            stats_dict['job_id'] = cols[0]\n            stats_dict['wallclock'] = get_timedelta(cols[1])\n            stats_dict['cpu'] = get_timedelta(cols[2])\n            stats_dict['queue'] = cols[3]\n            stats_dict['status'] = cols[6]\n            stats_dict['exit_code'] = cols[7].split(':')[0]\n            stats_dict['start'] = cols[8]\n            stats_dict['end'] = cols[9]\n\n            steps = []\n            for line in f:\n                step = {}\n                cols = line.split('|')\n                step_val = cols[0].split('.')[1]\n                step['step'] = step_val\n                step['wallclock'] = get_timedelta(cols[1])\n                step['cpu'] = get_timedelta(cols[2])\n                step['ntasks'] = cols[4]\n                step['status'] = cols[6]\n                step['exit_code'] = cols[7].split(':')[0]\n                step['start'] = cols[8]\n                step['end'] = cols[9]\n                steps.append(step)\n            stats_dict['steps'] = steps\n        except:\n            with os.popen('squeue -h -j %s' % str(job_id)) as f:\n                try:\n                    for line in f:\n                        new_line = re.sub(' +', ' ', line.strip())\n                        job_id = int(new_line.split(' ')[0])\n                        state = new_line.split(' ')[4]\n                        stats_dict['job_id'] = str(job_id)\n                        stats_dict['status'] = state\n                except:\n                    print('SLURM: Error reading job stats')\n                    stats_dict['status'] = 'UNKNOWN'\n    with os.popen('squeue --format %%S -h -j ' + str(job_id)) as f:\n        try:\n            line = f.readline()\n            if len(line) > 0:\n                stats_dict['start_time'] = line\n            else:\n                stats_dict['start_time'] = \"\"\n        except:\n            print('SLURM: Error getting start time')\n    return stats_dict", "response": "Get full job stats for a specific job_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a raw representation of a json structure returns the parsed corresponding data structure.", "response": "def parse_json_structure(string_item):\n    \"\"\"\n    Given a raw representation of a json structure, returns the parsed corresponding data\n    structure (``JsonRpcRequest`` or ``JsonRpcRequestBatch``)\n\n    :param string_item:\n    :return:\n    \"\"\"\n    if not isinstance(string_item, str):\n        raise TypeError(\"Expected str but got {} instead\".format(type(string_item).__name__))\n\n    try:\n        item = json.loads(string_item)\n    except json.JSONDecodeError:\n        raise JsonRpcParseError()\n\n    if isinstance(item, dict):\n        return JsonRpcRequest.from_dict(item)\n    elif isinstance(item, list):\n        if len(item) == 0:\n            raise JsonRpcInvalidRequestError()\n\n        request_batch = JsonRpcRequestBatch([])\n        for d in item:\n            try:\n                # handles the case of valid batch but with invalid\n                # requests.\n                if not isinstance(d, dict):\n                    raise JsonRpcInvalidRequestError()\n                # is dict, all fine\n                parsed_entry = JsonRpcRequest.from_dict(d)\n            except JsonRpcInvalidRequestError:\n                parsed_entry = GenericResponse.INVALID_REQUEST\n            request_batch.add_item(parsed_entry)\n        return request_batch"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates a dict instance and transforms it in a clf.", "response": "def from_dict(cls, d):\n        \"\"\"\n        Validates a dict instance and transforms it in a\n        :py:class:`gemstone.core.structs.JsonRpcRequest`\n        instance\n\n        :param d: The dict instance\n        :return: A :py:class:`gemstone.core.structs.JsonRpcRequest`\n                 if everything goes well, or None if the validation fails\n        \"\"\"\n        for key in (\"method\", \"jsonrpc\"):\n            if key not in d:\n                raise JsonRpcInvalidRequestError()\n\n        # check jsonrpc version\n        jsonrpc = d.get(\"jsonrpc\", None)\n        if jsonrpc != \"2.0\":\n            raise JsonRpcInvalidRequestError()\n\n        # check method\n        method = d.get(\"method\", None)\n        if not method:\n            raise JsonRpcInvalidRequestError()\n        if not isinstance(method, str):\n            raise JsonRpcInvalidRequestError()\n\n        # params\n        params = d.get(\"params\", {})\n        if not isinstance(params, (list, dict)):\n            raise JsonRpcInvalidRequestError()\n\n        req_id = d.get(\"id\", None)\n        if not isinstance(req_id, (int, str)) and req_id is not None:\n            raise JsonRpcInvalidRequestError()\n\n        extras = {k: d[k] for k in d if k not in (\"jsonrpc\", \"id\", \"method\", \"params\")}\n\n        instance = cls(\n            id=req_id,\n            method=method,\n            params=params,\n            extra=extras\n        )\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding an item to the batch.", "response": "def add_item(self, item):\n        \"\"\"Adds an item to the batch.\"\"\"\n\n        if not isinstance(item, JsonRpcResponse):\n            raise TypeError(\n                \"Expected JsonRpcResponse but got {} instead\".format(type(item).__name__))\n\n        self.items.append(item)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_spark_lines(table,filename,sc,**kwargs):\n\tspark_output = True\n\tlines_out_count = False\n\textrema = False\n\tfor key,value in kwargs.iteritems():\n\t\tif key == 'lines_out_count':\n\t\t\tlines_out_count = value\n\t\tif key == 'extrema':\n\t\t\textrema = value\n\t# removing datetime references from imported postgis database\n\t# CURRENTLY datetime from postgis dbs throw errors \n\t# fields containing dates removed\n\tlist = []\n\tcount = 0\n\tfor row in table.columns.values.tolist():\n\t\tif 'date' in row:\n\t\t\tlist.append(count)\n\t\tcount += 1\n\n\ttable.drop(table.columns[list], axis=1, inplace=True)\n\n\n\t# getting spark arguments\n\tif lines_out_count == False:\n\t\targs = make_spark_args(table,25,lines_out = True,extrema=extrema)\n\telse:\n\t\targs = make_spark_args(table,25,lines_out_count=lines_out_count)\n\t# concurrent represents rdd structure that will be parrelized\n\tconcurrent = sc.parallelize(args)\n\n\t# getting table that would normally be going into this function\n\ttable = concurrent.map(map_spark_lines).collect()\n\n\n\n\t'''\n\talignment_field = False\n\tspark_output = True\n\tif kwargs is not None:\n\t\tfor key,value in kwargs.iteritems():\n\t\t\tif key == 'alignment_field':\n\t\t\t\talignment_field = value \n\t\t\tif key == 'spark_output':\n\t\t\t\tspark_output = value\n\n\t#changing dataframe to list if dataframe\n\tif isinstance(table,pd.DataFrame):\n\t\ttable=df2list(table)\n\theader=table[0]\n\ttotal = []\n\t# making table the proper iterable for each input \n\tif spark_output == True:\n\t\t#table = sum(table,[])\n\t\tpass\n\telse:\n\t\ttable = table[1:]\n\t'''\n\t'''\n\t# making filenames list\n\tfilenames = []\n\tcount = 0\n\twhile not len(filenames) == len(table):\n\t\tcount += 1\n\t\tfilename = 'lines%s.geojson' % str(count)\n\t\tfilenames.append(filename)\n\n\targs = []\n\t# zipping arguments together for each value in table\n\tfor filename,row in itertools.izip(filenames,table):\n\t\targs.append([filename,row])\n\n\n\tconcurrent = sc.parallelize(args)\n\tconcurrent.map(map_lines_output).collect()\n\t'''\n\t'''\n\tcount=0\n\ttotal=0\n\tfor row in table:\n\t\tcount+=1\n\t\t# logic to treat rows as outputs of make_line or to perform make_line operation\n\t\tif spark_output == False:\n\t\t\tvalue = make_line([header,row],list=True,postgis=True,alignment_field=alignment_field)\n\t\telif spark_output == True:\n\t\t\tvalue = row\n\n\t\t# logic for how to handle starting and ending geojson objects\n\t\tif row==table[0]:\n\t\t\t#value=make_line([header,row],list=True,postgis=True,alignment_field=alignment_field)\n\t\t\tif not len(table)==2:\n\t\t\t\tvalue=value[:-3]\n\t\t\t\ttotalvalue=value+['\\t},']\n\t\t\n\t\telif row==table[-1]:\n\t\t\t#value=make_line([header,row],list=True,postgis=True,alignment_field=alignment_field)\n\t\t\tvalue=value[2:]\n\t\t\ttotalvalue=totalvalue+value\n\t\telse:\n\t\t\t#value=make_line([header,row],list=True,postgis=True,alignment_field=alignment_field)\n\t\t\tvalue=value[2:-3]\n\t\t\tvalue=value+['\\t},']\n\t\t\ttotalvalue=totalvalue+value\n\t\tif count == 1000:\n\t\t\ttotal += count\n\t\t\tcount = 0\n\t\t\tprint '[%s/%s]' % (total,len(table))\n\tbl.parselist(totalvalue,filename)\n\t'''", "response": "make spark lines from a pandas dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef great_circle(**kwargs):\n\n    distance  = kwargs.pop('distance')\n    azimuth   = np.radians(kwargs.pop('azimuth'))\n    latitude  = np.radians(kwargs.pop('latitude'))\n    longitude = np.radians(kwargs.pop('longitude'))\n    rmajor    = kwargs.pop('rmajor', 6378137.0)\n    rminor    = kwargs.pop('rminor', 6356752.3142)\n    f         = (rmajor - rminor) / rmajor\n\n    vector_pt = np.vectorize(vinc_pt)\n    lat_result, lon_result, angle_result = vector_pt(f, rmajor,\n                                                     latitude,\n                                                     longitude,\n                                                     azimuth,\n                                                     distance)\n    return {'latitude': np.degrees(lat_result),\n            'longitude': np.degrees(lon_result),\n            'reverse_azimuth': np.degrees(angle_result)}", "response": "Returns a dictionary of the great circle of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef great_distance(**kwargs):\n\n    sy     = kwargs.pop('start_latitude')\n    sx     = kwargs.pop('start_longitude')\n    ey     = kwargs.pop('end_latitude')\n    ex     = kwargs.pop('end_longitude')\n    rmajor = kwargs.pop('rmajor', 6378137.0)\n    rminor = kwargs.pop('rminor', 6356752.3142)\n    f      = (rmajor - rminor) / rmajor\n\n    if (np.ma.isMaskedArray(sy) or\n        np.ma.isMaskedArray(sx) or\n        np.ma.isMaskedArray(ey) or\n        np.ma.isMaskedArray(ex)\n       ):\n\n        try:\n            assert sy.size == sx.size == ey.size == ex.size\n        except AttributeError:\n            raise ValueError(\"All or none of the inputs should be masked\")\n        except AssertionError:\n            raise ValueError(\"When using masked arrays all must be of equal size\")\n\n        final_mask = np.logical_not((sy.mask | sx.mask | ey.mask | ex.mask))\n        if np.isscalar(final_mask):\n            final_mask = np.full(sy.size, final_mask, dtype=bool)\n        sy = sy[final_mask]\n        sx = sx[final_mask]\n        ey = ey[final_mask]\n        ex = ex[final_mask]\n\n        if (np.all(sy.mask) or np.all(sx.mask) or np.all(ey.mask) or np.all(ex.mask)) or \\\n           (sy.size == 0 or sx.size == 0 or ey.size == 0 or ex.size == 0):\n            vector_dist = np.vectorize(vinc_dist, otypes=[np.float64])\n        else:\n            vector_dist = np.vectorize(vinc_dist)\n\n        results = vector_dist(f, rmajor,\n                              np.radians(sy),\n                              np.radians(sx),\n                              np.radians(ey),\n                              np.radians(ex))\n\n        d = np.ma.masked_all(final_mask.size, dtype=np.float64)\n        a = np.ma.masked_all(final_mask.size, dtype=np.float64)\n        ra = np.ma.masked_all(final_mask.size, dtype=np.float64)\n\n        if len(results) == 3:\n            d[final_mask] = results[0]\n            a[final_mask] = results[1]\n            ra[final_mask] = results[2]\n\n    else:\n        vector_dist = np.vectorize(vinc_dist)\n        d, a, ra = vector_dist(f, rmajor,\n                               np.radians(sy),\n                               np.radians(sx),\n                               np.radians(ey),\n                               np.radians(ex))\n\n    return {'distance': d,\n            'azimuth': np.degrees(a),\n            'reverse_azimuth': np.degrees(ra)}", "response": "Returns a dictionaty of the great distance of the current segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef event_handler(event_name):\n\n    def wrapper(func):\n        func._event_handler = True\n        func._handled_event = event_name\n        return func\n\n    return wrapper", "response": "Decorator for designating a handler for an event type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmark a method as exposed via JSON RPC. :param name: the name of the exposed method. Must contains only letters, digits, dots and underscores. If not present or is set explicitly to ``None``, this parameter will default to the name of the exposed method. If two methods with the same name are exposed, a ``ValueError`` is raised. :type name: str :param private: Flag that specifies if the exposed method is private. :type private: bool :param is_coroutine: Flag that specifies if the method is a Tornado coroutine. If True, it will be wrapped with the :py:func:`tornado.gen.coroutine` decorator. :type is_coroutine: bool :param requires_handler_reference: If ``True``, the handler method will receive as the first parameter a ``handler`` argument with the Tornado request handler for the current request. This request handler can be further used to extract various information from the request, such as headers, cookies, etc. :type requires_handler_reference: bool .. versionadded:: 0.9.0", "response": "def exposed_method(name=None, private=False, is_coroutine=True, requires_handler_reference=False):\n    \"\"\"\n    Marks a method as exposed via JSON RPC.\n\n    :param name: the name of the exposed method. Must contains only letters, digits, dots and underscores.\n                 If not present or is set explicitly to ``None``, this parameter will default to the name\n                 of the exposed method.\n                 If two methods with the same name are exposed, a ``ValueError`` is raised.\n    :type name: str\n    :param private: Flag that specifies if the exposed method is private.\n    :type private: bool\n    :param is_coroutine: Flag that specifies if the method is a Tornado coroutine. If True, it will be wrapped\n                         with the :py:func:`tornado.gen.coroutine` decorator.\n    :type is_coroutine: bool\n    :param requires_handler_reference: If ``True``, the handler method will receive as the first\n                                       parameter a ``handler`` argument with the Tornado\n                                       request handler for the current request. This request handler\n                                       can be further used to extract various information from the\n                                       request, such as headers, cookies, etc.\n    :type requires_handler_reference: bool\n\n    .. versionadded:: 0.9.0\n\n    \"\"\"\n\n    def wrapper(func):\n\n        # validation\n\n        if name:\n            method_name = name\n        else:\n            method_name = func.__name__\n\n        if not METHOD_NAME_REGEX.match(method_name):\n            raise ValueError(\"Invalid method name: '{}'\".format(method_name))\n\n        @functools.wraps(func)\n        def real_wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n\n        # set appropriate flags\n        if private:\n            setattr(real_wrapper, \"_exposed_private\", True)\n        else:\n            setattr(real_wrapper, \"_exposed_public\", True)\n\n        if is_coroutine:\n            real_wrapper.__gemstone_is_coroutine = True\n            real_wrapper = tornado.gen.coroutine(real_wrapper)\n            setattr(real_wrapper, \"_is_coroutine\", True)\n\n        if requires_handler_reference:\n            setattr(real_wrapper, \"_req_h_ref\", True)\n\n        setattr(real_wrapper, \"_exposed_name\", method_name)\n\n        return real_wrapper\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef available(self):\n        ''' Check if a related database exists '''\n        return self.db_name in map(\n            lambda x: x['name'], self._db.get_database_list()\n        )", "response": "Check if a related database exists"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_geohash_tables(table,listofprecisions,**kwargs):\n\t'''\n\tsort_by - field to sort by for each group\n\treturn_squares - boolean arg if true returns a list of squares instead of writing out to table\n\t'''\n\treturn_squares = False\n\tsort_by = 'COUNT'\n\t# logic for accepting kwarg inputs\n\tfor key,value in kwargs.iteritems():\n\t\tif key == 'sort_by':\n\t\t\tsort_by = value\n\t\tif key == 'return_squares':\n\t\t\treturn_squares = value\n\n\t# getting header\n\theader = df2list(table)[0]\n\n\t# getting columns\n\tcolumns = header[10:]\n\n\t# getting original table\n\toriginaltable = table\n\tif not sort_by == 'COUNT':\n\t\toriginaltable = originaltable.sort([sort_by],ascending=[0])\n\n\n\n\n\tlistofprecisions = sorted(listofprecisions,reverse=True)\n\t# making total table to hold a list of dfs\n\tif return_squares == True and listofprecisions[-1] == 8:\n\t\ttotal_list = [table]\n\telif return_squares == True:\n\t\ttotal_list = []\n\n\tfor row in listofprecisions:\n\t\tprecision = int(row)\n\t\ttable = originaltable\n\t\ttable['GEOHASH'] = table.GEOHASH.str[:precision]\n\t\ttable = table[['GEOHASH','COUNT']+columns].groupby(['GEOHASH'],sort=True).sum()\n\t\ttable = table.sort([sort_by],ascending=[0])\n\t\ttable = table.reset_index()\n\n\t\tnewsquares = [header]\n\t\t# iterating through each square here \n\t\tfor row in df2list(table)[1:]:\n\t\t\t# getting points\n\t\t\tpoints = get_points_geohash(row[0])\n\t\t\t\n\t\t\t# making new row\n\t\t\tnewrow = [row[0]] + points + row[1:]\n\t\t\t\n\t\t\t# appending to newsquares \n\t\t\tnewsquares.append(newrow)\n\n\t\t# taking newsquares to dataframe\n\t\ttable = list2df(newsquares)\n\n\t\tif return_squares == True:\n\t\t\ttotal_list.append(table)\n\t\telse:\n\t\t\ttable.to_csv('squares' + str(precision) + '.csv',index=False)\n\n\tif return_squares == True:\n\t\treturn total_list\n\telse:\n\t\tprint 'Wrote output squares tables to csv files.'", "response": "make a list of tables with a geohash table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the angle of the vincenty of a sphere", "response": "def angSepVincenty(ra1, dec1, ra2, dec2):\n    \"\"\"\n    Vincenty formula for distances on a sphere\n    \"\"\"\n    ra1_rad = np.radians(ra1)\n    dec1_rad = np.radians(dec1)\n    ra2_rad = np.radians(ra2)\n    dec2_rad = np.radians(dec2)\n\n    sin_dec1, cos_dec1 = np.sin(dec1_rad), np.cos(dec1_rad)\n    sin_dec2, cos_dec2 = np.sin(dec2_rad), np.cos(dec2_rad)\n    delta_ra = ra2_rad - ra1_rad\n    cos_delta_ra, sin_delta_ra = np.cos(delta_ra), np.sin(delta_ra)\n\n    diffpos = np.arctan2(np.sqrt((cos_dec2 * sin_delta_ra) ** 2 +\n                         (cos_dec1 * sin_dec2 -\n                          sin_dec1 * cos_dec2 * cos_delta_ra) ** 2),\n                          sin_dec1 * sin_dec2 + cos_dec1 * cos_dec2 * cos_delta_ra)\n\n    return np.degrees(diffpos)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a comma - separated file with columns ra dec magnitude.", "response": "def parse_file(infile, exit_on_error=True):\n    \"\"\"Parse a comma-separated file with columns \"ra,dec,magnitude\".\n    \"\"\"\n    try:\n        a, b, mag = np.atleast_2d(\n                            np.genfromtxt(\n                                        infile,\n                                        usecols=[0, 1, 2],\n                                        delimiter=','\n                                        )\n                    ).T\n    except IOError as e:\n        if exit_on_error:\n            logger.error(\"There seems to be a problem with the input file, \"\n                         \"the format should be: RA_degrees (J2000), Dec_degrees (J2000), \"\n                         \"Magnitude. There should be no header, columns should be \"\n                         \"separated by a comma\")\n            sys.exit(1)\n        else:\n            raise e\n    return a, b, mag"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef onSiliconCheck(ra_deg, dec_deg, FovObj, padding_pix=DEFAULT_PADDING):\n    dist = angSepVincenty(FovObj.ra0_deg, FovObj.dec0_deg, ra_deg, dec_deg)\n    if dist >= 90.:\n        return False\n    # padding_pix=3 means that objects less than 3 pixels off the edge of\n    # a channel are counted inside, to account for inaccuracies in K2fov.\n    return FovObj.isOnSilicon(ra_deg, dec_deg, padding_pix=padding_pix)", "response": "Check a single position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef onSiliconCheckList(ra_deg, dec_deg, FovObj, padding_pix=DEFAULT_PADDING):\n    dist = angSepVincenty(FovObj.ra0_deg, FovObj.dec0_deg, ra_deg, dec_deg)\n    mask = (dist < 90.)\n    out = np.zeros(len(dist), dtype=bool)\n    out[mask] = FovObj.isOnSiliconList(ra_deg[mask], dec_deg[mask], padding_pix=padding_pix)\n    return out", "response": "Check a list of positions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef K2onSilicon(infile, fieldnum, do_nearSiliconCheck=False):\n    ra_sources_deg, dec_sources_deg, mag = parse_file(infile)\n    n_sources = np.shape(ra_sources_deg)[0]\n    if n_sources > 500:\n        logger.warning(\"Warning: there are {0} sources in your target list, \"\n                       \"this could take some time\".format(n_sources))\n\n    k = fields.getKeplerFov(fieldnum)\n    raDec = k.getCoordsOfChannelCorners()\n\n    onSilicon = list(\n                    map(\n                        onSiliconCheck,\n                        ra_sources_deg,\n                        dec_sources_deg,\n                        np.repeat(k, len(ra_sources_deg))\n                        )\n                    )\n    onSilicon = np.array(onSilicon, dtype=bool)\n\n    if do_nearSiliconCheck:\n        nearSilicon = list(\n                        map(\n                            nearSiliconCheck,\n                            ra_sources_deg,\n                            dec_sources_deg,\n                            np.repeat(k, len(ra_sources_deg))\n                            )\n                        )\n        nearSilicon = np.array(nearSilicon, dtype=bool)\n\n    if got_mpl:\n        almost_black = '#262626'\n        light_grey = np.array([float(248)/float(255)]*3)\n        ph = proj.PlateCaree()\n        k.plotPointing(ph, showOuts=False)\n        targets = ph.skyToPix(ra_sources_deg, dec_sources_deg)\n        targets = np.array(targets)\n        fig = pl.gcf()\n        ax = fig.gca()\n        ax = fig.add_subplot(111)\n        ax.scatter(*targets, color='#fc8d62', s=7, label='not on silicon')\n        ax.scatter(targets[0][onSilicon], targets[1][onSilicon],\n                   color='#66c2a5', s=8, label='on silicon')\n        ax.set_xlabel('R.A. [degrees]', fontsize=16)\n        ax.set_ylabel('Declination [degrees]', fontsize=16)\n        ax.invert_xaxis()\n        ax.minorticks_on()\n        legend = ax.legend(loc=0, frameon=True, scatterpoints=1)\n        rect = legend.get_frame()\n        rect.set_alpha(0.3)\n        rect.set_facecolor(light_grey)\n        rect.set_linewidth(0.0)\n        texts = legend.texts\n        for t in texts:\n            t.set_color(almost_black)\n        fig.savefig('targets_fov.png', dpi=300)\n        pl.close('all')\n\n    # prints zero if target is not on silicon\n    siliconFlag = np.zeros_like(ra_sources_deg)\n\n    # print a 1 if target is near but not on silicon\n    if do_nearSiliconCheck:\n        siliconFlag = np.where(nearSilicon, 1, siliconFlag)\n\n    # prints a 2 if target is on silicon\n    siliconFlag = np.where(onSilicon, 2, siliconFlag)\n\n    outarr = np.array([ra_sources_deg, dec_sources_deg, mag, siliconFlag])\n    np.savetxt('targets_siliconFlag.csv', outarr.T, delimiter=', ',\n               fmt=['%10.10f', '%10.10f', '%10.2f', '%i'])\n\n    if got_mpl:\n        print('I made two files: targets_siliconFlag.csv and targets_fov.png')\n    else:\n        print('I made one file: targets_siliconFlag.csv')", "response": "Checks whether targets are on silicon during a given campaign."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef K2onSilicon_main(args=None):\n    import argparse\n    parser = argparse.ArgumentParser(\n        description=\"Run K2onSilicon to find which targets in a \"\n                    \"list call on active silicon for a given K2 campaign.\")\n    parser.add_argument('csv_file', type=str,\n                        help=\"Name of input csv file with targets, column are \"\n                             \"Ra_degrees, Dec_degrees, Kepmag\")\n    parser.add_argument('campaign', type=int, help='K2 Campaign number')\n    args = parser.parse_args(args)\n    K2onSilicon(args.csv_file, args.campaign)", "response": "Function called when K2onSilicon is executed on the command line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the cached version of the template with the given name.", "response": "def _get_template(self, template_name):\n        \"\"\"\n        Retrieve the cached version of the template\n        \"\"\"\n        if template_name not in self.chached_templates:\n            self.chached_templates[template_name] = self.env.get_template(template_name)\n        return self.chached_templates[template_name]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_blocks(self, template_name, **context):\n        blocks = {}\n        template = self._get_template(template_name)\n        for block in template.blocks:\n            blocks[block] = self._render_context(template,\n                                                template.blocks[block],\n                                                **context)\n        return blocks", "response": "Render all the blocks with the given name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender a block in the template file with the given context", "response": "def render(self, template_name, block, **context):\n        \"\"\"\n        TO render a block in the template\n        :param template_name: the template file name\n        :param block: the name of the block within {% block $block_name %}\n        :param context: **kwargs context to render\n        :returns string: of rendered content\n        \"\"\"\n        template = self._get_template(template_name)\n        return self._render_context(template,\n                                    template.blocks[block],\n                                    **context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering a block to a string with its context", "response": "def _render_context(self, template, block, **context):\n        \"\"\"\n        Render a block to a string with its context\n        \"\"\"\n        return u''.join(block(template.new_context(context)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the base class for the given Flask application.", "response": "def init_app(self, app):\n        \"\"\"\n        For Flask using the app config\n        \"\"\"\n        self.__init__(aws_access_key_id=app.config.get(\"SES_AWS_ACCESS_KEY\"),\n                      aws_secret_access_key=app.config.get(\"SES_AWS_SECRET_KEY\"),\n                      region=app.config.get(\"SES_REGION\", \"us-east-1\"),\n                      sender=app.config.get(\"SES_SENDER\", None),\n                      reply_to=app.config.get(\"SES_REPLY_TO\", None),\n                      template=app.config.get(\"SES_TEMPLATE\", None),\n                      template_context=app.config.get(\"SES_TEMPLATE_CONTEXT\", {})\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending an email message using the AWS SES interface.", "response": "def send(self, to, subject, body, reply_to=None, **kwargs):\n        \"\"\"\n        Send email via AWS SES.\n        :returns string: message id\n\n        ***\n\n        Composes an email message based on input data, and then immediately\n        queues the message for sending.\n\n        :type to: list of strings or string\n        :param to: The To: field(s) of the message.\n\n        :type subject: string\n        :param subject: The subject of the message: A short summary of the\n                        content, which will appear in the recipient's inbox.\n\n        :type body: string\n        :param body: The message body.\n\n        :sender: email address of the sender. String or typle(name, email)\n        :reply_to: email to reply to\n\n        **kwargs:\n\n        :type cc_addresses: list of strings or string\n        :param cc_addresses: The CC: field(s) of the message.\n\n        :type bcc_addresses: list of strings or string\n        :param bcc_addresses: The BCC: field(s) of the message.\n\n        :type format: string\n        :param format: The format of the message's body, must be either \"text\"\n                       or \"html\".\n\n        :type return_path: string\n        :param return_path: The email address to which bounce notifications are\n                            to be forwarded. If the message cannot be delivered\n                            to the recipient, then an error message will be\n                            returned from the recipient's ISP; this message\n                            will then be forwarded to the email address\n                            specified by the ReturnPath parameter.\n\n        :type text_body: string\n        :param text_body: The text body to send with this email.\n\n        :type html_body: string\n        :param html_body: The html body to send with this email.\n\n        \"\"\"\n        if not self.sender:\n            raise AttributeError(\"Sender email 'sender' or 'source' is not provided\")\n\n        kwargs[\"to_addresses\"] = to\n        kwargs[\"subject\"] = subject\n        kwargs[\"body\"] = body\n        kwargs[\"source\"] = self._get_sender(self.sender)[0]\n        kwargs[\"reply_addresses\"] = self._get_sender(reply_to or self.reply_to)[2]\n\n        response = self.ses.send_email(**kwargs)\n        return response[\"SendEmailResponse\"][\"SendEmailResult\"][\"MessageId\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_template(self, template, to, reply_to=None, **context):\n        mail_data = self.parse_template(template, **context)\n        subject = mail_data[\"subject\"]\n        body = mail_data[\"body\"]\n        del(mail_data[\"subject\"])\n        del(mail_data[\"body\"])\n\n        return self.send(to=to,\n                         subject=subject,\n                         body=body,\n                         reply_to=reply_to,\n                         **mail_data)", "response": "Send email from template"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a template and returns all the blocks that are required and the mail params that are passed to the template.", "response": "def parse_template(self, template, **context):\n        \"\"\"\n        To parse a template and return all the blocks\n        \"\"\"\n        required_blocks = [\"subject\", \"body\"]\n        optional_blocks = [\"text_body\", \"html_body\", \"return_path\", \"format\"]\n\n        if self.template_context:\n            context = dict(self.template_context.items() + context.items())\n        blocks = self.template.render_blocks(template, **context)\n\n        for rb in required_blocks:\n            if rb not in blocks:\n                raise AttributeError(\"Template error: block '%s' is missing from '%s'\" % (rb, template))\n\n        mail_params = {\n            \"subject\": blocks[\"subject\"].strip(),\n            \"body\": blocks[\"body\"]\n        }\n        for ob in optional_blocks:\n            if ob in blocks:\n                if ob == \"format\" and mail_params[ob].lower() not in [\"html\", \"text\"]:\n                    continue\n                mail_params[ob] = blocks[ob]\n        return mail_params"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_sender(self, sender):\n        if isinstance(sender, tuple):\n            return \"%s <%s>\" % sender, sender[0], sender[1]\n        else:\n            return sender, sender, sender", "response": "Return a tuple of 3 elements where the first element is the name the second is the email address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating and sends a command message unit.", "response": "def write(self, transport, protocol, *data):\n        \"\"\"Generates and sends a command message unit.\n\n        :param transport: An object implementing the `.Transport` interface.\n            It is used by the protocol to send the message.\n        :param protocol: An object implementing the `.Protocol` interface.\n        :param data: The program data.\n\n        :raises AttributeError: if the command is not writable.\n\n        \"\"\"\n        if not self._write:\n            raise AttributeError('Command is not writeable')\n        if self.protocol:\n            protocol = self.protocol\n        if self._write.data_type:\n            data = _dump(self._write.data_type, data)\n        else:\n            # TODO We silently ignore possible data\n            data = ()\n        if isinstance(transport, SimulatedTransport):\n            self.simulate_write(data)\n        else:\n            protocol.write(transport, self._write.header, *data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate and sends a query message unit.", "response": "def query(self, transport, protocol, *data):\n        \"\"\"Generates and sends a query message unit.\n\n        :param transport: An object implementing the `.Transport` interface.\n            It is used by the protocol to send the message and receive the\n            response.\n        :param protocol: An object implementing the `.Protocol` interface.\n        :param data: The program data.\n\n        :raises AttributeError: if the command is not queryable.\n\n        \"\"\"\n        if not self._query:\n            raise AttributeError('Command is not queryable')\n        if self.protocol:\n            protocol = self.protocol\n        if self._query.data_type:\n            data = _dump(self._query.data_type, data)\n        else:\n            # TODO We silently ignore possible data\n            data = ()\n        if isinstance(transport, SimulatedTransport):\n            response = self.simulate_query(data)\n        else:\n            response = protocol.query(transport, self._query.header, *data)\n        response = _load(self._query.response_type, response)\n\n        # Return single value if parsed_data is 1-tuple.\n        return response[0] if len(response) == 1 else response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write(self, cmd, *datas):\n        cmd = Command(write=cmd)\n        cmd.write(self._transport, self._protocol, *datas)", "response": "Helper function to simplify writing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _query(self, cmd, *datas):\n        cmd = Command(query=cmd)\n        return cmd.query(self._transport, self._protocol, *datas)", "response": "Helper function to allow method queries."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates DAM with the given name and config", "response": "def createDAM(dam_name, config):\r\n        ''' create DAM '''\r\n        if 'yahoo' == dam_name:\r\n            from analyzerdam.yahooDAM import YahooDAM\r\n            dam=YahooDAM()\r\n        elif 'google' == dam_name:\r\n            from analyzerdam.google import GoogleDAM\r\n            dam=GoogleDAM()\r\n        elif 'excel' == dam_name:\r\n            from analyzerdam.excelDAM import ExcelDAM\r\n            dam=ExcelDAM()\r\n        elif 'hbase' == dam_name:\r\n            from analyzerdam.hbaseDAM import HBaseDAM\r\n            dam=HBaseDAM()\r\n        elif 'sql' == dam_name:\r\n            from analyzerdam.sqlDAM import SqlDAM\r\n            dam=SqlDAM(config)\r\n        elif 'cex' == dam_name:\r\n            from analyzerdam.cex import CexDAM\r\n            dam=CexDAM(config)\r\n        else:\r\n            raise UfException(Errors.INVALID_DAM_TYPE,\r\n                              \"DAM type is invalid %s\" % dam_name)\r\n\r\n        return dam"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getAll(self, symbol):\r\n        values = self.__request(symbol, 'l1c1va2xj1b4j4dyekjm3m4rr5p5p6s7').split(',')\r\n        data = {}\r\n        data['price'] = values[0]\r\n        data['change'] = values[1]\r\n        data['volume'] = values[2]\r\n        data['avg_daily_volume'] = values[3]\r\n        data['stock_exchange'] = values[4]\r\n        data['market_cap'] = values[5]\r\n        data['book_value'] = values[6]\r\n        data['ebitda'] = values[7]\r\n        data['dividend_per_share'] = values[8]\r\n        data['dividend_yield'] = values[9]\r\n        data['earnings_per_share'] = values[10]\r\n        data['52_week_high'] = values[11]\r\n        data['52_week_low'] = values[12]\r\n        data['50day_moving_avg'] = values[13]\r\n        data['200day_moving_avg'] = values[14]\r\n        data['price_earnings_ratio'] = values[15]\r\n        data['price_earnings_growth_ratio'] = values[16]\r\n        data['price_sales_ratio'] = values[17]\r\n        data['price_book_ratio'] = values[18]\r\n        data['short_ratio'] = values[19]\r\n        return data", "response": "Get all available quote data for the given ticker symbol. Returns a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of quotes for the given ticker symbol.", "response": "def getQuotes(self, symbol, start, end):\r\n        \"\"\"\r\n        Get historical prices for the given ticker symbol.\r\n        Date format is 'YYYY-MM-DD'\r\n\r\n        Returns a nested list.\r\n        \"\"\"\r\n        try:\r\n            start = str(start).replace('-', '')\r\n            end = str(end).replace('-', '')\r\n\r\n            url = 'http://ichart.yahoo.com/table.csv?s=%s&' % symbol + \\\r\n                'd=%s&' % str(int(end[4:6]) - 1) + \\\r\n                'e=%s&' % str(int(end[6:8])) + \\\r\n                'f=%s&' % str(int(end[0:4])) + \\\r\n                'g=d&' + \\\r\n                'a=%s&' % str(int(start[4:6]) - 1) + \\\r\n                'b=%s&' % str(int(start[6:8])) + \\\r\n                'c=%s&' % str(int(start[0:4])) + \\\r\n                'ignore=.csv'\r\n            days = urllib.urlopen(url).readlines()\r\n            values = [day[:-2].split(',') for day in days]\r\n            # sample values:[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Clos'], \\\r\n            #              ['2009-12-31', '112.77', '112.80', '111.39', '111.44', '90637900', '109.7']...]\r\n            data = []\r\n            for value in values[1:]:\r\n                data.append(Quote(value[0], value[1], value[2], value[3], value[4], value[5], value[6]))\r\n\r\n            dateValues = sorted(data, key = lambda q: q.time)\r\n            return dateValues\r\n\r\n        except IOError:\r\n            raise UfException(Errors.NETWORK_ERROR, \"Can't connect to Yahoo server\")\r\n        except BaseException:\r\n            raise UfException(Errors.UNKNOWN_ERROR, \"Unknown Error in YahooFinance.getHistoricalPrices %s\" % traceback.format_exc())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninstalling the product on the user s store.", "response": "def installProductOn(self, userstore):\n        \"\"\"\n        Creates an Installation in this user store for our collection\n        of powerups, and then install those powerups on the user's\n        store.\n        \"\"\"\n\n        def install():\n            i = Installation(store=userstore)\n            i.types = self.types\n            i.install()\n        userstore.transact(install)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef removeProductFrom(self, userstore):\n        def uninstall():\n            #this is probably highly insufficient, but i don't know the\n            #requirements\n            i = userstore.findFirst(Installation,\n                                    Installation.types == self.types)\n            i.uninstall()\n            i.deleteFromStore()\n        userstore.transact(uninstall)", "response": "Removes the product from the user s store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall this product on a user store.", "response": "def installOrResume(self, userstore):\n        \"\"\"\n        Install this product on a user store. If this product has been\n        installed on the user store already and the installation is suspended,\n        it will be resumed. If it exists and is not suspended, an error will be\n        raised.\n        \"\"\"\n        for i in userstore.query(Installation, Installation.types == self.types):\n            if i.suspended:\n                unsuspendTabProviders(i)\n                return\n            else:\n                raise RuntimeError(\"installOrResume called for an\"\n                                   \" installation that isn't suspended\")\n        else:\n            self.installProductOn(userstore)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the items this Installation refers to.", "response": "def items(self):\n        \"\"\"\n        Loads the items this Installation refers to.\n        \"\"\"\n        for id in self._items:\n            yield self.store.getItemByID(int(id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef install(self):\n        items = []\n        for typeName in self.types:\n            it = self.store.findOrCreate(namedAny(typeName))\n            installOn(it, self.store)\n            items.append(str(it.storeID).decode('ascii'))\n        self._items = items", "response": "Called when installed on the user store. Installs my powerups."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uninstall(self):\n        for item in self.items:\n            uninstallFrom(item, self.store)\n        self._items = []", "response": "Called when uninstalled from the user store. Uninstalls all powerups."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new product instance which confers the given list of powerup item types.", "response": "def createProduct(self, powerups):\n        \"\"\"\n        Create a new L{Product} instance which confers the given\n        powerups.\n\n        @type powerups: C{list} of powerup item types\n\n        @rtype: L{Product}\n        @return: The new product instance.\n        \"\"\"\n        types = [qual(powerup).decode('ascii')\n                       for powerup in powerups]\n        for p in self.store.parent.query(Product):\n            for t in types:\n                if t in p.types:\n                    raise ValueError(\"%s is already included in a Product\" % (t,))\n        return Product(store=self.store.parent,\n                       types=types)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a product and return a status string which should be part of a template.", "response": "def coerceProduct(self, **kw):\n        \"\"\"\n        Create a product and return a status string which should be part of a\n        template.\n\n        @param **kw: Fully qualified Python names for powerup types to\n        associate with the created product.\n        \"\"\"\n        self.original.createProduct(filter(None, kw.values()))\n        return u'Created.'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(self):\n        api = self.doapi_manager\n        return api._action(api.request(self.url)[\"action\"])", "response": "Fetch & return a new Action object representing the action s current\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_resource(self):\n        try:\n            if self.resource_type == \"droplet\":\n                return self.doapi_manager.fetch_droplet(self.resource_id)\n            elif self.resource_type == \"image\":\n                return self.doapi_manager.fetch_image(self.resource_id)\n            elif self.resource_type == \"floating_ip\":\n                return self.doapi_manager.fetch_floating_ip(self.resource_id)\n            else:\n                raise ValueError('{0.resource_type!r}: unknown resource_type'\\\n                                 .format(self))\n        except DOAPIError as e:\n            if e.response.status_code == 404:\n                return None\n            else:\n                raise", "response": "Fetch & return the resource that the action operated on."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait(self, wait_interval=None, wait_time=None):\n        return next(self.doapi_manager.wait_actions([self], wait_interval,\n                                                            wait_time))", "response": "Wait for the action to complete and return its final state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wasModified(self):\n        self.filePath.restat()\n        mtime = self.filePath.getmtime()\n        if mtime >= self.lastModified:\n            return True\n        else:\n            return False", "response": "Check to see if this module has been modified on disk since the last\n        time it was cached."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the cache entry if any filesystem information has changed.", "response": "def maybeUpdate(self):\n        \"\"\"\n        Check this cache entry and update it if any filesystem information has\n        changed.\n        \"\"\"\n        if self.wasModified():\n            self.lastModified = self.filePath.getmtime()\n            self.fileContents = self.filePath.getContent()\n            self.hashValue = hashlib.sha1(self.fileContents).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a JavaScript module cache from the file path cache.", "response": "def getModule(self, moduleName):\n        \"\"\"\n        Retrieve a JavaScript module cache from the file path cache.\n\n        @returns: Module cache for the named module.\n        @rtype: L{CachedJSModule}\n        \"\"\"\n        if moduleName not in self.moduleCache:\n            modulePath = FilePath(\n                athena.jsDeps.getModuleForName(moduleName)._cache.path)\n            cachedModule = self.moduleCache[moduleName] = CachedJSModule(\n                moduleName, modulePath)\n        else:\n            cachedModule = self.moduleCache[moduleName]\n        return cachedModule"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef locateChild(self, ctx, segments):\n        if len(segments) != 2:\n            return NotFound\n        hashCode, moduleName = segments\n        cachedModule = self.getModule(moduleName)\n        return static.Data(\n            cachedModule.fileContents,\n            'text/javascript', expires=(60 * 60 * 24 * 365 * 5)), []", "response": "Locate a child in the given segments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves the OpenAIRE grant code.", "response": "def resolve_grant_endpoint(doi_grant_code):\n    \"\"\"Resolve the OpenAIRE grant.\"\"\"\n    # jsonresolver will evaluate current_app on import if outside of function.\n    from flask import current_app\n    pid_value = '10.13039/{0}'.format(doi_grant_code)\n    try:\n        _, record = Resolver(pid_type='grant', object_type='rec',\n                             getter=Record.get_record).resolve(pid_value)\n        return record\n    except Exception:\n        current_app.logger.error(\n            'Grant {0} does not exists.'.format(pid_value), exc_info=True)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef jsonresolver_loader(url_map):\n    from flask import current_app\n    url_map.add(Rule(\n        '/grants/10.13039/<path:doi_grant_code>',\n        endpoint=resolve_grant_endpoint,\n        host=current_app.config['OPENAIRE_JSONRESOLVER_GRANTS_HOST']))", "response": "Resolve the OpenAIRE grant."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_result(data, key=''):\n    if not isinstance(data, dict):\n        return False\n\n    if key:\n        if key in data:\n            return True\n\n        return False\n\n    if 'resultCode' in data.keys():\n        # OpenBus\n        return True if data.get('resultCode', -1) == 0 else False\n\n    elif 'code' in data.keys():\n        # Parking\n        return True if data.get('code', -1) == 0 else False\n\n    return False", "response": "Check the result of an API response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef datetime_string(day, month, year, hour, minute):\n    # Overflow\n    if hour < 0 or hour > 23: hour = 0\n    if minute < 0 or minute > 60: minute = 0\n\n    return '%d-%02d-%02dT%02d:%02d:00' % (year, month, day, hour, minute)", "response": "Build a date string from the provided day month year and hour and minute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ints_to_string(ints):\n    if not isinstance(ints, list):\n        return six.u(str(ints))\n\n    return '|'.join(six.u(str(l)) for l in ints)", "response": "Convert a list of integers to a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef response_list(data, key):\n    if key not in data:\n        return None\n\n    if isinstance(data[key], list):\n        return data[key]\n\n    else:\n        return [data[key],]", "response": "Obtain the relevant response data in a list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef base_uri(self):\n        if self._base_uri is None:\n            if self._resolver is not None:\n                self._base_uri = self.resolver.resolution_scope\n            else:\n                self._base_uri = 'http://pudo.github.io/jsongraph'\n        return URIRef(self._base_uri)", "response": "Return the base URI for the resource ID for this object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolver(self):\n        if self._resolver is None:\n            self._resolver = RefResolver(self.base_uri, {})\n        # if self.base_uri not in self._resolver.store:\n        #    self._resolver.store[self.base_uri] = self.config\n        return self._resolver", "response": "Returns a RefResolver for JSON Schema references."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an in - memory store for RDF data. Either an in - memory store or an analytical store.", "response": "def store(self):\n        \"\"\" Backend storage for RDF data. Either an in-memory store, or an\n        external triple store controlled via SPARQL. \"\"\"\n        if self._store is None:\n            config = self.config.get('store', {})\n            if 'query' in config and 'update' in config:\n                self._store = sparql_store(config.get('query'),\n                                           config.get('update'))\n            else:\n                self._store = plugin.get('IOMemory', Store)()\n            log.debug('Created store: %r', self._store)\n        return self._store"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets or create a context with the given identifier and provenance meta data.", "response": "def context(self, identifier=None, meta=None):\n        \"\"\" Get or create a context, with the given identifier and/or\n        provenance meta data. A context can be used to add, update or delete\n        objects in the store. \"\"\"\n        return Context(self, identifier=identifier, meta=meta)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(self, alias, uri):\n        # TODO: do we want to constrain the valid alias names.\n        if isinstance(uri, dict):\n            id = uri.get('id', alias)\n            self.resolver.store[id] = uri\n            uri = id\n        self.aliases[alias] = uri", "response": "Register a new schema URI under a given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the URI for a given alias.", "response": "def get_uri(self, alias):\n        \"\"\" Get the URI for a given alias. A registered URI will return itself,\n        otherwise ``None`` is returned. \"\"\"\n        if alias in self.aliases.keys():\n            return self.aliases[alias]\n        if alias in self.aliases.values():\n            return alias\n        raise GraphException('No such schema: %r' % alias)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves the schema for the given alias.", "response": "def get_schema(self, alias):\n        \"\"\" Actually resolve the schema for the given alias/URI. \"\"\"\n        if isinstance(alias, dict):\n            return alias\n        uri = self.get_uri(alias)\n        if uri is None:\n            raise GraphException('No such schema: %r' % alias)\n        uri, schema = self.resolver.resolve(uri)\n        return schema"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear(self, context=None):\n        context = URIRef(context).n3() if context is not None else '?g'\n        query = \"\"\"\n            DELETE { GRAPH %s { ?s ?p ?o } } WHERE { GRAPH %s { ?s ?p ?o } }\n        \"\"\" % (context, context)\n        self.parent.graph.update(query)", "response": "Delete all data from the graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_url(text):\n    if text is None:\n        return False\n    text = text.lower()\n    return text.startswith('http://') or text.startswith('https://') or \\\n        text.startswith('urn:') or text.startswith('file://')", "response": "Check if the given text looks like a URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nescaping a URL properly.", "response": "def safe_uriref(text):\n    \"\"\" Escape a URL properly. \"\"\"\n    url_ = url.parse(text).sanitize().deuserinfo().canonical()\n    return URIRef(url_.punycode().unicode())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef job_stats_enhanced(job_id):\n    stats_dict = {}\n    with os.popen('qstat -xf ' + str(job_id)) as f:\n        try:\n            line = f.readline().strip()\n            while line:\n                if line.startswith('Job Id:'):\n                    stats_dict['job_id'] = line.split(':')[1].split('.')[0].strip()\n                elif line.startswith('resources_used.walltime'):\n                    stats_dict['wallclock'] = get_timedelta(line.split('=')[1])\n                elif line.startswith('resources_used.cput'):\n                    stats_dict['cpu'] = get_timedelta(line.split('=')[1])\n                elif line.startswith('queue'):\n                    stats_dict['queue'] = line.split('=')[1].strip()\n                elif line.startswith('job_state'):\n                    stats_dict['status'] = line.split('=')[1].strip()\n                elif line.startswith('Exit_status'):\n                    stats_dict['exit_code'] = line.split('=')[1].strip()\n                elif line.startswith('Exit_status'):\n                    stats_dict['exit_code'] = line.split('=')[1].strip()\n                elif line.startswith('stime'):\n                    stats_dict['start'] = line.split('=')[1].strip()\n                line = f.readline().strip()\n            if stats_dict['status'] == 'F' and 'exit_code' not in stats_dict:\n                stats_dict['status'] = 'CA'\n            elif stats_dict['status'] == 'F' and stats_dict['exit_code'] == '0':\n                stats_dict['status'] = 'PBS_F'\n        except Exception as e:\n            with os.popen('qstat -xaw ' + str(job_id)) as f:\n                try:\n                    output = f.readlines()\n                    for line in output:\n                        if str(job_id) in line:\n                            cols = line.split()\n                            stats_dict['job_id'] = cols[0].split('.')[0]\n                            stats_dict['queue'] = cols[2]\n                            stats_dict['status'] = cols[9]\n                            stats_dict['wallclock'] = get_timedelta(cols[10])\n                            return stats_dict\n                except Exception as e:\n                    print(e)\n                    print('PBS: Error reading job stats')\n                    stats_dict['status'] = 'UNKNOWN'\n    return stats_dict", "response": "Get full job and step stats for a given job_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getOrigin(self, cartesian=False):\n        out = self.origin.copy()\n\n        if cartesian is False:\n            out = self.getRaDecs(out)\n        return out", "response": "Returns the ra dec of the S - C\n        if the S - C\n        is pointed at the origin"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing a pointing model without changing the internal object pointing", "response": "def computePointing(self, ra_deg, dec_deg, roll_deg, cartesian=False):\n        \"\"\"Compute a pointing model without changing the internal object pointing\"\"\"\n        # Roll FOV\n        Rrotate = r.rotateInXMat(roll_deg)  # Roll\n\n        # Slew from ra/dec of zero\n        Ra = r.rightAscensionRotationMatrix(ra_deg)\n        Rd = r.declinationRotationMatrix(dec_deg)\n        Rslew = np.dot(Ra, Rd)\n\n        R = np.dot(Rslew, Rrotate)\n\n        slew = self.origin*1\n        for i, row in enumerate(self.origin):\n            slew[i, 3:6] = np.dot(R, row[3:6])\n\n        if cartesian is False:\n            slew = self.getRaDecs(slew)\n        return slew"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef isOnSiliconList(self, ra_deg, dec_deg, padding_pix=DEFAULT_PADDING):\n        ch, col, row = self.getChannelColRowList(ra_deg, dec_deg)\n        out = np.zeros(len(ch), dtype=bool)\n        for channel in set(ch):\n            mask = (ch == channel)\n            if channel in self.brokenChannels:\n                continue\n            if channel > 84:\n                continue\n            out[mask] = self.colRowIsOnSciencePixelList(col[mask], row[mask], padding_pix)\n        return out", "response": "similar to isOnSilicon but takes lists as input"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pickAChannelList(self, ra_deg, dec_deg):\n        try:\n            from astropy.coordinates import SkyCoord\n            from astropy import units as u\n        except ImportError:\n            raise ImportError(\"AstroPy needs to be installed to use this feature.\")\n        cRa = self.currentRaDec[:, 3]  # Ra of each channel corner\n        cDec = self.currentRaDec[:, 4]  # dec of each channel corner\n        catalog = SkyCoord(cRa*u.deg, cDec*u.deg)\n        position = SkyCoord(ra_deg*u.deg, dec_deg*u.deg)\n        idx, _, _ = position.match_to_catalog_sky(catalog)\n        return self.currentRaDec[idx, 2]", "response": "Similar to pickAChannel but takes lists as input."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the given location is observable with a science CCD.", "response": "def isOnSilicon(self, ra_deg, dec_deg, padding_pix=DEFAULT_PADDING):\n        \"\"\"Returns True if the given location is observable with a science CCD.\n\n        Parameters\n        ----------\n        ra_deg : float\n            Right Ascension (J2000) in decimal degrees.\n\n        dec_deg : float\n            Declination (J2000) in decimal degrees.\n\n        padding : float\n            Objects <=  this many pixels off the edge of a channel are counted\n            as inside.  This allows one to compensate for the slight\n            inaccuracy in `K2fov` that results from e.g. the lack of optical\n            distortion modeling.\n        \"\"\"\n        ch, col, row = self.getChannelColRow(ra_deg, dec_deg)\n        # Modules 3 and 7 are no longer operational\n        if ch in self.brokenChannels:\n            return False\n        # K2fov encodes the Fine Guidance Sensors (FGS) as\n        # \"channel\" numbers 85-88; they are not science CCDs.\n        if ch > 84:\n            return False\n        return self.colRowIsOnSciencePixel(col, row, padding_pix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the channel column and row given an ( ra dec ) coordinate.", "response": "def getChannelColRow(self, ra, dec, wantZeroOffset=False,\n                         allowIllegalReturnValues=True):\n        \"\"\"Returns (channel, column, row) given an (ra, dec) coordinate.\n\n        Returns (0, 0, 0) or a ValueError if the coordinate is not on silicon.\n        \"\"\"\n        try:\n            ch = self.pickAChannel(ra, dec)\n        except ValueError:\n            logger.warning(\"WARN: %.7f %.7f not on any channel\" % (ra, dec))\n            return (0, 0, 0)\n\n        col, row = self.getColRowWithinChannel(ra, dec, ch, wantZeroOffset,\n                                               allowIllegalReturnValues)\n        return (ch, col, row)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the channel number closest to a given ( ra dec ) coordinate.", "response": "def pickAChannel(self, ra_deg, dec_deg):\n        \"\"\"Returns the channel number closest to a given (ra, dec) coordinate.\n        \"\"\"\n        # Could improve speed by doing this in the projection plane\n        # instead of sky coords\n        cRa = self.currentRaDec[:, 3]  # Ra of each channel corner\n        cDec = self.currentRaDec[:, 4]  # dec of each channel corner\n\n        dist = cRa * 0\n        for i in range(len(dist)):\n            dist[i] = gcircle.sphericalAngSep(cRa[i], cDec[i], ra_deg, dec_deg)\n\n        i = np.argmin(dist)\n        return self.currentRaDec[i, 2]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the column and row indices given a ( ra dec ) coordinate and channel number.", "response": "def getColRowWithinChannel(self, ra, dec, ch, wantZeroOffset=False,\n                               allowIllegalReturnValues=True):\n        \"\"\"Returns (col, row) given a (ra, dec) coordinate and channel number.\n        \"\"\"\n        # How close is a given ra/dec to the origin of a KeplerModule?\n        x, y = self.defaultMap.skyToPix(ra, dec)\n        kepModule = self.getChannelAsPolygon(ch)\n        r = np.array([x[0],y[0]]) - kepModule.polygon[0, :]\n\n        v1 = kepModule.polygon[1, :] - kepModule.polygon[0, :]\n        v3 = kepModule.polygon[3, :] - kepModule.polygon[0, :]\n\n        # Divide by |v|^2 because you're normalising v and r\n        colFrac = np.dot(r, v1) / np.linalg.norm(v1)**2\n        rowFrac = np.dot(r, v3) / np.linalg.norm(v3)**2\n\n        # This is where it gets a little hairy. The channel \"corners\"\n        # supplied to me actually represent points 5x5 pixels inside\n        # the science array. Which isn't what you'd expect.\n        # These magic numbers are the pixel numbers of the corner\n        # edges given in fov.txt\n        col = colFrac*(1106-17) + 17\n        row = rowFrac*(1038-25) + 25\n\n        if not allowIllegalReturnValues:\n            if not self.colRowIsOnSciencePixel(col, row):\n                msg = \"Request position %7f %.7f \" % (ra, dec)\n                msg += \"does not lie on science pixels for channel %i \" % (ch)\n                msg += \"[ %.1f %.1f]\" % (col, row)\n                raise ValueError(msg)\n\n        # Convert from zero-offset to one-offset coords\n        if not wantZeroOffset:\n            col += 1\n            row += 1\n\n        return (col, row)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef colRowIsOnSciencePixel(self, col, row, padding=DEFAULT_PADDING):\n        if col < 12. - padding or col > 1111 + padding:\n            return False\n\n        if row < 20 - padding or row > 1043 + padding:\n            return False\n        return True", "response": "Returns True if col row is on a science pixel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef colRowIsOnFgsPixel(self, col, row, padding=-50):\n        if col < 12. - padding  or col > 547 + padding:\n            return False\n\n        if row < 0 - padding or row > 527 + padding :\n            return False\n        return True", "response": "Returns True if col row is on a science pixel."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn slew the telescope and return the corners of the modules as Polygon objects.", "response": "def getAllChannelsAsPolygons(self, maptype=None):\n        \"\"\"Return slew the telescope and return the corners of the modules\n        as Polygon objects.\n\n        If a projection is supplied, the ras and\n        decs are mapped onto x, y using that projection\n        \"\"\"\n        polyList = []\n        for ch in self.origin[:, 2]:\n            poly = self.getChannelAsPolygon(ch, maptype)\n            polyList.append(poly)\n        return polyList"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot the FOV with the pointing of the current FOV.", "response": "def plotPointing(self, maptype=None, colour='b', mod3='r', showOuts=True, **kwargs):\n        \"\"\"Plot the FOV\n        \"\"\"\n\n        if maptype is None:\n            maptype=self.defaultMap\n\n        radec = self.currentRaDec\n        for ch in radec[:,2][::4]:\n\n            idx = np.where(radec[:,2].astype(np.int) == ch)[0]\n            idx = np.append(idx, idx[0])  #% points to draw a box\n\n            c = colour\n            if ch in self.brokenChannels:\n                c = mod3\n            maptype.plot(radec[idx, 3], radec[idx, 4], '-', color=c, **kwargs)\n            #Show the origin of the col and row coords for this ch\n            if showOuts:\n                maptype.plot(radec[idx[0], 3], radec[idx[0],4], 'o', color=c)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plotOutline(self, maptype=None, colour='#AAAAAA', **kwargs):\n\n        if maptype is None:\n            maptype=self.defaultMap\n\n        xarr = []\n        yarr = []\n        radec = self.currentRaDec\n        for ch in [20,4,11,28,32, 71,68, 84, 75, 60, 56, 15 ]:\n            idx = np.where(radec[:,2].astype(np.int) == ch)[0]\n            idx = idx[0]    #Take on the first one\n            x, y = maptype.skyToPix(radec[idx][3], radec[idx][4])\n            xarr.append(x)\n            yarr.append(y)\n\n        verts = np.empty( (len(xarr), 2))\n        verts[:,0] = xarr\n        verts[:,1] = yarr\n\n        #There are two ways to specify line colour\n        ec = kwargs.pop('ec', \"none\")\n        ec = kwargs.pop('edgecolor', ec)\n        p = matplotlib.patches.Polygon(verts, fill=True, ec=ec, fc=colour, **kwargs)\n        mp.gca().add_patch(p)", "response": "Plot an outline of the FOV."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots a line pointing in the direction of the spacecraft + y - axis.", "response": "def plotSpacecraftYAxis(self, maptype=None):\n        \"\"\"Plot a line pointing in the direction of the spacecraft\n        y-axis (i.e normal to the solar panel\n        \"\"\"\n\n        if maptype is None:\n            maptype=self.defaultMap\n        #Plot direction of spacecraft +y axis. The subtraction of\n        #90 degrees accounts for the different defintions of where\n        #zero roll is.\n        yAngle_deg = getSpacecraftRollAngleFromFovAngle(self.roll0_deg)\n        yAngle_deg -=90\n\n        a,d = gcircle.sphericalAngDestination(self.ra0_deg, self.dec0_deg, -yAngle_deg, 12.0)\n        x0, y0 = maptype.skyToPix(self.ra0_deg, self.dec0_deg)\n        x1, y1 = maptype.skyToPix(a, d)\n        mp.plot([x0, x1], [y0, y1], 'k-')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plotChIds(self, maptype=None, modout=False):\n        if maptype is None:\n            maptype = self.defaultMap\n\n        polyList = self.getAllChannelsAsPolygons(maptype)\n        for p in polyList:\n            p.identifyModule(modout=modout)", "response": "Print the channel numbers on the plotting display."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isPointInside(self, xp, yp):\n\n        point = np.array([xp, yp]).transpose()\n        polygon = self.polygon\n        numVert, numDim = polygon.shape\n\n        #Subtract each point from the previous one.\n        polyVec = np.roll(polygon, -1, 0) - polygon\n        #Get the vector from each vertex to the given point\n        pointVec = point - polygon\n\n        crossProduct = np.cross(polyVec, pointVec)\n\n        if np.all(crossProduct < 0) or np.all(crossProduct > 0):\n            return True\n        return False", "response": "Returns True if the given point is inside the polygon False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw the polygon of the current object.", "response": "def draw(self, **kwargs):\n        \"\"\"Draw the polygon\n\n        Optional Inputs:\n        ------------\n        All optional inputs are passed to ``matplotlib.patches.Polygon``\n\n        Notes:\n        ---------\n        Does not accept maptype as an argument.\n        \"\"\"\n\n        ax = mp.gca()\n        shape = matplotlib.patches.Polygon(self.polygon, **kwargs)\n        ax.add_artist(shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the name of a channel and modout on a plot.", "response": "def identifyModule(self, modout=False):\n        \"\"\"Write the name of a channel/modout on a plot\n\n        Optional Inputs:\n        -----------\n        modout\n            (boolean). If True, write module and output. Otherwise\n            write channel number\n\n        Returns:\n        ------------\n        **None**\n\n        Output:\n        -----------\n        Channel numbers are written to the current axis.\n\n        \"\"\"\n        x,y = np.mean(self.polygon, 0)\n\n        if modout:\n            modout = modOutFromChannel(self.channel)\n            mp.text(x, y, \"%i-%i\" %(modout[0], modout[1]), fontsize=8, \\\n                ha=\"center\", clip_on=True)\n        else:\n            mp.text(x,y, \"%i\" %(self.channel), fontsize=8, \\\n                ha=\"center\", clip_on=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_response(self, response, header=None):\n        response = response.decode(self.encoding)\n        if header:\n            header = \"\".join((self.resp_prefix, header, self.resp_header_sep))\n            if not response.startswith(header):\n                raise IEC60488.ParsingError('Response header mismatch')\n            response = response[len(header):]\n        return response.split(self.resp_data_sep)", "response": "Parses the response message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear(self, transport):\n        logger.debug('IEC60488 clear')\n        with transport:\n            try:\n                transport.clear()\n            except AttributeError:\n                clear_msg = self.create_message('*CLS')\n                transport.write(clear_msg)", "response": "Issues a device clear command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying for binary data in the specified transport.", "response": "def query_bytes(self, transport, num_bytes, header, *data):\n        \"\"\"Queries for binary data\n\n        :param  transport: A transport object.\n        :param num_bytes: The exact number of data bytes expected.\n        :param header: The message header.\n        :param data: Optional data.\n        :returns: The raw unparsed data bytearray.\n\n        \"\"\"\n        message = self.create_message(header, *data)\n        logger.debug('SignalRecovery query bytes: %r', message)\n        with transport:\n            transport.write(message)\n\n            response = transport.read_exactly(num_bytes)\n            logger.debug('SignalRecovery response: %r', response)\n            # We need to read 3 bytes, because there is a \\0 character\n            # separating the data from the status bytes.\n            _, status_byte, overload_byte = transport.read_exactly(3)\n\n        logger.debug('SignalRecovery stb: %r olb: %r', status_byte, overload_byte)\n        self.call_byte_handler(status_byte, overload_byte)\n        # returns raw unparsed bytes.\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef raDecFromVec(v):\n\n    #Ensure v is a normal vector\n    v /= np.linalg.norm(v)\n\n    ra_deg=0    #otherwise not in namespace0\n    dec_rad = np.arcsin(v[2])\n    s = np.hypot(v[0], v[1])\n    if s ==0:\n        ra_rad = 0\n    else:\n        ra_rad = np.arcsin(v[1]/s)\n        ra_deg = np.degrees(ra_rad)\n        if v[0] >= 0:\n            if v[1] >= 0:\n                pass\n            else:\n                ra_deg = 360 + ra_deg\n        else:\n            if v[1] > 0:\n                ra_deg = 180 - ra_deg\n            else:\n                ra_deg = 180 - ra_deg\n\n    raDec = ra_deg, np.degrees(dec_rad)\n    return np.array(raDec)", "response": "Convert from Cartestion to spherical coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrotates vector v1 by an angle theta around w", "response": "def rotateAroundVector(v1, w, theta_deg):\n    \"\"\"Rotate vector v1 by an angle theta around w\n\n    Taken from https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation\n    (see Section \"Rotating a vector\")\n\n    Notes:\n    Rotating the x axis 90 degrees about the y axis gives -z\n    Rotating the x axis 90 degrees about the z axis gives +y\n    \"\"\"\n\n    ct = np.cos(np.radians(theta_deg))\n    st = np.sin(np.radians(theta_deg))\n    term1 = v1*ct\n    term2 = np.cross(w, v1) * st\n    term3 = np.dot(w, v1)\n    term3 = w * term3 * (1-ct)\n\n    return term1 + term2 + term3"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rotateInDeclination(v1, theta_deg):\n    axis = np.array([0,-1,0])\n    return rotateAroundVector(v1, axis, theta_deg)", "response": "Rotate in declination vector v1 by theta_deg degrees."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct the rotation matrix for a declination sequence of the given angle.", "response": "def declinationRotationMatrix(theta_deg):\n    \"\"\"Construct the rotation matrix for a rotation of the declination\n    coords (i.e around the axis of ra=90, dec=0)\n\n    Taken from Section 3.3 of Arfken and Weber (Eqn 3.91)\n    Modfied the signs of the sines so that a rotation of the zenith\n    vector by 90 degrees ends up at ra, dec = 0,0\n    \"\"\"\n\n    ct = np.cos(np.radians(theta_deg))\n    st = np.sin(np.radians(theta_deg))\n\n    mat = np.zeros((3,3))\n\n    mat[0,0] = ct\n    mat[0,2] = -st\n    mat[1,1] = 1\n    mat[2,0] = st\n    mat[2,2] = ct\n\n    return mat"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts the output current sweep.", "response": "def sweep(self, mode, speed=None):\n        \"\"\"Starts the output current sweep.\n\n        :param mode: The sweep mode. Valid entries are `'UP'`, `'DOWN'`,\n            `'PAUSE'`or `'ZERO'`. If in shim mode, `'LIMIT'` is valid as well.\n        :param speed: The sweeping speed. Valid entries are `'FAST'`, `'SLOW'`\n            or `None`.\n\n        \"\"\"\n        sweep_modes = ['UP', 'DOWN', 'PAUSE', 'ZERO', 'LIMIT']\n        sweep_speed = ['SLOW', 'FAST', None]\n        if not mode in sweep_modes:\n            raise ValueError('Invalid sweep mode.')\n        if not speed in sweep_speed:\n            raise ValueError('Invalid sweep speed.')\n        if speed is None:\n            self._write('SWEEP {0}'.format(mode))\n        else:\n            self._write('SWEEP {0} {1}'.format(mode, speed))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun the func on the main thread by using the provided IOLoop.", "response": "def run_on_main_thread(self, func, args=None, kwargs=None):\n        \"\"\"\n        Runs the ``func`` callable on the main thread, by using the provided microservice\n        instance's IOLoop.\n\n        :param func: callable to run on the main thread\n        :param args: tuple or list with the positional arguments.\n        :param kwargs: dict with the keyword arguments.\n        :return:\n        \"\"\"\n        if not args:\n            args = ()\n        if not kwargs:\n            kwargs = {}\n        self.microservice.get_io_loop().add_callback(func, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rotateAboutVectorMatrix(vec, theta_deg):\n    ct = np.cos(np.radians(theta_deg))\n    st = np.sin(np.radians(theta_deg))\n\n    # Ensure vector has normal length\n    vec /= np.linalg.norm(vec)\n    assert( np.all( np.isfinite(vec)))\n\n    # compute the three terms\n    term1 = ct * np.eye(3)\n\n    ucross = np.zeros( (3,3))\n    ucross[0] = [0, -vec[2], vec[1]]\n    ucross[1] = [vec[2], 0, -vec[0]]\n    ucross[2] = [-vec[1], vec[0], 0]\n\n    term2 = st*ucross\n\n    ufunny = np.zeros( (3,3))\n    for i in range(0,3):\n        for j in range(i,3):\n            ufunny[i,j] = vec[i]*vec[j]\n            ufunny[j,i] = ufunny[i,j]\n\n    term3 = (1-ct) * ufunny\n\n    return term1 + term2 + term3", "response": "Construct the matrix that rotates vector a about\n    vector vec by an angle of theta_deg degrees"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rotateInZMat(theta_deg):\n\n    ct = np.cos( np.radians(theta_deg))\n    st = np.sin( np.radians(theta_deg))\n    rMat = np.array([  [ ct, -st, 0],\n                       [ st,  ct, 0],\n                       [  0,   0, 1],\n                    ])\n\n    return rMat", "response": "Rotate a vector in the z - axis around the z - axis and return a matrix that is premultiplied by this matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning a tweet into Twitter hyperlinks.", "response": "def urlize_tweet(tweet):\n    \"\"\" Turn #hashtag and @username in a text to Twitter hyperlinks,\n        similar to the ``urlize()`` function in Django.\n\n        Replace shortened URLs with long URLs in the twitter status,\n        and add the \"RT\" flag. Should be used before urlize_tweet\n    \"\"\"\n    if tweet['retweeted']:\n        text = 'RT {user}: {text}'.format(\n            user=TWITTER_USERNAME_URL.format(screen_name=tweet['user']['screen_name']),\n            text=tweet['text'])\n    else:\n        text = tweet['text']\n\n    for hashtag in tweet['entities']['hashtags']:\n        text = text.replace(\n            '#%s' % hashtag['text'],\n            TWITTER_HASHTAG_URL.format(hashtag=hashtag['text']))\n\n    for mention in tweet['entities']['user_mentions']:\n        text = text.replace(\n            '@%s' % mention['screen_name'],\n            TWITTER_USERNAME_URL.format(screen_name=mention['screen_name']))\n\n    urls = tweet['entities']['urls']\n    for url in urls:\n        text = text.replace(\n            url['url'], TWITTER_URL.format(\n                url=url['expanded_url'], display_url=url['display_url']))\n\n    if 'media' in tweet['entities']:\n        for media in tweet['entities']['media']:\n            text = text.replace(\n                media['url'],\n                TWITTER_MEDIA_URL.format(\n                    url=media['expanded_url'],\n                    display_url=media['display_url']))\n\n    return mark_safe(text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getReadSession(self):\r\n        ''' return scopted session '''\r\n        if self.ReadSession is None:\r\n            self.ReadSession=scoped_session(sessionmaker(bind=self.engine))\r\n\r\n        return self.ReadSession", "response": "Returns a ScoptedSession object that can be used to access the read table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getWriteSession(self):\r\n        ''' return unscope session, TODO, make it clear '''\r\n        if self.WriteSession is None:\r\n            self.WriteSession=sessionmaker(bind=self.engine)\r\n            self.writeSession=self.WriteSession()\r\n\r\n        return self.writeSession", "response": "return a new session"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef readTupleQuotes(self, symbol, start, end):\r\n        ''' read quotes as tuple '''\r\n        if end is None:\r\n            end=sys.maxint\r\n\r\n        session=self.getReadSession()()\r\n        try:\r\n            rows=session.query(Quote).filter(and_(Quote.symbol == symbol,\r\n                                                       Quote.time >= int(start),\r\n                                                       Quote.time < int(end)))\r\n        finally:\r\n            self.getReadSession().remove()\r\n\r\n        return rows", "response": "read quotes as tuple"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef readBatchTupleQuotes(self, symbols, start, end):\r\n        '''\r\n        read batch quotes as tuple to save memory\r\n        '''\r\n        if end is None:\r\n            end=sys.maxint\r\n\r\n        ret={}\r\n        session=self.getReadSession()()\r\n        try:\r\n            symbolChunks=splitListEqually(symbols, 100)\r\n            for chunk in symbolChunks:\r\n                rows=session.query(Quote.symbol, Quote.time, Quote.close, Quote.volume,\r\n                                     Quote.low, Quote.high).filter(and_(Quote.symbol.in_(chunk),\r\n                                                                              Quote.time >= int(start),\r\n                                                                              Quote.time < int(end)))\r\n\r\n                for row in rows:\r\n                    if row.time not in ret:\r\n                        ret[row.time]={}\r\n\r\n                    ret[row.time][row.symbol]=self.__sqlToTupleQuote(row)\r\n        finally:\r\n            self.getReadSession().remove()\r\n\r\n        return ret", "response": "read batch quotes as tuple to save memory"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_tuple_ticks(self, symbol, start, end):\r\n        ''' read ticks as tuple '''\r\n        if end is None:\r\n            end=sys.maxint\r\n\r\n        session=self.getReadSession()()\r\n        try:\r\n            rows=session.query(Tick).filter(and_(Tick.symbol == symbol,\r\n                                                      Tick.time >= int(start),\r\n                                                      Tick.time < int(end)))\r\n        finally:\r\n            self.getReadSession().remove()\r\n\r\n        return [self.__sqlToTupleTick(row) for row in rows]", "response": "read ticks as tuple"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite quotes to database", "response": "def write_quotes(self, quotes):\r\n        ''' write quotes '''\r\n        if self.first:\r\n            Base.metadata.create_all(self.engine, checkfirst=True)\r\n            self.first=False\r\n\r\n        session=self.getWriteSession()\r\n        session.add_all([self.__quoteToSql(quote) for quote in quotes])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting ticks to database", "response": "def write_ticks(self, ticks):\r\n        ''' write ticks '''\r\n        if self.first:\r\n            Base.metadata.create_all(self.engine, checkfirst=True)\r\n            self.first=False\r\n\r\n        session=self.getWriteSession()\r\n        session.add_all([self.__tickToSql(tick) for tick in ticks])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite fundamental to database", "response": "def write_fundamental(self, keyTimeValueDict):\r\n        ''' write fundamental '''\r\n        if self.first:\r\n            Base.metadata.create_all(self.__getEngine(), checkfirst=True)\r\n            self.first=False\r\n\r\n        sqls=self._fundamentalToSqls(keyTimeValueDict)\r\n        session=self.Session()\r\n        try:\r\n            session.add_all(sqls)\r\n        finally:\r\n            self.Session.remove()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fundamentalToSqls(self, symbol, keyTimeValueDict):\r\n        ''' convert fundament dict to sqls '''\r\n        sqls=[]\r\n        for key, timeValues in keyTimeValueDict.iteritems():\r\n            for timeStamp, value in timeValues.iteritems():\r\n                sqls.append(FmSql(symbol, key, timeStamp, value))\r\n\r\n        return sqls", "response": "convert fundamental dict to sqls"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting the current curve. Raises when one tries to delete a read - only curve.", "response": "def delete(self):\n        \"\"\"Deletes the current curve.\n\n        :raises RuntimeError: Raises when` when one tries to delete a read-only\n            curve.\n\n        \"\"\"\n        if self._writeable:\n            self._write(('CRVDEL', Integer), self.idx)\n        else:\n            raise RuntimeError('Can not delete read-only curves.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef line(self, idx):\n        # TODO: We should parse the response properly.\n        return self._query(('PGM?', [Integer, Integer], String), self.idx, idx)", "response": "Return the i'th program line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend the new_line to the LS340 program.", "response": "def append_line(self, new_line):\n        \"\"\"Appends the new_line to the LS340 program.\"\"\"\n        # TODO: The user still has to write the raw line, this is error prone.\n        self._write(('PGM', [Integer, String]), self.idx, new_line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef softcal(self, std, dest, serial, T1, U1, T2, U2, T3=None, U3=None):\n        args = [std, dest, serial, T1, U1, T2, U2]\n        dtype = [Integer(min=1, max=21), Integer(min=21, max=61), String(max=10), Float, Float, Float, Float]\n        if (T3 is not None) and (U3 is not None):\n            args.extend([T3, U3])\n            dtype.extend([Float, Float])\n        self._write(('SCAL', dtype), *args)", "response": "Generates a softcal curve."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef makeThumbnail(inputFile, outputFile, thumbnailSize, outputFormat='jpeg'):\n    if Image is None:\n        # throw the ImportError here\n        import PIL\n    image = Image.open(inputFile)\n    # Resize needed?\n    if thumbnailSize < max(image.size):\n        # Convert bilevel and paletted images to grayscale and RGB respectively;\n        # otherwise PIL silently switches to Image.NEAREST sampling.\n        if image.mode == '1':\n            image = image.convert('L')\n        elif image.mode == 'P':\n            image = image.convert('RGB')\n        image.thumbnail((thumbnailSize, thumbnailSize), Image.ANTIALIAS)\n    image.save(outputFile, outputFormat)", "response": "This function creates a thumbnail of the image stored at C { inputFile } preserving its\n    aspect ratio and write the result to C { outputFile }."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a descriptive identifier for the given IContactType.", "response": "def _descriptiveIdentifier(contactType):\n    \"\"\"\n    Get a descriptive identifier for C{contactType}, taking into account the\n    fact that it might not have implemented the C{descriptiveIdentifier}\n    method.\n\n    @type contactType: L{IContactType} provider.\n\n    @rtype: C{unicode}\n    \"\"\"\n    descriptiveIdentifierMethod = getattr(\n        contactType, 'descriptiveIdentifier', None)\n    if descriptiveIdentifierMethod is not None:\n        return descriptiveIdentifierMethod()\n    warn(\n        \"IContactType now has the 'descriptiveIdentifier'\"\n        \" method, %s did not implement it\" % (contactType.__class__,),\n        category=PendingDeprecationWarning)\n    return _objectToName(contactType).decode('ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a name for the given plugin.", "response": "def _organizerPluginName(plugin):\n    \"\"\"\n    Get a name for C{plugin}, taking into account the fact that it might not\n    have defined L{IOrganizerPlugin.name}.\n\n    @type plugin: L{IOrganizerPlugin} provider.\n\n    @rtype: C{unicode}\n    \"\"\"\n    name = getattr(plugin, 'name', None)\n    if name is not None:\n        return name\n    warn(\n        \"IOrganizerPlugin now has the 'name' attribute\"\n        \" and %s does not define it\" % (plugin.__class__,),\n        category=PendingDeprecationWarning)\n    return _objectToName(plugin).decode('ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a copy of C { d with C { unicode } keys.", "response": "def _stringifyKeys(d):\n    \"\"\"\n    Return a copy of C{d} with C{str} keys.\n\n    @type d: C{dict} with C{unicode} keys.\n    @rtype: C{dict} with C{str} keys.\n    \"\"\"\n    return dict((k.encode('ascii'), v)  for (k, v) in d.iteritems())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mugshot1to2(old):\n    smallerBody = Mugshot.makeThumbnail(old.body.open(),\n                                        old.person,\n                                        old.type.split('/')[1],\n                                        smaller=True)\n\n    return old.upgradeVersion(Mugshot.typeName, 1, 2,\n                              person=old.person,\n                              type=old.type,\n                              body=old.body,\n                              smallerBody=smallerBody)", "response": "Upgrader for L { Mugshot } from version 1 to version 2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mugshot2to3(old):\n    new = old.upgradeVersion(Mugshot.typeName, 2, 3,\n                             person=old.person,\n                             type=old.type,\n                             body=old.body,\n                             smallerBody=old.smallerBody)\n    new.smallerBody = new.makeThumbnail(\n        new.body.open(), new.person, new.type[len('image/'):], smaller=True)\n    return new", "response": "Returns a new mugshot from version 2 to version 3."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getParameters(self, contactItem):\n        isVIP = False # default\n        if contactItem is not None:\n            isVIP = contactItem.person.vip\n        return [liveform.Parameter(\n            'vip', liveform.CHECKBOX_INPUT, bool, 'VIP', default=isVIP)]", "response": "Returns a list of liveform. Parameter objects suitable for changing the\n        VIP status of a person."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getParameters(self, emailAddress):\n        if emailAddress is not None:\n            address = emailAddress.address\n        else:\n            address = u''\n        return [\n            liveform.Parameter('email', liveform.TEXT_INPUT,\n                               _normalizeWhitespace, 'Email Address',\n                               default=address)]", "response": "Returns a C { list} of one L { LiveForm } parameter for editing an email address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the existing item with the given email address or None if there isn t one.", "response": "def _existing(self, email):\n        \"\"\"\n        Return the existing L{EmailAddress} item with the given address, or\n        C{None} if there isn't one.\n        \"\"\"\n        return self.store.findUnique(\n            EmailAddress,\n            EmailAddress.address == email,\n            default=None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new contact item based on the given person and email address.", "response": "def createContactItem(self, person, email):\n        \"\"\"\n        Create a new L{EmailAddress} associated with the given person based on\n        the given email address.\n\n        @type person: L{Person}\n        @param person: The person with whom to associate the new\n            L{EmailAddress}.\n\n        @type email: C{unicode}\n        @param email: The value to use for the I{address} attribute of the\n            newly created L{EmailAddress}.  If C{''}, no L{EmailAddress} will\n            be created.\n\n        @return: C{None}\n        \"\"\"\n        if email:\n            address = self._existing(email)\n            if address is not None:\n                raise ValueError('There is already a person with that email '\n                                 'address (%s): ' % (address.person.name,))\n            return EmailAddress(store=self.store,\n                                address=email,\n                                person=person)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getContactItems(self, person):\n        return person.store.query(\n            EmailAddress,\n            EmailAddress.person == person)", "response": "Returns all the items associated with the given person."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef editContactItem(self, contact, email):\n        address = self._existing(email)\n        if address is not None and address is not contact:\n            raise ValueError('There is already a person with that email '\n                             'address (%s): ' % (address.person.name,))\n        contact.address = email", "response": "Edit the contact item with the given email address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterator of all email addresses associated with this person.", "response": "def getEmailAddresses(self):\n        \"\"\"\n        Return an iterator of all email addresses associated with this person.\n\n        @return: an iterator of unicode strings in RFC2822 address format.\n        \"\"\"\n        return self.store.query(\n            EmailAddress,\n            EmailAddress.person == self).getColumn('address')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getMugshot(self):\n        mugshot = self.store.findUnique(\n            Mugshot, Mugshot.person == self, default=None)\n        if mugshot is not None:\n            return mugshot\n        return Mugshot.placeholderForPerson(self)", "response": "Returns the Mugshot associated with this person or an unstored\n        object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _makeStoreOwnerPerson(self):\n        if self.store is None:\n            return None\n        userInfo = self.store.findFirst(signup.UserInfo)\n        name = u''\n        if userInfo is not None:\n            name = userInfo.realName\n        account = self.store.findUnique(LoginAccount,\n                                        LoginAccount.avatars == self.store, None)\n        ownerPerson = self.createPerson(name)\n        if account is not None:\n            for method in (self.store.query(\n                    LoginMethod,\n                    attributes.AND(LoginMethod.account == account,\n                                   LoginMethod.internal == False))):\n                self.createContactItem(\n                    EmailContactType(self.store),\n                    ownerPerson, dict(\n                        email=method.localpart + u'@' + method.domain))\n        return ownerPerson", "response": "Make a L{Person representing the owner of the store that this signup is installed in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _gatherPluginMethods(self, methodName):\n        for plugin in self.getOrganizerPlugins():\n            implementation = getattr(plugin, methodName, None)\n            if implementation is not None:\n                yield implementation\n            else:\n                warn(\n                    ('IOrganizerPlugin now has the %r method, %s'\n                        ' did not implement it') % (\n                            methodName, plugin.__class__),\n                    category=PendingDeprecationWarning)", "response": "Yields the methods that implement the methodName."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the contactType has the correct methods.", "response": "def _checkContactType(self, contactType):\n        \"\"\"\n        Possibly emit some warnings about C{contactType}'s implementation of\n        L{IContactType}.\n\n        @type contactType: L{IContactType} provider\n        \"\"\"\n        if getattr(contactType, 'getEditFormForPerson', None) is None:\n            warn(\n                \"IContactType now has the 'getEditFormForPerson'\"\n                \" method, but %s did not implement it.\" % (\n                    contactType.__class__,),\n                category=PendingDeprecationWarning)\n\n        if getattr(contactType, 'getEditorialForm', None) is not None:\n            warn(\n                \"The IContactType %s defines the 'getEditorialForm'\"\n                \" method, which is deprecated.  'getEditFormForPerson'\"\n                \" does something vaguely similar.\" % (contactType.__class__,),\n                category=DeprecationWarning)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding all available contact types.", "response": "def getContactTypes(self):\n        \"\"\"\n        Return an iterator of L{IContactType} providers available to this\n        organizer's store.\n        \"\"\"\n        yield VIPPersonContactType()\n        yield EmailContactType(self.store)\n        yield PostalContactType()\n        yield PhoneNumberContactType()\n        yield NotesContactType()\n        for getContactTypes in self._gatherPluginMethods('getContactTypes'):\n            for contactType in getContactTypes():\n                self._checkContactType(contactType)\n                yield contactType"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getPeopleFilters(self):\n        yield AllPeopleFilter()\n        yield VIPPeopleFilter()\n        for getPeopleFilters in self._gatherPluginMethods('getPeopleFilters'):\n            for peopleFilter in getPeopleFilters():\n                yield peopleFilter\n        for tag in sorted(self.getPeopleTags()):\n            yield TaggedPeopleFilter(tag)", "response": "Return an iterator of all available PeopleFilter providers available to this organizer s store."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getPeopleTags(self):\n        query = self.store.query(\n            Tag, Tag.object == Person.storeID)\n        return set(query.getColumn('name').distinct())", "response": "Returns a sequence of tags which have been applied to items."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollects all contact items from the available contact types for the given person, organize them by contact group, and turn them into read-only views. @type person: L{Person} @param person: The person whose contact items we're interested in. @return: A mapping of of L{ContactGroup} names to the read-only views of their member contact items, with C{None} being the key for groupless contact items. @rtype: C{dict} of C{str}", "response": "def groupReadOnlyViews(self, person):\n        \"\"\"\n        Collect all contact items from the available contact types for the\n        given person, organize them by contact group, and turn them into\n        read-only views.\n\n        @type person: L{Person}\n        @param person: The person whose contact items we're interested in.\n\n        @return: A mapping of of L{ContactGroup} names to the read-only views\n        of their member contact items, with C{None} being the key for\n        groupless contact items.\n        @rtype: C{dict} of C{str}\n        \"\"\"\n        # this is a slightly awkward, specific API, but at the time of\n        # writing, read-only views are the thing that the only caller cares\n        # about.  we need the contact type to get a read-only view for a\n        # contact item.  there is no way to get from a contact item to a\n        # contact type, so this method can't be \"groupContactItems\" (which\n        # seems to make more sense), unless it returned some weird data\n        # structure which managed to associate contact items and contact\n        # types.\n        grouped = {}\n        for contactType in self.getContactTypes():\n            for contactItem in contactType.getContactItems(person):\n                contactGroup = contactType.getContactGroup(contactItem)\n                if contactGroup is not None:\n                    contactGroup = contactGroup.groupName\n                if contactGroup not in grouped:\n                    grouped[contactGroup] = []\n                grouped[contactGroup].append(\n                    contactType.getReadOnlyView(contactItem))\n        return grouped"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield a L{Parameter for each known L{IContactType } and each L{IContactType.", "response": "def getContactCreationParameters(self):\n        \"\"\"\n        Yield a L{Parameter} for each L{IContactType} known.\n\n        Each yielded object can be used with a L{LiveForm} to create a new\n        instance of a particular L{IContactType}.\n        \"\"\"\n        for contactType in self.getContactTypes():\n            if contactType.allowMultipleContactItems:\n                descriptiveIdentifier = _descriptiveIdentifier(contactType)\n                yield liveform.ListChangeParameter(\n                    contactType.uniqueIdentifier(),\n                    contactType.getParameters(None),\n                    defaults=[],\n                    modelObjects=[],\n                    modelObjectDescription=descriptiveIdentifier)\n            else:\n                yield liveform.FormParameter(\n                    contactType.uniqueIdentifier(),\n                    liveform.LiveForm(\n                        lambda **k: k,\n                        contactType.getParameters(None)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the defaults from the given list of parameters and returns a dictionary mapping parameter names to default values suitable for passing to", "response": "def _parametersToDefaults(self, parameters):\n        \"\"\"\n        Extract the defaults from C{parameters}, constructing a dictionary\n        mapping parameter names to default values, suitable for passing to\n        L{ListChangeParameter}.\n\n        @type parameters: C{list} of L{liveform.Parameter} or\n        L{liveform.ChoiceParameter}.\n\n        @rtype: C{dict}\n        \"\"\"\n        defaults = {}\n        for p in parameters:\n            if isinstance(p, liveform.ChoiceParameter):\n                selected = []\n                for choice in p.choices:\n                    if choice.selected:\n                        selected.append(choice.value)\n                defaults[p.name] = selected\n            else:\n                defaults[p.name] = p.default\n        return defaults"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the given contact type into a L { liveform. Parameter or similar.", "response": "def toContactEditorialParameter(self, contactType, person):\n        \"\"\"\n        Convert the given contact type into a L{liveform.LiveForm} parameter.\n\n        @type contactType: L{IContactType} provider.\n\n        @type person: L{Person}\n\n        @rtype: L{liveform.Parameter} or similar.\n        \"\"\"\n        contactItems = list(contactType.getContactItems(person))\n        if contactType.allowMultipleContactItems:\n            defaults = []\n            modelObjects = []\n            for contactItem in contactItems:\n                defaultedParameters = contactType.getParameters(contactItem)\n                if defaultedParameters is None:\n                    continue\n                defaults.append(self._parametersToDefaults(\n                    defaultedParameters))\n                modelObjects.append(contactItem)\n            descriptiveIdentifier = _descriptiveIdentifier(contactType)\n            return liveform.ListChangeParameter(\n                contactType.uniqueIdentifier(),\n                contactType.getParameters(None),\n                defaults=defaults,\n                modelObjects=modelObjects,\n                modelObjectDescription=descriptiveIdentifier)\n        (contactItem,) = contactItems\n        return liveform.FormParameter(\n            contactType.uniqueIdentifier(),\n            liveform.LiveForm(\n                lambda **k: k,\n                contactType.getParameters(contactItem)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getContactEditorialParameters(self, person):\n        for contactType in self.getContactTypes():\n            yield (\n                contactType,\n                self.toContactEditorialParameter(contactType, person))", "response": "Yields the L { LiveForm } parameters to edit each contact item of each contact\n        type for the given person."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new person with the given nickname in this organizer.", "response": "def createPerson(self, nickname, vip=_NO_VIP):\n        \"\"\"\n        Create a new L{Person} with the given name in this organizer.\n\n        @type nickname: C{unicode}\n        @param nickname: The value for the new person's C{name} attribute.\n\n        @type vip: C{bool}\n        @param vip: Value to set the created person's C{vip} attribute to\n        (deprecated).\n\n        @rtype: L{Person}\n        \"\"\"\n        for person in (self.store.query(\n                Person, attributes.AND(\n                    Person.name == nickname,\n                    Person.organizer == self))):\n            raise ValueError(\"Person with name %r exists already.\" % (nickname,))\n        person = Person(\n            store=self.store,\n            created=extime.Time(),\n            organizer=self,\n            name=nickname)\n\n        if vip is not self._NO_VIP:\n            warn(\n                \"Usage of Organizer.createPerson's 'vip' parameter\"\n                \" is deprecated\",\n                category=DeprecationWarning)\n            person.vip = vip\n\n        self._callOnOrganizerPlugins('personCreated', person)\n        return person"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new contact item for the given person with the given contact type and with the given contact info.", "response": "def createContactItem(self, contactType, person, contactInfo):\n        \"\"\"\n        Create a new contact item for the given person with the given contact\n        type.  Broadcast a creation to all L{IOrganizerPlugin} powerups.\n\n        @type contactType: L{IContactType}\n        @param contactType: The contact type which will be used to create the\n            contact item.\n\n        @type person: L{Person}\n        @param person: The person with whom the contact item will be\n            associated.\n\n        @type contactInfo: C{dict}\n        @param contactInfo: The contact information to use to create the\n            contact item.\n\n        @return: The contact item, as created by the given contact type.\n        \"\"\"\n        contactItem = contactType.createContactItem(\n            person, **_stringifyKeys(contactInfo))\n        if contactItem is not None:\n            self._callOnOrganizerPlugins('contactItemCreated', contactItem)\n        return contactItem"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nediting the given contact item with the given contact type.", "response": "def editContactItem(self, contactType, contactItem, contactInfo):\n        \"\"\"\n        Edit the given contact item with the given contact type.  Broadcast\n        the edit to all L{IOrganizerPlugin} powerups.\n\n        @type contactType: L{IContactType}\n        @param contactType: The contact type which will be used to edit the\n            contact item.\n\n        @param contactItem: The contact item to edit.\n\n        @type contactInfo: C{dict}\n        @param contactInfo: The contact information to use to edit the\n            contact item.\n\n        @return: C{None}\n        \"\"\"\n        contactType.editContactItem(\n            contactItem, **_stringifyKeys(contactInfo))\n        self._callOnOrganizerPlugins('contactItemEdited', contactItem)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _callOnOrganizerPlugins(self, methodName, *args):\n        for observer in self.getOrganizerPlugins():\n            method = getattr(observer, methodName, None)\n            if method is not None:\n                method(*args)\n            else:\n                warn(\n                    \"IOrganizerPlugin now has the %s method, %s \"\n                    \"did not implement it\" % (methodName, observer.__class__,),\n                    category=PendingDeprecationWarning)", "response": "Calls a method on all the organizer plugins."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef editPerson(self, person, nickname, edits):\n        for existing in self.store.query(Person, Person.name == nickname):\n            if existing is person:\n                continue\n            raise ValueError(\n                \"A person with the name %r exists already.\" % (nickname,))\n        oldname = person.name\n        person.name = nickname\n        self._callOnOrganizerPlugins('personNameChanged', person, oldname)\n        for contactType, submission in edits:\n            if contactType.allowMultipleContactItems:\n                for edit in submission.edit:\n                    self.editContactItem(\n                        contactType, edit.object, edit.values)\n                for create in submission.create:\n                    create.setter(\n                        self.createContactItem(\n                            contactType, person, create.values))\n                for delete in submission.delete:\n                    delete.deleteFromStore()\n            else:\n                (contactItem,) = contactType.getContactItems(person)\n                self.editContactItem(\n                    contactType, contactItem, submission)", "response": "Edit the name and contact information associated with the given person."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef personByName(self, name):\n        return self.store.findOrCreate(Person, organizer=self, name=name)", "response": "Retrieve the person with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the person object for the given email address.", "response": "def personByEmailAddress(self, address):\n        \"\"\"\n        Retrieve the L{Person} item for the given email address\n        (or return None if no such person exists)\n\n        @type name: C{unicode}\n        \"\"\"\n        email = self.store.findUnique(EmailAddress,\n                                      EmailAddress.address == address,\n                                      default=None)\n        if email is not None:\n            return email.person"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a url for the given person and viewState.", "response": "def urlForViewState(self, person, viewState):\n        \"\"\"\n        Return a url for L{OrganizerFragment} which will display C{person} in\n        state C{viewState}.\n\n        @type person: L{Person}\n        @type viewState: L{ORGANIZER_VIEW_STATES} constant.\n\n        @rtype: L{url.URL}\n        \"\"\"\n        # ideally there would be a more general mechanism for encoding state\n        # like this in a url, rather than ad-hoc query arguments for each\n        # fragment which needs to do it.\n        organizerURL = self._webTranslator.linkTo(self.storeID)\n        return url.URL(\n            netloc='', scheme='',\n            pathsegs=organizerURL.split('/')[1:],\n            querysegs=(('initial-person', person.name),\n                       ('initial-state', viewState)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filterByFilter(self, filterName):\n        filter = self.filters[filterName]\n        self.baseConstraint = filter.getPeopleQueryComparison(self.store)", "response": "This method is used to filter the entries in the store by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield the read - only views for each piece of contact info that is associated with the person.", "response": "def contactInfo(self, request, tag):\n        \"\"\"\n        Render the result of calling L{IContactType.getReadOnlyView} on the\n        corresponding L{IContactType} for each piece of contact info\n        associated with L{person}.  Arrange the result by group, using\n        C{tag}'s I{contact-group} pattern. Groupless contact items will have\n        their views yielded directly.\n\n        The I{contact-group} pattern appears once for each distinct\n        L{ContactGroup}, with the following slots filled:\n          I{name} - The group's C{groupName}.\n          I{views} - A sequence of read-only views belonging to the group.\n        \"\"\"\n        groupPattern = inevow.IQ(tag).patternGenerator('contact-group')\n        groupedViews = self.organizer.groupReadOnlyViews(self.person)\n        for (groupName, views) in sorted(groupedViews.items()):\n            if groupName is None:\n                yield views\n            else:\n                yield groupPattern().fillSlots(\n                    'name', groupName).fillSlots(\n                    'views', views)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pluginTabbedPane(self, request, tag):\n        iq = inevow.IQ(tag)\n        tabNames = [\n            _organizerPluginName(p).encode('ascii') # gunk\n                for p in self.plugins]\n        child = tabbedPane.TabbedPaneFragment(\n            zip(tabNames,\n                ([self.getPluginWidget(tabNames[0])]\n                    + [iq.onePattern('pane-body') for _ in tabNames[1:]])))\n        child.jsClass = u'Mantissa.People.PluginTabbedPane'\n        child.setFragmentParent(self)\n        return child", "response": "Render a tabbedPaneFragment with an entry for each item\n        in self. plugins."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the named plugin s view.", "response": "def getPluginWidget(self, pluginName):\n        \"\"\"\n        Return the named plugin's view.\n\n        @type pluginName: C{unicode}\n        @param pluginName: The name of the plugin.\n\n        @rtype: L{LiveElement}\n        \"\"\"\n        # this will always pick the first plugin with pluginName if there is\n        # more than one.  don't do that.\n        for plugin in self.plugins:\n            if _organizerPluginName(plugin) == pluginName:\n                view = self._toLiveElement(\n                    plugin.personalize(self.person))\n                view.setFragmentParent(self)\n                return view"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes the internal state of the object.", "response": "def beforeRender(self, ctx):\n        \"\"\"\n        Implement this hook to initialize the L{initialPerson} and\n        L{initialState} slots with information from the request url's query\n        args.\n        \"\"\"\n        # see the comment in Organizer.urlForViewState which suggests an\n        # alternate implementation of this kind of functionality.\n        request = inevow.IRequest(ctx)\n        if not set(['initial-person', 'initial-state']).issubset( # <=\n            set(request.args)):\n            return\n        initialPersonName = request.args['initial-person'][0].decode('utf-8')\n        initialPerson = self.store.findFirst(\n            Person, Person.name == initialPersonName)\n        if initialPerson is None:\n            return\n        initialState = request.args['initial-state'][0].decode('utf-8')\n        if initialState not in ORGANIZER_VIEW_STATES.ALL_STATES:\n            return\n        self.initialPerson = initialPerson\n        self.initialState = initialState"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getInitialArguments(self):\n        initialArguments = (self.organizer.storeOwnerPerson.name,)\n        if self.initialPerson is not None:\n            initialArguments += (self.initialPerson.name, self.initialState)\n        return initialArguments", "response": "Returns the list of initial arguments for this entry point."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAddPerson(self):\n        fragment = AddPersonFragment(self.organizer)\n        fragment.setFragmentParent(self)\n        return fragment", "response": "Returns an L { AddPersonFragment } which is a child of this fragment and\n        which will add a person to the current set of names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getImportPeople(self):\n        fragment = ImportPeopleWidget(self.organizer)\n        fragment.setFragmentParent(self)\n        return fragment", "response": "Returns an ImportPeopleWidget which is a child of this fragment and\n        which will add people to the current set of people."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an L { EditPersonView } for editing the person named name.", "response": "def getEditPerson(self, name):\n        \"\"\"\n        Get an L{EditPersonView} for editing the person named C{name}.\n\n        @param name: A person name.\n        @type name: C{unicode}\n\n        @rtype: L{EditPersonView}\n        \"\"\"\n        view = EditPersonView(self.organizer.personByName(name))\n        view.setFragmentParent(self)\n        return view"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deletePerson(self, name):\n        self.organizer.deletePerson(self.organizer.personByName(name))", "response": "Delete the person named name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef peopleTable(self, request, tag):\n        f = PersonScrollingFragment(\n            self.organizer, None, Person.name, self.wt)\n        f.setFragmentParent(self)\n        f.docFactory = webtheme.getLoader(f.fragmentName)\n        return f", "response": "Returns a new instance of the PersonScrollingFragment which will display the items in the wrapped organizer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding the people filters for each filter in the organizer s getPeopleFilters method.", "response": "def peopleFilters(self, request, tag):\n        \"\"\"\n        Return an instance of C{tag}'s I{filter} pattern for each filter we\n        get from L{Organizer.getPeopleFilters}, filling the I{name} slot with\n        the filter's name.  The first filter will be rendered using the\n        I{selected-filter} pattern.\n        \"\"\"\n        filters = iter(self.organizer.getPeopleFilters())\n        # at some point we might actually want to look at what filter is\n        # yielded first, and filter the person list accordingly.  we're just\n        # going to assume it's the \"All\" filter, and leave the person list\n        # untouched for now.\n        yield tag.onePattern('selected-filter').fillSlots(\n            'name', filters.next().filterName)\n        pattern = tag.patternGenerator('filter')\n        for filter in filters:\n            yield pattern.fillSlots('name', filter.filterName)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the L { PersonPluginView } for the named person.", "response": "def getPersonPluginWidget(self, name):\n        \"\"\"\n        Return the L{PersonPluginView} for the named person.\n\n        @type name: C{unicode}\n        @param name: A value which corresponds to the I{name} attribute of an\n        extant L{Person}.\n\n        @rtype: L{PersonPluginView}\n        \"\"\"\n        fragment = PersonPluginView(\n            self.organizer.getOrganizerPlugins(),\n            self.organizer.personByName(name))\n        fragment.setFragmentParent(self)\n        return fragment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nediting the contact items associated with the wrapped person.", "response": "def editContactItems(self, nickname, **edits):\n        \"\"\"\n        Update the information on the contact items associated with the wrapped\n        L{Person}.\n\n        @type nickname: C{unicode}\n        @param nickname: New value to use for the I{name} attribute of the\n            L{Person}.\n\n        @param **edits: mapping from contact type identifiers to\n            ListChanges instances.\n        \"\"\"\n        submissions = []\n        for paramName, submission in edits.iteritems():\n            contactType = self.contactTypes[paramName]\n            submissions.append((contactType, submission))\n        self.person.store.transact(\n            self.organizer.editPerson,\n            self.person, nickname, submissions)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes some L{LiveForm instances for editing the contact information of the wrapped person.", "response": "def makeEditorialLiveForms(self):\n        \"\"\"\n        Make some L{liveform.LiveForm} instances for editing the contact\n        information of the wrapped L{Person}.\n        \"\"\"\n        parameters = [\n            liveform.Parameter(\n                'nickname', liveform.TEXT_INPUT,\n                _normalizeWhitespace, 'Name',\n                default=self.person.name)]\n        separateForms = []\n        for contactType in self.organizer.getContactTypes():\n            if getattr(contactType, 'getEditFormForPerson', None):\n                editForm = contactType.getEditFormForPerson(self.person)\n                if editForm is not None:\n                    editForm.setFragmentParent(self)\n                    separateForms.append(editForm)\n                    continue\n            param = self.organizer.toContactEditorialParameter(\n                contactType, self.person)\n            parameters.append(param)\n            self.contactTypes[param.name] = contactType\n        form = liveform.LiveForm(\n            self.editContactItems, parameters, u'Save')\n        form.compact()\n        form.jsClass = u'Mantissa.People.EditPersonForm'\n        form.setFragmentParent(self)\n        return [form] + separateForms"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a C { list} of two liveform parameters one for editing C{phoneNumber}'s I { number attribute and one for editing C{label}s I { number attribute and one for editing C{label}s I { label }s attribute.", "response": "def getParameters(self, phoneNumber):\n        \"\"\"\n        Return a C{list} of two liveform parameters, one for editing\n        C{phoneNumber}'s I{number} attribute, and one for editing its I{label}\n        attribute.\n\n        @type phoneNumber: L{PhoneNumber} or C{NoneType}\n        @param phoneNumber: If not C{None}, an existing contact item from\n        which to get the parameter's default values.\n\n        @rtype: C{list}\n        \"\"\"\n        defaultNumber = u''\n        defaultLabel = PhoneNumber.LABELS.HOME\n        if phoneNumber is not None:\n            defaultNumber = phoneNumber.number\n            defaultLabel = phoneNumber.label\n        labelChoiceParameter = liveform.ChoiceParameter(\n            'label',\n            [liveform.Option(label, label, label == defaultLabel)\n                for label in PhoneNumber.LABELS.ALL_LABELS],\n            'Number Type')\n        return [\n            labelChoiceParameter,\n            liveform.Parameter(\n                'number',\n                liveform.TEXT_INPUT,\n                unicode,\n                'Phone Number',\n                default=defaultNumber)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createContactItem(self, person, label, number):\n        if number:\n            return PhoneNumber(\n                store=person.store, person=person, label=label, number=number)", "response": "Creates a new entry in the store for the given person and label and number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef editContactItem(self, contact, label, number):\n        contact.label = label\n        contact.number = number", "response": "Edit the I { number } attribute of the the\n        object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getContactItems(self, person):\n        return person.store.query(\n            PhoneNumber, PhoneNumber.person == person)", "response": "Returns an iterable of items that are associated with the given person."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a C { list} of one L { LiveForm } parameter for editing a postal address.", "response": "def getParameters(self, postalAddress):\n        \"\"\"\n        Return a C{list} of one L{LiveForm} parameter for editing a\n        L{PostalAddress}.\n\n        @type postalAddress: L{PostalAddress} or C{NoneType}\n\n        @param postalAddress: If not C{None}, an existing contact item from\n            which to get the postal address default value.\n\n        @rtype: C{list}\n        @return: The parameters necessary for specifying a postal address.\n        \"\"\"\n        address = u''\n        if postalAddress is not None:\n            address = postalAddress.address\n        return [\n            liveform.Parameter('address', liveform.TEXT_INPUT,\n                               unicode, 'Postal Address', default=address)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createContactItem(self, person, address):\n        if address:\n            return PostalAddress(\n                store=person.store, person=person, address=address)", "response": "Creates a new object of type PostalAddress based on the given person and the given address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a C { list } of the items associated with the given person.", "response": "def getContactItems(self, person):\n        \"\"\"\n        Return a C{list} of the L{PostalAddress} items associated with the\n        given person.\n\n        @type person: L{Person}\n        \"\"\"\n        return person.store.query(PostalAddress, PostalAddress.person == person)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a C { list} of one L { LiveForm } parameter for editing a .", "response": "def getParameters(self, notes):\n        \"\"\"\n        Return a C{list} of one L{LiveForm} parameter for editing a\n        L{Notes}.\n\n        @type notes: L{Notes} or C{NoneType}\n        @param notes: If not C{None}, an existing contact item from\n            which to get the parameter's default value.\n\n        @rtype: C{list}\n        \"\"\"\n        defaultNotes = u''\n        if notes is not None:\n            defaultNotes = notes.notes\n        return [\n            liveform.Parameter('notes', liveform.TEXTAREA_INPUT,\n                               unicode, 'Notes', default=defaultNotes)]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new object of type Notes associated with the given person based on the the given string.", "response": "def createContactItem(self, person, notes):\n        \"\"\"\n        Create a new L{Notes} associated with the given person based on the\n        given string.\n\n        @type person: L{Person}\n        @param person: The person with whom to associate the new L{Notes}.\n\n        @type notes: C{unicode}\n        @param notes: The value to use for the I{notes} attribute of the newly\n        created L{Notes}.  If C{''}, no L{Notes} will be created.\n\n        @rtype: L{Notes} or C{NoneType}\n        \"\"\"\n        if notes:\n            return Notes(\n                store=person.store, person=person, notes=notes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getContactItems(self, person):\n        notes = list(person.store.query(Notes, Notes.person == person))\n        if not notes:\n            return [Notes(store=person.store,\n                          person=person,\n                          notes=u'')]\n        return notes", "response": "Returns a C { list } of the L { Notes } items associated with the given person. If no items exist create one and return it."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates and return a L{liveform. LiveForm for creating a new Person.", "response": "def render_addPersonForm(self, ctx, data):\n        \"\"\"\n        Create and return a L{liveform.LiveForm} for creating a new L{Person}.\n        \"\"\"\n        addPersonForm = liveform.LiveForm(\n            self.addPerson, self._baseParameters, description='Add Person')\n        addPersonForm.compact()\n        addPersonForm.jsClass = u'Mantissa.People.AddPersonForm'\n        addPersonForm.setFragmentParent(self)\n        return addPersonForm"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addPerson(self, nickname):\n        try:\n            self.organizer.createPerson(nickname)\n        except ValueError, e:\n            raise liveform.InputError(unicode(e))", "response": "Add a person with the given nickname to the set of available persons."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parseAddresses(addresses):\n        def coerce((name, email)):\n            if len(email):\n                if not len(name):\n                    name = email.split(u'@', 1)[0]  # lame\n                return (name, email)\n        coerced = map(coerce, getaddresses([addresses]))\n        return [r for r in coerced if r is not None]", "response": "Parse the given list of addresses and return a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef importPeopleForm(self, request, tag):\n        form = liveform.LiveForm(\n            self.importAddresses,\n            [liveform.Parameter('addresses', liveform.TEXTAREA_INPUT,\n                                self._parseAddresses, 'Email Addresses')],\n            description='Import People')\n        form.jsClass = u'Mantissa.People.ImportPeopleForm'\n        form.compact()\n        form.setFragmentParent(self)\n        return form", "response": "Create and return a L{liveform. LiveForm for adding new People."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate new people for the given names and email addresses.", "response": "def importAddresses(self, addresses):\n        \"\"\"\n        Create new L{Person}s for the given names and email addresses.\n        Names and emails that already exist are ignored.\n\n        @param addresses: a sequence of C{(name, email)} tuples\n                          (as returned from L{_parseAddresses})\n        @return: the names of people actually imported\n        \"\"\"\n        results = []\n        for (name, address) in addresses:\n            def txn():\n                # Skip names and addresses that already exist.\n                if self.organizer.personByEmailAddress(address) is not None:\n                    return\n                # XXX: Needs a better existence check.\n                if self.store.query(Person, Person.name == name).count():\n                    return\n\n                try:\n                    person = self.organizer.createPerson(name)\n                    self.organizer.createContactItem(\n                        EmailContactType(self.store), person,\n                        dict(email=address))\n                except ValueError, e:\n                    # XXX: Granularity required;  see #711 and #2435\n                    raise liveform.ConfigurationError(u'%r' % (e,))\n                return person\n            results.append(self.store.transact(txn))\n        return [p.name for p in results if p is not None]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts the data from the I{uploaddata} field of the request and pass it to our callback.", "response": "def renderHTTP(self, ctx):\n        \"\"\"\n        Extract the data from the I{uploaddata} field of the request and pass\n        it to our callback.\n        \"\"\"\n        req = inevow.IRequest(ctx)\n        if req.method == 'POST':\n            udata = req.fields['uploaddata']\n            self.cbGotMugshot(udata.type.decode('ascii'), udata.file)\n        return rend.Page.renderHTTP(self, ctx)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new entry for a mugshot item from a file.", "response": "def fromFile(cls, person, inputFile, format):\n        \"\"\"\n        Create a L{Mugshot} item for C{person} out of the image data in\n        C{inputFile}, or update C{person}'s existing L{Mugshot} item to\n        reflect the new images.\n\n        @param inputFile: An image of a person.\n        @type inputFile: C{file}\n\n        @param person: The person this mugshot is to be associated with.\n        @type person: L{Person}\n\n        @param format: The format of the data in C{inputFile}.\n        @type format: C{unicode} (e.g. I{jpeg})\n\n        @rtype: L{Mugshot}\n        \"\"\"\n        body = cls.makeThumbnail(inputFile, person, format, smaller=False)\n        inputFile.seek(0)\n        smallerBody = cls.makeThumbnail(\n            inputFile, person, format, smaller=True)\n\n        ctype = u'image/' + format\n\n        self = person.store.findUnique(\n            cls, cls.person == person, default=None)\n        if self is None:\n            self = cls(store=person.store,\n                       person=person,\n                       type=ctype,\n                       body=body,\n                       smallerBody=smallerBody)\n        else:\n            self.body = body\n            self.smallerBody = smallerBody\n            self.type = ctype\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef makeThumbnail(cls, inputFile, person, format, smaller):\n        dirsegs = ['mugshots', str(person.storeID)]\n        if smaller:\n            dirsegs.insert(1, 'smaller')\n            size = cls.smallerSize\n        else:\n            size = cls.size\n        atomicOutputFile = person.store.newFile(*dirsegs)\n        makeThumbnail(inputFile, atomicOutputFile, size, format)\n        atomicOutputFile.close()\n        return atomicOutputFile.finalpath", "response": "This method creates a thumbnail of a mugshot image and store it on disk."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an unstored placeholder L { Mugshot } instance for the given person.", "response": "def placeholderForPerson(cls, person):\n        \"\"\"\n        Make an unstored, placeholder L{Mugshot} instance for the given\n        person.\n\n        @param person: A person without a L{Mugshot}.\n        @type person: L{Person}\n\n        @rtype: L{Mugshot}\n        \"\"\"\n        imageDir = FilePath(__file__).parent().child(\n            'static').child('images')\n        return cls(\n            type=u'image/png',\n            body=imageDir.child('mugshot-placeholder.png'),\n            smallerBody=imageDir.child(\n                'mugshot-placeholder-smaller.png'),\n            person=person)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister filter and global in Jinja environment instance", "response": "def post_build(self, container_builder, container):\n        \"\"\"\n        Register filter and global in jinja environment instance\n\n        IoC tags are:\n            - jinja2.filter to register filter, the tag must contain\n            a name and a method options\n            - jinja2.global to add new global, here globals are functions. \n            The tag must contain a name and a method options\n        \"\"\"\n        jinja = container.get('ioc.extra.jinja2')\n\n        for id in container_builder.get_ids_by_tag('jinja2.filter'):\n            definition = container_builder.get(id)\n            for option in definition.get_tag('jinja2.filter'):\n                if 'name' not in option:\n                    break\n\n                if 'method' not in option:\n                    break\n\n                jinja.filters[option['name']] = getattr(container.get(id), option['method'])\n\n        for id in container_builder.get_ids_by_tag('jinja2.global'):\n            definition = container_builder.get(id)\n            for option in definition.get_tag('jinja2.global'):\n\n                if 'name' not in option:\n                    break\n\n                if 'method' not in option:\n                    break                \n\n                jinja.globals[option['name']] = getattr(container.get(id), option['method'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the cache key with respect to the given arguments.", "response": "def cache_key(*args, **kwargs):\n    \"\"\"\n    Base method for computing the cache key with respect to the given\n    arguments.\n    \"\"\"\n    key = \"\"\n    for arg in args:\n        if callable(arg):\n            key += \":%s\" % repr(arg)\n        else:\n            key += \":%s\" % str(arg)\n\n    return key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupload a file to the server at baseurl.", "response": "def uploadfile(baseurl, filename, format_, token, nonce, cert, method=requests.post):\n    \"\"\"Uploads file (given by `filename`) to server at `baseurl`.\n\n    `sesson_key` and `nonce` are string values that get passed as POST\n    parameters.\n    \"\"\"\n    filehash = sha1sum(filename)\n    files = {'filedata': open(filename, 'rb')}\n\n    payload = {\n        'sha1': filehash,\n        'filename': os.path.basename(filename),\n        'token': token,\n        'nonce': nonce,\n    }\n\n    return method(\"%s/sign/%s\" % (baseurl, format_), files=files, data=payload, verify=cert)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode base64 encoded responses from Consul storage", "response": "def decode_values(fct):\n    ''' Decode base64 encoded responses from Consul storage '''\n    def inner(*args, **kwargs):\n        ''' decorator '''\n        data = fct(*args, **kwargs)\n        if 'error' not in data:\n            for result in data:\n                result['Value'] = base64.b64decode(result['Value'])\n        return data\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn json messages instead of raising errors", "response": "def safe_request(fct):\n    ''' Return json messages instead of raising errors '''\n    def inner(*args, **kwargs):\n        ''' decorator '''\n        try:\n            _data = fct(*args, **kwargs)\n        except requests.exceptions.ConnectionError as error:\n            return {'error': str(error), 'status': 404}\n\n        if _data.ok:\n            if _data.content:\n                safe_data = _data.json()\n            else:\n                safe_data = {'success': True}\n        else:\n            safe_data = {'error': _data.reason, 'status': _data.status_code}\n\n        return safe_data\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the given RFC 2821 email address into a structured object.", "response": "def parseAddress(address):\n    \"\"\"\n    Parse the given RFC 2821 email address into a structured object.\n\n    @type address: C{str}\n    @param address: The address to parse.\n\n    @rtype: L{Address}\n\n    @raise xmantissa.error.ArgumentError: The given string was not a valid RFC\n    2821 address.\n    \"\"\"\n    parts = []\n    parser = _AddressParser()\n    end = parser(parts, address)\n    if end != len(address):\n        raise InvalidTrailingBytes()\n    return parts[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n        self._initial_setup()\n        self.on_service_start()\n\n        self.app = self.make_tornado_app()\n        enable_pretty_logging()\n        self.app.listen(self.port, address=self.host)\n\n        self._start_periodic_tasks()\n        # starts the event handlers\n        self._initialize_event_handlers()\n        self._start_event_handlers()\n\n        try:\n            self.io_loop.start()\n        except RuntimeError:\n            # TODO : find a way to check if the io_loop is running before trying to start it\n            # this method to check if the loop is running is ugly\n            pass", "response": "Start the service. This method is blocking."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plugin(self, name):\n        for plugin in self.plugins:\n            if plugin.name == name:\n                return plugin\n\n        raise PluginDoesNotExistError(\"Plugin '{}' not found\".format(name))", "response": "Returns a plugin instance by name and raises an error if no such plugin exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlocate a remote service by name.", "response": "def get_service(self, name):\n        \"\"\"\n        Locates a remote service by name. The name can be a glob-like pattern\n        (``\"project.worker.*\"``). If multiple services match the given name, a\n        random instance will be chosen. There might be multiple services that\n        match a given name if there are multiple services with the same name\n        running, or when the pattern matches multiple different services.\n\n        .. todo::\n\n            Make this use self.io_loop to resolve the request. The current\n            implementation is blocking and slow\n\n        :param name: a pattern for the searched service.\n        :return: a :py:class:`gemstone.RemoteService` instance\n        :raises ValueError: when the service can not be located\n        :raises ServiceConfigurationError: when there is no configured discovery strategy\n        \"\"\"\n        if not self.discovery_strategies:\n            raise ServiceConfigurationError(\"No service registry available\")\n\n        cached = self.remote_service_cache.get_entry(name)\n        if cached:\n            return cached.remote_service\n\n        for strategy in self.discovery_strategies:\n            endpoints = strategy.locate(name)\n            if not endpoints:\n                continue\n            random.shuffle(endpoints)\n            for url in endpoints:\n                try:\n                    service = get_remote_service_instance_for_url(url)\n                    self.remote_service_cache.add_entry(name, service)\n                    return service\n                except ConnectionError:\n                    continue  # could not establish connection, try next\n\n        raise ValueError(\"Service could not be located\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npublishing an event to all available event transports.", "response": "def emit_event(self, event_name, event_body):\n        \"\"\"\n        Publishes an event of type ``event_name`` to all subscribers, having the body\n        ``event_body``. The event is pushed through all available event transports.\n\n        The event body must be a Python object that can be represented as a JSON.\n\n        :param event_name: a ``str`` representing the event type\n        :param event_body: a Python object that can be represented as JSON.\n\n        .. versionadded:: 0.5.0\n\n        .. versionchanged:: 0.10.0\n            Added parameter broadcast\n        \"\"\"\n\n        for transport in self.event_transports:\n            transport.emit_event(event_name, event_body)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Tornado application that exposes the designated methods.", "response": "def make_tornado_app(self):\n        \"\"\"\n        Creates a :py:class`tornado.web.Application` instance that respect the\n        JSON RPC 2.0 specs and exposes the designated methods. Can be used\n        in tests to obtain the Tornado application.\n\n        :return: a :py:class:`tornado.web.Application` instance\n        \"\"\"\n\n        handlers = [\n            (self.endpoint, TornadoJsonRpcHandler, {\"microservice\": self})\n        ]\n\n        self._add_extra_handlers(handlers)\n        self._add_static_handlers(handlers)\n\n        return Application(handlers, template_path=self.template_dir)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the extra handlers defined by the user to the list of handlers.", "response": "def _add_extra_handlers(self, handlers):\n        \"\"\"\n        Adds the extra handler (defined by the user)\n\n        :param handlers: a list of :py:class:`tornado.web.RequestHandler` instances.\n        :return:\n        \"\"\"\n        extra_handlers = [(h[0], h[1], {\"microservice\": self}) for h in self.extra_handlers]\n        handlers.extend(extra_handlers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and adds the handles needed for serving static files.", "response": "def _add_static_handlers(self, handlers):\n        \"\"\"\n        Creates and adds the handles needed for serving static files.\n\n        :param handlers:\n        \"\"\"\n        for url, path in self.static_dirs:\n            handlers.append((url.rstrip(\"/\") + \"/(.*)\", StaticFileHandler, {\"path\": path}))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch for the methods exposed in the current microservice class.", "response": "def _gather_exposed_methods(self):\n        \"\"\"\n        Searches for the exposed methods in the current microservice class. A method is considered\n        exposed if it is decorated with the :py:func:`gemstone.public_method` or\n        :py:func:`gemstone.private_api_method`.\n        \"\"\"\n\n        self._extract_methods_from_container(self)\n\n        for module in self.modules:\n            self._extract_methods_from_container(module)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for the event handlers in the current microservice class.", "response": "def _gather_event_handlers(self):\n        \"\"\"\n        Searches for the event handlers in the current microservice class.\n\n        :return:\n        \"\"\"\n        self._extract_event_handlers_from_container(self)\n        for module in self.modules:\n            self._extract_event_handlers_from_container(module)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\niterating through all the periodic tasks.", "response": "def _periodic_task_iter(self):\n        \"\"\"\n        Iterates through all the periodic tasks:\n\n        - the service registry pinging\n        - default dummy task if on Windows\n        - user defined periodic tasks\n\n        :return:\n        \"\"\"\n        for strategy in self.discovery_strategies:\n            self.default_periodic_tasks.append(\n                (functools.partial(strategy.ping, self.name, self.accessible_at),\n                 self.service_registry_ping_interval)\n            )\n            self.default_periodic_tasks[-1][0]()\n\n        all_periodic_tasks = self.default_periodic_tasks + self.periodic_tasks\n        for func, timer_in_seconds in all_periodic_tasks:\n            timer_milisec = timer_in_seconds * 1000\n            yield PeriodicCallback(func, timer_milisec, io_loop=self.io_loop)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize(self):\n        '''Calling this function initializes the printer.\n    \n        Args:\n            None\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        self.fonttype = self.font_types['bitmap']\n        self.send(chr(27)+chr(64))", "response": "This function initializes the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects international character set and changes codes in code table accordingly.", "response": "def select_charset(self, charset):\n        '''Select international character set and changes codes in code table accordingly\n        \n        Args:\n            charset: String. The character set we want.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid charset.\n        '''\n        charsets = {'USA':0,\n                   'France':1,\n                   'Germany':2,\n                   'UK':3, \n                   'Denmark':4,\n                   'Sweden':5, \n                   'Italy':6, \n                   'Spain':7,\n                   'Japan':8, \n                   'Norway':9, \n                   'Denmark II':10, \n                   'Spain II':11, \n                   'Latin America':12, \n                   'South Korea':13, \n                   'Legal':64, \n                   }\n        if charset in charsets:\n            self.send(chr(27)+'R'+chr(charsets[charset]))\n        else:\n            raise RuntimeError('Invalid charset.')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect character code table from tree built in ones.", "response": "def select_char_code_table(self, table):\n        '''Select character code table, from tree built in ones.\n        \n        Args:\n            table: The desired character code table. Choose from 'standard', 'eastern european', 'western european', and 'spare'\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid chartable.\n        '''\n        tables = {'standard': 0,\n                  'eastern european': 1,\n                  'western european': 2,\n                  'spare': 3\n                  }\n        if table in tables:\n            self.send(chr(27)+'t'+chr(tables[table]))\n        else:\n            raise RuntimeError('Invalid char table.')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cut_setting(self, cut):\n        '''Set cut setting for printer. \n        \n        Args:\n            cut: The type of cut setting we want. Choices are 'full', 'half', 'chain', and 'special'.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid cut type.\n        '''\n        \n        cut_settings = {'full' : 0b00000001,\n                        'half' : 0b00000010,\n                        'chain': 0b00000100,\n                        'special': 0b00001000\n                        }\n        if cut in cut_settings:\n            self.send(chr(27)+'iC'+chr(cut_settings[cut]))\n        else:\n            raise RuntimeError('Invalid cut type.')", "response": "Sets the cut setting for the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rotated_printing(self, action):\n        '''Calling this function applies the desired action to the printing orientation\n        of the printer.\n        \n        Args:\n            action: The desired printing orientation. 'rotate' enables rotated printing. 'normal' disables rotated printing.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid action.\n        '''\n        if action=='rotate':\n            action='1'\n        elif action=='cancel':\n            action='0'\n        else:\n            raise RuntimeError('Invalid action.')\n        self.send(chr(27)+chr(105)+chr(76)+action)", "response": "Applies the desired action to the printing orientation\n            of the printer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef feed_amount(self, amount):\n        '''Calling this function sets the form feed amount to the specified setting.\n    \n        Args:\n            amount: the form feed setting you desire. Options are '1/8', '1/6', 'x/180', and 'x/60',\n            with x being your own desired amount. X must be a minimum of 24 for 'x/180' and 8 for 'x/60'\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        n = None\n        if amount=='1/8':\n            amount = '0'\n        elif amount=='1/6':\n            amount = '2'\n        elif re.search('/180', amount):\n            n = re.search(r\"(\\d+)/180\", amount)\n            n = n.group(1)\n            amount = '3'\n        elif re.search('/60', amount):\n            n = re.search(r\"(\\d+)/60\", amount)\n            n = n.group(1)\n            amount = 'A'\n        if n:\n            self.send(chr(27)+amount+n)\n        else:\n            self.send(chr(27)+amount)", "response": "This function sets the form feed amount to the specified amount."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nspecifying page length. This command is only valid with continuous length labels.", "response": "def page_length(self, length):\n        '''Specifies page length. This command is only valid with continuous length labels.\n        \n        Args:\n            length: The length of the page, in dots. Can't exceed 12000.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Length must be less than 12000.\n        '''\n        mH = length/256\n        mL = length%256\n        if length < 12000:\n            self.send(chr(27)+'('+'C'+chr(2)+chr(0)+chr(mL)+chr(mH))\n        else:\n            raise RuntimeError('Length must be less than 12000.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef page_format(self, topmargin, bottommargin):\n        '''Specify settings for top and bottom margins. Physically printable area depends on media.\n        \n        Args:\n            topmargin: the top margin, in dots. The top margin must be less than the bottom margin.\n            bottommargin: the bottom margin, in dots. The bottom margin must be less than the top margin.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Top margin must be less than the bottom margin.\n        '''\n        tL = topmargin%256\n        tH = topmargin/256\n        BL = bottommargin%256\n        BH = topmargin/256\n        if (tL+tH*256) < (BL + BH*256):\n            self.send(chr(27)+'('+'c'+chr(4)+chr(0)+chr(tL)+chr(tH)+chr(BL)+chr(BH))\n        else:\n            raise RuntimeError('The top margin must be less than the bottom margin')", "response": "Specify settings for top and bottom margins. Physically printable area depends on media."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nspecify the left margin.", "response": "def left_margin(self, margin):\n        '''Specify the left margin.\n        \n        Args:\n            margin: The left margin, in character width. Must be less than the media's width.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid margin parameter.\n        '''\n        if margin <= 255 and margin >= 0:\n            self.send(chr(27)+'I'+chr(margin))\n        else:\n            raise RuntimeError('Invalid margin parameter.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef right_margin(self, margin):\n        '''Specify the right margin.\n        \n        Args:\n            margin: The right margin, in character width, must be less than the media's width.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid margin parameter\n        '''\n        if margin >=1 and margin <=255:\n            self.send(chr(27)+'Q'+chr(margin))\n        else:\n            raise RuntimeError('Invalid margin parameter in function rightMargin')", "response": "Specify the right margin."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vert_tab_pos(self, positions):\n        '''Sets tab positions, up to a maximum of 32 positions. Also can clear tab positions.\n        \n        Args:\n            positions -- Either a list of tab positions (between 1 and 255), or 'clear'.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid position parameter.\n            RuntimeError: Too many positions.\n        '''\n        if positions == 'clear':\n            self.send(chr(27)+'B'+chr(0))\n            return\n        if positions.min < 1 or positions.max >255:\n                raise RuntimeError('Invalid position parameter in function horzTabPos')\n        sendstr = chr(27) + 'D'\n        if len(positions)<=16:\n            for position in positions:\n                sendstr += chr(position)\n            self.send(sendstr + chr(0))\n        else:\n            raise RuntimeError('Too many positions in function vertTabPos')", "response": "Sets tab positions up to a maximum of 32 positions. Also can clear tab positions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls this function finishes input of the current line, then moves the vertical print position forward by x/300 inch. Args: amount: how far foward you want the position moved. Actual movement is calculated as amount/300 inches. Returns: None Raises: RuntimeError: Invalid foward feed.", "response": "def forward_feed(self, amount):\n        '''Calling this function finishes input of the current line, then moves the vertical \n        print position forward by x/300 inch.\n        \n        Args:\n            amount: how far foward you want the position moved. Actual movement is calculated as \n            amount/300 inches.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid foward feed.\n        '''\n        if amount <= 255 and amount >=0:\n            self.send(chr(27)+'J'+chr(amount))\n        else:\n            raise RuntimeError('Invalid foward feed, must be less than 255 and >= 0')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nspecifies vertical print position from the top margin position.", "response": "def abs_vert_pos(self, amount):\n        '''Specify vertical print position from the top margin position.\n        \n        Args:\n            amount: The distance from the top margin you'd like, from 0 to 32767\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid vertical position.\n        '''\n        mL = amount%256\n        mH = amount/256\n        if amount < 32767 and amount > 0:\n            self.send(chr(27)+'('+'V'+chr(2)+chr(0)+chr(mL)+chr(mH))\n        else:\n            raise RuntimeError('Invalid vertical position in function absVertPos')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling this function sets the absoulte print position for the next data, this is the position from the left margin. Args: amount: desired positioning. Can be a number from 0 to 2362. The actual positioning is calculated as (amount/60)inches from the left margin. Returns: None Raises: None", "response": "def abs_horz_pos(self, amount):\n        '''Calling this function sets the absoulte print position for the next data, this is\n        the position from the left margin.\n        \n        Args:\n            amount: desired positioning. Can be a number from 0 to 2362. The actual positioning\n            is calculated as (amount/60)inches from the left margin.\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        n1 = amount%256\n        n2 = amount/256\n        self.send(chr(27)+'${n1}{n2}'.format(n1=chr(n1), n2=chr(n2)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rel_horz_pos(self, amount):\n        '''Calling this function sets the relative horizontal position for the next data, this is\n        the position from the current position. The next character will be printed (x/180)inches\n        away from the current position. The relative position CANNOT be specified to the left.\n        This command is only valid with left alignment.\n        \n        Args:\n            amount: desired positioning. Can be a number from 0 to 7086. The actual positioning\n            is calculated as (amount/180)inches from the current position.\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        n1 = amount%256\n        n2 = amount/256\n        self.send(chr(27)+'\\{n1}{n2}'.format(n1=chr(n1),n2=chr(n2)))", "response": "This function sets the relative horizontal position for the next data in the current position. This command is only valid with left alignment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the alignment of the print.", "response": "def alignment(self, align):\n        '''Sets the alignment of the printer.\n        \n        Args:\n            align: desired alignment. Options are 'left', 'center', 'right', and 'justified'. Anything else\n            will throw an error.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid alignment.\n        '''\n        if align=='left':\n            align = '0'\n        elif align=='center':\n            align = '1'\n        elif align=='right':\n            align = '2'\n        elif align=='justified':\n            align = '3'\n        else:\n            raise RuntimeError('Invalid alignment in function alignment')\n        self.send(chr(27)+'a'+align)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef frame(self, action):\n        '''Places/removes frame around text\n        \n        Args:\n            action -- Enable or disable frame. Options are 'on' and 'off'\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid action.\n        '''\n        choices = {'on': '1',\n                   'off': '0'}\n        if action in choices:\n            self.send(chr(27)+'if'+choices[action])\n        else:\n            raise RuntimeError('Invalid action for function frame, choices are on and off')", "response": "Places or removes frame around text\n        \nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nenables or cancel bold printing", "response": "def bold(self, action):\n        '''Enable/cancel bold printing\n        \n        Args:\n            action: Enable or disable bold printing. Options are 'on' and 'off'\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid action.\n        '''\n        if action =='on':\n            action = 'E'\n        elif action == 'off':\n            action = 'F'\n        else:\n            raise RuntimeError('Invalid action for function bold. Options are on and off')\n        self.send(chr(27)+action)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables or cancel italic printing of the current object.", "response": "def italic(self, action):\n        '''Enable/cancel italic printing\n        \n        Args:\n            action: Enable or disable italic printing. Options are 'on' and 'off'\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid action.\n        '''\n        if action =='on':\n            action = '4'\n        elif action=='off':\n            action = '5'\n        else:\n            raise RuntimeError('Invalid action for function italic. Options are on and off')\n        self.send(chr(27)+action)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables or cancel doublestrike printing.", "response": "def double_strike(self, action):\n        '''Enable/cancel doublestrike printing\n        \n        Args:\n            action: Enable or disable doublestrike printing. Options are 'on' and 'off'\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid action.\n        '''\n        if action == 'on':\n            action = 'G'\n        elif action == 'off':\n            action = 'H'\n        else:\n            raise RuntimeError('Invalid action for function doubleStrike. Options are on and off')\n        self.send(chr(27)+action)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef double_width(self, action):\n        '''Enable/cancel doublewidth printing\n        \n        Args:\n            action: Enable or disable doublewidth printing. Options are 'on' and 'off'\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid action.\n        '''\n        if action == 'on':\n            action = '1'\n        elif action == 'off':\n            action = '0'\n        else:\n            raise RuntimeError('Invalid action for function doubleWidth. Options are on and off')\n        self.send(chr(27)+'W'+action)", "response": "Enable or cancel doublewidth printing."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compressed_char(self, action):\n        '''Enable/cancel compressed character printing\n        \n        Args:\n            action: Enable or disable compressed character printing. Options are 'on' and 'off'\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid action.\n        '''\n        if action == 'on':\n            action = 15\n        elif action == 'off':\n            action = 18\n        else:\n            raise RuntimeError('Invalid action for function compressedChar. Options are on and off')\n        self.send(chr(action))", "response": "Enable or cancel compressed character printing."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nenables or cancel underline printing.", "response": "def underline(self, action):\n        '''Enable/cancel underline printing\n        \n        Args:\n            action -- Enable or disable underline printing. Options are '1' - '4' and 'cancel'\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        if action == 'off':\n            action = '0'\n            self.send(chr(27)+chr(45)+action)\n        else:\n            self.send(chr(27)+chr(45)+action)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging font size of the current object.", "response": "def char_size(self, size):\n        '''Changes font size\n        \n        Args:\n            size: change font size. Options are 24' '32' '48' for bitmap fonts \n            33, 38, 42, 46, 50, 58, 67, 75, 83, 92, 100, 117, 133, 150, 167, 200 233, \n            11, 44, 77, 111, 144 for outline fonts.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid font size.\n            Warning: Your font is currently set to outline and you have selected a bitmap only font size\n            Warning: Your font is currently set to bitmap and you have selected an outline only font size\n        '''\n        sizes = {'24':0,\n                   '32':0,\n                   '48':0,\n                   '33':0, \n                   '38':0,\n                   '42':0, \n                   '46':0, \n                   '50':0,\n                   '58':0, \n                   '67':0, \n                   '75':0, \n                   '83':0, \n                   '92':0, \n                   '100':0, \n                   '117':0, \n                   '133':0, \n                   '150':0, \n                   '167':0, \n                   '200':0, \n                   '233':0, \n                   '11':1, \n                   '44':1, \n                   '77':1, \n                   '111':1, \n                   '144':1\n                   }\n        if size in sizes:\n            if size in ['24','32','48'] and self.fonttype != self.font_types['bitmap']:\n                raise Warning('Your font is currently set to outline and you have selected a bitmap only font size')\n            if size not in ['24', '32', '48'] and self.fonttype != self.font_types['outline']:\n                raise Warning('Your font is currently set to bitmap and you have selected an outline only font size')\n            self.send(chr(27)+'X'+chr(0)+chr(int(size))+chr(sizes[size]))\n        else:\n            raise RuntimeError('Invalid size for function charSize, choices are auto 4pt 6pt 9pt 12pt 18pt and 24pt')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting font type returning the related object.", "response": "def select_font(self, font):\n        '''Select font type\n        \n        Choices are: \n        <Bit map fonts>\n        'brougham'\n        'lettergothicbold'\n        'brusselsbit'\n        'helsinkibit'\n        'sandiego'\n        <Outline fonts>\n        'lettergothic'\n        'brusselsoutline'\n        'helsinkioutline'\n        \n        Args:\n            font: font type\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid font.\n        '''\n        fonts = {'brougham': 0, \n                 'lettergothicbold': 1, \n                 'brusselsbit' : 2, \n                 'helsinkibit': 3, \n                 'sandiego': 4, \n                 'lettergothic': 9,\n                 'brusselsoutline': 10, \n                 'helsinkioutline': 11}\n        \n        if font in fonts:\n            if font in ['broughham', 'lettergothicbold', 'brusselsbit', 'helsinkibit', 'sandiego']:\n                self.fonttype = self.font_types['bitmap']\n            else:\n                self.fonttype = self.font_types['outline']\n                \n            self.send(chr(27)+'k'+chr(fonts[font]))\n        else:\n            raise RuntimeError('Invalid font in function selectFont')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef char_style(self, style):\n        '''Sets the character style.\n        \n        Args:\n            style: The desired character style. Choose from 'normal', 'outline', 'shadow', and 'outlineshadow'\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid character style\n        '''\n        styleset = {'normal': 0,\n                    'outline': 1,\n                    'shadow': 2,\n                    'outlineshadow': 3\n                    }\n        if style in styleset:\n            self.send(chr(27) + 'q' + chr(styleset[style]))\n        else:\n            raise RuntimeError('Invalid character style in function charStyle')", "response": "Sets the character style."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspecifies proportional characters. When turned on the character spacing set with charSpacing.", "response": "def proportional_char(self, action):\n        '''Specifies proportional characters. When turned on, the character spacing set\n        with charSpacing.\n        \n        Args:\n            action: Turn proportional characters on or off.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid action.\n        '''\n        actions = {'off': 0,\n                   'on': 1\n                   }\n        if action in actions:\n            self.send(chr(27)+'p'+action)\n        else:\n            raise RuntimeError('Invalid action in function proportionalChar')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting a standard barcode in the specified format.", "response": "def barcode(self, data, format, characters='off', height=48, width='small', parentheses='on', ratio='3:1', equalize='off', rss_symbol='rss14std', horiz_char_rss=2):\n        '''Print a standard barcode in the specified format\n        \n        Args:\n            data: the barcode data\n            format: the barcode type you want. Choose between code39, itf, ean8/upca, upce, codabar, code128, gs1-128, rss\n            characters: Whether you want characters below the bar code. 'off' or 'on'\n            height: Height, in dots.\n            width: width of barcode. Choose 'xsmall' 'small' 'medium' 'large'\n            parentheses: Parentheses deletion on or off. 'on' or 'off' Only matters with GS1-128\n            ratio: ratio between thick and thin bars. Choose '3:1', '2.5:1', and '2:1'\n            equalize: equalize bar lengths, choose 'off' or 'on'\n            rss_symbol: rss symbols model, choose from 'rss14std', 'rss14trun', 'rss14stacked', 'rss14stackedomni', 'rsslimited', 'rssexpandedstd', 'rssexpandedstacked'\n            horiz_char_rss: for rss expanded stacked, specify the number of horizontal characters, must be an even number b/w 2 and 20.\n        '''\n        \n        barcodes = {'code39': '0',\n                    'itf': '1',\n                    'ean8/upca': '5',\n                    'upce': '6',\n                    'codabar': '9',\n                    'code128': 'a',\n                    'gs1-128': 'b',\n                    'rss': 'c'}\n        \n        widths = {'xsmall': '0',\n                  'small': '1',\n                  'medium': '2',\n                  'large': '3'}\n        \n        ratios = {'3:1': '0',\n                  '2.5:1': '1',\n                  '2:1': '2'}\n        \n        rss_symbols = {'rss14std': '0',\n                       'rss14trun': '1',\n                       'rss14stacked': '2',\n                       'rss14stackedomni' : '3',\n                       'rsslimited': '4',\n                       'rssexpandedstd': '5',\n                       'rssexpandedstacked': '6'\n                       }\n        \n        character_choices = {'off': '0',\n                      'on' : '1'}\n        parentheses_choices = {'off':'1',\n                               'on': '0'}\n        equalize_choices = {'off': '0',\n                            'on': '1'}\n        \n        sendstr = ''\n        n2 = height/256\n        n1 = height%256\n        if format in barcodes and width in widths and ratio in ratios and characters in character_choices and rss_symbol in rss_symbols:\n            sendstr += (chr(27)+'i'+'t'+barcodes[format]+'s'+'p'+'r'+character_choices[characters]+'u'+'x'+'y'+'h' + chr(n1) + chr(n2) +\n                        'w'+widths[width]+'e'+parentheses_choices[parentheses]+'o'+rss_symbols[rss_symbol]+'c'+chr(horiz_char_rss)+'z'+ratios[ratio]+'f'+equalize_choices[equalize]\n                        + 'b' + data + chr(92))\n            if format in ['code128', 'gs1-128']:\n                sendstr += chr(92)+ chr(92)\n            self.send(sendstr)\n        else:\n            raise RuntimeError('Invalid parameters')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchoosing a template from the set of available log files.", "response": "def choose_template(self, template):\n        '''Choose a template\n        \n        Args:\n            template: String, choose which template you would like.\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        n1 = int(template)/10\n        n2 = int(template)%10\n        self.send('^TS'+'0'+str(n1)+str(n2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef machine_op(self, operation):\n        '''Perform machine operations\n        \n        Args:\n            operations: which operation you would like\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid operation\n        '''\n        operations = {'feed2start': 1,\n                      'feedone': 2,\n                      'cut': 3\n                      }\n        \n        if operation in operations:\n            self.send('^'+'O'+'P'+chr(operations[operation]))\n        else:\n            raise RuntimeError('Invalid operation.')", "response": "Perform machine operations\n        \n        Args:\n            operations: which operation you would like\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid operation"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets print start trigger.", "response": "def print_start_trigger(self, type):\n        '''Set print start trigger.\n        \n        Args:\n            type: The type of trigger you desire.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Invalid type.\n        '''\n        types = {'recieved': 1,\n                 'filled': 2,\n                 'num_recieved': 3}\n        \n        if type in types:\n            self.send('^PT'+chr(types[type]))\n        else:\n            raise RuntimeError('Invalid type.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_start_command(self, command):\n        '''Set print command\n        \n        Args:\n            command: the type of command you desire.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Command too long.\n        '''\n        size = len(command)\n        if size > 20:\n            raise RuntimeError('Command too long')\n        n1 = size/10\n        n2 = size%10\n        self.send('^PS'+chr(n1)+chr(n2)+command)", "response": "Set print command\n        \n        Args:\n            command: the type of command you desire.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Command too long."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef received_char_count(self, count):\n        '''Set recieved char count limit\n        \n        Args:\n            count: the amount of received characters you want to stop at.\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        n1 = count/100\n        n2 = (count-(n1*100))/10\n        n3 = (count-((n1*100)+(n2*10)))\n        self.send('^PC'+chr(n1)+chr(n2)+chr(n3))", "response": "Set recieved char count limit\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select_delim(self, delim):\n        '''Select desired delimeter\n        \n        Args:\n            delim: The delimeter character you want.\n        Returns:\n            None\n        Raises:\n            RuntimeError: Delimeter too long.\n        '''\n        size = len(delim)\n        if size > 20:\n            raise RuntimeError('Delimeter too long')\n        n1 = size/10\n        n2 = size%10\n        self.send('^SS'+chr(n1)+chr(n2))", "response": "Select desired delimeter\n           ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert_into_obj(self, data):\n        '''Insert text into selected object.\n        \n        Args:\n            data: The data you want to insert.\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        if not data:\n            data = ''\n        size = len(data)\n        n1 = size%256\n        n2 = size/256\n            \n        self.send('^DI'+chr(n1)+chr(n2)+data)", "response": "Insert text into selected object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select_and_insert(self, name, data):\n        '''Combines selection and data insertion into one function\n        \n        Args:\n            name: the name of the object you want to insert into\n            data: the data you want to insert\n        Returns:\n            None\n        Raises:\n            None\n        '''\n        self.select_obj(name)\n        self.insert_into_obj(data)", "response": "Combines selection and data insertion into one function\n        \n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect_if_correct_version(db_path, version):\n    db = Database(db_path)\n    if db.has_version() and db.version() == version:\n        return db.connection\n    return None", "response": "Return a sqlite3 database connection if the version in the database s metadata matches the version argument."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating or retrieve a sqlite3 database.", "response": "def _create_cached_db(\n        db_path,\n        tables,\n        version=1):\n    \"\"\"\n    Either create or retrieve sqlite database.\n\n    Parameters\n    --------\n    db_path : str\n        Path to sqlite3 database file\n\n    tables : dict\n        Dictionary mapping table names to datacache.DatabaseTable objects\n\n    version : int, optional\n        Version acceptable as cached data.\n\n    Returns sqlite3 connection\n    \"\"\"\n    require_string(db_path, \"db_path\")\n    require_iterable_of(tables, DatabaseTable)\n    require_integer(version, \"version\")\n\n    # if the database file doesn't already exist and we encounter an error\n    # later, delete the file before raising an exception\n    delete_on_error = not exists(db_path)\n\n    # if the database already exists, contains all the table\n    # names and has the right version, then just return it\n    db = Database(db_path)\n\n    # make sure to delete the database file in case anything goes wrong\n    # to avoid leaving behind an empty DB\n    table_names = [table.name for table in tables]\n    try:\n        if db.has_tables(table_names) and \\\n                db.has_version() and \\\n                db.version() == version:\n            logger.info(\"Found existing table in database %s\", db_path)\n        else:\n            if len(db.table_names()) > 0:\n                logger.info(\n                    \"Dropping tables from database %s: %s\",\n                    db_path,\n                    \", \".join(db.table_names()))\n                db.drop_all_tables()\n            logger.info(\n                \"Creating database %s containing: %s\",\n                db_path,\n                \", \".join(table_names))\n            db.create(tables, version)\n    except:\n        logger.warning(\n            \"Failed to create tables %s in database %s\",\n            table_names,\n            db_path)\n        db.close()\n        if delete_on_error:\n            remove(db_path)\n        raise\n    return db.connection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a list of DatabaseTables from a dictionary of table names to dataframes.", "response": "def build_tables(\n        table_names_to_dataframes,\n        table_names_to_primary_keys={},\n        table_names_to_indices={}):\n    \"\"\"\n    Parameters\n    ----------\n    table_names_to_dataframes : dict\n        Dictionary mapping each table name to a DataFrame\n\n    table_names_to_primary_keys : dict\n        Dictionary mapping each table to its primary key\n\n    table_names_to_indices : dict\n        Dictionary mapping each table to a set of indices\n\n    Returns list of DatabaseTable objects\n    \"\"\"\n    tables = []\n    for table_name, df in table_names_to_dataframes.items():\n        table_indices = table_names_to_indices.get(table_name, [])\n        primary_key = table_names_to_primary_keys.get(table_name)\n        table = DatabaseTable.from_dataframe(\n            name=table_name,\n            df=df,\n            indices=table_indices,\n            primary_key=primary_key)\n        tables.append(table)\n    return tables"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef db_from_dataframes_with_absolute_path(\n        db_path,\n        table_names_to_dataframes,\n        table_names_to_primary_keys={},\n        table_names_to_indices={},\n        overwrite=False,\n        version=1):\n    \"\"\"\n    Create a sqlite3 database from a collection of DataFrame objects\n\n    Parameters\n    ----------\n    db_path : str\n        Path to database file to create\n\n    table_names_to_dataframes : dict\n        Dictionary from table names to DataFrame objects\n\n    table_names_to_primary_keys : dict, optional\n        Name of primary key column for each table\n\n    table_names_to_indices : dict, optional\n        Dictionary from table names to list of column name tuples\n\n    overwrite : bool, optional\n        If the database already exists, overwrite it?\n\n    version : int, optional\n    \"\"\"\n    if overwrite and exists(db_path):\n        remove(db_path)\n\n    tables = build_tables(\n        table_names_to_dataframes,\n        table_names_to_primary_keys,\n        table_names_to_indices)\n    return _create_cached_db(\n        db_path,\n        tables=tables,\n        version=version)", "response": "Create a sqlite3 database from a collection of DataFrame objects with absolute path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef db_from_dataframes(\n        db_filename,\n        dataframes,\n        primary_keys={},\n        indices={},\n        subdir=None,\n        overwrite=False,\n        version=1):\n    \"\"\"\n    Create a sqlite3 database from a collection of DataFrame objects\n\n    Parameters\n    ----------\n    db_filename : str\n        Name of database file to create\n\n    dataframes : dict\n        Dictionary from table names to DataFrame objects\n\n    primary_keys : dict, optional\n        Name of primary key column for each table\n\n    indices : dict, optional\n        Dictionary from table names to list of column name tuples\n\n    subdir : str, optional\n\n    overwrite : bool, optional\n        If the database already exists, overwrite it?\n\n    version : int, optional\n    \"\"\"\n    if not (subdir is None or isinstance(subdir, str)):\n        raise TypeError(\"Expected subdir to be None or str, got %s : %s\" % (\n            subdir, type(subdir)))\n    db_path = build_path(db_filename, subdir)\n    return db_from_dataframes_with_absolute_path(\n        db_path,\n        table_names_to_dataframes=dataframes,\n        table_names_to_primary_keys=primary_keys,\n        table_names_to_indices=indices,\n        overwrite=overwrite,\n        version=version)", "response": "Create a sqlite3 database from a collection of DataFrame objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a dataframe df turn it into a sqlite3 database.", "response": "def db_from_dataframe(\n        db_filename,\n        table_name,\n        df,\n        primary_key=None,\n        subdir=None,\n        overwrite=False,\n        indices=(),\n        version=1):\n    \"\"\"\n    Given a dataframe `df`, turn it into a sqlite3 database.\n    Store values in a table called `table_name`.\n\n    Returns full path to the sqlite database file.\n    \"\"\"\n    return db_from_dataframes(\n        db_filename=db_filename,\n        dataframes={table_name: df},\n        primary_keys={table_name: primary_key},\n        indices={table_name: indices},\n        subdir=subdir,\n        overwrite=overwrite,\n        version=version)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _db_filename_from_dataframe(base_filename, df):\n    db_filename = base_filename + (\"_nrows%d\" % len(df))\n    for column_name in df.columns:\n        column_db_type = db_type(df[column_name].dtype)\n        column_name = column_name.replace(\" \", \"_\")\n        db_filename += \".%s_%s\" % (column_name, column_db_type)\n    return db_filename + \".db\"", "response": "Generate a database filename for a sqlite3 database from a DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_csv_db(\n        table_name,\n        download_url,\n        csv_filename=None,\n        db_filename=None,\n        subdir=None,\n        version=1,\n        **pandas_kwargs):\n    \"\"\"\n    Download a remote CSV file and create a local sqlite3 database\n    from its contents\n    \"\"\"\n    df = fetch_csv_dataframe(\n        download_url=download_url,\n        filename=csv_filename,\n        subdir=subdir,\n        **pandas_kwargs)\n    base_filename = splitext(csv_filename)[0]\n    if db_filename is None:\n        db_filename = _db_filename_from_dataframe(base_filename, df)\n    return db_from_dataframe(\n        db_filename,\n        table_name,\n        df,\n        subdir=subdir,\n        version=version)", "response": "Download a remote CSV file and create a local sqlite3 database from its contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all available quote data for the given ticker security. Returns a dictionary.", "response": "def get_all(self, security):\r\n        \"\"\"\r\n        Get all available quote data for the given ticker security.\r\n        Returns a dictionary.\r\n        \"\"\"\r\n        url = 'http://www.google.com/finance?q=%s' % security\r\n        page = self._request(url)\r\n\r\n        soup = BeautifulSoup(page)\r\n        snapData = soup.find(\"table\", {\"class\": \"snap-data\"})\r\n        if snapData is None:\r\n            raise UfException(Errors.STOCK_SYMBOL_ERROR, \"Can find data for stock %s, security error?\" % security)\r\n        data = {}\r\n        for row in snapData.findAll('tr'):\r\n            keyTd, valTd = row.findAll('td')\r\n            data[keyTd.getText()] = valTd.getText()\r\n\r\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef quotes(self, security, start, end):\r\n        try:\r\n            url = 'http://www.google.com/finance/historical?q=%s&startdate=%s&enddate=%s&output=csv' % (security.symbol, start, end)\r\n            try:\r\n                page = self._request(url)\r\n            except UfException as ufExcep:\r\n                # if symol is not right, will get 400\r\n                if Errors.NETWORK_400_ERROR == ufExcep.getCode:\r\n                    raise UfException(Errors.STOCK_SYMBOL_ERROR, \"Can find data for stock %s, security error?\" % security)\r\n                raise ufExcep\r\n\r\n            days = page.readlines()\r\n            values = [day.split(',') for day in days]\r\n            # sample values:[['Date', 'Open', 'High', 'Low', 'Close', 'Volume'], \\\r\n            #              ['2009-12-31', '112.77', '112.80', '111.39', '111.44', '90637900']...]\r\n            for value in values[1:]:\r\n                date = convertGoogCSVDate(value[0])\r\n                try:\r\n                    yield Quote(date,\r\n                                      value[1].strip(),\r\n                                      value[2].strip(),\r\n                                      value[3].strip(),\r\n                                      value[4].strip(),\r\n                                      value[5].strip(),\r\n                                      None)\r\n                except Exception:\r\n                    LOG.warning(\"Exception when processing %s at date %s for value %s\" % (security, date, value))\r\n\r\n        except BaseException:\r\n            raise UfException(Errors.UNKNOWN_ERROR, \"Unknown Error in GoogleFinance.getHistoricalPrices %s\" % traceback.format_exc())", "response": "Returns a list of Quote objects for the given ticker security."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef financials(self, security):\r\n        try:\r\n            url = 'http://www.google.com/finance?q=%s&fstype=ii' % security\r\n            try:\r\n                page = self._request(url).read()\r\n            except UfException as ufExcep:\r\n                # if symol is not right, will get 400\r\n                if Errors.NETWORK_400_ERROR == ufExcep.getCode:\r\n                    raise UfException(Errors.STOCK_SYMBOL_ERROR, \"Can find data for stock %s, security error?\" % security)\r\n                raise ufExcep\r\n\r\n            bPage = BeautifulSoup(page)\r\n            target = bPage.find(id='incinterimdiv')\r\n\r\n            keyTimeValue = {}\r\n            # ugly do...while\r\n            i = 0\r\n            while True:\r\n                self._parseTarget(target, keyTimeValue)\r\n\r\n                if i < 5:\r\n                    i += 1\r\n                    target = target.nextSibling\r\n                    # ugly beautiful soap...\r\n                    if '\\n' == target:\r\n                        target = target.nextSibling\r\n                else:\r\n                    break\r\n\r\n            return keyTimeValue\r\n\r\n        except BaseException:\r\n            raise UfException(Errors.UNKNOWN_ERROR, \"Unknown Error in GoogleFinance.getHistoricalPrices %s\" % traceback.format_exc())", "response": "Returns a list of all financials for the given stock."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parseTarget(self, target, keyTimeValue):\r\n        ''' parse table for get financial '''\r\n        table = target.table\r\n        timestamps = self._getTimeStamps(table)\r\n\r\n        for tr in table.tbody.findChildren('tr'):\r\n            for i, td in enumerate(tr.findChildren('td')):\r\n                if 0 == i:\r\n                    key = td.getText()\r\n                    if key not in keyTimeValue:\r\n                        keyTimeValue[key] = {}\r\n                else:\r\n                    keyTimeValue[key][timestamps[i - 1]] = self._getValue(td)", "response": "parse table for get financial"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _getTimeStamps(self, table):\r\n        ''' get time stamps '''\r\n        timeStamps = []\r\n        for th in table.thead.tr.contents:\r\n            if '\\n' != th:\r\n                timeStamps.append(th.getText())\r\n\r\n        return timeStamps[1:]", "response": "get time stamps from table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of tuples containing the tick prices for the given ticker security.", "response": "def ticks(self, security, start, end):\r\n        \"\"\"\r\n        Get tick prices for the given ticker security.\r\n        @security: stock security\r\n        @interval: interval in mins(google finance only support query till 1 min)\r\n        @start: start date(YYYYMMDD)\r\n        @end: end date(YYYYMMDD)\r\n\r\n        start and end is disabled since only 15 days data will show\r\n\r\n        @Returns a nested list.\r\n        \"\"\"\r\n        period = 1\r\n        # url = 'http://www.google.com/finance/getprices?q=%s&i=%s&p=%sd&f=d,o,h,l,c,v&ts=%s' % (security, interval, period, start)\r\n        url = 'http://www.google.com/finance/getprices?q=%s&i=61&p=%sd&f=d,o,h,l,c,v' % (security.symbol, period)\r\n        LOG.debug('fetching {0}'.format(url))\r\n        try:\r\n            response = self._request(url)\r\n        except UfException as ufExcep:\r\n            # if symol is not right, will get 400\r\n            if Errors.NETWORK_400_ERROR == ufExcep.getCode:\r\n                raise UfException(Errors.STOCK_SYMBOL_ERROR, \"Can find data for stock %s, security error?\" % security)\r\n            raise ufExcep\r\n\r\n        # use csv reader here\r\n        days = response.text.split('\\n')[7:]  # first 7 line is document\r\n        # sample values:'a1316784600,31.41,31.5,31.4,31.43,150911'\r\n        values = [day.split(',') for day in days if len(day.split(',')) >= 6]\r\n        for value in values:\r\n            yield json.dumps({'date': value[0][1:].strip(),\r\n                'close': value[1].strip(),\r\n                'high': value[2].strip(),\r\n                'low': value[3].strip(),\r\n                'open': value[4].strip(),\r\n                'volume': value[5].strip()})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a binding mediator for a given schema and data.", "response": "def get_binding(self, schema, data):\n        \"\"\" For a given schema, get a binding mediator providing links to the\n        RDF terms matching that schema. \"\"\"\n        schema = self.parent.get_schema(schema)\n        return Binding(schema, self.parent.resolver, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, id, depth=3, schema=None):\n        uri = URIRef(id)\n        if schema is None:\n            for o in self.graph.objects(subject=uri, predicate=RDF.type):\n                schema = self.parent.get_schema(str(o))\n                if schema is not None:\n                    break\n        else:\n            schema = self.parent.get_schema(schema)\n        binding = self.get_binding(schema, None)\n        return self._objectify(uri, binding, depth=depth, path=set())", "response": "Construct a single object based on its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _objectify(self, node, binding, depth, path):\n        if binding.is_object:\n            obj = {'$schema': binding.path}\n            for (s, p, o) in self.graph.triples((node, None, None)):\n                prop = binding.get_property(p)\n                if prop is None or depth <= 1 or o in path:\n                    continue\n                # This is slightly odd but yield purty objects:\n                if depth <= 2 and (prop.is_array or prop.is_object):\n                    continue\n                sub_path = path.union([node])\n                value = self._objectify(o, prop, depth - 1, sub_path)\n                if prop.is_array and prop.name in obj:\n                    obj[prop.name].extend(value)\n                else:\n                    obj[prop.name] = value\n            return obj\n        elif binding.is_array:\n            for item in binding.items:\n                return [self._objectify(node, item, depth, path)]\n        else:\n            return node.toPython()", "response": "Given an RDF node URI and a binding depth and path return an object that represents the information available\n            about this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a text node from given XML tree given an lxml XPath.", "response": "def get_text_node(self, tree, xpath_str):\n        \"\"\"Return a text node from given XML tree given an lxml XPath.\"\"\"\n        try:\n            text = tree.xpath(xpath_str, namespaces=self.namespaces)[0].text\n            return text_type(text) if text else ''\n        except IndexError:  # pragma: nocover\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a subtree given an lxml XPath.", "response": "def get_subtree(self, tree, xpath_str):\n        \"\"\"Return a subtree given an lxml XPath.\"\"\"\n        return tree.xpath(xpath_str, namespaces=self.namespaces)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fundertree2json(self, tree, oai_id):\n        try:\n            tree = self.get_subtree(tree, 'fundingtree')[0]\n        except IndexError:  # pragma: nocover\n            pass\n\n        funder_node = self.get_subtree(tree, 'funder')\n        subfunder_node = self.get_subtree(tree, '//funding_level_0')\n\n        funder_id = self.get_text_node(funder_node[0], './id') \\\n            if funder_node else None\n        subfunder_id = self.get_text_node(subfunder_node[0], './id') \\\n            if subfunder_node else None\n        funder_name = self.get_text_node(funder_node[0], './shortname') \\\n            if funder_node else \"\"\n        subfunder_name = self.get_text_node(subfunder_node[0], './name') \\\n            if subfunder_node else \"\"\n\n        # Try to resolve the subfunder first, on failure try to resolve the\n        # main funder, on failure raise an error.\n        funder_doi_url = None\n        if subfunder_id:\n            funder_doi_url = self.funder_resolver.resolve_by_id(subfunder_id)\n        if not funder_doi_url:\n            if funder_id:\n                funder_doi_url = self.funder_resolver.resolve_by_id(funder_id)\n        if not funder_doi_url:\n            funder_doi_url = self.funder_resolver.resolve_by_oai_id(oai_id)\n        if not funder_doi_url:\n            raise FunderNotFoundError(oai_id, funder_id, subfunder_id)\n\n        funder_doi = FundRefDOIResolver.strip_doi_host(funder_doi_url)\n        if not funder_name:\n            # Grab name from FundRef record.\n            resolver = Resolver(\n                pid_type='frdoi', object_type='rec', getter=Record.get_record)\n            try:\n                dummy_pid, funder_rec = resolver.resolve(funder_doi)\n                funder_name = funder_rec['acronyms'][0]\n            except PersistentIdentifierError:\n                raise OAIRELoadingError(\n                    \"Please ensure that funders have been loaded prior to\"\n                    \"loading grants. Could not resolve funder {0}\".format(\n                        funder_doi))\n\n        return dict(\n            doi=funder_doi,\n            url=funder_doi_url,\n            name=funder_name,\n            program=subfunder_name,\n        )", "response": "Convert OpenAIRE s funder XML to JSON."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef grantxml2json(self, grant_xml):\n        tree = etree.fromstring(grant_xml)\n        # XML harvested from OAI-PMH has a different format/structure\n        if tree.prefix == 'oai':\n            ptree = self.get_subtree(\n                tree, '/oai:record/oai:metadata/oaf:entity/oaf:project')[0]\n            header = self.get_subtree(tree, '/oai:record/oai:header')[0]\n            oai_id = self.get_text_node(header, 'oai:identifier')\n            modified = self.get_text_node(header, 'oai:datestamp')\n        else:\n            ptree = self.get_subtree(\n                tree, '/record/result/metadata/oaf:entity/oaf:project')[0]\n            header = self.get_subtree(tree, '/record/result/header')[0]\n            oai_id = self.get_text_node(header, 'dri:objIdentifier')\n            modified = self.get_text_node(header, 'dri:dateOfTransformation')\n\n        url = self.get_text_node(ptree, 'websiteurl')\n        code = self.get_text_node(ptree, 'code')\n        title = self.get_text_node(ptree, 'title')\n        acronym = self.get_text_node(ptree, 'acronym')\n        startdate = self.get_text_node(ptree, 'startdate')\n        enddate = self.get_text_node(ptree, 'enddate')\n\n        funder = self.fundertree2json(ptree, oai_id)\n\n        internal_id = \"{0}::{1}\".format(funder['doi'], code)\n        eurepo_id = \\\n            \"info:eu-repo/grantAgreement/{funder}/{program}/{code}/\".format(\n                funder=quote_plus(funder['name'].encode('utf8')),\n                program=quote_plus(funder['program'].encode('utf8')),\n                code=quote_plus(code.encode('utf8')), )\n\n        ret_json = {\n            '$schema': self.schema_formatter.schema_url,\n            'internal_id': internal_id,\n            'identifiers': {\n                'oaf': oai_id,\n                'eurepo': eurepo_id,\n                'purl': url if url.startswith(\"http://purl.org/\") else None,\n            },\n            'code': code,\n            'title': title,\n            'acronym': acronym,\n            'startdate': startdate,\n            'enddate': enddate,\n            'funder': {'$ref': funder['url']},\n            'program': funder['program'],\n            'url': url,\n            'remote_modified': modified,\n        }\n        return ret_json", "response": "Convert OpenAIRE grant XML into JSON."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching records from the SQLite database.", "response": "def iter_grants(self, as_json=True):\n        \"\"\"Fetch records from the SQLite database.\"\"\"\n        self._connect()\n        result = self.db_connection.cursor().execute(\n            \"SELECT data, format FROM grants\"\n        )\n        for data, data_format in result:\n            if (not as_json) and data_format == 'json':\n                raise Exception(\"Cannot convert JSON source to XML output.\")\n            elif as_json and data_format == 'xml':\n                data = self.grantxml2json(data)\n            elif as_json and data_format == 'json':\n                data = json.loads(data)\n            yield data\n        self._disconnect()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the Sickle - provided generator object for grants.", "response": "def iter_grants(self, as_json=True):\n        \"\"\"Fetch grants from a remote OAI-PMH endpoint.\n\n        Return the Sickle-provided generator object.\n        \"\"\"\n        records = self.client.ListRecords(metadataPrefix='oaf',\n                                          set=self.setspec)\n        for rec in records:\n            try:\n                grant_out = rec.raw  # rec.raw is XML\n                if as_json:\n                    grant_out = self.grantxml2json(grant_out)\n                yield grant_out\n            except FunderNotFoundError as e:\n                current_app.logger.warning(\"Funder '{0}' not found.\".format(\n                    e.funder_id))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump(self, as_json=True, commit_batch_size=100):\n        connection = sqlite3.connect(self.destination)\n        format_ = 'json' if as_json else 'xml'\n        if not self._db_exists(connection):\n            connection.execute(\n                \"CREATE TABLE grants (data text, format text)\")\n\n        # This will call the RemoteOAIRELoader.iter_grants and fetch\n        # records from remote location.\n        grants_iterator = self.loader.iter_grants(as_json=as_json)\n        for idx, grant_data in enumerate(grants_iterator, 1):\n            if as_json:\n                grant_data = json.dumps(grant_data, indent=2)\n            connection.execute(\n                \"INSERT INTO grants VALUES (?, ?)\", (grant_data, format_))\n\n            # Commit to database every N records\n            if idx % commit_batch_size == 0:\n                connection.commit()\n        connection.commit()\n        connection.close()", "response": "Dump the grant information to a local storage."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_attrib(self, et_node, prefixed_attrib):\n        prefix, attrib = prefixed_attrib.split(':')\n        return et_node.get('{{{0}}}{1}'.format(self.namespaces[prefix],\n                                               attrib))", "response": "Get a prefixed attribute like rdf : resource from ET node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fundrefxml2json(self, node):\n        doi = FundRefDOIResolver.strip_doi_host(self.get_attrib(node,\n                                                'rdf:about'))\n        oaf_id = FundRefDOIResolver().resolve_by_doi(\n            \"http://dx.doi.org/\" + doi)\n        name = node.find('./skosxl:prefLabel/skosxl:Label/skosxl:literalForm',\n                         namespaces=self.namespaces).text\n        # Extract acronyms\n        acronyms = []\n        for n in node.findall('./skosxl:altLabel/skosxl:Label',\n                              namespaces=self.namespaces):\n            usagenode = n.find('./fref:usageFlag', namespaces=self.namespaces)\n            if usagenode is not None:\n                if self.get_attrib(usagenode, 'rdf:resource') == \\\n                        ('http://data.crossref.org/fundingdata'\n                         '/vocabulary/abbrevName'):\n                    label = n.find('./skosxl:literalForm',\n                                   namespaces=self.namespaces)\n                    if label is not None:\n                        acronyms.append(label.text)\n\n        parent_node = node.find('./skos:broader', namespaces=self.namespaces)\n        if parent_node is None:\n            parent = {}\n        else:\n            parent = {\n                \"$ref\": self.get_attrib(parent_node, 'rdf:resource'),\n            }\n        country_elem = node.find('./svf:country', namespaces=self.namespaces)\n        country_url = self.get_attrib(country_elem, 'rdf:resource')\n        country_code = self.cc_resolver.cc_from_url(country_url)\n        type_ = node.find('./svf:fundingBodyType',\n                          namespaces=self.namespaces).text\n        subtype = node.find('./svf:fundingBodySubType',\n                            namespaces=self.namespaces).text\n        country_elem = node.find('./svf:country', namespaces=self.namespaces)\n\n        modified_elem = node.find('./dct:modified', namespaces=self.namespaces)\n        created_elem = node.find('./dct:created', namespaces=self.namespaces)\n\n        json_dict = {\n            '$schema': self.schema_formatter.schema_url,\n            'doi': doi,\n            'identifiers': {\n                'oaf': oaf_id,\n            },\n            'name': name,\n            'acronyms': acronyms,\n            'parent': parent,\n            'country': country_code,\n            'type': type_,\n            'subtype': subtype.lower(),\n            'remote_created': (created_elem.text if created_elem is not None\n                               else None),\n            'remote_modified': (modified_elem.text if modified_elem is not None\n                                else None),\n        }\n        return json_dict", "response": "Convert a FundRef XML node into JSON."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a converted list of Funders as JSON dict.", "response": "def iter_funders(self):\n        \"\"\"Get a converted list of Funders as JSON dict.\"\"\"\n        root = self.doc_root\n        funders = root.findall('./skos:Concept', namespaces=self.namespaces)\n        for funder in funders:\n            funder_json = self.fundrefxml2json(funder)\n            yield funder_json"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_by_oai_id(self, oai_id):\n        if oai_id.startswith('oai:dnet:'):\n            oai_id = oai_id[len('oai:dnet:'):]\n        prefix = oai_id.split(\"::\")[0]\n        suffix = prefix.replace(\"_\", \"\").upper()\n        oaf = \"{0}::{1}\".format(prefix, suffix)\n        return self.data.get(oaf)", "response": "Resolve the funder from the OpenAIRE OAI record id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting a resource path into segments and perform a sanity check.", "response": "def split_resource_path(resource):\n    \"\"\"Split a path into segments and perform a sanity check.  If it detects\n    '..' in the path it will raise a `TemplateNotFound` error.\n    \"\"\"\n    pieces = []\n    for piece in resource.split('/'):\n        if path.sep in piece \\\n           or (path.altsep and path.altsep in piece) or \\\n           piece == path.pardir:\n            raise ResourceNotFound(resource)\n        elif piece and piece != '.':\n            pieces.append(piece)\n    return pieces"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a listing of all known predicates in the schemata.", "response": "def predicates(graph):\n    \"\"\" Return a listing of all known predicates in the registered schemata,\n    including the schema path they associate with, their name and allowed\n    types. \"\"\"\n    seen = set()\n\n    def _traverse(binding):\n        if binding.path in seen:\n            return\n        seen.add(binding.path)\n\n        if binding.is_object:\n            for prop in binding.properties:\n                yield (binding.path, prop.name, tuple(prop.types))\n                for pred in _traverse(prop):\n                    yield pred\n        elif binding.is_array:\n            for item in binding.items:\n                for pred in _traverse(item):\n                    yield pred\n\n    schemas = graph.aliases.values()\n    schemas.extend(graph.resolver.store)\n    for schema_uri in graph.aliases.values():\n        binding = graph.get_binding(schema_uri, None)\n        for pred in _traverse(binding):\n            if pred not in seen:\n                yield pred\n                seen.add(pred)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npower down and delete the item", "response": "def passwordReset1to2(old):\n    \"\"\"\n    Power down and delete the item\n    \"\"\"\n    new = old.upgradeVersion(old.typeName, 1, 2, installedOn=None)\n    for iface in new.store.interfacesFor(new):\n        new.store.powerDown(new, iface)\n    new.deleteFromStore()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upgradeUserInfo1to2(oldUserInfo):\n    newUserInfo = oldUserInfo.upgradeVersion(\n        UserInfo.typeName, 1, 2,\n        realName=oldUserInfo.firstName + u\" \" + oldUserInfo.lastName)\n    return newUserInfo", "response": "Upgrade the user s info item from 1 to 2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ticket1to2(old):\n    if isinstance(old.benefactor, Multifactor):\n        types = list(chain(*[b.powerupNames for b in\n                old.benefactor.benefactors('ascending')]))\n    elif isinstance(old.benefactor, InitializerBenefactor):\n        #oh man what a mess\n        types = list(chain(*[b.powerupNames for b in\n                old.benefactor.realBenefactor.benefactors('ascending')]))\n    newProduct = old.store.findOrCreate(Product,\n                                        types=types)\n\n    if old.issuer is None:\n        issuer = old.store.findOrCreate(TicketBooth)\n    else:\n        issuer = old.issuer\n    t = old.upgradeVersion(Ticket.typeName, 1, 2,\n                           product = newProduct,\n                           issuer = issuer,\n                           booth = old.booth,\n                           avatar = old.avatar,\n                           claimed = old.claimed,\n\n                           email = old.email,\n                           nonce = old.nonce)", "response": "change Ticket to refer to Products and not benefactor factories."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget information about public web - based signup mechanisms.", "response": "def _getPublicSignupInfo(siteStore):\n    \"\"\"\n    Get information about public web-based signup mechanisms.\n\n    @param siteStore: a store with some signups installed on it (as indicated\n    by _SignupTracker instances).\n\n    @return: a generator which yields 2-tuples of (prompt, url) where 'prompt'\n    is unicode briefly describing the signup mechanism (e.g. \"Sign Up\"), and\n    'url' is a (unicode) local URL linking to a page where an anonymous user\n    can access it.\n    \"\"\"\n\n    # Note the underscore; this _should_ be a public API but it is currently an\n    # unfortunate hack; there should be a different powerup interface that\n    # requires prompt and prefixURL attributes rather than _SignupTracker.\n    # -glyph\n\n    for tr in siteStore.query(_SignupTracker):\n        si = tr.signupItem\n        p = getattr(si, 'prompt', None)\n        u = getattr(si, 'prefixURL', None)\n        if p is not None and u is not None:\n            yield (p, u'/'+u)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef locateChild(self, ctx, segments):\n        if len(segments) == 1:\n            attempt = self.attemptByKey(unicode(segments[0]))\n            if attempt is not None:\n                self.attempt = attempt\n                return (self, ())\n        return NotFound", "response": "Locate a child with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the password reset form and returns the URL of the next page.", "response": "def renderHTTP(self, ctx):\n        \"\"\"\n        Handle the password reset form.\n\n        The following exchange describes the process:\n\n            S: Render C{reset}\n            C: POST C{username} or C{email}\n            S: L{handleRequestForUser}, render C{reset-check-email}\n\n            (User follows the emailed reset link)\n\n            S: Render C{reset-step-two}\n            C: POST C{password1}\n            S: L{resetPassword}, render C{reset-done}\n        \"\"\"\n        req = inevow.IRequest(ctx)\n\n        if req.method == 'POST':\n            if req.args.get('username', [''])[0]:\n                user = unicode(usernameFromRequest(req), 'ascii')\n                self.handleRequestForUser(user, URL.fromContext(ctx))\n                self.fragment = self.templateResolver.getDocFactory(\n                    'reset-check-email')\n            elif req.args.get('email', [''])[0]:\n                email = req.args['email'][0].decode('ascii')\n                acct = self.accountByAddress(email)\n                if acct is not None:\n                    username = '@'.join(\n                        userbase.getAccountNames(acct.avatars.open()).next())\n                    self.handleRequestForUser(username, URL.fromContext(ctx))\n                self.fragment = self.templateResolver.getDocFactory('reset-check-email')\n            elif 'password1' in req.args:\n                (password,) = req.args['password1']\n                self.resetPassword(self.attempt, unicode(password))\n                self.fragment = self.templateResolver.getDocFactory('reset-done')\n            else:\n                # Empty submit;  redirect back to self\n                return URL.fromContext(ctx)\n        elif self.attempt:\n            self.fragment = self.templateResolver.getDocFactory('reset-step-two')\n\n        return PublicPage.renderHTTP(self, ctx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a request for a user.", "response": "def handleRequestForUser(self, username, url):\n        \"\"\"\n        User C{username} wants to reset their password.  Create an attempt\n        item, and send them an email if the username is valid\n        \"\"\"\n        attempt = self.newAttemptForUser(username)\n        account = self.accountByAddress(username)\n        if account is None:\n            # do we want to disclose this to the user?\n            return\n        email = self.getExternalEmail(account)\n        if email is not None:\n            self.sendEmail(url, attempt, email)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends an email for the given URL and attempt.", "response": "def sendEmail(self, url, attempt, email, _sendEmail=_sendEmail):\n        \"\"\"\n        Send an email for the given L{_PasswordResetAttempt}.\n\n        @type url: L{URL}\n        @param url: The URL of the password reset page.\n\n        @type attempt: L{_PasswordResetAttempt}\n        @param attempt: An L{Item} representing a particular user's attempt to\n        reset their password.\n\n        @type email: C{str}\n        @param email: The email will be sent to this address.\n        \"\"\"\n\n        host = url.netloc.split(':', 1)[0]\n        from_ = 'reset@' + host\n\n        body = file(sibpath(__file__, 'reset.rfc2822')).read()\n        body %= {'from': from_,\n                 'to': email,\n                 'date': rfc822.formatdate(),\n                 'message-id': smtp.messageid(),\n                 'link': url.child(attempt.key)}\n\n        _sendEmail(from_, email, body)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attemptByKey(self, key):\n\n        return self.store.findUnique(_PasswordResetAttempt,\n                                     _PasswordResetAttempt.key == key,\n                                     default=None)", "response": "Locate the _PasswordResetAttempt that corresponds to the given key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _makeKey(self, usern):\n        return unicode(hashlib.md5(str((usern, time.time(), random.random()))).hexdigest())", "response": "Make a new key for a user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef newAttemptForUser(self, user):\n        # we could query for other attempts by the same\n        # user within some timeframe and raise an exception,\n        # if we wanted\n        return _PasswordResetAttempt(store=self.store,\n                                     username=user,\n                                     timestamp=extime.Time(),\n                                     key=self._makeKey(user))", "response": "Create an L { _PasswordResetAttempt } for the user whose username is user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resetPassword(self, attempt, newPassword):\n\n        self.accountByAddress(attempt.username).password = newPassword\n\n        self.store.query(\n            PersistentSession,\n            PersistentSession.authenticatedAs == str(attempt.username)\n            ).deleteFromStore()\n\n        attempt.deleteFromStore()", "response": "Reset the password of the user who initiated the attempt and delete any persistent sessions that belong to the user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a ticket via email to the supplied email.", "response": "def issueViaEmail(self, issuer, email, product, templateData,\n                      domainName, httpPort=80):\n        \"\"\"\n        Send a ticket via email to the supplied address, which, when claimed, will\n        create an avatar and allow the given product to endow it with\n        things.\n\n        @param issuer: An object, preferably a user, to track who issued this\n        ticket.\n\n        @param email: a str, formatted as an rfc2821 email address\n        (user@domain) -- source routes not allowed.\n\n        @param product: an instance of L{Product}\n\n        @param domainName: a domain name, used as the domain part of the\n        sender's address, and as the web server to generate a link to within\n        the email.\n\n        @param httpPort: a port number for the web server running on domainName\n\n        @param templateData: A string containing an rfc2822-format email\n        message, which will have several python values interpolated into it\n        dictwise:\n\n            %(from)s: To be used for the From: header; will contain an\n             rfc2822-format address.\n\n            %(to)s: the address that we are going to send to.\n\n            %(date)s: an rfc2822-format date.\n\n            %(message-id)s: an rfc2822 message-id\n\n            %(link)s: an HTTP URL that we are generating a link to.\n\n        \"\"\"\n\n        ticket = self.createTicket(issuer,\n                                   unicode(email, 'ascii'),\n                                   product)\n        nonce = ticket.nonce\n\n        signupInfo = {'from': 'signup@'+domainName,\n                      'to': email,\n                      'date': rfc822.formatdate(),\n                      'message-id': smtp.messageid(),\n                      'link': self.ticketLink(domainName, httpPort, nonce)}\n\n        msg = templateData % signupInfo\n\n        return ticket, _sendEmail(signupInfo['from'], email, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef usernameAvailable(self, username, domain):\n        if len(username) < 2:\n            return [False, u\"Username too short\"]\n        for char in u\"[ ,:;<>@()!\\\"'%&\\\\|\\t\\b\":\n            if char in username:\n                return [False,\n                        u\"Username contains invalid character: '%s'\" % char]\n\n        # The localpart is acceptable if it can be parsed as the local part\n        # of an RFC 2821 address.\n        try:\n            parseAddress(\"<%s@example.com>\" % (username,))\n        except ArgumentError:\n            return [False, u\"Username fails to parse\"]\n\n        # The domain is acceptable if it is one which we actually host.\n        if domain not in self.getAvailableDomains():\n            return [False, u\"Domain not allowed\"]\n\n        query = self.store.query(userbase.LoginMethod,\n                                 AND(userbase.LoginMethod.localpart == username,\n                                     userbase.LoginMethod.domain == domain))\n        return [not bool(query.count()), u\"Username already taken\"]", "response": "Check to see if a username is available for the user to select."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new user in the user store and stores some associated metadata in the user s store and the user s account and login methods.", "response": "def createUser(self, realName, username, domain, password, emailAddress):\n        \"\"\"\n        Create a user, storing some associated metadata in the user's store,\n        i.e. their first and last names (as a L{UserInfo} item), and a\n        L{axiom.userbase.LoginMethod} allowing them to login with their email\n        address.\n\n        @param realName: the real name of the user.\n        @type realName: C{unicode}\n\n        @param username: the user's username.  they will be able to login with\n            this.\n        @type username: C{unicode}\n\n        @param domain: the local domain - used internally to turn C{username}\n            into a localpart@domain style string .\n        @type domain: C{unicode}\n\n        @param password: the password to be used for the user's account.\n        @type password: C{unicode}\n\n        @param emailAddress: the user's external email address.  they will be\n            able to login with this also.\n        @type emailAddress: C{unicode}\n\n        @rtype: C{NoneType}\n        \"\"\"\n        # XXX This method should be called in a transaction, it shouldn't\n        # start a transaction itself.\n        def _():\n            loginsystem = self.store.findUnique(userbase.LoginSystem)\n\n            # Create an account with the credentials they specified,\n            # making it internal since it belongs to us.\n            acct = loginsystem.addAccount(username, domain, password,\n                                          verified=True, internal=True)\n\n            # Create an external login method associated with the email\n            # address they supplied, as well.  This creates an association\n            # between that external address and their account object,\n            # allowing password reset emails to be sent and letting them log\n            # in to this account using that address as a username.\n            emailPart, emailDomain = emailAddress.split(\"@\")\n            acct.addLoginMethod(emailPart, emailDomain, protocol=u\"email\",\n                                verified=False, internal=False)\n            substore = IBeneficiary(acct)\n            # Record some of that signup information in case application\n            # objects are interested in it.\n            UserInfo(store=substore, realName=realName)\n            self.product.installProductOn(substore)\n        self.store.transact(_)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createSignup(self, creator, signupClass, signupConf,\n                     product, emailTemplate, prompt):\n        \"\"\"\n        Create a new signup facility in the site store's database.\n\n        @param creator: a unicode string describing the creator of the new\n        signup mechanism, for auditing purposes.\n\n        @param signupClass: the item type of the signup mechanism to create.\n\n        @param signupConf: a dictionary of keyword arguments for\n        L{signupClass}'s constructor.\n\n        @param product: A Product instance, describing the powerups to be\n        installed with this signup.\n\n        @param emailTemplate: a unicode string which contains some text that\n        will be sent in confirmation emails generated by this signup mechanism\n        (if any)\n\n        @param prompt: a short unicode string describing this signup mechanism,\n        as distinct from others.  For example: \"Student Sign Up\", or \"Faculty\n        Sign Up\"\n\n        @return: a newly-created, database-resident instance of signupClass.\n        \"\"\"\n\n        siteStore = self.store.parent\n\n        booth = siteStore.findOrCreate(TicketBooth, lambda booth: installOn(booth, siteStore))\n        signupItem = signupClass(\n            store=siteStore,\n            booth=booth,\n            product=product,\n            emailTemplate=emailTemplate,\n            prompt=prompt,\n            **signupConf)\n        siteStore.powerUp(signupItem)\n        _SignupTracker(store=siteStore,\n                       signupItem=signupItem,\n                       createdOn=extime.Time(),\n                       createdBy=creator)\n\n        return signupItem", "response": "Create a new signup facility in the site store."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a LiveForm with radio buttons for each Product in the store.", "response": "def makeProductPicker(self):\n        \"\"\"\n        Make a LiveForm with radio buttons for each Product in the store.\n        \"\"\"\n        productPicker = liveform.LiveForm(\n            self.coerceProduct,\n            [liveform.Parameter(\n              str(id(product)),\n              liveform.FORM_INPUT,\n              liveform.LiveForm(\n              lambda selectedProduct, product=product: selectedProduct and product,\n              [liveform.Parameter(\n                'selectedProduct',\n                liveform.RADIO_INPUT,\n                bool,\n                repr(product))]\n              ))\n              for product\n              in self.original.store.parent.query(Product)],\n            u\"Product to Install\")\n        return productPicker"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _deleteTrackers(self, trackers):\n\n        for tracker in trackers:\n            if tracker.store is None:\n                # we're not updating the list of live signups client side, so\n                # we might get a signup that has already been deleted\n                continue\n\n            sig = tracker.signupItem\n\n            # XXX the only reason we're doing this here is that we're afraid to\n            # add a whenDeleted=CASCADE to powerups because it's inefficient,\n            # however, this is arguably the archetypical use of\n            # whenDeleted=CASCADE.  Soon we need to figure out a real solution\n            # (but I have no idea what it is). -glyph\n\n            for iface in sig.store.interfacesFor(sig):\n                sig.store.powerDown(sig, iface)\n            tracker.deleteFromStore()\n            sig.deleteFromStore()", "response": "Delete the given signup trackers and their associated signup resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch(self):\n        api = self.doapi_manager\n        return api._image(api.request(self.url)[\"image\"])", "response": "Fetch & return a new Image object representing the image s current\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the image with the given name.", "response": "def update_image(self, name):\n        # The `_image` is to avoid conflicts with MutableMapping.update.\n        \"\"\"\n        Update (i.e., rename) the image\n\n        :param str name: the new name for the image\n        :return: an updated `Image` object\n        :rtype: Image\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        api = self.doapi_manager\n        return api._image(api.request(self.url, method='PUT',\n                                               data={\"name\": name})[\"image\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npicks a random name form a specified list of name parts", "response": "def generate(self, nameformat=None, capitalize=None, formatters=None, **kwargs):\n        '''Pick a random name form a specified list of name parts'''\n\n        nameformat = nameformat or self.nameformat\n        capitalize = capitalize or self.capitalize\n        formatters = formatters or {}\n\n        lines = self._get_lines(kwargs)\n        names = dict((k, v['name']) for k, v in list(lines.items()))\n\n        if capitalize:\n            names = dict((k, n.capitalize()) for k, n in list(names.items()))\n\n        merged_formatters = dict()\n\n        try:\n            merged_formatters = dict(\n                (k, self.formatters.get(k, []) + formatters.get(k, [])) for k in set(list(self.formatters.keys()) + list(formatters.keys()))\n            )\n        except AttributeError:\n            raise TypeError(\"keyword argument 'formatters' for Censusname.generate() must be a dict\")\n\n        if merged_formatters:\n            for key, functions in list(merged_formatters.items()):\n                # 'surname', [func_a, func_b]\n                for func in functions:\n                    # names['surname'] = func_a(name['surname'])\n                    names[key] = func(names[key])\n\n        return nameformat.format(**names)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pick_frequency_line(self, filename, frequency, cumulativefield='cumulative_frequency'):\n        '''Given a numeric frequency, pick a line from a csv with a cumulative frequency field'''\n        if resource_exists('censusname', filename):\n            with closing(resource_stream('censusname', filename)) as b:\n                g = codecs.iterdecode(b, 'ascii')\n                return self._pick_frequency_line(g, frequency, cumulativefield)\n        else:\n            with open(filename, encoding='ascii') as g:\n                return self._pick_frequency_line(g, frequency, cumulativefield)", "response": "Given a numeric frequency pick a line from a csv with a cumulative frequency field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dfl_local_dir():\n    project_name = git_repo()\n    if not project_name and sys.argv:\n        project_name = sys.argv[0]\n    if not project_name:\n        project_name = \"unknown\"\n    dirpath = os.path.join(DFL_DIR_PARENT, project_name)\n    return os.path.expanduser(dirpath)", "response": "Infers a default local directory which is DFL_DIR_PARENT where the project name is guessed according to the following rules."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the git repository root if the cwd is in a repo else None", "response": "def git_repo():\n    \"\"\"\n    Returns the git repository root if the cwd is in a repo, else None\n    \"\"\"\n    try:\n        reldir = subprocess.check_output(\n            [\"git\", \"rev-parse\", \"--git-dir\"])\n        reldir = reldir.decode(\"utf-8\")\n        return os.path.basename(os.path.dirname(os.path.abspath(reldir)))\n    except subprocess.CalledProcessError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the current git hash or unknown", "response": "def git_hash():\n    \"\"\"returns the current git hash or unknown if not in git repo\"\"\"\n    if git_repo() is None:\n        return \"unknown\"\n    git_hash = subprocess.check_output(\n        [\"git\", \"rev-parse\", \"HEAD\"])\n    # git_hash is a byte string; we want a string.\n    git_hash = git_hash.decode(\"utf-8\")\n    # git_hash also comes with an extra \\n at the end, which we remove.\n    git_hash = git_hash.strip()\n    return git_hash"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a pretty summary of the commit or unkown", "response": "def git_pretty():\n    \"\"\"returns a pretty summary of the commit or unkown if not in git repo\"\"\"\n    if git_repo() is None:\n        return \"unknown\"\n    pretty = subprocess.check_output(\n        [\"git\", \"log\", \"--pretty=format:%h %s\", \"-n\", \"1\"])\n    pretty = pretty.decode(\"utf-8\")\n    pretty = pretty.strip()\n    return pretty"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreconstructs the invocation for this python program", "response": "def invocation():\n    \"\"\"reconstructs the invocation for this python program\"\"\"\n    cmdargs = [sys.executable] + sys.argv[:]\n    invocation = \" \".join(shlex.quote(s) for s in cmdargs)\n    return invocation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting cell to the log", "response": "def writeCell(self, row, col, value):\r\n        ''' write cell'''\r\n        self.__operation.writeCell(row, col, value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening a sheet with the given name", "response": "def openSheet(self, name):\r\n        ''' set a sheet to write '''\r\n        if name not in self.__sheetNameDict:\r\n            sheet = self.__workbook.add_sheet(name)\r\n            self.__sheetNameDict[name] = sheet\r\n\r\n        self.__sheet = self.__sheetNameDict[name]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __getSheet(self, name):\r\n        ''' get a sheet by name '''\r\n        if not self.sheetExsit(name):\r\n            raise UfException(Errors.SHEET_NAME_INVALID, \"Can't find a sheet named %s\" % name)\r\n\r\n        return self.__sheetNameDict[name]", "response": "get a sheet by name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef writeRow(self, row, values):\r\n        '''\r\n        write a row\r\n        Not sure whether xlwt support write the same cell multiple times\r\n        '''\r\n        if self.__sheet is None:\r\n            self.openSheet(super(ExcelWrite, self).DEFAULT_SHEET)\r\n\r\n        for index, value in enumerate(values):\r\n            self.__sheet.write(row, index, value)", "response": "Write a row with the given values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting local files downloaded from given URL", "response": "def delete_url(self, url):\n        \"\"\"\n        Delete local files downloaded from given URL\n        \"\"\"\n        # file may exist locally in compressed and decompressed states\n        # delete both\n        for decompress in [False, True]:\n            key = (url, decompress)\n            if key in self._local_paths:\n                path = self._local_paths[key]\n                remove(path)\n                del self._local_paths[key]\n\n            # possible that file was downloaded via the download module without\n            # using the Cache object, this wouldn't end up in the local_paths\n            # but should still be deleted\n            path = self.local_path(\n                url, decompress=decompress, download=False)\n\n            if exists(path):\n                remove(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if a local file corresponding to these arguments exists.", "response": "def exists(self, url, filename=None, decompress=False):\n        \"\"\"\n        Return True if a local file corresponding to these arguments\n        exists.\n        \"\"\"\n        return download.file_exists(\n            url,\n            filename=filename,\n            decompress=decompress,\n            subdir=self.subdir)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(\n            self,\n            url,\n            filename=None,\n            decompress=False,\n            force=False,\n            timeout=None,\n            use_wget_if_available=True):\n        \"\"\"\n        Return the local path to the downloaded copy of a given URL.\n        Don't download the file again if it's already present,\n        unless `force` is True.\n        \"\"\"\n        key = (url, decompress)\n        if not force and key in self._local_paths:\n            path = self._local_paths[key]\n            if exists(path):\n                return path\n            else:\n                del self._local_paths[key]\n        path = download.fetch_file(\n            url,\n            filename=filename,\n            decompress=decompress,\n            subdir=self.subdir,\n            force=force,\n            timeout=timeout,\n            use_wget_if_available=use_wget_if_available)\n\n        self._local_paths[key] = path\n        return path", "response": "Download a file from a given URL and return the local path to that file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a local filename for the given URL and filename.", "response": "def local_filename(\n            self,\n            url=None,\n            filename=None,\n            decompress=False):\n        \"\"\"\n        What local filename will we use within the cache directory\n        for the given URL/filename/decompress options.\n        \"\"\"\n        return common.build_local_filename(url, filename, decompress)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the full local path of a given file.", "response": "def local_path(self, url, filename=None, decompress=False, download=False):\n        \"\"\"\n        What will the full local path be if we download the given file?\n        \"\"\"\n        if download:\n            return self.fetch(url=url, filename=filename, decompress=decompress)\n        else:\n            filename = self.local_filename(url, filename, decompress)\n            return join(self.cache_directory_path, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect_redis(redis_client, name=None, transaction=False):\n    return ConnectionManager.connect_redis(\n        redis_client=redis_client, name=name, transaction=transaction)", "response": "Connect a redis - py instance to a unique identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(cls, pipeline_method, name=None):\n        new_pool = pipeline_method().connection_pool\n        try:\n            if cls.get(name).connection_pool != new_pool:\n                raise AlreadyConnected(\"can't change connection for %s\" % name)\n        except InvalidPipeline:\n            pass\n\n        cls.connections[name] = pipeline_method", "response": "Bind a callable method to a name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to a Redis instance.", "response": "def connect_redis(cls, redis_client, name=None, transaction=False):\n        \"\"\"\n        Store the redis connection in our connector instance.\n\n        Do this during your application bootstrapping.\n\n        We call the pipeline method of the redis client.\n\n        The ``redis_client`` can be either a redis or rediscluster client.\n        We use the interface, not the actual class.\n\n        That means we can handle either one identically.\n\n        It doesn't matter if you pass in `Redis` or `StrictRedis`.\n        the interface for direct redis commands will behave indentically.\n        Keyspaces will work with either, but it presents the same interface\n        that the Redis class does, not StrictRedis.\n\n        The transaction flag is a boolean value we hold on to and\n        pass to the invocation of something equivalent to:\n\n        .. code-block:: python\n\n            redis_client.pipeline(transaction=transation)\n\n        Unlike redis-py, this flag defaults to False.\n        You can configure it to always use the MULTI/EXEC flags,\n        but I don't see much point.\n\n        If you need transactional support I recommend using a LUA script.\n\n        **RedPipe** is about improving network round-trip efficiency.\n\n        :param redis_client: redis.StrictRedis() or redis.Redis()\n        :param name: identifier for the connection, optional\n        :param transaction: bool, defaults to False\n        :return: None\n        \"\"\"\n        connection_pool = redis_client.connection_pool\n\n        if connection_pool.connection_kwargs.get('decode_responses', False):\n            raise InvalidPipeline('decode_responses set to True')\n\n        def pipeline_method():\n            \"\"\"\n            A closure wrapping the pipeline.\n\n            :return: pipeline object\n            \"\"\"\n            return redis_client.pipeline(transaction=transaction)\n\n        # set up the connection.\n        cls.connect(pipeline_method=pipeline_method, name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remoteIndexer1to2(oldIndexer):\n    newIndexer = oldIndexer.upgradeVersion(\n        oldIndexer.typeName, 1, 2,\n        indexCount=oldIndexer.indexCount,\n        installedOn=oldIndexer.installedOn,\n        indexDirectory=oldIndexer.indexDirectory)\n\n    listeners = newIndexer.store.query(\n        batch._ReliableListener,\n        batch._ReliableListener.listener == newIndexer)\n\n    for listener in listeners:\n        _IndexerInputSource(\n            store=newIndexer.store,\n            indexer=newIndexer,\n            source=listener.processor)\n\n    return newIndexer", "response": "This function creates a new RemoteListener for the given version 1 to 2."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying attributes reset index due because information about deleted documents has been lost power up for IFulltextIndexer so other code can find this item.", "response": "def pyLuceneIndexer4to5(old):\n    \"\"\"\n    Copy attributes, reset index due because information about deleted\n    documents has been lost, and power up for IFulltextIndexer so other code\n    can find this item.\n    \"\"\"\n    new = old.upgradeVersion(PyLuceneIndexer.typeName, 4, 5,\n                             indexCount=old.indexCount,\n                             installedOn=old.installedOn,\n                             indexDirectory=old.indexDirectory)\n    new.reset()\n    new.store.powerUp(new, ixmantissa.IFulltextIndexer)\n    return new"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the given L { IBatchProcessor } as a source of input for this indexer.", "response": "def addSource(self, itemSource):\n        \"\"\"\n        Add the given L{IBatchProcessor} as a source of input for this indexer.\n        \"\"\"\n        _IndexerInputSource(store=self.store, indexer=self, source=itemSource)\n        itemSource.addReliableListener(self, style=iaxiom.REMOTE)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset(self):\n        self.indexCount = 0\n        indexDir = self.store.newDirectory(self.indexDirectory)\n        if indexDir.exists():\n            indexDir.remove()\n        for src in self.getSources():\n            src.removeReliableListener(self)\n            src.addReliableListener(self, style=iaxiom.REMOTE)", "response": "Reset the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _flush(self):\n        remove = self.store.query(_RemoveDocument)\n        documentIdentifiers = list(remove.getColumn(\"documentIdentifier\"))\n        if VERBOSE:\n            log.msg(\"%s/%d removing %r\" % (self.store, self.storeID, documentIdentifiers))\n        reader = self.openReadIndex()\n        map(reader.remove, documentIdentifiers)\n        reader.close()\n        remove.deleteFromStore()", "response": "Deal with pending result - affecting things."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting the index to its initial state.", "response": "def reset(self):\n        \"\"\"\n        In addition to the behavior of the superclass, delete any dangling\n        lockfiles which may prevent this index from being opened.  With the\n        tested version of PyLucene (something pre-2.0), this appears to not\n        actually be necessary: deleting the entire index directory but\n        leaving the lockfile in place seems to still allow the index to be\n        recreated (perhaps because when the directory does not exist, we\n        pass True as the create flag when opening the FSDirectory, I am\n        uncertain).  Nevertheless, do this anyway for now.\n        \"\"\"\n        RemoteIndexer.reset(self)\n        if hasattr(self, '_lockfile'):\n            os.remove(self._lockfile)\n            del self._lockfile"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a document to the database.", "response": "def add(self, document):\n        \"\"\"\n        Add a document to the database.\n        \"\"\"\n        docid = int(document.uniqueIdentifier())\n        text = u' '.join(document.textParts())\n\n        self.store.executeSQL(self.addSQL, (docid, text))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a document from the database.", "response": "def remove(self, docid):\n        \"\"\"\n        Remove a document from the database.\n        \"\"\"\n        docid = int(docid)\n        self.store.executeSQL(self.removeSQL, (docid,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches the database for the given term.", "response": "def search(self, term, keywords=None, sortAscending=True):\n        \"\"\"\n        Search the database.\n        \"\"\"\n        if sortAscending:\n            direction = 'ASC'\n        else:\n            direction = 'DESC'\n\n        return [_SQLiteResultWrapper(r[0]) for r in\n                self.store.querySQL(self.searchSQL % (direction,), (term,))]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getStore(self):\n        storeDir = self.store.newDirectory(self.indexDirectory)\n        if not storeDir.exists():\n            store = Store(storeDir)\n            self._initStore(store)\n            return store\n        else:\n            return Store(storeDir)", "response": "Get the Store used for FTS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing track s file handler for track package logger.", "response": "def init(track_log_handler):\n    \"\"\"\n    (Re)initialize track's file handler for track package logger.\n\n    Adds a stdout-printing handler automatically.\n    \"\"\"\n\n    logger = logging.getLogger(__package__)\n\n    # TODO (just document prominently)\n    # assume only one trial can run at once right now\n    # multi-concurrent-trial support will require complex filter logic\n    # based on the currently-running trial (maybe we shouldn't allow multiple\n    # trials on different python threads, that's dumb)\n    to_rm = [h for h in logger.handlers if isinstance(h, TrackLogHandler)]\n    for h in to_rm:\n        logger.removeHandler(h)\n\n    if not any(isinstance(h, StdoutHandler) for h in logger.handlers):\n        handler = StdoutHandler()\n        handler.setFormatter(_FORMATTER)\n        logger.addHandler(handler)\n\n    track_log_handler.setFormatter(_FORMATTER)\n    logger.addHandler(track_log_handler)\n\n    logger.propagate = False\n    logger.setLevel(logging.DEBUG)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndebugs logs s. format", "response": "def debug(s, *args):\n    \"\"\"debug(s, x1, ..., xn) logs s.format(x1, ..., xn).\"\"\"\n    # Get the path name and line number of the function which called us.\n    previous_frame = inspect.currentframe().f_back\n    try:\n        pathname, lineno, _, _, _ = inspect.getframeinfo(previous_frame)\n        # if path is in cwd, simplify it\n        cwd = os.path.abspath(os.getcwd())\n        pathname = os.path.abspath(pathname)\n        if os.path.commonprefix([cwd, pathname]) == cwd:\n            pathname = os.path.relpath(pathname, cwd)\n    except Exception:  # pylint: disable=broad-except\n        pathname = '<UNKNOWN-FILE>.py'\n        lineno = 0\n    if _FORMATTER: # log could have not been initialized.\n        _FORMATTER.pathname = pathname\n        _FORMATTER.lineno = lineno\n    logger = logging.getLogger(__package__)\n    logger.debug(s.format(*args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps the value to string.", "response": "def dump(self, value):\n        \"\"\"Dumps the value to string.\n\n        :returns: Returns the stringified version of the value.\n        :raises: TypeError, ValueError\n\n        \"\"\"\n        value = self.__convert__(value)\n        self.__validate__(value)\n        return self.__serialize__(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random integer in the available range.", "response": "def simulate(self):\n        \"\"\"Generates a random integer in the available range.\"\"\"\n        min_ = (-sys.maxsize - 1) if self._min is None else self._min\n        max_ = sys.maxsize if self._max is None else self._max\n        return random.randint(min_, max_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef simulate(self):\n        min_ = 1 if self._min is None else self._min\n        max_ = 10 if self._max is None else self._max\n        n = min_ if (min_ >= max_) else random.randint(min_, max_)\n        chars = string.ascii_letters + string.digits\n        return ''.join(random.choice(chars) for x in range(n))", "response": "Simulate randomly constructs a string with a length between min and max."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsimulate a stream of types.", "response": "def simulate(self):\n        \"\"\"Simulates a stream of types.\"\"\"\n        # Simulates zero to 10 types\n        return [t.simulate() for t in itertools.islice(self, random.choice(range(10)))]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __findRange(self, excelLib, start, end):\r\n        ''' return low and high as excel range '''\r\n        inc = 1\r\n        low = 0\r\n        high = 0\r\n        dates = excelLib.readCol(0, 1)\r\n\r\n        for index, date in enumerate(dates):\r\n            if int(start) <= int(date):\r\n                low = index + inc\r\n                break\r\n\r\n        if low:\r\n            for index, date in reversed(list(enumerate(dates))):\r\n                if int(date) <= int(end):\r\n                    high = index + inc\r\n                    break\r\n\r\n        return low, high", "response": "find the low and high as excel range"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread data from the target file", "response": "def __readData(self, targetPath, start, end):\r\n        ''' read data '''\r\n        ret = []\r\n        if not path.exists(targetPath):\r\n            LOG.error(\"Target file doesn't exist: %s\" % path.abspath(targetPath) )\r\n            return ret\r\n\r\n        with ExcelLib(fileName = targetPath, mode = ExcelLib.READ_MODE) as excel:\r\n            low, high = self.__findRange(excel, start, end)\r\n\r\n            for index in range(low, high + 1):\r\n                ret.append(excel.readRow(index))\r\n\r\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites data to a file", "response": "def __writeData(self, targetPath, fields, rows):\r\n        ''' write data '''\r\n        if path.exists(targetPath):\r\n            LOG.error(\"Target file exists: %s\" % path.abspath(targetPath) )\r\n            raise UfException(Errors.FILE_EXIST, \"can't write to a existing file\") #because xlwt doesn't support it\r\n\r\n        with ExcelLib(fileName = targetPath, mode = ExcelLib.WRITE_MODE) as excel:\r\n            excel.writeRow(0, fields)\r\n            for index, row in enumerate(rows):\r\n                excel.writeRow(index+1, row)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading quotes from the file", "response": "def readQuotes(self, start, end):\r\n        ''' read quotes '''\r\n        quotes = self.__readData(self.targetPath(ExcelDAM.QUOTE), start, end)\r\n        return [Quote(*quote) for quote in quotes]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef readTicks(self, start, end):\r\n        ''' read ticks '''\r\n        ticks =  self.__readData(self.targetPath(ExcelDAM.TICK), start, end)\r\n        return [Tick(*tick) for tick in ticks]", "response": "read ticks from the file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite ticks to file", "response": "def writeTicks(self, ticks):\r\n        ''' read quotes '''\r\n        self.__writeData(self.targetPath(ExcelDAM.TICK),\r\n                         TICK_FIELDS,\r\n                         [[getattr(tick, field) for field in TICK_FIELDS] for tick in ticks])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrecording multiple values at once.", "response": "def snap(self, *args):\n        \"\"\"Records multiple values at once.\n\n        It takes two to six arguments specifying which values should be\n        recorded together. Valid arguments are 'x', 'y', 'r', 'theta',\n        'aux1', 'aux2', 'aux3', 'aux4', 'frequency', 'trace1', 'trace2',\n        'trace3' and 'trace4'.\n\n        snap is faster since it avoids communication overhead. 'x' and 'y'\n        are recorded together, as well as 'r' and 'theta'. Between these\n        pairs, there is a delay of approximately 10 us. 'aux1', 'aux2', 'aux3'\n        and 'aux4' have am uncertainty of up to 32 us. It takes at least 40 ms\n        or a period to calculate the frequency.\n\n        E.g.::\n\n            lockin.snap('x', 'theta', 'trace3')\n\n        \"\"\"\n        length = len(args)\n        if not 2 <= length <= 6:\n            msg = 'snap takes 2 to 6 arguments, {0} given.'.format(length)\n            raise TypeError(msg)\n        # The program data type.\n        param = Enum(\n            'x', 'y', 'r', 'theta', 'aux1', 'aux2', 'aux3', 'aux4',\n            'frequency', 'trace1', 'trace2', 'trace3', 'trace4'\n        )\n        # construct command,\n        cmd = 'SNAP?', (Float,) * length, (param, ) * length\n        return self._ask(cmd, *args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the current state of the current active display to the file specified by ~SR850. filename.", "response": "def save(self, mode='all'):\n        \"\"\"Saves to the file specified by :attr:`~SR850.filename`.\n\n        :param mode: Defines what to save.\n\n            =======  ================================================\n            Value    Description\n            =======  ================================================\n            'all'    Saves the active display's data trace, the trace\n                     definition and the instrument state.\n            'data'   Saves the active display's data trace.\n            'state'  Saves the instrument state.\n            =======  ================================================\n\n        \"\"\"\n        if mode == 'all':\n            self._write('SDAT')\n        elif mode == 'data':\n            self._write('SASC')\n        elif mode=='state':\n            self._write('SSET')\n        else:\n            raise ValueError('Invalid save mode.')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrecalling the active display.", "response": "def recall(self, mode='all'):\n        \"\"\"Recalls from the file specified by :attr:`~SR850.filename`.\n\n        :param mode: Specifies the recall mode.\n\n            =======  ==================================================\n            Value    Description\n            =======  ==================================================\n            'all'    Recalls the active display's data trace, the trace\n                     definition and the instrument state.\n            'state'  Recalls the instrument state.\n            =======  ==================================================\n\n        \"\"\"\n        if mode == 'all':\n            self._write('RDAT')\n        elif mode == 'state':\n            self._write('RSET')\n        else:\n            raise ValueError('Invalid recall mode.')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfit a function to the active display s data trace within the specified time window.", "response": "def fit(self, range, function=None):\n        \"\"\"Fits a function to the active display's data trace within a\n        specified range of the time window.\n\n        E.g.::\n\n            # Fit's a gaussian to the first 30% of the time window.\n            lockin.fit(range=(0, 30), function='gauss')\n\n        :param start: The left limit of the time window in percent.\n        :param stop: The right limit of the time window in percent.\n        :param function: The function used to fit the data, either 'line',\n            'exp', 'gauss' or None, the default. The configured fit function is\n            left unchanged if function is None.\n\n        .. note::\n\n            Fitting takes some time. Check the status byte to see when the\n            operation is done. A running scan will be paused until the\n            fitting is complete.\n\n        .. warning::\n\n            The SR850 will generate an error if the active display trace is not\n            stored when the fit command is executed.\n\n        \"\"\"\n        if function is not None:\n            self.fit_function = function\n        cmd = 'FITT', Integer(min=0, max=100), Integer(min=0, max=100)\n        self._write(cmd, start, stop)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate_statistics(self, start, stop):\n        cmd = 'STAT', Integer, Integer\n        self._write(cmd, start, stop)", "response": "Starts the statistics calculation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate(self, operation=None, trace=None, constant=None, type=None):\n        if operation is not None:\n            self.math_operation = operation\n        if trace is not None:\n            self.math_trace_argument = trace\n            type = 'trace'\n        elif constant is not None:\n            self.math_constant = constant\n            type = 'constant'\n        if type is not None:\n            self.math_argument_type = type\n        self._write('CALC')", "response": "Starts the calculation of the lockin and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bin(self):\n        bin = self._query(('MBIN?', Integer, Integer), self.idx)\n        return None if bin == -1 else bin", "response": "Returns the bin index of this mark."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query(self, sql, **kwargs):\n        if 'format' not in kwargs or kwargs['format'] == 'dataframe':\n            resp = self.get('/v1/query', data={'q': sql, 'format': 'table'}).json()\n            if len(resp) == 0:\n                return pd.DataFrame()\n            else:\n                return pd.DataFrame.from_records(resp[1:], columns=resp[0],\n                                                 index=\"_rowName\")\n        kwargs['q'] = sql\n        return self.get('/v1/query', **kwargs).json()", "response": "Shortcut for GET / v1 / query except with argument format = dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nput and track progress.", "response": "def put_and_track(self, url, payload, refresh_rate_sec=1):\n        \"\"\"\n        Put and track progress, displaying progress bars.\n\n        May display the wrong progress if 2 things post/put on the same\n        procedure name at the same time.\n        \"\"\"\n        if not url.startswith('/v1/procedures'):\n            raise Exception(\"The only supported route is /v1/procedures\")\n        parts = url.split('/')\n        len_parts = len(parts)\n        if len_parts not in [4, 6]:\n            raise Exception(\n                \"You must either PUT a procedure or a procedure run\")\n\n        proc_id = parts[3]\n        run_id = None\n\n        if len_parts == 4:\n                if 'params' not in payload:\n                    payload['params'] = {}\n                payload['params']['runOnCreation'] = True\n        elif len_parts == 6:\n            run_id = parts[-1]\n\n        pm = ProgressMonitor(self, refresh_rate_sec, proc_id, run_id,\n                             self.notebook)\n        t = threading.Thread(target=pm.monitor_progress)\n        t.start()\n\n        try:\n            return self.put(url, payload)\n        except Exception as e:\n            print(e)\n        finally:\n            pass\n            pm.event.set()\n            t.join()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npost and track progress on a given procedure.", "response": "def post_and_track(self, url, payload, refresh_rate_sec=1):\n        \"\"\"\n        Post and track progress, displaying progress bars.\n\n        May display the wrong progress if 2 things post/put on the same\n        procedure name at the same time.\n        \"\"\"\n        if not url.startswith('/v1/procedures'):\n            raise Exception(\"The only supported route is /v1/procedures\")\n        if url.endswith('/runs'):\n            raise Exception(\n                \"Posting and tracking run is unsupported at the moment\")\n        if len(url.split('/')) != 3:\n            raise Exception(\"You must POST a procedure\")\n\n        if 'params' not in payload:\n            payload['params'] = {}\n        payload['params']['runOnCreation'] = False\n\n        res = self.post('/v1/procedures', payload).json()\n        proc_id = res['id']\n\n        pm = ProgressMonitor(self, refresh_rate_sec, proc_id,\n                             notebook=self.notebook)\n\n        t = threading.Thread(target=pm.monitor_progress)\n        t.start()\n\n        try:\n            return self.post('/v1/procedures/{}/runs'.format(proc_id), {})\n        except Exception as e:\n            print(e)\n        finally:\n            pm.event.set()\n            t.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a service object for the endpoint as described.", "response": "def _makeService(self):\n        \"\"\"\n        Construct a service for the endpoint as described.\n        \"\"\"\n        if self._endpointService is None:\n            _service = service\n        else:\n            _service = self._endpointService\n        return _service(\n            self.description.encode('ascii'), self.factory.getFactory())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint details about the ports which already exist.", "response": "def postOptions(self):\n        \"\"\"\n        Display details about the ports which already exist.\n        \"\"\"\n        store = self.parent.parent.getStore()\n        port = None\n        factories = {}\n        for portType in [TCPPort, SSLPort, StringEndpointPort]:\n            for port in store.query(portType):\n                key = port.factory.storeID\n                if key not in factories:\n                    factories[key] = (port.factory, [])\n                factories[key][1].append(port)\n        for factory in store.powerupsFor(IProtocolFactoryFactory):\n            key = factory.storeID\n            if key not in factories:\n                factories[key] = (factory, [])\n        def key((factory, ports)):\n            return factory.storeID\n        for factory, ports in sorted(factories.values(), key=key):\n            if ports:\n                print '%d) %r listening on:' % (factory.storeID, factory)\n                for port in ports:\n                    if getattr(port, 'interface', None):\n                        interface = \"interface \" + port.interface\n                    else:\n                        interface = \"any interface\"\n                    if isinstance(port, TCPPort):\n                        print '  %d) TCP, %s, port %d' % (\n                            port.storeID, interface, port.portNumber)\n                    elif isinstance(port, SSLPort):\n                        if port.certificatePath is not None:\n                            pathPart = 'certificate %s' % (\n                                port.certificatePath.path,)\n                        else:\n                            pathPart = 'NO CERTIFICATE'\n                        if port.portNumber is not None:\n                            portPart = 'port %d' % (port.portNumber,)\n                        else:\n                            portPart = 'NO PORT'\n                        print '  %d) SSL, %s, %s, %s' % (\n                            port.storeID, interface, portPart, pathPart)\n                    elif isinstance(port, StringEndpointPort):\n                        print '  {:d}) Endpoint {!r}'.format(\n                            port.storeID, port.description)\n            else:\n                print '%d) %r is not listening.' % (factory.storeID, factory)\n        if not factories:\n            print \"There are no ports configured.\"\n        raise SystemExit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the ports with the given store IDs.", "response": "def _delete(self, store, portIDs):\n        \"\"\"\n        Try to delete the ports with the given store IDs.\n\n        @param store: The Axiom store from which to delete items.\n\n        @param portIDs: A list of Axiom store IDs for TCPPort or SSLPort items.\n\n        @raise L{SystemExit}: If one of the store IDs does not identify a port\n            item.\n        \"\"\"\n        for portID in portIDs:\n            try:\n                port = store.getItemByID(portID)\n            except KeyError:\n                print \"%d does not identify an item.\" % (portID,)\n                raise SystemExit(1)\n            if isinstance(port, (TCPPort, SSLPort, StringEndpointPort)):\n                port.deleteFromStore()\n            else:\n                print \"%d does not identify a port.\" % (portID,)\n                raise SystemExit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef postOptions(self):\n        if self.portIdentifiers:\n            store = self.parent.parent.getStore()\n            store.transact(self._delete, store, self.portIdentifiers)\n            print \"Deleted.\"\n            raise SystemExit(0)\n        else:\n            self.opt_help()", "response": "Delete the ports specified with the port - identifier option."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef absl_flags():\n    # TODO: need same thing for argparse\n    flags_dict = flags.FLAGS.flags_by_module_dict()\n    # only include parameters from modules the user probably cares about\n    def _relevant_module(module_name):\n        if __package__ and __package__ in module_name:\n            return True\n        if module_name == sys.argv[0]:\n            return True\n        return False\n    return {\n        flag.name: flag.value for module, flags in flags_dict.items()\n        for flag in flags if _relevant_module(module)}", "response": "Extracts absl - py flags that the user has specified and outputs their\n    key - value mapping."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pipeline(pipe=None, name=None, autoexec=False, exit_handler=None):\n    if pipe is None:\n        return Pipeline(name=name, autoexec=autoexec,\n                        exit_handler=exit_handler)\n\n    try:\n        if pipe.supports_redpipe_pipeline():\n            return NestedPipeline(\n                parent=pipe,\n                name=name,\n                autoexec=autoexec,\n                exit_handler=exit_handler\n            )\n    except AttributeError:\n        pass\n\n    raise InvalidPipeline('check your configuration')", "response": "This function creates a pipeline and returns a NestedPipeline object that can be used to execute the pipeline."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a pipeline that automatically executes the pipeline upon leaving the context if no exception was raised.", "response": "def autoexec(pipe=None, name=None, exit_handler=None):\n    \"\"\"\n    create a pipeline with a context that will automatically execute the\n    pipeline upon leaving the context if no exception was raised.\n\n    :param pipe:\n    :param name:\n    :return:\n    \"\"\"\n    return pipeline(pipe=pipe, name=name, autoexec=True,\n                    exit_handler=exit_handler)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Pipeline object for the named connection.", "response": "def _pipeline(self, name):\n        \"\"\"\n        Don't call this function directly.\n        Used by the NestedPipeline class when it executes.\n        :param name:\n        :return:\n        \"\"\"\n        if name == self.connection_name:\n            return self\n\n        try:\n            return self._pipelines[name]\n        except KeyError:\n            pipe = Pipeline(name=name, autoexec=True)\n            self._pipelines[name] = pipe\n            return pipe"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self):\n        stack = self._stack\n        callbacks = self._callbacks\n\n        promises = []\n        if stack:\n            def process():\n                \"\"\"\n                take all the commands and pass them to redis.\n                this closure has the context of the stack\n                :return: None\n                \"\"\"\n\n                # get the connection to redis\n                pipe = ConnectionManager.get(self.connection_name)\n\n                # keep track of all the commands\n                call_stack = []\n\n                # build a corresponding list of the futures\n                futures = []\n\n                # we need to do this because we need to make sure\n                # all of these are callable.\n                # there shouldn't be any non-callables.\n                for item, args, kwargs, future in stack:\n                    f = getattr(pipe, item)\n                    if callable(f):\n                        futures.append(future)\n                        call_stack.append((f, args, kwargs))\n\n                # here's where we actually pass the commands to the\n                # underlying redis-py pipeline() object.\n                for f, args, kwargs in call_stack:\n                    f(*args, **kwargs)\n\n                # execute the redis-py pipeline.\n                # map all of the results into the futures.\n                for i, v in enumerate(pipe.execute()):\n                    futures[i].set(v)\n\n            promises.append(process)\n\n        # collect all the other pipelines for other named connections attached.\n        promises += [p.execute for p in self._pipelines.values()]\n        if len(promises) == 1:\n            promises[0]()\n        else:\n            # if there are no promises, this is basically a no-op.\n            TaskManager.wait(*[TaskManager.promise(p) for p in promises])\n\n        for cb in callbacks:\n            cb()", "response": "Invoke the Redis pipeline and take all the values\n        returned in sequential order of commands and map them to the Future objects we returned when each command was queued up."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting rid of the stack and callbacks. get rid of the stack and callbacks.", "response": "def reset(self):\n        \"\"\"\n        cleanup method. get rid of the stack and callbacks.\n        :return:\n        \"\"\"\n        self._stack = []\n        self._callbacks = []\n        pipes = self._pipelines\n        self._pipelines = {}\n        for pipe in pipes.values():\n            pipe.reset()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the commands inside the nested pipeline.", "response": "def execute(self):\n        \"\"\"\n        execute the commands inside the nested pipeline.\n        This causes all queued up commands to be passed upstream to the\n        parent, including callbacks.\n        The state of this pipeline object gets cleaned up.\n        :return:\n        \"\"\"\n        stack = self._stack\n        callbacks = self._callbacks\n        self._stack = []\n        self._callbacks = []\n\n        deferred = []\n\n        build = self._nested_future\n\n        pipe = self._pipeline(self.connection_name)\n        for item, args, kwargs, ref in stack:\n            f = getattr(pipe, item)\n            deferred.append(build(f(*args, **kwargs), ref))\n\n        inject_callbacks = getattr(self.parent, '_inject_callbacks')\n        inject_callbacks(deferred + callbacks)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting DataCite JSON format to DataCite XML format.", "response": "def dump_etree_helper(container_name, data, rules, nsmap, attrib):\n    \"\"\"Convert DataCite JSON format to DataCite XML.\n\n    JSON should be validated before it is given to to_xml.\n    \"\"\"\n    output = etree.Element(container_name, nsmap=nsmap, attrib=attrib)\n\n    for rule in rules:\n        if rule not in data:\n            continue\n\n        element = rules[rule](rule, data[rule])\n        for e in element:\n            output.append(e)\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndumps XML etree as a string.", "response": "def etree_to_string(root, pretty_print=True, xml_declaration=True,\n                    encoding='utf-8'):\n    \"\"\"Dump XML etree as a string.\"\"\"\n    return etree.tostring(\n        root,\n        pretty_print=pretty_print,\n        xml_declaration=xml_declaration,\n        encoding=encoding,\n    ).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecorating as a rule for a key in top level JSON.", "response": "def rule(self, key):\n        \"\"\"Decorate as a rule for a key in top level JSON.\"\"\"\n        def register(f):\n            self.rules[key] = f\n            return f\n        return register"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninfer table metadata from a DataFrame", "response": "def from_dataframe(cls, name, df, indices, primary_key=None):\n        \"\"\"Infer table metadata from a DataFrame\"\"\"\n\n        # ordered list (column_name, column_type) pairs\n        column_types = []\n        # which columns have nullable values\n        nullable = set()\n\n        # tag cached database by dataframe's number of rows and columns\n        for column_name in df.columns:\n            values = df[column_name]\n            if values.isnull().any():\n                nullable.add(column_name)\n            column_db_type = db_type(values.dtype)\n            column_types.append((column_name.replace(\" \", \"_\"), column_db_type))\n\n        def make_rows():\n            return list(tuple(row) for row in df.values)\n\n        return cls(\n            name=name,\n            column_types=column_types,\n            make_rows=make_rows,\n            indices=indices,\n            nullable=nullable,\n            primary_key=primary_key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nobtain detailed info of a given parking.", "response": "def detail_parking(self, **kwargs):\n        \"\"\"Obtain detailed info of a given parking.\n\n        Args:\n            lang (str):  Language code (*es* or *en*).\n            day (int): Day of the month in format DD.\n                The number is automatically padded if it only has one digit.\n            month (int): Month number in format MM.\n                The number is automatically padded if it only has one digit.\n            year (int): Year number in format YYYY.\n            hour (int): Hour of the day in format hh.\n                The number is automatically padded if it only has one digit.\n            minute (int): Minute of the hour in format mm.\n                The number is automatically padded if it only has one digit.\n            parking (int): ID of the parking to query.\n            family (str): Family code of the parking (3 chars).\n\n        Returns:\n            Status boolean and parsed response (list[ParkingDetails]), or message\n            string in case of error.\n        \"\"\"\n        # Endpoint parameters\n        date = util.datetime_string(\n            kwargs.get('day', 1),\n            kwargs.get('month', 1),\n            kwargs.get('year', 1970),\n            kwargs.get('hour', 0),\n            kwargs.get('minute', 0)\n        )\n\n        params = {\n            'language': util.language_code(kwargs.get('lang')),\n            'publicData': True,\n            'date': date,\n            'id': kwargs.get('parking'),\n            'family': kwargs.get('family')\n        }\n\n        # Request\n        result = self.make_request('detail_parking', {}, **params)\n\n        if not util.check_result(result):\n            return False, result.get('message', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'Data')\n        return True, [emtype.ParkingDetails(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef detail_poi(self, **kwargs):\n        # Endpoint parameters\n        params = {\n            'language': util.language_code(kwargs.get('lang')),\n            'family': kwargs.get('family')\n        }\n\n        if kwargs.get('id'):\n            params['id'] = kwargs['id']\n\n        # Request\n        result = self.make_request('detail_poi', {}, **params)\n\n        if not util.check_result(result):\n            return False, result.get('message', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'Data')\n        return True, [emtype.PoiDetails(**a) for a in values]", "response": "Obtain detailed info of a given POI."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef icon_description(self, **kwargs):\n        # Endpoint parameters\n        params = {'language': util.language_code(kwargs.get('lang'))}\n\n        # Request\n        result = self.make_request('icon_description', {}, **params)\n\n        if not util.check_result(result):\n            return False, result.get('message', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'Data')\n        return True, [emtype.IconDescription(**a) for a in values]", "response": "Obtain a list of elements that have an associated icon."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info_parking_poi(self, **kwargs):\n        # Endpoint parameters\n        date = util.datetime_string(\n            kwargs.get('day', 1),\n            kwargs.get('month', 1),\n            kwargs.get('year', 1970),\n            kwargs.get('hour', 0),\n            kwargs.get('minute', 0)\n        )\n\n        family_categories = []\n        for element in kwargs.get('poi_info', []):\n            family_categories.append({\n                'poiCategory': {\n                    'lstCategoryTypes': element[0]\n                    },\n                'poiFamily': element[1],\n                'poiType': element[2]\n            })\n\n        field_codes = []\n        for element in kwargs.get('field_codes', []):\n            field_codes.append({\n                'codes': {\n                    'lstCodes': element[0]\n                    },\n                'nameField': element[1]\n            })\n\n        params = {\n            'TFamilyTTypeTCategory': {\n                'lstFamilyTypeCategory': family_categories\n            },\n            'coordinate': {\n                'latitude': str(kwargs.get('latitude', '0.0')),\n                'longitude': str(kwargs.get('longitude', '0.0'))\n            },\n            'dateTimeUse': date,\n            'language': util.language_code(kwargs.get('lang')),\n            'minimumPlacesAvailable': {\n                'lstminimumPlacesAvailable': kwargs.get('min_free', [])\n            },\n            'nameFieldCodes': {\n                'lstNameFieldCodes': field_codes\n            },\n            'radius': str(kwargs.get('radius', '0'))\n        }\n\n        # Request\n        result = self.make_request('info_parking_poi', {}, **params)\n\n        if not util.check_result(result):\n            return False, result.get('message', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'Data')\n        return True, [emtype.InfoParkingPoi(**a) for a in values]", "response": "Obtain generic information on POIs and parkings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nobtaining a list of parkings.", "response": "def list_features(self, **kwargs):\n        \"\"\"Obtain a list of parkings.\n\n        Args:\n            lang (str):  Language code (*es* or *en*).\n\n        Returns:\n            Status boolean and parsed response (list[Parking]), or message\n            string in case of error.\n        \"\"\"\n        # Endpoint parameters\n        params = {\n            'language': util.language_code(kwargs.get('lang')),\n            'publicData': True\n        }\n\n        # Request\n        result = self.make_request('list_features', {}, **params)\n\n        if not util.check_result(result):\n            return False, result.get('message', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'Data')\n        return True, [emtype.ParkingFeature(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_parking(self, **kwargs):\n        # Endpoint parameters\n        url_args = {'lang': util.language_code(kwargs.get('lang'))}\n\n        # Request\n        result = self.make_request('list_parking', url_args)\n\n        if not util.check_result(result):\n            return False, result.get('message', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'Data')\n        return True, [emtype.Parking(**a) for a in values]", "response": "Obtain a list of parkings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nobtaining a list of addresses and POIs. This endpoint uses an address to perform the search Args: lang (str): Language code (*es* or *en*). address (str): Address in which to perform the search. Returns: Status boolean and parsed response (list[ParkingPoi]), or message string in case of error.", "response": "def list_street_poi_parking(self, **kwargs):\n        \"\"\"Obtain a list of addresses and POIs.\n\n        This endpoint uses an address to perform the search\n\n        Args:\n            lang (str): Language code (*es* or *en*).\n            address (str): Address in which to perform the search.\n\n        Returns:\n            Status boolean and parsed response (list[ParkingPoi]), or message\n            string in case of error.\n        \"\"\"\n        # Endpoint parameters\n        url_args = {\n            'language': util.language_code(kwargs.get('lang')),\n            'address': kwargs.get('address', '')\n        }\n\n        # Request\n        result = self.make_request('list_street_poi_parking', url_args)\n\n        if not util.check_result(result):\n            return False, result.get('message', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'Data')\n        return True, [emtype.ParkingPoi(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nobtaining a list of families types and categories of POI.", "response": "def list_types_poi(self, **kwargs):\n        \"\"\"Obtain a list of families, types and categories of POI.\n\n        Args:\n            lang (str): Language code (*es* or *en*).\n\n        Returns:\n            Status boolean and parsed response (list[ParkingPoiType]), or message\n            string in case of error.\n        \"\"\"\n        # Endpoint parameters\n        url_args = {'language': util.language_code(kwargs.get('lang'))}\n\n        # Request\n        result = self.make_request('list_poi_types', url_args)\n\n        if not util.check_result(result):\n            return False, result.get('message', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'Data')\n        return True, [emtype.ParkingPoiType(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readQuotes(self, start, end):\r\n        ''' read quotes from Yahoo Financial'''\r\n        if self.symbol is None:\r\n            LOG.debug('Symbol is None')\r\n            return []\r\n\r\n        return self.__yf.getQuotes(self.symbol, start, end)", "response": "read quotes from Yahoo Financial"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets the device to factory defaults.", "response": "def _factory_default(self, confirm=False):\n        \"\"\"Resets the device to factory defaults.\n\n        :param confirm: This function should not normally be used, to prevent\n            accidental resets, a confirm value of `True` must be used.\n\n        \"\"\"\n        if confirm is True:\n            self._write(('DFLT', Integer), 99)\n        else:\n            raise ValueError('Reset to factory defaults was not confirmed.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef usernameFromRequest(request):\n    username = request.args.get('username', [''])[0]\n    if '@' not in username:\n        username = '%s@%s' % (\n            username, request.getHeader('host').split(':')[0])\n    return username", "response": "Takes an HTTP request and returns a username of the form user@domain."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a persistent session in the database.", "response": "def createSessionForKey(self, key, user):\n        \"\"\"\n        Create a persistent session in the database.\n\n        @type key: L{bytes}\n        @param key: The persistent session identifier.\n\n        @type user: L{bytes}\n        @param user: The username the session will belong to.\n        \"\"\"\n        PersistentSession(\n            store=self.store,\n            sessionKey=key,\n            authenticatedAs=user)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the user ID that the user belongs to.", "response": "def authenticatedUserForKey(self, key):\n        \"\"\"\n        Find a persistent session for a user.\n\n        @type key: L{bytes}\n        @param key: The persistent session identifier.\n\n        @rtype: L{bytes} or C{None}\n        @return: The avatar ID the session belongs to, or C{None} if no such\n            session exists.\n        \"\"\"\n        session = self.store.findFirst(\n            PersistentSession, PersistentSession.sessionKey == key)\n        if session is None:\n            return None\n        else:\n            session.renew()\n            return session.authenticatedAs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef removeSessionWithKey(self, key):\n        self.store.query(\n            PersistentSession,\n            PersistentSession.sessionKey == key).deleteFromStore()", "response": "Removes a persistent session with the given key from the store."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _maybeCleanSessions(self):\n        sinceLast = self._clock.seconds() - self._lastClean\n        if sinceLast > self.sessionCleanFrequency:\n            self._cleanSessions()", "response": "Clean expired sessions if it s too long enough since the last clean."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the domain name to use when setting cookies for the request.", "response": "def cookieDomainForRequest(self, request):\n        \"\"\"\n        Pick a domain to use when setting cookies.\n\n        @type request: L{nevow.inevow.IRequest}\n        @param request: Request to determine cookie domain for\n\n        @rtype: C{str} or C{None}\n        @return: Domain name to use when setting cookies, or C{None} to\n            indicate that only the domain in the request should be used\n        \"\"\"\n        host = request.getHeader('host')\n        if host is None:\n            # This is a malformed request that we cannot possibly handle\n            # safely, fall back to the default behaviour.\n            return None\n\n        host = host.split(':')[0]\n        for domain in self._domains:\n            suffix = \".\" + domain\n            if host == domain:\n                # The request is for a domain which is directly recognized.\n                if self._enableSubdomains:\n                    # Subdomains are enabled, so the suffix is returned to\n                    # enable the cookie for this domain and all its subdomains.\n                    return suffix\n\n                # Subdomains are not enabled, so None is returned to allow the\n                # default restriction, which will enable this cookie only for\n                # the domain in the request, to apply.\n                return None\n\n            if self._enableSubdomains and host.endswith(suffix):\n                # The request is for a subdomain of a directly recognized\n                # domain and subdomains are enabled.  Drop the unrecognized\n                # subdomain portion and return the suffix to enable the cookie\n                # for this domain and all its subdomains.\n                return suffix\n\n        if self._enableSubdomains:\n            # No directly recognized domain matched the request.  If subdomains\n            # are enabled, prefix the request domain with \".\" to make the\n            # cookie valid for that domain and all its subdomains.  This\n            # probably isn't extremely useful.  Perhaps it shouldn't work this\n            # way.\n            return \".\" + host\n\n        # Subdomains are disabled and the domain from the request was not\n        # recognized.  Return None to get the default behavior.\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes the session cookie last as long as the persistent session.", "response": "def savorSessionCookie(self, request):\n        \"\"\"\n        Make the session cookie last as long as the persistent session.\n\n        @type request: L{nevow.inevow.IRequest}\n        @param request: The HTTP request object for the guard login URL.\n        \"\"\"\n        cookieValue = request.getSession().uid\n        request.addCookie(\n            self.cookieKey, cookieValue, path='/',\n            max_age=PERSISTENT_SESSION_LIFETIME,\n            domain=self.cookieDomainForRequest(request))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall to check the credentials of a user. Here we extend guard's implementation to preauthenticate users if they have a valid persistent session. @type request: L{nevow.inevow.IRequest} @param request: The HTTP request being handled. @type session: L{nevow.guard.GuardSession} @param session: The user's current session. @type creds: L{twisted.cred.credentials.ICredentials} @param creds: The credentials the user presented. @type segments: L{tuple} @param segments: The remaining segments of the URL. @return: A deferred firing with the user's avatar.", "response": "def login(self, request, session, creds, segments):\n        \"\"\"\n        Called to check the credentials of a user.\n\n        Here we extend guard's implementation to preauthenticate users if they\n        have a valid persistent session.\n\n        @type request: L{nevow.inevow.IRequest}\n        @param request: The HTTP request being handled.\n\n        @type session: L{nevow.guard.GuardSession}\n        @param session: The user's current session.\n\n        @type creds: L{twisted.cred.credentials.ICredentials}\n        @param creds: The credentials the user presented.\n\n        @type segments: L{tuple}\n        @param segments: The remaining segments of the URL.\n\n        @return: A deferred firing with the user's avatar.\n        \"\"\"\n        self._maybeCleanSessions()\n\n        if isinstance(creds, credentials.Anonymous):\n            preauth = self.authenticatedUserForKey(session.uid)\n            if preauth is not None:\n                self.savorSessionCookie(request)\n                creds = userbase.Preauthenticated(preauth)\n\n        def cbLoginSuccess(input):\n            \"\"\"\n            User authenticated successfully.\n\n            Create the persistent session, and associate it with the\n            username. (XXX it doesn't work like this now)\n            \"\"\"\n            user = request.args.get('username')\n            if user is not None:\n                # create a database session and associate it with this user\n                cookieValue = session.uid\n                if request.args.get('rememberMe'):\n                    self.createSessionForKey(cookieValue, creds.username)\n                    self.savorSessionCookie(request)\n            return input\n\n        return (\n            guard.SessionWrapper.login(\n                self, request, session, creds, segments)\n            .addCallback(cbLoginSuccess))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle a user - requested logout.", "response": "def explicitLogout(self, session):\n        \"\"\"\n        Handle a user-requested logout.\n\n        Here we override guard's behaviour for the logout action to delete the\n        persistent session.  In this case the user has explicitly requested a\n        logout, so the persistent session must be deleted to require the user\n        to log in on the next request.\n\n        @type session: L{nevow.guard.GuardSession}\n        @param session: The session of the user logging out.\n        \"\"\"\n        guard.SessionWrapper.explicitLogout(self, session)\n        self.removeSessionWithKey(session.uid)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nderiving credentials from an HTTP request.", "response": "def getCredentials(self, request):\n        \"\"\"\n        Derive credentials from an HTTP request.\n\n        Override SessionWrapper.getCredentials to add the Host: header to the\n        credentials.  This will make web-based virtual hosting work.\n\n        @type request: L{nevow.inevow.IRequest}\n        @param request: The request being handled.\n\n        @rtype: L{twisted.cred.credentials.1ICredentials}\n        @return: Credentials derived from the HTTP request.\n        \"\"\"\n        username = usernameFromRequest(request)\n        password = request.args.get('password', [''])[0]\n        return credentials.UsernamePassword(username, password)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setTabURLs(tabs, webTranslator):\n\n    for tab in tabs:\n        if not tab.linkURL:\n            tab.linkURL = webTranslator.linkTo(tab.storeID)\n        setTabURLs(tab.children, webTranslator)", "response": "Sets the linkURL attribute on each tab in the specified tabs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getSelectedTab(tabs, forURL):\n\n    flatTabs = []\n\n    def flatten(tabs):\n        for t in tabs:\n            flatTabs.append(t)\n            flatten(t.children)\n\n    flatten(tabs)\n    forURL = '/' + forURL.path\n\n    for t in flatTabs:\n        if forURL == t.linkURL:\n            return t\n\n    flatTabs.sort(key=lambda t: len(t.linkURL), reverse=True)\n\n    for t in flatTabs:\n        if not t.linkURL.endswith('/'):\n            linkURL = t.linkURL + '/'\n        else:\n            linkURL = t.linkURL\n\n        if forURL.startswith(linkURL):\n            return t", "response": "Returns the tab that should be selected when the current\n    resource lives at C { forURL."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef startMenu(translator, navigation, tag):\n    setTabURLs(navigation, translator)\n    getp = IQ(tag).onePattern\n\n    def fillSlots(tabs):\n        for tab in tabs:\n            if tab.children:\n                kids = getp('subtabs').fillSlots('kids', fillSlots(tab.children))\n            else:\n                kids = ''\n\n            yield dictFillSlots(getp('tab'), dict(href=tab.linkURL,\n                                                  name=tab.name,\n                                                  kids=kids))\n    return tag.fillSlots('tabs', fillSlots(navigation))", "response": "Start a Drop - down menu - style navigation view."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef applicationNavigation(ctx, translator, navigation):\n    setTabURLs(navigation, translator)\n    selectedTab = getSelectedTab(navigation,\n                                 url.URL.fromContext(ctx))\n\n    getp = IQ(ctx.tag).onePattern\n    tabs = []\n\n    for tab in navigation:\n        if tab == selectedTab or selectedTab in tab.children:\n            p = 'selected-app-tab'\n            contentp = 'selected-tab-contents'\n        else:\n            p = 'app-tab'\n            contentp = 'tab-contents'\n\n        childTabs = []\n        for subtab in tab.children:\n            try:\n                subtabp = getp(\"subtab\")\n            except NodeNotFound:\n                continue\n            childTabs.append(\n                dictFillSlots(subtabp, {\n                        'name': subtab.name,\n                        'href': subtab.linkURL,\n                        'tab-contents': getp(\"subtab-contents\")\n                        }))\n        tabs.append(dictFillSlots(\n                getp(p),\n                {'name': tab.name,\n                 'tab-contents': getp(contentp).fillSlots(\n                        'href', tab.linkURL),\n                 'subtabs': childTabs}))\n\n    ctx.tag.fillSlots('tabs', tabs)\n    return ctx.tag", "response": "This method creates a new application navigation view."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pathFromItem(self, item, avatar):\n        for subnav in self.children:\n            subpath = subnav.pathFromItem(item, avatar)\n            if subpath:\n                subpath.insert(0, self)\n                return subpath\n        else:\n            myItem = self.loadForAvatar(avatar)\n            if myItem is item:\n                return [self]\n        return []", "response": "Returns a list of all the path from this item to the item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate():\n    privateKey = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=4096,\n        backend=default_backend())\n    return Key(privateKey).toString('openssh')", "response": "Generate a new SSH key pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an L{SSHFactory which allows access to Mantissa accounts.", "response": "def getFactory(self):\n        \"\"\"\n        Create an L{SSHFactory} which allows access to Mantissa accounts.\n        \"\"\"\n        privateKey = Key.fromString(data=self.hostKey)\n        public = privateKey.public()\n        factory = SSHFactory()\n        factory.publicKeys = {'ssh-rsa': public}\n        factory.privateKeys = {'ssh-rsa': privateKey}\n        factory.portal = Portal(\n            IRealm(self.store), [ICredentialsChecker(self.store)])\n        return factory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw the main menu widget with the current known taxonomy size and the terminal size.", "response": "def _draw(self):\n        \"\"\"\n        Call the drawing API for the main menu widget with the current known\n        terminal size and the terminal.\n        \"\"\"\n        self._window.draw(self._width, self._height, self.terminal)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when a sub - protocol is finished.", "response": "def reactivate(self):\n        \"\"\"\n        Called when a sub-protocol is finished.  This disconnects the\n        sub-protocol and redraws the main menu UI.\n        \"\"\"\n        self._protocol.connectionLost(None)\n        self._protocol = None\n        self.terminal.reset()\n        self._window.filthy()\n        self._window.repaint()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nswitch the terminal to the given application.", "response": "def switchTo(self, app):\n        \"\"\"\n        Use the given L{ITerminalServerFactory} to create a new\n        L{ITerminalProtocol} and connect it to C{self.terminal} (such that it\n        cannot actually disconnect, but can do most anything else).  Control of\n        the terminal is delegated to it until it gives up that control by\n        disconnecting itself from the terminal.\n\n        @type app: L{ITerminalServerFactory} provider\n        @param app: The factory which will be used to create a protocol\n            instance.\n        \"\"\"\n        viewer = _AuthenticatedShellViewer(list(getAccountNames(self._store)))\n        self._protocol = app.buildTerminalProtocol(viewer)\n        self._protocol.makeConnection(_ReturnToMenuWrapper(self, self.terminal))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef keystrokeReceived(self, keyID, modifier):\n        if self._protocol is not None:\n            self._protocol.keystrokeReceived(keyID, modifier)\n        else:\n            self._window.keystrokeReceived(keyID, modifier)", "response": "Forward input events to the application - supplied protocol or main menu UI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef indirect(self, interface):\n        if interface is IConchUser:\n            componentized = Componentized()\n\n            user = _BetterTerminalUser(componentized, None)\n            session = _BetterTerminalSession(componentized)\n            session.transportFactory = TerminalSessionTransport\n            session.chainedProtocolFactory = lambda: ServerProtocol(ShellServer, self.store)\n\n            componentized.setComponent(IConchUser, user)\n            componentized.setComponent(ISession, session)\n\n            return user\n\n        raise NotImplementedError(interface)", "response": "Create an indirect user avatar which will use L { ShellServer } to interact with the connection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch(self):\n        api = self.doapi_manager\n        return api._floating_ip(api.request(self.url)[\"floating_ip\"])", "response": "Fetch & return a new FloatingIP object representing the floating IP s\n        current state"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassign the floating IP to a droplet.", "response": "def assign(self, droplet_id):\n        \"\"\"\n        Assign the floating IP to a droplet\n\n        :param droplet_id: the droplet to assign the floating IP to as either\n            an ID or a `Droplet` object\n        :type droplet_id: integer or `Droplet`\n        :return: an `Action` representing the in-progress operation on the\n            floating IP\n        :rtype: Action\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        if isinstance(droplet_id, Droplet):\n            droplet_id = droplet_id.id\n        return self.act(type='assign', droplet_id=droplet_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _id(self):\n        if self.get(\"id\") is not None:\n            return self.id\n        elif self.get(\"fingerprint\") is not None:\n            return self.fingerprint\n        else:\n            raise TypeError('SSHKey has neither .id nor .fingerprint')", "response": "r Returns the ID of the SSHKey."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching & return a new SSHKey object representing the SSH key s current", "response": "def fetch(self):\n        \"\"\"\n        Fetch & return a new `SSHKey` object representing the SSH key's current\n        state\n\n        :rtype: SSHKey\n        :raises DOAPIError: if the API endpoint replies with an error (e.g., if\n            the SSH key no longer exists)\n        \"\"\"\n        api = self.doapi_manager\n        return api._ssh_key(api.request(self.url)[\"ssh_key\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the SSH key object with the new name.", "response": "def update_ssh_key(self, name):\n        # The `_ssh_key` is to avoid conflicts with MutableMapping.update.\n        \"\"\"\n        Update (i.e., rename) the SSH key\n\n        :param str name: the new name for the SSH key\n        :return: an updated `SSHKey` object\n        :rtype: SSHKey\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        api = self.doapi_manager\n        return api._ssh_key(api.request(self.url, method='PUT',\n                                       data={\"name\": name})[\"ssh_key\"])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(msg):\n        sender, conn_id, path, rest = msg.split(' ', 3)\n        headers, rest = tnetstring.pop(rest)\n        body, _ = tnetstring.pop(rest)\n\n        if type(headers) is str:\n            headers = json.loads(headers)\n\n        return MongrelRequest(sender, conn_id, path, headers, body)", "response": "Parse a Mongrel2 request string and return a new MongrelRequest instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether the HTTP connection of this request should be closed and if it is not keep - alive.", "response": "def should_close(self):\n        \"\"\"\n        Check whether the HTTP connection of this request should be closed\n        after the request is finished.\n\n        We check for the `Connection` HTTP header and for the HTTP Version\n        (only `HTTP/1.1` supports keep-alive.\n        \"\"\"\n        if self.headers.get('connection') == 'close':\n            return True\n        elif 'content-length' in self.headers or \\\n            self.headers.get('METHOD') in ['HEAD', 'GET']:\n            return self.headers.get('connection') != 'keep-alive'\n        elif self.headers.get('VERSION') == 'HTTP/1.0':\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef system_status(self):\n        flag, timestamp, status = self._query(('GETDAT? 1', (Integer, Float, Integer)))\n        return {\n            # convert unix timestamp to datetime object\n            'timestamp': datetime.datetime.fromtimestamp(timestamp),\n            # bit 0-3 represent the temperature controller status\n            'temperature': STATUS_TEMPERATURE[status & 0xf],\n            # bit 4-7 represent the magnet status\n            'magnet': STATUS_MAGNET[(status >> 4) & 0xf],\n            # bit 8-11 represent the chamber status\n            'chamber': STATUS_CHAMBER[(status >> 8) & 0xf],\n            # bit 12-15 represent the sample position status\n            'sample_position': STATUS_SAMPLE_POSITION[(status >> 12) & 0xf],\n        }", "response": "The system status codes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef beep(self, duration, frequency):\n        cmd = 'BEEP', [Float(min=0.1, max=5.0), Integer(min=500, max=5000)]\n        self._write(cmd, duration, frequency)", "response": "Generates a beep.\n\n        :param duration: The duration in seconds, in the range 0.1 to 5.\n        :param frequency: The frequency in Hz, in the range 500 to 5000."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move(self, position, slowdown=0):\n        cmd = 'MOVE', [Float, Integer, Integer(min=0, max=14)]\n        self._write(cmd, position, 0, slowdown)", "response": "Move the sample to the specified sample position."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmoves to limit switch and define it as position.", "response": "def move_to_limit(self, position):\n        \"\"\"Move to limit switch and define it as position.\n\n        :param position: The new position of the limit switch.\n\n        \"\"\"\n        cmd = 'MOVE', [Float, Integer]\n        self._write(cmd, position, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef redefine_position(self, position):\n        cmd = 'MOVE', [Float, Integer]\n        self._write(cmd, position, 2)", "response": "Redefines the current position to the new position."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a temperature scan.", "response": "def scan_temperature(self, measure, temperature, rate, delay=1):\n        \"\"\"Performs a temperature scan.\n\n        Measures until the target temperature is reached.\n\n        :param measure: A callable called repeatedly until stability at target\n            temperature is reached.\n        :param temperature: The target temperature in kelvin.\n        :param rate: The sweep rate in kelvin per minute.\n        :param delay: The time delay between each call to measure in seconds.\n\n        \"\"\"\n        if not hasattr(measure, '__call__'):\n            raise TypeError('measure parameter not callable.')\n\n        self.set_temperature(temperature, rate, 'no overshoot', wait_for_stability=False)\n        start = datetime.datetime.now()\n        while True:\n            # The PPMS needs some time to update the status code, we therefore ignore it for 10s.\n            if (self.system_status['temperature'] == 'normal stability at target temperature' and\n                (datetime.datetime.now() - start > datetime.timedelta(seconds=10))):\n                break\n            measure()\n            time.sleep(delay)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms a field scan.", "response": "def scan_field(self, measure, field, rate, mode='persistent', delay=1):\n        \"\"\"Performs a field scan.\n\n        Measures until the target field is reached.\n\n        :param measure: A callable called repeatedly until stability at the\n            target field is reached.\n        :param field: The target field in Oersted.\n\n            .. note:: The conversion is 1 Oe = 0.1 mT.\n\n        :param rate: The field rate in Oersted per minute.\n        :param mode: The state of the magnet at the end of the charging\n            process, either 'persistent' or 'driven'.\n        :param delay: The time delay between each call to measure in seconds.\n\n        :raises TypeError: if measure parameter is not callable.\n\n        \"\"\"\n        if not hasattr(measure, '__call__'):\n            raise TypeError('measure parameter not callable.')\n        self.set_field(field, rate, approach='linear', mode=mode, wait_for_stability=False)\n        if self.system_status['magnet'].startswith('persist'):\n            # The persistent switch takes some time to open. While it's opening,\n            # the status does not change.\n            switch_heat_time = datetime.timedelta(seconds=self.magnet_config[5])\n            start = datetime.datetime.now()\n            while True:\n                now = datetime.datetime.now()\n                if now - start > switch_heat_time:\n                    break\n                measure()\n                time.sleep(delay)\n        while True:\n            status = self.system_status['magnet']\n            if status in ('persistent, stable', 'driven, stable'):\n                break\n            measure()\n            time.sleep(delay)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the magnetic field.", "response": "def set_field(self, field, rate, approach='linear', mode='persistent',\n                  wait_for_stability=True, delay=1):\n        \"\"\"Sets the magnetic field.\n\n        :param field: The target field in Oersted.\n\n            .. note:: The conversion is 1 Oe = 0.1 mT.\n\n        :param rate: The field rate in Oersted per minute.\n        :param approach: The approach mode, either 'linear', 'no overshoot' or\n            'oscillate'.\n        :param mode: The state of the magnet at the end of the charging\n            process, either 'persistent' or 'driven'.\n        :param wait_for_stability: If `True`, the function call blocks until\n            the target field is reached and stable.\n        :param delay: Specifies the frequency in seconds how often the magnet\n            status is checked. (This has no effect if wait_for_stability is\n            `False`).\n\n        \"\"\"\n        self.target_field = field, rate, approach, mode\n        if wait_for_stability and self.system_status['magnet'].startswith('persist'):\n            # Wait until the persistent switch heats up.\n            time.sleep(self.magnet_config[5])\n\n        while wait_for_stability:\n            status = self.system_status['magnet']\n            if status in ('persistent, stable', 'driven, stable'):\n                break\n            time.sleep(delay)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_temperature(self, temperature, rate, mode='fast', wait_for_stability=True, delay=1):\n        self.target_temperature = temperature, rate, mode\n        start = datetime.datetime.now()\n        while wait_for_stability:\n            # The PPMS needs some time to update the status code, we therefore ignore it for 10s.\n            if (self.system_status['temperature'] == 'normal stability at target temperature' and\n                (datetime.datetime.now() - start > datetime.timedelta(seconds=10))):\n                break\n            time.sleep(delay)", "response": "Sets the target temperature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadgrants(source=None, setspec=None, all_grants=False):\n    assert all_grants or setspec or source, \\\n        \"Either '--all', '--setspec' or '--source' is required parameter.\"\n    if all_grants:\n        harvest_all_openaire_projects.delay()\n    elif setspec:\n        click.echo(\"Remote grants loading sent to queue.\")\n        harvest_openaire_projects.delay(setspec=setspec)\n    else:  # if source\n        loader = LocalOAIRELoader(source=source)\n        loader._connect()\n        cnt = loader._count()\n        click.echo(\"Sending grants to queue.\")\n        with click.progressbar(loader.iter_grants(), length=cnt) as grants_bar:\n\n            for grant_json in grants_bar:\n                register_grant.delay(grant_json)", "response": "Load grants from a local file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nharvests grants from OpenAIRE.", "response": "def registergrant(source=None, setspec=None):\n    \"\"\"Harvest grants from OpenAIRE.\"\"\"\n    with open(source, 'r') as fp:\n        data = json.load(fp)\n    register_grant(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps grants from OpenAIRE and store them locally.", "response": "def dumpgrants(destination, as_json=None, setspec=None):\n    \"\"\"Harvest grants from OpenAIRE and store them locally.\"\"\"\n    if os.path.isfile(destination):\n        click.confirm(\"Database '{0}' already exists.\"\n                      \"Do you want to write to it?\".format(destination),\n                      abort=True)  # no cover\n    dumper = OAIREDumper(destination,\n                         setspec=setspec)\n    dumper.dump(as_json=as_json)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the site front page to its ecs.", "response": "def postOptions(self):\n        \"\"\"\n        Find an installed offering and set the site front page to its\n        application's front page.\n        \"\"\"\n        o = self.store.findFirst(\n            offering.InstalledOffering,\n            (offering.InstalledOffering.offeringName ==\n             self[\"name\"]))\n        if o is None:\n            raise usage.UsageError(\"No offering of that name\"\n                                   \" is installed.\")\n        fp = self.store.findUnique(publicweb.FrontPage)\n        fp.defaultApplication = o.application"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a view object for the given parameter. This function implements the remaining view construction logic which has not yet been converted to the C{viewFactory}-style expressed in L{_LiveFormMixin.form}. @type form: L{_LiveFormMixin} @param form: The form fragment which contains the given parameter. @type patterns: L{PatternDictionary} @type parameter: L{Parameter}, L{ChoiceParameter}, or L{ListParameter}.", "response": "def _legacySpecialCases(form, patterns, parameter):\n    \"\"\"\n    Create a view object for the given parameter.\n\n    This function implements the remaining view construction logic which has\n    not yet been converted to the C{viewFactory}-style expressed in\n    L{_LiveFormMixin.form}.\n\n    @type form: L{_LiveFormMixin}\n    @param form: The form fragment which contains the given parameter.\n    @type patterns: L{PatternDictionary}\n    @type parameter: L{Parameter}, L{ChoiceParameter}, or L{ListParameter}.\n    \"\"\"\n    p = patterns[parameter.type + '-input-container']\n\n    if parameter.type == TEXTAREA_INPUT:\n        p = dictFillSlots(p, dict(label=parameter.label,\n                                  name=parameter.name,\n                                  value=parameter.default or ''))\n    elif parameter.type == MULTI_TEXT_INPUT:\n        subInputs = list()\n\n        for i in xrange(parameter.count):\n            subInputs.append(dictFillSlots(patterns['input'],\n                                dict(name=parameter.name + '_' + str(i),\n                                     type='text',\n                                     value=parameter.defaults[i])))\n\n        p = dictFillSlots(p, dict(label=parameter.label or parameter.name,\n                                  inputs=subInputs))\n\n    else:\n        if parameter.default is not None:\n            value = parameter.default\n        else:\n            value = ''\n\n        if parameter.type == CHECKBOX_INPUT and parameter.default:\n            inputPattern = 'checked-checkbox-input'\n        else:\n            inputPattern = 'input'\n\n        p = dictFillSlots(\n            p, dict(label=parameter.label or parameter.name,\n                    input=dictFillSlots(patterns[inputPattern],\n                                        dict(name=parameter.name,\n                                             type=parameter.type,\n                                             value=value))))\n\n    p(**{'class' : 'liveform_'+parameter.name})\n\n    if parameter.description:\n        description = patterns['description'].fillSlots(\n                           'description', parameter.description)\n    else:\n        description = ''\n\n    return dictFillSlots(\n        patterns['parameter-input'],\n        dict(input=p, description=description))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a text parameter into a L { TextParameterView } instance.", "response": "def _textParameterToView(parameter):\n    \"\"\"\n    Return a L{TextParameterView} adapter for C{TEXT_INPUT}, C{PASSWORD_INPUT},\n    and C{FORM_INPUT} L{Parameter} instances.\n    \"\"\"\n    if parameter.type == TEXT_INPUT:\n        return TextParameterView(parameter)\n    if parameter.type == PASSWORD_INPUT:\n        return PasswordParameterView(parameter)\n    if parameter.type == FORM_INPUT:\n        return FormInputParameterView(parameter)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the inputs associated with this parameter from the given dictionary and coerce them using self. coerceMany.", "response": "def fromInputs(self, inputs):\n        \"\"\"\n        Extract the inputs associated with the child forms of this parameter\n        from the given dictionary and coerce them using C{self.coercer}.\n\n        @type inputs: C{dict} mapping C{unicode} to C{list} of C{unicode}\n        @param inputs: The contents of a form post, in the conventional\n            structure.\n\n        @rtype: L{Deferred}\n        @return: The structured data associated with this parameter represented\n            by the post data.\n        \"\"\"\n        try:\n            values = inputs[self.name]\n        except KeyError:\n            raise ConfigurationError(\n                \"Missing value for input: \" + self.name)\n        return self.coerceMany(values)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clone(self, default):\n        return self.__class__(\n            self.name,\n            self.type,\n            self.coercer,\n            self.label,\n            self.description,\n            default,\n            self.viewFactory)", "response": "Make a copy of this parameter supplying a different default."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prepareSubForm(self, liveForm):\n        liveForm = liveForm.asSubForm(self.name) # XXX Why did this work???\n        # if we are compact, tell the liveform so it can tell its parameters\n        # also\n        if self._parameterIsCompact:\n            liveForm.compact()\n        return liveForm", "response": "Utility for turning liveforms into subforms and compacting them as necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a copy of the original parameter with the default value.", "response": "def _cloneDefaultedParameter(self, original, default):\n        \"\"\"\n        Make a copy of the parameter C{original}, supplying C{default} as the\n        default value.\n\n        @type original: L{Parameter} or L{ChoiceParameter}\n        @param original: A liveform parameter.\n\n        @param default: An alternate default value for the parameter.\n\n        @rtype: L{Parameter} or L{ChoiceParameter}\n        @return: A new parameter.\n        \"\"\"\n        if isinstance(original, ChoiceParameter):\n            default = [Option(o.description, o.value, o.value in default)\n                        for o in original.choices]\n        return original.clone(default)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates an opaque identifier which can be used to talk about the specified object.", "response": "def _idForObject(self, defaultObject):\n        \"\"\"\n        Generate an opaque identifier which can be used to talk about\n        C{defaultObject}.\n\n        @rtype: C{int}\n        \"\"\"\n        identifier = self._allocateID()\n        self._idsToObjects[identifier] = defaultObject\n        return identifier"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a new identifier for an as - yet uncreated model object.", "response": "def _newIdentifier(self):\n        \"\"\"\n        Make a new identifier for an as-yet uncreated model object.\n\n        @rtype: C{int}\n        \"\"\"\n        id = self._allocateID()\n        self._idsToObjects[id] = self._NO_OBJECT_MARKER\n        self._lastValues[id] = None\n        return id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a live form with the parameters and identifier.", "response": "def _makeALiveForm(self, parameters, identifier, removable=True):\n        \"\"\"\n        Make a live form with the parameters C{parameters}, which will be used\n        to edit the values/model object with identifier C{identifier}.\n\n        @type parameters: C{list}\n        @param parameters: list of L{Parameter} instances.\n\n        @type identifier: C{int}\n\n        @type removable: C{bool}\n\n        @rtype: L{repeatedLiveFormWrapper}\n        \"\"\"\n        liveForm = self.liveFormFactory(lambda **k: None, parameters, self.name)\n        liveForm = self._prepareSubForm(liveForm)\n        liveForm = self.repeatedLiveFormWrapper(liveForm, identifier, removable)\n        liveForm.docFactory = webtheme.getLoader(liveForm.fragmentName)\n        return liveForm"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a liveform suitable for editing the set of default values.", "response": "def _makeDefaultLiveForm(self, (defaults, identifier)):\n        \"\"\"\n        Make a liveform suitable for editing the set of default values C{defaults}.\n\n        @type defaults: C{dict}\n        @param defaults: Mapping of parameter names to values.\n\n        @rtype: L{repeatedLiveFormWrapper}\n        \"\"\"\n        parameters = [self._cloneDefaultedParameter(p, defaults[p.name])\n                        for p in self.parameters]\n        return self._makeALiveForm(parameters, identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getInitialLiveForms(self):\n        liveForms = []\n        if self._defaultStuff:\n            for values in self._defaultStuff:\n                liveForms.append(self._makeDefaultLiveForm(values))\n        else:\n            # or only one, for the first new thing\n            liveForms.append(\n                self._makeALiveForm(\n                    self.parameters, self._newIdentifier(), False))\n        return liveForms", "response": "Makes and return as many L{LiveForm instances as necessary to hold\n        our default values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncoerces a single repetition of the data set into a liveform with our parameters and get it to coerce our dataset for us.", "response": "def _coerceSingleRepetition(self, dataSet):\n        \"\"\"\n        Make a new liveform with our parameters, and get it to coerce our data\n        for us.\n        \"\"\"\n        # make a liveform because there is some logic in _coerced\n        form = LiveForm(lambda **k: None, self.parameters, self.name)\n        return form.fromInputs(dataSet)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extractCreations(self, dataSets):\n        for dataSet in dataSets:\n            modelObject = self._objectFromID(dataSet[self._IDENTIFIER_KEY])\n            if modelObject is self._NO_OBJECT_MARKER:\n                dataCopy = dataSet.copy()\n                identifier = dataCopy.pop(self._IDENTIFIER_KEY)\n                yield identifier, dataCopy", "response": "Extracts the elements of C { dataSets which represent the creation of new\n            objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncoerces all the items in the input list.", "response": "def _coerceAll(self, inputs):\n        \"\"\"\n        XXX\n        \"\"\"\n        def associate(result, obj):\n            return (obj, result)\n\n        coerceDeferreds = []\n        for obj, dataSet in inputs:\n            oneCoerce = self._coerceSingleRepetition(dataSet)\n            oneCoerce.addCallback(associate, obj)\n            coerceDeferreds.append(oneCoerce)\n        return gatherResults(coerceDeferreds)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncoercing all of the repetitions and sort them into creations edits and deletions.", "response": "def coercer(self, dataSets):\n        \"\"\"\n        Coerce all of the repetitions and sort them into creations, edits and\n        deletions.\n\n        @rtype: L{ListChanges}\n        @return: An object describing all of the creations, modifications, and\n            deletions represented by C{dataSets}.\n        \"\"\"\n        # Xxx - This does a slightly complex (hey, it's like 20 lines, how\n        # complex could it really be?) thing to figure out which elements are\n        # newly created, which elements were edited, and which elements no\n        # longer exist.  It might be simpler if the client kept track of this\n        # and passed a three-tuple of lists (or whatever - some separate data\n        # structures) to the server, so everything would be all figured out\n        # already.  This would require the client\n        # (Mantissa.LiveForm.RepeatableForm) to be more aware of what events\n        # the user is triggering in the browser so that it could keep state for\n        # adds/deletes/edits separately from DOM and widget objects.  This\n        # would remove the need for RepeatedLiveFormWrapper.\n        def makeSetter(identifier, values):\n            def setter(defaultObject):\n                self._idsToObjects[identifier] = defaultObject\n                self._lastValues[identifier] = values\n            return setter\n\n        created = self._coerceAll(self._extractCreations(dataSets))\n        edited = self._coerceAll(self._extractEdits(dataSets))\n\n        coerceDeferred = gatherResults([created, edited])\n        def cbCoerced((created, edited)):\n            receivedIdentifiers = set()\n\n            createObjects = []\n            for (identifier, dataSet) in created:\n                receivedIdentifiers.add(identifier)\n                createObjects.append(\n                    CreateObject(dataSet, makeSetter(identifier, dataSet)))\n\n            editObjects = []\n            for (identifier, dataSet) in edited:\n                receivedIdentifiers.add(identifier)\n                lastValues = self._lastValues[identifier]\n                if dataSet != lastValues:\n                    modelObject = self._objectFromID(identifier)\n                    editObjects.append(EditObject(modelObject, dataSet))\n                    self._lastValues[identifier] = dataSet\n\n            deleted = []\n            for identifier in set(self._idsToObjects) - receivedIdentifiers:\n                existing = self._objectFromID(identifier)\n                if existing is not self._NO_OBJECT_MARKER:\n                    deleted.append(existing)\n                self._idsToObjects.pop(identifier)\n\n            return ListChanges(createObjects, editObjects, deleted)\n\n        coerceDeferred.addCallback(cbCoerced)\n        return coerceDeferred"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fromInputs(self, inputs):\n        outputs = []\n        for i in xrange(self.count):\n            name = self.name + '_' + str(i)\n            try:\n                value = inputs[name][0]\n            except KeyError:\n                raise ConfigurationError(\n                    \"Missing value for field %d of %s\" % (i, self.name))\n            else:\n                outputs.append(maybeDeferred(self.coercer, value))\n        return gatherResults(outputs)", "response": "Extract the inputs associated with this parameter from the given dictionary and coerce them using self. coercer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clone(self, choices):\n        return self.__class__(\n            self.name,\n            choices,\n            self.label,\n            self.description,\n            self.multiple,\n            self.viewFactory)", "response": "Make a copy of this parameter supply different choices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nswitch to the compact variant of the live form template.", "response": "def compact(self):\n        \"\"\"\n        Switch to the compact variant of the live form template.\n\n        By default, this will simply create a loader for the\n        C{self.compactFragmentName} template and compact all of this form's\n        parameters.\n        \"\"\"\n        self.docFactory = webtheme.getLoader(self.compactFragmentName)\n        for param in self.parameters:\n            param.compact()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a liveform suitable for nesting within another form.", "response": "def asSubForm(self, name):\n        \"\"\"\n        Make a form suitable for nesting within another form (a subform) out\n        of this top-level liveform.\n\n        @param name: the name of the subform within its parent.\n        @type name: C{unicode}\n\n        @return: a subform.\n        @rtype: L{LiveForm}\n        \"\"\"\n        self.subFormName = name\n        self.jsClass = _SUBFORM_JS_CLASS\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef submitbutton(self, request, tag):\n        return tags.input(type='submit',\n                          name='__submit__',\n                          value=self._getDescription())", "response": "Render an INPUT element of type SUBMIT which will post this form to the\n        server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender the inputs for a form.", "response": "def form(self, request, tag):\n        \"\"\"\n        Render the inputs for a form.\n\n        @param tag: A tag with:\n            - I{form} and I{description} slots\n            - I{liveform} and I{subform} patterns, to fill the I{form} slot\n                - An I{inputs} slot, to fill with parameter views\n            - L{IParameterView.patternName}I{-input-container} patterns for\n              each parameter type in C{self.parameters}\n        \"\"\"\n        patterns = PatternDictionary(self.docFactory)\n        inputs = []\n\n        for parameter in self.parameters:\n            view = parameter.viewFactory(parameter, None)\n            if view is not None:\n                view.setDefaultTemplate(\n                    tag.onePattern(view.patternName + '-input-container'))\n                setFragmentParent = getattr(view, 'setFragmentParent', None)\n                if setFragmentParent is not None:\n                    setFragmentParent(self)\n                inputs.append(view)\n            else:\n                inputs.append(_legacySpecialCases(self, patterns, parameter))\n\n        if self.subFormName is None:\n            pattern = tag.onePattern('liveform')\n        else:\n            pattern = tag.onePattern('subform')\n\n        return dictFillSlots(\n            tag,\n            dict(form=pattern.fillSlots('inputs', inputs),\n                 description=self._getDescription()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninvoking my callable with input from the browser.", "response": "def invoke(self, formPostEmulator):\n        \"\"\"\n        Invoke my callable with input from the browser.\n\n        @param formPostEmulator: a dict of lists of strings in a format like a\n            cgi-module form post.\n        \"\"\"\n        result = self.fromInputs(formPostEmulator)\n        result.addCallback(lambda params: self.callable(**params))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromInputs(self, received):\n        results = []\n        for parameter in self.parameters:\n            name = parameter.name.encode('ascii')\n            d = maybeDeferred(parameter.fromInputs, received)\n            d.addCallback(lambda value, name=name: (name, value))\n            results.append(d)\n        return gatherResults(results).addCallback(dict)", "response": "Convert some random strings received from a browser into structured\n            data using a list of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender the label of the wrapped parameter or choice parameter instance.", "response": "def label(self, request, tag):\n        \"\"\"\n        Render the label of the wrapped L{Parameter} or L{ChoiceParameter} instance.\n        \"\"\"\n        if self.parameter.label:\n            tag[self.parameter.label]\n        return tag"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender the description of the wrapped instance.", "response": "def description(self, request, tag):\n        \"\"\"\n        Render the description of the wrapped L{Parameter} instance.\n        \"\"\"\n        if self.parameter.description is not None:\n            tag[self.parameter.description]\n        return tag"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef realForm(self, req, tag):\n        self.liveForm.setFragmentParent(self)\n        return self.liveForm", "response": "Returns the real form that is used for this tag."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default(self, request, tag):\n        if self.parameter.default is not None:\n            tag[self.parameter.default]\n        return tag", "response": "Render the default value of the wrapped L { Parameter instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef selected(self, request, tag):\n        if self.option.selected:\n            tag(selected='selected')\n        return tag", "response": "Render a selected attribute on the given tag if the wrapped option is selected."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multiple(self, request, tag):\n        if self.parameter.multiple:\n            tag(multiple='multiple')\n        return tag", "response": "Render a I { multiple attribute on the given tag if the parameter allows multiple selection."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders each of the options of the wrapped parameter.", "response": "def options(self, request, tag):\n        \"\"\"\n        Render each of the options of the wrapped L{ChoiceParameter} instance.\n        \"\"\"\n        option = tag.patternGenerator('option')\n        return tag[[\n                OptionView(index, o, option())\n                for (index, o)\n                in enumerate(self.parameter.choices)]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forms(self, req, tag):\n        liveForms = self.parameter.getInitialLiveForms()\n        for liveForm in liveForms:\n            liveForm.setFragmentParent(self)\n        return liveForms", "response": "Make and return some subforms using the parameter s getInitialLiveForms method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes and return a form using self. parameter. asLiveForm.", "response": "def repeatForm(self):\n        \"\"\"\n        Make and return a form, using L{self.parameter.asLiveForm}.\n\n        @return: a subform.\n        @rtype: L{LiveForm}\n        \"\"\"\n        liveForm = self.parameter.asLiveForm()\n        liveForm.setFragmentParent(self)\n        return liveForm"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef repeater(self, req, tag):\n        repeater = inevow.IQ(self.docFactory).onePattern('repeater')\n        return repeater.fillSlots(\n            'object-description', self.parameter.modelObjectDescription)", "response": "Render some UI for repeating our form."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef input(self, request, tag):\n        subform = self.parameter.form.asSubForm(self.parameter.name)\n        subform.setFragmentParent(self)\n        return tag[subform]", "response": "Add the wrapped form as a subform of the given tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the known ra/decs of the channel corners into unit vectors. This code creates the conents of the function loadOriginVectors() (below)", "response": "def generateVectors():\n    \"\"\"Convert the known ra/decs of the channel corners\n    into unit vectors. This code creates the conents of the\n    function loadOriginVectors() (below)\n    \"\"\"\n\n    ra_deg = 290.66666667\n    dec_deg = +44.5\n    #rollAngle_deg = 33.0\n    rollAngle_deg = +123.\n    boresight = r.vecFromRaDec(ra_deg, dec_deg)\n\n    #Read in prime mission coords and convert to vectors\n    inFile = \"../etc/fov.txt\"\n    inFile = np.loadtxt(inFile)\n    radecs = np.zeros( (len(inFile), 3))\n    rotate = radecs*0\n    for i, row in enumerate(inFile):\n        radecs[i, :] = r.vecFromRaDec(inFile[i, 4], inFile[i,5])\n        rotate[i, :] = r.rotateAroundVector(radecs[i], boresight,\\\n            -rollAngle_deg)\n\n\n\n\n    #Slew to ra/dec of zero\n    Ra = r.rightAscensionRotationMatrix(-ra_deg)\n    Rd = r.declinationRotationMatrix(-dec_deg)\n    R = np.dot(Rd, Ra)\n    origin = rotate*0\n    for i, row in enumerate(rotate):\n        origin[i] = np.dot(R, rotate[i])\n\n    mp.plot(origin[:,0], origin[:,1])\n\n    #Print out the results\n    #import pdb; pdb.set_trace()\n    print(\"[\")\n    for i in range(len(inFile)):\n        ch = channelFromModOut(inFile[i,0], inFile[i,1])\n        print(\"[%3i., %3i., %3i., %13.7f, %13.7f, %13.7f], \\\\\" %( \\\n            inFile[i, 0], inFile[i, 1], ch, \\\n            origin[i, 0], origin[i, 1], origin[i,2]))\n    print(\"]\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nobtain bus arrival info in target stop.", "response": "def get_arrive_stop(self, **kwargs):\n        \"\"\"Obtain bus arrival info in target stop.\n\n        Args:\n            stop_number (int): Stop number to query.\n            lang (str): Language code (*es* or *en*).\n\n        Returns:\n            Status boolean and parsed response (list[Arrival]), or message string\n            in case of error.\n        \"\"\"\n        # Endpoint parameters\n        params = {\n            'idStop': kwargs.get('stop_number'),\n            'cultureInfo': util.language_code(kwargs.get('lang'))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_arrive_stop', **params)\n\n        # Funny endpoint, no status code\n        if not util.check_result(result, 'arrives'):\n            return False, 'UNKNOWN ERROR'\n\n        # Parse\n        values = util.response_list(result, 'arrives')\n        return True, [emtype.Arrival(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nobtain line types and details.", "response": "def get_groups(self, **kwargs):\n        \"\"\"Obtain line types and details.\n\n        Args:\n            lang (str): Language code (*es* or *en*).\n\n        Returns:\n            Status boolean and parsed response (list[GeoGroupItem]), or message\n            string in case of error.\n        \"\"\"\n        # Endpoint parameters\n        params = {\n            'cultureInfo': util.language_code(kwargs.get('lang'))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_groups', **params)\n\n        if not util.check_result(result):\n            return False, result.get('resultDescription', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'resultValues')\n        return True, [emtype.GeoGroupItem(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_info_line(self, **kwargs):\n        # Endpoint parameters\n        select_date = '%02d/%02d/%d' % (\n            kwargs.get('day', '01'),\n            kwargs.get('month', '01'),\n            kwargs.get('year', '1970')\n        )\n\n        params = {\n            'fecha': select_date,\n            'line': util.ints_to_string(kwargs.get('lines', [])),\n            'cultureInfo': util.language_code(kwargs.get('lang'))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_info_line', **params)\n\n        # Funny endpoint, no status code\n        if not util.check_result(result, 'Line'):\n            return False, 'UNKNOWN ERROR'\n\n        # Parse\n        values = util.response_list(result, 'Line')\n        return True, [emtype.Line(**a) for a in values]", "response": "Obtain basic information on a given line on a given date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_poi(self, **kwargs):\n        # Endpoint parameters\n        params = {\n            'coordinateX': kwargs.get('longitude'),\n            'coordinateY': kwargs.get('latitude'),\n            'tipos': util.ints_to_string(kwargs.get('types')),\n            'Radius': kwargs.get('radius'),\n            'cultureInfo': util.language_code(kwargs.get('lang'))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_poi', **params)\n\n        # Funny endpoint, no status code\n        if not util.check_result(result, 'poiList'):\n            return False, 'UNKNOWN ERROR'\n\n        # Parse\n        values = util.response_list(result, 'poiList')\n        return True, [emtype.Poi(**a) for a in values]", "response": "Obtain a list of POI in the given radius."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nobtaining POI types. Args: lang (str): Language code (*es* or *en*). Returns: Status boolean and parsed response (list[PoiType]), or message string in case of error.", "response": "def get_poi_types(self, **kwargs):\n        \"\"\"Obtain POI types.\n\n        Args:\n            lang (str): Language code (*es* or *en*).\n\n        Returns:\n            Status boolean and parsed response (list[PoiType]), or message string\n            in case of error.\n        \"\"\"\n        # Endpoint parameters\n        params = {\n            'cultureInfo': util.language_code(kwargs.get('lang'))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_poi_types', **params)\n\n        # Parse\n        values = result.get('types', [])\n        return True, [emtype.PoiType(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_route_lines_route(self, **kwargs):\n        # Endpoint parameters\n        select_date = '%02d/%02d/%d' % (\n            kwargs.get('day', '01'),\n            kwargs.get('month', '01'),\n            kwargs.get('year', '1970')\n        )\n\n        params = {\n            'SelectDate': select_date,\n            'Lines': util.ints_to_string(kwargs.get('lines', []))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_route_lines_route', **params)\n\n        if not util.check_result(result):\n            return False, result.get('resultDescription', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'resultValues')\n        return True, [emtype.RouteLinesItem(**a) for a in values]", "response": "Obtain the route lines for one or more lines in the given date."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_stops_line(self, **kwargs):\n        # Endpoint parameters\n        params = {\n            'line': util.ints_to_string(kwargs.get('lines', [])),\n            'direction': util.direction_code(kwargs.get('direction', '')),\n            'cultureInfo': util.language_code(kwargs.get('lang'))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_stops_line', **params)\n\n        # Funny endpoint, no status code\n        # Only interested in 'stop'\n        if not util.check_result(result, 'stop'):\n            return False, 'UNKNOWN ERROR'\n\n        # Parse\n        values = util.response_list(result, 'stop')\n        return True, [emtype.Stop(**a) for a in values]", "response": "This method returns information on the stops of the given lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_street(self, **kwargs):\n        # Endpoint parameters\n        params = {\n            'description': kwargs.get('street_name'),\n            'streetNumber': kwargs.get('street_number'),\n            'Radius': kwargs.get('radius'),\n            'Stops': kwargs.get('stops'),\n            'cultureInfo': util.language_code(kwargs.get('lang'))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_street', **params)\n\n        # Funny endpoint, no status code\n        if not util.check_result(result, 'site'):\n            return False, 'UNKNOWN ERROR'\n\n        # Parse\n        values = util.response_list(result, 'site')\n        return True, [emtype.Site(**a) for a in values]", "response": "Obtain a list of nodes related to a given location within a given radius."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nobtaining a list of streets around the specified point.", "response": "def get_street_from_xy(self, **kwargs):\n        \"\"\"Obtain a list of streets around the specified point.\n\n        Args:\n            latitude (double): Latitude in decimal degrees.\n            longitude (double): Longitude in decimal degrees.\n            radius (int): Radius (in meters) of the search.\n            lang (str): Language code (*es* or *en*).\n\n        Returns:\n            Status boolean and parsed response (list[Street]), or message string\n            in case of error.\n        \"\"\"\n        # Endpoint parameters\n        params = {\n            'coordinateX': kwargs.get('longitude'),\n            'coordinateY': kwargs.get('latitude'),\n            'Radius': kwargs.get('radius'),\n            'cultureInfo': util.language_code(kwargs.get('lang'))\n        }\n\n        # Request\n        result = self.make_request('geo', 'get_street_from_xy', **params)\n\n        # Funny endpoint, no status code\n        if not util.check_result(result, 'site'):\n            return False, 'UNKNOWN ERROR'\n\n        # Parse\n        values = util.response_list(result, 'site')\n        return True, [emtype.Street(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nharvest funders from FundRef and store as authority records.", "response": "def harvest_fundref(source=None):\n    \"\"\"Harvest funders from FundRef and store as authority records.\"\"\"\n    loader = LocalFundRefLoader(source=source) if source \\\n        else RemoteFundRefLoader()\n    for funder_json in loader.iter_funders():\n        register_funder.delay(funder_json)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef harvest_openaire_projects(source=None, setspec=None):\n    loader = LocalOAIRELoader(source=source) if source \\\n        else RemoteOAIRELoader(setspec=setspec)\n    for grant_json in loader.iter_grants():\n        register_grant.delay(grant_json)", "response": "Harvest grants from OpenAIRE and store as authority records."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a funder or grant.", "response": "def create_or_update_record(data, pid_type, id_key, minter):\n    \"\"\"Register a funder or grant.\"\"\"\n    resolver = Resolver(\n        pid_type=pid_type, object_type='rec', getter=Record.get_record)\n\n    try:\n        pid, record = resolver.resolve(data[id_key])\n        data_c = deepcopy(data)\n        del data_c['remote_modified']\n        record_c = deepcopy(record)\n        del record_c['remote_modified']\n        # All grants on OpenAIRE are modified periodically even if nothing\n        # has changed. We need to check for actual differences in the metadata\n        if data_c != record_c:\n            record.update(data)\n            record.commit()\n            record_id = record.id\n            db.session.commit()\n            RecordIndexer().index_by_id(str(record_id))\n    except PIDDoesNotExistError:\n        record = Record.create(data)\n        record_id = record.id\n        minter(record.id, data)\n        db.session.commit()\n        RecordIndexer().index_by_id(str(record_id))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef IS(instance, other):  # noqa\n    try:\n        instance = instance._redpipe_future_result  # noqa\n    except AttributeError:\n        pass\n\n    try:\n        other = other._redpipe_future_result\n    except AttributeError:\n        pass\n\n    return instance is other", "response": "Return True if the object is other."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if an object is an object of the correct type.", "response": "def ISINSTANCE(instance, A_tuple):  # noqa\n    \"\"\"\n    Allows you to do isinstance checks on futures.\n    Really, I discourage this because duck-typing is usually better.\n    But this can provide you with a way to use isinstance with futures.\n    Works with other objects too.\n\n    :param instance:\n    :param A_tuple:\n    :return:\n    \"\"\"\n    try:\n        instance = instance._redpipe_future_result\n    except AttributeError:\n        pass\n\n    return isinstance(instance, A_tuple)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _json_default_encoder(func):\n    @wraps(func)\n    def inner(self, o):\n        try:\n            return o._redpipe_future_result  # noqa\n        except AttributeError:\n            pass\n        return func(self, o)\n\n    return inner", "response": "A default encoder for the base class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef suspendJustTabProviders(installation):\n    if installation.suspended:\n        raise RuntimeError(\"Installation already suspended\")\n    powerups = list(installation.allPowerups)\n    for p in powerups:\n        if INavigableElement.providedBy(p):\n            p.store.powerDown(p, INavigableElement)\n            sne = SuspendedNavigableElement(store=p.store, originalNE=p)\n            p.store.powerUp(sne, INavigableElement)\n            p.store.powerUp(sne, ISuspender)\n    installation.suspended = True", "response": "Suspends all providers in the given installation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves suspension facades and replace them with their originals.", "response": "def unsuspendTabProviders(installation):\n    \"\"\"\n    Remove suspension facades and replace them with their originals.\n    \"\"\"\n    if not installation.suspended:\n        raise RuntimeError(\"Installation not suspended\")\n    powerups = list(installation.allPowerups)\n    allSNEs = list(powerups[0].store.powerupsFor(ISuspender))\n    for p in powerups:\n        for sne in allSNEs:\n            if sne.originalNE is p:\n                p.store.powerDown(sne, INavigableElement)\n                p.store.powerDown(sne, ISuspender)\n                p.store.powerUp(p, INavigableElement)\n                sne.deleteFromStore()\n    installation.suspended = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a numpy array of the rows name", "response": "def rows(self):\n        \"\"\"Returns a numpy array of the rows name\"\"\"\n        bf = self.copy()\n        result = bf.query.executeQuery(format=\"soa\")\n        return result[\"_rowName\"]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the rowCount and valueCount of the current object", "response": "def shape(self):\n        \"\"\"\n        Returns (rowCount, valueCount)\n        \"\"\"\n        bf = self.copy()\n        content = requests.get(bf.dataset_url).json()\n        rowCount = content['status']['rowCount']\n        valueCount = content['status']['valueCount']\n\n        return (rowCount, valueCount)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _binary_arithemtic(self, left, binary, right):\n        if isinstance(right, (int, float)):\n            right = right\n        elif isinstance(right, Column):\n            right = right.execution_name\n        else:\n            raise AttributeError(\n                \"{} can only be used \".format(binary)\n                + \"with integer, float or column\")\n\n        if isinstance(left, (int, float)):\n            left = left\n        elif isinstance(left, Column):\n            left = left.execution_name\n        else:\n            raise AttributeError(\n                \"{} can only be used \".format(binary)\n                + \"with integer, float or column\")\n\n        copy = self.copy()\n        copy.query.removeSELECT(\"{}\".format(copy.execution_name))\n        if binary == '^':  # POWER needs a different treatment\n            copy.execution_name = \"pow({},{})\".format(left, right)\n        else:\n            copy.execution_name = \"{}{}{}\".format(left, binary, right)\n        copy.query.addSELECT(copy.execution_name)\n\n        return copy", "response": "Internal method that returns a copy of the table with the same execution_name and the same binary arithmetic operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of this instance with the specified unary arithmetic operator applied to the current instance and the new instance.", "response": "def _unary_arithmetic(self, unary):\n        \"\"\"\n        Parameters\n        ----------\n        unary: char\n            Unary arithmetic operator (-, +) to be applied to this column\n\n        Returns\n        -------\n        self\n\n        Notes\n        -----\n        Returning self will allow the next object to use this column ops and\n        concatenate something else\n        \"\"\"\n        copy = self.copy()\n        copy.query.removeSELECT(\"{}\".format(copy.execution_name))\n        copy.execution_name = \"{}({})\".format(unary, self.execution_name)\n        copy.query.addSELECT(copy.execution_name)\n\n        return copy"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns first n rows", "response": "def head(self, n=5):\n        \"\"\"Returns first n rows\"\"\"\n        col = self.copy()\n        col.query.setLIMIT(n)\n        return col.toPandas()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_tsv(output_stream, *tup, **kwargs):\n    encoding = kwargs.get('encoding') or 'utf-8'\n    value = '\\t'.join([s for s in tup]) + '\\n'\n    output_stream.write(value.encode(encoding))", "response": "Writes a list of strings to a tab - seperated row."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_tsv(input_stream, cols=None, encoding='utf-8'):\n    if cols:\n        cols = [c if not c in ('x', 'X', 0, None) else random_string(length=5)\n                for c in cols]\n        Record = collections.namedtuple('Record', cols)\n        for line in input_stream:\n            yield Record._make(line.decode(encoding).rstrip('\\n').split('\\t'))\n    else:\n        for line in input_stream:\n            yield tuple(line.decode(encoding).rstrip('\\n').split('\\t'))", "response": "Iterate over a TTY file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_authenticode_signed(filename):\n    with open(filename, 'rb') as fp:\n        fp.seek(0)\n        magic = fp.read(2)\n        if magic != b'MZ':\n            return False\n\n        # First grab the pointer to the coff_header, which is at offset 60\n        fp.seek(60)\n        coff_header_offset = struct.unpack('<L', fp.read(4))[0]\n\n        # Check the COFF magic\n        fp.seek(coff_header_offset)\n        magic = fp.read(4)\n        if magic != b'PE\\x00\\x00':\n            return False\n\n        # Get the PE type\n        fp.seek(coff_header_offset + 0x18)\n        pe_type = struct.unpack('<h', fp.read(2))[0]\n\n        if pe_type == 0x10b:\n            # PE32 file (32-bit apps)\n            number_of_data_dirs_offset = coff_header_offset + 0x74\n        elif pe_type == 0x20b:\n            # PE32+ files (64-bit apps)\n            # PE32+ files have slightly larger fields in the header\n            number_of_data_dirs_offset = coff_header_offset + 0x74 + 16\n        else:\n            return False\n\n        fp.seek(number_of_data_dirs_offset)\n        num_data_dirs = struct.unpack('<L', fp.read(4))[0]\n\n        if num_data_dirs < 5:\n            # Probably shouldn't happen, but just in case\n            return False\n\n        cert_table_offset = number_of_data_dirs_offset + 4*8 + 4\n        fp.seek(cert_table_offset)\n        addr, size = struct.unpack('<LL', fp.read(8))\n        if not addr or not size:\n            return False\n        # Check that addr is inside the file\n        fp.seek(addr)\n        if fp.tell() != addr:\n            return False\n        cert = fp.read(size)\n        if len(cert) != size:\n            return False\n        return True", "response": "Returns True if the file is signed with authenticode"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse command line options and return a new parser.", "response": "def parse_cmdln_opts(parser, cmdln_args):\n    \"\"\"Rather than have this all clutter main(), let's split this out.\n    Clean arch decision: rather than parsing sys.argv directly, pass\n    sys.argv[1:] to this function (or any iterable for testing.)\n    \"\"\"\n    parser.set_defaults(\n        hosts=[],\n        cert=None,\n        log_level=logging.INFO,\n        output_dir=None,\n        output_file=None,\n        formats=[],\n        includes=[],\n        excludes=[],\n        nsscmd=None,\n        tokenfile=None,\n        noncefile=None,\n        cachedir=None,\n    )\n\n    parser.add_option(\n        \"-H\", \"--host\", dest=\"hosts\", action=\"append\", help=\"format[:format]:hostname[:port]\")\n    parser.add_option(\"-c\", \"--server-cert\", dest=\"cert\")\n    parser.add_option(\"-t\", \"--token-file\", dest=\"tokenfile\",\n                      help=\"file where token is stored\")\n    parser.add_option(\"-n\", \"--nonce-file\", dest=\"noncefile\",\n                      help=\"file where nonce is stored\")\n    parser.add_option(\"-d\", \"--output-dir\", dest=\"output_dir\",\n                      help=\"output directory; if not set then files are \"\n                      \"replaced with signed copies\")\n    parser.add_option(\"-o\", \"--output-file\", dest=\"output_file\",\n                      help=\"output file; if not set then files are replaced with signed \"\n                      \"copies. This can only be used when signing a single file\")\n    parser.add_option(\"-f\", \"--formats\", dest=\"formats\", action=\"append\",\n                      help=\"signing formats (one or more of %s)\" % \", \".join(ALLOWED_FORMATS))\n    parser.add_option(\"-q\", \"--quiet\", dest=\"log_level\", action=\"store_const\",\n                      const=logging.WARN)\n    parser.add_option(\n        \"-v\", \"--verbose\", dest=\"log_level\", action=\"store_const\",\n        const=logging.DEBUG)\n    parser.add_option(\"-i\", \"--include\", dest=\"includes\", action=\"append\",\n                      help=\"add to include patterns\")\n    parser.add_option(\"-x\", \"--exclude\", dest=\"excludes\", action=\"append\",\n                      help=\"add to exclude patterns\")\n    parser.add_option(\"--nsscmd\", dest=\"nsscmd\",\n                      help=\"command to re-sign nss libraries, if required\")\n    parser.add_option(\"--cachedir\", dest=\"cachedir\",\n                      help=\"local cache directory\")\n    # TODO: Concurrency?\n    # TODO: Different certs per server?\n\n    options, args = parser.parse_args(cmdln_args)\n\n    if not options.hosts:\n        parser.error(\"at least one host is required\")\n\n    if not options.cert:\n        parser.error(\"certificate is required\")\n\n    if not os.path.exists(options.cert):\n        parser.error(\"certificate not found\")\n\n    if not options.tokenfile:\n        parser.error(\"token file is required\")\n\n    if not options.noncefile:\n        parser.error(\"nonce file is required\")\n\n    # Covert nsscmd to win32 path if required\n    if sys.platform == 'win32' and options.nsscmd:\n        nsscmd = options.nsscmd.strip()\n        if nsscmd.startswith(\"/\"):\n            drive = nsscmd[1]\n            options.nsscmd = \"%s:%s\" % (drive, nsscmd[2:])\n\n    # Handle format\n    formats = []\n    for fmt in options.formats:\n        if \",\" in fmt:\n            for fmt in fmt.split(\",\"):\n                if fmt not in ALLOWED_FORMATS:\n                    parser.error(\"invalid format: %s\" % fmt)\n                formats.append(fmt)\n        elif fmt not in ALLOWED_FORMATS:\n            parser.error(\"invalid format: %s\" % fmt)\n        else:\n            formats.append(fmt)\n\n    # bug 1382882, 1164456\n    # Widevine and GPG signing must happen last because they will be invalid if\n    # done prior to any format that modifies the file in-place.\n    for fmt in (\"widevine\", \"widevine_blessed\", \"gpg\"):\n        if fmt in formats:\n            formats.remove(fmt)\n            formats.append(fmt)\n\n    if options.output_file and (len(args) > 1 or os.path.isdir(args[0])):\n        parser.error(\n            \"-o / --output-file can only be used when signing a single file\")\n\n    if options.output_dir:\n        if os.path.exists(options.output_dir):\n            if not os.path.isdir(options.output_dir):\n                parser.error(\n                    \"output_dir (%s) must be a directory\", options.output_dir)\n        else:\n            os.makedirs(options.output_dir)\n\n    if not options.includes:\n        # Do everything!\n        options.includes.append(\"*\")\n\n    if not formats:\n        parser.error(\"no formats specified\")\n\n    options.formats = formats\n\n    format_urls = defaultdict(list)\n    for h in options.hosts:\n        # The last two parts of a host is the actual hostname:port. Any parts\n        # before that are formats - there could be 0..n formats so this is\n        # tricky to split.\n        parts = h.split(\":\")\n        h = parts[-2:]\n        fmts = parts[:-2]\n        # If no formats are specified, the host is assumed to support all of them.\n        if not fmts:\n            fmts = formats\n\n        for f in fmts:\n            format_urls[f].append(\"https://%s\" % \":\".join(h))\n    options.format_urls = format_urls\n\n    missing_fmt_hosts = set(formats) - set(format_urls.keys())\n    if missing_fmt_hosts:\n        parser.error(\"no hosts capable of signing formats: %s\" % \" \".join(missing_fmt_hosts))\n\n    return options, args"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary specifying the details of all campaigns.", "response": "def _getCampaignDict():\n    \"\"\"Returns a dictionary specifying the details of all campaigns.\"\"\"\n    global _campaign_dict_cache\n    if _campaign_dict_cache is None:\n        # All pointing parameters and dates are stored in a JSON file\n        fn = os.path.join(PACKAGEDIR, \"data\", \"k2-campaign-parameters.json\")\n        _campaign_dict_cache = json.load(open(fn))\n    return _campaign_dict_cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getFieldInfo(fieldnum):\n    try:\n        info = _getCampaignDict()[\"c{0}\".format(fieldnum)]\n        # Print warning messages if necessary\n        if \"preliminary\" in info and info[\"preliminary\"] == \"True\":\n            logger.warning(\"Warning: the position of field {0} is preliminary. \"\n                           \"Do not use this position for your final \"\n                           \"target selection!\".format(fieldnum))\n        return info\n    except KeyError:\n        raise ValueError(\"Field {0} not set in this version \"\n                         \"of the code\".format(fieldnum))", "response": "Returns a dictionary containing the metadata of a K2 Campaign field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getKeplerFov(fieldnum):\n    info = getFieldInfo(fieldnum)\n    ra, dec, scRoll = info[\"ra\"], info[\"dec\"], info[\"roll\"]\n    # convert from SC roll to FOV coordinates\n    # do not use the fovRoll coords anywhere else\n    # they are internal to this script only\n    fovRoll = fov.getFovAngleFromSpacecraftRoll(scRoll)\n    # KeplerFov takes a listen of broken CCD channels as optional argument;\n    # these channels will be ignored during plotting and on-silicon determination.\n    # Modules 3 and 7 broke prior to the start of K2:\n    brokenChannels = [5, 6, 7, 8,  17, 18, 19, 20]\n    # Module 4 failed during Campaign 10\n    if fieldnum > 10:\n        brokenChannels.extend([9, 10, 11, 12])\n    # Hack: the Kepler field is defined as \"Campaign 1000\"\n    # and (initially) had no broken channels\n    if fieldnum == 1000:\n        brokenChannels = []\n\n    return fov.KeplerFov(ra, dec, fovRoll, brokenChannels=brokenChannels)", "response": "Returns a fov. KeplerFov object for a given K2 campaign."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef indexer_receiver(sender, json=None, record=None, index=None,\n                     **dummy_kwargs):\n    \"\"\"Connect to before_record_index signal to transform record for ES.\"\"\"\n    if index and index.startswith('grants-'):\n        # Generate suggest field\n        suggestions = [\n            json.get('code'),\n            json.get('acronym'),\n            json.get('title')\n        ]\n        json['suggest'] = {\n            'input': [s for s in suggestions if s],\n            'output': json['title'],\n            'context': {\n                'funder': [json['funder']['doi']]\n            },\n            'payload': {\n                'id': json['internal_id'],\n                'legacy_id': (json['code'] if json.get('program') == 'FP7'\n                              else json['internal_id']),\n                'code': json['code'],\n                'title': json['title'],\n                'acronym': json.get('acronym'),\n                'program': json.get('program'),\n            },\n        }\n    elif index and index.startswith('funders-'):\n        # Generate suggest field\n        suggestions = json.get('acronyms', []) + [json.get('name')]\n        json['suggest'] = {\n            'input': [s for s in suggestions if s],\n            'output': json['name'],\n            'payload': {\n                'id': json['doi']\n            },\n        }", "response": "Connect to before_record_index signal to transform record for ES."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_calendar(self, **kwargs):\n        # Endpoint parameters\n        start_date = util.date_string(\n            kwargs.get('start_day', '01'),\n            kwargs.get('start_month', '01'),\n            kwargs.get('start_year', '1970')\n        )\n\n        end_date = util.date_string(\n            kwargs.get('end_day', '01'),\n            kwargs.get('end_month', '01'),\n            kwargs.get('end_year', '1970')\n        )\n\n        params = {'SelectDateBegin': start_date, 'SelectDateEnd': end_date}\n\n        # Request\n        result = self.make_request('bus', 'get_calendar', **params)\n\n        if not util.check_result(result):\n            return False, result.get('resultDescription', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'resultValues')\n        return True, [emtype.CalendarItem(**a) for a in values]", "response": "Obtain EMT calendar for a range of dates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nobtaining stop IDs coordinates and line information.", "response": "def get_nodes_lines(self, **kwargs):\n        \"\"\"Obtain stop IDs, coordinates and line information.\n\n        Args:\n            nodes (list[int] | int): nodes to query, may be empty to get\n                all nodes.\n\n        Returns:\n            Status boolean and parsed response (list[NodeLinesItem]), or message\n            string in case of error.\n        \"\"\"\n        # Endpoint parameters\n        params = {'Nodes': util.ints_to_string(kwargs.get('nodes', []))}\n\n        # Request\n        result = self.make_request('bus', 'get_nodes_lines', **params)\n\n        if not util.check_result(result):\n            return False, result.get('resultDescription', 'UNKNOWN ERROR')\n\n        # Parse\n        values = util.response_list(result, 'resultValues')\n        return True, [emtype.NodeLinesItem(**a) for a in values]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef beforeRender(self, ctx):\n        request = IRequest(ctx)\n        root = self.webSite.rootURL(request)\n        self._moduleRoot = root.child('__jsmodule__')", "response": "Called before the render operation is performed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getJSModuleURL(self, moduleName):\n        if self._moduleRoot is None:\n            raise NotImplementedError(\n                \"JS module URLs cannot be requested before rendering.\")\n        moduleHash = self.hashCache.getModule(moduleName).hashValue\n        return self._moduleRoot.child(moduleHash).child(moduleName)", "response": "Retrieves an absolute URL which references the given module name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef produceResource(self, request, segments, webViewer):\n        def thunk():\n            cr = getattr(self, 'createResource', None)\n            if cr is not None:\n                return cr()\n            else:\n                return self.createResourceWith(webViewer)\n        return self._produceIt(segments, thunk)", "response": "Produce a resource for the given set of segments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _produceIt(self, segments, thunk):\n        if not self.prefixURL:\n            needle = ()\n        else:\n            needle = tuple(self.prefixURL.split('/'))\n        S = len(needle)\n        if segments[:S] == needle:\n            if segments == JUST_SLASH:\n                # I *HATE* THE WEB\n                subsegments = segments\n            else:\n                subsegments = segments[S:]\n            res = thunk()\n            # Even though the URL matched up, sometimes we might still\n            # decide to not handle this request (eg, some prerequisite\n            # for our function is not met by the store).  Allow None\n            # to be returned by createResource to indicate this case.\n            if res is not None:\n                return res, subsegments", "response": "This method is used to produce a resource from the given segments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef installSite(self):\n        for iface, priority in self.__getPowerupInterfaces__([]):\n            self.store.powerUp(self, iface, priority)", "response": "Installs the site into the dependency system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef makeStylesheetResource(self, path, registry):\n        return StylesheetRewritingResourceWrapper(\n            File(path), self.installedOfferingNames, self.rootURL)", "response": "Make a resource for the given path with its urls rewritten\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering the resource through a L { StylesheetRewritingRequestWrapper. }.", "response": "def renderHTTP(self, context):\n        \"\"\"\n        Render C{self.resource} through a L{StylesheetRewritingRequestWrapper}.\n        \"\"\"\n        request = IRequest(context)\n        request = StylesheetRewritingRequestWrapper(\n            request, self.installedOfferingNames, self.rootURL)\n        context.remember(request, IRequest)\n        return self.resource.renderHTTP(context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _replace(self, url):\n        segments = url.split('/')\n        if segments[0] == '':\n            root = self.rootURL(self.request)\n            if segments[1] == 'Mantissa':\n                root = root.child('static').child('mantissa-base')\n                segments = segments[2:]\n            elif segments[1] in self.installedOfferingNames:\n                root = root.child('static').child(segments[1])\n                segments = segments[2:]\n            for seg in segments:\n                root = root.child(seg)\n            return str(root)\n        return url", "response": "Replace the URL with absolute paths so they are rooted at the correct locations."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the buffered response body and write the result to the wrapped request and finish the wrapped request.", "response": "def finish(self):\n        \"\"\"\n        Parse the buffered response body, rewrite its URLs, write the result to\n        the wrapped request, and finish the wrapped request.\n        \"\"\"\n        stylesheet = ''.join(self._buffer)\n        parser = CSSParser()\n        css = parser.parseString(stylesheet)\n        replaceUrls(css, self._replace)\n        self.request.write(css.cssText)\n        return self.request.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cleartextRoot(self, hostname=None):\n        warnings.warn(\n            \"Use ISiteURLGenerator.rootURL instead of WebSite.cleartextRoot.\",\n            category=DeprecationWarning,\n            stacklevel=2)\n        if self.store.parent is not None:\n            generator = ISiteURLGenerator(self.store.parent)\n        else:\n            generator = ISiteURLGenerator(self.store)\n        return generator.cleartextRoot(hostname)", "response": "Return a string representing the HTTP URL which is at the root of this ArcGIS site."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rootURL(self, request):\n        warnings.warn(\n            \"Use ISiteURLGenerator.rootURL instead of WebSite.rootURL.\",\n            category=DeprecationWarning,\n            stacklevel=2)\n        if self.store.parent is not None:\n            generator = ISiteURLGenerator(self.store.parent)\n        else:\n            generator = ISiteURLGenerator(self.store)\n        return generator.rootURL(request)", "response": "Simple utility function to provide a root URL for this website which is\n            appropriate to use in links generated in response to the given request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rootChild_resetPassword(self, req, webViewer):\n        from xmantissa.ixmantissa import IWebTranslator, IPreferenceAggregator\n        return URL.fromString(\n            IWebTranslator(self.store).linkTo(\n                IPreferenceAggregator(self.store).storeID))", "response": "Redirect authenticated users to their settings page when they try to reset their password."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the API key for the named API.", "response": "def getKeyForAPI(cls, siteStore, apiName):\n        \"\"\"\n        Get the API key for the named API, if one exists.\n\n        @param siteStore: The site store.\n        @type siteStore: L{axiom.store.Store}\n\n        @param apiName: The name of the API.\n        @type apiName: C{unicode} (L{APIKey} constant)\n\n        @rtype: L{APIKey} or C{NoneType}\n        \"\"\"\n        return siteStore.findUnique(\n            cls, cls.apiName == apiName, default=None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the API key for the named API.", "response": "def setKeyForAPI(cls, siteStore, apiName, apiKey):\n        \"\"\"\n        Set the API key for the named API, overwriting any existing key.\n\n        @param siteStore: The site store to install the key in.\n        @type siteStore: L{axiom.store.Store}\n\n        @param apiName: The name of the API.\n        @type apiName: C{unicode} (L{APIKey} constant)\n\n        @param apiKey: The key for accessing the API.\n        @type apiKey: C{unicode}\n\n        @rtype: L{APIKey}\n        \"\"\"\n        existingKey = cls.getKeyForAPI(siteStore, apiName)\n        if existingKey is None:\n            return cls(store=siteStore, apiName=apiName, apiKey=apiKey)\n        existingKey.apiKey = apiKey\n        return existingKey"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the root URL for the resource hierarchy for the given request.", "response": "def rootURL(self, request):\n        \"\"\"\n        Return the URL for the root of this website which is appropriate to use\n        in links generated in response to the given request.\n\n        @type request: L{twisted.web.http.Request}\n        @param request: The request which is being responded to.\n\n        @rtype: L{URL}\n        @return: The location at which the root of the resource hierarchy for\n            this website is available.\n        \"\"\"\n        host = request.getHeader('host') or self.hostname\n        if ':' in host:\n            host = host.split(':', 1)[0]\n        for domain in [self.hostname] + getDomainNames(self.store):\n            if (host == domain or\n                host.startswith('www.') and host[len('www.'):] == domain):\n                return URL(scheme='', netloc='', pathsegs=[''])\n        if request.isSecure():\n            return self.encryptedRoot(self.hostname)\n        else:\n            return self.cleartextRoot(self.hostname)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an L{AxiomSite } which supports authenticated and anonymous access.", "response": "def getFactory(self):\n        \"\"\"\n        Create an L{AxiomSite} which supports authenticated and anonymous\n        access.\n        \"\"\"\n        checkers = [self.loginSystem, AllowAnonymousAccess()]\n        guardedRoot = PersistentSessionWrapper(\n            self.store,\n            Portal(self.loginSystem, checkers),\n            domains=[self.hostname])\n        unguardedRoot = UnguardedWrapper(self.store, guardedRoot)\n        securingRoot = SecuringWrapper(self, unguardedRoot)\n        logPath = None\n        if self.httpLog is not None:\n            logPath = self.httpLog.path\n        return AxiomSite(self.store, securingRoot, logPath=logPath)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef child_static(self, context):\n        offeringTech = IOfferingTechnician(self.siteStore)\n        installedOfferings = offeringTech.getInstalledOfferings()\n        offeringsWithContent = dict([\n                (offering.name, offering.staticContentPath)\n                for offering\n                in installedOfferings.itervalues()\n                if offering.staticContentPath])\n\n        # If you wanted to do CSS rewriting for all CSS files served beneath\n        # /static/, you could do it by passing a processor for \".css\" here.\n        # eg:\n        #\n        # website = IResource(self.store)\n        # factory = StylesheetFactory(\n        #     offeringsWithContent.keys(), website.rootURL)\n        # StaticContent(offeringsWithContent, {\n        #               \".css\": factory.makeStylesheetResource})\n        return StaticContent(offeringsWithContent, {})", "response": "Serve a container page for Mantissa and other offerings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlocates a child or a statically defined child.", "response": "def locateChild(self, context, segments):\n        \"\"\"\n        Return a statically defined child or a child defined by a sessionless\n        site root plugin or an avatar from guard.\n        \"\"\"\n        shortcut = getattr(self, 'child_' + segments[0], None)\n        if shortcut:\n            res = shortcut(context)\n            if res is not None:\n                return res, segments[1:]\n\n        req = IRequest(context)\n        for plg in self.siteStore.powerupsFor(ISessionlessSiteRootPlugin):\n            spr = getattr(plg, 'sessionlessProduceResource', None)\n            if spr is not None:\n                childAndSegments = spr(req, segments)\n            else:\n                childAndSegments = plg.resourceFactory(segments)\n            if childAndSegments is not None:\n                return childAndSegments\n\n        return self.guardedRoot.locateChild(context, segments)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlocate the child resource.", "response": "def locateChild(self, context, segments):\n        \"\"\"\n        Unwrap the wrapped resource if HTTPS is already being used, otherwise\n        wrap it in a helper which will preserve the wrapping all the way down\n        to the final resource.\n        \"\"\"\n        request = IRequest(context)\n        if request.isSecure():\n            return self.wrappedResource, segments\n        return _SecureWrapper(self.urlGenerator, self.wrappedResource), segments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef renderHTTP(self, context):\n        request = IRequest(context)\n        if request.isSecure():\n            renderer = self.wrappedResource\n        else:\n            renderer = _SecureWrapper(self.urlGenerator, self.wrappedResource)\n        return renderer.renderHTTP(context)", "response": "Render the wrapped resource if HTTPS is being used otherwise invoke a helper which may generate a redirect."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef locateChild(self, context, segments):\n        childDeferred = maybeDeferred(\n            self.wrappedResource.locateChild, context, segments)\n        def childLocated((resource, segments)):\n            if (resource, segments) == NotFound:\n                return NotFound\n            return _SecureWrapper(self.urlGenerator, resource), segments\n        childDeferred.addCallback(childLocated)\n        return childDeferred", "response": "Delegate child lookup to the wrapped resource but wrap whatever results\n        in another instance of this wrapper."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders the resource using the HTTP protocol.", "response": "def renderHTTP(self, context):\n        \"\"\"\n        Check to see if the wrapped resource wants to be rendered over HTTPS\n        and generate a redirect if this is so, if HTTPS is available, and if\n        the request is not already over HTTPS.\n        \"\"\"\n        if getattr(self.wrappedResource, 'needsSecure', False):\n            request = IRequest(context)\n            url = self.urlGenerator.encryptedRoot()\n            if url is not None:\n                for seg in request.prepath:\n                    url = url.child(seg)\n                return url\n        return self.wrappedResource.renderHTTP(context)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlocate the child file for the given segments.", "response": "def locateChild(self, context, segments):\n        \"\"\"\n        Find the offering with the name matching the first segment and return a\n        L{File} for its I{staticContentPath}.\n        \"\"\"\n        name = segments[0]\n        try:\n            staticContent = self.staticPaths[name]\n        except KeyError:\n            return NotFound\n        else:\n            resource = File(staticContent.path)\n            resource.processors = self.processors\n            return resource, segments[1:]\n        return NotFound"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a single request object and returns the raw response", "response": "def handle_single_request(self, request_object):\n        \"\"\"\n        Handles a single request object and returns the raw response\n\n        :param request_object:\n        \"\"\"\n        if not isinstance(request_object, (MethodCall, Notification)):\n            raise TypeError(\"Invalid type for request_object\")\n\n        method_name = request_object.method_name\n        params = request_object.params\n        req_id = request_object.id\n\n        request_body = self.build_request_body(method_name, params, id=req_id)\n        http_request = self.build_http_request_obj(request_body)\n\n        try:\n            response = urllib.request.urlopen(http_request)\n        except urllib.request.HTTPError as e:\n            raise CalledServiceError(e)\n\n        if not req_id:\n            return\n\n        response_body = json.loads(response.read().decode())\n        return response_body"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls the method_name_or_object method from the given service and returns a Result instance.", "response": "def call_method(self, method_name_or_object, params=None):\n        \"\"\"\n        Calls the ``method_name`` method from the given service and returns a\n        :py:class:`gemstone.client.structs.Result` instance.\n\n        :param method_name_or_object: The name of te called method or a ``MethodCall`` instance\n        :param params: A list of dict representing the parameters for the request\n        :return: a :py:class:`gemstone.client.structs.Result` instance.\n        \"\"\"\n        if isinstance(method_name_or_object, MethodCall):\n            req_obj = method_name_or_object\n        else:\n            req_obj = MethodCall(method_name_or_object, params)\n        raw_response = self.handle_single_request(req_obj)\n        response_obj = Result(result=raw_response[\"result\"], error=raw_response['error'],\n                              id=raw_response[\"id\"], method_call=req_obj)\n        return response_obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling the method_name method from the given service asynchronously and returns a : py : class : ~gemstone. client. structs. AsyncMethodCall instance.", "response": "def call_method_async(self, method_name_or_object, params=None):\n        \"\"\"\n        Calls the ``method_name`` method from the given service asynchronously\n        and returns a :py:class:`gemstone.client.structs.AsyncMethodCall` instance.\n\n        :param method_name_or_object: The name of te called method or a ``MethodCall`` instance\n        :param params: A list of dict representing the parameters for the request\n        :return: a :py:class:`gemstone.client.structs.AsyncMethodCall` instance.\n        \"\"\"\n        thread_pool = self._get_thread_pool()\n\n        if isinstance(method_name_or_object, MethodCall):\n            req_obj = method_name_or_object\n        else:\n            req_obj = MethodCall(method_name_or_object, params)\n\n        async_result_mp = thread_pool.apply_async(self.handle_single_request, args=(req_obj,))\n        return AsyncMethodCall(req_obj=req_obj, async_resp_object=async_result_mp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a notification to the service by calling the method_name_or_object with the params parameters.", "response": "def notify(self, method_name_or_object, params=None):\n        \"\"\"\n        Sends a notification to the service by calling the ``method_name``\n        method with the ``params`` parameters. Does not wait for a response, even\n        if the response triggers an error.\n\n        :param method_name_or_object: the name of the method to be called or a ``Notification``\n                                      instance\n        :param params: a list of dict representing the parameters for the call\n        :return: None\n        \"\"\"\n        if isinstance(method_name_or_object, Notification):\n            req_obj = method_name_or_object\n        else:\n            req_obj = Notification(method_name_or_object, params)\n        self.handle_single_request(req_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_single_request(self, request_object):\n        # don't handle responses?\n        if isinstance(request_object, JsonRpcResponse):\n            return request_object\n\n        error = None\n        result = None\n        id_ = request_object.id\n\n        # validate method name\n        if request_object.method not in self.methods:\n            resp = GenericResponse.METHOD_NOT_FOUND\n            resp.id = id_\n            return resp\n\n        # check for private access\n        method = self.methods[request_object.method]\n\n        if isinstance(request_object.params, (list, tuple)):\n            self.call_method_from_all_plugins(\"on_method_call\", request_object)\n        else:\n            self.call_method_from_all_plugins(\"on_method_call\", request_object)\n\n        if self._method_is_private(method):\n            if not self.get_current_user():\n                resp = GenericResponse.ACCESS_DENIED\n                resp.id = id_\n                return resp\n\n        method = self.prepare_method_call(method, request_object.params)\n\n        # before request hook\n        _method_duration = time.time()\n\n        try:\n            result = yield self.call_method(method)\n        except Exception as e:\n            # catch all exceptions generated by method\n            # and handle in a special manner only the TypeError\n            if isinstance(e, TypeError):\n                # TODO: find a proper way to check that the function got the wrong\n                # parameters (with **kwargs)\n                if \"got an unexpected keyword argument\" in e.args[0]:\n                    resp = GenericResponse.INVALID_PARAMS\n                    resp.id = id_\n                    return resp\n                # TODO: find a proper way to check that the function got the wrong\n                # parameters (with *args)\n                elif \"takes\" in e.args[0] and \"positional argument\" in e.args[0] and \"were given\" in \\\n                        e.args[0]:\n                    resp = GenericResponse.INVALID_PARAMS\n                    resp.id = id_\n                    return resp\n                elif \"missing\" in e.args[0] and \"required positional argument\" in e.args[0]:\n                    resp = GenericResponse.INVALID_PARAMS\n                    resp.id = id_\n                    return resp\n            # generic handling for any exception (even TypeError) that\n            # is not generated because of bad parameters\n\n            self.call_method_from_all_plugins(\"on_internal_error\", e)\n\n            err = GenericResponse.INTERNAL_ERROR\n            err.id = id_\n            err.error[\"data\"] = {\n                \"class\": type(e).__name__,\n                \"info\": str(e)\n            }\n            return err\n\n        to_return_resp = JsonRpcResponse(result=result, error=error, id=id_)\n\n        return to_return_resp", "response": "Handles a single request object and returns the correct result as follows"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a single response object to the response_obj.", "response": "def write_single_response(self, response_obj):\n        \"\"\"\n        Writes a json rpc response ``{\"result\": result, \"error\": error, \"id\": id}``.\n        If the ``id`` is ``None``, the response will not contain an ``id`` field.\n        The response is sent to the client as an ``application/json`` response. Only one call per\n        response is allowed\n\n        :param response_obj: A Json rpc response object\n        :return:\n        \"\"\"\n        if not isinstance(response_obj, JsonRpcResponse):\n            raise ValueError(\n                \"Expected JsonRpcResponse, but got {} instead\".format(type(response_obj).__name__))\n\n        if not self.response_is_sent:\n            self.set_status(200)\n            self.set_header(\"Content-Type\", \"application/json\")\n            self.finish(response_obj.to_string())\n            self.response_is_sent = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps a method so that it will call method with args or method ( ** args depending of args type", "response": "def prepare_method_call(self, method, args):\n        \"\"\"\n        Wraps a method so that method() will call ``method(*args)`` or ``method(**args)``,\n        depending of args type\n\n        :param method: a callable object (method)\n        :param args: dict or list with the parameters for the function\n        :return: a 'patched' callable\n        \"\"\"\n        if self._method_requires_handler_ref(method):\n            if isinstance(args, list):\n                args = [self] + args\n            elif isinstance(args, dict):\n                args[\"handler\"] = self\n\n        if isinstance(args, list):\n            to_call = partial(method, *args)\n        elif isinstance(args, dict):\n            to_call = partial(method, **args)\n        else:\n            raise TypeError(\n                \"args must be list or dict but got {} instead\".format(type(args).__name__))\n        return to_call"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call_method(self, method):\n        if self._method_is_async_generator(method):\n            result = yield method()\n        else:\n            result = yield self.executor.submit(method)\n        return result", "response": "Calls the method in an executor and returns the result of the method."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if a method is an async generator.", "response": "def _method_is_async_generator(self, method):\n        \"\"\"\n        Given a simple callable or a callable wrapped in funtools.partial, determines\n        if it was wrapped with the :py:func:`gemstone.async_method` decorator.\n        \n        :param method:\n        :return:\n        \"\"\"\n        if hasattr(method, \"func\"):\n            func = method.func\n        else:\n            func = method\n\n        return getattr(func, \"_is_coroutine\", False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a cygwin path into a windows style path", "response": "def cygpath(filename):\n    \"\"\"Convert a cygwin path into a windows style path\"\"\"\n    if sys.platform == 'cygwin':\n        proc = Popen(['cygpath', '-am', filename], stdout=PIPE)\n        return proc.communicate()[0].strip()\n    else:\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a srcpath return a corresponding path within dstdir", "response": "def convertPath(srcpath, dstdir):\n    \"\"\"Given `srcpath`, return a corresponding path within `dstdir`\"\"\"\n    bits = srcpath.split(\"/\")\n    bits.pop(0)\n    # Strip out leading 'unsigned' from paths like unsigned/update/win32/...\n    if bits[0] == 'unsigned':\n        bits.pop(0)\n    return os.path.join(dstdir, *bits)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef finddirs(root):\n    retval = []\n    for root, dirs, files in os.walk(root):\n        for d in dirs:\n            retval.append(os.path.join(root, d))\n    return retval", "response": "Return a list of all the directories under root"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _realGetLoader(n, default=_marker):\n    for t in getAllThemes():\n        fact = t.getDocFactory(n, None)\n        if fact is not None:\n            return fact\n    if default is _marker:\n        raise RuntimeError(\"No loader for %r anywhere\" % (n,))\n    return default", "response": "Get a loader for a template named n."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _realGetAllThemes(self):\n        l = []\n        for offering in getOfferings():\n            l.extend(offering.themes)\n        l.sort(key=lambda o: o.priority)\n        l.reverse()\n        return l", "response": "Collect themes from all available offerings."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncollects themes from all available offerings or return previously collected ones.", "response": "def getAllThemes(self):\n        \"\"\"\n        Collect themes from all available offerings, or (if called\n        multiple times) return the previously collected list.\n        \"\"\"\n        if self._getAllThemesCache is None:\n            self._getAllThemesCache = self._realGetAllThemes()\n        return self._getAllThemesCache"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _realGetInstalledThemes(self, store):\n        l = []\n        for offering in getInstalledOfferings(store).itervalues():\n            l.extend(offering.themes)\n        l.sort(key=lambda o: o.priority)\n        l.reverse()\n        return l", "response": "Collect themes from all installed offerings on this store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getInstalledThemes(self, store):\n        if not store in self._getInstalledThemesCache:\n            self._getInstalledThemesCache[store] = (self.\n                                                 _realGetInstalledThemes(store))\n        return self._getInstalledThemesCache[store]", "response": "Collect themes from all offerings installed on this store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlocate a L { nevow. iervow. IDocFactory object with the given name from the site store and return it. If the name is not found return default.", "response": "def getDocFactory(self, name, default=None):\n        \"\"\"\n        Locate a L{nevow.inevow.IDocFactory} object with the given name from\n        the themes installed on the site store and return it.\n        \"\"\"\n        loader = None\n        for theme in getInstalledThemes(self.siteStore):\n            loader = theme.getDocFactory(name)\n            if loader is not None:\n                return loader\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef head(self, request, website):\n        stylesheet = self.stylesheetLocation\n        if stylesheet is not None:\n            root = website.rootURL(request)\n            for segment in stylesheet:\n                root = root.child(segment)\n            return tags.link(rel='stylesheet', type='text/css', href=root)", "response": "Returns the content to include in the head of the document."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getDocFactory(self, fragmentName, default=None):\n        if fragmentName in self.cachedLoaders:\n            return self.cachedLoaders[fragmentName]\n        segments = fragmentName.split('/')\n        segments[-1] += '.html'\n        file = self.directory\n        for segment in segments:\n            file = file.child(segment)\n        if file.exists():\n            loader = xmlfile(file.path)\n            self.cachedLoaders[fragmentName] = loader\n            return loader\n        return default", "response": "Returns a loader for a given fragment name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rend(self, context, data):\n        if self.docFactory is None:\n            self.docFactory = self.getDocFactory(self.fragmentName)\n        return super(_ThemedMixin, self).rend(context, data)", "response": "Retrieve my docFactory based on the fragmentName and call the super class rend."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a zoom block", "response": "def make_zoom_block(min,max,count,colorkeyfields,bounds,filter_file_dictionary):\n\n\tif min == '' and max == '' and not bounds == True:\n\t\treturn ''\n\n\n\tif colorkeyfields == False and bounds == False:\n\t\tblock = '''\n\t\tmap.on('zoomend', function(e) {\n\t\t\tif ( (map.getZoom() >= %s)&&(map.getZoom() <= %s) ){ \n\t\t\t\tif (map.hasLayer(dataLayer) != true) {\n\t\t\t\t\tadd%s()\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\telse { map.removeLayer( dataLayer ) }\n\t\t})''' % (str(min),str(max),str(count))\n\telif bounds == True:\n\t\tif min == '' and max == '':\n\t\t\tmin,max = [0,20]\n\t\tif filter_file_dictionary == False:\n\t\t\tblock = '''\n\tmap.on('dragend',function(e) {\n\t\tvar outerbounds = [[map.getBounds()._southWest.lng,map.getBounds()._northEast.lat],[map.getBounds()._northEast.lng,map.getBounds()._southWest.lat]]\n\t\tvar outerbounds = L.bounds(outerbounds[0],outerbounds[1]);\n\t\tdataLayer.eachLayer(function(layer) {\n\t\t\tif (((outerbounds.contains(layer.feature.properties['bounds']) == true)||(outerbounds.intersects(layer.feature.properties['bounds']) == true))&&((map.getZoom() >= %s)&&(map.getZoom() <= %s))) { \n\t\t\t\tlayer.addTo(map) \n\t\t\t\tconsole.log('added')\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif ( dataLayer.hasLayer(layer) == true ) {\n\t\t\t\t\tmap.removeLayer(layer)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t});''' % (str(min),str(max))\n\t\telse:\n\t\t\tblock = make_zoom_block_filter(min,max,filter_file_dictionary)\n\t\n\n\n\n\n\t# section below is for if colorkey fields are implemented, currently not supported \n\t# however this code below can be a good start maybe\n\t\"\"\"\n\telse:\n\t\tblock = '''\n\tmap.on('zoomend', function(e) {\n\t\tif ( (map.getZoom() >= %s)&&(map.getZoom() <= %s) ){ \n\t\t\tif (map.hasLayer(dataLayer) != true) {\n\t\t\t\tmap.addLayer(dataLayer)\t\t\n\t\t\t}\n\t\t}\n\t\telse { map.removeLayer( dataLayer ) }\n\t})\n\tmap.on('click',function(e) {\n\t\tvar skillsSelect = document.getElementById(\"mapStyle\");\n\t\tvar selectedText2 = skillsSelect.options[skillsSelect.selectedIndex].text;\n\t\tvar selectedText2 = 'COLORKEY_' + selectedText2;\t\n\t\tif ( (map.getZoom() >= %s)&&(map.getZoom() <= %s)&&(selectedText2 != selectedText)){ \n\t\t\t\t// map.addLayer(dataLayer)\n\t\t\tdataLayer.eachLayer(function (layer) {\t\t\t\n\t\t\t\tvar style = {color: layer.feature.properties[selectedText2], weight: 6, opacity: 1}\n\t\t\t\tlayer.setStyle(style)\n\t\t\t});\n\t\t}\n\t\telse { \n\t\t\t}\n\t\tvar selectedText = selectedText2;\n\t\tconsole.log(selectedText)\n\t\n\t})''' % (str(min),str(max),str(min),str(max))\n\t\"\"\"\n\treturn block"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef making_blockstr(varblock,count,colorline,element,zoomblock,filename,sidebarstring,colorkeyfields):\n\t# starting wrapper that comes before html table code\n\t'''\n\tif not colorkeyfields == False:\n\t\tstart = \"\"\"\\n\\tfunction addDataToMap%s(data, map) {\\t\\tvar skillsSelect = document.getElementById(\"mapStyle\");\\n\\t\\tvar selectedText = skillsSelect.options[skillsSelect.selectedIndex].text;\\n\\t\\tvar selectedText = 'COLORKEY_' + selectedText\\n\\t\\tvar dataLayer = L.geoJson(data, {\\n\\t\\t\\tonEachFeature: function(feature, layer) {\"\"\" % (count)\n\telse:\n\t'''\t\n\tstart = \"\"\"\\n\\tfunction addDataToMap%s(data, map) {\\n\\t\\tvar dataLayer = L.geoJson(data, {\\n\\t\\t\\tonEachFeature: function(feature, layer) {\"\"\" % (count)\n\n    # ending wrapper that comes after html table code\n\tif count == 1 and colorkeyfields == False:\n\t\tend = \"\"\"\n\t\t            layer.bindPopup(popupText, {autoPan:false, maxHeight:500, maxWidth:350} ); }\n\t        });\n\t    dataLayer.addTo(map);\n\tconsole.log(map.fitBounds(dataLayer.getBounds()))};\\n\\t};\"\"\"\n\telse:\n\t\tend = \"\"\"\n\t\t            layer.bindPopup(popupText, {autoPan:false, maxHeight:500, maxWidth:350} ); }\n\t        });\n\t    dataLayer.addTo(map);\n\t\\n\\t};\\n\\t}\"\"\"\n\n\n\t'''\n\telse:\n\t\tend=\"\"\"\n\t            layer.bindPopup(popupText, {autoPan:false, maxHeight:500, maxWidth:350} ); };\n        });\n    \tdataLayer.addTo(map);\\nconsole.log(map.fitBounds(dataLayer.getBounds()));\\n\\t\\tsetTimeout(function() {\\n\\t\\t\\t\\tdataLayer.clearLayers();\\n\\t\\t},%s);\\n\\t}\\n}\\nsetInterval(add%s,%s)\"\"\" % (time,count,time)\n\t'''\n\t# iterates through each varblock and returns the entire bindings javascript block\n\ttotal = ''\n\n\t# logic for appending check_dropdown line to zoomblock\n\tif not zoomblock == '' and not colorkeyfields == False:\n\t\tpass\n\n\t# logic for replacing the datalayer add to line with the zoom text block\n\tif not zoomblock == '':\n\t\tend = end.replace('dataLayer.addTo(map);',zoomblock)\n\n\n\tfor row in varblock:\n\t\ttotal += row\n\n\tif element == 'Point':\n\t\treturn start + total + colorline + sidebarstring + end\n\telse:\n\t\treturn start + total + '\\n' + colorline + sidebarstring + end", "response": "make a block of text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_bindings_type(filenames,color_input,colorkey,file_dictionary,sidebar,bounds):\n\t# instantiating string the main string block for the javascript block of html code\n\tstring = ''\n\n\t'''\n\t# logic for instantiating variable colorkey input \n\tif not colorkeyfields == False:\n\t\tcolorkey = 'selectedText'\n\t'''\n\n\t# iterating through each geojson filename\n\tcount = 0\n\tfor row in filenames:\n\t\tcolor_input = ''\n\t\tcolorkeyfields = False\n\t\tcount += 1\n\t\tfilename = row\n\t\tzoomrange = ['','']\n\t\t# reading in geojson file into memory\n\t\twith open(filename) as data_file:    \n   \t\t\tdata = json.load(data_file)\n   \t\t#pprint(data)\n\n   \t\t# getting the featuretype which will later dictate what javascript splices are needed\n   \t\tdata = data['features']\n   \t\tdata = data[0]\n   \t\tfeaturetype = data['geometry']\n   \t\tfeaturetype = featuretype['type']\n\t\tdata = data['properties']\n\n\n\t\t# logic for overwriting colorkey fields if it exists for the filename \n\t\t# in the file dictionary\n\t\ttry:\n\t\t\tcolorkeyfields = file_dictionary[filename][str('colorkeyfields')]\n\t\texcept KeyError:\n\t\t\tcolorkeyfields = False\n\t\texcept TypeError:\n\t\t\tcolorkeyfields = False\n\n\t\tif not colorkeyfields == False:\n\t\t\tif len(colorkeyfields) == 1:\n\t\t\t\tcolorkey = colorkeyfields[0]\n\t\t\t\tcolorkeyfields = False\n\n\t\ttry:\n\t\t\tzoomrange = file_dictionary[filename][str('zooms')]\n\t\texcept KeyError:\n\t\t\tzoomrange = ['','']\n\t\texcept TypeError:\n\t\t\tzoomrange = ['','']\n\n\n\n\t\t# code for if the file_dictionary input isn't false \n\t\t#(i.e. getting the color inputs out of dictionary variable)\n\t\tif file_dictionary==False and colorkey == False:\t\t\t\n\t\t\t# logic for getting the colorline for different feature types\n\t\t\t# the point feature requires a different line of code\n\t\t\tif featuretype == 'Point':\n\t\t\t\tcolorline = get_colorline_marker(color_input)\n\t\t\telse:\n\t\t\t\tcolorline = get_colorline_marker2(color_input)\n\n\n\n\t\t# setting minzoom and maxzoom to be sent into js parsing \n\t\tminzoom,maxzoom = zoomrange\n\n\t\t# getting filter file dictionary if filter_dictonary exists\n\t\tif not file_dictionary == False:\n\t\t\tfilter_file_dictionary = file_dictionary[filename]\n\t\telse:\n\t\t\tfilter_file_dictionary = False \n\n\t\t# checking to see if a chart_dictionary exists\n\t\ttry: \n\t\t\tchart_dictionary = filter_file_dictionary['chart_dictionary']\n\t\texcept KeyError:\n\t\t\tchart_dictionary = False\n\t\texcept TypeError:\n\t\t\tchart_dictionary = False\n\n\n\t\t# sending min and max zoom into the function that makes the zoom block\n\t\tzoomblock = make_zoom_block(minzoom,maxzoom,count,colorkeyfields,bounds,filter_file_dictionary)\n\n\t\t# logic for if a color key is given \n\t\t# HINT look here for rgb raw color integration in a color line\n   \t\tif not colorkey == '':\n   \t\t\tif row == filenames[0]:\n   \t\t\t\tif colorkey == 'selectedText':\n   \t\t\t\t\tcolorkey = \"\"\"feature.properties[%s]\"\"\" % colorkey\n   \t\t\t\telse:\n   \t\t\t\t\tcolorkey = \"\"\"feature.properties['%s']\"\"\" % colorkey\n   \t\t\tif featuretype == 'Point':\n   \t\t\t\tcolorline = get_colorline_marker(str(colorkey))\n   \t\t\telse:\n   \t\t\t\tcolorline = get_colorline_marker2(str(colorkey))\n\n\n   \t\t# this may be able to be deleted \n   \t\t# test later \n   \t\t# im not sure what the fuck its here for \n   \t\tif file_dictionary == False and colorkey == '':\n\t   \t\tif featuretype == 'Point':\n\t   \t\t\tcolorline = get_colorline_marker(color_input)\n\t   \t\telse:\n\t   \t\t\tcolorline = get_colorline_marker2(color_input)\n   \t\tif colorkey == '' and colorkeyfields == False:\n\t   \t\tif featuretype == 'Point':\n\t   \t\t\tcolorline = get_colorline_marker(color_input)\n\t   \t\telse:\n\t   \t\t\tcolorline = get_colorline_marker2(color_input)\n\n   \t\t# iterating through each header \n   \t\theaders = []\n   \t\tfor row in data:\n   \t\t\theaders.append(str(row))\n\n   \t\t# logic for getting sidebar string that will be added in make_blockstr()\n   \t\tif sidebar == True:\n   \t\t\tsidebarstring = make_sidebar_string(headers,chart_dictionary)\n   \t\telse:\n   \t\t\tsidebarstring = ''\n\n   \t\t# section of javascript code dedicated to the adding the data layer \n   \t\tif count == 1:\n\t   \t\tblocky = \"\"\"\n\tfunction add%s() { \n\t\\n\\tfunction addDataToMap%s(data, map) {\n\t\\t\\tvar dataLayer = L.geoJson(data);\n\t\\t\\tvar map = L.mapbox.map('map', 'mapbox.streets',{\n\t\\t\\t\\tzoom: 5\n\t\\t\\t\\t}).fitBounds(dataLayer.getBounds());\n\t\\t\\tdataLayer.addTo(map)\n\t\\t}\\n\"\"\" % (count,count)\n\t\telse:\n\t\t\tblocky = \"\"\"\n\tfunction add%s() { \n\t\\n\\tfunction addDataToMap%s(data, map) {\n\t\\t\\tvar dataLayer = L.geoJson(data);\n\t\\t\\tdataLayer.addTo(map)\n\t\\t}\\n\"\"\" % (count,count)\n\t\t\n\t\t# making the string section that locally links the geojson file to the html document\n\t\t'''\n\t\tif not time == '':\n\t\t\tpreloc='\\tfunction add%s() {\\n' % (str(count))\n\t\t\tloc = \"\"\"\\t$.getJSON('http://localhost:8000/%s',function(data) { addDataToMap%s(data,map); });\"\"\" % (filename,count)\n\t\t\tloc = preloc + loc\n\t\telse: \n\t\t'''\n\t\tloc = \"\"\"\\t$.getJSON('http://localhost:8000/%s',function(data) { addDataToMap%s(data,map); });\"\"\" % (filename,count)\t\t\t\n\t\t# creating block to be added to the total or constituent string block\n\t\tif featuretype == 'Point':\n\t\t\tbindings = make_bindings(headers,count,colorline,featuretype,zoomblock,filename,sidebarstring,colorkeyfields)+'\\n'\n\t\t\tstringblock = blocky + loc + bindings\n\t\telse:\n\t\t\tbindings = make_bindings(headers,count,colorline,featuretype,zoomblock,filename,sidebarstring,colorkeyfields)+'\\n'\n\t\t\tstringblock = blocky + loc + bindings\n\t\t\n\t\t# adding the stringblock (one geojson file javascript block) to the total string block\n\t\tstring += stringblock\n\n\t# adding async function to end of string block\n\tstring = string + async_function_call(count)\n\n\treturn string", "response": "creates the type of the bindings needed for the given color input colorkey and file_dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unpackexe(exefile, destdir):\n    nullfd = open(os.devnull, \"w\")\n    exefile = cygpath(os.path.abspath(exefile))\n    try:\n        check_call([SEVENZIP, 'x', exefile], cwd=destdir,\n                   stdout=nullfd, preexec_fn=_noumask)\n    except Exception:\n        log.exception(\"Error unpacking exe %s to %s\", exefile, destdir)\n        raise\n    nullfd.close()", "response": "Unpack the given exefile into destdir using 7z"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef packexe(exefile, srcdir):\n    exefile = cygpath(os.path.abspath(exefile))\n    appbundle = exefile + \".app.7z\"\n\n    # Make sure that appbundle doesn't already exist\n    # We don't want to risk appending to an existing file\n    if os.path.exists(appbundle):\n        raise OSError(\"%s already exists\" % appbundle)\n\n    files = os.listdir(srcdir)\n\n    SEVENZIP_ARGS = ['-r', '-t7z', '-mx', '-m0=BCJ2', '-m1=LZMA:d27',\n                     '-m2=LZMA:d19:mf=bt2', '-m3=LZMA:d19:mf=bt2', '-mb0:1', '-mb0s1:2',\n                     '-mb0s2:3', '-m1fb=128', '-m1lc=4']\n\n    # First, compress with 7z\n    stdout = tempfile.TemporaryFile()\n    try:\n        check_call([SEVENZIP, 'a'] + SEVENZIP_ARGS + [appbundle] + files,\n                   cwd=srcdir, stdout=stdout, preexec_fn=_noumask)\n    except Exception:\n        stdout.seek(0)\n        data = stdout.read()\n        log.error(data)\n        log.exception(\"Error packing exe %s from %s\", exefile, srcdir)\n        raise\n    stdout.close()\n\n    # Then prepend our stubs onto the compressed 7z data\n    o = open(exefile, \"wb\")\n    parts = [\n        'checkouts/stubs/7z/7zSD.sfx.compressed',\n        'checkouts/stubs/tagfile/app.tag',\n        appbundle\n    ]\n    for part in parts:\n        i = open(part)\n        while True:\n            block = i.read(4096)\n            if not block:\n                break\n            o.write(block)\n        i.close()\n    o.close()\n    os.unlink(appbundle)", "response": "Packs the files in srcdir into exefile using 7z"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unpackmar(marfile, destdir):\n    marfile = cygpath(os.path.abspath(marfile))\n    nullfd = open(os.devnull, \"w\")\n    try:\n        check_call([MAR, '-x', marfile], cwd=destdir,\n                   stdout=nullfd, preexec_fn=_noumask)\n    except Exception:\n        log.exception(\"Error unpacking mar file %s to %s\", marfile, destdir)\n        raise\n    nullfd.close()", "response": "Unpack marfile into destdir"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npacks a MAR file from the contents of srcdir", "response": "def packmar(marfile, srcdir):\n    \"\"\"Create marfile from the contents of srcdir\"\"\"\n    nullfd = open(os.devnull, \"w\")\n    files = [f[len(srcdir) + 1:] for f in findfiles(srcdir)]\n    marfile = cygpath(os.path.abspath(marfile))\n    try:\n        check_call(\n            [MAR, '-c', marfile] + files, cwd=srcdir, preexec_fn=_noumask)\n    except Exception:\n        log.exception(\"Error packing mar file %s from %s\", marfile, srcdir)\n        raise\n    nullfd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunpacks a tarball into a specified dir", "response": "def unpacktar(tarfile, destdir):\n    \"\"\" Unpack given tarball into the specified dir \"\"\"\n    nullfd = open(os.devnull, \"w\")\n    tarfile = cygpath(os.path.abspath(tarfile))\n    log.debug(\"unpack tar %s into %s\", tarfile, destdir)\n    try:\n        check_call([TAR, '-xzf', tarfile], cwd=destdir,\n                   stdout=nullfd, preexec_fn=_noumask)\n    except Exception:\n        log.exception(\"Error unpacking tar file %s to %s\", tarfile, destdir)\n        raise\n    nullfd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tar_dir(tarfile, srcdir):\n    files = os.listdir(srcdir)\n    packtar(tarfile, files, srcdir)", "response": "Pack a tar file using all the files in the given srcdir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef packtar(tarfile, files, srcdir):\n    nullfd = open(os.devnull, \"w\")\n    tarfile = cygpath(os.path.abspath(tarfile))\n    log.debug(\"pack tar %s from folder  %s with files \", tarfile, srcdir)\n    log.debug(files)\n    try:\n        check_call([TAR, '-czf', tarfile] + files, cwd=srcdir,\n                   stdout=nullfd, preexec_fn=_noumask)\n    except Exception:\n        log.exception(\"Error packing tar file %s to %s\", tarfile, srcdir)\n        raise\n    nullfd.close()", "response": "Pack the given files into a tar file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunpack a mar or exe into destdir", "response": "def unpackfile(filename, destdir):\n    \"\"\"Unpack a mar or exe into destdir\"\"\"\n    if filename.endswith(\".mar\"):\n        return unpackmar(filename, destdir)\n    elif filename.endswith(\".exe\"):\n        return unpackexe(filename, destdir)\n    elif filename.endswith(\".tar\") or filename.endswith(\".tar.gz\") \\\n            or filename.endswith(\".tgz\"):\n        return unpacktar(filename, destdir)\n    else:\n        raise ValueError(\"Unknown file type: %s\" % filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npacking a file into a single archive with 7z for exes or mar files", "response": "def packfile(filename, srcdir):\n    \"\"\"Package up srcdir into filename, archived with 7z for exes or mar for\n    mar files\"\"\"\n    if filename.endswith(\".mar\"):\n        return packmar(filename, srcdir)\n    elif filename.endswith(\".exe\"):\n        return packexe(filename, srcdir)\n    elif filename.endswith(\".tar\"):\n        return tar_dir(filename, srcdir)\n    else:\n        raise ValueError(\"Unknown file type: %s\" % filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _reorderForPreference(themeList, preferredThemeName):\n    for theme in themeList:\n        if preferredThemeName == theme.themeName:\n            themeList.remove(theme)\n            themeList.insert(0, theme)\n            return", "response": "Re - order the input themeList according to the preferred theme. Returns None if the preferred theme is not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupgrades a PrivateApplication from schema version 3 to schema version 4.", "response": "def upgradePrivateApplication3to4(old):\n    \"\"\"\n    Upgrade L{PrivateApplication} from schema version 3 to schema version 4.\n\n    Copy all existing attributes to the new version and use the\n    L{PrivateApplication} to power up the item it is installed on for\n    L{ITemplateNameResolver}.\n    \"\"\"\n    new = old.upgradeVersion(\n        PrivateApplication.typeName, 3, 4,\n        preferredTheme=old.preferredTheme,\n        privateKey=old.privateKey,\n        website=old.website,\n        customizedPublicPage=old.customizedPublicPage,\n        authenticationApplication=old.authenticationApplication,\n        preferenceAggregator=old.preferenceAggregator,\n        defaultPreferenceCollection=old.defaultPreferenceCollection,\n        searchAggregator=old.searchAggregator)\n    # Almost certainly this would be more correctly expressed as\n    # installedOn(new).powerUp(...), however the 2 to 3 upgrader failed to\n    # translate the installedOn attribute to state which installedOn can\n    # recognize, consequently installedOn(new) will return None for an item\n    # which was created at schema version 2 or earlier.  It's not worth dealing\n    # with this inconsistency, since PrivateApplication is always only\n    # installed on its store. -exarkun\n    new.store.powerUp(new, ITemplateNameResolver)\n    return new"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupgrade the newly required powerup.", "response": "def upgradePrivateApplication4to5(old):\n    \"\"\"\n    Install the newly required powerup.\n    \"\"\"\n    new = old.upgradeVersion(\n        PrivateApplication.typeName, 4, 5,\n        preferredTheme=old.preferredTheme,\n        privateKey=old.privateKey,\n        website=old.website,\n        customizedPublicPage=old.customizedPublicPage,\n        authenticationApplication=old.authenticationApplication,\n        preferenceAggregator=old.preferenceAggregator,\n        defaultPreferenceCollection=old.defaultPreferenceCollection,\n        searchAggregator=old.searchAggregator)\n    new.store.powerUp(new, IWebViewer)\n    return new"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _wrapNavFrag(self, frag, useAthena):\n        username = self._privateApplication._getUsername()\n        cf = getattr(frag, 'customizeFor', None)\n        if cf is not None:\n            frag = cf(username)\n        if useAthena:\n            pageClass = GenericNavigationAthenaPage\n        else:\n            pageClass = GenericNavigationPage\n        return pageClass(self._privateApplication, frag,\n                         self._privateApplication.getPageComponents(),\n                         username)", "response": "Wrap the given L { INavigableFragment in an appropriate base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_rootURL(self, ctx, data):\n        site = ISiteURLGenerator(self._siteStore())\n        return ctx.tag[site.rootURL(IRequest(ctx))]", "response": "Add the WebSite s root URL as a child of the given tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering start - menu style navigation.", "response": "def render_startmenu(self, ctx, data):\n        \"\"\"\n        Add start-menu style navigation to the given tag.\n\n        @see {xmantissa.webnav.startMenu}\n        \"\"\"\n        return startMenu(\n            self.translator, self.pageComponents.navigation, ctx.tag)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_settingsLink(self, ctx, data):\n        return settingsLink(\n            self.translator, self.pageComponents.settings, ctx.tag)", "response": "Render the settings link."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender the primary application navigation.", "response": "def render_applicationNavigation(self, ctx, data):\n        \"\"\"\n        Add primary application navigation to the given tag.\n\n        @see L{xmantissa.webnav.applicationNavigation}\n        \"\"\"\n        return applicationNavigation(\n            ctx, self.translator, self.pageComponents.navigation)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_urchin(self, ctx, data):\n        key = APIKey.getKeyForAPI(self._siteStore(), APIKey.URCHIN)\n        if key is None:\n            return ''\n        return ctx.tag.fillSlots('urchin-key', key.apiKey)", "response": "Render the code for recording the urchin API key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the beforeRender method on MantissaLivePage and _FragmentWrapperMixin to call beforeRender on _FragmentWrapperMixin.", "response": "def beforeRender(self, ctx):\n        \"\"\"\n        Call the C{beforeRender} implementations on L{MantissaLivePage} and\n        L{_FragmentWrapperMixin}.\n        \"\"\"\n        MantissaLivePage.beforeRender(self, ctx)\n        return _FragmentWrapperMixin.beforeRender(self, ctx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef childFactory(self, ctx, name):\n        try:\n            o = self.webapp.fromWebID(name)\n        except _WebIDFormatException:\n            return None\n        if o is None:\n            return None\n        return self.webViewer.wrapModel(o)", "response": "Return a shell page wrapped around the Item model described by the the\n        webID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _getUsername(self):\n        for (l, d) in getAccountNames(self.store):\n            return l + u'@' + d", "response": "Return a localpart@domain style string naming the owner of our store."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a URL which will point to the web facet of childItem with the selected nav tab being the one that represents parentItem.", "response": "def linkToWithActiveTab(self, childItem, parentItem):\n        \"\"\"\n        Return a URL which will point to the web facet of C{childItem},\n        with the selected nav tab being the one that represents C{parentItem}\n        \"\"\"\n        return self.linkTo(parentItem.storeID) + '/' + self.toWebID(childItem)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _preferredThemes(self):\n        themes = getInstalledThemes(self.store.parent)\n        _reorderForPreference(themes, self.preferredTheme)\n        return themes", "response": "Return a list of preferred themes for this user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves a Nevow document factory for the given name.", "response": "def getDocFactory(self, fragmentName, default=None):\n        \"\"\"\n        Retrieve a Nevow document factory for the given name.\n\n        @param fragmentName: a short string that names a fragment template.\n\n        @param default: value to be returned if the named template is not\n        found.\n        \"\"\"\n        themes = self._preferredThemes()\n        for t in themes:\n            fact = t.getDocFactory(fragmentName, None)\n            if fact is not None:\n                return fact\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch(self):\n        api = self.doapi_manager\n        return api._domain(api.request(self.url)[\"domain\"])", "response": "Fetch & return a new Domain object representing the current domain s current\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _record(self, obj):\n        return DomainRecord(obj, domain=self, doapi_manager=self.doapi_manager)", "response": "Construct a DomainRecord object belonging to the domain."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_all_records(self):\n        api = self.doapi_manager\n        return map(self._record, api.paginate(self.record_url, 'domain_records'))", "response": "r Returns a generator that yields all of the DNS records for the domain."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_record(self, type, name, data, priority=None, port=None,\n                      weight=None, **kwargs):\n        # pylint: disable=redefined-builtin\n        \"\"\"\n        Add a new DNS record to the domain\n\n        :param str type: the type of DNS record to add (``\"A\"``, ``\"CNAME\"``,\n            etc.)\n        :param str name: the name (hostname, alias, etc.) of the new record\n        :param str data: the value of the new record\n        :param int priority: the priority of the new record (SRV and MX records\n            only)\n        :param int port: the port that the service is accessible on (SRV\n            records only)\n        :param int weight: the weight of records with the same priority (SRV\n            records only)\n        :param kwargs: additional fields to include in the API request\n        :return: the new domain record\n        :rtype: DomainRecord\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        api = self.doapi_manager\n        data = {\n            \"type\": type,\n            \"name\": name,\n            \"data\": data,\n            \"priority\": priority,\n            \"port\": port,\n            \"weight\": weight,\n        }\n        data.update(kwargs)\n        return self._record(api.request(self.record_url, method='POST',\n                                        data=data)[\"domain_record\"])", "response": "Add a new DNS record to the domain record store."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch & return a new DomainRecord object representing the domain record s current state.", "response": "def fetch(self):\n        \"\"\"\n        Fetch & return a new `DomainRecord` object representing the domain\n        record's current state\n\n        :rtype: DomainRecord\n        :raises DOAPIError: if the API endpoint replies with an error (e.g., if\n            the domain record no longer exists)\n        \"\"\"\n        return self.domain._record(self.doapi_manager.request(self.url)\\\n                                                             [\"domain_record\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_record(self, **attrs):\n        # The `_record` is to avoid conflicts with MutableMapping.update.\n        \"\"\"\n        Update the record, modifying any number of its attributes (except\n        ``id``).  ``update_record`` takes the same keyword arguments as\n        :meth:`Domain.create_record`; pass in only those attributes that you\n        want to update.\n\n        :return: an updated `DomainRecord` object\n        :rtype: DomainRecord\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        return self.domain._record(self.doapi_manager.request(self.url,\n                                                              method='PUT',\n                                                              data=attrs)\\\n                                                             [\"domain_record\"])", "response": "Update the record with the given attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn true if increasing ra increases pix in skyToPix", "response": "def isPositiveMap(self):\n        \"\"\"Returns true if increasing ra increases pix in skyToPix()\n        \"\"\"\n        x0, y0 = self.skyToPix(self.ra0_deg, self.dec0_deg)\n        x1, y1 = self.skyToPix(self.ra0_deg + 1/3600., self.dec0_deg)\n\n        if x1 > x0:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the grid of the current state of the object.", "response": "def plotGrid(self, numLines=(5,5), lineWidth=1, colour=\"#777777\"):\n        \"\"\"Plot NUMLINES[0] vertical gridlines and NUMLINES[1] horizontal gridlines,\n        while keeping the initial axes bounds that were present upon its calling.\n        Will not work for certain cases.\n        \"\"\"\n        x1, x2, y1, y2 = mp.axis()\n        ra1, dec0 = self.pixToSky(x1, y1)\n        ra0, dec1 = self.pixToSky(x2, y2)\n\n        xNum, yNum = numLines\n        self.raRange, self.decRange  = self.getRaDecRanges(numLines)\n\n        #import pdb; pdb.set_trace()\n        #Guard against Ra of zero within the plot\n        a1 = np.abs(ra1-ra0)\n        a2 = np.abs( min(ra0, ra1) - (max(ra0, ra1) - 360))\n        if a2 < a1:     #Then we straddle 360 degrees in RA\n            if ra0 < ra1:\n                ra1 -= 360\n            else:\n                ra0 -= 360\n\n\n        #Draw lines of constant dec\n        lwr = min(ra0, ra1)\n        upr = max(ra0, ra1)\n        stepX = round((upr-lwr) / float(xNum))\n        ra_deg = np.arange(lwr - 3*stepX, upr + 3.5*stepX, 1, dtype=np.float)\n        for dec in self.decRange:\n            self.plotLine(ra_deg, dec, '-', color = colour, linewidth = lineWidth)\n\n\n        #Draw lines of const ra\n        lwr = min(dec0, dec1)\n        upr = max(dec0, dec1)\n        stepY = round((upr-lwr) / float(yNum))\n        dec_deg = np.arange(dec0 - 3*stepY, dec1 + 3.5*stepY, 1, dtype=np.float)\n        for ra in self.raRange:\n            self.plotLine(ra, dec_deg, '-', color = colour, linewidth = lineWidth)\n\n        mp.axis([x1, x2, y1, y2])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nputting labels on axes that are used for the logarithmic logarithm.", "response": "def labelAxes(self, numLines=(5,5)):\n        \"\"\"Put labels on axes\n\n        Note: I should do better than this by picking round numbers\n        as the places to put the labels.\n\n        Note: If I ever do rotated projections, this simple approach\n        will fail.\n        \"\"\"\n\n        x1, x2, y1, y2 = mp.axis()\n        ra1, dec0 = self.pixToSky(x1, y1)\n        raRange, decRange = self.getRaDecRanges(numLines)\n        ax = mp.gca()\n\n        x_ticks = self.skyToPix(raRange, dec0)[0]\n        y_ticks = self.skyToPix(ra1, decRange)[1]\n\n        ax.xaxis.set_ticks(x_ticks)\n        ax.xaxis.set_ticklabels([str(int(i)) for i in raRange])\n        mp.xlabel(\"Right Ascension (deg)\")\n\n        ax.yaxis.set_ticks(y_ticks)\n        ax.yaxis.set_ticklabels([str(int(i)) for i in decRange])\n        mp.ylabel(\"Declination (deg)\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getRaDecRanges(self, numLines):\n        x1, x2, y1, y2 = mp.axis()\n\n        ra0, dec0 = self.pixToSky(x1, y1)\n        ra1, dec1 = self.pixToSky(x2, y2)\n\n        #Deal with the case where ra range straddles 0.\n        #Different code for case where ra increases left to right, or decreases.\n        if self.isPositiveMap():\n            if ra1 < ra0:\n                ra1 += 360\n        else:\n            if ra0 < ra1:\n                ra0 += 360\n\n        raMid = .5*(ra0+ra1)\n        decMid = .5*(dec0+dec1)\n\n\n        xNum, yNum = numLines\n        stepX = round((ra1 - ra0) / xNum)\n        stepY = round((dec1 - dec0) / yNum)\n\n        rangeX = stepX * (xNum - 1)\n        rangeY = stepY * (yNum - 1)\n\n        raStart = np.round(raMid - rangeX/2.)\n        decStart = np.round(decMid - rangeY/2.)\n\n        raRange = np.arange(raStart, raStart + stepX*xNum, stepX)\n        decRange = np.arange(decStart, decStart + stepY*yNum, stepY)\n        raRange = np.fmod(raRange, 360.)\n\n        return raRange, decRange", "response": "Pick suitable values for ra and dec ticks for the current tile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the value at the given key", "response": "def get(self, key, **kwargs):\n        '''\n        Fetch value at the given key\n        kwargs can hold `recurse`, `wait` and `index` params\n        '''\n        return self._get('/'.join([self._endpoint, key]), payload=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore a new value at the given key", "response": "def set(self, key, value, **kwargs):\n        '''\n        Store a new value at the given key\n        kwargs can hold `cas` and `flags` params\n        '''\n        return requests.put(\n            '{}/{}/kv/{}'.format(\n                self.master, pyconsul.__consul_api_version__, key),\n            data=value,\n            params=kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef health(self, **kwargs):\n        '''\n        Support `node`, `service`, `check`, `state`\n        '''\n        if not len(kwargs):\n            raise ValueError('no resource provided')\n        for resource, name in kwargs.iteritems():\n            endpoint = 'health/{}/{}'.format(resource, name)\n        return self._get(endpoint)", "response": "Get health information for all the resources in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef webIDToStoreID(key, webid):\n    if len(webid) != 16:\n        return None\n    try:\n        int(webid, 16)\n    except TypeError:\n        return None\n    except ValueError:\n        return None\n    l = list(webid)\n    for nybbleid in range(7, -1, -1):\n        a, b = _swapat(key, nybbleid)\n        _swap(l, b, a)\n    i = int(''.join(l), 16)\n    return i ^ key", "response": "Converts a webid to a storeID."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a key and storeid and produces a webid", "response": "def storeIDToWebID(key, storeid):\n    \"\"\"\n    Takes a key (int) and storeid (int) and produces a webid (a 16-character\n    str suitable for including in URLs)\n    \"\"\"\n    i = key ^ storeid\n    l = list('%0.16x' % (i,))\n    for nybbleid in range(0, 8):\n        a, b = _swapat(key, nybbleid)\n        _swap(l, a, b)\n    return ''.join(l)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_asweep(self, start=None, stop=None, step=None):\n        if start:\n            self.amplitude_start = start\n        if stop:\n            self.amplitude_stop = stop\n        if step:\n            self.amplitude_step = step\n        self._write(('SWEEP', Integer), 2)", "response": "Starts a amplitude sweep."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting a frequency sweep.", "response": "def start_fsweep(self, start=None, stop=None, step=None):\n        \"\"\"Starts a frequency sweep.\n\n        :param start: Sets the start frequency.\n        :param stop: Sets the target frequency.\n        :param step: Sets the frequency step.\n\n        \"\"\"\n        if start:\n            self.frequency_start = start\n        if stop:\n            self.frequency_stop = stop\n        if step:\n            self.frequency_step = step\n        self._write(('SWEEP', Integer), 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures data acquisition to start on a certain edge of a certain condition.", "response": "def take_data_triggered(self, trigger, edge, stop):\n        \"\"\"Configures data acquisition to start on various trigger conditions.\n\n        :param trigger: The trigger condition, either 'curve' or 'point'.\n\n            ======= =======================================================\n            Value   Description\n            ======= =======================================================\n            'curve' Each trigger signal starts a curve acquisition.\n            'point' A point is stored for each trigger signal. The max\n                    trigger frequency in this mode is 1 kHz.\n            ======= =======================================================\n\n        :param edge: Defines wether a 'rising' or 'falling' edge is interpreted\n            as a trigger signal.\n        :param stop: The stop condition. Valid are 'buffer', 'halt',\n            'rising' and 'falling'.\n\n            ========= ==========================================================\n            Value     Description\n            ========= ==========================================================\n            'buffer'  Data acquisition stops when the number of point\n                      specified in :attr:`~.Buffer.length` is acquired.\n            'halt'    Data acquisition stops when the halt command is issued.\n            'trigger' Takes data for the period of a trigger event. If edge is\n                      'rising' then teh acquisition starts on the rising edge of\n                      the trigger signal and stops on the falling edge and vice\n                      versa\n            ========= ==========================================================\n\n        \"\"\"\n        param = {\n            ('curve', 'rising', 'buffer'): 0,\n            ('point', 'rising', 'buffer'): 1,\n            ('curve', 'falling', 'buffer'): 2,\n            ('point', 'falling', 'buffer'): 3,\n            ('curve', 'rising', 'halt'): 4,\n            ('point', 'rising', 'halt'): 5,\n            ('curve', 'falling', 'halt'): 6,\n            ('point', 'falling', 'halt'): 7,\n            ('curve', 'rising', 'trigger'): 8,\n            ('curve', 'falling', 'trigger'): 9,\n        }\n        self._write(('TDT', Integer), param[(trigger, edge, stop)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _decompose(self, value):\n        data = {}\n        for n, attr in zip(self.recordType.__names__, self.attrs):\n            data[attr.attrname] = getattr(value, n)\n        return data", "response": "Decomposes an instance of our record type into a dictionary mapping the attribute names to values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an instance of this class with the specified keyword arguments.", "response": "def create(cls, **kw):\n        \"\"\"\n        Create an instance of this class, first cleaning up the keyword\n        arguments so they will fill in any required values.\n\n        @return: an instance of C{cls}\n        \"\"\"\n        for k, v in kw.items():\n            attr = getattr(cls, k, None)\n            if isinstance(attr, RecordAttribute):\n                kw.pop(k)\n                kw.update(attr._decompose(v))\n        return cls(**kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __rowResultToQuote(self, row):\r\n        ''' convert rowResult from Hbase to Quote'''\r\n        keyValues = row.columns\r\n        for field in QUOTE_FIELDS:\r\n            key = \"%s:%s\" % (HBaseDAM.QUOTE, field)\r\n            if 'time' != field and keyValues[key].value:\r\n                keyValues[key].value = float(keyValues[key].value)\r\n\r\n        return Quote(*[keyValues[\"%s:%s\" % (HBaseDAM.QUOTE, field)].value for field in QUOTE_FIELDS])", "response": "convert rowResult from Hbase to Quote"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert rowResult from Hbase to Tick", "response": "def __rowResultToTick(self, row):\r\n        ''' convert rowResult from Hbase to Tick'''\r\n        keyValues = row.columns\r\n        for field in TICK_FIELDS:\r\n            key = \"%s:%s\" % (HBaseDAM.TICK, field)\r\n            if 'time' != field and keyValues[key].value:\r\n                keyValues[key].value = float(keyValues[key].value)\r\n\r\n        return Tick(*[keyValues[\"%s:%s\" % (HBaseDAM.TICK, field)].value for field in TICK_FIELDS])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading quotes from the database", "response": "def readQuotes(self, start, end):\r\n        ''' read quotes '''\r\n        rows = self.__hbase.scanTable(self.tableName(HBaseDAM.QUOTE), [HBaseDAM.QUOTE], start, end)\r\n\r\n        return [self.__rowResultToQuote(row) for row in rows]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting quotes to table", "response": "def writeQuotes(self, quotes):\r\n        ''' write quotes '''\r\n        tName = self.tableName(HBaseDAM.QUOTE)\r\n        if tName not in self.__hbase.getTableNames():\r\n            self.__hbase.createTable(tName, [ColumnDescriptor(name=HBaseDAM.QUOTE, maxVersions=5)])\r\n\r\n        for quote in quotes:\r\n            self.__hbase.updateRow(self.tableName(HBaseDAM.QUOTE),\r\n                                   quote.time,\r\n                                   [Mutation(column = \"%s:%s\" % (HBaseDAM.QUOTE, field),\r\n                                             value = getattr(quote, field) ) for field in QUOTE_FIELDS])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads ticks from the table", "response": "def readTicks(self, start, end):\r\n        ''' read ticks '''\r\n        rows = self.__hbase.scanTable(self.tableName(HBaseDAM.TICK), [HBaseDAM.TICK], start, end)\r\n        return [self.__rowResultToTick(row) for row in rows]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a list of ticks to the table", "response": "def writeTicks(self, ticks):\r\n        ''' read quotes '''\r\n        tName = self.tableName(HBaseDAM.TICK)\r\n        if tName not in self.__hbase.getTableNames():\r\n            self.__hbase.createTable(tName, [ColumnDescriptor(name=HBaseDAM.TICK, maxVersions=5)])\r\n\r\n        for tick in ticks:\r\n            self.__hbase.updateRow(self.tableName(HBaseDAM.TICK),\r\n                                   tick.time,\r\n                                   [Mutation(column = \"%s:%s\" % (HBaseDAM.TICK, field),\r\n                                             value = getattr(tick, field) ) for field in TICK_FIELDS])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexpose K2visible to the command line.", "response": "def inMicrolensRegion_main(args=None):\n    \"\"\"Exposes K2visible to the command line.\"\"\"\n    import argparse\n    parser = argparse.ArgumentParser(\n                    description=\"Check if a celestial coordinate is \"\n                                \"inside the K2C9 microlensing superstamp.\")\n    parser.add_argument('ra', nargs=1, type=float,\n                        help=\"Right Ascension in decimal degrees (J2000).\")\n    parser.add_argument('dec', nargs=1, type=float,\n                        help=\"Declination in decimal degrees (J2000).\")\n    args = parser.parse_args(args)\n    if inMicrolensRegion(args.ra[0], args.dec[0]):\n        print(\"Yes! The coordinate is inside the K2C9 superstamp.\")\n    else:\n        print(\"Sorry, the coordinate is NOT inside the K2C9 superstamp.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inMicrolensRegion(ra_deg, dec_deg, padding=0):\n    fov = getKeplerFov(9)\n    try:\n        ch, col, row = fov.getChannelColRow(ra_deg, dec_deg,\n                                            allowIllegalReturnValues=False)\n        return maskInMicrolensRegion(ch, col, row, padding=padding)\n    except ValueError:\n        return False", "response": "Returns True if the given sky oordinate falls on the K2C9 microlens superstamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pixelInMicrolensRegion(ch, col, row):\n    # First try the superstamp\n    try:\n        vertices_col = SUPERSTAMP[\"channels\"][str(int(ch))][\"vertices_col\"]\n        vertices_row = SUPERSTAMP[\"channels\"][str(int(ch))][\"vertices_row\"]\n        # The point is in one of 5 channels which constitute the superstamp\n        # so check if it falls inside the polygon for this channel\n        if isPointInsidePolygon(col, row, vertices_col, vertices_row):\n            return True\n    except KeyError:  # Channel does not appear in file\n        pass\n\n    # Then try the late target masks\n    for mask in LATE_TARGETS[\"masks\"]:\n        if mask[\"channel\"] == ch:\n            vertices_col = mask[\"vertices_col\"]\n            vertices_row = mask[\"vertices_row\"]\n            if isPointInsidePolygon(col, row, vertices_col, vertices_row):\n                return True\n\n    return False", "response": "Returns True if the given pixel falls inside the K2C9 superstamp."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nis a target in the K2C9 superstamp including padding?", "response": "def maskInMicrolensRegion(ch, col, row, padding=0):\n    \"\"\"Is a target in the K2C9 superstamp, including padding?\n\n    This function is identical to pixelInMicrolensRegion, except it takes\n    the extra `padding` argument. The coordinate must be within the K2C9\n    superstamp by at least `padding` number of pixels on either side of the\n    coordinate.  (Note that this function does not check whether something is\n    close to the CCD boundaries, it only checks whether something is close\n    to the edge of stamp.)\n    \"\"\"\n    if padding == 0:\n        return pixelInMicrolensRegion(ch, col, row)\n\n    combinations = [[col - padding, row],\n                    [col + padding, row],\n                    [col, row - padding],\n                    [col, row + padding]]\n    for col, row in combinations:\n        # Science pixels occupy columns 12 - 1111, rows 20 - 1043\n        if col < 12:\n            col = 12\n        if col > 1111:\n            col = 1111\n        if row < 20:\n            row = 20\n        if row > 1043:\n            row = 1043\n        if not pixelInMicrolensRegion(ch, col, row):\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a given point is inside a polygon.", "response": "def isPointInsidePolygon(x, y, vertices_x, vertices_y):\n    \"\"\"Check if a given point is inside a polygon.\n\n    Parameters vertices_x[] and vertices_y[] define the polygon.\n    The number of array elements is equal to number of vertices of the polygon.\n    This function works for convex and concave polygons.\n\n    Parameters\n    ----------\n    vertices_x, vertices_y : lists or arrays of floats\n        Vertices that define the polygon.\n\n    x, y : float\n        Coordinates of the point to check.\n\n    Returns\n    -------\n    inside : bool\n        `True` if the point is inside the polygon.\n    \"\"\"\n    inside = False\n    for i in range(len(vertices_x)):\n        j = i - 1\n        if ((vertices_x[i] > x) != (vertices_x[j] > x)):\n            if (y < (x - vertices_x[i]) *\n                    (vertices_y[i] - vertices_y[j]) /\n                    (vertices_x[i] - vertices_x[j]) +\n                    vertices_y[i]):\n                inside = not inside\n    return inside"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot the coverage of both the channels and the C9 superstamp.", "response": "def plot_outline(self, annotate_late_targets=False, annotate_channels=False):\n        \"\"\"Plots the coverage of both the channels and the C9 superstamp.\"\"\"\n        fov = getKeplerFov(9)\n        # Plot the superstamp\n        superstamp_patches = []\n        for ch in SUPERSTAMP[\"channels\"]:\n            v_col = SUPERSTAMP[\"channels\"][ch][\"vertices_col\"]\n            v_row = SUPERSTAMP[\"channels\"][ch][\"vertices_row\"]\n            radec = np.array([\n                                fov.getRaDecForChannelColRow(int(ch),\n                                                             v_col[idx],\n                                                             v_row[idx])\n                                for idx in range(len(v_col))\n                              ])\n            patch = self.ax.fill(radec[:, 0], radec[:, 1],\n                                 lw=0, facecolor=\"#27ae60\", zorder=100)\n            superstamp_patches.append(patch)\n\n        # Plot the late target masks\n        late_target_patches = []\n        for mask in LATE_TARGETS[\"masks\"]:\n            ch = mask[\"channel\"]\n            v_col = mask[\"vertices_col\"]\n            v_row = mask[\"vertices_row\"]\n            radec = np.array([\n                                fov.getRaDecForChannelColRow(int(ch),\n                                                             v_col[idx],\n                                                             v_row[idx])\n                                for idx in range(len(v_col))\n                              ])\n            patch = self.ax.fill(radec[:, 0], radec[:, 1],\n                                 lw=0, facecolor=\"#27ae60\", zorder=201)\n            late_target_patches.append(patch)\n            if annotate_late_targets and 'context' not in mask[\"name\"]:\n                self.ax.text(np.mean(radec[:, 0]), np.mean(radec[:, 1]), '  ' + mask[\"name\"],\n                             ha=\"left\", va=\"center\",\n                             zorder=950, fontsize=10,\n                             color=\"#c0392b\", clip_on=True)\n\n        # Plot all channel outlines\n        channel_patches = []\n        corners = fov.getCoordsOfChannelCorners()\n        for ch in np.arange(1, 85, dtype=int):\n            if ch in fov.brokenChannels:\n                continue  # certain channel are no longer used\n            idx = np.where(corners[::, 2] == ch)\n            mdl = int(corners[idx, 0][0][0])\n            out = int(corners[idx, 1][0][0])\n            ra = corners[idx, 3][0]\n            dec = corners[idx, 4][0]\n            patch = self.ax.fill(np.concatenate((ra, ra[:1])),\n                                 np.concatenate((dec, dec[:1])),\n                                 lw=0, facecolor=\"#cccccc\", zorder=50)\n            channel_patches.append(patch)\n            if annotate_channels:\n                txt = \"{}.{}\\n#{}\".format(mdl, out, ch)\n                self.ax.text(np.mean(ra), np.mean(dec), txt,\n                             ha=\"center\", va=\"center\",\n                             zorder=900, fontsize=14,\n                             color=\"#000000\", clip_on=True)\n        return superstamp_patches, channel_patches"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the field to the specified value.", "response": "def set_field(self, target, rate, wait_for_stability=True):\n        \"\"\"Sets the field to the specified value.\n        \n        :param field: The target field in Tesla.\n        :param rate: The field rate in tesla per minute.\n        :param wait_for_stability: If True, the function call blocks until the\n            target field is reached.\n        \n        \"\"\"\n        self.field.target = target\n        self.field.sweep_rate = rate\n        self.activity = 'to setpoint'\n        while self.status['mode'] != 'at rest':\n            time.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming a field scan.", "response": "def scan_field(self, measure, target, rate, delay=1):\n        \"\"\"Performs a field scan.\n\n        Measures until the target field is reached.\n\n        :param measure: A callable called repeatedly until stability at the\n            target field is reached.\n        :param field: The target field in Tesla.\n        :param rate: The field rate in tesla per minute.\n        :param delay: The time delay between each call to measure in seconds.\n\n        :raises TypeError: if measure parameter is not callable.\n\n        \"\"\"\n        if not hasattr(measure, '__call__'):\n            raise TypeError('measure parameter not callable.')\n        self.activity = 'hold'\n        self.field.target = target\n        self.field.sweep_rate = rate\n        self.activity = 'to setpoint'\n        while self.status['mode'] != 'at rest':\n            measure()\n            time.sleep(delay)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_context_plot(ra, dec, name=\"Your object\"):\n    plot = K2FootprintPlot()\n    plot.plot_galactic()\n    plot.plot_ecliptic()\n    for c in range(0, 20):\n        plot.plot_campaign_outline(c, facecolor=\"#666666\")\n    # for c in [11, 12, 13, 14, 15, 16]:\n    #    plot.plot_campaign_outline(c, facecolor=\"green\")\n    plot.ax.scatter(ra, dec, marker='x', s=250, lw=3, color=\"red\", zorder=500)\n    plot.ax.text(ra, dec - 2, name,\n                 ha=\"center\", va=\"top\", color=\"red\",\n                 fontsize=20, fontweight='bold', zorder=501)\n    return plot", "response": "Creates a K2FootprintPlot showing a given position in context\n    with respect to the campaigns."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a K2FootprintPlot showing a given position in context with respect to the campaigns.", "response": "def create_context_plot_zoomed(ra, dec, name=\"Your object\", size=3):\n    \"\"\"Creates a K2FootprintPlot showing a given position in context\n    with respect to the campaigns.\"\"\"\n    plot = K2FootprintPlot(figsize=(8, 8))\n    for c in range(0, 20):\n        plot.plot_campaign(c)\n    plot.ax.scatter(ra, dec, marker='x', s=250, lw=3, color=\"red\", zorder=500)\n    plot.ax.text(ra, dec - 0.05*size, name,\n                 ha=\"center\", va=\"top\", color=\"red\",\n                 fontsize=20, fontweight='bold', zorder=501)\n    plot.ax.set_xlim([ra - size/2., ra + size/2.])\n    plot.ax.set_ylim([dec - size/2., dec + size/2.])\n    return plot"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting the outline of a specific K2 campaign.", "response": "def plot_campaign_outline(self, campaign=0, facecolor=\"#666666\", text=None):\n        \"\"\"Plot the outline of a campaign as a contiguous gray patch.\n\n        Parameters\n        ----------\n        campaign : int\n            K2 Campaign number.\n\n        facecolor : str\n            Color of the patch.\n        \"\"\"\n        # The outline is composed of two filled rectangles,\n        # defined by the first coordinate of the corner of four channels each\n        fov = getKeplerFov(campaign)\n        corners = fov.getCoordsOfChannelCorners()\n        for rectangle in [[4, 75, 84, 11], [15, 56, 71, 32]]:\n            ra_outline, dec_outline = [], []\n            for channel in rectangle:\n                idx = np.where(corners[::, 2] == channel)\n                ra_outline.append(corners[idx, 3][0][0])\n                dec_outline.append(corners[idx, 4][0][0])\n            ra = np.array(ra_outline + ra_outline[:1])\n            dec = np.array(dec_outline + dec_outline[:1])\n            if campaign == 1002:  # Overlaps the meridian\n                ra[ra > 180] -= 360\n            myfill = self.ax.fill(ra, dec,\n                                  facecolor=facecolor,\n                                  zorder=151, lw=0)\n        # Print the campaign number on top of the outline\n        if text is None:\n            text = \"{}\".format(campaign)\n        ra_center, dec_center, _ = fov.getBoresight()\n        if campaign == 6:\n            dec_center -= 2\n        elif campaign == 12:\n            ra_center += 0.5\n            dec_center -= 1.7\n        elif campaign == 13:\n            dec_center -= 1.5\n        elif campaign == 16:\n            dec_center += 1.5\n        elif campaign == 18:\n            dec_center -= 1.5\n        elif campaign == 19:\n            dec_center += 1.7\n        elif campaign == 20:\n            dec_center += 1.5\n        offsets = {5: (40, -20), 16: (-20, 40), 18: (-15, -50)}\n        if campaign in [5]:\n            pl.annotate(text, xy=(ra_center, dec_center),\n                        xycoords='data', ha='center',\n                        xytext=offsets[campaign], textcoords='offset points',\n                        size=18, zorder=0, color=facecolor,\n                        arrowprops=dict(arrowstyle=\"-\", ec=facecolor, lw=2))\n        else:\n            self.ax.text(ra_center, dec_center, text,\n                         fontsize=18, color=\"white\",\n                         ha=\"center\", va=\"center\",\n                         zorder=155)\n        return myfill"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting all the active channels of a specific campaign.", "response": "def plot_campaign(self, campaign=0, annotate_channels=True, **kwargs):\n        \"\"\"Plot all the active channels of a campaign.\"\"\"\n        fov = getKeplerFov(campaign)\n        corners = fov.getCoordsOfChannelCorners()\n\n        for ch in np.arange(1, 85, dtype=int):\n            if ch in fov.brokenChannels:\n                continue  # certain channel are no longer used\n            idx = np.where(corners[::, 2] == ch)\n            mdl = int(corners[idx, 0][0][0])\n            out = int(corners[idx, 1][0][0])\n            ra = corners[idx, 3][0]\n            if campaign == 1002:  # Concept Engineering Test overlapped the meridian\n                ra[ra < 180] += 360\n            dec = corners[idx, 4][0]\n            self.ax.fill(np.concatenate((ra, ra[:1])),\n                         np.concatenate((dec, dec[:1])), **kwargs)\n            if annotate_channels:\n                txt = \"K2C{0}\\n{1}.{2}\\n#{3}\".format(campaign, mdl, out, ch)\n                txt = \"{1}.{2}\\n#{3}\".format(campaign, mdl, out, ch)\n                self.ax.text(np.mean(ra), np.mean(dec), txt,\n                             ha=\"center\", va=\"center\",\n                             zorder=91, fontsize=10,\n                             color=\"#000000\", clip_on=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the outline of a specific K2 campaign.", "response": "def plot_campaign_outline(self, campaign=0, facecolor=\"#666666\", text=None, dashed=False):\n        \"\"\"Plot the outline of a campaign as a contiguous gray patch.\n\n        Parameters\n        ----------\n        campaign : int\n            K2 Campaign number.\n\n        facecolor : str\n            Color of the patch.\n        \"\"\"\n        try:\n            from astropy.coordinates import SkyCoord\n        except ImportError:\n            logger.error(\"You need to install AstroPy for this feature.\")\n            return None\n        # The outline is composed of two filled rectangles,\n        # defined by the first coordinate of the corner of four channels each\n        fov = getKeplerFov(campaign)\n        corners = fov.getCoordsOfChannelCorners()\n        for rectangle in [[4, 75, 84, 11], [15, 56, 71, 32]]:\n            ra_outline, dec_outline = [], []\n            for channel in rectangle:\n                idx = np.where(corners[::, 2] == channel)\n                ra_outline.append(corners[idx, 3][0][0])\n                dec_outline.append(corners[idx, 4][0][0])\n\n            crd = SkyCoord(ra_outline, dec_outline, unit='deg')\n            l = crd.galactic.l.deg\n            if campaign not in [4, 13, 1713]:\n                l[l > 180] -= 360\n            l, b = list(l), list(crd.galactic.b.deg)\n            if dashed:\n                myfill = self.ax.fill(l + l[:1],\n                                      b + b[:1],\n                                      facecolor=facecolor, zorder=151, lw=2, ls='dashed',\n                                      edgecolor='white')\n                # myfill = self.ax.plot(l + l[:1],\n                #                      b + b[:1],\n                #                      zorder=200, lw=2,\n                #                      ls='dotted', color='white')\n            else:\n                myfill = self.ax.fill(l + l[:1],\n                                      b + b[:1],\n                                      facecolor=facecolor, zorder=151, lw=0)\n        # Print the campaign number on top of the outline\n        ra, dec, roll = fov.getBoresight()\n        gal = SkyCoord(ra, dec, unit='deg').galactic\n        l, b = gal.l.deg, gal.b.deg\n        if l > 180:\n            l -= 360\n        if text is None:\n            text = \"{}\".format(campaign)\n        self.ax.text(l, b, text,\n                     fontsize=14, color=\"white\", ha=\"center\", va=\"center\",\n                     zorder=255)\n        return myfill"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_static(self, path):\n        if not path:\n            return \"\"\n\n        if path[0] == '/':\n            return \"%s?v=%s\" % (path, self.version)\n\n        return \"%s/%s?v=%s\" % (self.static, path, self.version)", "response": "This method generates a valid path to the public folder of the running project"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_values(values, extra=None):\n    coerced = list(values)\n\n    if coerced == values:\n        values = coerced\n    else:\n        coerced = tuple(values)\n        if coerced == values:\n            values = list(values)\n        else:\n            values = [values]\n\n    if extra:\n        values.extend(extra)\n    return values", "response": "Utility function to flatten out args.\n    is internal use only."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef redis_key(cls, key):\n        keyspace = cls.keyspace\n        tpl = cls.keyspace_template\n        key = \"%s\" % key if keyspace is None else tpl % (keyspace, key)\n        return cls.keyparse.encode(key)", "response": "Get the key we pass to redis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef super_pipe(self):\n        orig_pipe = self._pipe\n\n        def exit_handler():\n            self._pipe = orig_pipe\n\n        self._pipe = autoexec(orig_pipe, name=self.connection,\n                              exit_handler=exit_handler)\n\n        return self._pipe", "response": "Creates a shared pipeline that will bind two different differentCOOKIE keys together in a shared pipeline on the class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the key from redis", "response": "def delete(self, *names):\n        \"\"\"\n        Remove the key from redis\n\n        :param names: tuple of strings - The keys to remove from redis.\n        :return: Future()\n        \"\"\"\n        names = [self.redis_key(n) for n in names]\n        with self.pipe as pipe:\n            return pipe.delete(*names)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nallowing the key to expire after time seconds.", "response": "def expire(self, name, time):\n        \"\"\"\n        Allow the key to expire after ``time`` seconds.\n\n        :param name: str     the name of the redis key\n        :param time: time expressed in seconds.\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.expire(self.redis_key(name), time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exists(self, name):\n        with self.pipe as pipe:\n            return pipe.exists(self.redis_key(name))", "response": "Returns a Future that fires when the key exists in redis?"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a lua script against the current key.", "response": "def eval(self, script, numkeys, *keys_and_args):\n        \"\"\"\n        Run a lua script against the key.\n        Doesn't support multi-key lua operations because\n        we wouldn't be able to know what argument to namespace.\n        Also, redis cluster doesn't really support multi-key operations.\n\n        :param script: str  A lua script targeting the current key.\n        :param numkeys: number of keys passed to the script\n        :param keys_and_args: list of keys and args passed to script\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            keys_and_args = [a if i >= numkeys else self.redis_key(a) for i, a\n                             in enumerate(keys_and_args)]\n            return pipe.eval(script, numkeys, *keys_and_args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump(self, name):\n        with self.pipe as pipe:\n            return pipe.dump(self.redis_key(name))", "response": "get a redis RDB - like serialization of the object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restorenx(self, name, value, pttl=0):\n        return self.eval(lua_restorenx, 1, name, pttl, value)", "response": "Restore a serialized dump of a key into a future"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef restore(self, name, value, pttl=0):\n        with self.pipe as pipe:\n            res = pipe.restore(self.redis_key(name), ttl=pttl, value=value)\n            f = Future()\n\n            def cb():\n                f.set(self.valueparse.decode(res.result))\n\n            pipe.on_execute(cb)\n            return f", "response": "Restore serialized dump of a key into redis"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the number of seconds until the key s expiration", "response": "def ttl(self, name):\n        \"\"\"\n        get the number of seconds until the key's expiration\n\n        :param name: str     the name of the redis key\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.ttl(self.redis_key(name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear any expiration TTL set on the object holding the key name", "response": "def persist(self, name):\n        \"\"\"\n        clear any expiration TTL set on the object\n\n        :param name: str     the name of the redis key\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.persist(self.redis_key(name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset an expire flag on key name for time milliseconds.", "response": "def pexpire(self, name, time):\n        \"\"\"\n        Set an expire flag on key ``name`` for ``time`` milliseconds.\n        ``time`` can be represented by an integer or a Python timedelta\n        object.\n\n        :param name: str\n        :param time: int or timedelta\n        :return Future\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.pexpire(self.redis_key(name), time)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset an expire flag on key name to when.", "response": "def pexpireat(self, name, when):\n        \"\"\"\n        Set an expire flag on key ``name``. ``when`` can be represented\n        as an integer representing unix time in milliseconds (unix time * 1000)\n        or a Python datetime object.\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.pexpireat(self.redis_key(name), when)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pttl(self, name):\n        with self.pipe as pipe:\n            return pipe.pttl(self.redis_key(name))", "response": "Returns the number of milliseconds until the key name will expire\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrename key src to dst.", "response": "def rename(self, src, dst):\n        \"\"\"\n        Rename key ``src`` to ``dst``\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.rename(self.redis_key(src), self.redis_key(dst))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef renamenx(self, src, dst):\n        \"Rename key ``src`` to ``dst`` if ``dst`` doesn't already exist\"\n        with self.pipe as pipe:\n            return pipe.renamenx(self.redis_key(src), self.redis_key(dst))", "response": "Rename key src to dst if dst doesn t already exist"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the key s info", "response": "def object(self, infotype, key):\n        \"\"\"\n        get the key's info stats\n\n        :param name: str     the name of the redis key\n        :param subcommand: REFCOUNT | ENCODING | IDLETIME\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.object(infotype, self.redis_key(key))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scan(self, cursor=0, match=None, count=None):\n        f = Future()\n        if self.keyspace is None:\n            with self.pipe as pipe:\n                res = pipe.scan(cursor=cursor, match=match, count=count)\n\n                def cb():\n                    f.set((res[0], [self.keyparse.decode(v) for v in res[1]]))\n\n                pipe.on_execute(cb)\n                return f\n\n        if match is None:\n            match = '*'\n        match = \"%s{%s}\" % (self.keyspace, match)\n        pattern = re.compile(r'^%s\\{(.*)\\}$' % self.keyspace)\n\n        with self.pipe as pipe:\n\n            res = pipe.scan(cursor=cursor, match=match, count=count)\n\n            def cb():\n                keys = []\n                for k in res[1]:\n                    k = self.keyparse.decode(k)\n                    m = pattern.match(k)\n                    if m:\n                        keys.append(m.group(1))\n\n                f.set((res[0], keys))\n\n            pipe.on_execute(cb)\n            return f", "response": "Incrementally return lists of key names. Also return a cursor\n        indicating the scan position."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sort(self, name, start=None, num=None, by=None, get=None,\n             desc=False, alpha=False, store=None, groups=False):\n        \"\"\"\n        Sort and return the list, set or sorted set at ``name``.\n\n        ``start`` and ``num`` allow for paging through the sorted data\n\n        ``by`` allows using an external key to weight and sort the items.\n            Use an \"*\" to indicate where in the key the item value is located\n\n        ``get`` allows for returning items from external keys rather than the\n            sorted data itself.  Use an \"*\" to indicate where int he key\n            the item value is located\n\n        ``desc`` allows for reversing the sort\n\n        ``alpha`` allows for sorting lexicographically rather than numerically\n\n        ``store`` allows for storing the result of the sort into\n            the key ``store``\n\n        ``groups`` if set to True and if ``get`` contains at least two\n            elements, sort will return a list of tuples, each containing the\n            values fetched from the arguments to ``get``.\n\n        \"\"\"\n        with self.pipe as pipe:\n            res = pipe.sort(self.redis_key(name), start=start, num=num,\n                            by=by, get=get, desc=desc, alpha=alpha,\n                            store=store, groups=groups)\n            if store:\n                return res\n            f = Future()\n\n            def cb():\n                decode = self.valueparse.decode\n                f.set([decode(v) for v in res.result])\n\n            pipe.on_execute(cb)\n            return f", "response": "Sort and return the list or sorted set at name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mget(self, keys, *args):\n        keys = [self.redis_key(k) for k in self._parse_values(keys, args)]\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.mget(keys)\n\n            def cb():\n                decode = self.valueparse.decode\n                f.set([None if r is None else decode(r) for r in res.result])\n\n            pipe.on_execute(cb)\n            return f", "response": "Returns a list of values ordered identically to keys"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the value at key name to value.", "response": "def set(self, name, value, ex=None, px=None, nx=False, xx=False):\n        \"\"\"\n        Set the value at key ``name`` to ``value``\n\n        ``ex`` sets an expire flag on key ``name`` for ``ex`` seconds.\n\n        ``px`` sets an expire flag on key ``name`` for ``px`` milliseconds.\n\n        ``nx`` if set to True, set the value at key ``name`` to ``value`` if it\n        does not already exist.\n\n        ``xx`` if set to True, set the value at key ``name`` to ``value`` if it\n        already exists.\n\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            value = self.valueparse.encode(value)\n            return pipe.set(self.redis_key(name), value,\n                            ex=ex, px=px, nx=nx, xx=xx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the value of a key only if the key doesn t exist.", "response": "def setnx(self, name, value):\n        \"\"\"\n        Set the value as a string in the key only if the key doesn't exist.\n\n        :param name: str     the name of the redis key\n        :param value:\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.setnx(self.redis_key(name),\n                              self.valueparse.encode(value))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setex(self, name, value, time):\n        with self.pipe as pipe:\n            return pipe.setex(self.redis_key(name),\n                              value=self.valueparse.encode(value),\n                              time=time)", "response": "Set the value of key to value that expires in time."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef psetex(self, name, value, time_ms):\n        with self.pipe as pipe:\n            return pipe.psetex(self.redis_key(name), time_ms=time_ms,\n                               value=self.valueparse.encode(value=value))", "response": "Set the value of key name to value that expires in time_ms milliseconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend the string value to the value at key.", "response": "def append(self, name, value):\n        \"\"\"\n        Appends the string ``value`` to the value at ``key``. If ``key``\n        doesn't already exist, create it with a value of ``value``.\n        Returns the new length of the value at ``key``.\n\n        :param name: str     the name of the redis key\n        :param value: str\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.append(self.redis_key(name),\n                               self.valueparse.encode(value))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strlen(self, name):\n        with self.pipe as pipe:\n            return pipe.strlen(self.redis_key(name))", "response": "Return the number of bytes stored in the value of the key name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a substring of the string at key name. start and end are 0 - based integers specifying the portion of the string to return.", "response": "def substr(self, name, start, end=-1):\n        \"\"\"\n        Return a substring of the string at key ``name``. ``start`` and ``end``\n        are 0-based integers specifying the portion of the string to return.\n\n        :param name: str     the name of the redis key\n        :param start: int\n        :param end: int\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.substr(self.redis_key(name), start=start, end=end)\n\n            def cb():\n                f.set(self.valueparse.decode(res.result))\n\n            pipe.on_execute(cb)\n            return f"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the value of the key name starting at offset with value.", "response": "def setrange(self, name, offset, value):\n        \"\"\"\n        Overwrite bytes in the value of ``name`` starting at ``offset`` with\n        ``value``. If ``offset`` plus the length of ``value`` exceeds the\n        length of the original value, the new value will be larger\n        than before.\n        If ``offset`` exceeds the length of the original value, null bytes\n        will be used to pad between the end of the previous value and the start\n        of what's being injected.\n\n        Returns the length of the new string.\n        :param name: str     the name of the redis key\n        :param offset: int\n        :param value: str\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.setrange(self.redis_key(name), offset, value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setbit(self, name, offset, value):\n        with self.pipe as pipe:\n            return pipe.setbit(self.redis_key(name), offset, value)", "response": "Set the value of the offset in the key as value. Returns a future that fires with the previous value of offset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getbit(self, name, offset):\n        with self.pipe as pipe:\n            return pipe.getbit(self.redis_key(name), offset)", "response": "Returns a boolean indicating the value of offset in key name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bitcount(self, name, start=None, end=None):\n        with self.pipe as pipe:\n            return pipe.bitcount(self.redis_key(name), start=start, end=end)", "response": "Returns the number of bits in the value of key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nincrements the value for the key by amount", "response": "def incr(self, name, amount=1):\n        \"\"\"\n        increment the value for key by 1\n\n        :param name: str     the name of the redis key\n        :param amount: int\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.incr(self.redis_key(name), amount=amount)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef incrby(self, name, amount=1):\n        with self.pipe as pipe:\n            return pipe.incrby(self.redis_key(name), amount=amount)", "response": "increment the value for the key by amount"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nincrement the value for the key by amount", "response": "def incrbyfloat(self, name, amount=1.0):\n        \"\"\"\n        increment the value for key by value: float\n\n        :param name: str     the name of the redis key\n        :param amount: int\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.incrbyfloat(self.redis_key(name), amount=amount)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores the difference of sets specified by keys into a new set named dest. Returns the number of keys in the new set.", "response": "def sdiffstore(self, dest, *keys):\n        \"\"\"\n        Store the difference of sets specified by ``keys`` into a new\n        set named ``dest``.  Returns the number of keys in the new set.\n        \"\"\"\n        keys = [self.redis_key(k) for k in self._parse_values(keys)]\n\n        with self.pipe as pipe:\n            return pipe.sdiffstore(self.redis_key(dest), *keys)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstores the union of sets specified by keys into a new set named dest. Returns the number of members in the new set.", "response": "def sunionstore(self, dest, keys, *args):\n        \"\"\"\n        Store the union of sets specified by ``keys`` into a new\n        set named ``dest``.  Returns the number of members in the new set.\n        \"\"\"\n        keys = [self.redis_key(k) for k in self._parse_values(keys, args)]\n        with self.pipe as pipe:\n            return pipe.sunionstore(self.redis_key(dest), *keys)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the specified members to the set.", "response": "def sadd(self, name, values, *args):\n        \"\"\"\n        Add the specified members to the Set.\n\n        :param name: str     the name of the redis key\n        :param values: a list of values or a simple value.\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            values = [self.valueparse.encode(v) for v in\n                      self._parse_values(values, args)]\n            return pipe.sadd(self.redis_key(name), *values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scard(self, name):\n        with self.pipe as pipe:\n            return pipe.scard(self.redis_key(name))", "response": "Return the number of items in the set with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a future that fires when the value of the named key is in the set.", "response": "def sismember(self, name, value):\n        \"\"\"\n        Is the provided value is in the ``Set``?\n\n        :param name: str     the name of the redis key\n        :param value: str\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.sismember(self.redis_key(name),\n                                  self.valueparse.encode(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a random member of the set.", "response": "def srandmember(self, name, number=None):\n        \"\"\"\n        Return a random member of the set.\n\n        :param name: str     the name of the redis key\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.srandmember(self.redis_key(name), number=number)\n\n            def cb():\n                if number is None:\n                    f.set(self.valueparse.decode(res.result))\n                else:\n                    f.set([self.valueparse.decode(v) for v in res.result])\n\n            pipe.on_execute(cb)\n            return f"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sscan_iter(self, name, match=None, count=None):\n        if self._pipe is not None:\n            raise InvalidOperation('cannot pipeline scan operations')\n\n        cursor = '0'\n        while cursor != 0:\n            cursor, data = self.sscan(name, cursor=cursor,\n                                      match=match, count=count)\n            for item in data:\n                yield item", "response": "Return an iterator over the items in the set named name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the length of the list with the given name.", "response": "def llen(self, name):\n        \"\"\"\n        Returns the length of the list.\n\n        :param name: str     the name of the redis key\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.llen(self.redis_key(name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a range of items in the redis list.", "response": "def lrange(self, name, start, stop):\n        \"\"\"\n        Returns a range of items.\n\n        :param name: str     the name of the redis key\n        :param start: integer representing the start index of the range\n        :param stop: integer representing the size of the list.\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.lrange(self.redis_key(name), start, stop)\n\n            def cb():\n                f.set([self.valueparse.decode(v) for v in res.result])\n\n            pipe.on_execute(cb)\n            return f"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rpush(self, name, *values):\n        with self.pipe as pipe:\n            v_encode = self.valueparse.encode\n            values = [v_encode(v) for v in self._parse_values(values)]\n            return pipe.rpush(self.redis_key(name), *values)", "response": "Push the value into the right side of the list from the left side\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lpop(self, name):\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.lpop(self.redis_key(name))\n\n            def cb():\n                f.set(self.valueparse.decode(res.result))\n\n            pipe.on_execute(cb)\n            return f", "response": "Pop the first object from the left."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rpoplpush(self, src, dst):\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.rpoplpush(self.redis_key(src), self.redis_key(dst))\n\n            def cb():\n                f.set(self.valueparse.decode(res.result))\n\n            pipe.on_execute(cb)\n            return f", "response": "Atomically RPOP a value off of the src list and atomically LPUSH it\n            on to the dst list. Returns the new value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lrem(self, name, value, num=1):\n        with self.pipe as pipe:\n            value = self.valueparse.encode(value)\n            return pipe.execute_command('LREM', self.redis_key(name),\n                                        num, value)", "response": "Remove the first occurrence of value from the list named name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrimming the list from start to end.", "response": "def ltrim(self, name, start, end):\n        \"\"\"\n        Trim the list from start to end.\n\n        :param name: str     the name of the redis key\n        :param start:\n        :param end:\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.ltrim(self.redis_key(name), start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value in the list at index", "response": "def lset(self, name, index, value):\n        \"\"\"\n        Set the value in the list at index *idx*\n\n        :param name: str     the name of the redis key\n        :param value:\n        :param index:\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            value = self.valueparse.encode(value)\n            return pipe.lset(self.redis_key(name), index, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding members in the set and assign them the score.", "response": "def zadd(self, name, members, score=1, nx=False,\n             xx=False, ch=False, incr=False):\n        \"\"\"\n        Add members in the set and assign them the score.\n\n        :param name: str     the name of the redis key\n        :param members: a list of item or a single item\n        :param score: the score the assign to the item(s)\n        :param nx:\n        :param xx:\n        :param ch:\n        :param incr:\n        :return: Future()\n        \"\"\"\n\n        if nx:\n            _args = ['NX']\n        elif xx:\n            _args = ['XX']\n        else:\n            _args = []\n\n        if ch:\n            _args.append('CH')\n\n        if incr:\n            _args.append('INCR')\n\n        if isinstance(members, dict):\n            for member, score in members.items():\n                _args += [score, self.valueparse.encode(member)]\n        else:\n            _args += [score, self.valueparse.encode(members)]\n\n        if nx and xx:\n            raise InvalidOperation('cannot specify nx and xx at the same time')\n        with self.pipe as pipe:\n            return pipe.execute_command('ZADD', self.redis_key(name), *_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zincrby(self, name, value, amount=1):\n        with self.pipe as pipe:\n            return pipe.zincrby(self.redis_key(name),\n                                value=self.valueparse.encode(value),\n                                amount=amount)", "response": "Increment the score of the key by value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zrevrank(self, name, value):\n        with self.pipe as pipe:\n            return pipe.zrevrank(self.redis_key(name),\n                                 self.valueparse.encode(value))", "response": "Returns the ranking in reverse order for the member of the redis key name and value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zrange(self, name, start, end, desc=False, withscores=False,\n               score_cast_func=float):\n        \"\"\"\n        Returns all the elements including between ``start`` (non included)\n        and ``stop`` (included).\n\n        :param name: str     the name of the redis key\n        :param start:\n        :param end:\n        :param desc:\n        :param withscores:\n        :param score_cast_func:\n        :return:\n        \"\"\"\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.zrange(\n                self.redis_key(name), start, end, desc=desc,\n                withscores=withscores, score_cast_func=score_cast_func)\n\n            def cb():\n                if withscores:\n                    f.set([(self.valueparse.decode(v), s) for v, s in\n                           res.result])\n                else:\n                    f.set([self.valueparse.decode(v) for v in res.result])\n\n            pipe.on_execute(cb)\n            return f", "response": "Returns all the elements including between start and end."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the range of elements included between the scores min and max.", "response": "def zrangebyscore(self, name, min, max, start=None, num=None,\n                      withscores=False, score_cast_func=float):\n        \"\"\"\n        Returns the range of elements included between the scores (min and max)\n\n        :param name: str     the name of the redis key\n        :param min:\n        :param max:\n        :param start:\n        :param num:\n        :param withscores:\n        :param score_cast_func:\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.zrangebyscore(self.redis_key(name), min, max,\n                                     start=start, num=num,\n                                     withscores=withscores,\n                                     score_cast_func=score_cast_func)\n\n            def cb():\n                if withscores:\n                    f.set([(self.valueparse.decode(v), s) for v, s in\n                           res.result])\n                else:\n                    f.set([self.valueparse.decode(v) for v in res.result])\n\n            pipe.on_execute(cb)\n            return f"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zcard(self, name):\n        with self.pipe as pipe:\n            return pipe.zcard(self.redis_key(name))", "response": "Returns the cardinality of the sorted set entry with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zcount(self, name, min, max):\n        with self.pipe as pipe:\n            return pipe.zcount(self.redis_key(name), min, max)", "response": "Returns the number of elements in the sorted set at key name with a score between min and max."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the score of an element in the sorted set with the given name and value.", "response": "def zscore(self, name, value):\n        \"\"\"\n        Return the score of an element\n\n        :param name: str     the name of the redis key\n        :param value: the element in the sorted set key\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.zscore(self.redis_key(name),\n                               self.valueparse.encode(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zremrangebyrank(self, name, min, max):\n        with self.pipe as pipe:\n            return pipe.zremrangebyrank(self.redis_key(name), min, max)", "response": "Remove a range of element between the rank start and stop both included."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zremrangebyscore(self, name, min, max):\n        with self.pipe as pipe:\n            return pipe.zremrangebyscore(self.redis_key(name), min, max)", "response": "Remove a range of element from the set name by between score min_value and max_value both included."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the rank of the element in the sorted set.", "response": "def zrank(self, name, value):\n        \"\"\"\n        Returns the rank of the element.\n\n        :param name: str     the name of the redis key\n        :param value: the element in the sorted set\n        \"\"\"\n        with self.pipe as pipe:\n            value = self.valueparse.encode(value)\n            return pipe.zrank(self.redis_key(name), value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the number of items in the sorted set between the lexicographical range min and max.", "response": "def zlexcount(self, name, min, max):\n        \"\"\"\n        Return the number of items in the sorted set between the\n        lexicographical range ``min`` and ``max``.\n\n        :param name: str     the name of the redis key\n        :param min: int or '-inf'\n        :param max: int or '+inf'\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.zlexcount(self.redis_key(name), min, max)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zrevrangebylex(self, name, max, min, start=None, num=None):\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.zrevrangebylex(self.redis_key(name), max, min,\n                                      start=start, num=num)\n\n            def cb():\n                f.set([self.valueparse.decode(v) for v in res])\n\n            pipe.on_execute(cb)\n            return f", "response": "Return the reversed lexicographical range of values from the sorted set\n         between max and min."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of elements in the sorted set between the lexicographical range specified by min and max.", "response": "def zremrangebylex(self, name, min, max):\n        \"\"\"\n        Remove all elements in the sorted set between the\n        lexicographical range specified by ``min`` and ``max``.\n\n        Returns the number of elements removed.\n        :param name: str     the name of the redis key\n        :param min: int or -inf\n        :param max: into or +inf\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.zremrangebylex(self.redis_key(name), min, max)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef zunionstore(self, dest, keys, aggregate=None):\n        with self.pipe as pipe:\n            keys = [self.redis_key(k) for k in keys]\n            return pipe.zunionstore(self.redis_key(dest), keys,\n                                    aggregate=aggregate)", "response": "Union multiple sorted sets specified by keys into a new sorted set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zscan(self, name, cursor=0, match=None, count=None,\n              score_cast_func=float):\n        \"\"\"\n        Incrementally return lists of elements in a sorted set. Also return a\n        cursor indicating the scan position.\n\n        ``match`` allows for filtering the members by pattern\n\n        ``count`` allows for hint the minimum number of returns\n\n        ``score_cast_func`` a callable used to cast the score return value\n        \"\"\"\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.zscan(self.redis_key(name), cursor=cursor,\n                             match=match, count=count,\n                             score_cast_func=score_cast_func)\n\n            def cb():\n                f.set((res[0], [(self.valueparse.decode(k), v)\n                                for k, v in res[1]]))\n\n            pipe.on_execute(cb)\n            return f", "response": "Incrementally return lists of elements in a sorted set. Also return the position of the first matching entry in the sorted set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over the items in the named zset.", "response": "def zscan_iter(self, name, match=None, count=None,\n                   score_cast_func=float):\n        \"\"\"\n        Make an iterator using the ZSCAN command so that the client doesn't\n        need to remember the cursor position.\n\n        ``match`` allows for filtering the keys by pattern\n\n        ``count`` allows for hint the minimum number of returns\n\n        ``score_cast_func`` a callable used to cast the score return value\n        \"\"\"\n        if self._pipe is not None:\n            raise InvalidOperation('cannot pipeline scan operations')\n        cursor = '0'\n        while cursor != 0:\n            cursor, data = self.zscan(name, cursor=cursor, match=match,\n                                      count=count,\n                                      score_cast_func=score_cast_func)\n            for item in data:\n                yield item"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _value_encode(cls, member, value):\n        try:\n            field_validator = cls.fields[member]\n        except KeyError:\n            return cls.valueparse.encode(value)\n\n        return field_validator.encode(value)", "response": "Internal method used to encode values into the hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hlen(self, name):\n        with self.pipe as pipe:\n            return pipe.hlen(self.redis_key(name))", "response": "Returns the number of elements in the Hash."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hstrlen(self, name, key):\n        with self.pipe as pipe:\n            return pipe.hstrlen(self.redis_key(name), key)", "response": "Return the number of bytes stored in the value of key within hash name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value of a key in the Hash at value.", "response": "def hset(self, name, key, value):\n        \"\"\"\n        Set ``member`` in the Hash at ``value``.\n\n        :param name: str     the name of the redis key\n        :param value:\n        :param key: the member of the hash key\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            value = self._value_encode(key, value)\n            key = self.memberparse.encode(key)\n            return pipe.hset(self.redis_key(name), key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes one or more hash fields from the redis key.", "response": "def hdel(self, name, *keys):\n        \"\"\"\n        Delete one or more hash field.\n\n        :param name: str     the name of the redis key\n        :param keys: on or more members to remove from the key.\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            m_encode = self.memberparse.encode\n            keys = [m_encode(m) for m in self._parse_values(keys)]\n            return pipe.hdel(self.redis_key(name), *keys)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hkeys(self, name):\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.hkeys(self.redis_key(name))\n\n            def cb():\n                m_decode = self.memberparse.decode\n                f.set([m_decode(v) for v in res.result])\n\n            pipe.on_execute(cb)\n            return f", "response": "Returns all the fields name in the Hash."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hgetall(self, name):\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.hgetall(self.redis_key(name))\n\n            def cb():\n                data = {}\n                m_decode = self.memberparse.decode\n                v_decode = self._value_decode\n                for k, v in res.result.items():\n                    k = m_decode(k)\n                    v = v_decode(k, v)\n                    data[k] = v\n                f.set(data)\n\n            pipe.on_execute(cb)\n            return f", "response": "Returns all the fields and values in the Hash."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hget(self, name, key):\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.hget(self.redis_key(name),\n                            self.memberparse.encode(key))\n\n            def cb():\n                f.set(self._value_decode(key, res.result))\n\n            pipe.on_execute(cb)\n            return f", "response": "Returns the value stored in the field None if the field doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the field exists False otherwise.", "response": "def hexists(self, name, key):\n        \"\"\"\n        Returns ``True`` if the field exists, ``False`` otherwise.\n\n        :param name: str     the name of the redis key\n        :param key: the member of the hash\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.hexists(self.redis_key(name),\n                                self.memberparse.encode(key))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hincrby(self, name, key, amount=1):\n        with self.pipe as pipe:\n            return pipe.hincrby(self.redis_key(name),\n                                self.memberparse.encode(key),\n                                amount)", "response": "Increment the value of the key in the hash field."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hmget(self, name, keys, *args):\n        member_encode = self.memberparse.encode\n        keys = [k for k in self._parse_values(keys, args)]\n        with self.pipe as pipe:\n            f = Future()\n            res = pipe.hmget(self.redis_key(name),\n                             [member_encode(k) for k in keys])\n\n            def cb():\n                f.set([self._value_decode(keys[i], v)\n                       for i, v in enumerate(res.result)])\n\n            pipe.on_execute(cb)\n            return f", "response": "Returns the values stored in the fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets or updates the fields with their corresponding values.", "response": "def hmset(self, name, mapping):\n        \"\"\"\n        Sets or updates the fields with their corresponding values.\n\n        :param name: str     the name of the redis key\n        :param mapping: a dict with keys and values\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            m_encode = self.memberparse.encode\n            mapping = {m_encode(k): self._value_encode(k, v)\n                       for k, v in mapping.items()}\n            return pipe.hmset(self.redis_key(name), mapping)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the approximate cardinality of the set observed by the HyperLogLog at key ( s ).", "response": "def pfcount(self, *sources):\n        \"\"\"\n        Return the approximated cardinality of\n        the set observed by the HyperLogLog at key(s).\n\n        Using the execute_command because redis-py-cluster disabled it\n        unnecessarily. but you can only send one key at a time in that case,\n        or only keys that map to the same keyslot.\n        Use at your own risk.\n\n        :param sources: [str]     the names of the redis keys\n        \"\"\"\n        sources = [self.redis_key(s) for s in sources]\n        with self.pipe as pipe:\n            return pipe.execute_command('PFCOUNT', *sources)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging N different HyperLogLogs into a single HyperLogLog.", "response": "def pfmerge(self, dest, *sources):\n        \"\"\"\n        Merge N different HyperLogLogs into a single one.\n\n        :param dest:\n        :param sources:\n        :return:\n        \"\"\"\n        sources = [self.redis_key(k) for k in sources]\n        with self.pipe as pipe:\n            return pipe.pfmerge(self.redis_key(dest), *sources)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets full job stats for a given job_id", "response": "def job_stats_enhanced(job_id):\n    \"\"\"\n    Get full job and step stats for job_id\n    \"\"\"\n    stats_dict = {}\n    with os.popen('bjobs -o \"jobid run_time cpu_used  queue slots  stat exit_code start_time estimated_start_time finish_time delimiter=\\'|\\'\" -noheader ' + str(job_id)) as f:\n        try:\n            line = f.readline()\n            cols = line.split('|')\n            stats_dict['job_id'] = cols[0]\n            if cols[1] != '-':\n                stats_dict['wallclock'] = timedelta(\n                    seconds=float(cols[1].split(' ')[0]))\n            if cols[2] != '-':\n                stats_dict['cpu'] = timedelta(\n                    seconds=float(cols[2].split(' ')[0]))\n            stats_dict['queue'] = cols[3]\n            stats_dict['status'] = cols[5]\n            stats_dict['exit_code'] = cols[6]\n            stats_dict['start'] = cols[7]\n            stats_dict['start_time'] = cols[8]\n            if stats_dict['status'] in ['DONE', 'EXIT']:\n                stats_dict['end'] = cols[9]\n\n            steps = []\n            stats_dict['steps'] = steps\n        except:\n            with os.popen('bhist -l ' + str(job_id)) as f:\n                try:\n                    output = f.readlines()\n                    for line in output:\n                        if \"Done successfully\" in line:\n                            stats_dict['status'] = 'DONE'\n                            return stats_dict\n                        elif \"Completed <exit>\" in line:\n                            stats_dict['status'] = 'EXIT'\n                            return stats_dict\n                        else:\n                            stats_dict['status'] = 'UNKNOWN'\n                except Exception as e:\n                    print(e)\n                    print('LSF: Error reading job stats')\n                    stats_dict['status'] = 'UNKNOWN'\n    return stats_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a request to the given endpoint of the openbus server.", "response": "def request_openbus(self, service, endpoint, **kwargs):\n        \"\"\"Make a request to the given endpoint of the ``openbus`` server.\n\n        This returns the plain JSON (dict) response which can then be parsed\n        using one of the implemented types.\n\n        Args:\n            service (str): Service to fetch ('bus' or 'geo').\n            endpoint (str): Endpoint to send the request to.\n                This string corresponds to the key in the ``ENDPOINTS`` dict.\n            **kwargs: Request arguments.\n\n        Returns:\n            Obtained response (dict) or None if the endpoint was not found.\n        \"\"\"\n        if service == 'bus':\n            endpoints = ENDPOINTS_BUS\n\n        elif service == 'geo':\n            endpoints = ENDPOINTS_GEO\n\n        else:\n            # Unknown service\n            return None\n\n        if endpoint not in endpoints:\n            # Unknown endpoint\n            return None\n\n        url = URL_OPENBUS + endpoints[endpoint]\n\n        # Append credentials to request\n        kwargs['idClient'] = self._emt_id\n        kwargs['passKey'] = self._emt_pass\n\n        # SSL verification fails...\n        # return requests.post(url, data=kwargs, verify=False).json()\n        return requests.post(url, data=kwargs, verify=True).json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a request to the given endpoint of the parking server.", "response": "def request_parking(self, endpoint, url_args={}, **kwargs):\n        \"\"\"Make a request to the given endpoint of the ``parking`` server.\n\n        This returns the plain JSON (dict) response which can then be parsed\n        using one of the implemented types.\n\n        Args:\n            endpoint (str): Endpoint to send the request to.\n                This string corresponds to the key in the ``ENDPOINTS`` dict.\n            url_args (dict): Dictionary for URL string replacements.\n            **kwargs: Request arguments.\n\n        Returns:\n            Obtained response (dict) or None if the endpoint was not found.\n        \"\"\"\n        if endpoint not in ENDPOINTS_PARKING:\n            # Unknown endpoint\n            return None\n\n        url = URL_OPENBUS + ENDPOINTS_PARKING[endpoint]\n\n        # Append additional info to URL\n        lang = url_args.get('lang', 'ES')\n        address = url_args.get('address', '')\n\n        url = url.format(\n            id_client=self._emt_id,\n            passkey=self._emt_pass,\n            address=address,\n            lang=lang\n        )\n\n        # This server uses TLSv1\n        return _parking_req.post(url, data=kwargs).json()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parseSearchTerm(term):\n    terms = []\n    keywords = {}\n    for word in term.split():\n        if word.count(':') == 1:\n            k, v = word.split(u':')\n            if k and v:\n                keywords[k] = v\n            elif k or v:\n                terms.append(k or v)\n        else:\n            terms.append(word)\n    term = u' '.join(terms)\n    if keywords:\n        return term, keywords\n    return term, None", "response": "Turn a string search query into a two - tuple of a search term and a dictionary of search keywords."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps for Twisted s getPassword method.", "response": "def gtpswd(prompt, confirmPassword):\n    \"\"\"\n    Temporary wrapper for Twisted's getPassword until a version that supports\n    customizing the 'confirm' prompt is released.\n    \"\"\"\n    try:\n        return util.getPassword(prompt=prompt,\n                                confirmPrompt=confirmPassword,\n                                confirm=True)\n    except TypeError:\n        return util.getPassword(prompt=prompt,\n                                confirm=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a self - signed X. 509 certificate.", "response": "def _createCert(self, hostname, serial):\n        \"\"\"\n        Create a self-signed X.509 certificate.\n\n        @type hostname: L{unicode}\n        @param hostname: The hostname this certificate should be valid for.\n\n        @type serial: L{int}\n        @param serial: The serial number the certificate should have.\n\n        @rtype: L{bytes}\n        @return: The serialized certificate in PEM format.\n        \"\"\"\n        privateKey = rsa.generate_private_key(\n            public_exponent=65537,\n            key_size=2048,\n            backend=default_backend())\n        publicKey = privateKey.public_key()\n        name = x509.Name([\n            x509.NameAttribute(NameOID.COMMON_NAME, hostname)])\n        certificate = (\n            x509.CertificateBuilder()\n            .subject_name(name)\n            .issuer_name(name)\n            .not_valid_before(datetime.today() - timedelta(days=1))\n            .not_valid_after(datetime.today() + timedelta(days=365))\n            .serial_number(serial)\n            .public_key(publicKey)\n            .add_extension(\n                x509.BasicConstraints(ca=False, path_length=None),\n                critical=True)\n            .add_extension(\n                x509.SubjectAlternativeName([\n                    x509.DNSName(hostname)]),\n                critical=False)\n            .add_extension(\n                x509.KeyUsage(\n                    digital_signature=True,\n                    content_commitment=False,\n                    key_encipherment=True,\n                    data_encipherment=False,\n                    key_agreement=False,\n                    key_cert_sign=False,\n                    crl_sign=False,\n                    encipher_only=False,\n                    decipher_only=False),\n                critical=True)\n            .add_extension(\n                x509.ExtendedKeyUsage([\n                    ExtendedKeyUsageOID.SERVER_AUTH]),\n                critical=False)\n            .sign(\n                private_key=privateKey,\n                algorithm=hashes.SHA256(),\n                backend=default_backend()))\n        return '\\n'.join([\n            privateKey.private_bytes(\n                encoding=serialization.Encoding.PEM,\n                format=serialization.PrivateFormat.PKCS8,\n                encryption_algorithm=serialization.NoEncryption()),\n            certificate.public_bytes(\n                encoding=serialization.Encoding.PEM),\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling the site and the base Mantissa offering and SSH server.", "response": "def installSite(self, siteStore, domain, publicURL, generateCert=True):\n        \"\"\"\n        Create the necessary items to run an HTTP server and an SSH server.\n        \"\"\"\n        certPath = siteStore.filesdir.child(\"server.pem\")\n        if generateCert and not certPath.exists():\n            certPath.setContent(self._createCert(domain, genSerial()))\n\n        # Install the base Mantissa offering.\n        IOfferingTechnician(siteStore).installOffering(baseOffering)\n\n        # Make the HTTP server baseOffering includes listen somewhere.\n        site = siteStore.findUnique(SiteConfiguration)\n        site.hostname = domain\n        installOn(\n            TCPPort(store=siteStore, factory=site, portNumber=8080),\n            siteStore)\n        installOn(\n            SSLPort(store=siteStore, factory=site, portNumber=8443,\n                    certificatePath=certPath),\n            siteStore)\n\n        # Make the SSH server baseOffering includes listen somewhere.\n        shell = siteStore.findUnique(SecureShellConfiguration)\n        installOn(\n            TCPPort(store=siteStore, factory=shell, portNumber=8022),\n            siteStore)\n\n        # Install a front page on the top level store so that the\n        # developer will have something to look at when they start up\n        # the server.\n        fp = siteStore.findOrCreate(publicweb.FrontPage, prefixURL=u'')\n        installOn(fp, siteStore)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch & return a new Tag object representing the current state of the tag.", "response": "def fetch(self):\n        \"\"\"\n        Fetch & return a new `Tag` object representing the tag's current state\n\n        :rtype: Tag\n        :raises DOAPIError: if the API endpoint replies with an error (e.g., if\n            the tag no longer exists)\n        \"\"\"\n        api = self.doapi_manager\n        return api._tag(api.request(self.url)[\"tag\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_tag(self, name):\n        # The `_tag` is to avoid conflicts with MutableMapping.update.\n        \"\"\"\n        Update (i.e., rename) the tag\n\n        :param str name: the new name for the tag\n        :return: an updated `Tag` object\n        :rtype: Tag\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        api = self.doapi_manager\n        return api._tag(api.request(self.url, method='PUT',\n                                    data={\"name\": name})[\"tag\"])", "response": "Update the tag with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, *resources):\n        self.doapi_manager.request(self.url + '/resources', method='POST',\n                                   data={\"resources\": _to_taggable(resources)})", "response": "Apply the tag to one or more resources"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a badge role to your sphinx documents.", "response": "def add_badge_roles(app):\n    \"\"\"Add ``badge`` role to your sphinx documents. It can create\n    a colorful badge inline.\n    \"\"\"\n    from docutils.nodes import inline, make_id\n    from docutils.parsers.rst.roles import set_classes\n\n    def create_badge_role(color=None):\n        def badge_role(name, rawtext, text, lineno, inliner,\n                       options=None, content=None):\n            options = options or {}\n            set_classes(options)\n            classes = ['badge']\n            if color is None:\n                classes.append('badge-' + make_id(text))\n            else:\n                classes.append('badge-' + color)\n            if len(text) == 1:\n                classes.append('badge-one')\n            options['classes'] = classes\n            node = inline(rawtext, text, **options)\n            return [node], []\n        return badge_role\n\n    app.add_role('badge', create_badge_role())\n    app.add_role('badge-red', create_badge_role('red'))\n    app.add_role('badge-blue', create_badge_role('blue'))\n    app.add_role('badge-green', create_badge_role('green'))\n    app.add_role('badge-yellow', create_badge_role('yellow'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_github_roles(app, repo):\n    from docutils.nodes import reference\n    from docutils.parsers.rst.roles import set_classes\n\n    base_url = 'https://github.com/{}'.format(repo)\n\n    def github_role(name, rawtext, text, lineno, inliner,\n                    options=None, content=None):\n        if '#' in text:\n            t, n = text.split('#', 1)\n            if t.lower() in ['issue', 'issues']:\n                url = base_url + '/issues/{}'.format(n)\n            elif t.lower() in ['pr', 'pull', 'pull request']:\n                url = base_url + '/pull/{}'.format(n)\n            elif t.lower() in ['commit', 'commits']:\n                url = base_url + '/commit/{}'.format(n)\n        else:\n            url = base_url + '/' + text\n\n        options = options or {'classes': ['gh']}\n        set_classes(options)\n        node = reference(rawtext, text, refuri=url, **options)\n        return [node], []\n\n    app.add_role('gh', github_role)", "response": "Add GitHub role to the Sphinx document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a task based on a callable function and the arguments.", "response": "def promise(cls, fn, *args, **kwargs):\n        \"\"\"\n        Used to build a task based on a callable function and the arguments.\n        Kick it off and start execution of the task.\n\n        :param fn: callable\n        :param args: tuple\n        :param kwargs: dict\n        :return: SynchronousTask or AsynchronousTask\n        \"\"\"\n        task = cls.task(target=fn, args=args, kwargs=kwargs)\n        task.start()\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _interfacesToNames(interfaces):\n    if interfaces is ALL_IMPLEMENTED:\n        names = ALL_IMPLEMENTED_DB\n    else:\n        _checkConflictingNames(interfaces)\n        names = u','.join(map(qual, interfaces))\n    return names", "response": "Convert from a list of interfaces to a comma - separated list of names suitable for storing the database in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upgradeShare1to2(oldShare):\n    \"Upgrader from Share version 1 to version 2.\"\n    sharedInterfaces = []\n    attrs = set(oldShare.sharedAttributeNames.split(u','))\n    for iface in implementedBy(oldShare.sharedItem.__class__):\n        if set(iface) == attrs or attrs == set('*'):\n            sharedInterfaces.append(iface)\n\n    newShare = oldShare.upgradeVersion('sharing_share', 1, 2,\n                                       shareID=oldShare.shareID,\n                                       sharedItem=oldShare.sharedItem,\n                                       sharedTo=oldShare.sharedTo,\n                                       sharedInterfaces=sharedInterfaces)\n    return newShare", "response": "Upgrader from Share version 1 to version 2."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAuthenticatedRole(store):\n    def tx():\n        def addToEveryone(newAuthenticatedRole):\n            newAuthenticatedRole.becomeMemberOf(getEveryoneRole(store))\n            return newAuthenticatedRole\n        return store.findOrCreate(Role, addToEveryone, externalID=u'Authenticated')\n    return store.transact(tx)", "response": "Get the base Authenticated role for this store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the first role in the given store which corresponds to an accountName in the given store.", "response": "def getAccountRole(store, accountNames):\n    \"\"\"\n    Retrieve the first Role in the given store which corresponds an account\n    name in C{accountNames}.\n\n    Note: the implementation currently ignores all of the values in\n    C{accountNames} except for the first.\n\n    @param accountNames: A C{list} of two-tuples of account local parts and\n        domains.\n\n    @raise ValueError: If C{accountNames} is empty.\n\n    @rtype: L{Role}\n    \"\"\"\n    for (localpart, domain) in accountNames:\n        return getPrimaryRole(store, u'%s@%s' % (localpart, domain),\n                              createIfNotFound=True)\n    raise ValueError(\"Cannot get named role for unnamed account.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshare an item with a given role.", "response": "def shareItem(sharedItem, toRole=None, toName=None, shareID=None,\n              interfaces=ALL_IMPLEMENTED):\n    \"\"\"\n    Share an item with a given role.  This provides a way to expose items to\n    users for later retrieval with L{Role.getShare}.\n\n    This API is slated for deprecation.  Prefer L{Role.shareItem} in new code.\n\n    @param sharedItem: an item to be shared.\n\n    @param toRole: a L{Role} instance which represents the group that has\n    access to the given item.  May not be specified if toName is also\n    specified.\n\n    @param toName: a unicode string which uniquely identifies a L{Role} in the\n    same store as the sharedItem.\n\n    @param shareID: a unicode string.  If provided, specify the ID under which\n    the shared item will be shared.\n\n    @param interfaces: a list of Interface objects which specify the methods\n    and attributes accessible to C{toRole} on C{sharedItem}.\n\n    @return: a L{Share} which records the ability of the given role to access\n    the given item.\n    \"\"\"\n    warnings.warn(\"Use Role.shareItem() instead of sharing.shareItem().\",\n                  PendingDeprecationWarning,\n                  stacklevel=2)\n    if toRole is None:\n        if toName is not None:\n            toRole = getPrimaryRole(sharedItem.store, toName, True)\n        else:\n            toRole = getEveryoneRole(sharedItem.store)\n    return toRole.shareItem(sharedItem, shareID, interfaces)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _linearize(interface):\n    L = [interface]\n    for baseInterface in interface.__bases__:\n        if baseInterface is not Interface:\n            L.extend(_linearize(baseInterface))\n    return L", "response": "Linearizes an interface object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _commonParent(zi1, zi2):\n    shorter, longer = sorted([_linearize(x)[::-1] for x in zi1, zi2],\n                             key=len)\n    for n in range(len(shorter)):\n        if shorter[n] != longer[n]:\n            if n == 0:\n                return None\n            return shorter[n-1]\n    return shorter[-1]", "response": "Locate the common parent of two provided Interface objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nraising an exception if any of the names present in the given interfaces conflict with each other.", "response": "def _checkConflictingNames(interfaces):\n    \"\"\"\n    Raise an exception if any of the names present in the given interfaces\n    conflict with each other.\n\n    @param interfaces: a list of Zope Interface objects.\n\n    @return: None\n\n    @raise ConflictingNames: if any of the attributes of the provided\n    interfaces are the same, and they do not have a common base interface which\n    provides that name.\n    \"\"\"\n    names = {}\n    for interface in interfaces:\n        for name in interface:\n            if name in names:\n                otherInterface = names[name]\n                parent = _commonParent(interface, otherInterface)\n                if parent is None or name not in parent:\n                    raise ConflictingNames(\"%s conflicts with %s over %s\" % (\n                            interface, otherInterface, name))\n            names[name] = interface"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the accessible facet of an Item previously shared with the given shareID.", "response": "def getShare(store, role, shareID):\n    \"\"\"\n    Retrieve the accessible facet of an Item previously shared with\n    L{shareItem}.\n\n    This method is pending deprecation, and L{Role.getShare} should be\n    preferred in new code.\n\n    @param store: an axiom store (XXX must be the same as role.store)\n\n    @param role: a L{Role}, the primary role for a user attempting to retrieve\n    the given item.\n\n    @return: a L{SharedProxy}.  This is a wrapper around the shared item which\n    only exposes those interfaces explicitly allowed for the given role.\n\n    @raise: L{NoSuchShare} if there is no item shared to the given role for the\n    given shareID.\n    \"\"\"\n    warnings.warn(\"Use Role.getShare() instead of sharing.getShare().\",\n                  PendingDeprecationWarning,\n                  stacklevel=2)\n    return role.getShare(shareID)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an iterable that yields the shared proxies that are available to the given role from the given query.", "response": "def asAccessibleTo(role, query):\n    \"\"\"\n    Return an iterable which yields the shared proxies that are available to\n    the given role, from the given query.\n\n    This method is pending deprecation, and L{Role.asAccessibleTo} should be\n    preferred in new code.\n\n    @param role: The role to retrieve L{SharedProxy}s for.\n\n    @param query: An Axiom query describing the Items to retrieve, which this\n    role can access.\n    @type query: an L{iaxiom.IQuery} provider.\n    \"\"\"\n    warnings.warn(\n        \"Use Role.asAccessibleTo() instead of sharing.asAccessibleTo().\",\n        PendingDeprecationWarning,\n        stacklevel=2)\n    return role.asAccessibleTo(query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unShare(sharedItem):\n    sharedItem.store.query(Share, Share.sharedItem == sharedItem).deleteFromStore()", "response": "Unshare the given item from the public or shared view."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds a random Early Shared item.", "response": "def randomEarlyShared(store, role):\n    \"\"\"\n    If there are no explicitly-published public index pages to display, find a\n    shared item to present to the user as first.\n    \"\"\"\n    for r in role.allRoles():\n        share = store.findFirst(Share, Share.sharedTo == r,\n                                sort=Share.storeID.ascending)\n        if share is not None:\n            return share.sharedItem\n    raise NoSuchShare(\"Why, that user hasn't shared anything at all!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an instance of C { cls } derived from the given L { Item } that has been shared with the given L { Item }.", "response": "def fromSharedItem(cls, sharedItem):\n        \"\"\"\n        Return an instance of C{cls} derived from the given L{Item} that has\n        been shared.\n\n        Note that this API does not provide any guarantees of which result it\n        will choose.  If there are are multiple possible return values, it will\n        select and return only one.  Items may be shared under multiple\n        L{shareID}s.  A user may have multiple valid account names.  It is\n        sometimes impossible to tell from context which one is appropriate, so\n        if your application has another way to select a specific shareID you\n        should use that instead.\n\n        @param sharedItem: an L{Item} that should be shared.\n\n        @return: an L{Identifier} describing the C{sharedItem} parameter.\n\n        @raise L{NoSuchShare}: if the given item is not shared or its store\n        does not contain any L{LoginMethod} items which would identify a user.\n        \"\"\"\n        localpart = None\n        for (localpart, domain) in userbase.getAccountNames(sharedItem.store):\n            break\n        if localpart is None:\n            raise NoSuchShare()\n        for share in sharedItem.store.query(Share,\n                                            Share.sharedItem == sharedItem):\n            break\n        else:\n            raise NoSuchShare()\n        return cls(\n            shareID=share.shareID,\n            localpart=localpart, domain=domain)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef toString(self, obj):\n        return Box(shareID=obj.shareID.encode('utf-8'),\n                   localpart=obj.localpart.encode('utf-8'),\n                   domain=obj.domain.encode('utf-8')).serialize()", "response": "Convert the given L { Identifier } to a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromString(self, inString):\n        box = parseString(inString)[0]\n        return Identifier(shareID=box['shareID'].decode('utf-8'),\n                          localpart=box['localpart'].decode('utf-8'),\n                          domain=box['domain'].decode('utf-8'))", "response": "Convert the given string to an L { Identifier.\n        } object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninstructs this role to become a member of a group role.", "response": "def becomeMemberOf(self, groupRole):\n        \"\"\"\n        Instruct this (user or group) Role to become a member of a group role.\n\n        @param groupRole: The role that this group should become a member of.\n        \"\"\"\n        self.store.findOrCreate(RoleRelationship,\n                                group=groupRole,\n                                member=self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef allRoles(self, memo=None):\n        if memo is None:\n            memo = set()\n        elif self in memo:\n            # this is bad, but we have successfully detected and prevented the\n            # only really bad symptom, an infinite loop.\n            return\n        memo.add(self)\n        yield self\n        for groupRole in self.store.query(Role,\n                                          AND(RoleRelationship.member == self,\n                                              RoleRelationship.group == Role.storeID)):\n            for roleRole in groupRole.allRoles(memo):\n                yield roleRole", "response": "Return an iterator over all the roles that this role is authorized to act as."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshare an item with this role. This provides a way to expose items to users for later retrieval with L{Role.getShare}. @param sharedItem: an item to be shared. @param shareID: a unicode string. If provided, specify the ID under which the shared item will be shared. @param interfaces: a list of Interface objects which specify the methods and attributes accessible to C{toRole} on C{sharedItem}. @return: a L{Share} which records the ability of the given role to access the given item.", "response": "def shareItem(self, sharedItem, shareID=None, interfaces=ALL_IMPLEMENTED):\n        \"\"\"\n        Share an item with this role.  This provides a way to expose items to\n        users for later retrieval with L{Role.getShare}.\n\n        @param sharedItem: an item to be shared.\n\n        @param shareID: a unicode string.  If provided, specify the ID under which\n        the shared item will be shared.\n\n        @param interfaces: a list of Interface objects which specify the methods\n        and attributes accessible to C{toRole} on C{sharedItem}.\n\n        @return: a L{Share} which records the ability of the given role to\n        access the given item.\n        \"\"\"\n        if shareID is None:\n            shareID = genShareID(sharedItem.store)\n        return Share(store=self.store,\n                     shareID=shareID,\n                     sharedItem=sharedItem,\n                     sharedTo=self,\n                     sharedInterfaces=interfaces)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getShare(self, shareID):\n        shares = list(\n            self.store.query(Share,\n                             AND(Share.shareID == shareID,\n                                 Share.sharedTo.oneOf(self.allRoles()))))\n        interfaces = []\n        for share in shares:\n            interfaces += share.sharedInterfaces\n        if shares:\n            return SharedProxy(shares[0].sharedItem,\n                               interfaces,\n                               shareID)\n        raise NoSuchShare()", "response": "Retrieves a proxy object for a given shareID previously shared with\n        this role or one of its group roles via L { Role. shareItem } s sharedInterfaces\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asAccessibleTo(self, query):\n        # XXX TODO #2371: this method really *should* be returning an L{IQuery}\n        # provider as well, but that is kind of tricky to do.  Currently, doing\n        # queries leaks authority, because the resulting objects have stores\n        # and \"real\" items as part of their interface; having this be a \"real\"\n        # query provider would obviate the need to escape the L{SharedProxy}\n        # security constraints in order to do any querying.\n        allRoles = list(self.allRoles())\n        count = 0\n        unlimited = query.cloneQuery(limit=None)\n        for result in unlimited:\n            allShares = list(query.store.query(\n                    Share,\n                    AND(Share.sharedItem == result,\n                        Share.sharedTo.oneOf(allRoles))))\n            interfaces = []\n            for share in allShares:\n                interfaces += share.sharedInterfaces\n            if allShares:\n                count += 1\n                yield SharedProxy(result, interfaces, allShares[0].shareID)\n                if count == query.limit:\n                    return", "response": "Returns an iterable that yields the items that are available to the given role from the given query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef every_minute(dt=datetime.datetime.utcnow(), fmt=None):\n    date = datetime.datetime(dt.year, dt.month, dt.day, dt.hour, dt.minute, 1, 0, dt.tzinfo)\n    if fmt is not None:\n        return date.strftime(fmt)\n    return date", "response": "Returns a datetime object that represents every minute of the given date."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a new datetime object every hour.", "response": "def hourly(dt=datetime.datetime.utcnow(), fmt=None):\n    \"\"\"\n    Get a new datetime object every hour.\n    \"\"\"\n    date = datetime.datetime(dt.year, dt.month, dt.day, dt.hour, 1, 1, 0, dt.tzinfo)\n    if fmt is not None:\n        return date.strftime(fmt)\n    return date"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a date that is weekly.", "response": "def weekly(date=datetime.date.today()):\n    \"\"\"\n    Weeks start are fixes at Monday for now.\n    \"\"\"\n    return date - datetime.timedelta(days=date.weekday())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef biweekly(date=datetime.date.today()):\n    return datetime.date(date.year, date.month, 1 if date.day < 15 else 15)", "response": "Returns a new date that is biweekly."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a date object and return the first day of the month.", "response": "def monthly(date=datetime.date.today()):\n    \"\"\"\n    Take a date object and return the first day of the month.\n    \"\"\"\n    return datetime.date(date.year, date.month, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a date object that is quarterly.", "response": "def quarterly(date=datetime.date.today()):\n    \"\"\"\n    Fixed at: 1/1, 4/1, 7/1, 10/1.\n    \"\"\"\n    return datetime.date(date.year, ((date.month - 1)//3) * 3 + 1, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tabbedPane(self, req, tag):\n        navigation = webnav.getTabs(self.aggregator.getPreferenceCollections())\n        pages = list()\n        for tab in navigation:\n            f = inevow.IRenderer(\n                    self.aggregator.store.getItemByID(tab.storeID))\n            f.tab = tab\n            if hasattr(f, 'setFragmentParent'):\n                f.setFragmentParent(self)\n            pages.append((tab.name, f))\n\n        f = tabbedPane.TabbedPaneFragment(pages, name='preference-editor')\n        f.setFragmentParent(self)\n        return f", "response": "Render a tabbed pane for each top - level preferences collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsorts by one of my specified columns identified by attributeID.", "response": "def resort(self, attributeID, isAscending=None):\n        \"\"\"Sort by one of my specified columns, identified by attributeID\n        \"\"\"\n        if isAscending is None:\n            isAscending = self.defaultSortAscending\n\n        newSortColumn = self.columns[attributeID]\n        if newSortColumn.sortAttribute() is None:\n            raise Unsortable('column %r has no sort attribute' % (attributeID,))\n        if self.currentSortColumn == newSortColumn:\n            # if this query is to be re-sorted on the same column, but in the\n            # opposite direction to our last query, then use the first item in\n            # the result set as the marker\n            if self.isAscending == isAscending:\n                offset = 0\n            else:\n                # otherwise use the last\n                offset = -1\n        else:\n            offset = 0\n            self.currentSortColumn = newSortColumn\n        self.isAscending = isAscending\n        self._updateResults(self._sortAttributeValue(offset), True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a sequence of mappings of attribute IDs to column values for the current item.", "response": "def currentPage(self):\n        \"\"\"\n        Return a sequence of mappings of attribute IDs to column values, to\n        display to the user.\n\n        nextPage/prevPage will strive never to skip items whose column values\n        have not been returned by this method.\n\n        This is best explained by a demonstration.  Let's say you have a table\n        viewing an item with attributes 'a' and 'b', like this:\n\n        oid | a | b\n        ----+---+--\n        0   | 1 | 2\n        1   | 3 | 4\n        2   | 5 | 6\n        3   | 7 | 8\n        4   | 9 | 0\n\n        The table has 2 items per page.  You call currentPage and receive a\n        page which contains items oid 0 and oid 1.  item oid 1 is deleted.\n\n        If the next thing you do is to call nextPage, the result of currentPage\n        following that will be items beginning with item oid 2.  This is\n        because although there are no longer enough items to populate a full\n        page from 0-1, the user has never seen item #2 on a page, so the 'next'\n        page from the user's point of view contains #2.\n\n        If instead, at that same point, the next thing you did was to call\n        currentPage, *then* nextPage and currentPage again, the first\n        currentPage results would contain items #0 and #2; the following\n        currentPage results would contain items #3 and #4.  In this case, the\n        user *has* seen #2 already, so the user expects to see the following\n        item, not the same item again.\n        \"\"\"\n\n        self._updateResults(self._sortAttributeValue(0), equalToStart=True, refresh=True)\n        return self._currentResults"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the value of the sort attribute for the item at the given offset.", "response": "def _sortAttributeValue(self, offset):\n        \"\"\"\n        return the value of the sort attribute for the item at\n        'offset' in the results of the last query, otherwise None.\n        \"\"\"\n        if self._currentResults:\n            pageStart = (self._currentResults[offset][\n                self.currentSortColumn.attributeID],\n                         self._currentResults[offset][\n                    '__item__'].storeID)\n        else:\n            pageStart = None\n        return pageStart"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nestablishes connection with X server and prepares objects necessary to retrieve and send data.", "response": "def open_display(self):\n        \"\"\"Establishes connection with X server and prepares objects\n        necessary to retrieve and send data.\n        \"\"\"\n        self.close_display()    # Properly finish previous open_display()\n\n        XkbIgnoreExtension(False)\n\n        display_name = None\n        major = c_int(XkbMajorVersion)\n        minor = c_int(XkbMinorVersion)\n        reason = c_int()\n\n        self._display = XkbOpenDisplay(\n            display_name,\n            None, None, byref(major), byref(minor), byref(reason))\n        if not self._display:\n            if reason.value in OPEN_DISPLAY_ERRORS:\n                # Assume POSIX conformance\n                display_name = os.getenv(\"DISPLAY\") or \"default\"\n\n                raise X11Error(OPEN_DISPLAY_ERRORS[reason.value].format(\n                    libname=\"xkbgroup\",\n                    used_major=XkbMajorVersion,\n                    used_minor=XkbMinorVersion,\n                    found_major=major.value,\n                    found_minor=minor.value,\n                    display_name=display_name)\n                        + \".\")\n            else:\n                raise X11Error(\"Unknown error {} from XkbOpenDisplay.\".format(reason.value))\n\n        self._keyboard_description = XkbGetMap(self._display, 0, XkbUseCoreKbd)\n        if not self._keyboard_description:\n            self.close_display()\n            raise X11Error(\"Failed to get keyboard description.\")\n\n        # Controls mask doesn't affect the availability of xkb->ctrls->num_groups anyway\n        # Just use a valid value, and xkb->ctrls->num_groups will be definitely set\n        status = XkbGetControls(self._display, XkbAllControlsMask, self._keyboard_description)\n        if status != Success:\n            self.close_display()\n            raise X11Error(GET_CONTROLS_ERRORS[status] + \".\")\n\n        names_mask = XkbSymbolsNameMask | XkbGroupNamesMask\n        status = XkbGetNames(self._display, names_mask, self._keyboard_description)\n        if status != Success:\n            self.close_display()\n            raise X11Error(GET_NAMES_ERRORS[status] + \".\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose connection with X server and cleans up objects created on open_display().", "response": "def close_display(self):\n        \"\"\"Closes connection with X server and cleans up objects\n        created on open_display().\n        \"\"\"\n        if hasattr(self, \"_keyboard_description\") and self._keyboard_description:\n            names_mask = XkbSymbolsNameMask | XkbGroupNamesMask\n            XkbFreeNames(self._keyboard_description, names_mask, True)\n            XkbFreeControls(self._keyboard_description, XkbAllControlsMask, True)\n            XkbFreeClientMap(self._keyboard_description, 0, True)\n            del self._keyboard_description\n\n        if hasattr(self, \"_display\") and self._display:\n            XCloseDisplay(self._display)\n            del self._display"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef groups_data(self):\n        return _ListProxy(GroupData(num, name, symbol, variant)\n                          for (num, name, symbol, variant)\n                          in zip(range(self.groups_count),\n                                 self.groups_names,\n                                 self.groups_symbols,\n                                 self.groups_variants))", "response": "Returns all data about all groups."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of groups in the current keyboard.", "response": "def groups_count(self):\n        \"\"\"Number of all groups (get-only).\n\n        :getter: Returns number of all groups\n        :type: int\n        \"\"\"\n        if self._keyboard_description.contents.ctrls is not None:\n            return self._keyboard_description.contents.ctrls.contents.num_groups\n        else:\n            groups_source = self._groups_source\n\n            groups_count = 0\n            while (groups_count < XkbNumKbdGroups and\n                   groups_source[groups_count] != None_):\n                groups_count += 1\n\n            return groups_count"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all groups names.", "response": "def groups_names(self):\n        \"\"\"Names of all groups (get-only).\n\n        :getter: Returns names of all groups\n        :type: list of str\n        \"\"\"\n        return _ListProxy(self._get_group_name_by_num(i) for i in range(self.groups_count))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all data about the current group.", "response": "def group_data(self):\n        \"\"\"All data about the current group (get-only).\n\n        :getter: Returns all data about the current group\n        :type: GroupData\n        \"\"\"\n        return GroupData(self.group_num,\n                         self.group_name,\n                         self.group_symbol,\n                         self.group_variant)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef group_num(self):\n        xkb_state = XkbStateRec()\n        XkbGetState(self._display, XkbUseCoreKbd, byref(xkb_state))\n        return xkb_state.group", "response": "Get the current group number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef group_symbol(self):\n        s_mapping = {symdata.index: symdata.symbol for symdata in self._symboldata_list}\n        return s_mapping[self.group_num]", "response": "Returns the current group symbol."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the current group variant", "response": "def group_variant(self):\n        \"\"\"Current group variant (get-only).\n\n        :getter: Returns current group variant\n        :type: str\n        \"\"\"\n        v_mapping = {symdata.index: symdata.variant for symdata in self._symboldata_list}\n        return v_mapping[self.group_num] or \"\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a formatted version of format_str.", "response": "def format(self, format_str):\n        \"\"\"Returns a formatted version of format_str.\n        The only named replacement fields supported by this method and\n        their corresponding API calls are:\n\n        * {num}           group_num\n        * {name}          group_name\n        * {symbol}        group_symbol\n        * {variant}       group_variant\n        * {current_data}  group_data\n        * {nums}          groups_nums\n        * {names}         groups_names\n        * {symbols}       groups_symbols\n        * {variants}      groups_variants\n        * {all_data}      groups_data\n\n        Passing other replacement fields will result in raising exceptions.\n\n        :param format_str: a new style format string\n        :rtype: str\n        \"\"\"\n        return format_str.format(**{\n            \"num\": self.group_num,\n            \"name\": self.group_name,\n            \"symbol\": self.group_symbol,\n            \"variant\": self.group_variant,\n            \"current_data\": self.group_data,\n            \"count\": self.groups_count,\n            \"names\": self.groups_names,\n            \"symbols\": self.groups_symbols,\n            \"variants\": self.groups_variants,\n            \"all_data\": self.groups_data})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _construct_register(reg, default_reg):\n    if reg:\n        x = dict((k, reg.get(k, d)) for k, d in default_reg.items())\n    else:\n        x = dict(default_reg)\n    return x", "response": "Constructs a register dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pass_control_back(self, primary, secondary):\n        if secondary is None:\n            self._write(('*PCB', Integer(min=0, max=30)), primary)\n        else:\n            self._write(\n                ('*PCB', [Integer(min=0, max=30), Integer(min=0, max=30)]),\n                primary,\n                secondary\n            )", "response": "This function sends a control back command to the controller."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns when the specified port is free.", "response": "def free(host, port, timeout=float('Inf')):\n\t\"\"\"\n\tWait for the specified port to become free (dropping or rejecting\n\trequests). Return when the port is free or raise a Timeout if timeout has\n\telapsed.\n\n\tTimeout may be specified in seconds or as a timedelta.\n\tIf timeout is None or \u221e, the routine will run indefinitely.\n\n\t>>> free('localhost', find_available_local_port())\n\t\"\"\"\n\tif not host:\n\t\traise ValueError(\"Host values of '' or None are not allowed.\")\n\n\ttimer = timing.Timer(timeout)\n\n\twhile not timer.expired():\n\t\ttry:\n\t\t\t# Expect a free port, so use a small timeout\n\t\t\tChecker(timeout=0.1).assert_free(host, port)\n\t\t\treturn\n\t\texcept PortNotFree:\n\t\t\t# Politely wait.\n\t\t\ttime.sleep(0.1)\n\n\traise Timeout(\"Port {port} not free on {host}.\".format(**locals()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_available_local_port():\n\tinfos = socket.getaddrinfo(None, 0, socket.AF_UNSPEC, socket.SOCK_STREAM)\n\tfamily, proto, _, _, addr = next(iter(infos))\n\tsock = socket.socket(family, proto)\n\tsock.bind(addr)\n\taddr, port = sock.getsockname()[:2]\n\tsock.close()\n\treturn port", "response": "Find a free port on localhost."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_free(self, host, port=None):\n\t\tif port is None and isinstance(host, abc.Sequence):\n\t\t\thost, port = host[:2]\n\t\tif platform.system() == 'Windows':\n\t\t\thost = client_host(host)\n\t\tinfo = socket.getaddrinfo(\n\t\t\thost, port, socket.AF_UNSPEC, socket.SOCK_STREAM,\n\t\t)\n\t\tlist(itertools.starmap(self._connect, info))", "response": "Assert that the given addr is free."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an L { IMessageRouter } for the default case where no L { LoginSystem is present in the site store.", "response": "def _createLocalRouter(siteStore):\n    \"\"\"\n    Create an L{IMessageRouter} provider for the default case, where no\n    L{IMessageRouter} powerup is installed on the top-level store.\n\n    It wraps a L{LocalMessageRouter} around the L{LoginSystem} installed on the\n    given site store.\n\n    If no L{LoginSystem} is present, this returns a null router which will\n    simply log an error but not deliver the message anywhere, until this\n    configuration error can be corrected.\n\n    @rtype: L{IMessageRouter}\n    \"\"\"\n    ls = siteStore.findUnique(LoginSystem, default=None)\n    if ls is None:\n        try:\n            raise UnsatisfiedRequirement()\n        except UnsatisfiedRequirement:\n            log.err(Failure(),\n                    \"You have opened a substore from a site store with no \"\n                    \"LoginSystem.  Message routing is disabled.\")\n        return _NullRouter()\n    return LocalMessageRouter(ls)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef redeliver(self):\n        self.consequence.answerReceived(self.answerValue,\n                                        self.messageValue,\n                                        self.sender,\n                                        self.target)\n        self.deleteFromStore()", "response": "Re - deliver the answer to the consequence which previously handled it\n        by raising an exception."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _routerForAccount(self, identifier):\n        acct = self.loginSystem.accountByAddress(identifier.localpart,\n                                                 identifier.domain)\n        return IMessageRouter(acct, None)", "response": "Locate an avatar by the username and domain portions of anonymization identifier and return a router that can deliver a message to that user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef routeMessage(self, sender, target, value, messageID):\n        router = self._routerForAccount(target)\n        if router is not None:\n            router.routeMessage(sender, target, value, messageID)\n        else:\n            reverseRouter = self._routerForAccount(sender)\n            reverseRouter.routeAnswer(sender, target,\n                                      Value(DELIVERY_ERROR, ERROR_NO_USER),\n                                      messageID)", "response": "Route a message to another account."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef routeAnswer(self, originalSender, originalTarget, value, messageID):\n        router = self._routerForAccount(originalSender)\n        return router.routeAnswer(originalSender, originalTarget,\n                                  value, messageID)", "response": "Implement routeAnswer by synchronously locating an account via login system by address and then calling the router method to route the answer to that account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntelling the scheduler that this queue needs to be run at some point in the the future.", "response": "def _scheduleMePlease(self):\n        \"\"\"\n        This queue needs to have its run() method invoked at some point in the\n        future.  Tell the dependent scheduler to schedule it if it isn't\n        already pending execution.\n        \"\"\"\n        sched = IScheduler(self.store)\n        if len(list(sched.scheduledTimes(self))) == 0:\n            sched.schedule(self, sched.now())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef routeMessage(self, sender, target, value, messageID):\n        avatarName = sender.localpart + u\"@\" + sender.domain\n        # Look for the sender.\n        answer = self.store.findUnique(\n            _AlreadyAnswered,\n            AND(_AlreadyAnswered.originalSender == sender,\n                _AlreadyAnswered.messageID == messageID),\n            default=None)\n        if answer is None:\n            role = getPrimaryRole(self.store, avatarName)\n            try:\n                receiver = role.getShare(target.shareID)\n            except NoSuchShare:\n                response = Value(DELIVERY_ERROR,  ERROR_NO_SHARE)\n            else:\n                try:\n                    def txn():\n                        output = receiver.messageReceived(value, sender,\n                                                          target)\n                        if not isinstance(output, Value):\n                            raise TypeError(\"%r returned non-Value %r\" %\n                                            (receiver, output))\n                        return output\n                    response = self.store.transact(txn)\n                except RevertAndRespond, rar:\n                    response = rar.value\n                except:\n                    log.err(Failure(),\n                            \"An error occurred during inter-store \"\n                            \"message delivery.\")\n                    response = Value(DELIVERY_ERROR, ERROR_REMOTE_EXCEPTION)\n            answer = _AlreadyAnswered.create(store=self.store,\n                                             originalSender=sender,\n                                             originalTarget=target,\n                                             messageID=messageID,\n                                             value=response)\n        self._deliverAnswer(answer)\n        self._scheduleMePlease()", "response": "Route a message to another item in the store."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndelivers an answer to a message sent to this store via the store s parent s powerup.", "response": "def _deliverAnswer(self, answer):\n        \"\"\"\n        Attempt to deliver an answer to a message sent to this store, via my\n        store's parent's L{IMessageRouter} powerup.\n\n        @param answer: an L{AlreadyAnswered} that contains an answer to a\n        message sent to this store.\n        \"\"\"\n        router = self.siteRouter\n        if answer.deliveryDeferred is None:\n            d = answer.deliveryDeferred = router.routeAnswer(\n                answer.originalSender, answer.originalTarget, answer.value,\n                answer.messageID)\n            def destroyAnswer(result):\n                answer.deleteFromStore()\n            def transportErrorCheck(f):\n                answer.deliveryDeferred = None\n                f.trap(MessageTransportError)\n            d.addCallbacks(destroyAnswer, transportErrorCheck)\n            d.addErrback(log.err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nroutes an incoming answer to a message originally sent by this queue.", "response": "def routeAnswer(self, originalSender, originalTarget, value, messageID):\n        \"\"\"\n        Route an incoming answer to a message originally sent by this queue.\n        \"\"\"\n        def txn():\n            qm = self._messageFromSender(originalSender, messageID)\n            if qm is None:\n                return\n            c = qm.consequence\n            if c is not None:\n                c.answerReceived(value, qm.value,\n                                 qm.sender, qm.target)\n            elif value.type == DELIVERY_ERROR:\n                try:\n                    raise MessageTransportError(value.data)\n                except MessageTransportError:\n                    log.err(Failure(),\n                            \"An unhandled delivery error occurred on a message\"\n                            \" with no consequence.\")\n            qm.deleteFromStore()\n        try:\n            self.store.transact(txn)\n        except:\n            log.err(Failure(),\n                    \"An unhandled error occurred while handling a response to \"\n                    \"an inter-store message.\")\n            def answerProcessingFailure():\n                qm = self._messageFromSender(originalSender, messageID)\n                _FailedAnswer.create(store=qm.store,\n                                     consequence=qm.consequence,\n                                     sender=originalSender,\n                                     target=originalTarget,\n                                     messageValue=qm.value,\n                                     answerValue=value)\n                qm.deleteFromStore()\n            self.store.transact(answerProcessingFailure)\n        return defer.succeed(None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlocate a previously queued message by a given sender and messageID.", "response": "def _messageFromSender(self, sender, messageID):\n        \"\"\"\n        Locate a previously queued message by a given sender and messageID.\n        \"\"\"\n        return self.store.findUnique(\n            _QueuedMessage,\n            AND(_QueuedMessage.senderUsername == sender.localpart,\n                _QueuedMessage.senderDomain == sender.domain,\n                _QueuedMessage.messageID == messageID),\n            default=None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _verifySender(self, sender):\n        if self.store.findFirst(\n            LoginMethod,\n            AND(LoginMethod.localpart == sender.localpart,\n                LoginMethod.domain == sender.domain,\n                LoginMethod.internal == True)) is None:\n            raise BadSender(sender.localpart + u'@' + sender.domain,\n                            [lm.localpart + u'@' + lm.domain\n                             for lm in self.store.query(\n                        LoginMethod, LoginMethod.internal == True)])", "response": "Verify that this sender is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueues a persistent outgoing message.", "response": "def queueMessage(self, sender, target, value,\n                     consequence=None):\n        \"\"\"\n        Queue a persistent outgoing message.\n\n        @param sender: The a description of the shared item that is the sender\n        of the message.\n        @type sender: L{xmantissa.sharing.Identifier}\n\n        @param target: The a description of the shared item that is the target\n        of the message.\n        @type target: L{xmantissa.sharing.Identifier}\n\n        @param consequence: an item stored in the same database as this\n        L{MessageQueue} implementing L{IDeliveryConsequence}.\n        \"\"\"\n        self.messageCounter += 1\n        _QueuedMessage.create(store=self.store,\n                              sender=sender,\n                              target=target,\n                              value=value,\n                              messageID=self.messageCounter,\n                              consequence=consequence)\n        self._scheduleMePlease()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a message to the peer identified by the target using the commandObj and arguments.", "response": "def messageRemote(self, cmdObj, consequence=None, **args):\n        \"\"\"\n        Send a message to the peer identified by the target, via the\n        given L{Command} object and arguments.\n\n        @param cmdObj: a L{twisted.protocols.amp.Command}, whose serialized\n        form will be the message.\n\n        @param consequence: an L{IDeliveryConsequence} provider which will\n        handle the result of this message (or None, if no response processing\n        is desired).\n\n        @param args: keyword arguments which match the C{cmdObj}'s arguments\n        list.\n\n        @return: L{None}\n        \"\"\"\n        messageBox = cmdObj.makeArguments(args, self)\n        messageBox[COMMAND] = cmdObj.commandName\n        messageData = messageBox.serialize()\n        self.queue.queueMessage(self.sender, self.target,\n                                Value(AMP_MESSAGE_TYPE, messageData),\n                                consequence)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndeclare a method as being related to the given command object.", "response": "def expose(self, commandObject):\n        \"\"\"\n        Declare a method as being related to the given command object.\n\n        @param commandObject: a L{Command} subclass.\n        \"\"\"\n        thunk = super(_AMPExposer, self).expose(commandObject.commandName)\n        def thunkplus(function):\n            result = thunk(function)\n            result.command = commandObject\n            return result\n        return thunkplus"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expose(self, commandObject, exceptionType):\n        thunk = super(_AMPErrorExposer, self).expose(\n            (commandObject.commandName,\n             commandObject.errors.get(exceptionType)))\n        def thunkplus(function):\n            result = thunk(function)\n            result.command = commandObject\n            result.exception = exceptionType\n            return result\n        return thunkplus", "response": "Expose a function for processing a given AMP error."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef errbackForName(self, instance, commandName, errorName):\n        return super(_AMPErrorExposer, self).get(instance, (commandName, errorName))", "response": "Retrieve an errback for a given command name and error name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _boxFromData(self, messageData):\n        inputBoxes = parseString(messageData)\n        if not len(inputBoxes) == 1:\n            raise MalformedMessage()\n        [inputBox] = inputBoxes\n        return inputBox", "response": "Parse the AMP box from the serialized AMP message data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef answerReceived(self, value, originalValue,\n                       originalSender, originalTarget):\n        \"\"\"\n        An answer was received.  Dispatch to the appropriate answer responder,\n        i.e. a method on this object exposed with L{answerMethod.expose}.\n\n        @see IDeliveryConsequence.answerReceived\n        \"\"\"\n        if value.type != AMP_ANSWER_TYPE:\n            raise UnknownMessageType()\n        commandName = self._boxFromData(originalValue.data)[COMMAND]\n        rawArgs = self._boxFromData(value.data)\n        placeholder = _ProtocolPlaceholder(originalSender, originalTarget)\n        if ERROR in rawArgs:\n            thunk = errorMethod.errbackForName(self, commandName, rawArgs[ERROR])\n            thunk(Failure(thunk.exception()))\n        else:\n            thunk = answerMethod.responderForName(self, commandName)\n            arguments = thunk.command.parseResponse(rawArgs, placeholder)\n            thunk(**arguments)", "response": "An answer was received. Dispatch to the appropriate answer responder and return the object ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap around requests. get that shorten caller url and takes care of errors", "response": "def _get(self, resource, payload=None):\n        ''' Wrapper around requests.get that shorten caller url and takes care\n        of errors '''\n        # Avoid dangerous default function argument `{}`\n        payload = payload or {}\n        # Build the request and return json response\n        return requests.get(\n            '{}/{}/{}'.format(\n                self.master, pyconsul.__consul_api_version__, resource),\n            params=payload\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping around requests. put that shorten caller url takes care of errors", "response": "def _put(self, resource, payload=None):\n        ''' Wrapper around requests.put that shorten caller url and takes care\n        of errors '''\n        # Avoid dangerous default function argument `{}`\n        payload = payload or {}\n        # Build the request and return json response\n        return requests.put(\n            '{}/{}/{}'.format(\n                self.master, pyconsul.__consul_api_version__, resource),\n            params=payload\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef table_names(self):\n        query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n        cursor = self.connection.execute(query)\n        results = cursor.fetchall()\n        return [result_tuple[0] for result_tuple in results]", "response": "Returns a list of all tables in the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop_all_tables(self):\n        for table_name in self.table_names():\n            self.execute_sql(\"DROP TABLE %s\" % table_name)\n        self.connection.commit()", "response": "Drop all tables in the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_sql(self, sql, commit=False):\n        logger.info(\"Running sqlite query: \\\"%s\\\"\", sql)\n        self.connection.execute(sql)\n        if commit:\n            self.connection.commit()", "response": "Log and then execute a SQL query"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfinalize the database with the specified version number.", "response": "def _finalize_database(self, version):\n        \"\"\"\n        Create metadata table for database with version number.\n\n        Parameters\n        ----------\n        version : int\n            Tag created database with user-specified version number\n        \"\"\"\n        require_integer(version, \"version\")\n        create_metadata_sql = \\\n            \"CREATE TABLE %s (version INT)\" % METADATA_TABLE_NAME\n        self.execute_sql(create_metadata_sql)\n        insert_version_sql = \\\n            \"INSERT INTO %s VALUES (%s)\" % (METADATA_TABLE_NAME, version)\n        self.execute_sql(insert_version_sql)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a sqlite3 table from the given metadata.", "response": "def _create_table(self, table_name, column_types, primary=None, nullable=()):\n        \"\"\"Creates a sqlite3 table from the given metadata.\n\n        Parameters\n        ----------\n\n        column_types : list of (str, str) pairs\n            First element of each tuple is the column name, second element is the sqlite3 type\n\n        primary : str, optional\n            Which column is the primary key\n\n        nullable : iterable, optional\n            Names of columns which have null values\n        \"\"\"\n        require_string(table_name, \"table name\")\n        require_iterable_of(column_types, tuple, name=\"rows\")\n        if primary is not None:\n            require_string(primary, \"primary\")\n        require_iterable_of(nullable, str, name=\"nullable\")\n\n        column_decls = []\n        for column_name, column_type in column_types:\n            decl = \"%s %s\" % (column_name, column_type)\n            if column_name == primary:\n                decl += \" UNIQUE PRIMARY KEY\"\n            if column_name not in nullable:\n                decl += \" NOT NULL\"\n            column_decls.append(decl)\n        column_decl_str = \", \".join(column_decls)\n        create_table_sql = \\\n            \"CREATE TABLE %s (%s)\" % (table_name, column_decl_str)\n        self.execute_sql(create_table_sql)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, tables, version):\n        for table in tables:\n            self._create_table(\n                table_name=table.name,\n                column_types=table.column_types,\n                primary=table.primary_key,\n                nullable=table.nullable)\n            self._fill_table(table.name, table.rows)\n            self._create_indices(table.name, table.indices)\n        self._finalize_database(version)\n        self._commit()", "response": "Create the database and finalize the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an index over multiple columns of a given table.", "response": "def _create_index(self, table_name, index_columns):\n        \"\"\"\n        Creates an index over multiple columns of a given table.\n\n        Parameters\n        ----------\n        table_name : str\n\n        index_columns : iterable of str\n            Which columns should be indexed\n        \"\"\"\n\n        logger.info(\n            \"Creating index on %s (%s)\",\n            table_name,\n            \", \".join(index_columns))\n        index_name = \"%s_index_%s\" % (\n            table_name,\n            \"_\".join(index_columns))\n        self.connection.execute(\n            \"CREATE INDEX IF NOT EXISTS %s ON %s (%s)\" % (\n                index_name,\n                table_name,\n                \", \".join(index_columns)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_indices(self, table_name, indices):\n        require_string(table_name, \"table_name\")\n        require_iterable_of(indices, (tuple, list))\n        for index_column_set in indices:\n            self._create_index(table_name, index_column_set)", "response": "Create multiple indices on a given table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wrapModel(self, model):\n        res = IResource(model, None)\n        if res is None:\n            frag = INavigableFragment(model)\n            fragmentName = getattr(frag, 'fragmentName', None)\n            if fragmentName is not None:\n                fragDocFactory = self._getDocFactory(fragmentName)\n                if fragDocFactory is not None:\n                    frag.docFactory = fragDocFactory\n            if frag.docFactory is None:\n                raise CouldNotLoadFromThemes(frag, self._preferredThemes())\n            useAthena = isinstance(frag, (athena.LiveFragment, athena.LiveElement))\n            return self._wrapNavFrag(frag, useAthena)\n        else:\n            return res", "response": "Converts application - provided model objects to L { IResource providers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to locate the child via the. fragment attribute then fall back to normal locateChild behavior.", "response": "def locateChild(self, ctx, segments):\n        \"\"\"\n        Attempt to locate the child via the '.fragment' attribute, then fall\n        back to normal locateChild behavior.\n        \"\"\"\n        if self.fragment is not None:\n            # There are still a bunch of bogus subclasses of this class, which\n            # are used in a variety of distasteful ways.  'fragment' *should*\n            # always be set to something that isn't None, but there's no way to\n            # make sure that it will be for the moment.  Every effort should be\n            # made to reduce public use of subclasses of this class (instead\n            # preferring to wrap content objects with\n            # IWebViewer.wrapModel()), so that the above check can be\n            # removed. -glyph\n            lc = getattr(self.fragment, 'locateChild', None)\n            if lc is not None:\n                x = lc(ctx, segments)\n                if x is not NotFound:\n                    return x\n        return super(MantissaViewHelper, self).locateChild(ctx, segments)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlocate a statically defined child or a statically defined child.", "response": "def locateChild(self, context, segments):\n        \"\"\"\n        Return a statically defined child or a child defined by a site root\n        plugin or an avatar from guard.\n        \"\"\"\n        request = IRequest(context)\n        webViewer = IWebViewer(self.store, None)\n        childAndSegments = self.siteProduceResource(request, segments, webViewer)\n        if childAndSegments is not None:\n            return childAndSegments\n        return NotFound"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef siteProduceResource(self, req, segments, webViewer):\n\n        # rootChild_* is not the same as child_, because its signature is\n        # different.  Maybe this should be done some other way.\n        shortcut = getattr(self, 'rootChild_' + segments[0], None)\n        if shortcut:\n            res = shortcut(req, webViewer)\n            if res is not None:\n                return res, segments[1:]\n\n        for plg in self.store.powerupsFor(ISiteRootPlugin):\n            produceResource = getattr(plg, 'produceResource', None)\n            if produceResource is not None:\n                childAndSegments = produceResource(req, segments, webViewer)\n            else:\n                childAndSegments = plg.resourceFactory(segments)\n            if childAndSegments is not None:\n                return childAndSegments\n        return None", "response": "Retrieve a child resource and segments from rootChild_ methods on this object and SiteRootPlugins."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef indirect(self, interface):\n        if interface is IResource:\n            siteStore = self.store.parent\n            if self.store.parent is None:\n                siteStore = self.store\n            return VirtualHostWrapper(\n                siteStore,\n                IWebViewer(self.store),\n                self)\n        return self", "response": "Create a VirtualHostWrapper so it can handle web requests."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the given hostname is a subdomain of any known domain.", "response": "def subdomain(self, hostname):\n        \"\"\"\n        Determine of which known domain the given hostname is a subdomain.\n\n        @return: A two-tuple giving the subdomain part and the domain part or\n            C{None} if the domain is not a subdomain of any known domain.\n        \"\"\"\n        hostname = hostname.split(\":\")[0]\n        for domain in getDomainNames(self.siteStore):\n            if hostname.endswith(\".\" + domain):\n                username = hostname[:-len(domain) - 1]\n                if username != \"www\":\n                    return username, domain\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelegate dispatch to a sharing resource and segments implementation.", "response": "def locateChild(self, context, segments):\n        \"\"\"\n        Delegate dispatch to a sharing resource if the request is for a user\n        subdomain, otherwise fall back to the wrapped resource's C{locateChild}\n        implementation.\n        \"\"\"\n        request = IRequest(context)\n        hostname = request.getHeader('host')\n\n        info = self.subdomain(hostname)\n        if info is not None:\n            username, domain = info\n            index = UserIndexPage(IRealm(self.siteStore),\n                                  self.webViewer)\n            resource = index.locateChild(None, [username])[0]\n            return resource, segments\n        return self.wrapped.locateChild(context, segments)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _webTranslator(store, fallback):\n    if fallback is None:\n        fallback = IWebTranslator(store, None)\n        if fallback is None:\n            warnings.warn(\n                \"No IWebTranslator plugin when creating Scrolltable - broken \"\n                \"configuration, now deprecated!  Try passing webTranslator \"\n                \"keyword argument.\", category=DeprecationWarning,\n                stacklevel=4)\n    return fallback", "response": "Returns a webTranslator for the given store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming a query to obtain some rows from the table represented by this model.", "response": "def inequalityQuery(self, constraint, count, isAscending):\n        \"\"\"\n        Perform a query to obtain some rows from the table represented\n        by this model, at the behest of a networked client.\n\n        @param constraint: an additional constraint to apply to the\n        query.\n        @type constraint: L{axiom.iaxiom.IComparison}.\n\n        @param count: the maximum number of rows to return.\n        @type count: C{int}\n\n        @param isAscending: a boolean describing whether the query\n        should be yielding ascending or descending results.\n        @type isAscending: C{bool}\n\n        @return: an query which will yield some results from this\n        model.\n        @rtype: L{axiom.iaxiom.IQuery}\n        \"\"\"\n        if self.baseConstraint is not None:\n            if constraint is not None:\n                constraint = AND(self.baseConstraint, constraint)\n            else:\n                constraint = self.baseConstraint\n        # build the sort\n        currentSortAttribute = self.currentSortColumn.sortAttribute()\n        if isAscending:\n            sort = (currentSortAttribute.ascending,\n                    self.itemType.storeID.ascending)\n        else:\n            sort = (currentSortAttribute.descending,\n                    self.itemType.storeID.descending)\n        return self.store.query(self.itemType, constraint, sort=sort,\n                                limit=count).distinct()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rowsAfterValue(self, value, count):\n        if value is None:\n            query = self.inequalityQuery(None, count, True)\n        else:\n            pyvalue = self._toComparableValue(value)\n            currentSortAttribute = self.currentSortColumn.sortAttribute()\n            query = self.inequalityQuery(currentSortAttribute >= pyvalue, count, True)\n        return self.constructRows(query)", "response": "Retrieve some rows at or after a given value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap around L { rowsAfterItem } which accepts the web ID for a item and returns the specified number of rows.", "response": "def rowsAfterRow(self, rowObject, count):\n        \"\"\"\n        Wrapper around L{rowsAfterItem} which accepts the web ID for a item\n        instead of the item itself.\n\n        @param rowObject: a dictionary mapping strings to column values, sent\n        from the client.  One of those column values must be C{__id__} to\n        uniquely identify a row.\n\n        @param count: an integer, the number of rows to return.\n        \"\"\"\n        webID = rowObject['__id__']\n        return self.rowsAfterItem(\n            self.webTranslator.fromWebID(webID),\n            count)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap around rowsBeforeItem which accepts the web ID for a item instead of the item itself.", "response": "def rowsBeforeRow(self, rowObject, count):\n        \"\"\"\n        Wrapper around L{rowsBeforeItem} which accepts the web ID for a item\n        instead of the item itself.\n\n        @param rowObject: a dictionary mapping strings to column values, sent\n        from the client.  One of those column values must be C{__id__} to\n        uniquely identify a row.\n\n        @param count: an integer, the number of rows to return.\n        \"\"\"\n        webID = rowObject['__id__']\n        return self.rowsBeforeItem(\n            self.webTranslator.fromWebID(webID),\n            count)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _toComparableValue(self, value):\n        if hasattr(self.currentSortColumn, 'toComparableValue'):\n            return self.currentSortColumn.toComparableValue(value)\n        # Retrieve the location of the class's definition so that we can alert\n        # the user as to where they need to insert their implementation.\n        classDef = self.currentSortColumn.__class__\n        filename = inspect.getsourcefile(classDef)\n        lineno = inspect.findsource(classDef)[1]\n        warnings.warn_explicit(\n            \"IColumn implementor \" + qual(self.currentSortColumn.__class__) + \" \"\n            \"does not implement method toComparableValue.  This is required since \"\n            \"Mantissa 0.6.6.\",\n            DeprecationWarning, filename, lineno)\n        return value", "response": "Internal method that converts the value into a comparable value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves display data for rows with sort - column values less than the given value.", "response": "def rowsBeforeValue(self, value, count):\n        \"\"\"\n        Retrieve display data for rows with sort-column values less than the\n        given value.\n\n        @type value: Some type compatible with the current sort column.\n        @param value: Starting value in the index for the current sort column\n        at which to start returning results.  Rows with a column value for the\n        current sort column which is less than this value will be returned.\n\n        @type count: C{int}\n        @param count: The number of rows to return.\n\n        @return: A list of row data, ordered by the current sort column, ending\n        at C{value} and containing at most C{count} elements.\n        \"\"\"\n        if value is None:\n            query = self.inequalityQuery(None, count, False)\n        else:\n            pyvalue = self._toComparableValue(value)\n            currentSortAttribute = self.currentSortColumn.sortAttribute()\n            query = self.inequalityQuery(\n                currentSortAttribute < pyvalue, count, False)\n        return self.constructRows(query)[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rowsBeforeItem(self, item, count):\n        currentSortAttribute = self.currentSortColumn.sortAttribute()\n        value = currentSortAttribute.__get__(item, type(item))\n        firstQuery = self.inequalityQuery(\n            AND(currentSortAttribute == value,\n                self.itemType.storeID < item.storeID),\n            count, False)\n        results = self.constructRows(firstQuery)\n        count -= len(results)\n        if count:\n            secondQuery = self.inequalityQuery(currentSortAttribute < value,\n                                               count, False)\n            results.extend(self.constructRows(secondQuery))\n        return results[::-1]", "response": "Returns the rows before the given item."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requestRowRange(self, rangeBegin, rangeEnd):\n        return self.constructRows(self.performQuery(rangeBegin, rangeEnd))", "response": "Retrieve display data for the given range of rows."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getTableMetadata(self):\n        coltypes = {}\n        for (colname, column) in self.columns.iteritems():\n            sortable = column.sortAttribute() is not None\n            coltype = column.getType()\n            if coltype is not None:\n                coltype = unicode(coltype, 'ascii')\n            coltypes[colname] = (coltype, sortable)\n\n        if self.currentSortColumn:\n            csc = unicode(self.currentSortColumn.sortAttribute().attrname, 'ascii')\n        else:\n            csc = None\n\n        return [self.columnNames, coltypes, self.requestCurrentSize(),\n                csc, self.isAscending]", "response": "Retrieve a description of the various properties of this scrolltable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef constructRows(self, items):\n        rows = []\n        for item in items:\n            row = dict((colname, col.extractValue(self, item))\n                       for (colname, col) in self.columns.iteritems())\n            link = self.linkToItem(item)\n            if link is not None:\n                row[u'__id__'] = link\n            rows.append(row)\n\n        return rows", "response": "Build row objects that are serializable using Athena for sending to the\n        client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of serializable objects that describe the interesting columns on our item type.", "response": "def _getColumnList(self):\n        \"\"\"\n        Get a list of serializable objects that describe the interesting\n        columns on our item type.  Columns which report having no type will be\n        treated as having the type I{text}.\n\n        @rtype: C{list} of C{dict}\n        \"\"\"\n        columnList = []\n        for columnName in self.columnNames:\n            column = self.columns[columnName]\n            type = column.getType()\n            if type is None:\n                type = 'text'\n            columnList.append(\n                {u'name': columnName,\n                 u'type': type.decode('ascii')})\n        return columnList"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getInitialArguments(self):\n        ic = IColumn(self.currentSortColumn)\n        return [ic.attributeID.decode('ascii'),\n                self._getColumnList(),\n                self.isAscending]", "response": "Returns the constructor arguments required for the JavaScript client class Mantissa. ScrollTable. ScrollTable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef printChannelColRow(campaign, ra, dec):\n    fovobj = fields.getKeplerFov(campaign)\n    ch, col, row = fovobj.getChannelColRow(ra, dec)\n    print(\"Position in C{}: channel {}, col {:.0f}, row {:.0f}.\".format(campaign, int(ch), col, row))", "response": "Prints the channel col row for a given campaign and coordinate."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef findCampaigns(ra, dec):\n    # Temporary disable the logger to avoid the preliminary field warnings\n    logger.disabled = True\n    campaigns_visible = []\n    for c in fields.getFieldNumbers():\n        fovobj = fields.getKeplerFov(c)\n        if onSiliconCheck(ra, dec, fovobj):\n            campaigns_visible.append(c)\n    # Re-enable the logger\n    logger.disabled = True\n    return campaigns_visible", "response": "Returns a list of the campaigns that cover a given position."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of the campaigns that cover a given target name.", "response": "def findCampaignsByName(target):\n    \"\"\"Returns a list of the campaigns that cover a given target.\n\n    Parameters\n    ----------\n    target : str\n        Name of the celestial object.\n\n    Returns\n    -------\n    campaigns : list of int\n        A list of the campaigns that cover the given target name.\n\n    ra, dec : float, float\n        Resolved coordinates in decimal degrees (J2000).\n\n    Exceptions\n    ----------\n    Raises an ImportError if AstroPy is not installed.\n    Raises a ValueError if `name` cannot be resolved to coordinates.\n    \"\"\"\n    # Is AstroPy (optional dependency) installed?\n    try:\n        from astropy.coordinates import SkyCoord\n        from astropy.coordinates.name_resolve import NameResolveError\n        from astropy.utils.data import conf\n        conf.remote_timeout = 90\n    except ImportError:\n        print('Error: AstroPy needs to be installed for this feature.')\n        sys.exit(1)\n    # Translate the target name into celestial coordinates\n    try:\n        crd = SkyCoord.from_name(target)\n    except NameResolveError:\n        raise ValueError('Could not find coordinates '\n                         'for target \"{0}\".'.format(target))\n    # Find the campaigns with visibility\n    return findCampaigns(crd.ra.deg, crd.dec.deg), crd.ra.deg, crd.dec.deg"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexposes K2findCampaigns to the command line.", "response": "def K2findCampaigns_main(args=None):\n    \"\"\"Exposes K2findCampaigns to the command line.\"\"\"\n    parser = argparse.ArgumentParser(\n                    description=\"Check if a celestial coordinate is \"\n                                \"(or was) observable by any past or future \"\n                                \"observing campaign of NASA's K2 mission.\")\n    parser.add_argument('ra', nargs=1, type=float,\n                        help=\"Right Ascension in decimal degrees (J2000).\")\n    parser.add_argument('dec', nargs=1, type=float,\n                        help=\"Declination in decimal degrees (J2000).\")\n    parser.add_argument('-p', '--plot', action='store_true',\n                        help=\"Produce a plot showing the target position \"\n                             \"with respect to all K2 campaigns.\")\n    args = parser.parse_args(args)\n    ra, dec = args.ra[0], args.dec[0]\n    campaigns = findCampaigns(ra, dec)\n    # Print the result\n    if len(campaigns):\n        print(Highlight.GREEN + \"Success! The target is on silicon \"\n              \"during K2 campaigns {0}.\".format(campaigns) + Highlight.END)\n    else:\n        print(Highlight.RED + \"Sorry, the target is not on silicon \"\n              \"during any K2 campaign.\" + Highlight.END)\n    # Print the pixel positions\n    for c in campaigns:\n        printChannelColRow(c, ra, dec)\n    # Make a context plot if the user requested so\n    if args.plot:\n        save_context_plots(ra, dec, \"Your object\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexposes K2findCampaigns to the command line.", "response": "def K2findCampaigns_byname_main(args=None):\n    \"\"\"Exposes K2findCampaigns to the command line.\"\"\"\n    parser = argparse.ArgumentParser(\n                    description=\"Check if a target is \"\n                                \"(or was) observable by any past or future \"\n                                \"observing campaign of NASA's K2 mission.\")\n    parser.add_argument('name', nargs=1, type=str,\n                        help=\"Name of the object.  This will be passed on \"\n                             \"to the CDS name resolver \"\n                             \"to retrieve coordinate information.\")\n    parser.add_argument('-p', '--plot', action='store_true',\n                        help=\"Produce a plot showing the target position \"\n                             \"with respect to all K2 campaigns.\")\n    args = parser.parse_args(args)\n    targetname = args.name[0]\n    try:\n        campaigns, ra, dec = findCampaignsByName(targetname)\n    except ValueError:\n        print(\"Error: could not retrieve coordinates for {0}.\".format(targetname))\n        print(\"The target may be unknown or there may be a problem \"\n              \"connecting to the coordinate server.\")\n        sys.exit(1)\n    # Print the result\n    if len(campaigns):\n        print(Highlight.GREEN +\n              \"Success! {0} is on silicon \".format(targetname) +\n              \"during K2 campaigns {0}.\".format(campaigns) +\n              Highlight.END)\n    else:\n        print(Highlight.RED + \"Sorry, {} is not on silicon \"\n              \"during any K2 campaign.\".format(targetname) + Highlight.END)\n    # Print the pixel positions\n    for c in campaigns:\n        printChannelColRow(c, ra, dec)\n    # Make a context plot if the user requested so\n    if args.plot:\n        save_context_plots(ra, dec, targetname=targetname)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexposing K2findCampaigns - csv to the command line.", "response": "def K2findCampaigns_csv_main(args=None):\n    \"\"\"Exposes K2findCampaigns-csv to the command line.\"\"\"\n    parser = argparse.ArgumentParser(\n                    description=\"Check which objects listed in a CSV table \"\n                                \"are (or were) observable by NASA's K2 mission.\")\n    parser.add_argument('input_filename', nargs=1, type=str,\n                        help=\"Path to a comma-separated table containing \"\n                             \"columns 'ra,dec,kepmag' (decimal degrees) \"\n                             \"or 'name'.\")\n    args = parser.parse_args(args)\n    input_fn = args.input_filename[0]\n    output_fn = input_fn + '-K2findCampaigns.csv'\n    # First, try assuming the file has the classic \"ra,dec,kepmag\" format\n    try:\n        ra, dec, kepmag = parse_file(input_fn, exit_on_error=False)\n        campaigns = np.array([findCampaigns(ra[idx], dec[idx])\n                              for idx in range(len(ra))])\n        output = np.array([ra, dec, kepmag, campaigns])\n        print(\"Writing {0}\".format(output_fn))\n        np.savetxt(output_fn, output.T, delimiter=', ',\n                   fmt=['%10.10f', '%10.10f', '%10.2f', '%s'])\n    # If this fails, assume the file has a single \"name\" column\n    except ValueError:\n        names = [name.strip() for name in open(input_fn, \"r\").readlines()\n                 if len(name.strip()) > 0]\n        print(\"Writing {0}\".format(output_fn))\n        output = open(output_fn, \"w\")\n        for target in names:\n            try:\n                campaigns, ra, dec = findCampaignsByName(target)\n            except ValueError:\n                campaigns = []\n            output.write(\"{0}, {1}\\n\".format(target, campaigns))\n            output.flush()\n        output.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmock import statements by ignoring ImportErrors MimeType and replacing the missing module with a MagicMock object.", "response": "def mock_import(do_not_mock=None, **mock_kwargs):\n    \"\"\"\n    Mocks import statements by ignoring ImportErrors\n    and replacing the missing module with a Mock.\n\n    :param str|unicode|list[str|unicode] do_not_mock: names of modules\n        that should exists, and an ImportError could be raised for.\n    :param mock_kwargs: kwargs for MagicMock object.\n    :return: patch object\n    \"\"\"\n\n    do_not_mock = _to_list(do_not_mock)\n\n    def try_import(module_name, *args, **kwargs):\n        try:\n            return _builtins_import(module_name, *args, **kwargs)\n        except:    # intentionally catch all exceptions\n            if any((_match(module_name, prefix) for prefix in do_not_mock)):\n                # This is a module we need to import,\n                # so we raise the exception instead of mocking it\n                raise\n            # Mock external module so we can peacefully create our client\n            return mock.MagicMock(**mock_kwargs)\n\n    return mock.patch('six.moves.builtins.__import__', try_import)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming an HTTP request to the specified URL and return the response body as a decoded JSON value.", "response": "def request(self, url, params=None, data=None, method='GET'):\n        \"\"\"\n        Perform an HTTP request and return the response body as a decoded JSON\n        value\n\n        :param str url: the URL to make the request of.  If ``url`` begins with\n            a forward slash, :attr:`endpoint` is prepended to it; otherwise,\n            ``url`` is treated as an absolute URL.\n        :param dict params: parameters to add to the URL's query string\n        :param data: a value to send in the body of the request.  If ``data``\n            is not a string, it will be serialized as JSON before sending;\n            either way, the :mailheader:`Content-Type` header of the request\n            will be set to :mimetype:`application/json`.  Note that a ``data``\n            value of `None` means \"Don't send any data\"; to send an actual\n            `None` value, convert it to JSON (i.e., the string ``\"null\"``)\n            first.\n        :param str method: the HTTP method to use: ``\"GET\"``, ``\"POST\"``,\n            ``\"PUT\"``, or ``\"DELETE\"`` (case-insensitive); default: ``\"GET\"``\n        :return: a decoded JSON value, or `None` if no data was returned\n        :rtype: `list` or `dict` (depending on the request) or `None`\n        :raises ValueError: if ``method`` is an invalid value\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        if url.startswith('/'):\n            url = self.endpoint + url\n        attrs = {\n            \"headers\": {\"Authorization\": \"Bearer \" + self.api_token},\n            \"params\": params if params is not None else {},\n            \"timeout\": self.timeout,\n        }\n        method = method.upper()\n        if data is not None:\n            if not isinstance(data, string_types):\n                data = json.dumps(data, cls=DOEncoder)\n            attrs[\"data\"] = data\n            attrs[\"headers\"][\"Content-Type\"] = \"application/json\"\n        if method == 'GET':\n            r = self.session.get(url, **attrs)\n        elif method == 'POST':\n            r = self.session.post(url, **attrs)\n        elif method == 'PUT':\n            r = self.session.put(url, **attrs)\n        elif method == 'DELETE':\n            r = self.session.delete(url, **attrs)\n        else:\n            raise ValueError('Unrecognized HTTP method: ' + repr(method))\n        self.last_response = r\n        self.last_meta = None\n        if not r.ok:\n            raise DOAPIError(r)\n        if r.text.strip():\n            # Even when returning \"no content\", the API can still return\n            # whitespace.\n            response = r.json()\n            try:\n                self.last_meta = response[\"meta\"]\n            except (KeyError, TypeError):\n                pass\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef last_rate_limit(self):\n        if self.last_response is None:\n            return None\n        else:\n            return {k:v for k,v in iteritems(self.last_response.headers)\n                        if k.lower().startswith('ratelimit')}", "response": "Returns the most recent rate limit information in the most recent\n            response or None if no requests have been made yet."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paginate(self, url, key, params=None):\n        if params is None:\n            params = {}\n        if self.per_page is not None and \"per_page\" not in params:\n            params = dict(params, per_page=self.per_page)\n        page = self.request(url, params=params)\n        while True:\n            try:\n                objects = page[key]\n            except (KeyError, TypeError):\n                raise ValueError('{0!r}: not a key of the response body'\\\n                                 .format(key))\n            for obj in objects:\n                yield obj\n            try:\n                url = page[\"links\"][\"pages\"][\"next\"]\n            except KeyError:\n                break\n            page = self.request(url)", "response": "Fetch a sequence of paginated resources from the API endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_droplet(self, name, image, size, region, ssh_keys=None,\n                       backups=None, ipv6=None, private_networking=None,\n                       user_data=None, **kwargs):\n        \"\"\"\n        Create a new droplet.  All fields other than ``name``, ``image``,\n        ``size``, and ``region`` are optional and will be omitted from the API\n        request if not specified.\n\n        The returned `Droplet` object will represent the droplet at the moment\n        of creation; the actual droplet may not be active yet and may not have\n        even been assigned an IP address.  To wait for the droplet to activate,\n        use the `Droplet`'s :meth:`~Droplet.wait` method.\n\n        :param str name: a name for the droplet\n        :param image: the image ID, slug, or `Image` object representing the\n            base image to use for the droplet\n        :type image: integer, string, or `Image`\n        :param size: the slug or `Size` object representing the size of the new\n            droplet\n        :type size: string or `Size`\n        :param region: the slug or `Region` object representing the region in\n            which to create the droplet\n        :type region: string or `Region`\n        :param iterable ssh_keys: an iterable of SSH key resource IDs, SSH key\n            fingerprints, and/or `SSHKey` objects specifying the public keys to\n            add to the new droplet's :file:`/root/.ssh/authorized_keys` file\n        :param bool backups: whether to enable automatic backups on the new\n            droplet\n        :param bool ipv6: whether to enable IPv6 on the new droplet\n        :param bool private_networking: whether to enable private networking\n            for the new droplet\n        :param str user_data: a string of user data/metadata for the droplet\n        :param kwargs: additional fields to include in the API request\n        :return: the new droplet resource\n        :rtype: Droplet\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        data = {\n            \"name\": name,\n            \"image\": image.id if isinstance(image, Image) else image,\n            \"size\": str(size),\n            \"region\": str(region),\n        }\n        if ssh_keys is not None:\n            data[\"ssh_keys\"] = [k._id if isinstance(k, SSHKey) else k\n                                      for k in ssh_keys]\n        if backups is not None:\n            data[\"backups\"] = backups\n        if ipv6 is not None:\n            data[\"ipv6\"] = ipv6\n        if private_networking is not None:\n            data[\"private_networking\"] = private_networking\n        if user_data is not None:\n            data[\"user_data\"] = user_data\n        data.update(kwargs)\n        return self._droplet(self.request('/v2/droplets', method='POST',\n                                          data=data)[\"droplet\"])", "response": "Creates a new droplet at the moment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields the most recent actions on the objects in objects.", "response": "def wait_actions_on_objects(self, objects, wait_interval=None,\n                                               wait_time=None):\n        \"\"\"\n        .. versionadded:: 0.2.0\n\n        Poll the server periodically until the most recent action on each\n        resource in ``objects`` has finished, yielding each resource's final\n        state when the corresponding action is done.\n\n        If ``wait_time`` is exceeded, a `WaitTimeoutError` (containing any\n        remaining in-progress actions) is raised.\n\n        If a `KeyboardInterrupt` is caught, any remaining actions are returned\n        immediately without waiting for completion.\n\n        :param iterable objects: an iterable of resource objects that have\n            ``fetch_last_action`` methods\n        :param number wait_interval: how many seconds to sleep between\n            requests; defaults to :attr:`wait_interval` if not specified or\n            `None`\n        :param number wait_time: the total number of seconds after which the\n            method will raise an error if any actions have not yet completed,\n            or a negative number to wait indefinitely; defaults to\n            :attr:`wait_time` if not specified or `None`\n        :rtype: generator of objects\n        :raises DOAPIError: if the API endpoint replies with an error\n        :raises WaitTimeoutError: if ``wait_time`` is exceeded\n        \"\"\"\n        acts = []\n        for o in objects:\n            a = o.fetch_last_action()\n            if a is None:\n                yield o\n            else:\n                acts.append(a)\n        for a in self.wait_actions(acts, wait_interval, wait_time):\n            yield a.fetch_resource()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_ssh_key(self, name, public_key, **kwargs):\n        data = {\"name\": name, \"public_key\": public_key}\n        data.update(kwargs)\n        return self._ssh_key(self.request('/v2/account/keys', method='POST',\n                                          data=data)[\"ssh_key\"])", "response": "Add a new SSH public key to the account"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_domain(self, name, ip_address, **kwargs):\n        if isinstance(ip_address, FloatingIP):\n            ip_address = ip_address.ip\n        data = {\"name\": name, \"ip_address\": ip_address}\n        data.update(kwargs)\n        return self._domain(self.request('/v2/domains', method='POST',\n                                                        data=data)[\"domain\"])", "response": "Add a new domain name resource to the account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new floating IP in the specified region or a droplet.", "response": "def create_floating_ip(self, droplet_id=None, region=None, **kwargs):\n        \"\"\"\n        Create a new floating IP assigned to a droplet or reserved to a region.\n        Either ``droplet_id`` or ``region`` must be specified, but not both.\n\n        The returned `FloatingIP` object will represent the IP at the moment of\n        creation; if the IP address is supposed to be assigned to a droplet,\n        the assignment may not have been completed at the time the object is\n        returned.  To wait for the assignment to complete, use the\n        `FloatingIP`'s :meth:`~FloatingIP.wait_for_action` method.\n\n        :param droplet_id: the droplet to assign the floating IP to as either\n            an ID or a `Droplet` object\n        :type droplet_id: integer or `Droplet`\n        :param region: the region to reserve the floating IP to as either a\n            slug or a `Region` object\n        :type region: string or `Region`\n        :param kwargs: additional fields to include in the API request\n        :return: the new floating IP\n        :rtype: FloatingIP\n        :raises TypeError: if both ``droplet_id`` & ``region`` or neither of\n            them are defined\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        if (droplet_id is None) == (region is None):\n            ### TODO: Is TypeError the right type of error?\n            raise TypeError('Exactly one of \"droplet_id\" and \"region\" must be'\n                            ' specified')\n        if droplet_id is not None:\n            if isinstance(droplet_id, Droplet):\n                droplet_id = droplet_id.id\n            data = {\"droplet_id\": droplet_id}\n        else:\n            if isinstance(region, Region):\n                region = region.slug\n            data = {\"region\": region}\n        data.update(kwargs)\n        return self._floating_ip(self.request('/v2/floating_ips', method='POST',\n                                              data=data)[\"floating_ip\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new tag resource in the account.", "response": "def create_tag(self, name):\n        \"\"\"\n        .. versionadded:: 0.2.0\n\n        Add a new tag resource to the account\n\n        :param str name: the name of the new tag\n        :rtype: Tag\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        return self._tag(self.request('/v2/tags', method='POST', data={\n            \"name\": name,\n        })[\"tag\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef min_tasks_per_node(queue_id):\n    parallel_env = queue_id.split(':')[0]\n    queue_name = queue_id.split(':')[1]\n    tasks = 1\n    pe_tasks = tasks\n    with os.popen('qconf -sp ' + parallel_env) as f:\n        try:\n            for line in f:\n                if line.split(' ')[0] == 'allocation_rule':\n                    # This may throw exception as allocation rule\n                    # may not always be an integer\n                    pe_tasks = int(re.split('\\W+', line)[1])\n        except:\n            pass\n\n    return max(tasks, pe_tasks)", "response": "This function returns the minimum number of tasks per node in the queue"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef partial_shape(addr, full_shape):\n    def size(x, max):\n        if isinstance(x, (int, long, numpy.integer)):\n            return None\n        elif isinstance(x, slice):\n            y = min(max, x.stop or max)  # slice limits can go past the bounds\n            return 1 + (y - (x.start or 0) - 1) // (x.step or 1)\n        elif isinstance(x, collections.Sized):\n            if hasattr(x, 'dtype') and x.dtype == bool:\n                return x.sum()\n            else:\n                return len(x)\n        else:\n            raise TypeError(\"Unsupported index type %s\" % type(x))\n\n    addr = full_address(addr, full_shape)\n    if isinstance(addr, numpy.ndarray) and addr.dtype == bool:\n        return (addr.sum(),)\n    elif all(isinstance(x, collections.Sized) for x in addr):\n        return (len(addr[0]),)\n    else:\n        shape = [size(x, max) for (x, max) in zip(addr, full_shape)]\n        return tuple([x for x in shape if x is not None])", "response": "Calculate the size of the sub - array represented by addr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reverse(func):\n    @wraps(func)\n    def reversed_func(a, b):\n        return func(b, a)\n    reversed_func.__doc__ = \"Reversed argument form of %s\" % func.__doc__\n    reversed_func.__name__ = \"reversed %s\" % func.__name__\n    return reversed_func", "response": "Given a function f a b returns f ( a b"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a ufunc that works with lazy arrays", "response": "def _build_ufunc(func):\n    \"\"\"Return a ufunc that works with lazy arrays\"\"\"\n    def larray_compatible_ufunc(x):\n        if isinstance(x, larray):\n            y = deepcopy(x)\n            y.apply(func)\n            return y\n        else:\n            return func(x)\n    return larray_compatible_ufunc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_homogeneous(self):\n        hom_base = isinstance(self.base_value, (int, long, numpy.integer, float, bool)) \\\n                   or type(self.base_value) == self.dtype \\\n                   or (isinstance(self.dtype, type) and isinstance(self.base_value, self.dtype))\n        hom_ops = all(obj.is_homogeneous for f, obj in self.operations if isinstance(obj, larray))\n        return hom_base and hom_ops", "response": "True if all the elements of the array are the same."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn part of the lazy array.", "response": "def _partially_evaluate(self, addr, simplify=False):\n        \"\"\"\n        Return part of the lazy array.\n        \"\"\"\n        if self.is_homogeneous:\n            if simplify:\n                base_val = self.base_value\n            else:\n                base_val = self._homogeneous_array(addr) * self.base_value\n        elif isinstance(self.base_value, (int, long, numpy.integer, float, bool)):\n            base_val = self._homogeneous_array(addr) * self.base_value\n        elif isinstance(self.base_value, numpy.ndarray):\n            base_val = self.base_value[addr]\n        elif have_scipy and sparse.issparse(self.base_value):  # For sparse matrices larr[2, :]\n            base_val = self.base_value[addr]\n        elif callable(self.base_value):\n            indices = self._array_indices(addr)\n            base_val = self.base_value(*indices)\n            if isinstance(base_val, numpy.ndarray) and base_val.shape == (1,):\n                base_val = base_val[0]\n        elif hasattr(self.base_value, \"lazily_evaluate\"):\n            base_val = self.base_value.lazily_evaluate(addr, shape=self._shape)\n        elif isinstance(self.base_value, VectorizedIterable):\n            partial_shape = self._partial_shape(addr)\n            if partial_shape:\n                n = reduce(operator.mul, partial_shape)\n            else:\n                n = 1\n            base_val = self.base_value.next(n)  # note that the array contents will depend on the order of access to elements\n            if n == 1:\n                base_val = base_val[0]\n            elif partial_shape and base_val.shape != partial_shape:\n                base_val = base_val.reshape(partial_shape)\n        elif isinstance(self.base_value, collections.Iterator):\n            raise NotImplementedError(\"coming soon...\")\n        else:\n            raise ValueError(\"invalid base value for array (%s)\" % self.base_value)\n        return self._apply_operations(base_val, addr, simplify=simplify)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_bounds(self, addr):\n        def is_boolean_array(arr):\n            return hasattr(arr, 'dtype') and arr.dtype == bool\n\n        def check_axis(x, size):\n            if isinstance(x, (int, long, numpy.integer)):\n                lower = upper = x\n            elif isinstance(x, slice):\n                lower = x.start or 0\n                upper = min(x.stop or size - 1, size - 1)  # slices are allowed to go past the bounds\n            elif isinstance(x, collections.Sized):\n                if is_boolean_array(x):\n                    lower = 0\n                    upper = x.size - 1\n                else:\n                    if len(x) == 0:\n                        raise ValueError(\"Empty address component (address was %s)\" % str(addr))\n                    if hasattr(x, \"min\"):\n                        lower = x.min()\n                    else:\n                        lower = min(x)\n                    if hasattr(x, \"max\"):\n                        upper = x.max()\n                    else:\n                        upper = max(x)\n            else:\n                raise TypeError(\"Invalid array address: %s (element of type %s)\" % (str(addr), type(x)))\n            if (lower < -size) or (upper >= size):\n                raise IndexError(\"Index out of bounds\")\n        full_addr = self._full_address(addr)\n        if isinstance(addr, numpy.ndarray) and addr.dtype == bool:\n            if len(addr.shape) > len(self._shape):\n                raise IndexError(\"Too many indices for array\")\n            for xmax, size in zip(addr.shape, self._shape):\n                upper = xmax - 1\n                if upper >= size:\n                    raise IndexError(\"Index out of bounds\")\n        else:\n            for i, size in zip(full_addr, self._shape):\n                check_axis(i, size)", "response": "Checks whether the given address is within the array bounds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evaluate(self, simplify=False, empty_val=0):\n        # need to catch the situation where a generator-based larray is evaluated a second time\n        if self.is_homogeneous:\n            if simplify:\n                x = self.base_value\n            else:\n                x = self.base_value * numpy.ones(self._shape, dtype=self.dtype)\n        elif isinstance(self.base_value, (int, long, numpy.integer, float, bool, numpy.bool_)):\n            x = self.base_value * numpy.ones(self._shape, dtype=self.dtype)\n        elif isinstance(self.base_value, numpy.ndarray):\n            x = self.base_value\n        elif callable(self.base_value):\n            x = numpy.array(numpy.fromfunction(self.base_value, shape=self._shape, dtype=int), dtype=self.dtype)\n        elif hasattr(self.base_value, \"lazily_evaluate\"):\n            x = self.base_value.lazily_evaluate(shape=self._shape)\n        elif isinstance(self.base_value, VectorizedIterable):\n            x = self.base_value.next(self.size)\n            if x.shape != self._shape:\n                x = x.reshape(self._shape)\n        elif have_scipy and sparse.issparse(self.base_value):  # For sparse matrices\n            if empty_val!=0:\n                x = self.base_value.toarray((sparse.csc_matrix))\n                x = numpy.where(x, x, numpy.nan)\n            else:\n                x = self.base_value.toarray((sparse.csc_matrix))\n        elif isinstance(self.base_value, collections.Iterator):\n            x = numpy.fromiter(self.base_value, dtype=self.dtype or float, count=self.size)\n            if x.shape != self._shape:\n                x = x.reshape(self._shape)\n        else:\n            raise ValueError(\"invalid base value for array\")\n        return self._apply_operations(x, simplify=simplify)", "response": "Evaluate the lazy array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_closest_date_parameter(task, param_name):\n    for name, obj in task.get_params():\n        if name == param_name:\n            return hasattr(obj, 'use_closest_date')\n    return False", "response": "Return the class of the closest date parameter on task."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef effective_task_id(self):\n        params = self.param_kwargs\n        if 'date' in params and is_closest_date_parameter(self, 'date'):\n            params['date'] = self.closest()\n            task_id_parts = sorted(['%s=%s' % (k, str(v)) for k, v in params.items()])\n            return '%s(%s)' % (self.task_family, ', '.join(task_id_parts))\n        else:\n            return self.task_id", "response": "Return the effective task id for this entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef taskdir(self):\n        return os.path.join(self.BASE, self.TAG, self.task_family)", "response": "Return the directory under which all artefacts are stored."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef path(self, filename=None, ext='tsv', digest=False, shard=False, encoding='utf-8'):\n        if self.BASE is NotImplemented:\n            raise RuntimeError('BASE directory must be set.')\n\n        params = dict(self.get_params())\n\n        if filename is None:\n            parts = []\n\n            for name, param in self.get_params():\n                if not param.significant:\n                    continue\n                if name == 'date' and is_closest_date_parameter(self, 'date'):\n                    parts.append('date-%s' % self.closest())\n                    continue\n                if hasattr(param, 'is_list') and param.is_list:\n                    es = '-'.join([str(v) for v in getattr(self, name)])\n                    parts.append('%s-%s' % (name, es))\n                    continue\n                \n                val = getattr(self, name)\n\n                if isinstance(val, datetime.datetime):\n                    val = val.strftime('%Y-%m-%dT%H%M%S')\n                elif isinstance(val, datetime.date):\n                    val = val.strftime('%Y-%m-%d')\n                \n                parts.append('%s-%s' % (name, val))\n\n            name = '-'.join(sorted(parts))\n            if len(name) == 0:\n                name = 'output'\n            if digest:\n                name = hashlib.sha1(name.encode(encoding)).hexdigest()\n            if not ext:\n                filename = '{fn}'.format(ext=ext, fn=name)\n            else:\n                filename = '{fn}.{ext}'.format(ext=ext, fn=name)\n            if shard:\n                prefix = hashlib.sha1(filename.encode(encoding)).hexdigest()[:2]\n                return os.path.join(self.BASE, self.TAG, self.task_family, prefix, filename)\n\n        return os.path.join(self.BASE, self.TAG, self.task_family, filename)", "response": "Return the path for this class with a certain set of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy the fixture to the output directory.", "response": "def run(self):\n        \"\"\" Just copy the fixture, so we have some output. \"\"\"\n        luigi.LocalTarget(path=self.fixture).copy(self.output().path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the list of callables related to name", "response": "def get_listeners(self, name):\n        \"\"\"\n        Return the callables related to name\n        \"\"\"        \n        return list(map(lambda listener: listener[0], self.listeners[name]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_listener(self, name, listener, priority=0):\n        if name not in self.listeners:\n            self.listeners[name] = []\n\n        self.listeners[name].append((listener, priority))\n\n        # reorder event\n        self.listeners[name].sort(key=lambda listener: listener[1], reverse=True)", "response": "Add a new listener to the dispatch\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert dictionary to Simple Dublin Core XML as ElementTree.", "response": "def dump_etree(data, container=None, nsmap=None, attribs=None):\n    \"\"\"Convert dictionary to Simple Dublin Core XML as ElementTree.\n\n    :param data: Dictionary.\n    :param container: Name (include namespace) of container element.\n    :param nsmap: Namespace mapping for lxml.\n    :param attribs: Default attributes for container element.\n    :returns: LXML ElementTree.\n    \"\"\"\n    container = container or container_element\n    nsmap = nsmap or ns\n    attribs = attribs or container_attribs\n    return dump_etree_helper(container, data, rules, nsmap, attribs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef startReceivingBoxes(self, sender):\n        AMP.startReceivingBoxes(self, sender)\n        log.addObserver(self._emit)", "response": "Start observing log events for stat events to send."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stopReceivingBoxes(self, reason):\n        AMP.stopReceivingBoxes(self, reason)\n        log.removeObserver(self._emit)", "response": "Stop observing log events."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nemit a stat event.", "response": "def _emit(self, event):\n        \"\"\"\n        If the given event is a stat event, send a I{StatUpdate} command.\n        \"\"\"\n        if (event.get('interface') is not iaxiom.IStatEvent and\n            'athena_send_messages' not in event and\n            'athena_received_messages' not in event):\n            return\n\n        out = []\n        for k, v in event.iteritems():\n            if k in ('system', 'message', 'interface', 'isError'):\n                continue\n            if not isinstance(v, unicode):\n                v = str(v).decode('ascii')\n            out.append(dict(key=k.decode('ascii'), value=v))\n        self.callRemote(StatUpdate, data=out)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing a filename so that it is not too long.", "response": "def normalize_filename(filename):\n    \"\"\"\n    Remove special characters and shorten if name is too long\n    \"\"\"\n    # if the url pointed to a directory then just replace all the special chars\n    filename = re.sub(\"/|\\\\|;|:|\\?|=\", \"_\", filename)\n\n    if len(filename) > 150:\n        prefix = hashlib.md5(filename).hexdigest()\n        filename = prefix + filename[-140:]\n\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_local_filename(download_url=None, filename=None, decompress=False):\n    assert download_url or filename, \"Either filename or URL must be specified\"\n\n    # if no filename provided, use the original filename on the server\n    if not filename:\n        digest = hashlib.md5(download_url.encode('utf-8')).hexdigest()\n        parts = split(download_url)\n        filename = digest + \".\" + \"_\".join(parts)\n\n    filename = normalize_filename(filename)\n\n    if decompress:\n        (base, ext) = splitext(filename)\n        if ext in (\".gz\", \".zip\"):\n            filename = base\n\n    return filename", "response": "Builds a local filename based on the download URL and filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compare(file1, file2):\n    if isinstance(file1, six.string_types):  # pragma: no branch\n        file1 = open(file1, 'r', True)\n    if isinstance(file2, six.string_types):  # pragma: no branch\n        file2 = open(file2, 'r', True)\n    file1_contents = file1.read()\n    file2_contents = file2.read()\n    return file1_contents == file2_contents", "response": "compares the contents of two files"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sha1sum(f):\n    h = hashlib.sha1()\n    fp = open(f, 'rb')\n    while True:\n        block = fp.read(512 * 1024)\n        if not block:\n            break\n        h.update(block)\n    return h.hexdigest()", "response": "Return the SHA - 1 hash of the contents of file f in hex format"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef safe_copyfile(src, dest):\n    fd, tmpname = tempfile.mkstemp(dir=os.path.dirname(dest))\n    shutil.copyfileobj(open(src, 'rb'), os.fdopen(fd, 'wb'))\n    shutil.copystat(src, tmpname)\n    os.rename(tmpname, dest)", "response": "safely copy src to dest using a temporary intermediate and then renaming\n    to dest"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the spherical angular separation between two points on the sky.", "response": "def sphericalAngSep(ra0, dec0, ra1, dec1, radians=False):\n    \"\"\"\n        Compute the spherical angular separation between two\n        points on the sky.\n\n        //Taken from http://www.movable-type.co.uk/scripts/gis-faq-5.1.html\n\n        NB: For small distances you can probably use\n        sqrt( dDec**2 + cos^2(dec)*dRa)\n        where dDec = dec1 - dec0 and\n               dRa = ra1 - ra0\n               and dec1 \\approx dec \\approx dec0\n    \"\"\"\n\n    if radians==False:\n        ra0  = np.radians(ra0)\n        dec0 = np.radians(dec0)\n        ra1  = np.radians(ra1)\n        dec1 = np.radians(dec1)\n\n    deltaRa= ra1-ra0\n    deltaDec= dec1-dec0\n\n    val = haversine(deltaDec)\n    val += np.cos(dec0) * np.cos(dec1) * haversine(deltaRa)\n    val = min(1, np.sqrt(val)) ; #Guard against round off error?\n    val = 2*np.arcsin(val)\n\n    #Convert back to degrees if necessary\n    if radians==False:\n        val = np.degrees(val)\n\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the haversine of an angle in radians", "response": "def haversine(x):\n    \"\"\"Return the haversine of an angle\n\n    haversine(x) = sin(x/2)**2, where x is an angle in radians\n    \"\"\"\n    y = .5*x\n    y = np.sin(y)\n    return y*y"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a default share ID to store pointing to shareID with priority C { priority }.", "response": "def addDefaultShareID(store, shareID, priority):\n    \"\"\"\n    Add a default share ID to C{store}, pointing to C{shareID} with a\n    priority C{priority}.  The highest-priority share ID identifies the share\n    that will be retrieved when a user does not explicitly provide a share ID\n    in their URL (e.g. /host/users/username/).\n\n    @param shareID: A share ID.\n    @type shareID: C{unicode}\n\n    @param priority: The priority of this default.  Higher means more\n    important.\n    @type priority: C{int}\n    \"\"\"\n    _DefaultShareID(store=store, shareID=shareID, priority=priority)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getDefaultShareID(store):\n    defaultShareID = store.findFirst(\n        _DefaultShareID, sort=_DefaultShareID.priority.desc)\n    if defaultShareID is None:\n        return u''\n    return defaultShareID.shareID", "response": "Get the highest - priority default share ID for the store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef linkTo(sharedProxyOrItem):\n    if isinstance(sharedProxyOrItem, sharing.SharedProxy):\n        userStore = sharing.itemFromProxy(sharedProxyOrItem).store\n    else:\n        userStore = sharedProxyOrItem.store\n    appStore = isAppStore(userStore)\n    if appStore:\n        # This code-path should be fixed by #2703; PublicWeb is deprecated.\n        from xmantissa.publicweb import PublicWeb\n        substore = userStore.parent.getItemByID(userStore.idInParent)\n        pw = userStore.parent.findUnique(PublicWeb, PublicWeb.application == substore)\n        path = [pw.prefixURL.encode('ascii')]\n    else:\n        for lm in userbase.getLoginMethods(userStore):\n            if lm.internal:\n                path = ['users', lm.localpart.encode('ascii')]\n                break\n        else:\n            raise RuntimeError(\n                \"Shared item is in a user store with no\"\n                \" internal username -- can't generate a link.\")\n    if (sharedProxyOrItem.shareID == getDefaultShareID(userStore)):\n        shareID = sharedProxyOrItem.shareID\n        path.append('')\n    else:\n        shareID = None\n        path.append(sharedProxyOrItem.shareID)\n    return _ShareURL(shareID, scheme='', netloc='', pathsegs=path)", "response": "Generate the path part of a URL to link to a shared proxy or item."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the user store that the user signed up with username.", "response": "def _storeFromUsername(store, username):\n    \"\"\"\n    Find the user store of the user with username C{store}\n\n    @param store: site-store\n    @type store: L{axiom.store.Store}\n\n    @param username: the name a user signed up with\n    @type username: C{unicode}\n\n    @rtype: L{axiom.store.Store} or C{None}\n    \"\"\"\n    lm = store.findUnique(\n            userbase.LoginMethod,\n            attributes.AND(\n                userbase.LoginMethod.localpart == username,\n                userbase.LoginMethod.internal == True),\n            default=None)\n    if lm is not None:\n        return lm.account.avatars.open()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new URL with the given path.", "response": "def child(self, path):\n        \"\"\"\n        Override the base implementation to inject the share ID our\n        constructor was passed.\n        \"\"\"\n        if self._shareID is not None:\n            self = url.URL.child(self, self._shareID)\n            self._shareID = None\n        return url.URL.child(self, path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noverrides the base implementation to pass along the share ID our constructor was passed.", "response": "def cloneURL(self, scheme, netloc, pathsegs, querysegs, fragment):\n        \"\"\"\n        Override the base implementation to pass along the share ID our\n        constructor was passed.\n        \"\"\"\n        return self.__class__(\n            self._shareID, scheme, netloc, pathsegs, querysegs, fragment)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef locateChild(self, ctx, segments):\n        store = _storeFromUsername(\n            self.loginSystem.store, segments[0].decode('utf-8'))\n        if store is None:\n            return rend.NotFound\n        return (SharingIndex(store, self.webViewer), segments[1:])", "response": "Locate a child for a particular user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlocate a child item for the user viewing this SharingIndex and return that item s fragment.", "response": "def locateChild(self, ctx, segments):\n        \"\"\"\n        Look up a shared item for the role viewing this SharingIndex and return a\n        L{PublicAthenaLivePage} containing that shared item's fragment to the\n        user.\n\n        These semantics are UNSTABLE.  This method is adequate for simple uses,\n        but it should be expanded in the future to be more consistent with\n        other resource lookups.  In particular, it should allow share\n        implementors to adapt their shares to L{IResource} directly rather than\n        L{INavigableFragment}, to allow for simpler child dispatch.\n\n        @param segments: a list of strings, the first of which should be the\n        shareID of the desired item.\n\n        @param ctx: unused.\n\n        @return: a L{PublicAthenaLivePage} wrapping a customized fragment.\n        \"\"\"\n        shareID = segments[0].decode('utf-8')\n\n        role = self.webViewer.roleIn(self.userStore)\n\n        # if there is an empty segment\n        if shareID == u'':\n            # then we want to return the default share.  if we find one, then\n            # let's use that\n            defaultShareID = getDefaultShareID(self.userStore)\n            try:\n                sharedItem = role.getShare(defaultShareID)\n            except sharing.NoSuchShare:\n                return rend.NotFound\n        # otherwise the user is trying to access some other share\n        else:\n            # let's see if it's a real share\n            try:\n                sharedItem = role.getShare(shareID)\n            # oops it's not\n            except sharing.NoSuchShare:\n                return rend.NotFound\n\n        return (self.webViewer.wrapModel(sharedItem),\n                segments[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake sure a connection is in autocommit mode.", "response": "def _set_autocommit(connection):\n        \"\"\"Make sure a connection is in autocommit mode.\"\"\"\n        if hasattr(connection.connection, \"autocommit\"):\n            if callable(connection.connection.autocommit):\n                connection.connection.autocommit(True)\n            else:\n                connection.connection.autocommit = True\n        elif hasattr(connection.connection, \"set_isolation_level\"):\n            connection.connection.set_isolation_level(0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npatching in support for static files serving if supported and enabled.", "response": "def _patch_static_handler(handler):\n    \"\"\"Patch in support for static files serving if supported and enabled.\n    \"\"\"\n\n    if django.VERSION[:2] < (1, 3):\n        return\n\n    from django.contrib.staticfiles.handlers import StaticFilesHandler\n    return StaticFilesHandler(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninjects a selenium instance into the method.", "response": "def _inject_selenium(self, test):\n        \"\"\"\n        Injects a selenium instance into the method.\n        \"\"\"\n        from django.conf import settings\n\n        test_case = get_test_case_class(test)\n        test_case.selenium_plugin_started = True\n\n        # Provide some reasonable default values\n        sel = selenium(\n            getattr(settings, \"SELENIUM_HOST\", \"localhost\"),\n            int(getattr(settings, \"SELENIUM_PORT\", 4444)),\n            getattr(settings, \"SELENIUM_BROWSER_COMMAND\", \"*chrome\"),\n            getattr(settings, \"SELENIUM_URL_ROOT\", \"http://127.0.0.1:8000/\"))\n\n        try:\n            sel.start()\n        except socket.error:\n            if getattr(settings, \"FORCE_SELENIUM_TESTS\", False):\n                raise\n            else:\n                raise SkipTest(\"Selenium server not available.\")\n        else:\n            test_case.selenium_started = True\n            # Only works on method test cases, because we obviously need\n            # self.\n            if isinstance(test.test, nose.case.MethodTestCase):\n                test.test.test.im_self.selenium = sel\n            elif isinstance(test.test, TestCase):\n                test.test.run.im_self.selenium = sel\n            else:\n                raise SkipTest(\"Test skipped because it's not a method.\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef server_bind(self):\n\n        try:\n            HTTPServer.server_bind(self)\n        except Exception as e:\n            raise WSGIServerException(e)\n\n        self.setup_environ()\n        self.socket.settimeout(1)", "response": "Bind server to socket. Overrided to store server name and\n        set timeout."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef result(self, wait=False):\n        if wait:\n            self._async_resp.wait()\n\n        if not self.finished():\n            raise RuntimeError(\"Result is not ready yet\")\n\n        raw_response = self._async_resp.get()\n\n        return Result(result=raw_response[\"result\"], error=raw_response[\"error\"],\n                      id=raw_response[\"id\"], method_call=self.request)", "response": "Gets the result of the method call."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post_build(self, container_builder, container):\n        app = container.get('ioc.extra.flask.app')\n\n        app.config.update(container_builder.parameters.get('ioc.extra.flask.app.config'))\n\n        if container.has('ioc.extra.jinja2'):\n            # This must be an instance of jinja.ChoiceLoader\n            # This code replace the flask specific jinja configuration to use\n            # the one provided by the ioc.extra.jinja2 code\n            jinja2 = container.get('ioc.extra.jinja2')\n\n            jinja2.loader.loaders.append(app.create_global_jinja_loader())\n\n            for name, value in app.jinja_env.globals.items():\n                if name not in jinja2.globals:\n                    jinja2.globals[name] = value                \n\n            for name, value in app.jinja_env.filters.items():\n                if name not in jinja2.filters:\n                    jinja2.filters[name] = value                \n\n            app.jinja_env = jinja2", "response": "This method is called when the ioc is built."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self):\n        assert not self._started\n        self._listening_stream.on_recv(self._recv_callback)\n        self._started = True", "response": "Start listening for incoming requests."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_listening_stream(self, pull_addr):\n        sock = self._zmq_context.socket(zmq.PULL)\n        sock.connect(pull_addr)\n        stream = ZMQStream(sock, io_loop=self.io_loop)\n\n        return stream", "response": "Create a listening stream for requests."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a ZMQStream for sending responses back to Mongrel2.", "response": "def _create_sending_stream(self, pub_addr):\n        \"\"\"\n        Create a `ZMQStream` for sending responses back to Mongrel2.\n        \"\"\"\n        sock = self._zmq_context.socket(zmq.PUB)\n        sock.setsockopt(zmq.IDENTITY, self.sender_id)\n        sock.connect(pub_addr)\n        stream = ZMQStream(sock, io_loop=self.io_loop)\n\n        return stream"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _begin_request(self):\n        headers = self.m2req.headers\n\n        self._request = HTTPRequest(connection=self,\n            method=headers.get(\"METHOD\"),\n            uri=self.m2req.path,\n            version=headers.get(\"VERSION\"),\n            headers=headers,\n            remote_ip=headers.get(\"x-forwarded-for\"))\n\n        if len(self.m2req.body) > 0:\n            self._request.body = self.m2req.body\n\n        if self.m2req.is_disconnect():\n            self.finish()\n\n        elif headers.get(\"x-mongrel2-upload-done\", None):\n            # there has been a file upload.\n            expected = headers.get(\"x-mongrel2-upload-start\", \"BAD\")\n            upload = headers.get(\"x-mongrel2-upload-done\", None)\n\n            if expected == upload:\n                self.request_callback(self._request)\n\n        elif headers.get(\"x-mongrel2-upload-start\", None):\n            # this is just a notification that a file upload has started. Do\n            # nothing for now!\n            pass\n\n        else:\n            self.request_callback(self._request)", "response": "Begin executing this request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send(self, msg):\n        uuid = self.m2req.sender\n        conn_id = self.m2req.conn_id\n\n        header = \"%s %d:%s,\" % (uuid, len(str(conn_id)), str(conn_id))\n        zmq_message = header + ' ' + msg\n        self.stream.send(zmq_message)", "response": "Raw send to the given connection ID at the given uuid mostly used \n        internally."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _json_default_encoder(func):\n\n    @wraps(func)\n    def inner(self, o):\n        try:\n            return o._redpipe_struct_as_dict  # noqa\n        except AttributeError:\n            pass\n        return func(self, o)\n\n    return inner", "response": "A default encoder for the JSON encoder library."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_completed(*async_result_wrappers):\n    for item in async_result_wrappers:\n        if not isinstance(item, AsyncMethodCall):\n            raise TypeError(\"Got non-AsyncMethodCall object: {}\".format(item))\n\n    wrappers_copy = list(async_result_wrappers)\n\n    while len(wrappers_copy):\n        completed = list(filter(lambda x: x.finished(), wrappers_copy))\n        if not len(completed):\n            continue\n\n        for item in completed:\n            wrappers_copy.remove(item)\n            yield item", "response": "Yields items as soon they become available from asynchronous method calls."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dynamic_load(module_or_member):\n    parts = module_or_member.split(\".\")\n    if len(parts) > 1:\n        name_to_import = parts[-1]\n        module_to_import = \".\".join(parts[:-1])\n    else:\n        name_to_import = None\n        module_to_import = module_or_member\n\n    module = importlib.import_module(module_to_import)\n    if name_to_import:\n        to_return = getattr(module, name_to_import)\n        if not to_return:\n            raise AttributeError(\"{} has no attribute {}\".format(module, name_to_import))\n        return to_return\n    else:\n        return module", "response": "Dynamically loads a class or member of a module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encode(cls, value):\n        if value not in [True, False]:\n            raise InvalidValue('not a boolean')\n\n        return b'1' if value else b''", "response": "Convert a boolean value into something we can persist to redis."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes a floating point number to bytes in redis", "response": "def encode(cls, value):\n        \"\"\"\n        encode a floating point number to bytes in redis\n\n        :param value: float\n        :return: bytes\n        \"\"\"\n        try:\n            if float(value) + 0 == value:\n                return repr(value)\n        except (TypeError, ValueError):\n            pass\n\n        raise InvalidValue('not a float')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encode(cls, value):\n        coerced = unicode(value)\n        if coerced == value:\n            return coerced.encode(cls._encoding)\n\n        raise InvalidValue('not text')", "response": "take a valid unicode string and turn it into utf - 8 bytes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a list of strings and turn it into utf - 8 byte - string", "response": "def encode(cls, value):\n        \"\"\"\n        take a list of strings and turn it into utf-8 byte-string\n\n        :param value:\n        :return:\n        \"\"\"\n        coerced = unicode(value)\n        if coerced == value and cls.PATTERN.match(coerced):\n            return coerced.encode(cls._encoding)\n\n        raise InvalidValue('not ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode(cls, value):\n        try:\n            coerced = bytes(value)\n            if coerced == value:\n                return coerced\n        except (TypeError, UnicodeError):\n            pass\n\n        raise InvalidValue('not binary')", "response": "encode binary data into redis without encoding it"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a list and turn it into a utf - 8 encoded byte - string for redis.", "response": "def encode(cls, value):\n        \"\"\"\n        take a list and turn it into a utf-8 encoded byte-string for redis.\n\n        :param value: list\n        :return: bytes\n        \"\"\"\n        try:\n            coerced = list(value)\n            if coerced == value:\n                return json.dumps(coerced).encode(cls._encoding)\n        except TypeError:\n            pass\n\n        raise InvalidValue('not a list')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a utf - 8 encoded byte - string from redis and turn it into a list", "response": "def decode(cls, value):\n        \"\"\"\n        take a utf-8 encoded byte-string from redis and\n        turn it back into a list\n\n        :param value: bytes\n        :return: list\n        \"\"\"\n        try:\n            return None if value is None else \\\n                list(json.loads(value.decode(cls._encoding)))\n        except (TypeError, AttributeError):\n            return list(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes the dict as a json string to be written into redis", "response": "def encode(cls, value):\n        \"\"\"\n        encode the dict as a json string to be written into redis.\n\n        :param value: dict\n        :return: bytes\n        \"\"\"\n        try:\n            coerced = dict(value)\n            if coerced == value:\n                return json.dumps(coerced).encode(cls._encoding)\n        except (TypeError, ValueError):\n            pass\n        raise InvalidValue('not a dict')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode the data from redis.", "response": "def decode(cls, value):\n        \"\"\"\n        decode the data from redis.\n        :param value: bytes\n        :return: list\n        \"\"\"\n        try:\n            data = [v for v in value.decode(cls._encoding).split(',') if\n                    v != '']\n            return data if data else None\n        except AttributeError:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nencode the list of items in the n - item list into a string.", "response": "def encode(cls, value):\n        \"\"\"\n        the list it so it can be stored in redis.\n\n        :param value: list\n        :return: bytes\n        \"\"\"\n        try:\n            coerced = [str(v) for v in value]\n            if coerced == value:\n                return \",\".join(coerced).encode(cls._encoding) if len(\n                    value) > 0 else None\n        except TypeError:\n            pass\n\n        raise InvalidValue('not a list of strings')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nswapping the subject and body for twitter.", "response": "def swap_twitter_subject(subject, body):\n    \"\"\"If subject starts from 'Tweet from...'\n    then we need to get first meaning line from the body.\"\"\"\n\n    if subject.startswith('Tweet from'):\n        lines = body.split('\\n')\n        for idx, line in enumerate(lines):\n            if re.match(r'.*, ?\\d{2}:\\d{2}]]', line) is not None:\n                try:\n                    subject = lines[idx + 1]\n                except IndexError:\n                    pass\n                break\n    return subject, body"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef trial(log_dir=None,\n          upload_dir=None,\n          sync_period=None,\n          trial_prefix=\"\",\n          param_map=None,\n          init_logging=True):\n    \"\"\"\n    Generates a trial within a with context.\n    \"\"\"\n    global _trial  # pylint: disable=global-statement\n    if _trial:\n        # TODO: would be nice to stack crawl at creation time to report\n        # where that initial trial was created, and that creation line\n        # info is helpful to keep around anyway.\n        raise ValueError(\"A trial already exists in the current context\")\n    local_trial = Trial(\n        log_dir=log_dir,\n        upload_dir=upload_dir,\n        sync_period=sync_period,\n        trial_prefix=trial_prefix,\n        param_map=param_map,\n        init_logging=True)\n    try:\n        _trial = local_trial\n        _trial.start()\n        yield local_trial\n    finally:\n        _trial = None\n        local_trial.close()", "response": "A generator that creates a trial within a context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index(index, length):\n    if index < 0:\n        index += length\n    if 0 <= index < length:\n        return index\n    raise IndexError()", "response": "Generates an index.\n\n    :param index: The index, can be positive or negative.\n    :param length: The length of the sequence to index.\n\n    :raises: IndexError\n\n    Negative indices are typically used to index a sequence in reverse order.\n    But to use them, the indexed object must convert them to the correct,\n    positive index. This function can be used to do this."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef range_to_numeric(ranges):\n    values, units = zip(*(r.split() for r in ranges))\n    # Detect common unit.\n    unit = os.path.commonprefix([u[::-1] for u in units])\n\n    # Strip unit to get just the SI prefix.\n    prefixes = (u[:-len(unit)] for u in units)\n\n    # Convert string value and scale with prefix.\n    values = [float(v) * SI_PREFIX[p] for v, p in zip(values, prefixes)]\n    return values", "response": "Converts a sequence of string ranges to a sequence of floats."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap_exception(exc, new_exc):\n    def make_wrapper(fn):\n        @functools.wraps(fn)\n        def wrapper(*args, **kw):\n            try:\n                return fn(*args, **kw)\n            except exc as e:\n                future.utils.raise_with_traceback(new_exc(e))\n        return wrapper\n    return make_wrapper", "response": "Wraps an exception in a new exception and raises it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nestimates an appropriate sensitivity range.", "response": "def range(self, value):\n        \"\"\"Estimates an appropriate sensitivity range.\"\"\"\n        self._buffer.append(abs(value))\n        mean = sum(self._buffer) / len(self._buffer)\n        estimate = next(\n            (r for r in self.ranges if mean < self.scale * r),\n            self.ranges[-1]\n        )\n        if self._mapping:\n            return self._mapping[estimate]\n        else:\n            return estimate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding data to the set of statements based on the given schema.", "response": "def add(self, schema, data):\n        \"\"\" Stage ``data`` as a set of statements, based on the given\n        ``schema`` definition. \"\"\"\n        binding = self.get_binding(schema, data)\n        uri, triples = triplify(binding)\n        for triple in triples:\n            self.graph.add(triple)\n        return uri"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransfer the statements in this context over to the main store.", "response": "def save(self):\n        \"\"\" Transfer the statements in this context over to the main store. \"\"\"\n        if self.parent.buffered:\n            query = \"\"\"\n                INSERT DATA { GRAPH %s { %s } }\n            \"\"\"\n            query = query % (self.identifier.n3(),\n                             self.graph.serialize(format='nt'))\n            self.parent.graph.update(query)\n            self.flush()\n        else:\n            self.meta.generate()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n        if self.parent.buffered:\n            query = 'CLEAR SILENT GRAPH %s ;' % self.identifier.n3()\n            self.parent.graph.update(query)\n            self.flush()\n        else:\n            self.graph.remove((None, None, None))", "response": "Delete all statements matching the current context identifier\n            from the main store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_bytes(self, num_bytes):\n        buffer_size = len(self._buffer)\n        if buffer_size > num_bytes:\n            # The buffer is larger than the requested amount of bytes.\n            data, self._buffer = self._buffer[:num_bytes], self._buffer[num_bytes:]\n        elif 0 < buffer_size <= num_bytes:\n            # This might return less bytes than requested.\n            data, self._buffer = self._buffer, bytearray()\n        else:\n            # Buffer is empty. Try to read `num_bytes` and call `read_bytes()`\n            # again. This ensures that at most `num_bytes` are returned.\n            self._buffer += self.__read__(num_bytes)\n            return self.read_bytes(num_bytes)\n        return data", "response": "Reads at most num_bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads until the delimiter is found.", "response": "def read_until(self, delimiter):\n        \"\"\"Reads until the delimiter is found.\"\"\"\n        if delimiter in self._buffer:\n            data, delimiter, self._buffer = self._buffer.partition(delimiter)\n            return data\n        else:\n            self._buffer += self.__read__(self._max_bytes)\n            return self.read_until(delimiter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncloses the gpib transport.", "response": "def close(self):\n        \"\"\"Closes the gpib transport.\"\"\"\n        if self._device is not None:\n            ibsta = self._lib.ibonl(self._device, 0)\n            self._check_status(ibsta)\n            self._device = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntriggers the device. The trigger method sens a GET(group execute trigger) command byte to the device.", "response": "def trigger(self):\n        \"\"\"Triggers the device.\n\n        The trigger method sens a GET(group execute trigger) command byte to\n        the device.\n        \"\"\"\n        ibsta = self._lib.ibtrg(self._device)\n        self._check_status(ibsta)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_status(self, ibsta):\n        if ibsta & 0x4000:\n            raise LinuxGpib.Timeout()\n        elif ibsta & 0x8000:\n            raise LinuxGpib.Error(self.error_status)", "response": "Checks the status of an ibsta value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        output = shellout('wget -q \"{url}\" -O {output}', url=self.url)\n        luigi.LocalTarget(output).move(self.output().path)", "response": "Just run wget quietly."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the output of this URL.", "response": "def output(self):\n        \"\"\" Use the digest version, since URL can be ugly. \"\"\"\n        return luigi.LocalTarget(path=self.path(digest=True, ext='html'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        document = {}\n        document['_id'] = hashlib.sha1('%s:%s' % (\n                                       self.date, self.url)).hexdigest()\n        with self.input().open() as handle:\n            document['content'] = handle.read().decode('utf-8', 'ignore')\n        document['url'] = self.url\n        document['date'] = unicode(self.date)\n        with self.output().open('w') as output:\n            output.write(json.dumps(document))", "response": "Construct the document id from the date and the url."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self):\n        with self.input().open() as handle:\n            body = json.loads(handle.read())\n        es = elasticsearch.Elasticsearch()\n        id = body.get('_id')\n        es.index(index='frontpage', doc_type='html', id=id, body=body)", "response": "Index the document. Since ids are predictable,\n            we won't index anything twice."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef complete(self):\n        id = hashlib.sha1('%s:%s' % (self.date, self.url)).hexdigest()\n        es = elasticsearch.Elasticsearch()\n        try:\n            es.get(index='frontpage', doc_type='html', id=id)\n        except elasticsearch.NotFoundError:\n            return False\n        return True", "response": "Check if out hashed date : url id is already in the index."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the name of the object in the data.", "response": "def get_name(self, data):\n        \"\"\" For non-specific queries, this will return the actual name in the\n        result. \"\"\"\n        if self.node.specific_attribute:\n            return self.node.name\n        name = data.get(self.predicate_var)\n        if str(RDF.type) in [self.node.name, name]:\n            return '$schema'\n        if name.startswith(PRED):\n            name = name[len(PRED):]\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef project(self, q, parent=False):\n        if self.parent:\n            print (self.parent.var, self.predicate, self.var)\n        q = q.project(self.var, append=True)\n        if parent and self.parent:\n            q = q.project(self.parent.var, append=True)\n        if not self.node.specific_attribute:\n            q = q.project(self.predicate, append=True)\n        for child in self.children:\n            if child.node.leaf:\n                q = child.project(q)\n        return q", "response": "Figure out which attributes should be returned for the current node level of the query."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying any filters to the query.", "response": "def filter(self, q, parents=None):\n        \"\"\" Apply any filters to the query. \"\"\"\n        if self.node.leaf and self.node.filtered:\n            # TODO: subject filters?\n            q = q.where((self.parent.var,\n                         self.predicate,\n                         self.var))\n            # TODO: inverted nodes\n            q = self.filter_value(q, self.var)\n        elif self.parent is not None:\n            q = q.where((self.parent.var, self.predicate, self.var))\n\n            if parents is not None:\n                parents = [URIRef(p) for p in parents]\n                q = q.filter(self.parent.var.in_(*parents))\n\n        # TODO: forbidden nodes.\n        for child in self.children:\n            q = child.filter(q)\n        return q"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query(self, parents=None):\n        # TODO: benchmark single-query strategy\n        q = Select([])\n        q = self.project(q, parent=True)\n        q = self.filter(q, parents=parents)\n\n        if self.parent is None:\n            subq = Select([self.var])\n            subq = self.filter(subq, parents=parents)\n            subq = subq.offset(self.node.offset)\n            subq = subq.limit(self.node.limit)\n            subq = subq.distinct()\n            # TODO: sorting.\n            subq = subq.order_by(desc(self.var))\n            q = q.where(subq)\n\n        # if hasattr(self.context, 'identifier'):\n        #     q._where = graph(self.context.identifier, q._where)\n        log.debug(\"Compiled query: %r\", q.compile())\n        return q", "response": "Construct the query and generate SPARQL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef base_object(self, data):\n        obj = {'id': data.get(self.id)}\n        if self.parent is not None:\n            obj['$parent'] = data.get(self.parent.id)\n        return obj", "response": "Make sure to return all the existing filter fields\n        for query results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the data query and construct entities from it s results.", "response": "def execute(self, parents=None):\n        \"\"\" Run the data query and construct entities from it's results. \"\"\"\n        results = OrderedDict()\n        for row in self.query(parents=parents).execute(self.context.graph):\n            data = {k: v.toPython() for (k, v) in row.asdict().items()}\n            id = data.get(self.id)\n            if id not in results:\n                results[id] = self.base_object(data)\n\n            for child in self.children:\n                if child.id in data:\n                    name = child.get_name(data)\n                    value = data.get(child.id)\n                    if child.node.many and \\\n                            child.node.op not in [OP_IN, OP_NIN]:\n                        if name not in results[id]:\n                            results[id][name] = [value]\n                        else:\n                            results[id][name].append(value)\n                    else:\n                        results[id][name] = value\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef collect(self, parents=None):\n        results = self.execute(parents=parents)\n        ids = results.keys()\n        for child in self.nested():\n            name = child.node.name\n            for child_data in child.collect(parents=ids).values():\n                parent_id = child_data.pop('$parent', None)\n                if child.node.many:\n                    if name not in results[parent_id]:\n                        results[parent_id][name] = []\n                    results[parent_id][name].append(child_data)\n                else:\n                    results[parent_id][name] = child_data\n        return results", "response": "Given re - constructed entities conduct queries for child\n            entities and merge them into the current level s object graph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload and decompresses the specified file at the given path.", "response": "def _download_and_decompress_if_necessary(\n        full_path,\n        download_url,\n        timeout=None,\n        use_wget_if_available=False):\n    \"\"\"\n    Downloads remote file at `download_url` to local file at `full_path`\n    \"\"\"\n    logger.info(\"Downloading %s to %s\", download_url, full_path)\n    filename = os.path.split(full_path)[1]\n    base_name, ext = os.path.splitext(filename)\n    tmp_path = _download_to_temp_file(\n        download_url=download_url,\n        timeout=timeout,\n        base_name=base_name,\n        ext=ext,\n        use_wget_if_available=use_wget_if_available)\n\n    if download_url.endswith(\"zip\") and not filename.endswith(\"zip\"):\n        logger.info(\"Decompressing zip into %s...\", filename)\n        with zipfile.ZipFile(tmp_path) as z:\n            names = z.namelist()\n            assert len(names) > 0, \"Empty zip archive\"\n            if filename in names:\n                chosen_filename = filename\n            else:\n                # If zip archive contains multiple files, choose the biggest.\n                biggest_size = 0\n                chosen_filename = names[0]\n                for info in z.infolist():\n                    if info.file_size > biggest_size:\n                        chosen_filename = info.filename\n                        biggest_size = info.file_size\n            extract_path = z.extract(chosen_filename)\n        move(extract_path, full_path)\n        os.remove(tmp_path)\n    elif download_url.endswith(\"gz\") and not filename.endswith(\"gz\"):\n        logger.info(\"Decompressing gzip into %s...\", filename)\n        with gzip.GzipFile(tmp_path) as src:\n            contents = src.read()\n        os.remove(tmp_path)\n        with open(full_path, 'wb') as dst:\n            dst.write(contents)\n    elif download_url.endswith((\"html\", \"htm\")) and full_path.endswith(\".csv\"):\n        logger.info(\"Extracting HTML table into CSV %s...\", filename)\n        df = pd.read_html(tmp_path, header=0)[0]\n        df.to_csv(full_path, sep=',', index=False, encoding='utf-8')\n    else:\n        move(tmp_path, full_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if a local file corresponding to these arguments exists.", "response": "def file_exists(\n        download_url,\n        filename=None,\n        decompress=False,\n        subdir=None):\n    \"\"\"\n    Return True if a local file corresponding to these arguments\n    exists.\n    \"\"\"\n    filename = build_local_filename(download_url, filename, decompress)\n    full_path = build_path(filename, subdir)\n    return os.path.exists(full_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch_file(\n        download_url,\n        filename=None,\n        decompress=False,\n        subdir=None,\n        force=False,\n        timeout=None,\n        use_wget_if_available=False):\n    \"\"\"\n    Download a remote file and store it locally in a cache directory. Don't\n    download it again if it's already present (unless `force` is True.)\n\n    Parameters\n    ----------\n    download_url : str\n        Remote URL of file to download.\n\n    filename : str, optional\n        Local filename, used as cache key. If omitted, then determine the local\n        filename from the URL.\n\n    decompress : bool, optional\n        By default any file whose remote extension is one of (\".zip\", \".gzip\")\n        and whose local filename lacks this suffix is decompressed. If a local\n        filename wasn't provided but you still want to decompress the stored\n        data then set this option to True.\n\n    subdir : str, optional\n        Group downloads in a single subdirectory.\n\n    force : bool, optional\n        By default, a remote file is not downloaded if it's already present.\n        However, with this argument set to True, it will be overwritten.\n\n    timeout : float, optional\n        Timeout for download in seconds, default is None which uses\n        global timeout.\n\n    use_wget_if_available: bool, optional\n        If the `wget` command is available, use that for download instead\n        of Python libraries (default True)\n\n    Returns the full path of the local file.\n    \"\"\"\n    filename = build_local_filename(download_url, filename, decompress)\n    full_path = build_path(filename, subdir)\n    if not os.path.exists(full_path) or force:\n        logger.info(\"Fetching %s from URL %s\", filename, download_url)\n        _download_and_decompress_if_necessary(\n            full_path=full_path,\n            download_url=download_url,\n            timeout=timeout,\n            use_wget_if_available=use_wget_if_available)\n    else:\n        logger.info(\"Cached file %s from URL %s\", filename, download_url)\n    return full_path", "response": "Download a remote file and store it locally in a cache directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch a remote file from source_url and transform it into a in - memory object.", "response": "def fetch_and_transform(\n        transformed_filename,\n        transformer,\n        loader,\n        source_filename,\n        source_url,\n        subdir=None):\n    \"\"\"\n    Fetch a remote file from `source_url`, save it locally as `source_filename` and then use\n    the `loader` and `transformer` function arguments to turn this saved data into an in-memory\n    object.\n    \"\"\"\n    transformed_path = build_path(transformed_filename, subdir)\n    if not os.path.exists(transformed_path):\n        source_path = fetch_file(source_url, source_filename, subdir)\n        logger.info(\"Generating data file %s from %s\", transformed_path, source_path)\n        result = transformer(source_path, transformed_path)\n    else:\n        logger.info(\"Cached data file: %s\", transformed_path)\n        result = loader(transformed_path)\n    assert os.path.exists(transformed_path)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads a remote file from download_url and save it locally as filename.", "response": "def fetch_csv_dataframe(\n        download_url,\n        filename=None,\n        subdir=None,\n        **pandas_kwargs):\n    \"\"\"\n    Download a remote file from `download_url` and save it locally as `filename`.\n    Load that local file as a CSV into Pandas using extra keyword arguments such as sep='\\t'.\n    \"\"\"\n    path = fetch_file(\n        download_url=download_url,\n        filename=filename,\n        decompress=True,\n        subdir=subdir)\n    return pd.read_csv(path, **pandas_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getLoader(*a, **kw):\n    warn(\"xmantissa.publicweb.getLoader is deprecated, use \"\n         \"PrivateApplication.getDocFactory or SiteTemplateResolver.\"\n         \"getDocFactory.\", category=DeprecationWarning, stacklevel=2)\n    from xmantissa.webtheme import getLoader\n    return getLoader(*a, **kw)", "response": "Deprecated. Don t use this.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering a potentially shortened version of the user s login identifier.", "response": "def renderShortUsername(ctx, username):\n    \"\"\"\n    Render a potentially shortened version of the user's login identifier,\n    depending on how the user is viewing it.  For example, if bob@example.com\n    is viewing http://example.com/private/, then render 'bob'.  If bob instead\n    signed up with only his email address (bob@hotmail.com), and is viewing a\n    page at example.com, then render the full address, 'bob@hotmail.com'.\n\n    @param ctx: a L{WovenContext} which has remembered IRequest.\n\n    @param username: a string of the form localpart@domain.\n\n    @return: a L{Tag}, the given context's tag, with the appropriate username\n    appended to it.\n    \"\"\"\n    if username is None:\n        return ''\n    req = inevow.IRequest(ctx)\n    localpart, domain = username.split('@')\n    host = req.getHeader('Host').split(':')[0]\n    if host == domain or host.endswith(\".\" + domain):\n        username = localpart\n    return ctx.tag[username]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _installV2Powerups(anonymousSite):\n    anonymousSite.store.powerUp(anonymousSite, IWebViewer)\n    anonymousSite.store.powerUp(anonymousSite, IMantissaSite)", "response": "Installs the given L { AnonymousSite } for the powerup interfaces it was given in version 2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createResource(self):\n        pp = ixmantissa.IPublicPage(self.application, None)\n        if pp is not None:\n            warn(\n            \"Use the sharing system to provide public pages, not IPublicPage\",\n            category=DeprecationWarning,\n            stacklevel=2)\n            return pp.getResource()\n        return SharingIndex(self.application.open())", "response": "When invoked by L { PrefixURLMixin}, return a SharingIndex for my application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping the given L { INavigableFragment in the appropriate type of PublicPage.", "response": "def _wrapNavFrag(self, frag, useAthena):\n        \"\"\"\n        Wrap the given L{INavigableFragment} in the appropriate type of\n        L{_PublicPageMixin}.\n        \"\"\"\n        if useAthena:\n            return PublicAthenaLivePage(self._siteStore, frag)\n        else:\n            return PublicPage(None, self._siteStore, frag, None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef locateChild(self, ctx, segments):\n        D = defer.maybeDeferred(\n            self.currentResource.locateChild, ctx, segments)\n\n        def finishLocating((nextRes, nextPath)):\n            custom = ixmantissa.ICustomizable(nextRes, None)\n            if custom is not None:\n                return (custom.customizeFor(self.forWho), nextPath)\n            self.currentResource = nextRes\n            if nextRes is None:\n                return (nextRes, nextPath)\n            return (_CustomizingResource(nextRes, self.forWho), nextPath)\n\n        return D.addCallback(finishLocating)", "response": "Locate the child resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef produceResource(self, request, segments, webViewer):\n        mantissaSite = self.publicSiteRoot\n        if mantissaSite is not None:\n            for resource, domain in userbase.getAccountNames(self.store):\n                username = '%s@%s' % (resource, domain)\n                break\n            else:\n                username = None\n            bottomResource, newSegments = mantissaSite.siteProduceResource(\n                request, segments, webViewer)\n            return (_CustomizingResource(bottomResource, username), newSegments)\n        return None", "response": "Produce a resource that traverses site - wide content passing down the webViewer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the object that is used by the viewer and viewee.", "response": "def _getViewerPrivateApplication(self):\n        \"\"\"\n        Get the L{PrivateApplication} object for the logged-in user who is\n        viewing this resource, as indicated by its C{username} attribute.\n\n        This is highly problematic because it precludes the possibility of\n        separating the stores of the viewer and the viewee into separate\n        processes, and it is only here until we can get rid of it.  The reason\n        it remains is that some application code still imports things which\n        subclass L{PublicAthenaLivePage} and L{PublicPage} and uses them with\n        usernames specified.  See ticket #2702 for progress on this goal.\n\n        However, Mantissa itself will no longer set this class's username\n        attribute to anything other than None, because authenticated users'\n        pages will be generated using\n        L{xmantissa.webapp._AuthenticatedWebViewer}.  This method is used only\n        to render content in the shell template, and those classes have a direct\n        reference to the requisite object.\n\n        @rtype: L{PrivateApplication}\n        \"\"\"\n        ls = self.store.findUnique(userbase.LoginSystem)\n        substore = ls.accountByAddress(*self.username.split('@')).avatars.open()\n        from xmantissa.webapp import PrivateApplication\n        return substore.findUnique(PrivateApplication)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding login and signup links to the given tag.", "response": "def render_authenticateLinks(self, ctx, data):\n        \"\"\"\n        For unauthenticated users, add login and signup links to the given tag.\n        For authenticated users, remove the given tag from the output.\n\n        When necessary, the I{signup-link} pattern will be loaded from the tag.\n        Each copy of it will have I{prompt} and I{url} slots filled.  The list\n        of copies will be added as children of the tag.\n        \"\"\"\n        if self.username is not None:\n            return ''\n        # there is a circular import here which should probably be avoidable,\n        # since we don't actually need signup links on the signup page.  on the\n        # other hand, maybe we want to eventually put those there for\n        # consistency.  for now, this import is easiest, and although it's a\n        # \"friend\" API, which I dislike, it doesn't seem to cause any real\n        # problems...  -glyph\n        from xmantissa.signup import _getPublicSignupInfo\n\n        IQ = inevow.IQ(ctx.tag)\n        signupPattern = IQ.patternGenerator('signup-link')\n\n        signups = []\n        for (prompt, url) in _getPublicSignupInfo(self.store):\n            signups.append(signupPattern.fillSlots(\n                    'prompt', prompt).fillSlots(\n                    'url', url))\n\n        return ctx.tag[signups]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_startmenu(self, ctx, data):\n        if self.username is None:\n            return ''\n        translator = self._getViewerPrivateApplication()\n        pageComponents = translator.getPageComponents()\n        return startMenu(translator, pageComponents.navigation, ctx.tag)", "response": "Render the start - menu style navigation for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_settingsLink(self, ctx, data):\n        if self.username is None:\n            return ''\n        translator = self._getViewerPrivateApplication()\n        return settingsLink(\n            translator,\n            translator.getPageComponents().settings,\n            ctx.tag)", "response": "Render the settings link."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_applicationNavigation(self, ctx, data):\n        if self.username is None:\n            return ''\n        translator = self._getViewerPrivateApplication()\n        return applicationNavigation(\n            ctx,\n            translator,\n            translator.getPageComponents().navigation)", "response": "Render the application navigation for the given tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders some UI for performing searches.", "response": "def render_search(self, ctx, data):\n        \"\"\"\n        Render some UI for performing searches, if we know about a search\n        aggregator.\n        \"\"\"\n        if self.username is None:\n            return ''\n        translator = self._getViewerPrivateApplication()\n        searchAggregator = translator.getPageComponents().searchAggregator\n        if searchAggregator is None or not searchAggregator.providers():\n            return ''\n        return ctx.tag.fillSlots(\n            'form-action', translator.linkTo(searchAggregator.storeID))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_rootURL(self, ctx, data):\n        return ctx.tag[\n            ixmantissa.ISiteURLGenerator(self.store).rootURL(IRequest(ctx))]", "response": "Render the root URL of the WebSite."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender any required static content in the header from the C { staticContent } attribute of this page.", "response": "def render_header(self, ctx, data):\n        \"\"\"\n        Render any required static content in the header, from the C{staticContent}\n        attribute of this page.\n        \"\"\"\n        if self.staticContent is None:\n            return ctx.tag\n\n        header = self.staticContent.getHeader()\n        if header is not None:\n            return ctx.tag[header]\n        else:\n            return ctx.tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_footer(self, ctx, data):\n        if self.staticContent is None:\n            return ctx.tag\n\n        header = self.staticContent.getFooter()\n        if header is not None:\n            return ctx.tag[header]\n        else:\n            return ctx.tag", "response": "Render any required static content in the footer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_urchin(self, ctx, data):\n        key = website.APIKey.getKeyForAPI(self.store, website.APIKey.URCHIN)\n        if key is None:\n            return ''\n        return ctx.tag.fillSlots('urchin-key', key.apiKey)", "response": "Render the code for recording the urchin website."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getHeadContent(self, req):\n        site = ixmantissa.ISiteURLGenerator(self.store)\n        for t in getInstalledThemes(self.store):\n            yield t.head(req, site)", "response": "Retrieve a list of header content from all installed themes on the site\n        store."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef data_offerings(self, ctx, data):\n        for io in self.original.store.query(offering.InstalledOffering):\n            pp = ixmantissa.IPublicPage(io.application, None)\n            if pp is not None and getattr(pp, 'index', True):\n                warn(\"Use the sharing system to provide public pages,\"\n                     \" not IPublicPage\",\n                     category=DeprecationWarning,\n                     stacklevel=2)\n                yield {'name': io.offeringName}\n            else:\n                s = io.application.open()\n                try:\n                    pp = getEveryoneRole(s).getShare(getDefaultShareID(s))\n                    yield {'name': io.offeringName}\n                except NoSuchShare:\n                    continue", "response": "Generate a list of installed offerings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef locateChild(self, ctx, segments):\n        result = self._getAppStoreResource(ctx, segments[0])\n        if result is not None:\n            child, segments = result, segments[1:]\n            return child, segments\n\n        if segments[0] == '':\n            result = self.child_(ctx)\n            if result is not None:\n                child, segments = result, segments[1:]\n                return child, segments\n\n        # If the user is trying to access /private/*, then his session has\n        # expired or he is otherwise not logged in. Redirect him to /login,\n        # preserving the URL segments, rather than giving him an obscure 404.\n        if segments[0] == 'private':\n            u = URL.fromContext(ctx).click('/').child('login')\n            for seg in segments:\n                u = u.child(seg)\n            return u, ()\n\n        return rend.NotFound", "response": "Look up children in the normal manner but customize them for the authenticated user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncustomizes child lookup such that all installed offerings on the site have the same name and return the resource that is available on the site.", "response": "def _getAppStoreResource(self, ctx, name):\n        \"\"\"\n        Customize child lookup such that all installed offerings on the site\n        store that this page is viewing are given an opportunity to display\n        their own page.\n        \"\"\"\n        offer = self.frontPageItem.store.findFirst(\n            offering.InstalledOffering,\n            offering.InstalledOffering.offeringName == unicode(name, 'ascii'))\n        if offer is not None:\n            pp = ixmantissa.IPublicPage(offer.application, None)\n            if pp is not None:\n                warn(\"Use the sharing system to provide public pages,\"\n                     \" not IPublicPage\",\n                     category=DeprecationWarning,\n                     stacklevel=2)\n                return pp.getResource()\n            return SharingIndex(offer.application.open(),\n                                self.webViewer)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the child of the current page.", "response": "def child_(self, ctx):\n        \"\"\"\n        If the root resource is requested, return the primary\n        application's front page, if a primary application has been\n        chosen.  Otherwise return 'self', since this page can render a\n        simple index.\n        \"\"\"\n        if self.frontPageItem.defaultApplication is None:\n            return self.webViewer.wrapModel(\n                _OfferingsFragment(self.frontPageItem))\n        else:\n            return SharingIndex(self.frontPageItem.defaultApplication.open(),\n                                self.webViewer).locateChild(ctx, [''])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlocates a child page that remembers its segments.", "response": "def locateChild(self, ctx, segments):\n        \"\"\"\n        Return a clone of this page that remembers its segments, so that URLs like\n        /login/private/stuff will redirect the user to /private/stuff after\n        login has completed.\n        \"\"\"\n        arguments = IRequest(ctx).args\n        return self.__class__(\n            self.store, segments, arguments), ()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fromRequest(cls, store, request):\n        location = URL.fromRequest(request)\n        segments = location.pathList(unquote=True, copy=False)\n        segments.append(request.postpath[0])\n        return cls(store, segments, request.args)", "response": "Returns a L { LoginPage } which will present the user with a login prompt."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_head(self, ctx, data):\n        ctx.tag[tags.invisible(render=tags.directive('liveglue'))]\n        return _PublicPageMixin.render_head(self, ctx, data)", "response": "Render the head tag."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rootChild_resetPassword(self, req, webViewer):\n        from xmantissa.signup import PasswordResetResource\n        return PasswordResetResource(self.store)", "response": "This is the root child of a page which will allow the user to re - set their password."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef indirect(self, interface):\n        if interface == IWebViewer:\n            return _AnonymousWebViewer(self.store)\n        return super(AnonymousSite, self).indirect(interface)", "response": "Indirect the implementation of L{_AnonymousWebViewer. indirect."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_configurable_by_name(self, name):\n        l = [c for c in self.configurables if c.name == name]\n        if l:\n            return l[0]", "response": "Returns the first configurable with the specified name or None if no such configurator exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a pandas dataframe with the schema for each trial id and iteration?", "response": "def results(self, trial_ids):\n        \"\"\"\n        Accepts a sequence of trial ids and returns a pandas dataframe\n        with the schema\n\n        trial_id, iteration?, *metric_schema_union\n\n        where iteration is an optional column that specifies the iteration\n        when a user logged a metric, if the user supplied one. The iteration\n        column is added if any metric was logged with an iteration.\n        Then, every metric name that was ever logged is a column in the\n        metric_schema_union.\n        \"\"\"\n        metadata_folder = os.path.join(self.log_dir, constants.METADATA_FOLDER)\n        dfs = []\n        # TODO: various file-creation corner cases like the result file not\n        # always existing if stuff is not logged and etc should be ironed out\n        # (would probably be easier if we had a centralized Sync class which\n        # relied on some formal remote store semantics).\n        for trial_id in trial_ids:\n            # TODO constants should just contain the recipes for filename\n            # construction instead of this multi-file implicit constraint\n            result_file = os.path.join(\n                metadata_folder, trial_id + \"_\" + constants.RESULT_SUFFIX)\n            assert os.path.isfile(result_file), result_file\n            dfs.append(pd.read_json(result_file, typ='frame', lines=True))\n        df = pd.concat(dfs, axis=0, ignore_index=True, sort=False)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch the artifact at the given trial_id and prefix.", "response": "def fetch_artifact(self, trial_id, prefix):\n        \"\"\"\n        Verifies that all children of the artifact prefix path are\n        available locally. Fetches them if not.\n\n        Returns the local path to the given trial's artifacts at the\n        specified prefix, which is always just\n\n        {log_dir}/{trial_id}/{prefix}\n        \"\"\"\n        # TODO: general windows concern: local prefix will be in\n        # backslashes but remote dirs will be expecting /\n        # TODO: having s3 logic split between project and sync.py\n        # worries me\n        local = os.path.join(self.log_dir, trial_id, prefix)\n        if self.upload_dir:\n            remote = '/'.join([self.upload_dir, trial_id, prefix])\n            _remote_to_local_sync(remote, local)\n        return local"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scan_temperature(self, measure, temperature, rate, delay=1):\n        # set target temperature to current control temperature\n        self.target_temperature = Tset =  self.control_temperature\n        # we use a positive sign for the sweep rate if we sweep up and negative\n        # if we sweep down.\n        rate = abs(rate) if temperature - Tset > 0 else -abs(rate)\n        \n        t_last = time.time()\n        time.sleep(delay)\n        while True:\n            measure()\n            \n            # Update setpoint\n            t_now = time.time()\n            dt = t_now - t_last\n            dT =  dt * rate / 60.\n            t_last = t_now\n            if abs(temperature - Tset) < abs(dT):\n                self.target_temperature = temperature\n                break\n            else:\n                self.target_temperature = Tset = Tset + dT\n            time.sleep(delay)", "response": "Performs a temperature scan."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a temperature scan.", "response": "def scan_temperature_old(self, measure, temperature, rate, delay=1):\n        \"\"\"Performs a temperature scan.\n\n        Measures until the target temperature is reached.\n\n        :param measure: A callable called repeatedly until stability at target\n            temperature is reached.\n        :param temperature: The target temperature in kelvin.\n        :param rate: The sweep rate in kelvin per minute.\n        :param delay: The time delay between each call to measure in seconds.\n\n        \"\"\"\n        self.activity = 'hold'\n        # Clear old sweep table\n        self.sweep_table.clear()\n\n        # Use current temperature as target temperature\n        # and calculate sweep time.\n        current_temperature = self.control_temperature\n        sweep_time = abs((temperature - current_temperature) / rate)\n\n        self.sweep_table[0] = temperature, sweep_time, 0.\n        self.sweep_table[-1] = temperature, 0., 0.\n\n        self.activity = 'sweep'\n        while self.activity == 'sweep':\n            measure()\n            time.sleep(delay)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_temperature(self, temperature, rate, delay=1):\n        self.scan_temperature(lambda: None, temperature, rate, delay)", "response": "Performs a temperature scan."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_temperature_old(self, temperature, rate, wait_for_stability=True, delay=1):\n        self.activity = 'hold'\n        # Clear old sweep table\n        self.sweep_table.clear()\n\n        # Use current temperature as target temperature\n        # and calculate sweep time.\n        current_temperature = self.control_temperature\n        sweep_time = abs((temperature - current_temperature) / rate)\n\n        self.sweep_table[0] = temperature, sweep_time, 0.\n        self.sweep_table[-1] = temperature, 0., 0.\n\n        self.activity = 'sweep'\n        if wait_for_stability:\n            while self.activity == 'sweep':\n                time.sleep(delay)", "response": "Sets the temperature.\n\n        .. note::\n\n            For complex sweep sequences, checkout :attr:`ITC503.sweep_table`.\n\n        :param temperature: The target temperature in kelvin.\n        :param rate: The sweep rate in kelvin per minute.\n        :param wait_for_stability: If wait_for_stability is `True`, the function\n            call blocks until the target temperature is reached and stable.\n        :param delay: The delay specifies the frequency how often the status is\n            checked."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load(self):\n        graph = self.context.parent.graph.get_context(self.context.identifier)\n        data = {}\n        for (_, p, o) in graph.triples((self.context.identifier, None, None)):\n            if not p.startswith(META):\n                continue\n            name = p[len(META):]\n            data[name] = o.toPython()\n        return data", "response": "Load provenance info from the main store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the provenance info for the current resource.", "response": "def generate(self):\n        \"\"\" Add provenance info to the context graph. \"\"\"\n        t = (self.context.identifier, RDF.type, META.Provenance)\n        if t not in self.context.graph:\n            self.context.graph.add(t)\n        for name, value in self.data.items():\n            pat = (self.context.identifier, META[name], None)\n            if pat in self.context.graph:\n                self.context.graph.remove(pat)\n            self.context.graph.add((pat[0], META[name], Literal(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef jsonresolver_loader(url_map):\n    def endpoint(doi_code):\n        pid_value = \"10.13039/{0}\".format(doi_code)\n        _, record = Resolver(pid_type='frdoi', object_type='rec',\n                             getter=Record.get_record).resolve(pid_value)\n        return record\n\n    pattern = '/10.13039/<doi_code>'\n    url_map.add(Rule(pattern, endpoint=endpoint, host='doi.org'))\n    url_map.add(Rule(pattern, endpoint=endpoint, host='dx.doi.org'))", "response": "Jsonresolver hook for funders resolving."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrecords up to 6 parameters at a time. :param args: Specifies the values to record. Valid ones are 'X', 'Y', 'R', 'theta', 'AuxIn1', 'AuxIn2', 'AuxIn3', 'AuxIn4', 'Ref', 'CH1' and 'CH2'. If none are given 'X' and 'Y' are used.", "response": "def snap(self, *args):\n        \"\"\"Records up to 6 parameters at a time.\n\n        :param args: Specifies the values to record. Valid ones are 'X', 'Y',\n          'R', 'theta', 'AuxIn1', 'AuxIn2', 'AuxIn3', 'AuxIn4', 'Ref', 'CH1'\n          and 'CH2'. If none are given 'X' and 'Y' are used.\n\n        \"\"\"\n        # TODO: Do not use transport directly.\n        params = {'X': 1, 'Y': 2, 'R': 3, 'Theta': 4, 'AuxIn1': 5, 'AuxIn2': 6,\n                  'AuxIn3': 7, 'AuxIn4': 8, 'Ref': 9, 'CH1': 10, 'CH2': 11}\n        if not args:\n            args = ['X', 'Y']\n        if len(args) > 6:\n            raise ValueError('Too many parameters (max: 6).')\n        cmd = 'SNAP? ' + ','.join(map(lambda x: str(params[x]), args))\n        result = self.transport.ask(cmd)\n        return map(float, result.split(','))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trace(self, buffer, start, length=1):\n        # TODO: Do not use transport directly.\n        query = 'TRCA? {0}, {1}, {2}'.format(buffer, start, length)\n        result = self.transport.ask(query)\n        # Result format: \"1.0e-004,1.2e-004,\". Strip trailing comma then split.\n        return (float(f) for f in result.strip(',').split(','))", "response": "Reads the points stored in the channel buffer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning whether the given store is an application store or not.", "response": "def isAppStore(s):\n    \"\"\"\n    Return whether the given store is an application store or not.\n    @param s: A Store.\n    \"\"\"\n    if s.parent is None:\n        return False\n    substore = s.parent.getItemByID(s.idInParent)\n    return s.parent.query(InstalledOffering,\n                          InstalledOffering.application == substore\n                          ).count() > 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getInstalledOfferings(self):\n        d = {}\n        installed = self._siteStore.query(InstalledOffering)\n        for installation in installed:\n            offering = installation.getOffering()\n            if offering is not None:\n                d[offering.name] = offering\n        return d", "response": "Returns a dictionary mapping from the name of each installed offering to the corresponding plugins."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls the given offering on the application store.", "response": "def installOffering(self, offering):\n        \"\"\"\n        Install the given offering::\n\n          - Create and install the powerups in its I{siteRequirements} list.\n          - Create an application L{Store} and a L{LoginAccount} referring to\n            it.  Install the I{appPowerups} on the application store.\n          - Create an L{InstalledOffering.\n\n        Perform all of these tasks in a transaction managed within the scope of\n        this call (that means you should not call this function inside a\n        transaction, or you should not handle any exceptions it raises inside\n        an externally managed transaction).\n\n        @type offering: L{IOffering}\n        @param offering: The offering to install.\n\n        @return: The C{InstalledOffering} item created.\n        \"\"\"\n        for off in self._siteStore.query(\n            InstalledOffering,\n            InstalledOffering.offeringName == offering.name):\n            raise OfferingAlreadyInstalled(off)\n\n        def siteSetup():\n            for (requiredInterface, requiredPowerup) in offering.siteRequirements:\n                if requiredInterface is not None:\n                    nn = requiredInterface(self._siteStore, None)\n                    if nn is not None:\n                        continue\n                if requiredPowerup is None:\n                    raise NotImplementedError(\n                        'Interface %r required by %r but not provided by %r' %\n                        (requiredInterface, offering, self._siteStore))\n                self._siteStore.findOrCreate(\n                    requiredPowerup, lambda p: installOn(p, self._siteStore))\n\n            ls = self._siteStore.findOrCreate(userbase.LoginSystem)\n            substoreItem = substore.SubStore.createNew(\n                self._siteStore, ('app', offering.name + '.axiom'))\n            ls.addAccount(offering.name, None, None, internal=True,\n                          avatars=substoreItem)\n\n            from xmantissa.publicweb import PublicWeb\n            PublicWeb(store=self._siteStore, application=substoreItem,\n                      prefixURL=offering.name)\n            ss = substoreItem.open()\n            def appSetup():\n                for pup in offering.appPowerups:\n                    installOn(pup(store=ss), ss)\n\n            ss.transact(appSetup)\n            # Woops, we need atomic cross-store transactions.\n            io = InstalledOffering(\n                store=self._siteStore, offeringName=offering.name,\n                application=substoreItem)\n\n            #Some new themes may be available now. Clear the theme cache\n            #so they can show up.\n            #XXX This is pretty terrible -- there\n            #really should be a scheme by which ThemeCache instances can\n            #be non-global. Fix this at the earliest opportunity.\n            from xmantissa import webtheme\n            webtheme.theThemeCache.emptyCache()\n            return io\n        return self._siteStore.transact(siteSetup)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling an offering and returns it.", "response": "def installOffering(self, offering, configuration):\n        \"\"\"\n        Create an app store for an L{Offering} and install its\n        dependencies. Also create an L{InstalledOffering} in the site store,\n        and return it.\n        \"\"\"\n        s = self.store.parent\n        self.installedOfferingCount += 1\n        return installOffering(s, offering, configuration)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_file(self, file):\n        if self.logger:\n            self.logger.debug(\"[ioc.extra.tornado.RouterHandler] send file %s\" % file)\n\n        self.send_file_header(file)\n\n        fp = open(file, 'rb')\n        self.write(fp.read())\n\n        fp.close()", "response": "Send a file to the client"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef triplify_object(binding):\n    triples = []\n    if binding.uri:\n        triples.append((binding.subject, RDF.type, binding.uri))\n\n    if binding.parent is not None:\n        parent = binding.parent.subject\n        if binding.parent.is_array:\n            parent = binding.parent.parent.subject\n        triples.append((parent, binding.predicate, binding.subject))\n        if binding.reverse is not None:\n            triples.append((binding.subject, binding.reverse, parent))\n\n    for prop in binding.properties:\n        _, prop_triples = triplify(prop)\n        triples.extend(prop_triples)\n\n    return binding.subject, triples", "response": "Create bi - directional bindings for object relationships."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef triplify(binding):\n    triples = []\n    if binding.data is None:\n        return None, triples\n\n    if binding.is_object:\n        return triplify_object(binding)\n    elif binding.is_array:\n        for item in binding.items:\n            _, item_triples = triplify(item)\n            triples.extend(item_triples)\n        return None, triples\n    else:\n        subject = binding.parent.subject\n        triples.append((subject, binding.predicate, binding.object))\n        if binding.reverse is not None:\n            triples.append((binding.object, binding.reverse, subject))\n        return subject, triples", "response": "Recursively generate RDF statements from the data and\n    schema supplied to the application."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef db_type(python_type_representation):\n    for type_name in _candidate_type_names(python_type_representation):\n        db_type_name = _lookup_type_name(type_name)\n        if db_type_name:\n            return db_type_name\n    raise ValueError(\"Failed to find sqlite3 column type for %s\" % (\n        python_type_representation))", "response": "Converts from any of the types in python_type_representation to a sqlite3 type name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ip_address(self):\n        networks = self.get(\"networks\", {})\n        v4nets = networks.get(\"v4\", [])\n        v6nets = networks.get(\"v6\", [])\n        try:\n            return (v4nets + v6nets)[0].ip_address\n        except IndexError:\n            return None", "response": "Returns the IP address of the first interface listed in the droplet s\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching & return a new Droplet object representing the droplet s current state", "response": "def fetch(self):\n        \"\"\"\n        Fetch & return a new `Droplet` object representing the droplet's\n        current state\n\n        :rtype: Droplet\n        :raises DOAPIError: if the API endpoint replies with an error (e.g., if\n            the droplet no longer exists)\n        \"\"\"\n        api = self.doapi_manager\n        return api._droplet(api.request(self.url)[\"droplet\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_all_snapshots(self):\n        api = self.doapi_manager\n        for obj in api.paginate(self.url + '/snapshots', 'snapshots'):\n            yield Image(obj, doapi_manager=api)", "response": "r Returns a generator that yields all of the snapshot images created from\n        the droplet\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch_all_backups(self):\n        api = self.doapi_manager\n        for obj in api.paginate(self.url + '/backups', 'backups'):\n            yield Image(obj, doapi_manager=api)", "response": "r Returns a generator that yields all of the backup images created from\n        the droplet\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch_all_kernels(self):\n        api = self.doapi_manager\n        for kern in api.paginate(self.url + '/kernels', 'kernels'):\n            yield Kernel(kern, doapi_manager=api)", "response": "r Returns a generator that yields all of the kernels available to the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef restore(self, image):\n        if isinstance(image, Image):\n            image = image.id\n        return self.act(type='restore', image=image)", "response": "Restores the droplet to the specified backup image"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resize(self, size, disk=None):\n        if isinstance(size, Size):\n            size = size.slug\n        opts = {\"disk\": disk} if disk is not None else {}\n        return self.act(type='resize', size=size, **opts)", "response": "This method resizes the droplet with the specified size."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrebuilds the droplet with the specified image", "response": "def rebuild(self, image):\n        \"\"\"\n        Rebuild the droplet with the specified image\n\n            A rebuild action functions just like a new create. [APIDocs]_\n\n        :param image: an image ID, an image slug, or an `Image` object\n            representing the image the droplet should use as a base\n        :type image: integer, string, or `Image`\n        :return: an `Action` representing the in-progress operation on the\n            droplet\n        :rtype: Action\n        :raises DOAPIError: if the API endpoint replies with an error\n        \"\"\"\n        if isinstance(image, Image):\n            image = image.id\n        return self.act(type='rebuild', image=image)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef change_kernel(self, kernel):\n        if isinstance(kernel, Kernel):\n            kernel = kernel.id\n        return self.act(type='change_kernel', kernel=kernel)", "response": "Change the kernel of the droplet"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait(self, status=None, locked=None, wait_interval=None,\n             wait_time=None):\n        \"\"\"\n        Poll the server periodically until the droplet has reached some final\n        state.  If ``status`` is non-`None`, ``wait`` will wait for the\n        droplet's ``status`` field to equal the given value.  If ``locked`` is\n        non-`None`, `wait` will wait for the droplet's ``locked`` field to\n        equal (the truth value of) the given value.  Exactly one of ``status``\n        and ``locked`` must be non-`None`.\n\n        If ``wait_time`` is exceeded, a `WaitTimeoutError` (containing the\n        droplet's most recently fetched state) is raised.\n\n        If a `KeyboardInterrupt` is caught, the droplet's most recently fetched\n        state is returned immediately without waiting for completion.\n\n        .. versionchanged:: 0.2.0\n            Raises `WaitTimeoutError` on timeout\n\n        .. versionchanged:: 0.2.0\n            ``locked`` parameter added\n\n        .. versionchanged:: 0.2.0\n            No longer waits for latest action to complete\n\n        :param status: When non-`None`, the desired value for the ``status``\n            field of the droplet, which should be one of\n            `Droplet.STATUS_ACTIVE`, `Droplet.STATUS_ARCHIVE`,\n            `Droplet.STATUS_NEW`, and `Droplet.STATUS_OFF`.  (For the sake of\n            forwards-compatibility, any other value is accepted as well.)\n        :type status: string or `None`\n        :param locked: When non-`None`, the desired value for the ``locked``\n            field of the droplet\n        :type locked: `bool` or `None`\n        :param number wait_interval: how many seconds to sleep between\n            requests; defaults to the `doapi` object's\n            :attr:`~doapi.wait_interval` if not specified or `None`\n        :param number wait_time: the total number of seconds after which the\n            method will raise an error if the droplet has not yet completed, or\n            a negative number to wait indefinitely; defaults to the `doapi`\n            object's :attr:`~doapi.wait_time` if not specified or `None`\n        :return: the droplet's final state\n        :rtype: Droplet\n        :raises TypeError: if both or neither of ``status`` & ``locked`` are\n            defined\n        :raises DOAPIError: if the API endpoint replies with an error\n        :raises WaitTimeoutError: if ``wait_time`` is exceeded\n        \"\"\"\n        return next(self.doapi_manager.wait_droplets([self], status, locked,\n                                                     wait_interval, wait_time))", "response": "Wait for the server to reach the desired status and optionally wait for the latest droplet to complete."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmint PIDs for a record.", "response": "def minter(record_uuid, data, pid_type, key):\n    \"\"\"Mint PIDs for a record.\"\"\"\n    pid = PersistentIdentifier.create(\n        pid_type,\n        data[key],\n        object_type='rec',\n        object_uuid=record_uuid,\n        status=PIDStatus.REGISTERED\n    )\n    for scheme, identifier in data['identifiers'].items():\n        if identifier:\n            PersistentIdentifier.create(\n                scheme,\n                identifier,\n                object_type='rec',\n                object_uuid=record_uuid,\n                status=PIDStatus.REGISTERED\n            )\n    return pid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating date objects between start_date and end_date in increment intervals.", "response": "def date_range(start_date, end_date, increment, period):\n    \"\"\"\n    Generate `date` objects between `start_date` and `end_date` in `increment`\n    `period` intervals.\n    \"\"\"\n    next = start_date\n    delta = relativedelta.relativedelta(**{period:increment})\n    while next <= end_date:\n        yield next\n        next += delta"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the Gamma - valley bandgap Eg_Gamma in electron Volts at a given temperature T in Kelvin", "response": "def GaP_Eg_Gamma(self, **kwargs):\n    '''\n    Returns the Gamma-valley bandgap, Eg_Gamma, in electron Volts at a\n    given temperature, T, in Kelvin (default: 300 K).\n\n    GaP has a unique Gamma-gap temperature dependence.\n    '''\n    T = kwargs.get('T', 300.)\n    if T < 1e-4:\n        return self.Eg_Gamma_0()\n    return self.Eg_Gamma_0() + 0.1081 * (1 - 1. / tanh(164. / T))  # eV"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_date_bounds(self, date):\n        '''\n        Pass in the date used in the original query.\n\n        :param date: Date (date range) that was queried:\n            date -> 'd', '~d', 'd~', 'd~d'\n            d -> '%Y-%m-%d %H:%M:%S,%f', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d'\n        '''\n        if date is not None:\n            split = date.split('~')\n            if len(split) == 1:\n                self._lbound = ts2dt(date)\n                self._rbound = ts2dt(date)\n            elif len(split) == 2:\n                if split[0] != '':\n                    self._lbound = ts2dt(split[0])\n                if split[1] != '':\n                    self._rbound = ts2dt(split[1])\n            else:\n                raise Exception('Date %s is not in the correct format' % date)", "response": "Sets the date bounds of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that left and right bounds are sane", "response": "def check_in_bounds(self, date):\n        '''Check that left and right bounds are sane\n\n        :param date: date to validate left/right bounds for\n        '''\n        dt = Timestamp(date)\n        return ((self._lbound is None or dt >= self._lbound) and\n                (self._rbound is None or dt <= self._rbound))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering out only the rows that match the spectified date.", "response": "def on_date(self, date, only_count=False):\n        '''\n        Filters out only the rows that match the spectified date.\n        Works only on a Result that has _start and _end columns.\n\n        :param date: date can be anything Pandas.Timestamp supports parsing\n        :param only_count: return back only the match count\n        '''\n        if not self.check_in_bounds(date):\n            raise ValueError('Date %s is not in the queried range.' % date)\n        date = Timestamp(date)\n        after_start = self._start <= date\n        before_end = (self._end > date) | self._end_isnull\n        if only_count:\n            return np.sum(before_end & after_start)\n        else:\n            return self.filter(before_end & after_start)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Series of the result s history.", "response": "def history(self, dates=None, linreg_since=None, lin_reg_days=20):\n        '''\n        Works only on a Result that has _start and _end columns.\n\n        :param dates: list of dates to query\n        :param linreg_since: estimate future values using linear regression.\n        :param lin_reg_days: number of past days to use as prediction basis\n        '''\n        dates = dates or self.get_dates_range()\n        vals = [self.on_date(dt, only_count=True) for dt in dates]\n        ret = Series(vals, index=dates)\n        if linreg_since is not None:\n            ret = self._linreg_future(ret, linreg_since, lin_reg_days)\n        return ret.sort_index()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _linreg_future(self, series, since, days=20):\n        '''\n        Predicts future using linear regression.\n\n        :param series:\n            A series in which the values will be places.\n            The index will not be touched.\n            Only the values on dates > `since` will be predicted.\n        :param since:\n            The starting date from which the future will be predicted.\n        :param days:\n            Specifies how many past days should be used in the linear\n            regression.\n        '''\n        last_days = pd.date_range(end=since, periods=days)\n        hist = self.history(last_days)\n\n        xi = np.array(map(dt2ts, hist.index))\n        A = np.array([xi, np.ones(len(hist))])\n        y = hist.values\n        w = np.linalg.lstsq(A.T, y)[0]\n\n        for d in series.index[series.index > since]:\n            series[d] = w[0] * dt2ts(d) + w[1]\n            series[d] = 0 if series[d] < 0 else series[d]\n\n        return series", "response": "Predicts future using linear regression."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of dates sampled according to the specified parameters.", "response": "def get_dates_range(self, scale='auto', start=None, end=None,\n                        date_max='2010-01-01'):\n        '''\n        Returns a list of dates sampled according to the specified parameters.\n\n        :param scale: {'auto', 'maximum', 'daily', 'weekly', 'monthly',\n            'quarterly', 'yearly'}\n            Scale specifies the sampling intervals.\n            'auto' will heuristically choose a scale for quick processing\n        :param start: First date that will be included.\n        :param end: Last date that will be included\n        '''\n        if scale not in ['auto', 'maximum', 'daily', 'weekly', 'monthly',\n                         'quarterly', 'yearly']:\n            raise ValueError('Incorrect scale: %s' % scale)\n        start = Timestamp(start or self._start.min() or date_max)\n        # FIXME: start != start is true for NaN objects... is NaT the same?\n        start = Timestamp(date_max) if repr(start) == 'NaT' else start\n        end = Timestamp(end or max(Timestamp(self._end.max()),\n                                   self._start.max()))\n        # FIXME: end != end ?\n        end = datetime.utcnow() if repr(end) == 'NaT' else end\n        start = start if self.check_in_bounds(start) else self._lbound\n        end = end if self.check_in_bounds(end) else self._rbound\n\n        if scale == 'auto':\n            scale = self._auto_select_scale(start, end)\n        if scale == 'maximum':\n            start_dts = list(self._start.dropna().values)\n            end_dts = list(self._end.dropna().values)\n            dts = map(Timestamp, set(start_dts + end_dts))\n            dts = filter(lambda ts: self.check_in_bounds(ts) and\n                         ts >= start and ts <= end, dts)\n            return dts\n\n        freq = dict(daily='D', weekly='W', monthly='M', quarterly='3M',\n                    yearly='12M')\n        offset = dict(daily=off.Day(n=0), weekly=off.Week(),\n                      monthly=off.MonthEnd(), quarterly=off.QuarterEnd(),\n                      yearly=off.YearEnd())\n        # for some reason, weekly date range gives one week less:\n        end_ = end + off.Week() if scale == 'weekly' else end\n        ret = list(pd.date_range(start + offset[scale], end_,\n                                 freq=freq[scale]))\n        ret = [dt for dt in ret if dt <= end]\n        ret = [start] + ret if ret and start < ret[0] else ret\n        ret = ret + [end] if ret and end > ret[-1] else ret\n        ret = filter(lambda ts: self.check_in_bounds(ts), ret)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nguess what a good timeseries scale might be, given a particular data set, attempting to make the total number of x values as close to `ideal` as possible This is a helper for plotting", "response": "def _auto_select_scale(self, start=None, end=None, ideal=300):\n        '''\n        Guess what a good timeseries scale might be,\n        given a particular data set, attempting to\n        make the total number of x values as close to\n        `ideal` as possible\n\n        This is a helper for plotting\n        '''\n        start = start or self._start.min()\n        end = end or max(self._end.max(), self._start.max())\n        daily_count = (end - start).days\n        if daily_count <= ideal:\n            return 'daily'\n        elif daily_count / 7 <= ideal:\n            return 'weekly'\n        elif daily_count / 30 <= ideal:\n            return 'monthly'\n        elif daily_count / 91 <= ideal:\n            return 'quarterly'\n        else:\n            return 'yearly'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nleaving only objects with specified oids.", "response": "def filter_oids(self, oids):\n        '''\n        Leaves only objects with specified oids.\n\n        :param oids: list of oids to include\n        '''\n        oids = set(oids)\n        return self[self['_oid'].map(lambda x: x in oids)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of unfinished objects.", "response": "def unfinished_objects(self):\n        '''\n        Leaves only versions of those objects that has some version with\n        `_end == None` or with `_end > right cutoff`.\n        '''\n        mask = self._end_isnull\n        if self._rbound is not None:\n            mask = mask | (self._end > self._rbound)\n        oids = set(self[mask]._oid.tolist())\n        return self[self._oid.apply(lambda oid: oid in oids)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncount how many objects that exist before a given date or on a given date.", "response": "def persistent_oid_counts(self, dates):\n        '''\n        Counts how many objects (identified by their oids) existed before\n        or on a given date.\n\n        :param dates: list of the dates the count should be computed.\n        '''\n        total = pd.Series([self.on_date(d)._oid for d in dates],\n                          index=dates)\n        for i in range(1, total.size):\n            a1 = total[total.index[i - 1]]\n            a2 = total[total.index[i]]\n            total[total.index[i]] = list(set(a1) | set(a2))\n        return total.apply(len)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef last_versions_with_age(self, col_name='age'):\n        '''\n        Leaves only the latest version for each object.\n        Adds a new column which represents age.\n        The age is computed by subtracting _start of the oldest version\n        from one of these possibilities::\n\n            # psuedo-code\n            if self._rbound is None:\n                if latest_version._end is pd.NaT:\n                    current_time is used\n                else:\n                    min(current_time, latest_version._end) is used\n            else:\n                if latest_version._end is pd.NaT:\n                    self._rbound is used\n                else:\n                    min(self._rbound, latest_version._end) is used\n\n        :param index: name of the new column.\n        '''\n        min_start_map = {}\n        max_start_map = {}\n        max_start_ser_map = {}\n\n        cols = self.columns.tolist()\n        i_oid = cols.index('_oid')\n        i_start = cols.index('_start')\n        i_end = cols.index('_end')\n        for row in self.values:\n            s = row[i_start]\n            oid = row[i_oid]\n            mins = min_start_map.get(oid, s)\n            if s <= mins:\n                min_start_map[oid] = s\n            maxs = max_start_map.get(oid, s)\n            if s >= maxs:\n                max_start_map[oid] = s\n                max_start_ser_map[oid] = row\n\n        vals = max_start_ser_map.values()\n        cut_ts = datetime.utcnow()\n        ages = []\n        for row in vals:\n            end = row[i_end]\n            end = cut_ts if end is pd.NaT else min(cut_ts, end)\n            age = end - min_start_map[row[i_oid]]\n            age = age - timedelta(microseconds=age.microseconds)\n            ages.append(age)\n\n        res = pd.DataFrame(max_start_ser_map.values(), columns=cols)\n        res[col_name] = pd.Series(ages, index=res.index)\n        return res", "response": "Returns a DataFrame with the last versions of each object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a DataFrame with the last chain of objects in the archive.", "response": "def last_chain(self):\n        '''\n        Leaves only the last chain for each object.\n\n        Chain is a series of consecutive versions where\n        `_end` of one is `_start` of another.\n        '''\n        cols = self.columns.tolist()\n        i_oid = cols.index('_oid')\n        i_start = cols.index('_start')\n        i_end = cols.index('_end')\n\n        start_map = {}\n        end_map = {}\n        for row in self.values:\n            oid = row[i_oid]\n            if oid not in start_map:\n                start_map[oid] = set()\n                end_map[oid] = set()\n            start_map[oid].add(row[i_start])\n            end_map[oid].add(row[i_end])\n\n        cutoffs = {}\n        for oid in start_map:\n            maxend = pd.NaT if pd.NaT in end_map[oid] else max(end_map[oid])\n            ends = end_map[oid] - start_map[oid] - set([maxend])\n            cutoffs[oid] = None if len(ends) == 0 else max(ends)\n\n        vals = [row for row in self.values\n                if cutoffs[row[i_oid]] is None\n                or cutoffs[row[i_oid]] < row[i_start]]\n\n        return pd.DataFrame(vals, columns=cols)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef one_version(self, index=0):\n        '''\n        Leaves only one version for each object.\n\n        :param index: List-like index of the version.  0 == first; -1 == last\n        '''\n        def prep(df):\n            start = sorted(df._start.tolist())[index]\n            return df[df._start == start]\n\n        return pd.concat([prep(df) for _, df in self.groupby(self._oid)])", "response": "Leaves only one version for each object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nleaves only those objects whose first version started after the specified date.", "response": "def started_after(self, date):\n        '''\n        Leaves only those objects whose first version started after the\n        specified date.\n\n        :param date: date string to use in calculation\n        '''\n        dt = Timestamp(date)\n        starts = self.groupby(self._oid).apply(lambda df: df._start.min())\n        oids = set(starts[starts > dt].index.tolist())\n        return self[self._oid.apply(lambda v: v in oids)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying a function to each object in the group by _oid then concatenates the results.", "response": "def object_apply(self, function):\n        '''\n        Groups by _oid, then applies the function to each group\n        and finally concatenates the results.\n\n        :param function: func that takes a DataFrame and returns a DataFrame\n        '''\n        return pd.concat([function(df) for _, df in self.groupby(self._oid)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if x is explicitly defined in kwargs", "response": "def _has_x(self, kwargs):\n        '''Returns True if x is explicitly defined in kwargs'''\n        return (('x' in kwargs) or (self._element_x in kwargs) or\n                (self._type == 3 and self._element_1mx in kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn x if it is explicitly defined in kwargs otherwise raises TypeError.", "response": "def _get_x(self, kwargs):\n        '''\n        Returns x if it is explicitly defined in kwargs.\n        Otherwise, raises TypeError.\n        '''\n        if 'x' in kwargs:\n            return round(float(kwargs['x']), 6)\n        elif self._element_x in kwargs:\n            return round(float(kwargs[self._element_x]), 6)\n        elif self._type == 3 and self._element_1mx in kwargs:\n            return round(1. - float(kwargs[self._element_1mx]), 6)\n        else:\n            raise TypeError()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if y is explicitly defined in kwargs", "response": "def _has_y(self, kwargs):\n        '''Returns True if y is explicitly defined in kwargs'''\n        return (('y' in kwargs) or (self._element_y in kwargs) or\n                (self._type == 3 and self._element_1my in kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_y(self, kwargs):\n        '''\n        Returns y if it is explicitly defined in kwargs.\n        Otherwise, raises TypeError.\n        '''\n        if 'y' in kwargs:\n            return round(float(kwargs['y']), 6)\n        elif self._element_y in kwargs:\n            return round(float(kwargs[self._element_y]), 6)\n        elif self._type == 3 and self._element_1my in kwargs:\n            return round(1. - float(kwargs[self._element_1my]), 6)\n        else:\n            raise TypeError()", "response": "Returns y if it is explicitly defined in kwargs otherwise raises TypeError."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning z if type is 1 or 2 and z is explicitly defined in kwargs. Otherwise raises TypeError.", "response": "def _get_z(self, kwargs):\n        '''\n        Returns z if type is 1 or 2 and z is explicitly defined in kwargs.\n        Otherwise, raises TypeError.\n        '''\n        if self._type == 1 or self._type == 2:\n            if 'z' in kwargs:\n                return round(float(kwargs['z']), 6)\n            elif self._element_z in kwargs:\n                return round(float(kwargs[self._element_z]), 6)\n        raise TypeError()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exists(cls, query=None, path=None, **kwargs):\n        if query is None and len(kwargs) > 0:\n            query = kwargs\n        if query is None:\n            return False\n        return cls.db(path).find_one(query) is not None", "response": "Returns a boolean as to whether or not the object with the specified key - value pairs exists in the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(cls, data, path=None, defaults=None, overwrite=False,\n               random_id=False, **kwargs):\n        \"\"\"\n        Creates a new database object and stores it in the database\n        \n        NOTE: The path and defaults parameters to this function are to allow\n        use of the DatabaseObject class directly.  However, this class is\n        intended for subclassing and children of it should override the PATH\n        and DEFAULTS attributes rather than passing them as parameters here.\n        \n        @param data: dictionary of data that the object should be created with;\n            this must follow all mongo rules, as well as have an entry for\n            ID_KEY unless random_id == True\n        @param path: the path of the database to use, in the form\n            \"database.collection\"\n        @param defaults: the defaults dictionary to use for this object\n        @param overwrite: if set to true, will overwrite any object in the\n            database with the same ID_KEY; if set to false will raise an\n            exception if there is another object with the same ID_KEY\n        @param random_id: stores the new object with a random value for ID_KEY;\n            overwrites data[ID_KEY]\n        @param **kwargs: ignored\n        \n        @raise Exception: if path and self.PATH are None; the database path\n            must be defined in at least one of these\n        @raise DatabaseConflictError: if there is already an object with that\n            ID_KEY and overwrite == False\n        @raise MalformedObjectError: if a REQUIRED key of defaults is missing,\n            or if the ID_KEY of the object is None and random_id is False\n        \"\"\"\n        self = cls(path=path, defaults=defaults, _new_object=data)\n        for key, value in self.items():\n            if key == ID_KEY:\n                continue\n            if self.DEFAULTS and key not in self.DEFAULTS:\n                self._handle_non_default_key(key, value)\n            self._check_type(key, value)\n        if random_id and ID_KEY in self:\n            dict.__delitem__(self, ID_KEY)\n        if not random_id and ID_KEY not in self:\n            raise MalformedObjectError(\"No \" + ID_KEY + \" key in item\")\n        if not random_id and not overwrite and self._collection.find_one({ID_KEY: data[ID_KEY]}):\n            raise DatabaseConflictError('ID_KEY \"%s\" already exists in collection %s' %\n                                        (data[ID_KEY], self.PATH))\n        self._pre_save()\n        if ID_KEY in self and overwrite:\n            self._collection.replace_one({ID_KEY: self[ID_KEY]}, dict(self), upsert=True)\n        else:\n            insert_result = self._collection.insert_one(dict(self))\n            dict.__setitem__(self, ID_KEY, insert_result.inserted_id)\n        return self", "response": "Creates a new database object and stores it in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_from_json(cls, json_str, ignore_non_defaults=True):\n        create_dict = json.loads(json_str, cls=MongoliaJSONDecoder, encoding=\"utf-8\")\n        # Remove all keys not in DEFAULTS if ignore_non_defaults is True\n        if cls.DEFAULTS and ignore_non_defaults:\n            for key in frozenset(create_dict).difference(frozenset(cls.DEFAULTS)):\n                del create_dict[key]\n        \n        cls.create(create_dict, random_id=True)", "response": "Creates a new database object from a json string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef db(cls, path=None):\n        if cls.PATH is None and path is None:\n            raise Exception(\"No database specified\")\n        if path is None:\n            path = cls.PATH\n        if \".\" not in path:\n            raise Exception(('invalid path \"%s\"; database paths must be ' +\n                             'of the form \"database.collection\"') % (path,))\n        if CONNECTION.test_mode:\n            return CONNECTION.get_connection()[TEST_DATABASE_NAME][path]\n        (db, coll) = path.split('.', 1)\n        return CONNECTION.get_connection()[db][coll]", "response": "Returns a pymongo Collection object from the current database connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the current state of the DatabaseObject to the database.", "response": "def save(self):\n        \"\"\"\n        Saves the current state of the DatabaseObject to the database.  Fills\n        in missing values from defaults before saving.\n        \n        NOTE: The actual operation here is to overwrite the entry in the\n        database with the same ID_KEY.\n        \n        WARNING: While the save operation itself is atomic, it is not atomic\n        with loads and modifications to the object.  You must provide your own\n        synchronization if you have multiple threads or processes possibly\n        modifying the same database object.  The update method is better from\n        a concurrency perspective.\n        \n        @raise MalformedObjectError: if the object does not provide a value\n            for a REQUIRED default\n        \"\"\"\n        self._pre_save()\n        self._collection.replace_one({ID_KEY: self[ID_KEY]}, dict(self))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rename(self, new_id):\n        old_id = dict.__getitem__(self, ID_KEY)\n        dict.__setitem__(self, ID_KEY, new_id)\n        self._collection.save(self)\n        self._collection.remove({ID_KEY: old_id})", "response": "Renames the DatabaseObject to have ID_KEY new_id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self):\n        self._collection.remove({ID_KEY: self[ID_KEY]})\n        dict.clear(self)", "response": "Removes the object from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a copy of the DatabaseObject under the ID_KEY new_id.", "response": "def copy(self, new_id=None, attribute_overrides={}):\n        \"\"\"\n        Copies the DatabaseObject under the ID_KEY new_id.\n        \n        @param new_id: the value for ID_KEY of the copy; if this is none,\n            creates the new object with a random ID_KEY\n        @param attribute_overrides: dictionary of attribute names -> values that you would like to override with.\n        \"\"\"\n        data = dict(self)\n        data.update(attribute_overrides)\n        if new_id is not None:\n            data[ID_KEY] = new_id\n            return self.create(data, path=self.PATH)\n        else:\n            del data[ID_KEY]\n            return self.create(data, random_id=True, path=self.PATH)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply updates to the database object with the specified update_dict.", "response": "def update(self, update_dict=None, raw=False, **kwargs):\n        \"\"\"\n        Applies updates both to the database object and to the database via the\n        mongo update method with the $set argument.  Use the `raw` keyword to\n        perform an arbitrary mongo update query.\n        \n        WARNING: Raw updates do not perform type checking.\n        \n        WARNING: While the update operation itself is atomic, it is not atomic\n        with loads and modifications to the object.  You must provide your own\n        synchronization if you have multiple threads or processes possibly\n        modifying the same database object.  While this is safer from a\n        concurrency perspective than the access pattern load -> modify -> save\n        as it only updates keys specified in the update_dict, it will still\n        overwrite updates to those same keys that were made while the object\n        was held in memory.\n        \n        @param update_dict: dictionary of updates to apply\n        @param raw: if set to True, uses the contents of update_dict directly\n            to perform the update rather than wrapping them in $set.\n        @param **kwargs: used as update_dict if no update_dict is None\n        \"\"\"\n        if update_dict is None:\n            update_dict = kwargs\n        if raw:\n            self._collection.update_one({ID_KEY: self[ID_KEY]}, update_dict)\n            new_data = self._collection.find_one({ID_KEY: self[ID_KEY]})\n            dict.clear(self)\n            dict.update(self, new_data)\n        else:\n            for key, value in update_dict.items():\n                self._check_type(key, value)\n            dict.update(self, update_dict)\n            self._collection.update_one({ID_KEY: self[ID_KEY]}, {SET: update_dict})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef json_update(self, json_str, exclude=[], ignore_non_defaults=True):\n        update_dict = json.loads(json_str, cls=MongoliaJSONDecoder, encoding=\"utf-8\")\n        # Remove ID_KEY since it can't be part of a mongo update operation\n        if ID_KEY in update_dict:\n            del update_dict[ID_KEY]\n        \n        # Remove all keys in the exclude list from the update\n        for key in frozenset(exclude).intersection(frozenset(update_dict)):\n            del update_dict[key]\n        \n        # Remove all keys not in DEFAULTS if ignore_non_defaults is True\n        if self.DEFAULTS and ignore_non_defaults:\n            for key in frozenset(update_dict).difference(frozenset(self.DEFAULTS)):\n                del update_dict[key]\n        \n        self.update(update_dict)", "response": "Updates the database object based on a json string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef json_update_fields(self, json_str, fields_to_update):\n        update_dict = json.loads(json_str, cls=MongoliaJSONDecoder, encoding=\"utf-8\")\n        update_dict = dict((k, v) for k, v in update_dict.items()\n                       if k in fields_to_update and k != ID_KEY)\n        self.update(update_dict)", "response": "Updates the specified fields of a database object based on a json string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning raxml on alignment object align_obj returns tuple of tree node parsimony tree node log likelihood total exec time", "response": "def raxml_alignment(align_obj,\n                 raxml_model=\"GTRCAT\",\n                 params={},\n                 SuppressStderr=True,\n                 SuppressStdout=True):\n    \"\"\"Run raxml on alignment object\n\n    align_obj: Alignment object\n    params: you can set any params except -w and -n\n\n    returns: tuple (phylonode,\n                    parsimonyphylonode,\n                    log likelihood,\n                    total exec time)\n    \"\"\"\n\n    # generate temp filename for output\n    params[\"-w\"] = \"/tmp/\"\n    params[\"-n\"] = get_tmp_filename().split(\"/\")[-1]\n    params[\"-m\"] = raxml_model\n    params[\"-p\"] = randint(1,100000)\n    ih = '_input_as_multiline_string'\n    seqs, align_map = align_obj.toPhylip()\n\n    #print params[\"-n\"]\n\n    # set up command\n    raxml_app = Raxml(\n                   params=params,\n                   InputHandler=ih,\n                   WorkingDir=None,\n                   SuppressStderr=SuppressStderr,\n                   SuppressStdout=SuppressStdout)\n\n    # run raxml\n    ra = raxml_app(seqs)\n\n    # generate tree\n    tree_node =  DndParser(ra[\"Result\"])\n\n    # generate parsimony tree\n    parsimony_tree_node =  DndParser(ra[\"ParsimonyTree\"])\n\n    # extract log likelihood from log file\n    log_file = ra[\"Log\"]\n    total_exec_time = exec_time = log_likelihood = 0.0\n    for line in log_file:\n        exec_time, log_likelihood = map(float, line.split())\n        total_exec_time += exec_time\n\n    # remove output files\n    ra.cleanUp()\n\n    return tree_node, parsimony_tree_node, log_likelihood, total_exec_time"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_tree_from_alignment(aln, moltype=DNA, best_tree=False, params={}):\n    if best_tree:\n        raise NotImplementedError\n\n    if '-m' not in params:\n        if moltype == DNA or moltype == RNA:\n            #params[\"-m\"] = 'GTRMIX'\n            # in version 7.2.3, GTRMIX is no longer supported but says GTRCAT\n            # behaves like GTRMIX (http://www.phylo.org/tools/raxmlhpc2.html)\n            params[\"-m\"] = 'GTRGAMMA'\n        elif moltype == PROTEIN:\n            params[\"-m\"] = 'PROTGAMMAmatrixName'\n        else:\n            raise ValueError, \"Moltype must be either DNA, RNA, or PROTEIN\"\n\n    if not hasattr(aln, 'toPhylip'):\n        aln = Alignment(aln)\n    seqs, align_map = aln.toPhylip()\n\n    # generate temp filename for output\n    params[\"-w\"] = \"/tmp/\"\n    params[\"-n\"] = get_tmp_filename().split(\"/\")[-1]\n    params[\"-k\"] = True\n    params[\"-p\"] = randint(1,100000)\n    params[\"-x\"] = randint(1,100000)\n\n    ih = '_input_as_multiline_string'\n\n    raxml_app = Raxml(params=params,\n                      InputHandler=ih,\n                      WorkingDir=None,\n                      SuppressStderr=True,\n                      SuppressStdout=True)\n\n    raxml_result = raxml_app(seqs)\n\n    tree = DndParser(raxml_result['Bootstrap'], constructor=PhyloNode)\n\n    for node in tree.tips():\n        node.Name = align_map[node.Name]\n\n    raxml_result.cleanUp()\n\n    return tree", "response": "Builds a tree from an alignment object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts sequences into a tree.", "response": "def insert_sequences_into_tree(seqs, moltype, params={},\n                                           write_log=True):\n    \"\"\"Insert sequences into Tree.\n\n    aln: an xxx.Alignment object, or data that can be used to build one.\n\n    moltype: cogent.core.moltype.MolType object\n\n    params: dict of parameters to pass in to the RAxML app controller.\n\n    The result will be a tree.\n    \"\"\"\n\n    ih = '_input_as_multiline_string'\n\n    raxml_app = Raxml(params=params,\n                      InputHandler=ih,\n                      WorkingDir=None,\n                      SuppressStderr=False,\n                      SuppressStdout=False,\n                      HALT_EXEC=False)\n\n    raxml_result = raxml_app(seqs)\n\n    # write a log file\n    if write_log:\n        log_fp = join(params[\"-w\"],'log_raxml_'+split(get_tmp_filename())[-1])\n        log_file=open(log_fp,'w')\n        log_file.write(raxml_result['StdOut'].read())\n        log_file.close()\n\n    '''\n    # getting setup since parsimony doesn't output tree..only jplace, however\n    # it is currently corrupt\n\n    # use guppy to convert json file into a placement tree\n    guppy_params={'tog':None}\n\n    new_tree=build_tree_from_json_using_params(raxml_result['json'].name, \\\n                                               output_dir=params[\"-w\"], \\\n                                               params=guppy_params)\n    '''\n\n    # get tree from 'Result Names'\n    new_tree=raxml_result['Result'].readlines()\n    filtered_tree=re.sub('\\[I\\d+\\]','',str(new_tree))\n    tree = DndParser(filtered_tree, constructor=PhyloNode)\n\n    raxml_result.cleanUp()\n\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats the output filename for the log file.", "response": "def _format_output(self, outfile_name, out_type):\n        \"\"\" Prepend proper output prefix to output filename \"\"\"\n\n        outfile_name = self._absolute(outfile_name)\n        outparts = outfile_name.split(\"/\")\n        outparts[-1] = self._out_format % (out_type, outparts[-1] )\n\n        return '/'.join(outparts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_app_result_build_failure(self,out,err,exit_status,result_paths):\n\n        try:\n            raise ApplicationError, \\\n             'RAxML failed to produce an output file due to the following error: \\n\\n%s ' \\\n             % err.read()\n        except:\n            raise ApplicationError,\\\n                'RAxML failed to run properly.'", "response": "Catch the error when files are not produced"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of queues available.", "response": "def names(self):\n        \"\"\"\n        Returns a list of queues available, ``None`` if no such\n        queues found. Remember this will only shows queues with\n        at least one item enqueued.\n        \"\"\"\n        data = None\n        if not self.connected:\n            raise ConnectionError('Queue is not connected')\n\n        try:\n            data = self.rdb.keys(\"retaskqueue-*\")\n        except redis.exceptions.ConnectionError as err:\n            raise ConnectionError(str(err))\n\n        return [name[12:] for name in data]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef length(self):\n        if not self.connected:\n            raise ConnectionError('Queue is not connected')\n\n        try:\n            length = self.rdb.llen(self._name)\n        except redis.exceptions.ConnectionError as err:\n            raise ConnectionError(str(err))\n\n        return length", "response": "Returns the length of the queue."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a connection to the redis server and returns True if the connection works otherwise returns False.", "response": "def connect(self):\n        \"\"\"\n        Creates the connection with the redis server.\n        Return ``True`` if the connection works, else returns\n        ``False``. It does not take any arguments.\n\n        :return: ``Boolean`` value\n\n        .. note::\n\n           After creating the ``Queue`` object the user should call\n           the ``connect`` method to create the connection.\n\n        .. doctest::\n\n           >>> from retask import Queue\n           >>> q = Queue('test')\n           >>> q.connect()\n           True\n\n        \"\"\"\n        config = self.config\n        self.rdb = redis.Redis(config['host'], config['port'], config['db'],\\\n                              config['password'])\n        try:\n            info = self.rdb.info()\n            self.connected = True\n        except redis.ConnectionError:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait(self, wait_time=0):\n        if not self.connected:\n            raise ConnectionError('Queue is not connected')\n\n        data = self.rdb.brpop(self._name, wait_time)\n        if data:\n            task = Task()\n            task.__dict__ = json.loads(data[1])\n            return task\n        else:\n            return False", "response": "Waits for a task from the queue to arrive. Returns False if it timeout."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Task object from the queue.", "response": "def dequeue(self):\n        \"\"\"\n        Returns a :class:`~retask.task.Task` object from the queue. Returns ``None`` if the\n        queue is empty.\n\n        :return: :class:`~retask.task.Task` object from the queue\n\n        If the queue is not connected then it will raise\n        :class:`retask.ConnectionError`\n\n        .. doctest::\n\n           >>> from retask import Queue\n           >>> q = Queue('test')\n           >>> q.connect()\n           True\n           >>> t = q.dequeue()\n           >>> print t.data\n           {u'name': u'kushal'}\n\n        \"\"\"\n        if not self.connected:\n            raise ConnectionError('Queue is not connected')\n\n        if self.rdb.llen(self._name) == 0:\n            return None\n\n        data = self.rdb.rpop(self._name)\n        if not data:\n            return None\n        if isinstance(data, six.binary_type):\n            data = six.text_type(data, 'utf-8', errors = 'replace')\n        task = Task()\n        task.__dict__ = json.loads(data)\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending the result back to the producer.", "response": "def send(self, task, result, expire=60):\n        \"\"\"\n        Sends the result back to the producer. This should be called if only you\n        want to return the result in async manner.\n\n        :arg task: ::class:`~retask.task.Task` object\n        :arg result: Result data to be send back. Should be in JSON serializable.\n        :arg expire: Time in seconds after the key expires. Default is 60 seconds.\n        \"\"\"\n        self.rdb.lpush(task.urn, json.dumps(result))\n        self.rdb.expire(task.urn, expire)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find(self, obj):\n        if not self.connected:\n            raise ConnectionError('Queue is not connected')\n\n        data = self.rdb.lrange(self._name, 0, -1)\n        for i, datum in enumerate(data):\n            if datum.find(str(obj)) != -1:\n                return i\n        return -1", "response": "Returns the index of the given object in the queue or - 1 if the object is not found."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef result(self):\n        if self.__result:\n            return self.__result\n        data = self.rdb.rpop(self.urn)\n        if data:\n            self.rdb.delete(self.urn)\n            data = json.loads(data)\n            self.__result = data\n            return data\n        else:\n            return None", "response": "Returns the result of the job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wait(self, wait_time=0):\n        if self.__result:\n            return True\n        data = self.rdb.brpop(self.urn, wait_time)\n        if data:\n            self.rdb.delete(self.urn)\n            data = json.loads(data[1])\n            self.__result = data\n            return True\n        else:\n            return False", "response": "Blocking call to check if the worker returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef messages_in_flight(self):\n        self.prune_sent()\n        if not self.send_queue.empty() or len(self.sent) > 0:\n            return True\n        return False", "response": "Returns True if there are messages waiting to be sent or that there are errors occuring in the send queue."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a push to the device.", "response": "def _reallysend(self, payload, token, expiration=None, priority=None, identifier=None):\n        \"\"\"\n        Args:\n            payload (dict): The payload dictionary of the push to send\n            descriptor (any): Opaque variable that is passed back to the pushbaby on failure\n        \"\"\"\n\n        if not self.alive:\n            raise ConnectionDeadException()\n        if not self.useable:\n            raise ConnectionDeadException()\n        seq = self._nextSeq()\n        if seq >= PushConnection.MAX_PUSHES_PER_CONNECTION:\n            # IDs are 4 byte so rather than worry about wrapping IDs, just make a new connection\n            # Note we don't close the connection because we want to wait to see if any errors arrive\n            self._retire_connection()\n\n        payload_str = json_for_payload(truncate(payload))\n        items = ''\n        items += self._apns_item(PushConnection.ITEM_DEVICE_TOKEN, token)\n        items += self._apns_item(PushConnection.ITEM_PAYLOAD, payload_str)\n        items += self._apns_item(PushConnection.ITEM_IDENTIFIER, seq)\n        if expiration:\n            items += self._apns_item(PushConnection.ITEM_EXPIRATION, expiration)\n        if priority:\n            items += self._apns_item(PushConnection.ITEM_PRIORITY, priority)\n\n        apnsFrame = struct.pack(\"!BI\", PushConnection.COMMAND_SENDPUSH, len(items)) + items\n\n        try:\n            written = 0\n            while written < len(apnsFrame):\n                written += self.sock.send(apnsFrame[written:])\n        except:\n            logger.exception(\"Caught exception sending push\")\n            raise\n        self.sent[seq] = PushConnection.SentMessage(\n            time.time(), token, payload, expiration, priority, identifier\n        )\n        self.last_push_sent = time.time()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef db(self, connection_string=None):\n\n        connection_string = connection_string or self.settings[\"db\"]\n\n        if not hasattr(self, \"_db_conns\"):\n            self._db_conns = {}\n        if not connection_string in self._db_conns:\n            self._db_conns[connection_string] = oz.sqlalchemy.session(connection_string=connection_string)\n\n        return self._db_conns[connection_string]", "response": "Gets the SQLALchemy session for this request"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the sqlalchemy transaction. Rolls back if an error occurred.", "response": "def _sqlalchemy_on_finish(self):\n        \"\"\"\n        Closes the sqlalchemy transaction. Rolls back if an error occurred.\n        \"\"\"\n\n        if hasattr(self, \"_db_conns\"):\n            try:\n                if self.get_status() >= 200 and self.get_status() <= 399:\n                    for db_conn in self._db_conns.values():\n                        db_conn.commit()\n                else:\n                    for db_conn in self._db_conns.values():\n                        db_conn.rollback()\n            except:\n                tornado.log.app_log.warning(\"Error occurred during database transaction cleanup: %s\", str(sys.exc_info()[0]))\n                raise\n            finally:\n                for db_conn in self._db_conns.values():\n                    try:\n                        db_conn.close()\n                    except:\n                        tornado.log.app_log.warning(\"Error occurred when closing the database connection\", exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef use_settings(**kwargs):\n    '''\n    Context manager to temporarily override settings\n    '''\n    from omnic import singletons\n    singletons.settings.use_settings_dict(kwargs)\n    yield\n    singletons.settings.use_previous_settings()", "response": "Context manager to temporarily override settings"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_key(self):\n        \"Add ssh key to gitlab if necessary\"\n        try:\n            with open(self.args.ssh_public_key) as f:\n                public_key = f.read().strip()\n        except:\n            log.debug(\"No key found in {}\".format(self.args.ssh_public_key))\n            return None\n        g = self.gitlab\n        url = g['url'] + \"/user/keys\"\n        query = {'private_token': g['token']}\n        keys = requests.get(url, params=query).json()\n        log.debug(\"looking for '\" + public_key + \"' in \" + str(keys))\n        if (list(filter(lambda key: key['key'] == public_key, keys))):\n            log.debug(self.args.ssh_public_key + \" already exists\")\n            return None\n        else:\n            name = 'github2gitlab'\n            log.info(\"add \" + name + \" ssh public key from \" +\n                     self.args.ssh_public_key)\n            query['title'] = name\n            query['key'] = public_key\n            result = requests.post(url, query)\n            if result.status_code != requests.codes.created:\n                log.warn('Key {} already in GitLab. '\n                         'Possible under a different user. Skipping...'\n                         .format(self.args.ssh_public_key))\n            return public_key", "response": "Add ssh key to gitlab if necessary"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating project in gitlab if it does not exist", "response": "def add_project(self):\n        \"Create project in gitlab if it does not exist\"\n        g = self.gitlab\n        url = g['url'] + \"/projects/\" + g['repo']\n        query = {'private_token': g['token']}\n        if (requests.get(url, params=query).status_code == requests.codes.ok):\n            log.debug(\"project \" + url + \" already exists\")\n            return None\n        else:\n            log.info(\"add project \" + g['repo'])\n            url = g['url'] + \"/projects\"\n            query['public'] = 'true'\n            query['namespace'] = g['namespace']\n            query['name'] = g['name']\n            result = requests.post(url, params=query)\n            if result.status_code != requests.codes.created:\n                raise ValueError(result.text)\n            log.debug(\"project \" + g['repo'] + \" added: \" +\n                      result.text)\n            return result.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unprotect_branches(self):\n        \"Unprotect branches of the GitLab project\"\n        g = self.gitlab\n        url = g['url'] + \"/projects/\" + g['repo'] + \"/repository/branches\"\n        query = {'private_token': g['token']}\n        unprotected = 0\n        r = requests.get(url, params=query)\n        r.raise_for_status()\n        for branch in r.json():\n            if branch['protected']:\n                r = requests.put(url + \"/\" + branch['name'] +\n                                 \"/unprotect\", params=query)\n                r.raise_for_status()\n                unprotected += 1\n        return unprotected", "response": "Unprotect branches of the GitLab project"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json_loads(payload):\n        \"Log the payload that cannot be parsed\"\n        try:\n            return json.loads(payload)\n        except ValueError as e:\n            log.error(\"unable to json.loads(\" + payload + \")\")\n            raise e", "response": "Log the payload that cannot be parsed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pull_requests(self):\n        \"https://developer.github.com/v3/pulls/#list-pull-requests\"\n        g = self.github\n        query = {'state': 'all'}\n        if self.args.github_token:\n            query['access_token'] = g['token']\n\n        def f(pull):\n            if self.args.ignore_closed:\n                return (pull['state'] == 'opened' or\n                        (pull['state'] == 'closed' and pull['merged_at']))\n            else:\n                return True\n        pulls = filter(f,\n                       self.get(g['url'] + \"/repos/\" + g['repo'] + \"/pulls\",\n                                query, self.args.cache))\n        return dict([(str(pull['number']), pull) for pull in pulls])", "response": "Get all pull requests from github"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cropIndices(dims, lat, lon, depth=None, doy=None):\n    dims_out = {}\n    idx = {}\n    \n    yn = slice(\n            np.nonzero(dims['lat'] <= lat.min())[0].max(),\n            np.nonzero(dims['lat'] >= lat.max())[0].min() + 1)\n    dims_out['lat'] = np.atleast_1d(dims['lat'][yn])\n    idx['yn'] = yn\n\n    lon_ext = np.array(\n            (dims['lon'] - 2*360).tolist() +\n            (dims['lon'] - 360).tolist() +\n            dims['lon'].tolist() +\n            (dims['lon'] + 360).tolist())\n    xn_ext = list(4 * list(range(dims['lon'].shape[0])))\n    xn_start = np.nonzero(lon_ext <= lon.min())[0].max()\n    xn_end = np.nonzero(lon_ext >= lon.max())[0].min()\n    xn = xn_ext[xn_start:xn_end+1]\n    dims_out['lon'] = np.atleast_1d(lon_ext[xn_start:xn_end+1])\n    idx['xn'] = xn\n\n    if depth is not None:\n        zn = slice(\n                np.nonzero(dims['depth'] <= depth.min())[0].max(),\n                np.nonzero(dims['depth'] >= min(dims['depth'].max(), depth.max())\n                    )[0].min() + 1\n                                                        )\n        # If a higher degree interpolation system uses more than one data\n        #   point in the edge, I should extend this selection one point on\n        #   each side, without go beyond 0\n        # if zn.start < 0:\n        #    zn = slice(0, zn.stop, zn.step)\n        dims_out['depth'] = np.atleast_1d(dims['depth'][zn])\n        idx['zn'] = zn\n\n    if doy is not None:\n        # Source has only one time, like total mean field, or annual mean.\n        if dims['time'].shape == (1,):\n            dims_out['time'] = dims['time']\n            idx['tn'] = [0]\n        else:\n            time_ext = np.array(\n                    [dims['time'][-1] - 365.25] +\n                            dims['time'].tolist() +\n                            [dims['time'][0] + 365.25])\n            tn_ext = list(range(dims['time'].size))\n            tn_ext = [tn_ext[-1]] + tn_ext + [tn_ext[0]]\n            tn_start = np.nonzero(time_ext <= doy.min())[0].max()\n            tn_end = np.nonzero(time_ext >= doy.max())[0].min()\n            dims_out['time'] = np.atleast_1d(time_ext[tn_start:tn_end+1])\n            idx['tn'] = tn_ext[tn_start:tn_end+1]\n\n    return dims_out, idx", "response": "Returns the indices to crop the dataset with the given dimensions"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun SeqPrep parameters to assemble paired-end reads. -reads1_infile_path : reads1.fastq infile path -reads2_infile_path : reads2.fastq infile path -max_overlap_ascii_q_score : 'J' for Illumina 1.8+ phred+33, representing a score of 41. See: http://en.wikipedia.org/wiki/FASTQ_format -min_overlap : minimum overall base pair overlap to merge two reads -max_mismatch_good_frac : maximum fraction of good quality mismatching bases to overlap reads -min_frac_matching : minimum fraction of matching bases to overlap reads -phred_64 : if input is in phred+64. Output will always be phred+33. -params : other optional SeqPrep parameters NOTE: SeqPrep always outputs gzipped files", "response": "def join_paired_end_reads_seqprep(\n        reads1_infile_path,\n        reads2_infile_path,\n        outfile_label='seqprep',\n        max_overlap_ascii_q_score='J',\n        min_overlap=None,  # typical default vs 15\n        max_mismatch_good_frac=None,  # typical default is 0.02,\n        min_frac_matching=None,  # typical default is 0.9,\n        phred_64=False,\n        params={},\n        working_dir=tempfile.gettempdir(),\n        SuppressStderr=True,\n        SuppressStdout=True,\n        HALT_EXEC=False):\n    \"\"\" Runs SeqPrep parameters to assemble paired-end reads.\n        -reads1_infile_path : reads1.fastq infile path\n        -reads2_infile_path : reads2.fastq infile path\n        -max_overlap_ascii_q_score : 'J' for Illumina 1.8+ phred+33,\n                                    representing a score of 41. See:\n                                    http://en.wikipedia.org/wiki/FASTQ_format\n        -min_overlap : minimum overall base pair overlap to merge two reads\n        -max_mismatch_good_frac : maximum fraction of good quality mismatching\n                                  bases to overlap reads\n        -min_frac_matching : minimum fraction of matching bases to overlap\n                             reads\n        -phred_64 : if input is in phred+64. Output will always be phred+33.\n        -params : other optional SeqPrep parameters\n\n         NOTE: SeqPrep always outputs gzipped files\n    \"\"\"\n\n    abs_r1_path = os.path.abspath(reads1_infile_path)\n    abs_r2_path = os.path.abspath(reads2_infile_path)\n\n    infile_paths = [abs_r1_path, abs_r2_path]\n\n    # check / make absolute infile paths\n    for p in infile_paths:\n        if not os.path.exists(p):\n            raise IOError('Infile not found at: %s' % p)\n\n    # set up controller\n    seqprep_app = SeqPrep(params=params,\n                          WorkingDir=working_dir,\n                          SuppressStderr=SuppressStderr,\n                          SuppressStdout=SuppressStdout,\n                          HALT_EXEC=HALT_EXEC)\n\n    # required by SeqPrep to assemble:\n    seqprep_app.Parameters['-f'].on(abs_r1_path)\n    seqprep_app.Parameters['-r'].on(abs_r2_path)\n\n    if outfile_label is not None:\n        seqprep_app.Parameters['-s'].on(outfile_label + '_assembled.fastq.gz')\n        seqprep_app.Parameters[\n            '-1'].on(outfile_label + '_unassembled_R1.fastq.gz')\n        seqprep_app.Parameters[\n            '-2'].on(outfile_label + '_unassembled_R2.fastq.gz')\n    else:\n        raise ValueError(\"Must set an outfile_label in order to set\",\n                         \" the -s, -1, & -2 options!\")\n\n    if min_overlap is not None:\n        if isinstance(min_overlap, int) and min_overlap > 0:\n                seqprep_app.Parameters['-o'].on(min_overlap)\n        else:\n            raise ValueError(\"min_overlap must be an int >= 0!\")\n\n    if max_mismatch_good_frac is not None:\n        if isinstance(max_mismatch_good_frac, float) and 0.0 < max_mismatch_good_frac <= 1.0:\n            seqprep_app.Parameters['-m'].on(max_mismatch_good_frac)\n        else:\n            raise ValueError(\n                \"max_mismatch_good_frac must be a float between 0.0-1.0!\")\n\n    if min_frac_matching is not None:\n        if isinstance(min_frac_matching, float) and 0.0 < min_frac_matching <= 1.0:\n            seqprep_app.Parameters['-n'].on(min_frac_matching)\n        else:\n            raise ValueError(\n                \"min_frac_matching must be a float between 0.0-1.0!\")\n\n    if max_overlap_ascii_q_score is not None:\n        if isinstance(max_overlap_ascii_q_score, str) \\\n                and len(max_overlap_ascii_q_score) == 1:\n            seqprep_app.Parameters['-y'].on(max_overlap_ascii_q_score)\n        else:\n            raise ValueError(\"max_overlap_ascii_q_score must be a single\",\n                             \" ASCII character string. e.g. \\'J\\'!\")\n\n   # if input is phred+64\n    if phred_64 is True:\n        seqprep_app.Parameters['-6'].on()\n\n    # run assembler\n    result = seqprep_app()\n\n    # Store output file path data to dict\n    path_dict = {}\n    path_dict['Assembled'] = result['Assembled'].name\n    path_dict['UnassembledReads1'] = result['UnassembledReads1'].name\n    path_dict['UnassembledReads2'] = result['UnassembledReads2'].name\n\n   # sanity check that files actually exist in path lcoations\n    for path in path_dict.values():\n        if not os.path.exists(path):\n            raise IOError('Output file not found at: %s' % path)\n\n    return path_dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck file name is set for reads1 output. Returns absolute path.", "response": "def _unassembled_reads1_out_file_name(self):\n        \"\"\"Checks file name is set for reads1 output.\n           Returns absolute path.\"\"\"\n        if self.Parameters['-1'].isOn():\n            unassembled_reads1 = self._absolute(\n                str(self.Parameters['-1'].Value))\n        else:\n            raise ValueError(\"No reads1 (flag: -1) output path specified\")\n        return unassembled_reads1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _unassembled_reads2_out_file_name(self):\n        if self.Parameters['-2'].isOn():\n            unassembled_reads2 = self._absolute(\n                str(self.Parameters['-2'].Value))\n        else:\n            raise ValueError(\"No reads2 (flag -2) output path specified\")\n        return unassembled_reads2", "response": "Checks if file name is set for reads2 output.\n           Returns absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _discarded_reads1_out_file_name(self):\n        if self.Parameters['-3'].isOn():\n            discarded_reads1 = self._absolute(str(self.Parameters['-3'].Value))\n        else:\n            raise ValueError(\n                \"No discarded-reads1 (flag -3) output path specified\")\n        return discarded_reads1", "response": "Checks if file name is set for discarded reads1 output.\n           Returns absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if file name is set for discarded reads2 output. Returns absolute path.", "response": "def _discarded_reads2_out_file_name(self):\n        \"\"\"Checks if file name is set for discarded reads2 output.\n           Returns absolute path.\"\"\"\n        if self.Parameters['-4'].isOn():\n            discarded_reads2 = self._absolute(str(self.Parameters['-4'].Value))\n        else:\n            raise ValueError(\n                \"No discarded-reads2 (flag -4) output path specified\")\n        return discarded_reads2"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if file name is set for assembled output. Returns absolute path.", "response": "def _assembled_out_file_name(self):\n        \"\"\"Checks file name is set for assembled output.\n           Returns absolute path.\"\"\"\n        if self.Parameters['-s'].isOn():\n            assembled_reads = self._absolute(str(self.Parameters['-s'].Value))\n        else:\n            raise ValueError(\n                \"No assembled-reads (flag -s) output path specified\")\n        return assembled_reads"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking file name is set for pretty alignment output. Returns absolute path.", "response": "def _pretty_alignment_out_file_name(self):\n        \"\"\"Checks file name is set for pretty alignment output.\n           Returns absolute path.\"\"\"\n        if self.Parameters['-E'].isOn():\n            pretty_alignment = self._absolute(str(self.Parameters['-E'].Value))\n        else:\n            raise ValueError(\n                \"No pretty-=alignment (flag -E) output path specified\")\n        return pretty_alignment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the available files for all languages in a document.", "response": "def get_files_for_document(document):\n    \"\"\"\n    Returns the available files for all languages.\n\n    In case the file is already present in another language, it does not re-add\n    it again.\n\n    \"\"\"\n    files = []\n    for doc_trans in document.translations.all():\n        if doc_trans.filer_file is not None and \\\n                doc_trans.filer_file not in files:\n            doc_trans.filer_file.language = doc_trans.language_code\n            files.append(doc_trans.filer_file)\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the library favs that should be shown on the front page.", "response": "def get_frontpage_documents(context):\n    \"\"\"Returns the library favs that should be shown on the front page.\"\"\"\n    req = context.get('request')\n    qs = Document.objects.published(req).filter(is_on_front_page=True)\n    return qs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend a character to a list of components.", "response": "def append_comps(comps, char):\n    \"\"\"\n    Append a character to `comps` following this rule: a vowel is added to the\n    vowel part if there is no last consonant, else to the last consonant part;\n    a consonant is added to the first consonant part if there is no vowel, and\n    to the last consonant part if the vowel part is not empty.\n\n    >>> transform(['', '', ''])\n    ['c', '', '']\n    >>> transform(['c', '', ''], '+o')\n    ['c', 'o', '']\n    >>> transform(['c', 'o', ''], '+n')\n    ['c', 'o', 'n']\n    >>> transform(['c', 'o', 'n'], '+o')\n    ['c', 'o', 'no']\n    \"\"\"\n    c = list(comps)\n    if is_vowel(char):\n        if not c[2]: pos = 1\n        else: pos = 2\n    else:\n        if not c[2] and not c[1]: pos = 0\n        else: pos = 2\n    c[pos] += char\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef separate(string):\n    def atomic_separate(string, last_chars, last_is_vowel):\n        if string == \"\" or (last_is_vowel != is_vowel(string[-1])):\n            return (string, last_chars)\n        else:\n            return atomic_separate(string[:-1],\n                                   string[-1] + last_chars, last_is_vowel)\n\n    head, last_consonant = atomic_separate(string, \"\", False)\n    first_consonant, vowel = atomic_separate(head, \"\", True)\n\n    if last_consonant and not (vowel + first_consonant):\n        comps = [last_consonant, '', '']  # ['', '', b] -> ['b', '', '']\n    else:\n        comps = [first_consonant, vowel, last_consonant]\n\n    # 'gi' and 'qu' are considered qualified consonants.\n    # We want something like this:\n    #     ['g', 'ia', ''] -> ['gi', 'a', '']\n    #     ['q', 'ua', ''] -> ['qu', 'a', '']\n    if (comps[0] != '' and comps[1] != '') and \\\n        ((comps[0] in 'gG' and comps[1][0] in 'iI' and len(comps[1]) > 1) or\n         (comps[0] in 'qQ' and comps[1][0] in 'uU')):\n        comps[0] += comps[1][:1]\n        comps[1] = comps[1][1:]\n\n    return comps", "response": "Separate a string into smaller parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions that launches the Swarm de novo OTU picker and returns a list of lists of the Swarm - map file that contains the read sequence file.", "response": "def swarm_denovo_cluster(seq_path,\n                         d=1,\n                         threads=1,\n                         HALT_EXEC=False):\n    \"\"\" Function  : launch the Swarm de novo OTU picker\n\n        Parameters: seq_path, filepath to reads\n                    d, resolution\n                    threads, number of threads to use\n\n        Return    : clusters, list of lists\n    \"\"\"\n\n    # Check sequence file exists\n    if not exists(seq_path):\n        raise ValueError(\"%s does not exist\" % seq_path)\n\n    # Instantiate the object\n    swarm = Swarm(HALT_EXEC=HALT_EXEC)\n\n    # Set the resolution\n    if d > 0:\n        swarm.Parameters['-d'].on(d)\n    else:\n        raise ValueError(\"Resolution -d must be a positive integer.\")\n\n    # Set the number of threads\n    if threads > 0:\n        swarm.Parameters['-t'].on(threads)\n    else:\n        raise ValueError(\"Number of threads must be a positive integer.\")\n\n    # create temporary file for Swarm OTU-map\n    f, tmp_swarm_otumap = mkstemp(prefix='temp_otumap_',\n                                  suffix='.swarm')\n    close(f)\n\n    swarm.Parameters['-o'].on(tmp_swarm_otumap)\n\n    # Remove this file later, the final OTU-map\n    # is output by swarm_breaker.py and returned\n    # as a list of lists (clusters)\n    swarm.files_to_remove.append(tmp_swarm_otumap)\n\n    # Launch Swarm\n    # set the data string to include the read filepath\n    # (to be passed as final arguments in the swarm command)\n    clusters = swarm(seq_path)\n\n    remove_files(swarm.files_to_remove, error_on_missing=False)\n\n    # Return clusters\n    return clusters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninputting : seq_path, a filepath to de-replicated input FASTA reads Method: using swarm_breaker.py, break chains of amplicons based on abundance information. Abundance is stored after the final underscore '_' in each sequence label (recommended procedure for Swarm) Return: clusters, a list of lists", "response": "def _swarm_breaker(self,\n                       seq_path):\n        \"\"\"\n            Input : seq_path, a filepath to de-replicated\n                    input FASTA reads\n\n            Method: using swarm_breaker.py, break\n                    chains of amplicons based on\n                    abundance information. Abundance\n                    is stored after the final\n                    underscore '_' in each sequence\n                    label (recommended procedure for\n                    Swarm)\n\n            Return: clusters, a list of lists\n        \"\"\"\n        swarm_breaker_command = [\"swarm_breaker.py\",\n                                 \"-f\",\n                                 seq_path,\n                                 \"-s\",\n                                 self.Parameters['-o'].Value,\n                                 \"-d\",\n                                 str(self.Parameters['-d'].Value)]\n\n        try:\n            # launch swarm_breaker.py as a subprocess,\n            # pipe refined OTU-map to the standard stream\n            proc = Popen(swarm_breaker_command,\n                         stdout=PIPE,\n                         stderr=PIPE,\n                         close_fds=True)\n\n            stdout, stderr = proc.communicate()\n\n            if stderr:\n                raise StandardError(\"Process exited with %s\" % stderr)\n\n            # store refined clusters in list of lists\n            clusters = []\n            for line in stdout.split(linesep):\n                # skip line if contains only the newline character\n                if not line:\n                    break\n                seq_ids = re.split(\"\\t| \", line.strip())\n                # remove the abundance information from the labels\n                for i in range(len(seq_ids)):\n                    seq_ids[i] = seq_ids[i].rsplit(\"_\", 1)[0]\n                clusters.append(seq_ids)\n        except OSError:\n            raise ApplicationNotFoundError(\"Cannot find swarm_breaker.py \"\n                                           \"in the $PATH directories.\")\n\n        return clusters"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _apply_identical_sequences_prefilter(self,\n                                             seq_path):\n        \"\"\"\n            Input : seq_path, a filepath to input FASTA reads\n            Method: prepares and writes de-replicated reads\n                    to a temporary FASTA file, calls\n                    parent method to do the actual\n                    de-replication\n            Return: exact_match_id_map, a dictionary storing\n                    de-replicated amplicon ID as key and\n                    all original FASTA IDs with identical\n                    sequences as values;\n                    unique_seqs_fp, filepath to FASTA file\n                    holding only de-replicated sequences\n        \"\"\"\n        # creating mapping for de-replicated reads\n        seqs_to_cluster, exact_match_id_map =\\\n            self._prefilter_exact_matches(parse_fasta(seq_path))\n\n        # create temporary file for storing the de-replicated reads\n        fd, unique_seqs_fp = mkstemp(\n            prefix='SwarmExactMatchFilter', suffix='.fasta')\n        close(fd)\n\n        self.files_to_remove.append(unique_seqs_fp)\n\n        # write de-replicated reads to file\n        unique_seqs_f = open(unique_seqs_fp, 'w')\n        for seq_id, seq in seqs_to_cluster:\n            unique_seqs_f.write('>%s_%d\\n%s\\n'\n                                % (seq_id,\n                                   len(exact_match_id_map[seq_id]),\n                                   seq))\n        unique_seqs_f.close()\n\n        return exact_match_id_map, unique_seqs_fp", "response": "This method prepares and writes de - replicated reads to a temporary file and then applies the identical sequences prefilter to the actual sequence and returns the dictionary storing the original sequences as keys and the file to which the actual sequence is stored as values."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninputs clusters, a list of cluster lists filter_map, the seq_id in each clusters is the key to the filter_map containing all seq_ids with duplicate FASTA sequences Output: an extended list of cluster lists", "response": "def _map_filtered_clusters_to_full_clusters(self,\n                                                clusters,\n                                                filter_map):\n        \"\"\"\n            Input:  clusters, a list of cluster lists\n                    filter_map, the seq_id in each clusters\n                                is the key to the filter_map\n                                containing all seq_ids with\n                                duplicate FASTA sequences\n            Output: an extended list of cluster lists\n        \"\"\"\n        results = []\n        for cluster in clusters:\n            full_cluster = []\n            for seq_id in cluster:\n                full_cluster += filter_map[seq_id]\n            results.append(full_cluster)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the result paths for OTU map", "response": "def _get_result_paths(self, data):\n        \"\"\" Set the result paths\n        \"\"\"\n\n        # Swarm OTU map (mandatory output)\n        return {'OtuMap': ResultPath(Path=self.Parameters['-o'].Value,\n                                     IsWritten=True)}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconnect to the application s database.", "response": "def connect_to_database(host=None, port=None, connect=False, **kwargs):\n    \"\"\"\n    Explicitly begins a database connection for the application\n    (if this function is not called, a connection is created when\n    it is first needed).  Takes arguments identical to\n    pymongo.MongoClient.__init__\n    \n    @param host: the hostname to connect to\n    @param port: the port to connect to\n    @param connect:  if True, immediately begin connecting to MongoDB in the\n        background; otherwise connect on the first operation\n    \"\"\"\n    return CONNECTION.connect(host=host, port=port, connect=connect, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef authenticate_connection(username, password, db=None):\n    return CONNECTION.authenticate(username, password, db=db)", "response": "Authenticates the current database connection with the passed username and password."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a user to the database.", "response": "def add_user(name, password=None, read_only=None, db=None, **kwargs):\n    \"\"\"\n    Adds a user that can be used for authentication.\n    \n    @param name: the name of the user to create\n    @param passowrd: the password of the user to create. Can not be used with\n        the userSource argument.\n    @param read_only: if True the user will be read only\n    @param db: the database the user is authenticated to access.  Passing None\n        (the default) means add the user to the admin database, which gives the\n        user access to all databases\n    @param **kwargs: forwarded to pymongo.database.add_user\n    \n    Example; adding a user with full database access:\n        add_user(\"username\", \"password\")\n    \n    Example; adding a user with read only privilage on a partiucalr database:\n        add_user(\"username\", \"password\", read_only=True, db=\"somedb\")\n    \n    NOTE: This function will only work if mongo is being run unauthenticated\n    or you have already authenticated with another user with appropriate\n    privileges to add a user to the specified database.\n    \"\"\"\n    return CONNECTION.add_user(name, password=password, read_only=read_only, db=db, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_superuser(name, password, **kwargs):\n    return CONNECTION.add_user(\n            name, password=password,\n            roles=[\"userAdminAnyDatabase\", \"readWriteAnyDatabase\", \"root\", \"backup\", \"restore\"], **kwargs\n    )", "response": "Adds a user with userAdminAnyDatabase role to the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting the names of the databases on the machine or collections of a particular database.", "response": "def list_database(db=None):\n    \"\"\"\n    Lists the names of either the databases on the machine or the collections\n    of a particular database\n    \n    @param db: the database for which to list the collection names;\n        if db is None, then it lists all databases instead\n        the contents of the database with the name passed in db\n    \"\"\"\n    if db is None:\n        return CONNECTION.get_connection().database_names()\n    return CONNECTION.get_connection()[db].collection_names()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef authenticate(self, username, password, db=None):\n        if db is None:\n            return self.get_connection().admin.authenticate(username, password)\n        return self.get_connection()[db].authenticate(username, password)", "response": "Authenticates the MongoClient with the passed username and password"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a user that can be used for authentication", "response": "def add_user(self, name, password=None, read_only=None, db=None, **kwargs):\n        \"\"\" Adds a user that can be used for authentication \"\"\"\n        if db is None:\n            return self.get_connection().admin.add_user(\n                    name, password=password, read_only=read_only, **kwargs)\n        return self.get_connection()[db].add_user(\n                    name, password=password, read_only=read_only, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction which returns a metrique object.", "response": "def metrique_object(_oid, _id=None, _hash=None, _start=None, _end=None,\n                    _e=None, _v=None, id=None, __v__=None, **kwargs):\n    '''\n    Function which takes a dictionary (Mapping) object as input\n    and returns return back a metrique object.\n\n    Special meta property are added to each object::\n        _oid: ...\n        _start: ...\n        ...\n        FIXME\n    '''\n    # NOTE: we completely ignore incoming 'id' keys!\n    # id is RESERVED and ALWAYS expected to be 'autoincrement'\n    # upon insertion into DB (though, its optional, depending\n    # on backend storage behaivor).\n    if id:\n        warnings.warn('non-null \"id\" keys detected, ignoring them!')\n\n    _e = dict(_e or {})  # expecting a dict with copy() atr\n    _v = int(_v or 0)\n\n    if not isinstance(_start, float):\n        _start = dt2ts(_start) if _start else utcnow(as_datetime=False)\n    assert _start is not None, \"_start (%s) must be set!\" % _start\n\n    if not isinstance(_end, float):\n        _end = dt2ts(_end) if _end else None\n\n    _err_msg = \"_end(%s) must be >= _start(%s) or None!\" % (_end, _start)\n    assert _end is None or bool(_end >= _start), _err_msg\n\n    # these meta fields are used to generate unique object _hash\n    kwargs['_oid'] = _oid\n    kwargs['_v'] = _v\n    kwargs['_id'] = gen_id(_oid, _start, _end)  # ignore passed in _id\n    # generate unique, consistent object _hash based on 'frozen' obj contents\n    # FIXME: make _hash == None valid\n    #kwargs['_hash'] = jsonhash(kwargs) if _hash else None\n    kwargs['_hash'] = jsonhash(kwargs)\n\n    # add some additional non-hashable meta data\n    kwargs['_start'] = _start\n    kwargs['_end'] = _end\n    kwargs['__v__'] = __v__ or __version__\n    kwargs['_e'] = _e\n    return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_variants(self, key, value, schema):\n        ''' also possible to define some function that takes\n            current value and creates a new value from it\n        '''\n        variants = schema.get('variants')\n        obj = {}\n        if variants:\n            for _key, func in variants.iteritems():\n                _value = func(value, self.store)\n                obj.update({_key: _value})\n        return obj", "response": "add variants to the object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies type to all values in the list '", "response": "def _type_container(self, value, _type):\n        ' apply type to all values in the list '\n        if value is None:\n            # normalize null containers to empty list\n            return []\n        elif not isinstance(value, list):\n            raise ValueError(\"expected list type, got: %s\" % type(value))\n        else:\n            return sorted(self._type_single(item, _type) for item in value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _type_single(self, value, _type):\n        ' apply type to the single value '\n        if value is None or _type in (None, NoneType):\n            # don't convert null values\n            # default type is the original type if none set\n            pass\n        elif isinstance(value, _type):  # or values already of correct type\n            # normalize all dates to epochs\n            value = dt2ts(value) if _type in [datetime, date] else value\n        else:\n            if _type in (datetime, date):\n                # normalize all dates to epochs\n                value = dt2ts(value)\n            elif _type in (unicode, str):\n                # make sure all string types are properly unicoded\n                value = to_encoding(value)\n            else:\n                try:\n                    value = _type(value)\n                except Exception:\n                    value = to_encoding(value)\n                    logger.error(\"typecast failed: %s(value=%s)\" % (\n                        _type.__name__, value))\n                    raise\n        return value", "response": "apply type to the single value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flush(self, objects=None, batch_size=None, **kwargs):\n        ''' flush objects stored in self.container or those passed in'''\n        batch_size = batch_size or self.config.get('batch_size')\n        # if we're flushing these from self.store, we'll want to\n        # pop them later.\n        if objects:\n            from_store = False\n        else:\n            from_store = True\n            objects = self.itervalues()\n        # sort by _oid for grouping by _oid below\n        objects = sorted(objects, key=lambda x: x['_oid'])\n        batch, _ids = [], []\n        # batch in groups with _oid, since upsert's delete\n        # all _oid rows when autosnap=False!\n        for key, group in groupby(objects, lambda x: x['_oid']):\n            _grouped = list(group)\n            if len(batch) + len(_grouped) > batch_size:\n                logger.debug(\"Upserting %s objects\" % len(batch))\n                _ = self.upsert(objects=batch, **kwargs)\n                logger.debug(\"... done upserting %s objects\" % len(batch))\n                _ids.extend(_)\n                # start a new batch\n                batch = _grouped\n            else:\n                # extend existing batch, since still will be < batch_size\n                batch.extend(_grouped)\n        else:\n            if batch:\n                # get the last batch too\n                logger.debug(\"Upserting last batch of %s objects\" % len(batch))\n                _ = self.upsert(objects=batch, **kwargs)\n                _ids.extend(_)\n            logger.debug(\"... Finished upserting all objects!\")\n\n        if from_store:\n            for _id in _ids:\n                # try to pop the _id's flushed from store; warn / ignore\n                # the KeyError if they're not there\n                try:\n                    self.store.pop(_id)\n                except KeyError:\n                    logger.warn(\n                        \"failed to pop {} from self.store!\".format(_id))\n        return sorted(_ids)", "response": "flush objects stored in self. container or those passed in"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count(self, query=None, date=None):\n        '''\n        Run a query on the given cube and return only\n        the count of resulting matches.\n\n        :param query: The query in pql\n        :param date: date (metrique date range) that should be queried\n                    If date==None then the most recent versions of the\n                    objects will be queried.\n        :param collection: cube name\n        :param owner: username of cube owner\n        '''\n        return self.proxy.count(table=self.name, query=query, date=date)", "response": "Run a query on the given cube and return only\n        the count of resulting matches."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a new index on a cube.", "response": "def index(self, fields, name=None, **kwargs):\n        '''\n        Build a new index on a cube.\n\n        Examples:\n            + index('field_name')\n\n        :param fields: A single field or a list of (key, direction) pairs\n        :param name: (optional) Custom name to use for this index\n        :param collection: cube name\n        :param owner: username of cube owner\n        '''\n        return self.proxy.index(fields=fields, name=name, table=self.name,\n                                **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef share(self, with_user, roles=None):\n        '''\n        Give cube access rights to another user\n        '''\n        return self.proxy.share(table=self.name, with_user=with_user,\n                                roles=roles)", "response": "Share this cube with another user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_database_sortmerna(fasta_path,\n                             max_pos=None,\n                             output_dir=None,\n                             temp_dir=tempfile.gettempdir(),\n                             HALT_EXEC=False):\n    \"\"\" Build sortmerna db from fasta_path; return db name\n        and list of files created\n\n        Parameters\n        ----------\n        fasta_path : string\n            path to fasta file of sequences to build database.\n        max_pos : integer, optional\n            maximum positions to store per seed in index\n            [default: 10000].\n        output_dir : string, optional\n            directory where output should be written\n            [default: same directory as fasta_path]\n        HALT_EXEC : boolean, optional\n            halt just before running the indexdb_rna command\n            and print the command -- useful for debugging\n            [default: False].\n\n        Return\n        ------\n        db_name : string\n            filepath to indexed database.\n        db_filepaths : list\n            output files by indexdb_rna\n    \"\"\"\n\n    if fasta_path is None:\n        raise ValueError(\"Error: path to fasta reference \"\n                         \"sequences must exist.\")\n\n    fasta_dir, fasta_filename = split(fasta_path)\n    if not output_dir:\n        output_dir = fasta_dir or '.'\n        # Will cd to this directory, so just pass the filename\n        # so the app is not confused by relative paths\n        fasta_path = fasta_filename\n\n    index_basename = splitext(fasta_filename)[0]\n\n    db_name = join(output_dir, index_basename)\n\n    # Instantiate the object\n    sdb = IndexDB(WorkingDir=output_dir, HALT_EXEC=HALT_EXEC)\n\n    # The parameter --ref STRING must follow the format where\n    # STRING = /path/to/ref.fasta,/path/to/ref.idx\n    sdb.Parameters['--ref'].on(\"%s,%s\" % (fasta_path, db_name))\n\n    # Set temporary directory\n    sdb.Parameters['--tmpdir'].on(temp_dir)\n\n    # Override --max_pos parameter\n    if max_pos is not None:\n        sdb.Parameters['--max_pos'].on(max_pos)\n\n    # Run indexdb_rna\n    app_result = sdb()\n\n    # Return all output files (by indexdb_rna) as a list,\n    # first however remove the StdErr and StdOut filepaths\n    # as they files will be destroyed at the exit from\n    # this function (IndexDB is a local instance)\n    db_filepaths = [v.name for k, v in app_result.items()\n                    if k not in {'StdErr', 'StdOut'} and hasattr(v, 'name')]\n\n    return db_name, db_filepaths", "response": "Build sortmerna database from a fasta file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlaunches sortmerna OTU picker and return a dict of OTU ids and reads mapping to those OTU ids.", "response": "def sortmerna_ref_cluster(seq_path=None,\n                          sortmerna_db=None,\n                          refseqs_fp=None,\n                          result_path=None,\n                          tabular=False,\n                          max_e_value=1,\n                          similarity=0.97,\n                          coverage=0.97,\n                          threads=1,\n                          best=1,\n                          HALT_EXEC=False\n                          ):\n    \"\"\"Launch sortmerna OTU picker\n\n        Parameters\n        ----------\n        seq_path : str\n            filepath to query sequences.\n        sortmerna_db : str\n            indexed reference database.\n        refseqs_fp : str\n            filepath of reference sequences.\n        result_path : str\n            filepath to output OTU map.\n        max_e_value : float, optional\n            E-value threshold [default: 1].\n        similarity : float, optional\n            similarity %id threshold [default: 0.97].\n        coverage : float, optional\n            query coverage % threshold [default: 0.97].\n        threads : int, optional\n            number of threads to use (OpenMP) [default: 1].\n        tabular : bool, optional\n            output BLAST tabular alignments [default: False].\n        best : int, optional\n            number of best alignments to output per read\n            [default: 1].\n\n        Returns\n        -------\n        clusters : dict of lists\n            OTU ids and reads mapping to them\n\n        failures : list\n            reads which did not align\n    \"\"\"\n\n    # Instantiate the object\n    smr = Sortmerna(HALT_EXEC=HALT_EXEC)\n\n    # Set input query sequences path\n    if seq_path is not None:\n        smr.Parameters['--reads'].on(seq_path)\n    else:\n        raise ValueError(\"Error: a read file is mandatory input.\")\n\n    # Set the input reference sequence + indexed database path\n    if sortmerna_db is not None:\n        smr.Parameters['--ref'].on(\"%s,%s\" % (refseqs_fp, sortmerna_db))\n    else:\n        raise ValueError(\"Error: an indexed database for reference set %s must\"\n                         \" already exist.\\nUse indexdb_rna to index the\"\n                         \" database.\" % refseqs_fp)\n\n    if result_path is None:\n        raise ValueError(\"Error: the result path must be set.\")\n\n    # Set output results path (for Blast alignments, clusters and failures)\n    output_dir = dirname(result_path)\n    if output_dir is not None:\n        output_file = join(output_dir, \"sortmerna_otus\")\n        smr.Parameters['--aligned'].on(output_file)\n\n    # Set E-value threshold\n    if max_e_value is not None:\n        smr.Parameters['-e'].on(max_e_value)\n\n    # Set similarity threshold\n    if similarity is not None:\n        smr.Parameters['--id'].on(similarity)\n\n    # Set query coverage threshold\n    if coverage is not None:\n        smr.Parameters['--coverage'].on(coverage)\n\n    # Set number of best alignments to output\n    if best is not None:\n        smr.Parameters['--best'].on(best)\n\n    # Set Blast tabular output\n    # The option --blast 3 represents an\n    # m8 blast tabular output + two extra\n    # columns containing the CIGAR string\n    # and the query coverage\n    if tabular:\n        smr.Parameters['--blast'].on(\"3\")\n\n    # Set number of threads\n    if threads is not None:\n        smr.Parameters['-a'].on(threads)\n\n    # Run sortmerna\n    app_result = smr()\n\n    # Put clusters into a map of lists\n    f_otumap = app_result['OtuMap']\n    rows = (line.strip().split('\\t') for line in f_otumap)\n    clusters = {r[0]: r[1:] for r in rows}\n\n    # Put failures into a list\n    f_failure = app_result['FastaForDenovo']\n    failures = [re.split('>| ', label)[0]\n                for label, seq in parse_fasta(f_failure)]\n\n    # remove the aligned FASTA file and failures FASTA file\n    # (currently these are re-constructed using pick_rep_set.py\n    # further in the OTU-picking pipeline)\n    smr_files_to_remove = [app_result['FastaForDenovo'].name,\n                           app_result['FastaMatches'].name,\n                           app_result['OtuMap'].name]\n\n    return clusters, failures, smr_files_to_remove"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds the dict of result filepaths that are used by the user to access the database.", "response": "def _get_result_paths(self, data):\n        \"\"\" Build the dict of result filepaths\n        \"\"\"\n        # get the filepath of the indexed database (after comma)\n        # /path/to/refseqs.fasta,/path/to/refseqs.idx\n        #                        ^------------------^\n        db_name = (self.Parameters['--ref'].Value).split(',')[1]\n\n        result = {}\n        extensions = ['bursttrie', 'kmer', 'pos', 'stats']\n        for extension in extensions:\n            for file_path in glob(\"%s.%s*\" % (db_name, extension)):\n                # this will match e.g. nr.bursttrie_0.dat, nr.bursttrie_1.dat\n                # and nr.stats\n                key = file_path.split(db_name + '.')[1]\n                result[key] = ResultPath(Path=file_path, IsWritten=True)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_result_paths(self, data):\n\n        result = {}\n\n        # get the file extension of the reads file (sortmerna\n        # internally outputs all results with this extension)\n        fileExtension = splitext(self.Parameters['--reads'].Value)[1]\n\n        # at this point the parameter --aligned should be set as\n        # sortmerna will not run without it\n        if self.Parameters['--aligned'].isOff():\n            raise ValueError(\"Error: the --aligned parameter must be set.\")\n\n        # file base name for aligned reads\n        output_base = self.Parameters['--aligned'].Value\n\n        # Blast alignments\n        result['BlastAlignments'] =\\\n            ResultPath(Path=output_base + '.blast',\n                       IsWritten=self.Parameters['--blast'].isOn())\n\n        # SAM alignments\n        result['SAMAlignments'] =\\\n            ResultPath(Path=output_base + '.sam',\n                       IsWritten=self.Parameters['--sam'].isOn())\n\n        # OTU map (mandatory output)\n        result['OtuMap'] =\\\n            ResultPath(Path=output_base + '_otus.txt',\n                       IsWritten=self.Parameters['--otu_map'].isOn())\n\n        # FASTA file of sequences in the OTU map (madatory output)\n        result['FastaMatches'] =\\\n            ResultPath(Path=output_base + fileExtension,\n                       IsWritten=self.Parameters['--fastx'].isOn())\n\n        # FASTA file of sequences not in the OTU map (mandatory output)\n        result['FastaForDenovo'] =\\\n            ResultPath(Path=output_base + '_denovo' +\n                       fileExtension,\n                       IsWritten=self.Parameters['--de_novo_otu'].isOn())\n        # Log file\n        result['LogFile'] =\\\n            ResultPath(Path=output_base + '.log',\n                       IsWritten=self.Parameters['--log'].isOn())\n\n        return result", "response": "Get the result paths for the current sortmerna instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a color to use.", "response": "def get_color(self, color):\n        '''\n        Returns a color to use.\n\n        :param integer/string color:\n            Color for the plot. Can be an index for the color from COLORS\n            or a key(string) from CNAMES.\n        '''\n        if color is None:\n            color = self.counter\n        if isinstance(color, str):\n            color = CNAMES[color]\n        self.counter = color + 1\n        color %= len(COLORS)\n        return color"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot(self, series, label='', color=None, style=None):\n        '''\n        Wrapper around plot.\n\n        :param pandas.Series series:\n            The series to be plotted, all values must be positive if stacked\n            is True.\n        :param string label:\n            The label for the series.\n        :param integer/string color:\n            Color for the plot. Can be an index for the color from COLORS\n            or a key(string) from CNAMES.\n        :param string style:\n            Style forwarded to the plt.plot.\n        '''\n        color = self.get_color(color)\n        if self.stacked:\n            series += self.running_sum\n            plt.fill_between(series.index, self.running_sum, series,\n                             facecolor=ALPHAS[color])\n            self.running_sum = series\n            plt.gca().set_ylim(bottom=0, top=int(series.max() * 1.05))\n        series.plot(label=label, c=COLORS[color], linewidth=2, style=style)", "response": "Wrapper around plot.\n\n        :param pandas.Series series:\n            The series to be plotted, all values must be positive if stacked\n            is True.\n        :param string label:\n            The label for the series.\n        :param integer/string color:\n            Color for the plot. Can be an index for the color from COLORS\n            or a key(string) from CNAMES.\n        :param string style:\n            Style forwarded to the plt.plot."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plots(self, series_list, label_list, colors=None):\n        '''\n        Plots all the series from the list.\n        The assumption is that all of the series share the same index.\n\n        :param list series_list:\n            A list of series which should be plotted\n        :param list label_list:\n            A list of labels corresponding to the series\n        :params list list_of_colors:\n            A list of colors to use.\n        '''\n        colors = colors or range(len(series_list))\n        for series, label, color in zip(series_list, label_list, colors):\n            self.plot(series=series, label=label, color=color)", "response": "Plots all the series from the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef line(self, x, label=None, y='bottom', color='grey', ax=None, **kwargs):\n        '''\n        Creates a vertical line in the plot.\n\n        :param x:\n            The x coordinate of the line. Should be in the same units\n            as the x-axis.\n        :param string label:\n            The label to be displayed.\n        :param y:\n            May be 'top', 'bottom' or int.\n            The y coordinate of the text-label.\n        :param color color:\n            The color of the line.\n        '''\n        if ax is None:\n            ax = plt\n            y0, y1 = ax.ylim()\n        else:\n            y0, y1 = ax.get_ylim()\n        ax.axvline(x, color=color, **kwargs)\n        if label is not None:\n            verticalalignment = 'bottom'\n            if y == 'bottom':\n                y = y0 + (y1 - y0) / 25.\n            if y == 'top':\n                verticalalignment = 'top'\n                y = y0 + (y1 - y0) * 24 / 25.\n            ax.annotate('\\n' + label, (x, y), rotation=90,\n                        verticalalignment=verticalalignment)", "response": "Creates a vertical line in the plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates vertical lines in the plot.", "response": "def lines(self, lines_dict, y='bottom', color='grey', **kwargs):\n        '''\n        Creates vertical lines in the plot.\n\n        :param lines_dict:\n            A dictionary of label, x-coordinate pairs.\n        :param y:\n            May be 'top', 'bottom' or int.\n            The y coordinate of the text-labels.\n        :param color color:\n            The color of the lines.\n        '''\n        for l, x in lines_dict.items():\n            self.line(x, l, y, color, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot(self, series, series_diff=None, label='', color=None, style=None):\n        '''\n        :param pandas.Series series:\n            The series to be plotted, all values must be positive if stacked\n            is True.\n        :param pandas.Series series_diff:\n            The series representing the diff that will be plotted in the\n            bottom part.\n        :param string label:\n            The label for the series.\n        :param integer/string color:\n            Color for the plot. Can be an index for the color from COLORS\n            or a key(string) from CNAMES.\n        :param string style:\n            Style forwarded to the plt.plot.\n        '''\n        color = self.get_color(color)\n        if series_diff is None and self.autodiffs:\n            series_diff = series.diff()\n        if self.stacked:\n            series += self.running_sum\n            self.ax1.fill_between(series.index, self.running_sum, series,\n                                  facecolor=ALPHAS[color])\n            self.running_sum = series\n            self.ax1.set_ylim(bottom=0, top=int(series.max() * 1.05))\n        series.plot(label=label, c=COLORS[color], linewidth=2, style=style,\n                    ax=self.ax1)\n        if series_diff is not None:\n            series_diff.plot(label=label, c=COLORS[color], linewidth=2,\n                             style=style, ax=self.ax2)", "response": "Plots the series and the diff."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a vertical line in the plot.", "response": "def line(self, x, label=None, y='bottom', color='grey', **kwargs):\n        '''\n        Creates a vertical line in the plot.\n\n        :param x:\n            The x coordinate of the line. Should be in the same units\n            as the x-axis.\n        :param string label:\n            The label to be displayed.\n        :param y:\n            May be 'top', 'bottom' or int.\n            The y coordinate of the text-label.\n        :param color color:\n            The color of the line.\n        '''\n        super(DiffPlotter, self).line(x, label, y, color, self.ax1, **kwargs)\n        super(DiffPlotter, self).line(x, '', 0, color, self.ax2, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef published(self, request=None):\n        language = getattr(request, 'LANGUAGE_CODE', get_language())\n        if not language:\n            return self.model.objects.none()\n\n        qs = self.get_queryset()\n        qs = qs.filter(\n            translations__is_published=True,\n            translations__language_code=language,\n        )\n        # either it has no category or the one it has is published\n        qs = qs.filter(\n            models.Q(category__isnull=True) |\n            models.Q(category__is_published=True))\n        return qs", "response": "Returns the published documents in the current language."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _format(self):\n        self.log.debug(\"Formatting URLs to request\")\n        items = list()\n        for i in range(0, self.limit, 10):\n            query = '\"%s\" %s' % (self.domain, self.modifier)\n            url = self.host + \"/search?q=\" + query + \"&first=\" + str(i)\n            items.append(url)\n        self.log.debug(\"URLs were generated\")\n        return items", "response": "Format search queries to perform in bulk."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process(self, responses):\n        self.log.debug(\"Processing search results\")\n        items = list()\n        for response in responses:\n            try:\n                soup = BeautifulSoup(response.content, 'html.parser',\n                                     from_encoding=\"iso-8859-1\")\n            except:\n                continue\n            else:\n                listings = soup.findAll('li', {'class': 'b_algo'})\n                items.extend([l.find('a')['href'] for l in listings])\n        self.log.debug(\"Search result URLs were extracted\")\n        return items", "response": "Process search engine results for detailed analysis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform bulk collection of data and return the content.", "response": "def _fetch(self, urls):\n        \"\"\"Perform bulk collection of data and return the content.\n\n        Gathering responses is handled by the base class and uses futures to\n        speed up the processing. Response data is saved inside a local variable\n        to be used later in extraction.\n        \"\"\"\n        responses = self._request_bulk(urls)\n        for response in responses:\n            try:\n                soup = BeautifulSoup(response.content, 'html.parser',\n                                     from_encoding=\"iso-8859-1\")\n                text = soup.get_text()\n            except Exception:\n                text = response.text\n            self.data.append(text) # Opportunistic findings\n        return responses"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract email addresses from all crawled pages.", "response": "def _extract(self):\n        \"\"\"Extract email addresses from results.\n\n        Text content from all crawled pages are ran through a simple email\n        extractor. Data is cleaned prior to running pattern expressions.\n        \"\"\"\n        self.log.debug(\"Extracting emails from text content\")\n        for item in self.data:\n            emails = extract_emails(item, self.domain, self.fuzzy)\n            self.results.extend(emails)\n        self.log.debug(\"Email extraction completed\")\n        return list(set(self.results))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the full search process.", "response": "def search(self):\n        \"\"\"Run the full search process.\n\n        Simple public method to abstract the steps needed to produce a full\n        search using the engine.\n        \"\"\"\n        requests = self._format()\n        serps = self._fetch(requests)\n        urls = self._process(serps)\n        details = self._fetch(urls)\n        emails = self._extract()\n        return {'emails': emails, 'processed': len(self.data)}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef which(executable_name, env_var='PATH'):\n    exec_fp = None\n\n    if env_var in os.environ:\n        paths = os.environ[env_var]\n\n        for path in paths.split(os.pathsep):\n            curr_exec_fp = os.path.join(path, executable_name)\n\n            if os.access(curr_exec_fp, os.X_OK):\n                exec_fp = curr_exec_fp\n                break\n\n    return exec_fp", "response": "Equivalent to which in a nix environment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating command lines that can be used in a cluster environment.", "response": "def cmdline_generator(param_iter, PathToBin=None, PathToCmd=None,\n                      PathsToInputs=None, PathToOutput=None,\n                      PathToStderr='/dev/null', PathToStdout='/dev/null',\n                      UniqueOutputs=False, InputParam=None,\n                      OutputParam=None):\n    \"\"\"Generates command lines that can be used in a cluster environment\n\n    param_iter : ParameterIterBase subclass instance\n    PathToBin : Absolute location primary command (i.e. Python)\n    PathToCmd : Absolute location of the command\n    PathsToInputs : Absolute location(s) of input file(s)\n    PathToOutput : Absolute location of output file\n    PathToStderr : Path to stderr\n    PathToStdout : Path to stdout\n    UniqueOutputs : Generate unique tags for output files\n    InputParam : Application input parameter (if not specified, assumes\n        stdin is to be used)\n    OutputParam : Application output parameter (if not specified, assumes\n        stdout is to be used)\n    \"\"\"\n    # Make sure we have input(s) and output\n    if not PathsToInputs:\n        raise ValueError(\"No input file(s) specified.\")\n    if not PathToOutput:\n        raise ValueError(\"No output file specified.\")\n\n    if not isinstance(PathsToInputs, list):\n        PathsToInputs = [PathsToInputs]\n\n    # PathToBin and PathToCmd can be blank\n    if PathToBin is None:\n        PathToBin = ''\n    if PathToCmd is None:\n        PathToCmd = ''\n\n    # stdout_ and stderr_ do not have to be redirected\n    if PathToStdout is None:\n        stdout_ = ''\n    else:\n        stdout_ = '> \"%s\"' % PathToStdout\n    if PathToStderr is None:\n        stderr_ = ''\n    else:\n        stderr_ = '2> \"%s\"' % PathToStderr\n\n    # Output can be redirected to stdout or specified output argument\n    if OutputParam is None:\n        output = '> \"%s\"' % PathToOutput\n        stdout_ = ''\n    else:\n        output_param = param_iter.AppParams[OutputParam]\n        output_param.on('\"%s\"' % PathToOutput)\n        output = str(output_param)\n        output_param.off()\n\n    output_count = 0\n    base_command = ' '.join([PathToBin, PathToCmd])\n    for params in param_iter:\n        # Support for multiple input files\n        for inputfile in PathsToInputs:\n            cmdline = [base_command]\n            cmdline.extend(sorted(filter(None, map(str, params.values()))))\n\n            # Input can come from stdin or specified input argument\n            if InputParam is None:\n                input = '< \"%s\"' % inputfile\n            else:\n                input_param = params[InputParam]\n                input_param.on('\"%s\"' % inputfile)\n                input = str(input_param)\n                input_param.off()\n\n            cmdline.append(input)\n\n            if UniqueOutputs:\n                cmdline.append(''.join([output, str(output_count)]))\n                output_count += 1\n            else:\n                cmdline.append(output)\n\n            cmdline.append(stdout_)\n            cmdline.append(stderr_)\n\n            yield ' '.join(cmdline)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tmp_filename(tmp_dir=gettempdir(), prefix=\"tmp\", suffix=\".txt\",\n                     result_constructor=FilePath):\n    \"\"\" Generate a temporary filename and return as a FilePath object\n\n        tmp_dir: the directory to house the tmp_filename\n        prefix: string to append to beginning of filename\n            Note: It is very useful to have prefix be descriptive of the\n            process which is creating the temporary file. For example, if\n            your temp file will be used to build a temporary blast database,\n            you might pass prefix=TempBlastDB\n        suffix: the suffix to be appended to the temp filename\n        result_constructor: the constructor used to build the result filename\n            (default: cogent.app.parameters.FilePath). Note that joining\n            FilePath objects with one another or with strings, you must use\n            the + operator. If this causes trouble, you can pass str as the\n            the result_constructor.\n    \"\"\"\n    # check not none\n    if not tmp_dir:\n        tmp_dir = \"\"\n    # if not current directory, append \"/\" if not already on path\n    elif not tmp_dir.endswith(\"/\"):\n        tmp_dir += \"/\"\n\n    chars = \"abcdefghigklmnopqrstuvwxyz\"\n    picks = chars + chars.upper() + \"0123456790\"\n    return result_constructor(tmp_dir) + result_constructor(prefix) +\\\n        result_constructor(\"%s%s\" %\n                           (''.join([choice(picks) for i in range(20)]),\n                            suffix))", "response": "Generate a temporary filename and return it as a FilePath object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the name of the input handler for seqs.", "response": "def guess_input_handler(seqs, add_seq_names=False):\n    \"\"\"Returns the name of the input handler for seqs.\"\"\"\n    if isinstance(seqs, str):\n        if '\\n' in seqs:  # can't be a filename...\n            return '_input_as_multiline_string'\n        else:  # assume it was a filename\n            return '_input_as_string'\n\n    if isinstance(seqs, list) and len(seqs) and isinstance(seqs[0], tuple):\n        return '_input_as_seq_id_seq_pairs'\n\n    if add_seq_names:\n        return '_input_as_seqs'\n\n    return '_input_as_lines'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cleanUp(self):\n        file_keys = self.file_keys\n        for item in file_keys:\n            if self[item] is not None:\n                self[item].close()\n                remove(self[item].name)\n\n        # remove input handler temp files\n        if hasattr(self, \"_input_filename\"):\n            remove(self._input_filename)", "response": "Delete all files that are written by CommandLineApplication from disk\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _input_as_multiline_string(self, data):\n        filename = self._input_filename = \\\n            FilePath(self.getTmpFilename(self.TmpDir))\n        data_file = open(filename, 'w')\n        data_file.write(data)\n        data_file.close()\n        return filename", "response": "Write a multiline string to a temp file and return the filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _input_as_lines(self, data):\n        filename = self._input_filename = \\\n            FilePath(self.getTmpFilename(self.TmpDir))\n        filename = FilePath(filename)\n        data_file = open(filename, 'w')\n        data_to_file = '\\n'.join([str(d).strip('\\n') for d in data])\n        data_file.write(data_to_file)\n        data_file.close()\n        return filename", "response": "Write a sequence of lines to a temp file and return the filename"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _input_as_paths(self, data):\n        return self._command_delimiter.join(\n            map(str, map(self._input_as_path, data)))", "response": "Return data as a space delimited string with each path quoted\n\n            data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a filename to an absolute path", "response": "def _absolute(self, path):\n        \"\"\" Convert a filename to an absolute path \"\"\"\n        path = FilePath(path)\n        if isabs(path):\n            return path\n        else:\n            # these are both Path objects, so joining with + is acceptable\n            return self.WorkingDir + path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _error_on_missing_application(self, params):\n        command = self._command\n        # strip off \" characters, in case we got a FilePath object\n        found_in_path = which(command.strip('\"')) is not None\n        if not (exists(command) or found_in_path):\n            raise ApplicationNotFoundError(\"Cannot find %s. Is it installed? \"\n                                           \"Is it in your path?\" % command)", "response": "Raise an ApplicationNotFoundError if the application is not available."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getTmpFilename(self, tmp_dir=None, prefix='tmp', suffix='.txt',\n                       include_class_id=False, result_constructor=FilePath):\n        \"\"\" Return a temp filename\n\n            tmp_dir: directory where temporary files will be stored\n            prefix: text to append to start of file name\n            suffix: text to append to end of file name\n            include_class_id: if True, will append a class identifier (built\n             from the class name) to the filename following prefix. This is\n             False by default b/c there is some string processing overhead\n             in getting the class name. This will probably be most useful for\n             testing: if temp files are being left behind by tests, you can\n             turn this on in here (temporarily) to find out which tests are\n             leaving the temp files.\n            result_constructor: the constructor used to build the result\n             (default: cogent.app.parameters.FilePath). Note that joining\n             FilePath objects with one another or with strings, you must use\n             the + operator. If this causes trouble, you can pass str as the\n             the result_constructor.\n        \"\"\"\n\n        # check not none\n        if not tmp_dir:\n            tmp_dir = self.TmpDir\n        # if not current directory, append \"/\" if not already on path\n        elif not tmp_dir.endswith(\"/\"):\n            tmp_dir += \"/\"\n\n        if include_class_id:\n            # Append the classname to the prefix from the class name\n            # so any problematic temp files can be associated with\n            # the class that created them. This should be especially\n            # useful for testing, but is turned off by default to\n            # avoid the string-parsing overhead.\n            class_id = str(self.__class__())\n            prefix = ''.join([prefix,\n                              class_id[class_id.rindex('.') + 1:\n                                       class_id.index(' ')]])\n\n        try:\n            mkdir(tmp_dir)\n        except OSError:\n            # Directory already exists\n            pass\n        # note: it is OK to join FilePath objects with +\n        return result_constructor(tmp_dir) + result_constructor(prefix) + \\\n            result_constructor(''.join([choice(_all_chars)\n                                        for i in range(self.TmpNameLen)])) +\\\n            result_constructor(suffix)", "response": "Returns a temporary filename for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite your forwards methods here.", "response": "def forwards(self, orm):\n        \"Write your forwards methods here.\"\n        # Note: Remember to use orm['appname.ModelName'] rather than \"from appname.models...\"\n        for category in orm['document_library.DocumentCategory'].objects.all():\n            category.slug = category.documentcategorytitle_set.all()[0].title.lower()\n            category.save()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the accent of a single character.", "response": "def get_accent_char(char):\n    \"\"\"\n    Get the accent of an single char, if any.\n    \"\"\"\n    index = utils.VOWELS.find(char.lower())\n    if (index != -1):\n        return 5 - index % 6\n    else:\n        return Accent.NONE"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_accent_string(string):\n    accents = list(filter(lambda accent: accent != Accent.NONE,\n                          map(get_accent_char, string)))\n    return accents[-1] if accents else Accent.NONE", "response": "Get the first accent from the right of a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds accent to the given components.", "response": "def add_accent(components, accent):\n    \"\"\"\n    Add accent to the given components. The parameter components is\n    the result of function separate()\n    \"\"\"\n    vowel = components[1]\n    last_consonant = components[2]\n    if accent == Accent.NONE:\n        vowel = remove_accent_string(vowel)\n        return [components[0], vowel, last_consonant]\n\n    if vowel == \"\":\n        return components\n    #raw_string is a list, not a str object\n    raw_string = remove_accent_string(vowel).lower()\n    new_vowel = \"\"\n    # Highest priority for \u00ea and \u01a1\n    index = max(raw_string.find(\"\u00ea\"), raw_string.find(\"\u01a1\"))\n    if index != -1:\n        new_vowel = vowel[:index] + add_accent_char(vowel[index], accent) + vowel[index+1:]\n    elif len(vowel) == 1 or (len(vowel) == 2 and last_consonant == \"\"):\n        new_vowel = add_accent_char(vowel[0], accent) + vowel[1:]\n    else:\n        new_vowel = vowel[:1] + add_accent_char(vowel[1], accent) + vowel[2:]\n    return [components[0], new_vowel, components[2]]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_accent_char(char, accent):\n    if char == \"\":\n        return \"\"\n    case = char.isupper()\n    char = char.lower()\n    index = utils.VOWELS.find(char)\n    if (index != -1):\n        index = index - index % 6 + 5\n        char = utils.VOWELS[index - accent]\n    return utils.change_case(char, case)", "response": "Add accent to a single char."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_accent_at(string, accent, index):\n    if index == -1:\n        return string\n    # Python can handle the case which index is out of range of given string\n    return string[:index] + \\\n        accent.accent.add_accent_char(string[index], accent) + \\\n        string[index+1:]", "response": "Add an accent character at the given index to the given string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_accent_string(string):\n    return utils.join([add_accent_char(c, Accent.NONE) for c in string])", "response": "Removes all accent from a whole string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_command_line_parameters(argv=None):\n    usage =\\\n        'usage: %prog [options] input_sequences_filepath'\n    version = 'Version: %prog ' + __version__\n    parser = OptionParser(usage=usage, version=version)\n\n    parser.add_option('-o', '--output_fp', action='store',\n                      type='string', dest='output_fp', help='Path to store ' +\n                      'output file [default: generated from input_sequences_filepath]')\n\n    parser.add_option('-c', '--min_confidence', action='store',\n                      type='float', dest='min_confidence', help='minimum confidence ' +\n                      'level to return a classification [default: %default]')\n\n    parser.set_defaults(verbose=False, min_confidence=0.80)\n\n    opts, args = parser.parse_args(argv)\n    if len(args) != 1:\n        parser.error('Exactly one argument is required.')\n\n    return opts, args", "response": "Parses command line arguments and returns options and args."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning taxonomy to each sequence in data with the RDP classifier.", "response": "def assign_taxonomy(\n        data, min_confidence=0.80, output_fp=None, training_data_fp=None,\n        fixrank=True, max_memory=None, tmp_dir=tempfile.gettempdir()):\n    \"\"\"Assign taxonomy to each sequence in data with the RDP classifier\n\n        data: open fasta file object or list of fasta lines\n        confidence: minimum support threshold to assign taxonomy to a sequence\n        output_fp: path to write output; if not provided, result will be\n         returned in a dict of {seq_id:(taxonomy_assignment,confidence)}\n    \"\"\"\n    # Going to iterate through this twice in succession, best to force\n    # evaluation now\n    data = list(data)\n\n    # RDP classifier doesn't preserve identifiers with spaces\n    # Use lookup table\n    seq_id_lookup = {}\n    for seq_id, seq in parse_fasta(data):\n        seq_id_lookup[seq_id.split()[0]] = seq_id\n\n    app_kwargs = {}\n    if tmp_dir is not None:\n        app_kwargs['TmpDir'] = tmp_dir\n    app = RdpClassifier(**app_kwargs)\n\n    if max_memory is not None:\n        app.Parameters['-Xmx'].on(max_memory)\n\n    temp_output_file = tempfile.NamedTemporaryFile(\n        prefix='RdpAssignments_', suffix='.txt', dir=tmp_dir)\n    app.Parameters['-o'].on(temp_output_file.name)\n    if training_data_fp is not None:\n        app.Parameters['-t'].on(training_data_fp)\n\n    if fixrank:\n        app.Parameters['-f'].on('fixrank')\n    else:\n        app.Parameters['-f'].on('allrank')\n\n    app_result = app(data)\n\n    assignments = {}\n\n    # ShortSequenceException messages are written to stdout\n    # Tag these ID's as unassignable\n    for line in app_result['StdOut']:\n        excep = parse_rdp_exception(line)\n        if excep is not None:\n            _, rdp_id = excep\n            orig_id = seq_id_lookup[rdp_id]\n            assignments[orig_id] = ('Unassignable', 1.0)\n\n    for line in app_result['Assignments']:\n        rdp_id, direction, taxa = parse_rdp_assignment(line)\n        if taxa[0][0] == \"Root\":\n            taxa = taxa[1:]\n        orig_id = seq_id_lookup[rdp_id]\n        lineage, confidence = get_rdp_lineage(taxa, min_confidence)\n        if lineage:\n            assignments[orig_id] = (';'.join(lineage), confidence)\n        else:\n            assignments[orig_id] = ('Unclassified', 1.0)\n\n    if output_fp:\n        try:\n            output_file = open(output_fp, 'w')\n        except OSError:\n            raise OSError(\"Can't open output file for writing: %s\" % output_fp)\n        for seq_id, assignment in assignments.items():\n            lineage, confidence = assignment\n            output_file.write(\n                '%s\\t%s\\t%1.3f\\n' % (seq_id, lineage, confidence))\n        output_file.close()\n        return None\n    else:\n        return assignments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntraining RDP Classifier on the training sequence file.", "response": "def train_rdp_classifier(\n        training_seqs_file, taxonomy_file, model_output_dir, max_memory=None,\n        tmp_dir=tempfile.gettempdir()):\n    \"\"\" Train RDP Classifier, saving to model_output_dir\n\n        training_seqs_file, taxonomy_file: file-like objects used to\n            train the RDP Classifier (see RdpTrainer documentation for\n            format of training data)\n\n        model_output_dir: directory in which to save the files\n            necessary to classify sequences according to the training\n            data\n\n    Once the model data has been generated, the RDP Classifier may\n    \"\"\"\n    app_kwargs = {}\n    if tmp_dir is not None:\n        app_kwargs['TmpDir'] = tmp_dir\n    app = RdpTrainer(**app_kwargs)\n\n    if max_memory is not None:\n        app.Parameters['-Xmx'].on(max_memory)\n\n    temp_taxonomy_file = tempfile.NamedTemporaryFile(\n        prefix='RdpTaxonomy_', suffix='.txt', dir=tmp_dir)\n    temp_taxonomy_file.write(taxonomy_file.read())\n    temp_taxonomy_file.seek(0)\n\n    app.Parameters['taxonomy_file'].on(temp_taxonomy_file.name)\n    app.Parameters['model_output_dir'].on(model_output_dir)\n    return app(training_seqs_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntraining RDP Classifier and assign taxonomy in one fell swoop.", "response": "def train_rdp_classifier_and_assign_taxonomy(\n        training_seqs_file, taxonomy_file, seqs_to_classify, min_confidence=0.80,\n        model_output_dir=None, classification_output_fp=None, max_memory=None,\n        tmp_dir=tempfile.gettempdir()):\n    \"\"\" Train RDP Classifier and assign taxonomy in one fell swoop\n\n    The file objects training_seqs_file and taxonomy_file are used to\n    train the RDP Classifier (see RdpTrainer documentation for\n    details).  Model data is stored in model_output_dir.  If\n    model_output_dir is not provided, a temporary directory is created\n    and removed after classification.\n\n    The sequences in seqs_to_classify are classified according to the\n    model and filtered at the desired confidence level (default:\n    0.80).\n\n    The results are saved to classification_output_fp if provided,\n    otherwise a dict of {seq_id:(taxonomy_assignment,confidence)} is\n    returned.\n    \"\"\"\n    if model_output_dir is None:\n        training_dir = tempfile.mkdtemp(prefix='RdpTrainer_', dir=tmp_dir)\n    else:\n        training_dir = model_output_dir\n\n    training_results = train_rdp_classifier(\n        training_seqs_file, taxonomy_file, training_dir, max_memory=max_memory,\n        tmp_dir=tmp_dir)\n    training_data_fp = training_results['properties'].name\n\n    assignment_results = assign_taxonomy(\n        seqs_to_classify, min_confidence=min_confidence,\n        output_fp=classification_output_fp, training_data_fp=training_data_fp,\n        max_memory=max_memory, fixrank=False, tmp_dir=tmp_dir)\n\n    if model_output_dir is None:\n        # Forum user reported an error on the call to os.rmtree:\n        # https://groups.google.com/d/topic/qiime-forum/MkNe7-JtSBw/discussion\n        # We were not able to replicate the problem and fix it\n        # properly.  However, even if an error occurs, we would like\n        # to return results, along with a warning.\n        try:\n            rmtree(training_dir)\n        except OSError:\n            msg = (\n                \"Temporary training directory %s not removed\" % training_dir)\n            if os.path.isdir(training_dir):\n                training_dir_files = os.listdir(training_dir)\n                msg += \"\\nDetected files %s\" % training_dir_files\n            warnings.warn(msg, RuntimeWarning)\n\n    return assignment_results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing an RDP assignment line into a list of assigned taxa.", "response": "def parse_rdp_assignment(line):\n    \"\"\"Returns a list of assigned taxa from an RDP classification line\n    \"\"\"\n    toks = line.strip().split('\\t')\n    seq_id = toks.pop(0)\n    direction = toks.pop(0)\n    if ((len(toks) % 3) != 0):\n        raise ValueError(\n            \"Expected assignments in a repeating series of (rank, name, \"\n            \"confidence), received %s\" % toks)\n    assignments = []\n    # Fancy way to create list of triples using consecutive items from\n    # input.  See grouper function in documentation for itertools for\n    # more general example.\n    itoks = iter(toks)\n    for taxon, rank, confidence_str in zip(itoks, itoks, itoks):\n        if not taxon:\n            continue\n        assignments.append((taxon.strip('\"'), rank, float(confidence_str)))\n    return seq_id, direction, assignments"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise an ApplicationNotFoundError if the application is not accessible by the user.", "response": "def _error_on_missing_application(self, params):\n        \"\"\"Raise an ApplicationNotFoundError if the app is not accessible\n\n        In this case, checks for the java runtime and the RDP jar file.\n        \"\"\"\n        if not (os.path.exists('java') or which('java')):\n            raise ApplicationNotFoundError(\n                \"Cannot find java runtime. Is it installed? Is it in your \"\n                \"path?\")\n        jar_fp = self._get_jar_fp()\n        if jar_fp is None:\n            raise ApplicationNotFoundError(\n                \"JAR file not found in current directory and the RDP_JAR_PATH \"\n                \"environment variable is not set.  Please set RDP_JAR_PATH to \"\n                \"the full pathname of the JAR file.\")\n        if not os.path.exists(jar_fp):\n            raise ApplicationNotFoundError(\n                \"JAR file %s does not exist.\" % jar_fp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_jar_fp(self):\n        # handles case where the jar file is in the current working directory\n        if os.path.exists(self._command):\n            return self._command\n        # handles the case where the user has specified the location via\n        # an environment variable\n        elif 'RDP_JAR_PATH' in environ:\n            return getenv('RDP_JAR_PATH')\n        else:\n            return None", "response": "Returns the full path to the JAR file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_base_command(self):\n        cd_command = ''.join(['cd ', str(self.WorkingDir), ';'])\n        jvm_command = \"java\"\n        jvm_arguments = self._commandline_join(\n            [self.Parameters[k] for k in self._jvm_parameters])\n        jar_arguments = '-jar \"%s\"' % self._get_jar_fp()\n        rdp_arguments = self._commandline_join(\n            [self.Parameters[k] for k in self._options])\n\n        command_parts = [\n            cd_command, jvm_command, jvm_arguments, jar_arguments,\n            rdp_arguments, '-q']\n        return self._commandline_join(command_parts).strip()", "response": "Returns the base command plus command - line options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _commandline_join(self, tokens):\n        commands = filter(None, map(str, tokens))\n        return self._command_delimiter.join(commands).strip()", "response": "Formats a list of tokens as a shell commandline"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict of ResultPath objects representing all possible output of a specific resource.", "response": "def _get_result_paths(self, data):\n        \"\"\" Return a dict of ResultPath objects representing all possible output\n        \"\"\"\n        assignment_fp = str(self.Parameters['-o'].Value).strip('\"')\n        if not os.path.isabs(assignment_fp):\n            assignment_fp = os.path.relpath(assignment_fp, self.WorkingDir)\n        return {'Assignments': ResultPath(assignment_fp, IsWritten=True)}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the base command plus command - line options.", "response": "def _get_base_command(self):\n        \"\"\"Returns the base command plus command-line options.\n\n        Handles everything up to and including the classpath.  The\n        positional training parameters are added by the\n        _input_handler_decorator method.\n        \"\"\"\n        cd_command = ''.join(['cd ', str(self.WorkingDir), ';'])\n        jvm_command = \"java\"\n        jvm_args = self._commandline_join(\n            [self.Parameters[k] for k in self._jvm_parameters])\n        cp_args = '-cp \"%s\" %s' % (self._get_jar_fp(), self.TrainingClass)\n\n        command_parts = [cd_command, jvm_command, jvm_args, cp_args]\n        return self._commandline_join(command_parts).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ModelDir(self):\n        model_dir = self.Parameters['model_output_dir'].Value\n        absolute_model_dir = os.path.abspath(model_dir)\n        return FilePath(absolute_model_dir)", "response": "Absolute FilePath to the training output directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _input_handler_decorator(self, data):\n        input_handler = getattr(self, self.__InputHandler)\n        input_parts = [\n            self.Parameters['taxonomy_file'],\n            input_handler(data),\n            self.Parameters['training_set_id'],\n            self.Parameters['taxonomy_version'],\n            self.Parameters['modification_info'],\n            self.ModelDir,\n        ]\n        return self._commandline_join(input_parts)", "response": "Adds positional parameters to selected input_handler s results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of output files.", "response": "def _get_result_paths(self, output_dir):\n        \"\"\"Return a dict of output files.\n        \"\"\"\n        # Only include the properties file here. Add the other result\n        # paths in the __call__ method, so we can catch errors if an\n        # output file is not written.\n        self._write_properties_file()\n        properties_fp = os.path.join(self.ModelDir, self.PropertiesFile)\n        result_paths = {\n            'properties': ResultPath(properties_fp, IsWritten=True,)\n        }\n        return result_paths"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _write_properties_file(self):\n        # The properties file specifies the names of the files in the\n        # training directory.  We use the example properties file\n        # directly from the rdp_classifier distribution, which lists\n        # the default set of files created by the application.  We\n        # must write this file manually after generating the\n        # training data.\n        properties_fp = os.path.join(self.ModelDir, self.PropertiesFile)\n        properties_file = open(properties_fp, 'w')\n        properties_file.write(\n            \"# Sample ResourceBundle properties file\\n\"\n            \"bergeyTree=bergeyTrainingTree.xml\\n\"\n            \"probabilityList=genus_wordConditionalProbList.txt\\n\"\n            \"probabilityIndex=wordConditionalProbIndexArr.txt\\n\"\n            \"wordPrior=logWordPrior.txt\\n\"\n            \"classifierVersion=Naive Bayesian rRNA Classifier Version 1.0, \"\n            \"November 2003\\n\"\n        )\n        properties_file.close()", "response": "Write an RDP training properties file manually."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove all records for the given hostname.", "response": "def delete_old_host(self, hostname):\n        \"\"\"Remove all records for the host.\n\n        :param str hostname: Hostname to remove\n        :rtype: bool\n\n        \"\"\"\n        host = Host(self.session, name=hostname)\n        return host.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_new_host(self, hostname, ipv4addr, comment=None):\n        host = Host(self.session, name=hostname)\n        if host.ipv4addrs:\n            host.ipv4addrs = []\n        host.add_ipv4addr(ipv4addr)\n        host.comment = comment\n        return host.save()", "response": "Add or update a new host in the infoblox"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef align_unaligned_seqs(seqs_fp, moltype=DNA, params=None, accurate=False):\n    # Create Mafft app.\n    app = Mafft(InputHandler='_input_as_path', params=params)\n\n    # Turn on correct sequence type\n    app.Parameters[MOLTYPE_MAP[moltype]].on()\n\n    # Do not report progress\n    app.Parameters['--quiet'].on()\n\n    # More accurate alignment, sacrificing performance.\n    if accurate:\n        app.Parameters['--globalpair'].on()\n        app.Parameters['--maxiterate'].Value = 1000\n\n    # Get results using int_map as input to app\n    res = app(seqs_fp)\n\n    # Get alignment as dict out of results\n    alignment = Alignment.read(res['StdOut'], constructor=moltype)\n\n    # Clean up\n    res.cleanUp()\n\n    return alignment", "response": "Aligns unaligned sequences in a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an Alignment object from seqs and existing Alignment.", "response": "def add_seqs_to_alignment(seqs_fp, aln_fp, moltype=DNA,\n                          params=None, accurate=False):\n    \"\"\"Returns an Alignment object from seqs and existing Alignment.\n\n    The \"--seed\" option can be used for adding unaligned sequences into\n    a highly reliable alignment (seed) consisting of a small number of\n    sequences.\n\n    Parameters\n    ----------\n    seqs_fp : string\n        file path of the unaligned sequences\n    aln_fp : string\n        file path of the seed alignment\n    params : dict of parameters to pass in to the Mafft app controller.\n\n    Returns\n    -------\n        The aligned sequences. The seq in the seed alignment will have\n        \"_seed_\" prefixed to their seq id.\n    \"\"\"\n    if params is None:\n        params = {'--seed': aln_fp}\n    else:\n        params['--seed'] = aln_fp\n\n    return align_unaligned_seqs(seqs_fp, moltype, params, accurate)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an Alignment object from two existing Alignments.", "response": "def align_two_alignments(aln1_fp, aln2_fp, moltype, params=None):\n    \"\"\"Returns an Alignment object from two existing Alignments.\n\n    Parameters\n    ----------\n    aln1_fp : string\n        file path of 1st alignment\n    aln2_fp : string\n        file path of 2nd alignment\n    params : dict of parameters to pass in to the Mafft app controller.\n\n    Returns\n    -------\n        The aligned sequences.\n    \"\"\"\n\n    # Create Mafft app.\n    app = Mafft(InputHandler='_input_as_paths',\n                params=params,\n                SuppressStderr=False)\n    app._command = 'mafft-profile'\n\n    # Get results using int_map as input to app\n    res = app([aln1_fp, aln2_fp])\n\n    return Alignment.read(res['StdOut'], constructor=moltype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat a list of strings as input.", "response": "def _input_as_seqs(self, data):\n        \"\"\"Format a list of seq as input.\n\n        Parameters\n        ----------\n        data: list of strings\n            Each string is a sequence to be aligned.\n\n        Returns\n        -------\n        A temp file name that contains the sequences.\n\n        See Also\n        --------\n        burrito.util.CommandLineApplication\n        \"\"\"\n        lines = []\n        for i, s in enumerate(data):\n            # will number the sequences 1,2,3,etc.\n            lines.append(''.join(['>', str(i+1)]))\n            lines.append(s)\n        return self._input_as_lines(lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs a segmenter from a configuration doc.", "response": "def from_config(cls, config, name, section_key=\"segmenters\"):\n        \"\"\"\n        Constructs a segmenter from a configuration doc.\n        \"\"\"\n        section = config[section_key][name]\n        segmenter_class_path = section['class']\n        Segmenter = yamlconf.import_module(segmenter_class_path)\n        return Segmenter.from_config(config, name, section_key=section_key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a random hex string", "response": "def random_hex(length):\n    \"\"\"Generates a random hex string\"\"\"\n    return escape.to_unicode(binascii.hexlify(os.urandom(length))[length:])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhashing a specified password", "response": "def password_hash(password, password_salt=None):\n    \"\"\"Hashes a specified password\"\"\"\n    password_salt = password_salt or oz.settings[\"session_salt\"]\n    salted_password = password_salt + password\n    return \"sha256!%s\" % hashlib.sha256(salted_password.encode(\"utf-8\")).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the root of a tree of a continuous function that accepts a single number input returns a single number.", "response": "def bisect(func, a, b, xtol=1e-12, maxiter=100):\n    \"\"\"\n    Finds the root of `func` using the bisection method.\n\n    Requirements\n    ------------\n    - func must be continuous function that accepts a single number input\n      and returns a single number\n    - `func(a)` and `func(b)` must have opposite sign\n\n    Parameters\n    ----------\n    func : function\n        the function that we want to find the root of\n    a : number\n        one of the bounds on the input\n    b : number\n        the other bound on the input\n    xtol : number, optional\n        the solution tolerance of the input value. The algorithm is\n        considered converged if `abs(b-a)2. < xtol`\n    maxiter : number, optional\n        the maximum number of iterations allowed for convergence\n    \"\"\"\n    fa = func(a)\n    if fa == 0.:\n        return a\n\n    fb = func(b)\n    if fb == 0.:\n        return b\n\n    assert sign(fa) != sign(fb)\n\n    for i in xrange(maxiter):\n        c = (a + b) / 2.\n        fc = func(c)\n        if fc == 0. or abs(b - a) / 2. < xtol:\n            return c\n        if sign(fc) == sign(func(a)):\n            a = c\n        else:\n            b = c\n    else:\n        raise RuntimeError('Failed to converge after %d iterations.' % maxiter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a foreign resource URL into the URL string itself and any relevant args and kwargs.", "response": "def parse_string(s):\n        '''\n        Parses a foreign resource URL into the URL string itself and any\n        relevant args and kwargs\n        '''\n        matched_obj = SPLIT_URL_RE.match(s)\n        if not matched_obj:\n            raise URLParseException('Invalid Resource URL: \"%s\"' % s)\n\n        url_string, arguments_string = matched_obj.groups()\n        args_as_strings = URL_ARGUMENTS_RE.findall(arguments_string)\n\n        # Determine args and kwargs\n        args = []\n        kwargs = {}\n        for arg_string in args_as_strings:\n            kwarg_match = ARG_RE.match(arg_string)\n            if kwarg_match:\n                key, value = kwarg_match.groups()\n                kwargs[key.strip()] = value.strip()\n            else:\n                args.append(arg_string.strip())\n\n        # Default to HTTP if url_string has no URL\n        if not SCHEME_RE.match(url_string):\n            url_string = '%s://%s' % (DEFAULT_SCHEME, url_string)\n\n        return url_string.strip(), args, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_experiment(experiment):\n    redis = oz.redis.create_connection()\n    oz.bandit.add_experiment(redis, experiment)", "response": "Adds a new experiment to the sequence of experiments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an experiment choice", "response": "def add_experiment_choice(experiment, choice):\n    \"\"\"Adds an experiment choice\"\"\"\n    redis = oz.redis.create_connection()\n    oz.bandit.Experiment(redis, experiment).add_choice(choice)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_experiment_choice(experiment, choice):\n    redis = oz.redis.create_connection()\n    oz.bandit.Experiment(redis, experiment).remove_choice(choice)", "response": "Removes an experiment choice"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the results of all experiments and prints it out", "response": "def get_experiment_results():\n    \"\"\"\n    Computes the results of all experiments, stores it in redis, and prints it\n    out\n    \"\"\"\n\n    redis = oz.redis.create_connection()\n\n    for experiment in oz.bandit.get_experiments(redis):\n        experiment.compute_default_choice()\n        csq, confident = experiment.confidence()\n\n        print(\"%s:\" % experiment.name)\n        print(\"- creation date: %s\" % experiment.metadata[\"creation_date\"])\n        print(\"- default choice: %s\" % experiment.default_choice)\n        print(\"- chi squared: %s\" % csq)\n        print(\"- confident: %s\" % confident)\n        print(\"- choices:\")\n\n        for choice in experiment.choices:\n            print(\"  - %s: plays=%s, rewards=%s, performance=%s\" % (choice.name, choice.plays, choice.rewards, choice.performance))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sync_experiments_from_spec(filename):\n\n    redis = oz.redis.create_connection()\n\n    with open(filename, \"r\") as f:\n        schema = escape.json_decode(f.read())\n\n    oz.bandit.sync_from_spec(redis, schema)", "response": "Syncs the experiments stored in redis to match the spec"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_chapter(self, title):\n        '''\n        Adds a new chapter to the report.\n\n        :param str title: Title of the chapter.\n        '''\n        chap_id = 'chap%s' % self.chap_counter\n        self.chap_counter += 1\n        self.sidebar += '<a href=\"#%s\" class=\"list-group-item\">%s</a>\\n' % (\n            chap_id, title)\n        self.body += '<h1 id=\"%s\">%s</h1>\\n' % (chap_id, title)", "response": "Adds a new chapter to the report."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_image(self, figure, dpi=72):\n        '''\n        Adds an image to the last chapter/section.\n        The image will be stored in the `{self.title}_files` directory.\n\n        :param matplotlib.figure figure:\n            A matplotlib figure to be saved into the report\n        '''\n        name = os.path.join(self._dir, '/fig%s.png' % self.fig_counter)\n        self.fig_counter += 1\n        figure.savefig(name, dpi=dpi)\n        plt.close(figure)\n        self.body += '<img src=\"%s\" />\\n' % name", "response": "Adds an image to the last chapter section."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the report to a file.", "response": "def write_report(self, force=False):\n        '''\n        Writes the report to a file.\n        '''\n        path = self.title + '.html'\n        value = self._template.format(\n            title=self.title, body=self.body, sidebar=self.sidebar)\n        write_file(path, value, force=force)\n        plt.ion()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a tree from an alignment object", "response": "def build_tree_from_alignment(aln, moltype=DNA, best_tree=False, params=None):\n    \"\"\"Returns a tree from alignment\n\n    Will check MolType of aln object\n    \"\"\"\n    if params is None:\n        params = {}\n\n    if moltype == DNA or moltype == RNA:\n        params['-nt'] = True\n    elif moltype == PROTEIN:\n        params['-nt'] = False\n    else:\n        raise ValueError, \\\n                \"FastTree does not support moltype: %s\" % moltype.label\n\n    app = FastTree(params=params)\n\n    if best_tree:\n        raise NotImplementedError, \"best_tree not implemented yet\"\n    result = app(aln.toFasta())\n    tree = DndParser(result['Tree'].read(), constructor=PhyloNode)\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dbsource(dbname, var, resolution=None, tscale=None):\n    db_cfg = {}\n    cfg_dir = 'datasource'\n    cfg_files = pkg_resources.resource_listdir('oceansdb', cfg_dir)\n    cfg_files = [f for f in cfg_files if f[-5:] == '.json']\n    for src_cfg in cfg_files:\n        text = pkg_resources.resource_string(\n                'oceansdb', os.path.join(cfg_dir, src_cfg))\n        text = text.decode('UTF-8', 'replace')\n        cfg = json.loads(text)\n        for c in cfg:\n            assert c not in db_cfg, \"Trying to overwrite %s\"\n            db_cfg[c] = cfg[c]\n\n    dbpath = oceansdb_dir()\n    datafiles = []\n    cfg = db_cfg[dbname]\n\n    if (resolution is None):\n        resolution = cfg['vars'][var]['default_resolution']\n\n    if (tscale is None):\n        tscale = cfg['vars'][var][resolution][\"default_tscale\"]\n\n    for c in cfg['vars'][var][resolution][tscale]:\n        download_file(outputdir=dbpath, **c)\n\n        if 'filename' in c:\n            filename = os.path.join(dbpath, c['filename'])\n        else:\n            filename = os.path.join(dbpath,\n                    os.path.basename(urlparse(c['url']).path))\n\n        if 'varnames' in cfg['vars'][var][resolution]:\n            datafiles.append(Dataset_flex(filename,\n                aliases=cfg['vars'][var][resolution]['varnames']))\n        else:\n            datafiles.append(Dataset_flex(filename))\n\n    return datafiles", "response": "Return which file(s) to use according to dbname var etc."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a longest common substring diff.", "response": "def diff(a, b):\n    \"\"\"\n    Performs a longest common substring diff.\n\n    :Parameters:\n        a : sequence of `comparable`\n            Initial sequence\n        b : sequence of `comparable`\n            Changed sequence\n\n    :Returns:\n        An `iterable` of operations.\n    \"\"\"\n    a, b = list(a), list(b)\n    opcodes = SM(None, a, b).get_opcodes()\n    return parse_opcodes(opcodes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an endpoint from a local file to a local file.", "response": "async def convert_endpoint(url_string, ts, is_just_checking):\n    '''\n    Main logic for HTTP endpoint.\n    '''\n    response = singletons.server.response\n\n    # Prep ForeignResource and ensure does not validate security settings\n    singletons.settings\n    foreign_res = ForeignResource(url_string)\n\n    target_ts = TypeString(ts)\n    target_resource = TypedResource(url_string, target_ts)\n\n    # Send back cache if it exists\n    if target_resource.cache_exists():\n        if is_just_checking:\n            return _just_checking_response(True, target_resource)\n        return await response.file(target_resource.cache_path, headers={\n            'Content-Type': target_ts.mimetype,\n        })\n\n    # Check if already downloaded. If not, queue up download.\n    if not foreign_res.cache_exists():\n        singletons.workers.enqueue_download(foreign_res)\n\n    # Queue up a single function that will in turn queue up conversion\n    # process\n    singletons.workers.enqueue_sync(\n        enqueue_conversion_path,\n        url_string,\n        str(target_ts),\n        singletons.workers.enqueue_convert\n    )\n\n    if is_just_checking:\n        return _just_checking_response(False, target_resource)\n\n    # Respond with placeholder\n    return singletons.placeholders.stream_response(target_ts, response)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_command_list_template(command_list, in_path, out_path, args):\n    '''\n    Perform necessary substitutions on a command list to create a CLI-ready\n    list to launch a conversion or download process via system binary.\n    '''\n    replacements = {\n        '$IN': in_path,\n        '$OUT': out_path,\n    }\n\n    # Add in positional arguments ($0, $1, etc)\n    for i, arg in enumerate(args):\n        replacements['$' + str(i)] = arg\n\n    results = [replacements.get(arg, arg) for arg in command_list]\n\n    # Returns list of truthy replaced arguments in command\n    return [item for item in results if item]", "response": "Apply necessary substitutions on a list of command lists to create a CLI - ready\n    list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def convert_local(path, to_type):\n    '''\n    Given an absolute path to a local file, convert to a given to_type\n    '''\n    # Now find path between types\n    typed_foreign_res = TypedLocalResource(path)\n    original_ts = typed_foreign_res.typestring\n    conversion_path = singletons.converter_graph.find_path(\n        original_ts, to_type)\n    # print('Conversion path: ', conversion_path)\n\n    # Loop through each step in graph path and convert\n    for is_first, is_last, path_step in first_last_iterator(conversion_path):\n        converter_class, from_ts, to_ts = path_step\n        converter = converter_class()\n        in_resource = TypedLocalResource(path, from_ts)\n        if is_first:  # Ensure first resource is just the source one\n            in_resource = typed_foreign_res\n        out_resource = TypedLocalResource(path, to_ts)\n\n        if is_last:\n            out_resource = TypedPathedLocalResource(path, to_ts)\n        await converter.convert(in_resource, out_resource)", "response": "Given an absolute path to a local file convert to a given to_type\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a URL string that has already been downloaded enqueue a conversion to get to target type", "response": "def enqueue_conversion_path(url_string, to_type, enqueue_convert):\n    '''\n    Given a URL string that has already been downloaded, enqueue\n    necessary conversion to get to target type\n    '''\n    target_ts = TypeString(to_type)\n    foreign_res = ForeignResource(url_string)\n\n    # Determine the file type of the foreign resource\n    typed_foreign_res = foreign_res.guess_typed()\n\n    if not typed_foreign_res.cache_exists():\n        # Symlink to new location that includes typed extension\n        typed_foreign_res.symlink_from(foreign_res)\n\n    # Now find path between types\n    original_ts = typed_foreign_res.typestring\n    path = singletons.converter_graph.find_path(original_ts, target_ts)\n\n    # Loop through each step in graph path and convert\n    is_first = True\n    for converter_class, from_ts, to_ts in path:\n        converter = converter_class()\n        in_resource = TypedResource(url_string, from_ts)\n        if is_first:  # Ensure first resource is just the source one\n            in_resource = TypedForeignResource(url_string, from_ts)\n        out_resource = TypedResource(url_string, to_ts)\n        enqueue_convert(converter, in_resource, out_resource)\n        is_first = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a path exists and execute otherwise callback argument.", "response": "def check_path(path, otherwise):\n    \"\"\"\n    Checks if a path exists. If it does, print a warning message; if not,\n    execute the `otherwise` callback argument.\n    \"\"\"\n\n    if os.path.exists(path):\n        print(\"WARNING: Path '%s' already exists; skipping\" % path)\n    else:\n        otherwise(path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config_maker(project_name, path):\n\n    with open(skeleton_path(\"config.py\"), \"r\") as config_source:\n        config_content = config_source.read()\n\n    config_content = config_content.replace(\"__PROJECT_NAME__\", project_name)\n\n    with open(path, \"w\") as config_dest:\n        config_dest.write(config_content)", "response": "Creates a config file based on the project name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef skeleton_path(parts):\n    return os.path.join(os.path.dirname(oz.__file__), \"skeleton\", parts)", "response": "Gets the path to a skeleton asset"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init(project_name):\n\n    if not VALID_PROJECT_NAME.match(project_name):\n        print(\"Invalid project name. It may only contain letters, numbers and underscores.\", file=sys.stderr)\n        return\n\n    check_path(project_name, functools.partial(shutil.copytree, skeleton_path(\"plugin\")))\n    check_path(\"static\", os.mkdir)\n    check_path(\"templates\", os.mkdir)\n    check_path(\"config.py\", functools.partial(config_maker, project_name))", "response": "Creates a new project"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns an IPython repl with some context", "response": "def repl():\n    \"\"\"Runs an IPython repl with some context\"\"\"\n\n    try:\n        import IPython\n    except:\n        print(\"ERROR: IPython is not installed. Please install it to use the repl.\", file=sys.stderr)\n        raise\n\n    IPython.embed(user_ns=dict(\n        settings=oz.settings,\n        actions=oz._actions,\n        uimodules=oz._uimodules,\n        routes=oz._routes,\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiguring out path basename for given resource_url", "response": "def find_resource_url_basename(self, resource_url):\n        '''\n        Figure out path basename for given resource_url\n        '''\n        scheme = resource_url.parsed.scheme\n        if scheme in ('http', 'https', 'file'):\n            return _get_basename_based_on_url(resource_url)\n\n        elif scheme in ('git', 'git+https', 'git+http'):\n            if len(resource_url.args) == 2:\n                # For now, git has 2 positional args, hash and path\n                git_tree, subpath = resource_url.args\n                basename = os.path.basename(subpath)\n                if basename:\n                    return basename  # subpath was not '/' or ''\n        return _get_basename_based_on_url(resource_url)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a resource_url figure out what it would resolve into", "response": "def find_destination_type(self, resource_url):\n        '''\n        Given a resource_url, figure out what it would resolve into\n        '''\n        resolvers = self.converters.values()\n        for resolver in resolvers:\n            # Not all resolvers are opinionated about destination types\n            if not hasattr(resolver, 'get_destination_type'):\n                continue\n\n            destination_type = resolver.get_destination_type(resource_url)\n            if destination_type:\n                return destination_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def download(self, resource_url):\n        '''\n        Download given Resource URL by finding path through graph and applying\n        each step\n        '''\n        resolver_path = self.find_path_from_url(resource_url)\n        await self.apply_resolver_path(resource_url, resolver_path)", "response": "Download given Resource URL by finding path through graph and applying\n        each step"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert_sequences_into_tree(aln, moltype, params={}):\n    # convert aln to phy since seq_names need fixed to run through parsinsert\n    new_aln=get_align_for_phylip(StringIO(aln))\n\n    # convert aln to fasta in case it is not already a fasta file\n    aln2 = Alignment(new_aln)\n    seqs = aln2.toFasta()\n\n    parsinsert_app = ParsInsert(params=params)\n    result = parsinsert_app(seqs)\n\n    # parse tree\n    tree = DndParser(result['Tree'].read(), constructor=PhyloNode)\n\n    # cleanup files\n    result.cleanUp()\n\n    return tree", "response": "Returns a tree from placement of sequences\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the resulting tree", "response": "def _get_result_paths(self,data):\n        \"\"\" Get the resulting tree\"\"\"\n        result = {}\n        result['Tree'] = ResultPath(Path=splitext(self._input_filename)[0] + \\\n                                                  '.tree')\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a folder in MAL.", "response": "def create_folder(self, dir_name):\n        \"\"\"\u521b\u5efa\u76ee\u5f55(https://www.qcloud.com/document/product/436/6061)\n\n        :param dir_name:\u8981\u521b\u5efa\u7684\u76ee\u5f55\u7684\u76ee\u5f55\u7684\u540d\u79f0\n        :return \u8fd4\u56deTrue\u521b\u5efa\u6210\u529f\uff0c\u8fd4\u56deFalse\u521b\u5efa\u5931\u8d25\n        \"\"\"\n        if dir_name[0] == '/':\n            dir_name = dir_name[1:len(dir_name)]\n        self.url = \"http://<Region>.file.myqcloud.com\" + \"/files/v2/<appid>/<bucket_name>/<dir_name>/\"\n        self.url = self.url.replace(\"<Region>\", self.config.region).replace(\"<appid>\", str(self.config.app_id))\n        self.url = str(self.url).replace(\"<bucket_name>\", self.config.bucket).replace(\"<dir_name>\", dir_name)\n        self.headers['Authorization'] = CosAuth(self.config).sign_more(self.config.bucket, '', 30 )\n        response, content = self.http.request(uri=self.url, method='POST', body='{\"op\": \"create\", \"biz_attr\": \"\"}', headers=self.headers)\n        if eval(content.decode('utf8')).get(\"code\") == 0:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_folder(self, dir_name=None, prefix=None, num=1000, context=None):\n        if dir_name[0] == '/':\n            dir_name = dir_name[1:len(dir_name)]\n        self.url = 'http://<Region>.file.myqcloud.com/files/v2/<appid>/<bucket_name>/'\n        self.url = self.url.replace(\"<Region>\", self.config.region).replace(\"<appid>\", str(self.config.app_id)).replace(\"<bucket_name>\", self.config.bucket)\n        if dir_name is not None:\n            self.url = self.url + str(dir_name) + \"/\"\n        if prefix is not None:\n            self.url = self.url + str(prefix)\n        self.url = self.url + \"?op=list&num=\" + str(num)\n        if context is not None:\n            self.url = self.url + '&context=' + str(context)\n        self.headers['Authorization'] = CosAuth(self.config).sign_more(self.config.bucket, '', 30)\n        response, content = self.http.request(uri=self.url, method='GET', headers=self.headers)\n        return content.decode(\"utf8\")", "response": "List all the files in a folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries the folder for the given name.", "response": "def query_folder(self, dir_name):\n        \"\"\"\u67e5\u8be2\u76ee\u5f55\u5c5e\u6027(https://www.qcloud.com/document/product/436/6063)\n\n        :param dir_name:\u67e5\u8be2\u7684\u76ee\u5f55\u7684\u540d\u79f0\n        :return:\u67e5\u8be2\u51fa\u6765\u7684\u7ed3\u679c\uff0c\u4e3ajson\u683c\u5f0f\n        \"\"\"\n        if dir_name[0] == '/':\n            dir_name = dir_name[1:len(dir_name)]\n        self.url = 'http://' + self.config.region + '.file.myqcloud.com' + '/files/v2/' + str(self.config.app_id) + '/' + self.config.bucket + '/' + dir_name + '/?op=stat'\n        self.headers['Authorization'] = CosAuth(self.config).sign_more(self.config.bucket, '', 30)\n        reponse, content = self.http.request(uri=self.url, method='GET',headers=self.headers)\n        return content.decode(\"utf8\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuploads a file to the MALQ Cloud.", "response": "def upload_file(self, real_file_path, file_name, dir_name=None):\n        \"\"\"\u7b80\u5355\u4e0a\u4f20\u6587\u4ef6(https://www.qcloud.com/document/product/436/6066)\n\n        :param real_file_path: \u6587\u4ef6\u7684\u7269\u7406\u5730\u5740\n        :param file_name: \u6587\u4ef6\u540d\u79f0\n        :param dir_name: \u6587\u4ef6\u5939\u540d\u79f0\uff08\u53ef\u9009\uff09\n        :return:json\u6570\u636e\u4e32\n        \"\"\"\n\n        if dir_name is not None and dir_name[0] == '/':\n            dir_name = dir_name[1:len(dir_name)]\n        if dir_name is None:\n            dir_name = \"\"\n        self.url = 'http://' + self.config.region + '.file.myqcloud.com/files/v2/' + str(self.config.app_id) + '/' + self.config.bucket\n        if dir_name is not None:\n            self.url = self.url + '/' + dir_name\n        self.url = self.url + '/' + file_name\n        headers = {}\n        headers['Authorization'] = CosAuth(self.config).sign_more(self.config.bucket, '', 30)\n        files = {'file': ('', open(real_file_path, 'rb'))}\n        r = requests.post(url=self.url, data={'op': 'upload', 'biz_attr': '', 'insertOnly': '0'}, files={\n            'filecontent': (real_file_path, open(real_file_path, 'rb'), 'application/octet-stream')}, headers=headers)\n        return str(eval(r.content.decode('utf8')).get('data'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading a file to MALQ Cloud.", "response": "def upload_slice_file(self, real_file_path, slice_size, file_name, offset=0, dir_name=None):\n        \"\"\"\n        \u6b64\u5206\u7247\u4e0a\u4f20\u4ee3\u7801\u7531GitHub\u7528\u6237a270443177(https://github.com/a270443177)\u53cb\u60c5\u63d0\u4f9b\n\n        :param real_file_path:\n        :param slice_size:\n        :param file_name:\n        :param offset:\n        :param dir_name:\n        :return:\n        \"\"\"\n        if dir_name is not None and dir_name[0] == '/':\n            dir_name = dir_name[1:len(dir_name)]\n        if dir_name is None:\n            dir_name = \"\"\n        self.url = 'http://' + self.config.region + '.file.myqcloud.com/files/v2/' + str(\n            self.config.app_id) + '/' + self.config.bucket\n        if dir_name is not None:\n            self.url = self.url + '/' + dir_name\n        self.url = self.url + '/' + file_name\n        file_size = os.path.getsize(real_file_path)\n        session = self._upload_slice_control(file_size=file_size, slice_size=slice_size)\n        with open(real_file_path, 'rb') as local_file:\n            while offset < file_size:\n                file_content = local_file.read(slice_size)\n                self._upload_slice_data(filecontent=file_content, session=session, offset=offset)\n                offset += slice_size\n            r = self._upload_slice_finish(session=session, file_size=file_size)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupload a file from a url", "response": "def upload_file_from_url(self, url, file_name, dir_name=None):\n        \"\"\"\u7b80\u5355\u4e0a\u4f20\u6587\u4ef6(https://www.qcloud.com/document/product/436/6066)\n\n        :param url: \u6587\u4ef6url\u5730\u5740\n        :param file_name: \u6587\u4ef6\u540d\u79f0\n        :param dir_name: \u6587\u4ef6\u5939\u540d\u79f0\uff08\u53ef\u9009\uff09\n        :return:json\u6570\u636e\u4e32\n        \"\"\"\n        real_file_name = str(int(time.time()*1000))\n        urllib.request.urlretrieve(url, real_file_name)\n        data = self.upload_file(real_file_name, file_name, dir_name)\n        os.remove(real_file_name)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsigns a new bucket.", "response": "def sign_more(self, bucket, cos_path, expired):\n        \"\"\"\u591a\u6b21\u7b7e\u540d(\u9488\u5bf9\u4e0a\u4f20\u6587\u4ef6\uff0c\u521b\u5efa\u76ee\u5f55, \u83b7\u53d6\u6587\u4ef6\u76ee\u5f55\u5c5e\u6027, \u62c9\u53d6\u76ee\u5f55\u5217\u8868)\n\n        :param bucket: bucket\u540d\u79f0\n        :param cos_path: \u8981\u64cd\u4f5c\u7684cos\u8def\u5f84, \u4ee5'/'\u5f00\u59cb\n        :param expired: \u7b7e\u540d\u8fc7\u671f\u65f6\u95f4, UNIX\u65f6\u95f4\u6233, \u5982\u60f3\u8ba9\u7b7e\u540d\u572830\u79d2\u540e\u8fc7\u671f, \u5373\u53ef\u5c06expired\u8bbe\u6210\u5f53\u524d\u65f6\u95f4\u52a0\u4e0a30\u79d2\n        :return: \u7b7e\u540d\u5b57\u7b26\u4e32\n        \"\"\"\n        return self.app_sign(bucket, cos_path, expired)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sign_download(self, bucket, cos_path, expired):\n        return self.app_sign(bucket, cos_path, expired, False)", "response": "Signs a file for download"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef strained_001(self, target):\n        '''\n        Returns an instance of ``IIIVZincBlendeStrained001``, which is a\n        biaxial-strained III-V zinc blende binary alloy grown on a (001)\n        surface.\n        \n        Parameters\n        ----------\n        target : Alloy with ``a`` parameter or float\n            Growth substrate, assumed to have a (001) surface, or out-of-plane\n            strain, which is negative for tensile strain and positive for\n            compressive strain. This is the strain measured by X-ray\n            diffraction (XRD) symmetric omega-2theta scans.\n        '''\n        if isinstance(target, Alloy):\n            return IIIVZincBlendeStrained001(unstrained=self,\n                                             substrate=target)\n        else:\n            return IIIVZincBlendeStrained001(unstrained=self,\n                                             strain_out_of_plane=target)", "response": "Returns an instance of III - V zinc blende binary alloy grown on a ( 1999 ) target."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Eg(self, **kwargs):\n        '''\n        Returns the bandgap, Eg, in eV at a given\n        temperature, T, in K (default=300.).\n        '''\n        return min(self.Eg_Gamma(**kwargs),\n                   self.Eg_L(**kwargs),\n                   self.Eg_X(**kwargs))", "response": "Returns the bandgap Eg in eV at a given\n        temperature T in K"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef F(self, **kwargs):\n        '''\n        Returns the Kane remote-band parameter, `F`, calculated from\n        `Eg_Gamma_0`, `Delta_SO`, `Ep`, and `meff_e_Gamma_0`.\n        '''\n        Eg = self.Eg_Gamma_0(**kwargs)\n        Delta_SO = self.Delta_SO(**kwargs)\n        Ep = self.Ep(**kwargs)\n        meff = self.meff_e_Gamma_0(**kwargs)\n        return (1./meff-1-(Ep*(Eg+2.*Delta_SO/3.))/(Eg*(Eg+Delta_SO)))/2", "response": "Returns the Kane remote - band parameter F calculated from Eg Delta_SO Ep and meff_e_Gamma_0."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef a(self, **kwargs):\n        '''\n        Returns the lattice parameter, a, in Angstroms at a given\n        temperature, `T`, in Kelvin (default: 300 K).\n        '''\n        T = kwargs.get('T', 300.)\n        return (self.a_300K(**kwargs) +\n                self.thermal_expansion(**kwargs) * (T - 300.))", "response": "Returns the lattice parameter a in Angstroms at a given temperature T in Kelvin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the split - off hole effective mass", "response": "def meff_SO(self, **kwargs):\n        '''\n        Returns the split-off hole effective mass\n        calculated from Eg_Gamma(T), Delta_SO, Ep and F.\n        \n        Interpolation of Eg_Gamma(T), Delta_SO, Ep and luttinger1, and\n        then calculation of meff_SO is recommended for alloys.\n        '''\n        Eg = self.Eg_Gamma(**kwargs)\n        Delta_SO = self.Delta_SO(**kwargs)\n        Ep = self.Ep(**kwargs)\n        luttinger1 = self.luttinger1(**kwargs)\n        return 1./(luttinger1 - (Ep*Delta_SO)/(3*Eg*(Eg+Delta_SO)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the electron effective mass in the Gamma - valley species", "response": "def meff_e_Gamma(self, **kwargs):\n        '''\n        Returns the electron effective mass in the Gamma-valley\n        calculated from Eg_Gamma(T), Delta_SO, Ep and F.\n        \n        Interpolation of Eg_Gamma(T), Delta_SO, Ep and F, and\n        then calculation of meff_e_Gamma is recommended for alloys.\n        '''\n        Eg = self.Eg_Gamma(**kwargs)\n        Delta_SO = self.Delta_SO(**kwargs)\n        Ep = self.Ep(**kwargs)\n        F = self.F(**kwargs)\n        return 1./((1.+2.*F)+(Ep*(Eg+2.*Delta_SO/3.))/(Eg*(Eg+Delta_SO)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef meff_hh_110(self, **kwargs):\n        '''\n        Returns the heavy-hole band effective mass in the [110] direction,\n        meff_hh_110, in units of electron mass.\n        '''\n        return 2. / (2 * self.luttinger1(**kwargs) - self.luttinger2(**kwargs)\n                - 3 * self.luttinger3(**kwargs))", "response": "Returns the heavy - hole band effective mass in the [ 110 ] direction meff_hh_110 in units of electron mass."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the light - hole band effective mass in the [ 110 ] direction meff_lh_110 in units of electron mass.", "response": "def meff_lh_110(self, **kwargs):\n        '''\n        Returns the light-hole band effective mass in the [110] direction,\n        meff_lh_110, in units of electron mass.\n        '''\n        return 2. / (2 * self.luttinger1(**kwargs) + self.luttinger2(**kwargs)\n                + 3 * self.luttinger3(**kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nonparabolicity(self, **kwargs):\n        '''\n        Returns the Kane band nonparabolicity parameter for the Gamma-valley.\n        '''\n        Eg = self.Eg_Gamma(**kwargs)\n        meff = self.meff_e_Gamma(**kwargs)\n        T = kwargs.get('T', 300.)\n        return k*T/Eg * (1 - meff)**2", "response": "Returns the Kane band nonparabolicity parameter for the Gamma - valley."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef crop(self, lat, lon, var):\n        dims, idx = cropIndices(self.dims, lat, lon)\n        subset = {}\n        for v in var:\n            subset = {v: self.ncs[0][v][idx['yn'], idx['xn']]}\n        return subset, dims", "response": "Crop a subset of the dataset for each var in the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninterpolates each var on the coordinates requested by the user.", "response": "def interpolate(self, lat, lon, var):\n        \"\"\" Interpolate each var on the coordinates requested\n\n        \"\"\"\n\n        subset, dims = self.crop(lat, lon, var)\n\n        if np.all([y in dims['lat'] for y in lat]) & \\\n                np.all([x in dims['lon'] for x in lon]):\n                    yn = np.nonzero([y in lat for y in dims['lat']])[0]\n                    xn = np.nonzero([x in lon for x in dims['lon']])[0]\n                    output = {}\n                    for v in subset:\n                        # output[v] = subset[v][dn, zn, yn, xn]\n                        # Seriously that this is the way to do it?!!??\n                        output[v] = subset[v][:, xn][yn]\n                    return output\n\n        # The output coordinates shall be created only once.\n        points_out = []\n        for latn in lat:\n            for lonn in lon:\n                points_out.append([latn, lonn])\n        points_out = np.array(points_out)\n\n        output = {}\n        for v in var:\n            output[v] = ma.masked_all(\n                    (lat.size, lon.size),\n                    dtype=subset[v].dtype)\n\n            # The valid data\n            idx = np.nonzero(~ma.getmaskarray(subset[v]))\n\n            if idx[0].size > 0:\n                points = np.array([\n                    dims['lat'][idx[0]], dims['lon'][idx[1]]]).T\n                values = subset[v][idx]\n\n                # Interpolate along the dimensions that have more than one\n                #   position, otherwise it means that the output is exactly\n                #   on that coordinate.\n                ind = np.array(\n                        [np.unique(points[:, i]).size > 1 for i in\n                            range(points.shape[1])])\n                assert ind.any()\n\n                values_out = griddata(\n                        np.atleast_1d(np.squeeze(points[:, ind])),\n                        values,\n                        np.atleast_1d(np.squeeze(points_out[:, ind]))\n                        )\n\n                # Remap the interpolated value back into a 4D array\n                idx = np.isfinite(values_out)\n                for [y, x], out in zip(points_out[idx], values_out[idx]):\n                    output[v][y==lat, x==lon] = out\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset up directed conversion graph, pruning unavailable converters as necessary", "response": "def _setup_converter_graph(self, converter_list, prune_converters):\n        '''\n        Set up directed conversion graph, pruning unavailable converters as\n        necessary\n        '''\n        for converter in converter_list:\n            if prune_converters:\n                try:\n                    converter.configure()\n                except ConverterUnavailable as e:\n                    log.warning('%s unavailable: %s' %\n                                (converter.__class__.__name__, str(e)))\n                    continue\n\n            for in_ in converter.inputs:\n                for out in converter.outputs:\n                    self.dgraph.add_edge(in_, out, converter.cost)\n                    self.converters[(in_, out)] = converter\n\n            if hasattr(converter, 'direct_outputs'):\n                self._setup_direct_converter(converter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_preferred_paths(self, preferred_conversion_paths):\n        '''\n        Add given valid preferred conversion paths\n        '''\n        for path in preferred_conversion_paths:\n            for pair in pair_looper(path):\n                if pair not in self.converters:\n                    log.warning('Invalid conversion path %s, unknown step %s' %\n                                (repr(path), repr(pair)))\n                    break\n            else:\n                # If it did not break, then add to dgraph\n                self.dgraph.add_preferred_path(*path)", "response": "Add given preferred conversion paths to dgraph"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds given conversion profiles checking for invalid profiles", "response": "def _setup_profiles(self, conversion_profiles):\n        '''\n        Add given conversion profiles checking for invalid profiles\n        '''\n        # Check for invalid profiles\n        for key, path in conversion_profiles.items():\n            if isinstance(path, str):\n                path = (path, )\n            for left, right in pair_looper(path):\n                pair = (_format(left), _format(right))\n                if pair not in self.converters:\n                    msg = 'Invalid conversion profile %s, unknown step %s'\n                    log.warning(msg % (repr(key), repr(pair)))\n                    break\n            else:\n                # If it did not break, then add to conversion profiles\n                self.conversion_profiles[key] = path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_direct_converter(self, converter):\n        '''\n        Given a converter, set up the direct_output routes for conversions,\n        which is used for transcoding between similar datatypes.\n        '''\n        inputs = (\n            converter.direct_inputs\n            if hasattr(converter, 'direct_inputs')\n            else converter.inputs\n        )\n        for in_ in inputs:\n            for out in converter.direct_outputs:\n                self.direct_converters[(in_, out)] = converter", "response": "Sets up the direct_output routes for conversions and direct_inputs of the given converter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_path(self, in_, out):\n        '''\n        Given an input and output TypeString, produce a graph traversal,\n        keeping in mind special options like Conversion Profiles, Preferred\n        Paths, and Direct Conversions.\n        '''\n        if in_.arguments:\n            raise ValueError('Cannot originate path in argumented TypeString')\n\n        # Determine conversion profile. This is either simply the output, OR,\n        # if a custom profile has been specified for this output, that custom\n        # path or type is used.\n        profile = self.conversion_profiles.get(str(out), str(out))\n        if isinstance(profile, str):\n            profile = (profile, )\n        types_by_format = {_format(s): TypeString(s) for s in profile}\n\n        # Normalize input and output types to string\n        in_str = str(in_)\n        out_str = _format(profile[0])\n\n        # First check for direct conversions, returning immediately if found\n        direct_converter = self.direct_converters.get((in_str, out_str))\n        if direct_converter:\n            out_ts = types_by_format.get(out_str, TypeString(out_str))\n            return [(direct_converter, TypeString(in_str), out_ts)]\n\n        # No direct conversions was found, so find path through graph.\n        # If profile was plural, add in extra steps.\n        path = self.dgraph.shortest_path(in_str, out_str)\n        path += profile[1:]\n\n        # Loop through each edge traversal, adding converters and type\n        # string pairs as we go along. This is to ensure conversion\n        # profiles that have arguments mid-profile get included.\n        results = []\n        for left, right in pair_looper(path):\n            converter = self.converters.get((_format(left), _format(right)))\n            right_typestring = types_by_format.get(right, TypeString(right))\n            results.append((converter, TypeString(left), right_typestring))\n        return results", "response": "Given an input and output TypeString produce a graph traversal of the tree of the types that are used to convert the input and output types."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlike find_path except forces the conversion profiles to be the given conversion profile setting. Useful for overriding the conversion profiles with your own.", "response": "def find_path_with_profiles(self, conversion_profiles, in_, out):\n        '''\n        Like find_path, except forces the conversion profiles to be the given\n        conversion profile setting. Useful for \"temporarily overriding\" the\n        global conversion profiles with your own.\n        '''\n        original_profiles = dict(self.conversion_profiles)\n        self._setup_profiles(conversion_profiles)\n        results = self.find_path(in_, out)\n        self.conversion_profiles = original_profiles\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the lines before and after lineno from file.", "response": "def get_lines_from_file(filename, lineno, context_lines):\n    \"\"\"\n    Returns context_lines before and after lineno from file.\n    Returns (pre_context_lineno, pre_context, context_line, post_context).\n    \"\"\"\n\n    def get_lines(start, end):\n        return [linecache.getline(filename, l).rstrip() for l in range(start, end)]\n\n    lower_bound = max(1, lineno - context_lines)\n    upper_bound = lineno + context_lines\n    linecache.checkcache(filename)\n    pre_context = get_lines(lower_bound, lineno)\n    context_line = linecache.getline(filename, lineno).rstrip()\n    post_context = get_lines(lineno + 1, upper_bound)\n    return lower_bound, pre_context, context_line, post_context"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_frames(tback, is_breakpoint):\n\n    frames = []\n\n    while tback is not None:\n        if tback.tb_next is None and is_breakpoint:\n            break\n\n        filename = tback.tb_frame.f_code.co_filename\n        function = tback.tb_frame.f_code.co_name\n        context = tback.tb_frame.f_locals\n        lineno = tback.tb_lineno - 1\n        tback_id = id(tback)\n        pre_context_lineno, pre_context, context_line, post_context = get_lines_from_file(filename, lineno + 1, 7)\n        frames.append(ErrorFrame(tback, filename, function, lineno, context, tback_id, pre_context, context_line, post_context, pre_context_lineno))\n        tback = tback.tb_next\n\n    return frames", "response": "Builds a list of ErrorFrame objects from a traceback"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prettify_object(obj):\n\n    try:\n        return pprint.pformat(str(obj))\n    except UnicodeDecodeError as e:\n        raise\n    except Exception as e:\n        return \"[could not display: <%s: %s>]\" % (e.__class__.__name__, str(e))", "response": "Makes a pretty string for an object for nice output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clone_git_repo(repo_url):\n    REPO_PREFIX = \"djangodeployer-cache-\"\n    REPO_POSTFIX_UUID = str(uuid.uuid4()).split('-')[-1]\n    REPO_CACHE_NAME = REPO_PREFIX + REPO_POSTFIX_UUID\n    REPO_CACHE_LOCATION = '/tmp/%s' % REPO_CACHE_NAME\n\n    repo = git.Repo.clone_from(repo_url, REPO_CACHE_LOCATION)\n    return REPO_CACHE_LOCATION", "response": "clone the git repo and return the path of the cloned repository"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a list of files which need to be rendered in a node template.", "response": "def get_template_filelist(repo_path, ignore_files=[], ignore_folders=[]):\n    \"\"\"\n    input: local repo path\n    output: path list of files which need to be rendered\n    \"\"\"\n\n    default_ignore_files = ['.gitignore']\n    default_ignore_folders = ['.git']\n\n    ignore_files += default_ignore_files\n    ignore_folders += default_ignore_folders\n\n    filelist = []\n\n    for root, folders, files in os.walk(repo_path):\n        for ignore_file in ignore_files:\n            if ignore_file in files:\n                files.remove(ignore_file)\n\n        for ignore_folder in ignore_folders:\n            if ignore_folder in folders:\n                folders.remove(ignore_folder)\n\n        for file_name in files:\n            filelist.append( '%s/%s' % (root, file_name))\n\n    return filelist"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_from_repo(repo_path, to_path, template_params, settings_dir):\n    TEMPLATE_PROJECT_FOLDER_PLACEHOLDER_NAME = 'deployer_project'\n\n    repo_path = repo_path.rstrip('/')\n    to_path = to_path.rstrip('/')\n    files_to_render = get_template_filelist(repo_path, ignore_folders=[TEMPLATE_PROJECT_FOLDER_PLACEHOLDER_NAME])\n\n\n    # rendering generic deploy files\n    for single_file_path in files_to_render:\n        source_file_path = single_file_path\n        dest_file_path = source_file_path.replace(repo_path, to_path)\n\n        render_from_single_file(source_file_path, dest_file_path, template_params)\n\n    settings_template_dir = os.path.join(repo_path, TEMPLATE_PROJECT_FOLDER_PLACEHOLDER_NAME)\n    settings_files = get_template_filelist(settings_template_dir)\n\n    # rendering settings file\n    for single_file_path in settings_files:\n        source = single_file_path\n        dest = single_file_path.replace(settings_template_dir, settings_dir)\n        render_from_single_file(source, dest, template_params)", "response": "Renders all files into the target directory"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a logger to be used between processes.", "response": "def gen_logger(name: str, log_level: int=logging.INFO) -> logging.Logger:\n    \"\"\"Create a logger to be used between processes.\n\n    :returns: Logging instance.\n    \"\"\"\n    logger = logging.getLogger(name)\n    logger.setLevel(log_level)\n    shandler: logging.StreamHandler = logging.StreamHandler(sys.stdout)\n    fmt: str = '\\033[1;32m%(levelname)-5s %(module)s:%(funcName)s():'\n    fmt += '%(lineno)d %(asctime)s\\033[0m| %(message)s'\n    shandler.setFormatter(logging.Formatter(fmt))\n    logger.addHandler(shandler)\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a header pairing.", "response": "def gen_headers() -> Dict[str, str]:\n    \"\"\"Generate a header pairing.\"\"\"\n    ua_list: List[str] = ['Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.117 Safari/537.36']\n    headers: Dict[str, str] = {'User-Agent': ua_list[random.randint(0, len(ua_list) - 1)]}\n    return headers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngrab email addresses from raw text data.", "response": "def extract_emails(results: str, domain: str, fuzzy: bool) -> List[str]:\n    \"\"\"Grab email addresses from raw text data.\"\"\"\n    pattern: Pattern = re.compile(r'([\\w.-]+@[\\w.-]+)')\n    hits: List[str] = pattern.findall(results)\n    if fuzzy:\n        seed = domain.split('.')[0]\n        emails: List[str] = [x.lower() for x in hits if x.split('@')[1].__contains__(seed)]\n    else:\n        emails: List[str] = [x.lower() for x in hits if x.endswith(domain)]\n    return list(set(emails))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef seqs_to_stream(seqs, ih):\n    if ih == '_input_as_multiline_string':\n        recs = FastaFinder(seqs.split('\\n'))\n    elif ih == '_input_as_string':\n        recs = FastaFinder(open(seqs))\n    elif ih == '_input_as_seqs':\n        recs = [['>'+str(i), s] for i, s in enumerate(seqs)]\n    elif ih == '_input_as_lines':\n        recs = FastaFinder(seqs)\n    else:\n        raise TypeError, \"Unknown input handler %s\" % ih\n    return recs", "response": "Converts seqs into stream of FASTA records depending on input handler."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef blast_seqs(seqs,\n                 blast_constructor,\n                 blast_db=None,\n                 blast_mat_root=None,\n                 params={},\n                 add_seq_names=True,\n                 out_filename=None,\n                 WorkingDir=None,\n                 SuppressStderr=None,\n                 SuppressStdout=None,\n                 input_handler=None,\n                 HALT_EXEC=False\n                 ):\n    \"\"\"Blast list of sequences.\n\n    seqs: either file name or list of sequence objects or list of strings or\n    single multiline string containing sequences.\n\n    WARNING: DECISION RULES FOR INPUT HANDLING HAVE CHANGED. Decision rules\n    for data are as follows. If it's s list, treat as lines, unless\n    add_seq_names is true (in which case treat as list of seqs). If it's a\n    string, test whether it has newlines. If it doesn't have newlines, assume\n    it's a filename. If it does have newlines, it can't be a filename, so\n    assume it's a multiline string containing sequences.\n\n    If you want to skip the detection and force a specific type of input\n    handler, use input_handler='your_favorite_handler'.\n\n    add_seq_names: boolean. if True, sequence names are inserted in the list\n        of sequences. if False, it assumes seqs is a list of lines of some\n        proper format that the program can handle\n    \"\"\"\n\n    # set num keep\n\n    if blast_db:\n        params[\"-d\"] = blast_db\n\n    if out_filename:\n        params[\"-o\"] = out_filename\n\n    ih = input_handler or guess_input_handler(seqs, add_seq_names)\n\n    blast_app = blast_constructor(\n                   params=params,\n                   blast_mat_root=blast_mat_root,\n                   InputHandler=ih,\n                   WorkingDir=WorkingDir,\n                   SuppressStderr=SuppressStderr,\n                   SuppressStdout=SuppressStdout,\n                   HALT_EXEC=HALT_EXEC)\n\n    return blast_app(seqs)", "response": "Blast a list of sequences."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve sequences for list of accessions", "response": "def fasta_cmd_get_seqs(acc_list,\n                 blast_db=None,\n                 is_protein=None,\n                 out_filename=None,\n                 params={},\n                 WorkingDir=tempfile.gettempdir(),\n                 SuppressStderr=None,\n                 SuppressStdout=None):\n    \"\"\"Retrieve sequences for list of accessions \"\"\"\n\n    if is_protein is None:\n        params[\"-p\"] = 'G'\n    elif is_protein:\n        params[\"-p\"] = 'T'\n    else:\n        params[\"-p\"] = 'F'\n\n    if blast_db:\n        params[\"-d\"] = blast_db\n\n    if out_filename:\n        params[\"-o\"] = out_filename\n\n    # turn off duplicate accessions\n    params[\"-a\"] = \"F\"\n\n    # create Psi-BLAST\n    fasta_cmd = FastaCmd(params=params,\n                       InputHandler='_input_as_string',\n                       WorkingDir=WorkingDir,\n                       SuppressStderr=SuppressStderr,\n                       SuppressStdout=SuppressStdout)\n\n    # return results\n    return fasta_cmd(\"\\\"%s\\\"\" % ','.join(acc_list))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets dict of description : seq from fastacmd.", "response": "def seqs_from_fastacmd(acc_list, blast_db,is_protein=True):\n    \"\"\"Get dict of description:seq from fastacmd.\"\"\"\n    fasta_cmd_res = fasta_cmd_get_seqs(acc_list, blast_db=blast_db, \\\n        is_protein=is_protein)\n    recs = FastaCmdFinder(fasta_cmd_res['StdOut'])\n    result = {}\n    for rec in recs:\n        try:\n            result[rec[0][1:].strip()] = ''.join(map(strip, rec[1:]))\n        except IndexError:  #maybe we didn't get a sequence?\n            pass\n    fasta_cmd_res.cleanUp()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the ids that match a seq using a 2 - tiered strategy.", "response": "def ids_from_seq_two_step(seq, n, max_iterations, app, core_threshold, \\\n    extra_threshold, lower_threshold, second_db=None):\n    \"\"\"Returns ids that match a seq, using a 2-tiered strategy.\n\n    Optionally uses a second database for the second search.\n    \"\"\"\n    #first time through: reset 'h' and 'e' to core\n    #-h is the e-value threshold for including seqs in the score matrix model\n    app.Parameters['-h'].on(core_threshold)\n    #-e is the e-value threshold for the final blast\n    app.Parameters['-e'].on(core_threshold)\n    checkpoints = []\n    ids = []\n    last_num_ids = None\n    for i in range(max_iterations):\n        if checkpoints:\n            app.Parameters['-R'].on(checkpoints[-1])\n        curr_check = 'checkpoint_%s.chk' % i\n        app.Parameters['-C'].on(curr_check)\n\n        output = app(seq)\n        #if we didn't write a checkpoint, bail out\n        if not access(curr_check, F_OK):\n            break\n        #if we got here, we wrote a checkpoint file\n        checkpoints.append(curr_check)\n        result = list(output.get('BlastOut', output['StdOut']))\n        output.cleanUp()\n        if result:\n            ids = LastProteinIds9(result,keep_values=True,filter_identity=False)\n        num_ids = len(ids)\n        if num_ids >= n:\n            break\n        if num_ids == last_num_ids:\n            break\n        last_num_ids = num_ids\n\n    #if we didn't write any checkpoints, second run won't work, so return ids\n    if not checkpoints:\n        return ids\n\n    #if we got too many ids and don't have a second database, return the ids we got\n    if (not second_db) and num_ids >= n:\n        return ids\n\n    #second time through: reset 'h' and 'e' to get extra hits, and switch the\n    #database if appropriate\n    app.Parameters['-h'].on(extra_threshold)\n    app.Parameters['-e'].on(lower_threshold)\n    if second_db:\n        app.Parameters['-d'].on(second_db)\n    for i in range(max_iterations): #will always have last_check if we get here\n        app.Parameters['-R'].on(checkpoints[-1])\n        curr_check = 'checkpoint_b_%s.chk' % i\n        app.Parameters['-C'].on(curr_check)\n        output = app(seq)\n        #bail out if we couldn't write a checkpoint\n        if not access(curr_check, F_OK):\n            break\n        #if we got here, the checkpoint worked\n        checkpoints.append(curr_check)\n        result = list(output.get('BlastOut', output['StdOut']))\n        if result:\n            ids = LastProteinIds9(result,keep_values=True,filter_identity=False)\n        num_ids = len(ids)\n        if num_ids >= n:\n            break\n        if num_ids == last_num_ids:\n            break\n        last_num_ids = num_ids\n    #return the ids we got. may not be as many as we wanted.\n    for c in checkpoints:\n        remove(c)\n    return ids"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ids_from_seq_lower_threshold(seq, n, max_iterations, app, core_threshold, \\\n    lower_threshold, step=100):\n    \"\"\"Returns ids that match a seq, decreasing the sensitivity.\"\"\"\n    last_num_ids = None\n    checkpoints = []\n    cp_name_base = make_unique_str()\n\n    # cache ides for each iteration\n    # store { iteration_num:(core_threshold, [list of matching ids]) }\n    all_ids = {}\n    try:\n        i=0\n        while 1:\n            #-h is the e-value threshold for inclusion in the score matrix model\n            app.Parameters['-h'].on(core_threshold)\n            app.Parameters['-e'].on(core_threshold)\n            if core_threshold > lower_threshold:\n                raise ThresholdFound\n            if checkpoints:\n                #-R restarts from a previously stored file\n                app.Parameters['-R'].on(checkpoints[-1])\n            #store the score model from this iteration\n            curr_check = 'checkpoint_' + cp_name_base + '_' + str(i) + \\\n                    '.chk'\n            app.Parameters['-C'].on(curr_check)\n            output = app(seq)\n            result = list(output.get('BlastOut', output['StdOut']))\n            #sometimes fails on first try -- don't know why, but this seems\n            #to fix problem\n            while not result:\n                output = app(seq)\n                result = list(output.get('BlastOut', output['StdOut']))\n\n            ids = LastProteinIds9(result,keep_values=True,filter_identity=False)\n            output.cleanUp()\n            all_ids[i + 1] = (core_threshold, copy(ids))\n            if not access(curr_check, F_OK):\n                raise ThresholdFound\n            checkpoints.append(curr_check)\n            num_ids = len(ids)\n            if num_ids >= n:\n                raise ThresholdFound\n            last_num_ids = num_ids\n            core_threshold *= step\n            if i >= max_iterations - 1: #because max_iterations is 1-based\n                raise ThresholdFound\n            i += 1\n    except ThresholdFound:\n        for c in checkpoints:\n            remove(c)\n        #turn app.Parameters['-R'] off so that for the next file it does not\n        #try and read in a checkpoint file that is not there\n        app.Parameters['-R'].off()\n        return ids, i + 1, all_ids", "response": "Returns a list of ids that match a seq decreasing the sensitivity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_unique_str(num_chars=20):\n    chars = 'abcdefghigklmnopqrstuvwxyz'\n    all_chars = chars + chars.upper() + '01234567890'\n    picks = list(all_chars)\n    return ''.join([choice(picks) for i in range(num_chars)])", "response": "make a random string of characters for a temp filename"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef keep_everything_scorer(checked_ids):\n    result = checked_ids.keys()\n    for i in checked_ids.values():\n        result.extend(i.keys())\n    return dict.fromkeys(result).keys()", "response": "Returns every query and every match in checked_ids with best score."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ids_from_seqs_iterative(seqs, app, query_parser, \\\n    scorer=keep_everything_scorer, max_iterations=None, blast_db=None,\\\n    max_seqs=None, ):\n    \"\"\"Gets the ids from each seq, then does each additional id until all done.\n\n    If scorer is passed in as an int, uses shotgun scorer with that # hits.\n    \"\"\"\n    if isinstance(scorer, int):\n        scorer = make_shotgun_scorer(scorer)\n    seqs_to_check = list(seqs)\n    checked_ids = {}\n    curr_iteration = 0\n    while seqs_to_check:\n        unchecked_ids = {}\n        #pass seqs to command\n        all_output = app(seqs_to_check)\n        output = all_output.get('BlastOut', all_output['StdOut'])\n\n        for query_id, match_id, match_score in query_parser(output):\n            if query_id not in checked_ids:\n                checked_ids[query_id] = {}\n            checked_ids[query_id][match_id] = match_score\n            if match_id not in checked_ids:\n                unchecked_ids[match_id] = True\n        all_output.cleanUp()\n        if unchecked_ids:\n            seq_file = fasta_cmd_get_seqs(unchecked_ids.keys(),\n                app.Parameters['-d'].Value)['StdOut']\n            seqs_to_check = []\n            for s in FastaCmdFinder(fasta_cmd_get_seqs(\\\n                unchecked_ids.keys(), app.Parameters['-d'].Value)['StdOut']):\n                seqs_to_check.extend(s)\n        else:\n            seqs_to_check = []\n        #bail out if max iterations or max seqs was defined and we've reached it\n        curr_iteration += 1\n        if max_iterations and (curr_iteration >= max_iterations):\n            break\n        if max_seqs:\n            curr = scorer(checked_ids)\n            if len(curr) >= max_seqs:\n                return curr\n    return scorer(checked_ids)", "response": "Gets the ids from each seq then does each additional id until all done."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn BlastResult from input seqs, using blastp. Need to add doc string", "response": "def blastp(seqs, blast_db=\"nr\", e_value=\"1e-20\", max_hits=200,\n           working_dir=tempfile.gettempdir(), blast_mat_root=None,\n           extra_params={}):\n    \"\"\"\n    Returns BlastResult from input seqs, using blastp.\n\n    Need to add doc string\n    \"\"\"\n\n    # set up params to use with blastp\n    params = {\n        # matrix\n        \"-M\":\"BLOSUM62\",\n\n        # max procs\n        \"-a\":\"1\",\n\n        # expectation\n        \"-e\":e_value,\n\n        # max seqs to show\n        \"-b\":max_hits,\n\n        # max one line descriptions\n        \"-v\":max_hits,\n\n        # program\n        \"-p\":\"blastp\"\n    }\n    params.update(extra_params)\n\n    # blast\n    blast_res =  blast_seqs(seqs,\n        Blastall,\n        blast_mat_root=blast_mat_root,\n        blast_db=blast_db,\n        params=params,\n        add_seq_names=False,\n        WorkingDir=working_dir\n        )\n\n    # get prot id map\n    if blast_res['StdOut']:\n        lines = [x for x in blast_res['StdOut']]\n        return BlastResult(lines)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to lock file and write PID.", "response": "def set_lock(fname):\n    \"\"\"\n    Try to lock file and write PID.\n    \n    Return the status of operation.\n    \"\"\"\n    \n    global fh\n    fh = open(fname, 'w')\n\n    if os.name == 'nt':\n        # Code for NT systems got from: http://code.activestate.com/recipes/65203/\n        \n        import win32con\n        import win32file\n        import pywintypes\n        \n        LOCK_EX = win32con.LOCKFILE_EXCLUSIVE_LOCK\n        LOCK_SH = 0 # the default\n        LOCK_NB = win32con.LOCKFILE_FAIL_IMMEDIATELY\n        \n        # is there any reason not to reuse the following structure?\n        __overlapped = pywintypes.OVERLAPPED()\n        \n        hfile = win32file._get_osfhandle(fh.fileno())\n        try:\n            win32file.LockFileEx(hfile, LOCK_EX | LOCK_NB, 0, -0x10000, __overlapped)\n        except pywintypes.error as exc_value:\n            # error: (33, 'LockFileEx', 'The process cannot access \n            # the file because another process has locked a portion\n            # of the file.')\n            if exc_value[0] == 33:\n                return False\n    else:\n        from fcntl import flock, LOCK_EX, LOCK_NB\n        try:\n            flock(fh.fileno(), LOCK_EX | LOCK_NB)\n        except Exception as ex:\n            return False\n    \n    fh.write(str(os.getpid()))\n    fh.flush()\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassert that file is locked.", "response": "def assert_lock(fname):\n    \"\"\"\n    If file is locked then terminate program else lock file.\n    \"\"\"\n\n    if not set_lock(fname):\n        logger.error('File {} is already locked. Terminating.'.format(fname))\n        sys.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_blast_db_from_fasta_path(fasta_path, is_protein=False,\n                                   output_dir=None, HALT_EXEC=False):\n    \"\"\"Build blast db from fasta_path; return db name and list of files created\n\n        **If using to create temporary blast databases, you can call\n        cogent.util.misc.remove_files(db_filepaths) to clean up all the\n        files created by formatdb when you're done with the database.\n\n        fasta_path: path to fasta file of sequences to build database from\n        is_protein: True if working on protein seqs (default: False)\n        output_dir: directory where output should be written\n         (default: directory containing fasta_path)\n        HALT_EXEC: halt just before running the formatdb command and\n         print the command -- useful for debugging\n    \"\"\"\n    fasta_dir, fasta_filename = split(fasta_path)\n    if not output_dir:\n        output_dir = fasta_dir or '.'\n        # Will cd to this directory, so just pass the filename\n        # so the app is not confused by relative paths\n        fasta_path = fasta_filename\n\n    if not output_dir.endswith('/'):\n        db_name = output_dir + '/' + fasta_filename\n    else:\n        db_name = output_dir + fasta_filename\n\n    # instantiate the object\n    fdb = FormatDb(WorkingDir=output_dir, HALT_EXEC=HALT_EXEC)\n    if is_protein:\n        fdb.Parameters['-p'].on('T')\n    else:\n        fdb.Parameters['-p'].on('F')\n    app_result = fdb(fasta_path)\n    db_filepaths = []\n    for v in app_result.values():\n        try:\n            db_filepaths.append(v.name)\n        except AttributeError:\n            # not a file object, so no path to return\n            pass\n    return db_name, db_filepaths", "response": "Build a BLAST database from a fasta file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a BLAST database from a fasta file.", "response": "def build_blast_db_from_fasta_file(fasta_file, is_protein=False,\n                                   output_dir=None, HALT_EXEC=False):\n    \"\"\"Build blast db from fasta_path; return db name and list of files created\n\n        **If using to create temporary blast databases, you can call\n        cogent.util.misc.remove_files(db_filepaths) to clean up all the\n        files created by formatdb when you're done with the database.\n\n        fasta_path: path to fasta file of sequences to build database from\n        is_protein: True if working on protein seqs (default: False)\n        output_dir: directory where output should be written\n         (default: directory containing fasta_path)\n        HALT_EXEC: halt just before running the formatdb command and\n         print the command -- useful for debugging\n    \"\"\"\n    output_dir = output_dir or '.'\n    _, fasta_path = mkstemp(dir=output_dir, prefix=\"BLAST_temp_db_\",\n                            suffix=\".fasta\")\n\n    fasta_f = open(fasta_path, 'w')\n    for line in fasta_file:\n        fasta_f.write('%s\\n' % line.strip())\n    fasta_f.close()\n\n    blast_db, db_filepaths = build_blast_db_from_fasta_path(fasta_path,\n                                                            is_protein=is_protein,\n                                                            output_dir=None,\n                                                            HALT_EXEC=HALT_EXEC\n                                                            )\n\n    db_filepaths.append(fasta_path)\n\n    return blast_db, db_filepaths"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a bast database from a sequence collection or alignment object.", "response": "def build_blast_db_from_seqs(seqs, is_protein=False, output_dir='./',\n                             HALT_EXEC=False):\n    \"\"\"Build blast db from seqs; return db name and list of files created\n\n        **If using to create temporary blast databases, you can call\n        cogent.util.misc.remove_files(db_filepaths) to clean up all the\n        files created by formatdb when you're done with the database.\n\n        seqs: sequence collection or alignment object\n        is_protein: True if working on protein seqs (default: False)\n        output_dir: directory where output should be written\n         (default: current directory)\n        HALT_EXEC: halt just before running the formatdb command and\n         print the command -- useful for debugging\n    \"\"\"\n\n    # Build a temp filepath\n    _, tmp_fasta_filepath = mkstemp(prefix='Blast_tmp_db', suffix='.fasta')\n    # open the temp file\n    tmp_fasta_file = open(tmp_fasta_filepath, 'w')\n    # write the sequence collection to file\n    tmp_fasta_file.write(seqs.toFasta())\n    tmp_fasta_file.close()\n\n    # build the bast database\n    db_name, db_filepaths = build_blast_db_from_fasta_path(tmp_fasta_filepath,\n                                                           is_protein=is_protein,\n                                                           output_dir=output_dir,\n                                                           HALT_EXEC=HALT_EXEC)\n\n    # clean-up the temporary file\n    remove(tmp_fasta_filepath)\n\n    # return the results\n    return db_name, db_filepaths"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_command_line_parameters():\n    usage = 'usage: %prog [options] fasta_filepath'\n    version = 'Version: %prog 0.1'\n    parser = OptionParser(usage=usage, version=version)\n\n    # A binary 'verbose' flag\n    parser.add_option('-p', '--is_protein', action='store_true',\n                      dest='is_protein', default=False,\n                      help='Pass if building db of protein sequences [default:'\n                           ' False, nucleotide db]')\n\n    parser.add_option('-o', '--output_dir', action='store', type='string',\n                      dest='output_dir', default=None,\n                      help='the output directory [default: directory '\n                           'containing input fasta_filepath]')\n\n    opts, args = parser.parse_args()\n    num_args = 1\n    if len(args) != num_args:\n        parser.error('Must provide single filepath to build database from.')\n\n    return opts, args", "response": "Parses command line parameters and returns options and args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _input_as_parameter(self, data):\n        self.Parameters['-i'].on(data)\n        # access data through self.Parameters so we know it's been cast\n        # to a FilePath\n        input_filepath = self.Parameters['-i'].Value\n        input_file_dir, input_filename = split(input_filepath)\n        input_file_base, input_file_ext = splitext(input_filename)\n        # FIXME: the following all other options\n        # formatdb ignores the working directory if not name is passed.\n        self.Parameters['-l'].on(FilePath('%s.log') % input_filename)\n        self.Parameters['-n'].on(FilePath(input_filename))\n        return ''", "response": "Set the input path and log path based on the passed data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_result_paths(self, data):\n        # access data through self.Parameters so we know it's been cast\n        # to a FilePath\n        wd = self.WorkingDir\n        db_name = self.Parameters['-n'].Value\n        log_name = self.Parameters['-l'].Value\n        result = {}\n        result['log'] = ResultPath(Path=wd + log_name, IsWritten=True)\n        if self.Parameters['-p'].Value == 'F':\n            extensions = ['nhr', 'nin', 'nsq', 'nsd', 'nsi']\n        else:\n            extensions = ['phr', 'pin', 'psq', 'psd', 'psi']\n        for extension in extensions:\n            for file_path in glob(wd + (db_name + '*' + extension)):\n                # this will match e.g. nr.01.psd and nr.psd\n                key = file_path.split(db_name + '.')[1]\n                result_path = ResultPath(Path=file_path, IsWritten=True)\n                result[key] = result_path\n        return result", "response": "Build the dict of result filepaths based on the parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _session_key(self):\n\n        if not hasattr(self, \"_cached_session_key\"):\n            session_id_bytes = self.get_secure_cookie(\"session_id\")\n            session_id = None\n\n            if session_id_bytes:\n                try:\n                    session_id = session_id_bytes.decode('utf-8')\n                except:\n                    pass\n\n            if not session_id:\n                session_id = oz.redis_sessions.random_hex(20)\n\n            session_time = oz.settings[\"session_time\"]\n            kwargs = dict(\n                name=\"session_id\",\n                value=session_id.encode('utf-8'),\n                domain=oz.settings.get(\"cookie_domain\"),\n                httponly=True,\n            )\n            if session_time:\n                kwargs[\"expires_days\"] = round(session_time/60/60/24)\n\n            self.set_secure_cookie(**kwargs)\n\n            password_salt = oz.settings[\"session_salt\"]\n            self._cached_session_key = \"session:%s:v4\" % oz.redis_sessions.password_hash(session_id, password_salt=password_salt)\n\n        return self._cached_session_key", "response": "Gets the redis key for a session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating a redis item to expire later since it has been interacted with recently", "response": "def _update_session_expiration(self):\n        \"\"\"\n        Updates a redis item to expire later since it has been interacted with\n        recently\n        \"\"\"\n\n        session_time = oz.settings[\"session_time\"]\n\n        if session_time:\n            self.redis().expire(self._session_key, session_time)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_session_value(self, name, default=None):\n\n        value = self.redis().hget(self._session_key, name) or default\n        self._update_session_expiration()\n        return value", "response": "Gets a session value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a session value", "response": "def set_session_value(self, name, value):\n        \"\"\"Sets a session value\"\"\"\n\n        self.redis().hset(self._session_key, name, value)\n        self._update_session_expiration()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_session_value(self, name):\n        self.redis().hdel(self._session_key, name)\n        self._update_session_expiration()", "response": "Removes a session value from the redis table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def rewrite_middleware(server, request):\n    '''\n    Sanic middleware that utilizes a security class's \"rewrite\" method to\n    check\n    '''\n    if singletons.settings.SECURITY is not None:\n        security_class = singletons.settings.load('SECURITY')\n    else:\n        security_class = DummySecurity\n    security = security_class()\n    try:\n        new_path = await security.rewrite(request)\n    except SecurityException as e:\n        msg = ''\n        if DEBUG:\n            msg = str(e)\n        return server.response.text(msg, status=400)\n    request.path = new_path", "response": "Sanic middleware that utilizes a security class s rewrite method to\n    check\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nanswer will provide all necessary feedback for the caller Args: c (int): HTTP Code details (dict): Response payload Returns: dict: Response payload Raises: ErrAtlasBadRequest ErrAtlasUnauthorized ErrAtlasForbidden ErrAtlasNotFound ErrAtlasMethodNotAllowed ErrAtlasConflict ErrAtlasServerErrors", "response": "def answer(self, c, details):\n        \"\"\"Answer will provide all necessary feedback for the caller\n        \n        Args:\n            c (int): HTTP Code\n            details (dict): Response payload\n        \n        Returns:\n            dict: Response payload\n            \n        Raises:\n            ErrAtlasBadRequest\n            ErrAtlasUnauthorized\n            ErrAtlasForbidden\n            ErrAtlasNotFound\n            ErrAtlasMethodNotAllowed\n            ErrAtlasConflict\n            ErrAtlasServerErrors\n        \n        \"\"\"\n        if c in [Settings.SUCCESS, Settings.CREATED, Settings.ACCEPTED]:\n            return details\n        elif c == Settings.BAD_REQUEST:\n            raise ErrAtlasBadRequest(c, details)\n        elif c == Settings.UNAUTHORIZED:\n            raise ErrAtlasUnauthorized(c, details)\n        elif c == Settings.FORBIDDEN:\n            raise ErrAtlasForbidden(c, details)\n        elif c == Settings.NOTFOUND:\n            raise ErrAtlasNotFound(c, details)\n        elif c == Settings.METHOD_NOT_ALLOWED:\n            raise ErrAtlasMethodNotAllowed(c, details)\n        elif c == Settings.CONFLICT:\n            raise ErrAtlasConflict(c, details)\n        else:\n            # Settings.SERVER_ERRORS\n            raise ErrAtlasServerErrors(c, details)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, uri):\n        r = None\n        \n        try:\n            r = requests.get(uri,\n                             allow_redirects=True,\n                             timeout=Settings.requests_timeout,\n                             headers={},\n                             auth=HTTPDigestAuth(self.user, self.password))\n            return self.answer(r.status_code, r.json())\n        except:\n            raise\n        finally:\n            if r:\n                r.connection.close()", "response": "Get request to the API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_objects(self, uri, pull=True, **kwargs):\n        '''\n        Walk through repo commits to generate a list of repo commit\n        objects.\n\n        Each object has the following properties:\n            * repo uri\n            * general commit info\n            * files added, removed fnames\n            * lines added, removed\n            * acked_by\n            * signed_off_by\n            * resolves\n            * related\n        '''\n        self.repo = repo = git_clone(uri, pull=pull, reflect=True)\n        # get a full list of all commit SHAs in the repo (all branches)\n        cmd = 'git rev-list --all'\n        output = sys_call(cmd, cwd=repo.path)\n        repo_shas = set(x.strip() for x in output.split('\\n') if x)\n        logger.debug(\"Total Commits: %s\" % len(repo_shas))\n\n        cmd = 'git --no-pager log --all --format=sha:%H --numstat'\n        output = sys_call(cmd)\n        all_logs = re.sub('\\n+', '\\n', output)\n        c_logs = [x for x in [s.strip() for s in all_logs.split('sha:')] if x]\n\n        _end = None  # once was true, always is true...\n        objs = []\n        for c_log in c_logs:\n            sha, s, all_changes = c_log.partition('\\n')\n            #try:\n            c = repo.get_object(sha)\n            # FIXME: not normalizing to UTC\n            _start = ts2dt(c.commit_time)\n            #except Exception as e:\n            #    _start = now\n            #    obj = dict(_oid=sha, _start=_start, _end=_end,\n            #               repo_uri=uri, _e={sha: to_encoding(e)})\n            #    self.objects.add(obj)\n            #    continue\n\n            # and some basic stuff...\n            obj = dict(_oid=sha, _start=_start, _end=_end,\n                       repo_uri=uri, tree=c.tree, parents=c.parents,\n                       author=c.author, committer=c.committer,\n                       author_time=c.author_time, message=c.message,\n                       mergetag=c.mergetag, extra=c.extra)\n\n            for _file in all_changes.split('\\n'):\n                _file = _file.strip()\n                obj.setdefault('files', {})\n                if not _file:\n                    added, removed, fname = 0, 0, None\n                else:\n                    added, removed, fname = _file.split('\\t')\n                    added = 0 if added == '-' else int(added)\n                    removed = 0 if removed == '-' else int(removed)\n                    # FIXME: sql doesn't nest well..\n                    changes = {'added': added,\n                               'removed': removed}\n                    obj['files'][fname] = changes\n\n            # file +/- totals\n            obj['added'] = sum(\n                [v.get('added', 0) for v in obj['files'].itervalues()])\n            obj['removed'] = sum(\n                [v.get('removed', 0) for v in obj['files'].itervalues()])\n\n            # extract interesting bits from the message\n            obj['acked_by'] = acked_by_re.findall(c.message)\n            obj['signed_off_by'] = signed_off_by_re.findall(c.message)\n            obj['resolves'] = resolves_re.findall(c.message)\n            obj['related'] = related_re.findall(c.message)\n            objs.append(obj)\n        self.objects.extend(objs)\n\n        return super(Commit, self).get_objects(**kwargs)", "response": "Get all objects from the repo."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dict_values_sorted_by_key(dictionary):\n    # This should be a yield from instead.\n    \"\"\"Internal helper to return the values of a dictionary, sorted by key.\n    \"\"\"\n    for _, value in sorted(dictionary.iteritems(), key=operator.itemgetter(0)):\n        yield value", "response": "Internal helper to return the values of a dictionary sorted by key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ondemand(f):\n    name = f.__name__\n\n    def func(self, *args, **kwargs):\n        if not args and not kwargs:\n            if hasattr(self, '_%s' % name):\n                return getattr(self, '_%s' % name)\n\n            a = f(self, *args, **kwargs)\n            setattr(self, '_%s' % name, a)\n            return a\n        else:\n            return f(self, *args, **kwargs)\n    func.__name__ = name\n    return func", "response": "Decorator to only request information if not in cache already."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves an area of memory from IDA.", "response": "def get_memory(self, start, size):\n        \"\"\"Retrieve an area of memory from IDA.\n        Returns a sparse dictionary of address -> value.\n        \"\"\"\n        LOG.debug('get_memory: %d bytes from %x', size, start)\n        return get_memory(self.ida.idaapi, start, size,\n                          default_byte=self.default_byte)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_objects(self, **kwargs):\n        '''\n        Run `rpm -q` command on a {local, remote} system to get back\n        details of installed RPMs.\n\n        Default rpm details extracted are as follows:\n            * name\n            * version\n            * release\n            * arch\n            * nvra\n            * license\n            * os\n            * packager\n            * platform\n            * sourcepackage\n            * sourcerpm\n            * summary\n        '''\n        fmt = ':::'.join('%%{%s}' % f for f in self._fields)\n        if self.ssh_host:\n            output = self._ssh_cmd(fmt)\n        else:\n            output = self._local_cmd(fmt)\n        if isinstance(output, basestring):\n            output = unicode(output, 'utf-8')\n            output = output.strip().split('\\n')\n        lines = [l.strip().split(':::') for l in output]\n        now = utcnow()\n        host = self.ssh_host or socket.gethostname()\n        for line in lines:\n            obj = {'host': host, '_start': now}\n            for i, item in enumerate(line):\n                if item == '(none)':\n                    item = None\n                obj[self._fields[i]] = item\n            obj['_oid'] = '%s__%s' % (host, obj['nvra'])\n            self.objects.add(obj)\n        return super(Rpm, self).get_objects(**kwargs)", "response": "Get back the available objects for this RPM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_404(request, exception):\n    '''Handle 404 Not Found\n    This handler should be used to handle error http 404 not found for all\n    endpoints or if resource not available.\n    '''\n    error = format_error(title='Resource not found', detail=str(exception))\n    return json(return_an_error(error), status=HTTPStatus.NOT_FOUND)", "response": "Handle 404 Not Found\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_to_dict(t, container, name, value):\n\n    if name in container:\n        raise Exception(\"%s '%s' already exists\" % (t, name))\n    else:\n        container[name] = value", "response": "Adds an item to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing oz with the given config", "response": "def initialize(config=None):\n    \"\"\"Initializes oz\"\"\"\n\n    # Load the config file\n    if config == None:\n        config = {}\n        config_source = None\n\n        try:\n            with open(os.environ.get(\"OZ_CONFIG\", \"config.py\")) as f:\n                config_source = f.read()\n        except Exception:\n            tornado.log.gen_log.info(\"Could not read config.py\", exc_info=True)\n\n        if config_source != None:\n            tornado.util.exec_in(config_source, config, config)\n\n    # Load the plugins\n    for p in config.get(\"plugins\", [\"oz.core\"]):\n        plugin(p)\n\n    # Set the options\n    for key, value in config.get(\"app_options\", {}).items():\n        setattr(tornado.options.options, key, value)\n\n    # Generate the application settings\n    global settings\n    settings = tornado.options.options.as_dict()\n    settings[\"ui_modules\"] = _uimodules\n    settings[\"project_name\"] = config.get(\"project_name\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntriggering an event to run through the middleware.", "response": "def trigger(self, name, *args, **kwargs):\n        \"\"\"\n        Triggers an event to run through middleware. This method will execute\n        a chain of relevant trigger callbacks, until one of the callbacks\n        returns the `break_trigger`.\n        \"\"\"\n\n        # Relevant middleware is cached so we don't have to rediscover it\n        # every time. Fetch the cached value if possible.\n\n        listeners = self._triggers.get(name, [])\n\n        # Execute each piece of middleware\n        for listener in listeners:\n            result = listener(*args, **kwargs)\n\n            if result == break_trigger:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking necessary directories to hold cache value.", "response": "def cache_makedirs(self, subdir=None):\n        '''\n        Make necessary directories to hold cache value\n        '''\n        if subdir is not None:\n            dirname = self.cache_path\n            if subdir:\n                dirname = os.path.join(dirname, subdir)\n        else:\n            dirname = os.path.dirname(self.cache_path)\n        os.makedirs(dirname, exist_ok=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a SQLAlchemy session", "response": "def session(connection_string=None):\n    \"\"\"Gets a SQLAlchemy session\"\"\"\n    global _session_makers\n    connection_string = connection_string or oz.settings[\"db\"]\n\n    if not connection_string in _session_makers:\n        _session_makers[connection_string] = sessionmaker(bind=engine(connection_string=connection_string))\n\n    return _session_makers[connection_string]()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assign_reads_to_database(query_fasta_fp, database_fasta_fp, output_fp,\n                             params=None):\n    \"\"\"Assign a set of query sequences to a reference database\n\n    query_fasta_fp : absolute file path to query sequences\n    database_fasta_fp : absolute file path to the reference database\n    output_fp : absolute file path of the output file to write\n    params : dict of BLAT specific parameters.\n\n    This method returns an open file object. The output format\n    defaults to blast9 and should be parsable by the PyCogent BLAST parsers.\n    \"\"\"\n    if params is None:\n        params = {}\n    if '-out' not in params:\n        params['-out'] = 'blast9'\n    blat = Blat(params=params)\n\n    result = blat([query_fasta_fp, database_fasta_fp, output_fp])\n    return result['output']", "response": "Assign a set of query sequences to a reference database and write the result to the output file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassigns DNA reads to a database fasta of DNA sequences.", "response": "def assign_dna_reads_to_dna_database(query_fasta_fp, database_fasta_fp,\n                                     output_fp, params=None):\n    \"\"\"Assign DNA reads to a database fasta of DNA sequences.\n\n    Wraps assign_reads_to_database, setting database and query types. All\n    parameters are set to default unless params is passed.\n\n    query_fasta_fp: absolute path to the query fasta file containing DNA\n                   sequences.\n    database_fasta_fp: absolute path to the database fasta file containing\n                      DNA sequences.\n    output_fp: absolute path where the output file will be generated.\n    params: optional. dict containing parameter settings to be used\n                  instead of default values. Cannot change database or query\n                  file types from dna and dna, respectively.\n\n    This method returns an open file object. The output format\n    defaults to blast9 and should be parsable by the PyCogent BLAST parsers.\n    \"\"\"\n    if params is None:\n        params = {}\n\n    my_params = {'-t': 'dna',\n                 '-q': 'dna'\n                 }\n\n    # if the user specified parameters other than default, then use them.\n    # However, if they try to change the database or query types, raise an\n    # applciation error.\n    if '-t' in params or '-q' in params:\n        raise ApplicationError(\"Cannot change database or query types when \" +\n                               \"using assign_dna_reads_to_dna_database. \" +\n                               \"Use assign_reads_to_database instead.\\n\")\n\n    my_params.update(params)\n\n    result = assign_reads_to_database(query_fasta_fp, database_fasta_fp,\n                                      output_fp, my_params)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassign DNA reads to a database fasta of protein sequences.", "response": "def assign_dna_reads_to_protein_database(query_fasta_fp, database_fasta_fp,\n                                         output_fp, temp_dir=\"/tmp\", params=None):\n    \"\"\"Assign DNA reads to a database fasta of protein sequences.\n\n    Wraps assign_reads_to_database, setting database and query types. All\n    parameters are set to default unless params is passed. A temporary\n    file must be written containing the translated sequences from the input\n    query fasta file because BLAT cannot do this automatically.\n\n    query_fasta_fp: absolute path to the query fasta file containing DNA\n                   sequences.\n    database_fasta_fp: absolute path to the database fasta file containing\n                      protein sequences.\n    output_fp: absolute path where the output file will be generated.\n    temp_dir: optional. Change the location where the translated sequences\n              will be written before being used as the query. Defaults to\n              /tmp.\n    params: optional. dict containing parameter settings to be used\n                  instead of default values. Cannot change database or query\n                  file types from protein and dna, respectively.\n\n    This method returns an open file object. The output format\n    defaults to blast9 and should be parsable by the PyCogent BLAST parsers.\n    \"\"\"\n    if params is None:\n        params = {}\n\n    my_params = {'-t': 'prot', '-q': 'prot'}\n\n    # make sure temp_dir specifies an absolute path\n    if not isabs(temp_dir):\n        raise ApplicationError(\"temp_dir must be an absolute path.\")\n\n    # if the user specified parameters other than default, then use them.\n    # However, if they try to change the database or query types, raise an\n    # applciation error.\n    if '-t' in params or '-q' in params:\n        raise ApplicationError(\"Cannot change database or query types \"\n                               \"when using assign_dna_reads_to_dna_database. Use \"\n                               \"assign_reads_to_database instead.\")\n\n    if 'genetic_code' in params:\n        my_genetic_code = GeneticCodes[params['genetic_code']]\n        del params['genetic_code']\n    else:\n        my_genetic_code = GeneticCodes[1]\n\n    my_params.update(params)\n\n    # get six-frame translation of the input DNA sequences and write them to\n    # temporary file.\n    _, tmp = mkstemp(dir=temp_dir)\n    tmp_out = open(tmp, 'w')\n\n    for label, sequence in parse_fasta(open(query_fasta_fp)):\n        seq_id = label.split()[0]\n\n        s = DNA.makeSequence(sequence)\n        translations = my_genetic_code.sixframes(s)\n        frames = [1, 2, 3, -1, -2, -3]\n        translations = dict(zip(frames, translations))\n\n        for frame, translation in sorted(translations.iteritems()):\n            entry = '>{seq_id}_frame_{frame}\\n{trans}\\n'\n            entry = entry.format(seq_id=seq_id, frame=frame, trans=translation)\n            tmp_out.write(entry)\n\n    tmp_out.close()\n    result = assign_reads_to_database(tmp, database_fasta_fp, output_fp,\n                                      params=my_params)\n\n    remove(tmp)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_base_command(self):\n        command_parts = []\n        cd_command = ''.join(['cd ', str(self.WorkingDir), ';'])\n        if self._command is None:\n            raise ApplicationError('_command has not been set.')\n        command = self._command\n        parameters = sorted([str(x) for x in self.Parameters.values()\n                            if str(x)])\n\n        synonyms = self._synonyms\n\n        command_parts.append(cd_command)\n        command_parts.append(command)\n        command_parts.append(self._database)  # Positional argument\n        command_parts.append(self._query)  # Positional argument\n        command_parts += parameters\n        if self._output:\n            command_parts.append(self._output.Path)  # Positional\n\n        return (\n            self._command_delimiter.join(filter(None, command_parts)).strip()\n        )", "response": "Gets the base command that will be run when the app controller is called."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake the positional arguments as input in a list.", "response": "def _input_as_list(self, data):\n        '''Takes the positional arguments as input in a list.\n\n        The list input here should be [query_file_path, database_file_path,\n        output_file_path]'''\n        query, database, output = data\n        if (not isabs(database)) \\\n                or (not isabs(query)) \\\n                or (not isabs(output)):\n            raise ApplicationError(\"Only absolute paths allowed.\\n%s\" %\n                                   ', '.join(data))\n\n        self._database = FilePath(database)\n        self._query = FilePath(query)\n        self._output = ResultPath(output, IsWritten=True)\n\n        # check parameters that can only take a particular set of values\n        # check combination of databse and query type\n        if self.Parameters['-t'].isOn() and self.Parameters['-q'].isOn() and \\\n                (self.Parameters['-t'].Value, self.Parameters['-q'].Value) not in \\\n                self._valid_combinations:\n            error_message = \"Invalid combination of database and query \" + \\\n                            \"types ('%s', '%s').\\n\" % \\\n                            (self.Paramters['-t'].Value,\n                             self.Parameters['-q'].Value)\n\n            error_message += \"Must be one of: %s\\n\" % \\\n                             repr(self._valid_combinations)\n\n            raise ApplicationError(error_message)\n\n        # check database type\n        if self.Parameters['-t'].isOn() and \\\n                self.Parameters['-t'].Value not in self._database_types:\n            error_message = \"Invalid database type %s\\n\" % \\\n                            self.Parameters['-t'].Value\n\n            error_message += \"Allowed values: %s\\n\" % \\\n                             ', '.join(self._database_types)\n\n            raise ApplicationError(error_message)\n\n        # check query type\n        if self.Parameters['-q'].isOn() and \\\n                self.Parameters['-q'].Value not in self._query_types:\n            error_message = \"Invalid query type %s\\n\" % \\\n                            self.Parameters['-q'].Value\n\n            error_message += \"Allowed values: %s\\n\" % \\\n                ', '.join(self._query_types)\n\n            raise ApplicationError(error_message)\n\n        # check mask type\n        if self.Parameters['-mask'].isOn() and \\\n                self.Parameters['-mask'].Value not in self._mask_types:\n            error_message = \"Invalid mask type %s\\n\" % \\\n                            self.Parameters['-mask']\n\n            error_message += \"Allowed Values: %s\\n\" % \\\n                ', '.join(self._mask_types)\n\n            raise ApplicationError(error_message)\n\n        # check qmask type\n        if self.Parameters['-qMask'].isOn() and \\\n                self.Parameters['-qMask'].Value not in self._mask_types:\n            error_message = \"Invalid qMask type %s\\n\" % \\\n                            self.Parameters['-qMask'].Value\n\n            error_message += \"Allowed values: %s\\n\" % \\\n                             ', '.join(self._mask_types)\n\n            raise ApplicationError(error_message)\n\n        # check repeat type\n        if self.Parameters['-repeats'].isOn() and \\\n                self.Parameters['-repeats'].Value not in self._mask_types:\n            error_message = \"Invalid repeat type %s\\n\" % \\\n                            self.Parameters['-repeat'].Value\n\n            error_message += \"Allowed values: %s\\n\" % \\\n                             ', '.join(self._mask_types)\n\n            raise ApplicationError(error_message)\n\n        # check output format\n        if self.Parameters['-out'].isOn() and \\\n                self.Parameters['-out'].Value not in self._out_types:\n            error_message = \"Invalid output type %s\\n\" % \\\n                            self.Parameters['-out']\n\n            error_message += \"Allowed values: %s\\n\" % \\\n                             ', '.join(self._out_types)\n\n            raise ApplicationError(error_message)\n\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef woa_profile_from_dap(var, d, lat, lon, depth, cfg):\n    if lon < 0:\n        lon = lon+360\n\n    url = cfg['url']\n\n    doy = int(d.strftime('%j'))\n    dataset = open_url(url)\n\n    dn = (np.abs(doy-dataset['time'][:])).argmin()\n    xn = (np.abs(lon-dataset['lon'][:])).argmin()\n    yn = (np.abs(lat-dataset['lat'][:])).argmin()\n\n    if re.match(\"temperature\\d?$\", var):\n        mn = ma.masked_values(dataset.t_mn.t_mn[dn, :, yn, xn].reshape(\n            dataset['depth'].shape[0]), dataset.t_mn.attributes['_FillValue'])\n        sd = ma.masked_values(dataset.t_sd.t_sd[dn, :, yn, xn].reshape(\n            dataset['depth'].shape[0]), dataset.t_sd.attributes['_FillValue'])\n        # se = ma.masked_values(dataset.t_se.t_se[dn, :, yn, xn].reshape(\n        #    dataset['depth'].shape[0]), dataset.t_se.attributes['_FillValue'])\n        # Use this in the future. A minimum # of samples\n        # dd = ma.masked_values(dataset.t_dd.t_dd[dn, :, yn, xn].reshape(\n        #    dataset['depth'].shape[0]), dataset.t_dd.attributes['_FillValue'])\n    elif re.match(\"salinity\\d?$\", var):\n        mn = ma.masked_values(dataset.s_mn.s_mn[dn, :, yn, xn].reshape(\n            dataset['depth'].shape[0]), dataset.s_mn.attributes['_FillValue'])\n        sd = ma.masked_values(dataset.s_sd.s_sd[dn, :, yn, xn].reshape(\n            dataset['depth'].shape[0]), dataset.s_sd.attributes['_FillValue'])\n        # dd = ma.masked_values(dataset.s_dd.s_dd[dn, :, yn, xn].reshape(\n        #    dataset['depth'].shape[0]), dataset.s_dd.attributes['_FillValue'])\n    zwoa = ma.array(dataset.depth[:])\n\n    ind = (depth <= zwoa.max()) & (depth >= zwoa.min())\n    # Mean value profile\n    f = interp1d(zwoa[~ma.getmaskarray(mn)].compressed(), mn.compressed())\n    mn_interp = ma.masked_all(depth.shape)\n    mn_interp[ind] = f(depth[ind])\n    # The stdev profile\n    f = interp1d(zwoa[~ma.getmaskarray(sd)].compressed(), sd.compressed())\n    sd_interp = ma.masked_all(depth.shape)\n    sd_interp[ind] = f(depth[ind])\n\n    output = {'woa_an': mn_interp, 'woa_sd': sd_interp}\n\n    return output", "response": "Reads the WOA Monthly Climatologic Mean and Standard Deviation from WOA and returns the corresponding WOA values for the given time lon and depth."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef woa_track_from_file(d, lat, lon, filename, varnames=None):\n    d = np.asanyarray(d)\n    lat = np.asanyarray(lat)\n    lon = np.asanyarray(lon)\n\n    lon[lon < 0] += 360\n\n    doy = np.array([int(dd.strftime('%j')) for dd in d])\n\n    nc = netCDF4.Dataset(expanduser(filename), 'r')\n\n    if varnames is None:\n        varnames = {}\n        for v in nc.variables.keys():\n            if nc.variables[v].dimensions == \\\n                    (u'time', u'depth', u'lat', u'lon'):\n                        varnames[v] = v\n\n    output = {}\n    for v in varnames:\n        output[v] = []\n\n    for d_n, lat_n, lon_n in zip(doy, lat, lon):\n        # Get the nearest point. In the future interpolate.\n        n_d = (np.abs(d_n - nc.variables['time'][:])).argmin()\n        n_x = (np.abs(lon_n - nc.variables['lon'][:])).argmin()\n        n_y = (np.abs(lat_n - nc.variables['lat'][:])).argmin()\n\n        for v in varnames:\n            output[v].append(nc.variables[varnames[v]][n_d, 0, n_y, n_x])\n\n    for v in varnames:\n        output[v] = ma.fix_invalid(output[v])\n\n    return output", "response": "Temporary solution for WOA for surface track"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncrop a subset of the dataset for each var in the list of var.", "response": "def crop(self, doy, depth, lat, lon, var):\n        \"\"\" Crop a subset of the dataset for each var\n\n            Given doy, depth, lat and lon, it returns the smallest subset\n              that still contains the requested coordinates inside it.\n\n            It handels special cases like a region around greenwich and\n            the international date line.\n\n            Accepts 0 to 360 and -180 to 180 longitude reference.\n\n            It extends time and longitude coordinates, so simplify the use\n               of series. For example, a ship track can be requested with\n               a longitude sequence like [352, 358, 364, 369, 380], and\n               the equivalent for day of year above 365.\n        \"\"\"\n        dims, idx = cropIndices(self.dims, lat, lon, depth, doy)\n        subset = {}\n        for v in var:\n            subset[v] = ma.asanyarray([\n                self.ncs[tnn][v][0, idx['zn'], idx['yn'], idx['xn']] \\\n                        for tnn in idx['tn']])\n        return subset, dims"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpolate(self, doy, depth, lat, lon, var):\n        subset, dims = self.crop(doy, depth, lat, lon, var)\n\n        # Subset contains everything requested. No need to interpolate.\n        if np.all([d in dims['time'] for d in doy]) & \\\n                np.all([z in dims['depth'] for z in depth]) & \\\n                np.all([y in dims['lat'] for y in lat]) & \\\n                np.all([x in dims['lon'] for x in lon]):\n                    dn = np.nonzero([d in doy for d in dims['time']])[0]\n                    zn = np.nonzero([z in depth for z in dims['depth']])[0]\n                    yn = np.nonzero([y in lat for y in dims['lat']])[0]\n                    xn = np.nonzero([x in lon for x in dims['lon']])[0]\n                    output = {}\n                    for v in subset:\n                        # output[v] = subset[v][dn, zn, yn, xn]\n                        # Seriously that this is the way to do it?!!??\n                        output[v] = subset[v][:, :, :, xn][:, :, yn][:, zn][dn]\n                    return output\n\n        output = {}\n        for v in var:\n            output[v] = ma.masked_all(\n                    (doy.size, depth.size, lat.size, lon.size),\n                    dtype=subset[v].dtype)\n\n            # These interpolators don't understand Masked Arrays, but do NaN\n            if subset[v].dtype in ['int32']:\n                subset[v] = subset[v].astype('f')\n            subset[v][ma.getmaskarray(subset[v])] = np.nan\n            subset[v] = subset[v].data\n\n        # First linear interpolate on time.\n        if not (doy == dims['time']).all():\n            for v in subset.keys():\n                f = interp1d(dims['time'], subset[v], axis=0)\n                subset[v] = f(doy)\n            dims['time'] = np.atleast_1d(doy)\n\n        if not (np.all(lat == dims['lat']) and np.all(lon == dims['lon'])):\n            # Lat x Lon target coordinates are the same for all time and depth.\n            points_out = []\n            for latn in lat:\n                for lonn in lon:\n                    points_out.append([latn, lonn])\n            points_out = np.array(points_out)\n\n            # Interpolate on X/Y plane\n            for v in subset:\n                tmp = np.nan * np.ones(\n                        (doy.size, dims['depth'].size, lat.size, lon.size),\n                        dtype=subset[v].dtype)\n                for nt in range(doy.size):\n                    for nz in range(dims['depth'].size):\n                        data = subset[v][nt, nz]\n                        # The valid data\n                        idx = np.nonzero(~np.isnan(data))\n                        if idx[0].size > 0:\n                            points = np.array([\n                                dims['lat'][idx[0]], dims['lon'][idx[1]]]).T\n                            values = data[idx]\n                            # Interpolate along the dimensions that have more than\n                            #   one position, otherwise it means that the output\n                            #   is exactly on that coordinate.\n                            #ind = np.array([np.unique(points[:, i]).size > 1\n                            #    for i in range(points.shape[1])])\n                            #assert ind.any()\n\n                            try:\n                                values_out = griddata(\n                                    #np.atleast_1d(np.squeeze(points[:, ind])),\n                                    np.atleast_1d(np.squeeze(points)),\n                                    values,\n                                    #np.atleast_1d(np.squeeze(points_out[:, ind])))\n                                    np.atleast_1d(np.squeeze(points_out)))\n                            except:\n                                values_out = []\n                                for p in points_out:\n                                    try:\n                                        values_out.append(griddata(\n                                            np.atleast_1d(np.squeeze(points)),\n                                            values,\n                                            np.atleast_1d(np.squeeze(\n                                                p))))\n                                    except:\n                                        values_out.append(np.nan)\n                                values_out = np.array(values_out)\n\n                            # Remap the interpolated value back into a 4D array\n                            idx = np.isfinite(values_out)\n                            for [y, x], out in zip(\n                                    points_out[idx], values_out[idx]):\n                                tmp[nt, nz, y==lat, x==lon] = out\n                subset[v] = tmp\n\n        # Interpolate on z\n        same_depth = (np.shape(depth) == dims['depth'].shape) and \\\n                np.allclose(depth, dims['depth'])\n        if not same_depth:\n            for v in list(subset.keys()):\n                try:\n                    f = interp1d(dims['depth'], subset[v], axis=1, bounds_error=False)\n                    # interp1d does not handle Masked Arrays\n                    subset[v] = f(np.array(depth))\n                except:\n                    print(\"Fail to interpolate '%s' in depth\" % v)\n                    del(subset[v])\n\n        for v in subset:\n            if output[v].dtype in ['int32']:\n                subset[v] = np.round(subset[v])\n            output[v][:] = ma.fix_invalid(subset[v][:])\n\n        return output", "response": "Interpolate each var on the coordinates requested\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count(cls, path=None, objtype=None, query=None, **kwargs):\n        if not objtype:\n            objtype = cls.OBJTYPE\n        if not path:\n            path = cls.PATH\n        if not query:\n            query = kwargs\n        return objtype.db(path).find(query).count()", "response": "Like count but returns the number of objects that match the query rather than returning the objects that match the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iterator(cls, path=None, objtype=None, query=None, page_size=1000, **kwargs):\n        if not objtype:\n            objtype = cls.OBJTYPE\n        if not path:\n            path = cls.PATH\n        db = objtype.db(path)\n        if not query:\n            query = kwargs\n        results = list(db.find(query).sort(ID_KEY, ASCENDING).limit(page_size))\n        while results:\n            page = [objtype(path=path, _new_object=result) for result in results]\n            for obj in page:\n                yield obj\n            query[ID_KEY] = {GT: results[-1][ID_KEY]}\n            results = list(db.find(query).sort(ID_KEY, ASCENDING).limit(page_size))", "response": "Linear time constant memory iterator for a mongo collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new object in the database.", "response": "def insert(self, data, **kwargs):\n        \"\"\"\n        Calls the create method of OBJTYPE\n        \n        NOTE: this function is only properly usable on children classes that\n        have overridden either OBJTYPE or PATH.\n        \n        @param data: the data of the new object to be created\n        @param **kwargs: forwarded to create\n        \n        @raise DatabaseConflictError: if there is already an object with that\n            ID_KEY and overwrite == False\n        @raise MalformedObjectError: if a REQUIRED key of defaults is missing,\n            or if the ID_KEY of the object is None and random_id is False\n        \"\"\"\n        obj = self.OBJTYPE.create(data, path=self.PATH, **kwargs)\n        self.append(obj)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _move(self, new_path):\n        for elt in self:\n            DatabaseObject.create(elt, path=new_path)\n        for elt in self:\n            elt._collection.remove({ID_KEY: elt[ID_KEY]})", "response": "Moves the collection to a different database path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of local_pairwise alignment.", "response": "def pair_hmm_align_unaligned_seqs(seqs, moltype=DNA_cogent, params={}):\n    \"\"\"\n        Checks parameters for pairwise alignment, returns alignment.\n\n        Code from Greg Caporaso.\n    \"\"\"\n\n    seqs = LoadSeqs(data=seqs, moltype=moltype, aligned=False)\n    try:\n        s1, s2 = seqs.values()\n    except ValueError:\n        raise ValueError(\n            \"Pairwise aligning of seqs requires exactly two seqs.\")\n\n    try:\n        gap_open = params['gap_open']\n    except KeyError:\n        gap_open = 5\n    try:\n        gap_extend = params['gap_extend']\n    except KeyError:\n        gap_extend = 2\n    try:\n        score_matrix = params['score_matrix']\n    except KeyError:\n        score_matrix = make_dna_scoring_dict(\n            match=1, transition=-1, transversion=-1)\n\n    return local_pairwise(s1, s2, score_matrix, gap_open, gap_extend)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def viewers_js(request):\n    '''\n    Viewers determines the viewers installed based on settings, then uses the\n    conversion infrastructure to convert all these JS files into a single JS\n    bundle, that is then served. As with media, it will simply serve a cached\n    version if necessary.\n    '''\n    # Generates single bundle as such:\n    # BytesResource -> ViewerNodePackageBuilder -> nodepackage -> ... -> min.js\n    response = singletons.server.response\n\n    # Create a viewers resource, which is simply a JSON encoded description of\n    # the viewers necessary for this viewers bundle.\n    viewers_resource = singletons.viewers.get_resource()\n    url_string = viewers_resource.url_string\n\n    target_ts = TypeString('min.js')  # get a minified JS bundle\n    target_resource = TypedResource(url_string, target_ts)\n\n    if target_resource.cache_exists():\n        return await response.file(target_resource.cache_path, headers={\n            'Content-Type': 'application/javascript',\n        })\n\n    # Otherwise, does not exist, save this descriptor to cache and kick off\n    # conversion process\n    if not viewers_resource.cache_exists():\n        viewers_resource.save()\n\n    # Queue up a single function that will in turn queue up conversion process\n    await singletons.workers.async_enqueue_sync(\n        enqueue_conversion_path,\n        url_string,\n        str(target_ts),\n        singletons.workers.enqueue_convert\n    )\n\n    return response.text(NOT_LOADED_JS, headers={\n        'Content-Type': 'application/javascript',\n    })", "response": "This function generates a single bundle that contains all the viewers needed for this bundle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a tree from an alignment object", "response": "def build_tree_from_alignment(aln, moltype=DNA, best_tree=False, params=None):\n    \"\"\"Returns a tree from alignment\n\n    Will check MolType of aln object\n    \"\"\"\n    if params is None:\n        params = {}\n\n    if moltype == DNA or moltype == RNA:\n        params['-nt'] = True\n    elif moltype == PROTEIN:\n        params['-nt'] = False\n    else:\n        raise ValueError, \\\n                \"FastTree does not support moltype: %s\" % moltype.label\n\n    if best_tree:\n        params['-slow'] = True\n\n    #Create mapping between abbreviated IDs and full IDs\n    int_map, int_keys = aln.getIntMap()\n    #Create SequenceCollection from int_map.\n    int_map = SequenceCollection(int_map,MolType=moltype)\n\n    app = FastTree(params=params)\n\n    result = app(int_map.toFasta())\n    tree = DndParser(result['Tree'].read(), constructor=PhyloNode)\n    #remap tip names\n    for tip in tree.tips():\n        tip.Name = int_keys[tip.Name]\n\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_objects(self, uri, _oid=None, _start=None, _end=None,\n                    load_kwargs=None, **kwargs):\n        '''\n        Load and transform csv data into a list of dictionaries.\n\n        Each row in the csv will result in one dictionary in the list.\n\n        :param uri: uri (file://, http(s)://) of csv file to load\n        :param _oid:\n            column or func to apply to map _oid in all resulting objects\n        :param _start:\n            column or func to apply to map _start in all resulting objects\n        :param _end:\n            column or func to apply to map _end in all resulting objects\n        :param kwargs: kwargs to pass to pandas.read_csv method\n\n        _start and _oid arguments can be a column name or a function\n        which accepts a single argument -- the row being extracted.\n\n        If either is a column name (string) then that column will be applied\n        as _oid for each object generated.\n\n        If either is a function, the function will be applied per each row\n        and the result of the function will be assigned to the _start\n        or _oid, respectively.\n        '''\n        load_kwargs = load_kwargs or {}\n        objects = load(path=uri, filetype='csv', **load_kwargs)\n\n        k = itertools.count(1)\n        now = utcnow()\n        __oid = lambda o: k.next()\n\n        _oid = _oid or __oid\n        _start = _start or now\n        _end = _end or None\n\n        def is_callable(v):\n            _v = type(v)\n            _ = True if _v is type or hasattr(v, '__call__') else False\n            return _\n\n        for obj in objects:\n            obj['_oid'] = _oid(obj) if is_callable(_oid) else _oid\n            obj['_start'] = _start(obj) if is_callable(_start) else _start\n            obj['_end'] = _end(obj) if is_callable(_end) else _end\n            self.container.add(obj)\n\n        return super(Rows, self).get_objects(**kwargs)", "response": "Load and transform csv data into a list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getSpecs(self):\n        content = {\n            \"databaseName\" : self.databaseName,\n            \"roles\" : self.roles,\n            \"username\" : self.username,\n            \"password\" : self.password\n        }\n        \n        return content", "response": "Get the specs of the object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_roles(self, databaseName, roleNames, collectionName=None):\n        for roleName in roleNames:\n            self.add_role(databaseName, roleName, collectionName)", "response": "Add multiple roles to the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_role(self, databaseName, roleName, collectionName=None):\n        role = {\"databaseName\" : databaseName,\n                \"roleName\" : roleName}\n        \n        if collectionName:\n            role[\"collectionName\"] = collectionName\n        \n        # Check atlas constraints\n        if collectionName and roleName not in [RoleSpecs.read, RoleSpecs.readWrite]:\n            raise ErrRole(\"Permissions [%s] not available for a collection\" % roleName)\n        elif not collectionName and roleName not in [RoleSpecs.read, RoleSpecs.readWrite, RoleSpecs.dbAdmin] and databaseName != \"admin\":\n            raise ErrRole(\"Permissions [%s] is only available for admin database\" % roleName)\n        \n        if role not in self.roles:\n            self.roles.append(role)", "response": "Add one role to the atlas."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_roles(self, databaseName, roleNames, collectionName=None):\n        for roleName in roleNames:\n            self.remove_role(databaseName, roleName, collectionName)", "response": "Remove multiple roles from a database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove one role from the set of roles.", "response": "def remove_role(self, databaseName, roleName, collectionName=None):\n        \"\"\"Remove one role\n        \n        Args:\n            databaseName (str): Database Name\n            roleName (RoleSpecs): role\n            \n        Keyword Args:\n            collectionName (str): Collection\n        \"\"\"\n        role = {\"databaseName\" : databaseName,\n                \"roleName\" : roleName}\n        \n        if collectionName:\n            role[\"collectionName\"] = collectionName\n        \n        if role in self.roles:\n            self.roles.remove(role)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getSpecs(self):\n        \n        content = {}\n        \n        if len(self.roles) != 0:\n            content[\"roles\"] = self.roles\n        \n        if self.password:\n            content[\"password\"] = self.password\n        \n        return content", "response": "Get the object s properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sumaclust_denovo_cluster(seq_path=None,\n                             result_path=None,\n                             shortest_len=True,\n                             similarity=0.97,\n                             threads=1,\n                             exact=False,\n                             HALT_EXEC=False\n                             ):\n    \"\"\" Function  : launch SumaClust de novo OTU picker\n\n        Parameters: seq_path, filepath to reads;\n                    result_path, filepath to output OTU map;\n                    shortest_len, boolean;\n                    similarity, the similarity threshold (between (0,1]);\n                    threads, number of threads to use;\n                    exact, boolean to perform exact matching\n\n        Return    : clusters, list of lists\n    \"\"\"\n\n    # Sequence path is mandatory\n    if (seq_path is None\n            or not exists(seq_path)):\n        raise ValueError(\"Error: FASTA query sequence filepath is \"\n                         \"mandatory input.\")\n\n    # Output directory is mandatory\n    if (result_path is None\n            or not isdir(dirname(realpath(result_path)))):\n        raise ValueError(\"Error: output directory is mandatory input.\")\n\n    # Instantiate the object\n    sumaclust = Sumaclust(HALT_EXEC=HALT_EXEC)\n\n    # Set the OTU-map filepath\n    sumaclust.Parameters['-O'].on(result_path)\n\n    # Set the similarity threshold\n    if similarity is not None:\n        sumaclust.Parameters['-t'].on(similarity)\n\n    # Set the option to perform exact clustering (default: False)\n    if exact:\n        sumaclust.Parameters['-e'].on()\n\n    # Turn off option for reference sequence length to be the shortest\n    if not shortest_len:\n        sumaclust.Parameters['-l'].off()\n\n    # Set the number of threads\n    if threads > 0:\n        sumaclust.Parameters['-p'].on(threads)\n    else:\n        raise ValueError(\"Number of threads must be positive.\")\n\n    # Launch SumaClust,\n    # set the data string to include the read filepath\n    # (to be passed as final arguments in the sumaclust command)\n    app_result = sumaclust(seq_path)\n\n    # Put clusters into a list of lists\n    f_otumap = app_result['OtuMap']\n    clusters = [line.strip().split('\\t')[1:] for line in f_otumap]\n\n    # Return clusters\n    return clusters", "response": "Function that launches a SumaClust de novo OTU cluster"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_result_paths(self, data):\n\n        result = {}\n\n        # OTU map (mandatory output)\n        result['OtuMap'] = ResultPath(Path=self.Parameters['-O'].Value,\n                                      IsWritten=True)\n\n        # SumaClust will not produce any output file if the\n        # input file was empty, so we create an empty\n        # output file\n        if not isfile(result['OtuMap'].Path):\n            otumap_f = open(result['OtuMap'].Path, 'w')\n            otumap_f.close()\n\n        return result", "response": "Set the result paths\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates clusters and fasta file of dereplicated subsequences Parameters ---------- fasta_filepath : string input filepath of fasta file to be dereplicated output_filepath : string write the dereplicated sequences to output_filepath working_dir : string, optional directory path for storing intermediate output output_uc : boolean, optional uutput dereplication results in a file using a uclust-like format strand : string, optional when searching for strictly identical sequences, check the 'strand' only (default: both) or check the plus strand only maxuniquesize : integer, optional discard sequences with an abundance value greater than maxuniquesize minuniquesize : integer, optional discard sequences with an abundance value smaller than integer sizein : boolean, optional take into account the abundance annotations present in the input fasta file, (search for the pattern \"[>;]size=integer[;]\" in sequence headers) sizeout : boolean, optional add abundance annotations to the output fasta file (add the pattern \";size=integer;\" to sequence headers) log_name : string, optional specifies log filename HALT_EXEC : boolean, optional used for debugging app controller Return ------ output_filepath : string filepath to dereplicated fasta file uc_filepath : string filepath to dereplication results in uclust-like format log_filepath : string filepath to log file", "response": "def vsearch_dereplicate_exact_seqs(\n    fasta_filepath,\n    output_filepath,\n    output_uc=False,\n    working_dir=None,\n    strand=\"both\",\n    maxuniquesize=None,\n    minuniquesize=None,\n    sizein=False,\n    sizeout=True,\n    log_name=\"derep.log\",\n    HALT_EXEC=False):\n    \"\"\" Generates clusters and fasta file of\n        dereplicated subsequences\n\n        Parameters\n        ----------\n\n        fasta_filepath : string\n           input filepath of fasta file to be dereplicated\n        output_filepath : string\n           write the dereplicated sequences to output_filepath\n        working_dir : string, optional\n           directory path for storing intermediate output\n        output_uc : boolean, optional\n           uutput dereplication results in a file using a\n           uclust-like format\n        strand : string, optional\n           when searching for strictly identical sequences,\n           check the 'strand' only (default: both) or\n           check the plus strand only\n        maxuniquesize : integer, optional\n           discard sequences with an abundance value greater\n           than maxuniquesize\n        minuniquesize : integer, optional\n           discard sequences with an abundance value smaller\n           than integer\n        sizein : boolean, optional\n           take into account the abundance annotations present in\n           the input fasta file,  (search for the pattern\n           \"[>;]size=integer[;]\" in sequence headers)\n        sizeout : boolean, optional\n           add abundance annotations to the output fasta file\n           (add the pattern \";size=integer;\" to sequence headers)\n        log_name : string, optional\n           specifies log filename\n        HALT_EXEC : boolean, optional\n           used for debugging app controller\n\n        Return\n        ------\n\n        output_filepath : string\n           filepath to dereplicated fasta file\n        uc_filepath : string\n           filepath to dereplication results in uclust-like format\n        log_filepath : string\n           filepath to log file\n    \"\"\"\n\n    # write all vsearch output files to same directory\n    # as output_filepath if working_dir is not specified\n    if not working_dir:\n        working_dir = dirname(abspath(output_filepath))\n\n    app = Vsearch(WorkingDir=working_dir, HALT_EXEC=HALT_EXEC)\n\n    log_filepath = join(working_dir, log_name)\n    uc_filepath = None\n    if output_uc:\n        root_name = splitext(abspath(output_filepath))[0]\n        uc_filepath = join(working_dir, '%s.uc' % root_name)\n        app.Parameters['--uc'].on(uc_filepath)\n\n    if maxuniquesize:\n        app.Parameters['--maxuniquesize'].on(maxuniquesize)\n    if minuniquesize:\n        app.Parameters['--minuniquesize'].on(minuniquesize)\n    if sizein:\n        app.Parameters['--sizein'].on()\n    if sizeout:\n        app.Parameters['--sizeout'].on()\n    if (strand == \"both\" or strand == \"plus\"):\n        app.Parameters['--strand'].on(strand)\n    else:\n        raise ValueError(\"Option --strand accepts only 'both'\"\n                         \"or 'plus' values\")\n    app.Parameters['--derep_fulllength'].on(fasta_filepath)\n    app.Parameters['--output'].on(output_filepath)\n    app.Parameters['--log'].on(log_filepath)\n\n    app_result = app()\n\n    return output_filepath, uc_filepath, log_filepath"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vsearch_sort_by_abundance(\n    fasta_filepath,\n    output_filepath,\n    working_dir=None,\n    minsize=None,\n    maxsize=None,\n    log_name=\"abundance_sort.log\",\n    HALT_EXEC=False):\n    \"\"\" Fasta entries are sorted by decreasing abundance\n        (Fasta entries are assumed to be dereplicated with\n        the pattern \"[>;]size=integer[;]\" present in the\n        read label, ex. use function vsearch_dereplicate_exact_seqs\n        prior to calling this function)\n\n        Parameters\n        ----------\n\n        fasta_filepath : string\n           input fasta file (dereplicated fasta)\n        output_filepath : string\n           output filepath for the sorted sequences in fasta format\n        working_dir : string, optional\n           working directory to store intermediate files\n        minsize : integer, optional\n           discard sequences with an abundance value smaller than\n           minsize\n        maxsize : integer, optional\n           discard sequences with an abundance value greater than\n           maxsize\n        log_name : string, optional\n           log filename\n        HALT_EXEC : boolean, optional\n           used for debugging app controller\n\n        Return\n        ------\n\n        output_filepath : string\n           filepath to sorted fasta file\n        log_filepath : string\n           filepath to log file\n    \"\"\"\n\n    # set working dir to same directory as the output\n    # file (if not provided)\n    if not working_dir:\n        working_dir = dirname(output_filepath)\n\n    app = Vsearch(WorkingDir=working_dir, HALT_EXEC=HALT_EXEC)\n\n    log_filepath = join(working_dir, log_name)\n\n    if minsize:\n        app.Parameters['--minsize'].on(minsize)\n\n    if maxsize:\n        app.Parameters['--maxsize'].on(maxsize)\n\n    app.Parameters['--sortbysize'].on(fasta_filepath)\n    app.Parameters['--output'].on(output_filepath)\n    app.Parameters['--log'].on(log_filepath)\n\n    app_result = app()\n\n    return output_filepath, log_filepath", "response": "This function sorts the sequences in the specified fasta file using VSEARCH."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects chimeras present in the file and filter them using VSEARCH.", "response": "def vsearch_chimera_filter_de_novo(\n    fasta_filepath,\n    working_dir,\n    output_chimeras=True,\n    output_nonchimeras=True,\n    output_alns=False,\n    output_tabular=False,\n    log_name=\"vsearch_uchime_de_novo_chimera_filtering.log\",\n    HALT_EXEC=False):\n    \"\"\" Detect chimeras present in the fasta-formatted filename,\n        without external references (i.e. de novo). Automatically\n        sort the sequences in filename by decreasing abundance\n        beforehand. Output chimeras and non-chimeras to FASTA files\n        and/or 3-way global alignments and/or tabular output.\n\n        Parameters\n        ----------\n\n        fasta_filepath : string\n           input fasta file (dereplicated fasta with pattern\n           [>;]size=integer[;] in the fasta header)\n        working_dir : string\n           directory path for all output files\n        output_chimeras : boolean, optional\n           output chimeric sequences to file, in fasta format\n        output_nonchimeras : boolean, optional\n           output nonchimeric sequences to file, in fasta format\n        output_alns : boolean, optional\n           output 3-way global alignments (parentA, parentB, chimera)\n           in human readable format to file\n        output_tabular : boolean, optional\n           output results using the uchime tab-separated format of\n           18 fields (see Vsearch user manual)\n        HALT_EXEC : boolean, optional\n           used for debugging app controller\n\n        Return\n        ------\n\n        output_chimera_filepath : string\n           filepath to chimeric fasta sequences\n        output_non_chimera_filepath : string\n           filepath to nonchimeric fasta sequences\n        output_alns_filepath : string\n           filepath to chimeric sequences alignment\n           file\n        output_tabular_filepath : string\n           filepath to chimeric sequences tabular\n           output file\n        log_filepath : string\n           filepath to log file\n    \"\"\"\n\n    app = Vsearch(WorkingDir=working_dir, HALT_EXEC=HALT_EXEC)\n\n    if not (output_chimeras or\n            output_nonchimeras or\n            output_alns or\n            output_tabular):\n        raise ValueError(\"At least one output format (output_chimeras,\"\n                         \"output_nonchimeras, output_alns, output_tabular)\"\n                         \"must be selected\")\n\n    output_chimera_filepath = None\n    output_non_chimera_filepath = None\n    output_alns_filepath = None\n    output_tabular_filepath = None\n\n    # set output filepaths\n    if output_chimeras:\n        output_chimera_filepath = join(working_dir, 'uchime_chimeras.fasta')\n        app.Parameters['--chimeras'].on(output_chimera_filepath)\n    if output_nonchimeras:\n        output_non_chimera_filepath = join(working_dir,\n                                           'uchime_non_chimeras.fasta')\n        app.Parameters['--nonchimeras'].on(output_non_chimera_filepath)\n    if output_alns:\n        output_alns_filepath = join(working_dir, 'uchime_alignments.txt')\n        app.Parameters['--uchimealns'].on(output_alns_filepath)\n    if output_tabular:\n        output_tabular_filepath = join(working_dir, 'uchime_tabular.txt')\n        app.Parameters['--uchimeout'].on(output_tabular_filepath)\n    log_filepath = join(working_dir, log_name)\n\n    app.Parameters['--uchime_denovo'].on(fasta_filepath)\n    app.Parameters['--log'].on(log_filepath)\n\n    app_result = app()\n\n    return output_chimera_filepath, output_non_chimera_filepath,\\\n        output_alns_filepath, output_tabular_filepath, log_filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_result_paths(self, data):\n\n        result = {}\n\n        result['Output'] = ResultPath(\n            Path=self.Parameters['--output'].Value,\n            IsWritten=self.Parameters['--output'].isOn())\n\n        result['ClusterFile'] = ResultPath(\n            Path=self.Parameters['--uc'].Value,\n            IsWritten=self.Parameters['--uc'].isOn())\n\n        # uchime 3-way global alignments\n        result['Output_aln'] = ResultPath(\n            Path=self.Parameters['--uchimealns'].Value,\n            IsWritten=self.Parameters['--uchimealns'].isOn())\n\n        # uchime tab-separated format\n        result['Output_tabular'] = ResultPath(\n            Path=self.Parameters['--uchimeout'].Value,\n            IsWritten=self.Parameters['--uchimeout'].isOn())\n\n        # chimeras fasta file output\n        result['Output_chimeras'] = ResultPath(\n            Path=self.Parameters['--chimeras'].Value,\n            IsWritten=self.Parameters['--chimeras'].isOn())\n\n        # nonchimeras fasta file output\n        result['Output_nonchimeras'] = ResultPath(\n            Path=self.Parameters['--nonchimeras'].Value,\n            IsWritten=self.Parameters['--nonchimeras'].isOn())\n\n        # log file\n        result['LogFile'] = ResultPath(\n            Path=self.Parameters['--log'].Value,\n            IsWritten=self.Parameters['--log'].isOn())\n\n        return result", "response": "Set the result paths based on the command line parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract(filename, doy, latitude, longitude, depth):\n    assert np.size(doy) == 1\n    assert np.size(latitude) == 1\n    assert np.size(longitude) == 1\n    assert np.size(depth) == 1\n\n    assert (longitude >= 0) & (longitude <= 360)\n    assert depth >= 0\n\n    nc = netCDF4.Dataset(filename)\n\n    t = 2 * np.pi * doy/366\n\n    Z = np.absolute(nc['depth'][:] - depth).argmin()\n    I = np.absolute(nc['lat'][:] - latitude).argmin()\n    J = np.absolute(nc['lon'][:] - longitude).argmin()\n\n    # Naive solution\n    value = nc['mean'][:, I, J]\n    value[:64] += nc['an_cos'][Z, I, J] * np.cos(t) + \\\n            nc['an_sin'][:, I, J] * np.sin(t)\n    value[:55] += nc['sa_cos'][Z, I, J] * np.cos(2*t) + \\\n            nc['sa_sin'][:, I, J] * np.sin(2*t)\n    value = value[Z]\n\n    std = nc['std_dev'][Z, I, J]\n\n    return value, std", "response": "Extract the value and standard deviation from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef crop(self, doy, depth, lat, lon, var):\n        dims, idx = cropIndices(self.dims, lat, lon, depth)\n\n        dims['time'] = np.atleast_1d(doy)\n        idx['tn'] = np.arange(dims['time'].size)\n\n        # Temporary solution. Create an object for CARS dataset\n        xn = idx['xn']\n        yn = idx['yn']\n        zn = idx['zn']\n        tn = idx['tn']\n\n        subset = {}\n        for v in var:\n            if v == 'mn':\n                mn = []\n                for d in doy:\n                    t = 2 * np.pi * d/366\n                    # Naive solution\n                    # FIXME: This is not an efficient solution.\n                    value = self.ncs[0]['mean'][:, yn, xn]\n                    value[:64] += self.ncs[0]['an_cos'][:, yn, xn] * np.cos(t) + \\\n                        self.ncs[0]['an_sin'][:, yn, xn] * np.sin(t)\n                    value[:55] += self.ncs[0]['sa_cos'][:, yn, xn] * np.cos(2*t) + \\\n                        self.ncs[0]['sa_sin'][:, yn, xn] * np.sin(2*t)\n                    mn.append(value[zn])\n\n                subset['mn'] = ma.asanyarray(mn)\n            else:\n                subset[v] = ma.asanyarray(\n                        doy.size * [self[v][zn, yn, xn]])\n        return subset, dims", "response": "Crop a subset of the dataset for each var in doy and depth lat and lon."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninterpolate each var on the coordinates requested by the user.", "response": "def interpolate(self, doy, depth, lat, lon, var):\n        \"\"\" Interpolate each var on the coordinates requested\n\n        \"\"\"\n\n        subset, dims = self.crop(doy, depth, lat, lon, var)\n\n        if np.all([d in dims['time'] for d in doy]) & \\\n                np.all([z in dims['depth'] for z in depth]) & \\\n                np.all([y in dims['lat'] for y in lat]) & \\\n                np.all([x in dims['lon'] for x in lon]):\n                    dn = np.nonzero([d in doy for d in dims['time']])[0]\n                    zn = np.nonzero([z in depth for z in dims['depth']])[0]\n                    yn = np.nonzero([y in lat for y in dims['lat']])[0]\n                    xn = np.nonzero([x in lon for x in dims['lon']])[0]\n                    output = {}\n                    for v in subset:\n                        # output[v] = subset[v][dn, zn, yn, xn]\n                        # Seriously that this is the way to do it?!!??\n                        output[v] = subset[v][:, :, :, xn][:, :, yn][:, zn][dn]\n                    return output\n\n        # The output coordinates shall be created only once.\n        points_out = []\n        for doyn in doy:\n            for depthn in depth:\n                for latn in lat:\n                    for lonn in lon:\n                        points_out.append([doyn, depthn, latn, lonn])\n        points_out = np.array(points_out)\n\n        output = {}\n        for v in var:\n            output[v] = ma.masked_all(\n                    (doy.size, depth.size, lat.size, lon.size),\n                    dtype=subset[v].dtype)\n\n            # The valid data\n            idx = np.nonzero(~ma.getmaskarray(subset[v]))\n\n            if idx[0].size > 0:\n                points = np.array([\n                    dims['time'][idx[0]], dims['depth'][idx[1]],\n                    dims['lat'][idx[2]], dims['lon'][idx[3]]]).T\n                values = subset[v][idx]\n\n                # Interpolate along the dimensions that have more than one\n                #   position, otherwise it means that the output is exactly\n                #   on that coordinate.\n                ind = np.array(\n                        [np.unique(points[:, i]).size > 1 for i in\n                            range(points.shape[1])])\n                assert ind.any()\n\n                # These interpolators understand NaN, but not masks.\n                values[ma.getmaskarray(values)] = np.nan\n\n                values_out = griddata(\n                        np.atleast_1d(np.squeeze(points[:, ind])),\n                        values,\n                        np.atleast_1d(np.squeeze(points_out[:, ind]))\n                        )\n\n                # Remap the interpolated value back into a 4D array\n                idx = np.isfinite(values_out)\n                for [t, z, y, x], out in zip(points_out[idx], values_out[idx]):\n                    output[v][t==doy, z==depth, y==lat, x==lon] = out\n\n            output[v] = ma.fix_invalid(output[v])\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmark the user as read", "response": "def mark_as_read(self, room_name):\n        \"\"\"\n        message_ids return an array\n        with unread message ids ['131313231', '323131']\n        \"\"\"\n        api_meth = self.set_user_items_url(room_name)\n        message_ids = self.unread_items(room_name).get('chat')\n        if message_ids:\n            return self.post(api_meth, data={'chat': message_ids})\n        else:\n            raise GitterItemsError(room_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init(cls, site):\n        bash_header = \"\"\n        for k,v in site.items():\n            bash_header += \"%s=%s\" % (k.upper(), v)\n            bash_header += '\\n'\n        site['bash_header'] = bash_header\n\n        # TODO: execute before_deploy\n        # P.S. running init_before seems like impossible, because the file hasn't been rendered.\n        if cls.git_template:\n            # do render from git repo\n            print \"Cloning template files...\"\n            repo_local_copy = utils.clone_git_repo(cls.git_template_url)\n            print \"Rendering files from templates...\"\n            target_path = os.getcwd()\n            settings_dir = '/'.join(site['django_settings'].split('.')[:-1])\n            site['project_name'] = settings_dir.replace('/', '.')\n            settings_dir_path = target_path\n            if settings_dir:\n                settings_dir_path +=  '/' + settings_dir\n            utils.render_from_repo(repo_local_copy, target_path, site, settings_dir_path)\n        else:\n            cls._create_configs(site)\n        print cls.setup_instructions\n        # TODO: execute after_deploy\n        run_hooks('init_after')", "response": "Initializes the site dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the configuration files for the current project.", "response": "def _create_configs(cls, site):\n        \"\"\"\n        This is going to generate the following configuration:\n        * wsgi.py\n        * <provider>.yml\n        * settings_<provider>.py\n        \"\"\"\n        provider = cls.name\n\n        cls._render_config('wsgi.py', 'wsgi.py', site)\n\n        # create yaml file\n        yaml_template_name = os.path.join(provider, cls.provider_yml_name)\n        cls._render_config(cls.provider_yml_name, yaml_template_name, site)\n\n        # create requirements file\n        # don't do anything if the requirements file is called requirements.txt and in the root of the project\n        requirements_filename = \"requirements.txt\"\n        if site['requirements'] != requirements_filename:   # providers expect the file to be called requirements.txt\n            requirements_template_name = os.path.join(provider, requirements_filename)\n            cls._render_config(requirements_filename, requirements_template_name, site)\n\n        # create settings file\n        settings_template_name = os.path.join(provider, 'settings_%s.py' % provider)\n        settings_path = site['django_settings'].replace('.', '/') + '_%s.py' % provider\n        cls._render_config(settings_path, settings_template_name, site)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _render_config(cls, dest, template_name, template_args):\n        template_args = template_args.copy()\n\n        # Substitute values here\n        pyversion = template_args['pyversion']\n        template_args['pyversion'] = cls.PYVERSIONS[pyversion]\n\n        template = template_env.get_template(template_name)\n        contents = template.render(**template_args)\n        _write_file(dest, contents)", "response": "Renders and writes a template_name to a dest given some template_args."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse args and returns an action and the args that were parsed", "response": "def parse_args_to_action_args(self, argv=None):\n        '''\n        Parses args and returns an action and the args that were parsed\n        '''\n        args = self.parse_args(argv)\n        action = self.subcommands[args.subcommand][1]\n        return action, args"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_subparser(self, action, name, description='', arguments={}):\n        '''\n        Registers a new subcommand with a given function action.\n\n        If the function action is synchronous\n        '''\n        action = coerce_to_synchronous(action)\n        opts = []\n        for flags, kwargs in arguments.items():\n            if isinstance(flags, str):\n                flags = tuple([flags])\n            opts.append((flags, kwargs))\n        self.subcommands[name] = (description, action, opts)", "response": "Registers a new subcommand with a given function action."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subcommand(self, description='', arguments={}):\n        '''\n        Decorator for quickly adding subcommands to the omnic CLI\n        '''\n        def decorator(func):\n            self.register_subparser(\n                func,\n                func.__name__.replace('_', '-'),\n                description=description,\n                arguments=arguments,\n            )\n            return func\n        return decorator", "response": "Decorator for quickly adding subcommands to the omnic CLI\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_uclust_pw_alignment_results(fasta_pairs_lines, uc_lines):\n    alignments = get_next_two_fasta_records(fasta_pairs_lines)\n    for hit in get_next_record_type(uc_lines, 'H'):\n        matching_strand = hit[4]\n        if matching_strand == '-':\n            strand_id = '-'\n            target_rev_match = True\n        elif matching_strand == '+':\n            strand_id = '+'\n            target_rev_match = False\n        elif matching_strand == '.':\n            # protein sequence, so no strand information\n            strand_id = ''\n            target_rev_match = False\n        else:\n            raise UclustParseError(\"Unknown strand type: %s\" % matching_strand)\n        uc_query_id = hit[8]\n        uc_target_id = hit[9]\n        percent_id = float(hit[3])\n\n        fasta_pair = alignments.next()\n\n        fasta_query_id = fasta_pair[0][0]\n        aligned_query = fasta_pair[0][1]\n\n        if fasta_query_id != uc_query_id:\n            raise UclustParseError(\"Order of fasta and uc files do not match.\" +\n                                   \" Got query %s but expected %s.\" %\n                                   (fasta_query_id, uc_query_id))\n\n        fasta_target_id = fasta_pair[1][0]\n        aligned_target = fasta_pair[1][1]\n\n        if fasta_target_id != uc_target_id + strand_id:\n            raise UclustParseError(\"Order of fasta and uc files do not match.\" +\n                                   \" Got target %s but expected %s.\" %\n                                   (fasta_target_id, uc_target_id + strand_id))\n\n        if target_rev_match:\n            query_id = uc_query_id + ' RC'\n            aligned_query = DNA.rc(aligned_query)\n            target_id = uc_target_id\n            aligned_target = DNA.rc(aligned_target)\n        else:\n            query_id = uc_query_id\n            aligned_query = aligned_query\n            target_id = uc_target_id\n            aligned_target = aligned_target\n\n        yield (query_id, target_id, aligned_query, aligned_target, percent_id)", "response": "Process results of uclust search and align"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive an open. uc file return a list of clusters failures and new_seeds.", "response": "def clusters_from_uc_file(uc_lines,\n                          error_on_multiple_hits=True):\n    \"\"\" Given an open .uc file, return lists (clusters, failures, new_seeds)\n\n        uc_lines: open .uc file, or similar object -- this is the output\n         generated by uclust's -uc parameter\n        error_on_multiple_hits: if True (default), when a single query hits\n         to multiple seeds, as can happen when --allhits is passed to uclust,\n         throw a UclustParseError. if False, when a single query hits to\n         multiple seeds, it will appear in each cluster.\n\n        This function processes all hit (H), seed (S), and no hit (N) lines\n         to return all clusters, failures, and new_seeds generated in\n         a uclust run. failures should only arise when users have passed\n         --lib and --libonly, and a sequence doesn't cluster to any existing\n         reference database sequences.\n\n    \"\"\"\n    clusters = {}\n    failures = []\n    seeds = []\n    all_hits = set()\n    # the types of hit lines we're interested in here\n    # are hit (H), seed (S), library seed (L) and no hit (N)\n    hit_types = {}.fromkeys(list('HSNL'))\n    for record in get_next_record_type(uc_lines, hit_types):\n        hit_type = record[0]\n        # sequence identifiers from the fasta header lines only\n        # (no comment data) are stored to identify a sequence in\n        # a cluster -- strip off any comments here as this value\n        # is used in several places\n        query_id = record[8].split()[0]\n        target_cluster = record[9].split()[0]\n        if hit_type == 'H':\n            if error_on_multiple_hits and query_id in all_hits:\n                raise UclustParseError(\"Query id \" + query_id + \" hit multiple seeds. \"\n                                       \"This can happen if --allhits is \"\n                                       \"enabled in the call to uclust, which isn't supported by default. \"\n                                       \"Call clusters_from_uc_file(lines, error_on_multiple_hits=False) to \"\n                                       \"allow a query to cluster to multiple seeds.\")\n            else:\n                # add the hit to its existing cluster (either library\n                # or new cluster)\n                clusters[target_cluster].append(query_id)\n                all_hits.add(query_id)\n        elif hit_type == 'S':\n            # a new seed was identified -- create a cluster with this\n            # sequence as the first instance\n            if query_id in clusters:\n                raise UclustParseError(\"A seq id was provided as a seed, but that seq id already \"\n                                       \"represents a cluster. Are there overlapping seq ids in your \"\n                                       \"reference and input files or repeated seq ids in either? \"\n                                       \"Offending seq id is %s\" % query_id)\n            clusters[query_id] = [query_id]\n            seeds.append(query_id)\n        elif hit_type == 'L':\n            # a library seed was identified -- create a cluster with this\n            # id as the index, but don't give it any instances yet bc the hit\n            # line will be specified separately. note we need to handle these\n            # lines separately from the H lines to detect overlapping seq ids\n            # between the reference and the input fasta files\n            if query_id in clusters:\n                raise UclustParseError(\"A seq id was provided as a seed, but that seq id already \"\n                                       \"represents a cluster. Are there overlapping seq ids in your \"\n                                       \"reference and input files or repeated seq ids in either? \"\n                                       \"Offending seq id is %s\" % query_id)\n            clusters[query_id] = []\n        elif hit_type == 'N':\n            # a failure was identified -- add it to the failures list\n            failures.append(query_id)\n        else:\n            # shouldn't be possible to get here, but provided for\n            # clarity\n            raise UclustParseError(\n                \"Unexpected result parsing line:\\n%s\" %\n                '\\t'.join(record))\n\n    # will need to return the full clusters dict, I think, to support\n    # useful identifiers in reference database clustering\n    # return  clusters.values(), failures, seeds\n    return clusters, failures, seeds"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uclust_fasta_sort_from_filepath(\n        fasta_filepath,\n        output_filepath=None,\n        tmp_dir=gettempdir(),\n        HALT_EXEC=False):\n    \"\"\"Generates sorted fasta file via uclust --mergesort.\"\"\"\n    if not output_filepath:\n        _, output_filepath = mkstemp(dir=tmp_dir, prefix='uclust_fasta_sort',\n                                     suffix='.fasta')\n\n    app = Uclust(params={'--tmpdir': tmp_dir},\n                 TmpDir=tmp_dir, HALT_EXEC=HALT_EXEC)\n\n    app_result = app(data={'--mergesort': fasta_filepath,\n                           '--output': output_filepath})\n\n    return app_result", "response": "Generates sorted fasta file via uclust."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uclust_search_and_align_from_fasta_filepath(\n        query_fasta_filepath,\n        subject_fasta_filepath,\n        percent_ID=0.75,\n        enable_rev_strand_matching=True,\n        max_accepts=8,\n        max_rejects=32,\n        tmp_dir=gettempdir(),\n        HALT_EXEC=False):\n    \"\"\" query seqs against subject fasta using uclust,\n\n       return global pw alignment of best match\n    \"\"\"\n\n    # Explanation of parameter settings\n    #  id - min percent id to count a match\n    #  maxaccepts = 8 , searches for best match rather than first match\n    #                   (0 => infinite accepts, or good matches before\n    #                    quitting search)\n    #  maxaccepts = 32,\n    #  libonly = True , does not add sequences to the library if they don't\n    #                   match something there already. this effectively makes\n    #                   uclust a search tool rather than a clustering tool\n\n    params = {'--id': percent_ID,\n              '--maxaccepts': max_accepts,\n              '--maxrejects': max_rejects,\n              '--libonly': True,\n              '--lib': subject_fasta_filepath,\n              '--tmpdir': tmp_dir}\n\n    if enable_rev_strand_matching:\n        params['--rev'] = True\n\n    # instantiate the application controller\n    app = Uclust(params,\n                 TmpDir=tmp_dir, HALT_EXEC=HALT_EXEC)\n\n    # apply uclust\n    _, alignment_filepath = mkstemp(dir=tmp_dir, prefix='uclust_alignments',\n                                    suffix='.fasta')\n    _, uc_filepath = mkstemp(dir=tmp_dir, prefix='uclust_results',\n                             suffix='.uc')\n    input_data = {'--input': query_fasta_filepath,\n                  '--fastapairs': alignment_filepath,\n                  '--uc': uc_filepath}\n    app_result = app(input_data)\n\n    # yield the pairwise alignments\n    for result in process_uclust_pw_alignment_results(\n            app_result['PairwiseAlignments'], app_result['ClusterFile']):\n        try:\n            yield result\n        except GeneratorExit:\n            break\n\n    # clean up the temp files that were generated\n    app_result.cleanUp()\n\n    return", "response": "search and align a set of sequences against a subject fasta using uclust"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a clustered uclust file from sorted fasta file", "response": "def uclust_cluster_from_sorted_fasta_filepath(\n        fasta_filepath,\n        uc_save_filepath=None,\n        percent_ID=0.97,\n        max_accepts=1,\n        max_rejects=8,\n        stepwords=8,\n        word_length=8,\n        optimal=False,\n        exact=False,\n        suppress_sort=False,\n        enable_rev_strand_matching=False,\n        subject_fasta_filepath=None,\n        suppress_new_clusters=False,\n        stable_sort=False,\n        tmp_dir=gettempdir(),\n        HALT_EXEC=False):\n    \"\"\" Returns clustered uclust file from sorted fasta\"\"\"\n    output_filepath = uc_save_filepath\n    if not output_filepath:\n        _, output_filepath = mkstemp(dir=tmp_dir, prefix='uclust_clusters',\n                                     suffix='.uc')\n\n    params = {'--id': percent_ID,\n              '--maxaccepts': max_accepts,\n              '--maxrejects': max_rejects,\n              '--stepwords': stepwords,\n              '--w': word_length,\n              '--tmpdir': tmp_dir}\n    app = Uclust(params,\n                 TmpDir=tmp_dir, HALT_EXEC=HALT_EXEC)\n\n    # Set any additional parameters specified by the user\n    if enable_rev_strand_matching:\n        app.Parameters['--rev'].on()\n    if optimal:\n        app.Parameters['--optimal'].on()\n    if exact:\n        app.Parameters['--exact'].on()\n    if suppress_sort:\n        app.Parameters['--usersort'].on()\n    if subject_fasta_filepath:\n        app.Parameters['--lib'].on(subject_fasta_filepath)\n    if suppress_new_clusters:\n        app.Parameters['--libonly'].on()\n    if stable_sort:\n        app.Parameters['--stable_sort'].on()\n\n    app_result = app({'--input': fasta_filepath, '--uc': output_filepath})\n    return app_result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the input path as parameters", "response": "def _input_as_parameters(self, data):\n        \"\"\" Set the input path (a fasta filepath)\n        \"\"\"\n        # The list of values which can be passed on a per-run basis\n        allowed_values = ['--input', '--uc', '--fastapairs',\n                          '--uc2clstr', '--output', '--mergesort']\n\n        unsupported_parameters = set(data.keys()) - set(allowed_values)\n        if unsupported_parameters:\n            raise ApplicationError(\n                \"Unsupported parameter(s) passed when calling uclust: %s\" %\n                ' '.join(unsupported_parameters))\n\n        for v in allowed_values:\n            # turn the parameter off so subsequent runs are not\n            # affected by parameter settings from previous runs\n            self.Parameters[v].off()\n            if v in data:\n                # turn the parameter on if specified by the user\n                self.Parameters[v].on(data[v])\n\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_result_paths(self, data):\n\n        result = {}\n\n        result['Output'] = ResultPath(\n            Path=self.Parameters['--output'].Value,\n            IsWritten=self.Parameters['--output'].isOn())\n\n        result['ClusterFile'] = ResultPath(\n            Path=self.Parameters['--uc'].Value,\n            IsWritten=self.Parameters['--uc'].isOn())\n\n        result['PairwiseAlignments'] = ResultPath(\n            Path=self.Parameters['--fastapairs'].Value,\n            IsWritten=self.Parameters['--fastapairs'].isOn())\n\n        return result", "response": "Set the result paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_error(status=None, title=None, detail=None, code=None):\n    '''Formatting JSON API Error Object\n    Constructing an error object based on JSON API standard\n    ref: http://jsonapi.org/format/#error-objects\n    Args:\n        status: Can be a http status codes\n        title: A summary of error\n        detail: A descriptive error message\n        code: Application error codes (if any)\n    Returns:\n        A dictionary contains of status, title, detail and code\n    '''\n    error = {}\n    error.update({ 'title': title })\n\n    if status is not None:\n        error.update({ 'status': status })\n\n    if detail is not None:\n        error.update({ 'detail': detail })\n\n    if code is not None:\n        error.update({ 'code': code })\n\n    return error", "response": "Formats an error object based on JSON API standards."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef return_an_error(*args):\n    '''List of errors\n    Put all errors into a list of errors\n    ref: http://jsonapi.org/format/#errors\n    Args:\n        *args: A tuple contain errors\n    Returns:\n        A dictionary contains a list of errors\n    '''\n    list_errors = []\n    list_errors.extend(list(args))\n\n    errors = { 'errors': list_errors }\n    return errors", "response": "List of errors into a list of errors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting your forwards methods here.", "response": "def forwards(self, orm):\n        \"Write your forwards methods here.\"\n        for doc in orm['document_library.Document'].objects.all():\n            for title in doc.documenttitle_set.all():\n                title.is_published = doc.is_published\n                title.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports activities for a single document into timeline.", "response": "def _activity_import_doc(self, time_doc, activities):\n        '''\n        Import activities for a single document into timeline.\n        '''\n        batch_updates = [time_doc]\n        # We want to consider only activities that happend before time_doc\n        # do not move this, because time_doc._start changes\n        # time_doc['_start'] is a timestamp, whereas act[0] is a datetime\n        # we need to be sure to convert act[0] (when) to timestamp!\n        td_start = time_doc['_start']\n        activities = filter(lambda act: (act[0] < td_start and\n                                         act[1] in time_doc), activities)\n        creation_field = self.lconfig.get('cfield')\n        # make sure that activities are sorted by when descending\n        activities.sort(reverse=True, key=lambda o: o[0])\n        new_doc = {}\n        for when, field, removed, added in activities:\n            last_doc = batch_updates.pop()\n            # check if this activity happened at the same time as the last one,\n            # if it did then we need to group them together\n            if last_doc['_end'] == when:\n                new_doc = deepcopy(last_doc)\n                last_doc = batch_updates.pop()\n            else:\n                new_doc = deepcopy(last_doc)\n                new_doc['_start'] = when\n                new_doc['_end'] = when\n                last_doc['_start'] = when\n            last_val = last_doc[field]\n\n            new_val, inconsistent = self._activity_backwards(new_doc[field],\n                                                             removed, added)\n            new_doc[field] = new_val\n            # Check if the object has the correct field value.\n            if inconsistent:\n                self._log_inconsistency(last_doc, last_val, field,\n                                        removed, added, when)\n                new_doc['_e'] = {} if not new_doc.get('_e') else new_doc['_e']\n                # set curreupted field value to the the value that was added\n                # and continue processing as if that issue didn't exist\n                new_doc['_e'][field] = added\n            # Add the objects to the batch\n            batch_updates.extend([last_doc, new_doc])\n        # try to set the _start of the first version to the creation time\n        try:\n            # set start to creation time if available\n            last_doc = batch_updates[-1]\n            if creation_field:\n                # again, we expect _start to be epoch float...\n                creation_ts = dt2ts(last_doc[creation_field])\n                if creation_ts < last_doc['_start']:\n                    last_doc['_start'] = creation_ts\n                elif len(batch_updates) == 1:\n                    # we have only one version, that we did not change\n                    return []\n                else:\n                    pass  # leave as-is\n        except Exception as e:\n            logger.error('Error updating creation time; %s' % e)\n        return batch_updates"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of object ids of those objects that have changed since the given time.", "response": "def get_changed_oids(self, last_update=None):\n        '''\n        Returns a list of object ids of those objects that have changed since\n        `mtime`. This method expects that the changed objects can be\n        determined based on the `delta_mtime` property of the cube which\n        specifies the field name that carries the time of the last change.\n\n        This method is expected to be overriden in the cube if it is not\n        possible to use a single field to determine the time of the change and\n        if another approach of determining the oids is available. In such\n        cubes the `delta_mtime` property is expected to be set to `True`.\n\n        If `delta_mtime` evaluates to False then this method is not expected\n        to be used.\n\n        :param mtime: datetime string used as 'change since date'\n        '''\n        mtime_columns = self.lconfig.get('delta_mtime', [])\n        if not (mtime_columns and last_update):\n            return []\n        mtime_columns = str2list(mtime_columns)\n        where = []\n        for _column in mtime_columns:\n            _sql = \"%s >= %s\" % (_column, last_update)\n            where.append(_sql)\n        return self.sql_get_oids(where)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting objects from the database.", "response": "def get_objects(self, force=None, last_update=None, flush=False):\n        '''\n        Extract routine for SQL based cubes.\n\n        :param force:\n            for querying for all objects (True) or only those passed in as list\n        :param last_update: manual override for 'changed since date'\n        '''\n        return self._run_object_import(force=force, last_update=last_update,\n                                       flush=flush, full_history=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of unique oids that have not been extracted yet.", "response": "def get_new_oids(self):\n        '''\n        Returns a list of unique oids that have not been extracted yet.\n\n        Essentially, a diff of distinct oids in the source database\n        compared to cube.\n        '''\n        table = self.lconfig.get('table')\n        _oid = self.lconfig.get('_oid')\n        if is_array(_oid):\n            _oid = _oid[0]  # get the db column, not the field alias\n        last_id = self.container.get_last_field(field='_oid')\n        ids = []\n        if last_id:\n            try:  # try to convert to integer... if not, assume unicode value\n                last_id = float(last_id)\n                where = \"%s.%s > %s\" % (table, _oid, last_id)\n            except (TypeError, ValueError):\n                where = \"%s.%s > '%s'\" % (table, _oid, last_id)\n            ids = self.sql_get_oids(where)\n        return ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the full history of the object store", "response": "def get_full_history(self, force=None, last_update=None, flush=False):\n        '''\n        Fields change depending on when you run activity_import,\n        such as \"last_updated\" type fields which don't have activity\n        being tracked, which means we'll always end up with different\n        hash values, so we need to always remove all existing object\n        states and import fresh\n        '''\n        return self._run_object_import(force=force, last_update=last_update,\n                                       flush=flush, full_history=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries source database for a distinct list of oids.", "response": "def sql_get_oids(self, where=None):\n        '''\n        Query source database for a distinct list of oids.\n        '''\n        table = self.lconfig.get('table')\n        db = self.lconfig.get('db_schema_name') or self.lconfig.get('db')\n        _oid = self.lconfig.get('_oid')\n        if is_array(_oid):\n            _oid = _oid[0]  # get the db column, not the field alias\n        sql = 'SELECT DISTINCT %s.%s FROM %s.%s' % (table, _oid, db, table)\n        if where:\n            where = [where] if isinstance(where, basestring) else list(where)\n            sql += ' WHERE %s' % ' OR '.join(where)\n        result = sorted([r[_oid] for r in self._load_sql(sql)])\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_objects(self, flush=False, autosnap=True, **kwargs):\n        '''\n        Main API method for sub-classed cubes to override for the\n        generation of the objects which are to (potentially) be added\n        to the cube (assuming no duplicates)\n        '''\n        logger.debug('Running get_objects(flush=%s, autosnap=%s, %s)' % (\n                     flush, autosnap, kwargs))\n        if flush:\n            s = time()\n            result = self.flush(autosnap=autosnap, **kwargs)\n            diff = time() - s\n            logger.debug(\"Flush complete (%ss)\" % int(diff))\n            return result\n        else:\n            return self", "response": "Get the objects from the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping for metrique. utils. get_cube", "response": "def get_cube(self, cube, init=True, name=None, copy_config=True, **kwargs):\n        '''wrapper for :func:`metrique.utils.get_cube`\n\n        Locates and loads a metrique cube\n\n        :param cube: name of cube to load\n        :param init: (bool) initialize cube before returning?\n        :param name: override the name of the cube\n        :param copy_config: apply config of calling cube to new?\n                            Implies init=True.\n        :param kwargs: additional :func:`metrique.utils.get_cube`\n        '''\n        name = name or cube\n        config = copy(self.config) if copy_config else {}\n        config_file = self.config_file\n        container = type(self.container)\n        container_config = copy(self.container_config)\n        proxy = str(type(self.proxy))\n        return get_cube(cube=cube, init=init, name=name, config=config,\n                        config_file=config_file, container=container,\n                        container_config=container_config,\n                        proxy=proxy, proxy_config=self.proxy_config, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tree from an alignment object or data that can be used to build one.", "response": "def insert_sequences_into_tree(aln, moltype, params={},\n                                           write_log=True):\n    \"\"\"Returns a tree from Alignment object aln.\n\n    aln: an xxx.Alignment object, or data that can be used to build one.\n\n    moltype: cogent.core.moltype.MolType object\n\n    params: dict of parameters to pass in to the RAxML app controller.\n\n    The result will be an xxx.Alignment object, or None if tree fails.\n    \"\"\"\n\n    # convert aln to phy since seq_names need fixed to run through pplacer\n\n    new_aln=get_align_for_phylip(StringIO(aln))\n\n    # convert aln to fasta in case it is not already a fasta file\n    aln2 = Alignment(new_aln)\n    seqs = aln2.toFasta()\n\n    ih = '_input_as_multiline_string'\n\n    pplacer_app = Pplacer(params=params,\n                      InputHandler=ih,\n                      WorkingDir=None,\n                      SuppressStderr=False,\n                      SuppressStdout=False)\n\n    pplacer_result = pplacer_app(seqs)\n\n    # write a log file\n    if write_log:\n        log_fp = join(params[\"--out-dir\"],'log_pplacer_' + \\\n                      split(get_tmp_filename())[-1])\n        log_file=open(log_fp,'w')\n        log_file.write(pplacer_result['StdOut'].read())\n        log_file.close()\n\n    # use guppy to convert json file into a placement tree\n    guppy_params={'tog':None}\n\n    new_tree=build_tree_from_json_using_params(pplacer_result['json'].name, \\\n                                               output_dir=params['--out-dir'], \\\n                                               params=guppy_params)\n\n    pplacer_result.cleanUp()\n\n    return new_tree"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getTmpFilename(self, tmp_dir=\"/tmp\",prefix='tmp',suffix='.fasta',\\\n           include_class_id=False,result_constructor=FilePath):\n        \"\"\" Define Tmp filename to contain .fasta suffix, since pplacer requires\n            the suffix to be .fasta \"\"\"\n\n        return super(Pplacer,self).getTmpFilename(tmp_dir=tmp_dir,\n                                    prefix=prefix,\n                                    suffix=suffix,\n                                    include_class_id=include_class_id,\n                                    result_constructor=result_constructor)", "response": "Define Tmp filename to contain. fasta suffix"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefines the output filepaths", "response": "def _get_result_paths(self,data):\n        \"\"\" Define the output filepaths \"\"\"\n        output_dir = self.Parameters['--out-dir'].Value\n        result = {}\n        result['json'] = ResultPath(Path=join(output_dir,\n                                splitext(split(self._input_filename)[-1])[0] + \\\n                                '.jplace'))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds unit vectors expressing the ion drift coordinate system of the passed instrument.", "response": "def add_mag_drift_unit_vectors_ecef(inst, steps=None, max_steps=40000, step_size=10.,\n                                    ref_height=120.):\n    \"\"\"Adds unit vectors expressing the ion drift coordinate system\n    organized by the geomagnetic field. Unit vectors are expressed\n    in ECEF coordinates.\n    \n    Parameters\n    ----------\n    inst : pysat.Instrument\n        Instrument object that will get unit vectors\n    max_steps : int\n        Maximum number of steps allowed for field line tracing\n    step_size : float\n        Maximum step size (km) allowed when field line tracing\n    ref_height : float\n        Altitude used as cutoff for labeling a field line location a footpoint\n        \n    Returns\n    -------\n    None\n        unit vectors are added to the passed Instrument object with a naming \n        scheme:\n            'unit_zon_ecef_*' : unit zonal vector, component along ECEF-(X,Y,or Z)\n            'unit_fa_ecef_*' : unit field-aligned vector, component along ECEF-(X,Y,or Z)\n            'unit_mer_ecef_*' : unit meridional vector, component along ECEF-(X,Y,or Z)\n            \n    \"\"\"\n\n    # add unit vectors for magnetic drifts in ecef coordinates\n    zvx, zvy, zvz, bx, by, bz, mx, my, mz = calculate_mag_drift_unit_vectors_ecef(inst['latitude'], \n                                                            inst['longitude'], inst['altitude'], inst.data.index,\n                                                            steps=steps, max_steps=max_steps, step_size=step_size, ref_height=ref_height)\n    \n    inst['unit_zon_ecef_x'] = zvx\n    inst['unit_zon_ecef_y'] = zvy\n    inst['unit_zon_ecef_z'] = zvz\n\n    inst['unit_fa_ecef_x'] = bx\n    inst['unit_fa_ecef_y'] = by\n    inst['unit_fa_ecef_z'] = bz\n\n    inst['unit_mer_ecef_x'] = mx\n    inst['unit_mer_ecef_y'] = my\n    inst['unit_mer_ecef_z'] = mz\n\n    inst.meta['unit_zon_ecef_x'] = {'long_name': 'Zonal unit vector along ECEF-x',\n                                    'desc': 'Zonal unit vector along ECEF-x',\n                                    'label': 'Zonal unit vector along ECEF-x',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Zonal unit vector along ECEF-x',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n    inst.meta['unit_zon_ecef_y'] = {'long_name': 'Zonal unit vector along ECEF-y',\n                                    'desc': 'Zonal unit vector along ECEF-y',\n                                    'label': 'Zonal unit vector along ECEF-y',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Zonal unit vector along ECEF-y',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n    inst.meta['unit_zon_ecef_z'] = {'long_name': 'Zonal unit vector along ECEF-z',\n                                    'desc': 'Zonal unit vector along ECEF-z',\n                                    'label': 'Zonal unit vector along ECEF-z',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Zonal unit vector along ECEF-z',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n\n    inst.meta['unit_fa_ecef_x'] = {'long_name': 'Field-aligned unit vector along ECEF-x',\n                                    'desc': 'Field-aligned unit vector along ECEF-x',\n                                    'label': 'Field-aligned unit vector along ECEF-x',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Field-aligned unit vector along ECEF-x',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n    inst.meta['unit_fa_ecef_y'] = {'long_name': 'Field-aligned unit vector along ECEF-y',\n                                    'desc': 'Field-aligned unit vector along ECEF-y',\n                                    'label': 'Field-aligned unit vector along ECEF-y',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Field-aligned unit vector along ECEF-y',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n    inst.meta['unit_fa_ecef_z'] = {'long_name': 'Field-aligned unit vector along ECEF-z',\n                                    'desc': 'Field-aligned unit vector along ECEF-z',\n                                    'label': 'Field-aligned unit vector along ECEF-z',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Field-aligned unit vector along ECEF-z',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n\n    inst.meta['unit_mer_ecef_x'] = {'long_name': 'Meridional unit vector along ECEF-x',\n                                    'desc': 'Meridional unit vector along ECEF-x',\n                                    'label': 'Meridional unit vector along ECEF-x',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Meridional unit vector along ECEF-x',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n    inst.meta['unit_mer_ecef_y'] = {'long_name': 'Meridional unit vector along ECEF-y',\n                                    'desc': 'Meridional unit vector along ECEF-y',\n                                    'label': 'Meridional unit vector along ECEF-y',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Meridional unit vector along ECEF-y',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n    inst.meta['unit_mer_ecef_z'] = {'long_name': 'Meridional unit vector along ECEF-z',\n                                    'desc': 'Meridional unit vector along ECEF-z',\n                                    'label': 'Meridional unit vector along ECEF-z',\n                                    'notes': ('Unit vector expressed using Earth Centered Earth Fixed (ECEF) frame. '\n                                              'Vector system is calcluated by field-line tracing along IGRF values '\n                                              'down to reference altitudes of 120 km in both the Northern and Southern '\n                                              'hemispheres. These two points, along with the satellite position, are '\n                                              'used to define the magnetic meridian. Vector math from here generates '\n                                              'the orthogonal system.'),\n                                    'axis': 'Meridional unit vector along ECEF-z',\n                                    'value_min': -1.,\n                                    'value_max': 1.,\n                                    }\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_mag_drift_unit_vectors(inst, max_steps=40000, step_size=10.):\n\n    # vectors are returned in geo/ecef coordinate system\n    add_mag_drift_unit_vectors_ecef(inst, max_steps=max_steps, step_size=step_size)\n    # convert them to S/C using transformation supplied by OA\n    inst['unit_zon_x'], inst['unit_zon_y'], inst['unit_zon_z'] = project_ecef_vector_onto_basis(inst['unit_zon_ecef_x'], inst['unit_zon_ecef_y'], inst['unit_zon_ecef_z'],\n                                                                                                inst['sc_xhat_x'], inst['sc_xhat_y'], inst['sc_xhat_z'],\n                                                                                                inst['sc_yhat_x'], inst['sc_yhat_y'], inst['sc_yhat_z'],\n                                                                                                inst['sc_zhat_x'], inst['sc_zhat_y'], inst['sc_zhat_z'])\n    inst['unit_fa_x'], inst['unit_fa_y'], inst['unit_fa_z'] = project_ecef_vector_onto_basis(inst['unit_fa_ecef_x'], inst['unit_fa_ecef_y'], inst['unit_fa_ecef_z'],\n                                                                                                inst['sc_xhat_x'], inst['sc_xhat_y'], inst['sc_xhat_z'],\n                                                                                                inst['sc_yhat_x'], inst['sc_yhat_y'], inst['sc_yhat_z'],\n                                                                                                inst['sc_zhat_x'], inst['sc_zhat_y'], inst['sc_zhat_z'])\n    inst['unit_mer_x'], inst['unit_mer_y'], inst['unit_mer_z'] = project_ecef_vector_onto_basis(inst['unit_mer_ecef_x'], inst['unit_mer_ecef_y'], inst['unit_mer_ecef_z'],\n                                                                                                inst['sc_xhat_x'], inst['sc_xhat_y'], inst['sc_xhat_z'],\n                                                                                                inst['sc_yhat_x'], inst['sc_yhat_y'], inst['sc_yhat_z'],\n                                                                                                inst['sc_zhat_x'], inst['sc_zhat_y'], inst['sc_zhat_z'])\n\n    inst.meta['unit_zon_x'] = { 'long_name':'Zonal direction along IVM-x',\n                                'desc': 'Unit vector for the zonal geomagnetic direction.',\n                                'label': 'Zonal Unit Vector: IVM-X component',\n                                'axis': 'Zonal Unit Vector: IVM-X component',\n                                'notes': ('Positive towards the east. Zonal vector is normal to magnetic meridian plane. '\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n    inst.meta['unit_zon_y'] = {'long_name':'Zonal direction along IVM-y',\n                                'desc': 'Unit vector for the zonal geomagnetic direction.',\n                                'label': 'Zonal Unit Vector: IVM-Y component',\n                                'axis': 'Zonal Unit Vector: IVM-Y component',\n                                'notes': ('Positive towards the east. Zonal vector is normal to magnetic meridian plane. '\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n    inst.meta['unit_zon_z'] = {'long_name':'Zonal direction along IVM-z',\n                                'desc': 'Unit vector for the zonal geomagnetic direction.',\n                                'label': 'Zonal Unit Vector: IVM-Z component',\n                                'axis': 'Zonal Unit Vector: IVM-Z component',\n                                'notes': ('Positive towards the east. Zonal vector is normal to magnetic meridian plane. '\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n\n    inst.meta['unit_fa_x'] = {'long_name':'Field-aligned direction along IVM-x',\n                                'desc': 'Unit vector for the geomagnetic field line direction.',\n                                'label': 'Field Aligned Unit Vector: IVM-X component',\n                                'axis': 'Field Aligned Unit Vector: IVM-X component',\n                                'notes': ('Positive along the field, generally northward. Unit vector is along the geomagnetic field. '\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n    inst.meta['unit_fa_y'] = {'long_name':'Field-aligned direction along IVM-y',\n                                'desc': 'Unit vector for the geomagnetic field line direction.',\n                                'label': 'Field Aligned Unit Vector: IVM-Y component',\n                                'axis': 'Field Aligned Unit Vector: IVM-Y component',\n                                'notes': ('Positive along the field, generally northward. Unit vector is along the geomagnetic field. '\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n    inst.meta['unit_fa_z'] = {'long_name':'Field-aligned direction along IVM-z',\n                                'desc': 'Unit vector for the geomagnetic field line direction.',\n                                'label': 'Field Aligned Unit Vector: IVM-Z component',\n                                'axis': 'Field Aligned Unit Vector: IVM-Z component',\n                                'notes': ('Positive along the field, generally northward. Unit vector is along the geomagnetic field. '\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n\n    inst.meta['unit_mer_x'] = {'long_name':'Meridional direction along IVM-x',\n                                'desc': 'Unit vector for the geomagnetic meridional direction.',\n                                'label': 'Meridional Unit Vector: IVM-X component',\n                                'axis': 'Meridional Unit Vector: IVM-X component',\n                                'notes': ('Positive is aligned with vertical at '\n                                          'geomagnetic equator. Unit vector is perpendicular to the geomagnetic field '\n                                          'and in the plane of the meridian.'\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n    inst.meta['unit_mer_y'] = {'long_name':'Meridional direction along IVM-y',\n                                'desc': 'Unit vector for the geomagnetic meridional direction.',\n                                'label': 'Meridional Unit Vector: IVM-Y component',\n                                'axis': 'Meridional Unit Vector: IVM-Y component',\n                                'notes': ('Positive is aligned with vertical at '\n                                          'geomagnetic equator. Unit vector is perpendicular to the geomagnetic field '\n                                          'and in the plane of the meridian.'\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n    inst.meta['unit_mer_z'] = {'long_name':'Meridional direction along IVM-z',\n                                'desc': 'Unit vector for the geomagnetic meridional direction.',\n                                'label': 'Meridional Unit Vector: IVM-Z component',\n                                'axis': 'Meridional Unit Vector: IVM-Z component',\n                                'notes': ('Positive is aligned with vertical at '\n                                          'geomagnetic equator. Unit vector is perpendicular to the geomagnetic field '\n                                          'and in the plane of the meridian.'\n                                          'The unit vector is expressed in the IVM coordinate system, x - along RAM, '\n                                          'z - towards nadir, y - completes the system, generally southward. '\n                                          'Calculated using the corresponding unit vector in ECEF and the orientation '\n                                          'of the IVM also expressed in ECEF (sc_*hat_*).'),\n                                'scale': 'linear',\n                                'units': '',\n                               'value_min':-1., \n                               'value_max':1}\n\n    return", "response": "Adds unit vectors expressing the ion drift coordinate system and the basis vectors of the Molecule field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_mag_drifts(inst):\n    \n    inst['iv_zon'] = {'data':inst['unit_zon_x'] * inst['iv_x'] + inst['unit_zon_y']*inst['iv_y'] + inst['unit_zon_z']*inst['iv_z'],\n                      'units':'m/s',\n                      'long_name':'Zonal ion velocity',\n                      'notes':('Ion velocity relative to co-rotation along zonal '\n                               'direction, normal to meridional plane. Positive east. '\n                               'Velocity obtained using ion velocities relative '\n                               'to co-rotation in the instrument frame along '\n                               'with the corresponding unit vectors expressed in '\n                               'the instrument frame. '),\n                      'label': 'Zonal Ion Velocity',\n                      'axis': 'Zonal Ion Velocity',\n                      'desc': 'Zonal ion velocity',\n                      'scale': 'Linear',\n                      'value_min':-500., \n                      'value_max':500.}\n                      \n    inst['iv_fa'] = {'data':inst['unit_fa_x'] * inst['iv_x'] + inst['unit_fa_y'] * inst['iv_y'] + inst['unit_fa_z'] * inst['iv_z'],\n                      'units':'m/s',\n                      'long_name':'Field-Aligned ion velocity',\n                      'notes':('Ion velocity relative to co-rotation along magnetic field line. Positive along the field. ',\n                               'Velocity obtained using ion velocities relative '\n                               'to co-rotation in the instrument frame along '\n                               'with the corresponding unit vectors expressed in '\n                               'the instrument frame. '),\n                      'label':'Field-Aligned Ion Velocity',\n                      'axis':'Field-Aligned Ion Velocity',\n                      'desc':'Field-Aligned Ion Velocity',\n                      'scale':'Linear',\n                      'value_min':-500., \n                      'value_max':500.}\n\n    inst['iv_mer'] = {'data':inst['unit_mer_x'] * inst['iv_x'] + inst['unit_mer_y']*inst['iv_y'] + inst['unit_mer_z']*inst['iv_z'],\n                      'units':'m/s',\n                      'long_name':'Meridional ion velocity',\n                      'notes':('Velocity along meridional direction, perpendicular '\n                               'to field and within meridional plane. Positive is up at magnetic equator. ',\n                               'Velocity obtained using ion velocities relative '\n                               'to co-rotation in the instrument frame along '\n                               'with the corresponding unit vectors expressed in '\n                               'the instrument frame. '),\n                      'label':'Meridional Ion Velocity',\n                      'axis':'Meridional Ion Velocity',\n                      'desc':'Meridional Ion Velocity',\n                      'scale':'Linear',\n                      'value_min':-500., \n                      'value_max':500.}\n    \n    return", "response": "Adds ion drifts in magnetic coordinates using the pre - calculated unit vectors for the magnetic coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntranslates geomagnetic ion velocities to those at the meridional and magnetic equator.", "response": "def add_footpoint_and_equatorial_drifts(inst, equ_mer_scalar='equ_mer_drifts_scalar',\n                                              equ_zonal_scalar='equ_zon_drifts_scalar',\n                                              north_mer_scalar='north_footpoint_mer_drifts_scalar',\n                                              north_zon_scalar='north_footpoint_zon_drifts_scalar',\n                                              south_mer_scalar='south_footpoint_mer_drifts_scalar',\n                                              south_zon_scalar='south_footpoint_zon_drifts_scalar',\n                                              mer_drift='iv_mer',\n                                              zon_drift='iv_zon'):\n    \"\"\"Translates geomagnetic ion velocities to those at footpoints and magnetic equator.\n    Note\n    ----\n        Presumes scalar values for mapping ion velocities are already in the inst, labeled\n        by north_footpoint_zon_drifts_scalar, north_footpoint_mer_drifts_scalar,\n        equ_mer_drifts_scalar, equ_zon_drifts_scalar.\n    \n        Also presumes that ion motions in the geomagnetic system are present and labeled\n        as 'iv_mer' and 'iv_zon' for meridional and zonal ion motions.\n        \n        This naming scheme is used by the other pysat oriented routines\n        in this package.\n    \n    Parameters\n    ----------\n    inst : pysat.Instrument\n    equ_mer_scalar : string\n        Label used to identify equatorial scalar for meridional ion drift\n    equ_zon_scalar : string\n        Label used to identify equatorial scalar for zonal ion drift\n    north_mer_scalar : string\n        Label used to identify northern footpoint scalar for meridional ion drift\n    north_zon_scalar : string\n        Label used to identify northern footpoint scalar for zonal ion drift\n    south_mer_scalar : string\n        Label used to identify northern footpoint scalar for meridional ion drift\n    south_zon_scalar : string\n        Label used to identify southern footpoint scalar for zonal ion drift\n    mer_drift : string\n        Label used to identify meridional ion drifts within inst\n    zon_drift : string\n        Label used to identify zonal ion drifts within inst\n        \n    Returns\n    -------\n    None\n        Modifies pysat.Instrument object in place. Drifts mapped to the magnetic equator\n        are labeled 'equ_mer_drift' and 'equ_zon_drift'. Mappings to the northern\n        and southern footpoints are labeled 'south_footpoint_mer_drift' and\n        'south_footpoint_zon_drift'. Similarly for the northern hemisphere.\n    \"\"\"\n\n    inst['equ_mer_drift'] = {'data' : inst[equ_mer_scalar]*inst[mer_drift],\n                            'units':'m/s',\n                            'long_name':'Equatorial meridional ion velocity',\n                            'notes':('Velocity along meridional direction, perpendicular '\n                                    'to field and within meridional plane, scaled to '\n                                    'magnetic equator. Positive is up at magnetic equator. '\n                                    'Velocity obtained using ion velocities relative '\n                                    'to co-rotation in the instrument frame along '\n                                    'with the corresponding unit vectors expressed in '\n                                    'the instrument frame. Field-line mapping and '\n                                    'the assumption of equi-potential field lines '\n                                    'is used to translate the locally measured ion '\n                                    'motion to the magnetic equator. The mapping '\n                                    'is used to determine the change in magnetic '\n                                    'field line distance, which, under assumption of '\n                                    'equipotential field lines, in turn alters '\n                                    'the electric field at that location (E=V/d). '),\n                            'label':'Equatorial Meridional Ion Velocity',\n                            'axis':'Equatorial Meridional Ion Velocity',\n                            'desc':'Equatorial Meridional Ion Velocity',\n                            'scale':'Linear',\n                            'value_min':-500., \n                            'value_max':500.}\n\n    inst['equ_zon_drift'] = {'data' : inst[equ_zonal_scalar]*inst[zon_drift],\n                            'units':'m/s',\n                            'long_name':'Equatorial zonal ion velocity',\n                            'notes':('Velocity along zonal direction, perpendicular '\n                                    'to field and the meridional plane, scaled to '\n                                    'magnetic equator. Positive is generally eastward. '\n                                    'Velocity obtained using ion velocities relative '\n                                    'to co-rotation in the instrument frame along '\n                                    'with the corresponding unit vectors expressed in '\n                                    'the instrument frame. Field-line mapping and '\n                                    'the assumption of equi-potential field lines '\n                                    'is used to translate the locally measured ion '\n                                    'motion to the magnetic equator. The mapping '\n                                    'is used to determine the change in magnetic '\n                                    'field line distance, which, under assumption of '\n                                    'equipotential field lines, in turn alters '\n                                    'the electric field at that location (E=V/d). '),\n                            'label':'Equatorial Zonal Ion Velocity',\n                            'axis':'Equatorial Zonal Ion Velocity',\n                            'desc':'Equatorial Zonal Ion Velocity',\n                            'scale':'Linear',\n                            'value_min':-500., \n                            'value_max':500.}\n\n    inst['south_footpoint_mer_drift'] = {'data' : inst[south_mer_scalar]*inst[mer_drift],\n                            'units':'m/s',\n                            'long_name':'Southern meridional ion velocity',\n                            'notes':('Velocity along meridional direction, perpendicular '\n                                    'to field and within meridional plane, scaled to '\n                                    'southern footpoint. Positive is up at magnetic equator. '\n                                    'Velocity obtained using ion velocities relative '\n                                    'to co-rotation in the instrument frame along '\n                                    'with the corresponding unit vectors expressed in '\n                                    'the instrument frame. Field-line mapping and '\n                                    'the assumption of equi-potential field lines '\n                                    'is used to translate the locally measured ion '\n                                    'motion to the magnetic footpoint. The mapping '\n                                    'is used to determine the change in magnetic '\n                                    'field line distance, which, under assumption of '\n                                    'equipotential field lines, in turn alters '\n                                    'the electric field at that location (E=V/d). '),\n                            'label':'Southern Meridional Ion Velocity',\n                            'axis':'Southern Meridional Ion Velocity',\n                            'desc':'Southern Meridional Ion Velocity',\n                            'scale':'Linear',\n                            'value_min':-500., \n                            'value_max':500.}\n\n    inst['south_footpoint_zon_drift'] = {'data':inst[south_zon_scalar]*inst[zon_drift],\n                            'units':'m/s',\n                            'long_name':'Southern zonal ion velocity',\n                            'notes':('Velocity along zonal direction, perpendicular '\n                                    'to field and the meridional plane, scaled to '\n                                    'southern footpoint. Positive is generally eastward. '\n                                    'Velocity obtained using ion velocities relative '\n                                    'to co-rotation in the instrument frame along '\n                                    'with the corresponding unit vectors expressed in '\n                                    'the instrument frame. Field-line mapping and '\n                                    'the assumption of equi-potential field lines '\n                                    'is used to translate the locally measured ion '\n                                    'motion to the southern footpoint. The mapping '\n                                    'is used to determine the change in magnetic '\n                                    'field line distance, which, under assumption of '\n                                    'equipotential field lines, in turn alters '\n                                    'the electric field at that location (E=V/d). '),\n                            'label':'Southern Zonal Ion Velocity',\n                            'axis':'Southern Zonal Ion Velocity',\n                            'desc':'Southern Zonal Ion Velocity',\n                            'scale':'Linear',\n                            'value_min':-500., \n                            'value_max':500.}\n\n    inst['north_footpoint_mer_drift'] = {'data':inst[north_mer_scalar]*inst[mer_drift],\n                            'units':'m/s',\n                            'long_name':'Northern meridional ion velocity',\n                            'notes':('Velocity along meridional direction, perpendicular '\n                                    'to field and within meridional plane, scaled to '\n                                    'northern footpoint. Positive is up at magnetic equator. '\n                                    'Velocity obtained using ion velocities relative '\n                                    'to co-rotation in the instrument frame along '\n                                    'with the corresponding unit vectors expressed in '\n                                    'the instrument frame. Field-line mapping and '\n                                    'the assumption of equi-potential field lines '\n                                    'is used to translate the locally measured ion '\n                                    'motion to the magnetic footpoint. The mapping '\n                                    'is used to determine the change in magnetic '\n                                    'field line distance, which, under assumption of '\n                                    'equipotential field lines, in turn alters '\n                                    'the electric field at that location (E=V/d). '),\n                            'label':'Northern Meridional Ion Velocity',\n                            'axis':'Northern Meridional Ion Velocity',\n                            'desc':'Northern Meridional Ion Velocity',\n                            'scale':'Linear',\n                            'value_min':-500., \n                            'value_max':500.}\n\n    inst['north_footpoint_zon_drift'] = {'data':inst[north_zon_scalar]*inst[zon_drift],\n                            'units':'m/s',\n                            'long_name':'Northern zonal ion velocity',\n                            'notes':('Velocity along zonal direction, perpendicular '\n                                    'to field and the meridional plane, scaled to '\n                                    'northern footpoint. Positive is generally eastward. '\n                                    'Velocity obtained using ion velocities relative '\n                                    'to co-rotation in the instrument frame along '\n                                    'with the corresponding unit vectors expressed in '\n                                    'the instrument frame. Field-line mapping and '\n                                    'the assumption of equi-potential field lines '\n                                    'is used to translate the locally measured ion '\n                                    'motion to the northern footpoint. The mapping '\n                                    'is used to determine the change in magnetic '\n                                    'field line distance, which, under assumption of '\n                                    'equipotential field lines, in turn alters '\n                                    'the electric field at that location (E=V/d). '),\n                            'label':'Northern Zonal Ion Velocity',\n                            'axis':'Northern Zonal Ion Velocity',\n                            'desc':'Northern Zonal Ion Velocity',\n                            'scale':'Linear',\n                            'value_min':-500., \n                            'value_max':500.}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chi_squared(*choices):\n\n    term = lambda expected, observed: float((expected - observed) ** 2) / max(expected, 1)\n    mean_success_rate = float(sum([c.rewards for c in choices])) / max(sum([c.plays for c in choices]), 1)\n    mean_failure_rate = 1 - mean_success_rate\n\n    return sum([\n        term(mean_success_rate * c.plays, c.rewards)\n        + term(mean_failure_rate * c.plays, c.plays - c.rewards\n    ) for c in choices])", "response": "Calculates the chi squared of a list of choices"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sync_from_spec(redis, schema):\n\n    def get_experiments_dict(active=True):\n        \"\"\"Returns a dictionary of experiment names -> experiment objects\"\"\"\n        return dict((experiment.name, experiment) for experiment in get_experiments(redis, active=active))\n\n    # Get the current experiments\n    active_experiments = get_experiments_dict()\n    archived_experiments = get_experiments_dict(active=False)\n\n    # Get the newly defined experiment names and the names of the experiments\n    # already setup\n    new_experiment_names = set(schema.keys())\n    active_experiment_names = set(active_experiments.keys())\n\n    # Find all the experiments that are in the schema and are defined among the\n    # archived experiments, but not the active ones (we check against active\n    # experiments to prevent the edge case where an experiment might be defined\n    # doubly in both active and archived experiments)\n    unarchivable_experiment_names = (new_experiment_names - active_experiment_names) & set(archived_experiments.keys())\n\n    # De-archive the necessary experiments\n    for unarchivable_experiment_name in unarchivable_experiment_names:\n        print(\"- De-archiving %s\" % unarchivable_experiment_name)\n\n        # Because there is no function to de-archive an experiment, it must\n        # be done manually\n        pipe = redis.pipeline(transaction=True)\n        pipe.sadd(ACTIVE_EXPERIMENTS_REDIS_KEY, unarchivable_experiment_name)\n        pipe.srem(ARCHIVED_EXPERIMENTS_REDIS_KEY, unarchivable_experiment_name)\n        pipe.execute()\n\n    # Reload the active experiments if we de-archived any\n    if unarchivable_experiment_names:\n        active_experiments = get_experiments_dict()\n        active_experiment_names = set(active_experiments.keys())\n\n    # Create the new experiments\n    for new_experiment_name in new_experiment_names - active_experiment_names:\n        print(\"- Creating experiment %s\" % new_experiment_name)\n\n        experiment = add_experiment(redis, new_experiment_name)\n\n        for choice in schema[new_experiment_name]:\n            print(\"  - Adding choice %s\" % choice)\n            experiment.add_choice(choice)\n\n    # Archive experiments not defined in the schema\n    for archivable_experiment_name in active_experiment_names - new_experiment_names:\n        print(\"- Archiving %s\" % archivable_experiment_name)\n        active_experiments[archivable_experiment_name].archive()\n\n    # Update the choices for existing experiments that are also defined in the\n    # schema\n    for experiment_name in new_experiment_names & active_experiment_names:\n        experiment = active_experiments[experiment_name]\n        new_choice_names = set(schema[experiment_name])\n        old_choice_names = set(experiment.choice_names)\n\n        # Add choices in the schema that do not exist yet\n        for new_choice_name in new_choice_names - old_choice_names:\n            print(\"- Adding choice %s to existing experiment %s\" % (new_choice_name, experiment_name))\n            experiment.add_choice(new_choice_name)\n\n        # Remove choices that aren't in the schema\n        for removable_choice_name in old_choice_names - new_choice_names:\n            print(\"- Removing choice %s from existing experiment %s\" % (removable_choice_name, experiment_name))\n            experiment.remove_choice(removable_choice_name)", "response": "Synchronizes the current experiment with the given experiment spec."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_experiment(redis, name):\n\n    if not ALLOWED_NAMES.match(name):\n        raise ExperimentException(name, \"Illegal name\")\n    if redis.exists(EXPERIMENT_REDIS_KEY_TEMPLATE % name):\n        raise ExperimentException(name, \"Already exists\")\n\n    json = dict(creation_date=util.unicode_type(datetime.datetime.now()))\n    pipe = redis.pipeline(transaction=True)\n    pipe.sadd(ACTIVE_EXPERIMENTS_REDIS_KEY, name)\n    pipe.hset(EXPERIMENT_REDIS_KEY_TEMPLATE % name, \"metadata\", escape.json_encode(json))\n    pipe.execute()\n    return Experiment(redis, name)", "response": "Adds a new experiment to the active experiment list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_experiments(redis, active=True):\n\n    key = ACTIVE_EXPERIMENTS_REDIS_KEY if active else ARCHIVED_EXPERIMENTS_REDIS_KEY\n    return [Experiment(redis, escape.to_unicode(name)) for name in redis.smembers(key)]", "response": "Gets the full list of experiments"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refresh(self):\n        pipe = self.redis.pipeline()\n        pipe.hget(EXPERIMENT_REDIS_KEY_TEMPLATE % self.name, \"metadata\")\n        pipe.hget(EXPERIMENT_REDIS_KEY_TEMPLATE % self.name, \"choices\")\n        pipe.hget(EXPERIMENT_REDIS_KEY_TEMPLATE % self.name, \"default-choice\")\n        results = pipe.execute()\n\n        if results[0] == None:\n            raise ExperimentException(self.name, \"Does not exist\")\n\n        self.metadata = parse_json(results[0])\n        self.choice_names = parse_json(results[1]) if results[1] != None else []\n        self.default_choice = escape.to_unicode(results[2])\n        self._choices = None", "response": "Re - pulls the data from redis and sets the properties of the object to the current values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the experiment choices", "response": "def choices(self):\n        \"\"\"Gets the experiment choices\"\"\"\n\n        if self._choices == None:\n            self._choices = [ExperimentChoice(self, choice_name) for choice_name in self.choice_names]\n\n        return self._choices"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef confidence(self):\n\n        choices = self.choices\n\n        # Get the chi-squared between the top two choices, if more than two choices exist\n        if len(choices) >= 2:\n            csq = chi_squared(*choices)\n            confident = is_confident(csq, len(choices)) if len(choices) <= 10 else None\n        else:\n            csq = None\n            confident = False\n\n        return (csq, confident)", "response": "Returns a tuple containing the chi squared and confident status of the experiment. Confident is simply a boolean specifying whether we re > 95%% significant."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a choice for the experiment", "response": "def add_choice(self, choice_name):\n        \"\"\"Adds a choice for the experiment\"\"\"\n\n        if not ALLOWED_NAMES.match(choice_name):\n            raise ExperimentException(self.name, \"Illegal choice name: %s\" % choice_name)\n\n        if choice_name in self.choice_names:\n            raise ExperimentException(self.name, \"Choice already exists: %s\" % choice_name)\n\n        self.choice_names.append(choice_name)\n        self.redis.hset(EXPERIMENT_REDIS_KEY_TEMPLATE % self.name, \"choices\", escape.json_encode(self.choice_names))\n        self.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_choice(self, choice_name):\n\n        self.choice_names.remove(choice_name)\n        self.redis.hset(EXPERIMENT_REDIS_KEY_TEMPLATE % self.name, \"choices\", escape.json_encode(self.choice_names))\n        self.refresh()", "response": "Removes a choice for the experiment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nincrementing the play count for a given experiment choice", "response": "def add_play(self, choice, count=1):\n        \"\"\"Increments the play count for a given experiment choice\"\"\"\n        self.redis.hincrby(EXPERIMENT_REDIS_KEY_TEMPLATE % self.name, \"%s:plays\" % choice, count)\n        self._choices = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute and sets the default choice", "response": "def compute_default_choice(self):\n        \"\"\"Computes and sets the default choice\"\"\"\n\n        choices = self.choices\n\n        if len(choices) == 0:\n            return None\n\n        high_choice = max(choices, key=lambda choice: choice.performance)\n        self.redis.hset(EXPERIMENT_REDIS_KEY_TEMPLATE % self.name, \"default-choice\", high_choice.name)\n        self.refresh()\n        return high_choice"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch(self, pageNum, itemsPerPage):\n        return self.get_all_alerts(self.status, pageNum, itemsPerPage)", "response": "Intermediate fetching\n        \n        Args:\n            pageNum (int): Page number\n            itemsPerPage (int): Number of Users per Page\n            \n        Returns:\n            dict: Response payload"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef coerce_to_synchronous(func):\n    '''\n    Given a function that might be async, wrap it in an explicit loop so it can\n    be run in a synchronous context.\n    '''\n    if inspect.iscoroutinefunction(func):\n        @functools.wraps(func)\n        def sync_wrapper(*args, **kwargs):\n            loop = asyncio.get_event_loop()\n            try:\n                loop.run_until_complete(func(*args, **kwargs))\n            finally:\n                loop.close()\n        return sync_wrapper\n    return func", "response": "Coerce a function that might be async to a synchronous function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef diff(a, b, segmenter=None):\n    a, b = list(a), list(b)\n    segmenter = segmenter or SEGMENTER\n\n    # Cluster the input tokens\n    a_segments = segmenter.segment(a)\n    b_segments = segmenter.segment(b)\n\n    return diff_segments(a_segments, b_segments)", "response": "Performs a diff between two sequences of tokens a and b."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a diff between two sequence trees.", "response": "def diff_segments(a_segments, b_segments):\n    \"\"\"\n    Performs a diff comparison between two pre-clustered\n    :class:`deltas.Segment` trees.  In most cases, segmentation\n    takes 100X more time than actually performing the diff.\n\n    :Parameters:\n        a_segments : :class:`deltas.Segment`\n            An initial sequence\n        b_segments : :class:`deltas.Segment`\n            A changed sequence\n\n    :Returns:\n        An `iterable` of operations.\n    \"\"\"\n    # Match and re-sequence unmatched tokens\n    a_segment_tokens, b_segment_tokens = _cluster_matching_segments(a_segments,\n                                                                    b_segments)\n\n    # Perform a simple LCS over unmatched tokens and clusters\n    clustered_ops = sequence_matcher.diff(a_segment_tokens, b_segment_tokens)\n\n    # Return the expanded (de-clustered) operations\n    return (op for op in SegmentOperationsExpander(clustered_ops,\n                                                   a_segment_tokens,\n                                                   b_segment_tokens).expand())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding a sequence of texts with a .", "response": "def process(texts, *args, **kwargs):\n    \"\"\"\n    Processes a single sequence of texts with a\n    :class:`~deltas.SegmentMatcher`.\n\n    :Parameters:\n        texts : `iterable`(`str`)\n            sequence of texts\n        args : `tuple`\n            passed to :class:`~deltas.SegmentMatcher`'s\n            constructor\n        kwaths : `dict`\n            passed to :class:`~deltas.SegmentMatcher`'s\n            constructor\n    \"\"\"\n    processor = SegmentMatcher.Processor(*args, **kwargs)\n    for text in texts:\n        yield processor.process(text)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_matchable_segments(segments):\n    for subsegment in segments:\n        if isinstance(subsegment, Token):\n            break # No tokens allowed next to segments\n        if isinstance(subsegment, Segment):\n            if isinstance(subsegment, MatchableSegment):\n                yield subsegment\n\n            for matchable_subsegment in _get_matchable_segments(subsegment):\n                yield matchable_subsegment", "response": "Recursively returns all matchable segments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef forwards(self, orm):\n        \"Write your forwards methods here.\"\n        for document in orm['document_library.Document'].objects.all():\n            self.migrate_placeholder(\n                orm, document, 'content', 'document_library_content', 'content')", "response": "Write your forwards methods here."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_command_line(predictions='/dev/stdout',\n                      quiet=True,\n                      save_resume=True,\n                      q_colon=None,\n                      **kwargs\n                      ):\n    \"\"\"Construct a command line for VW, with each named argument corresponding\n    to a VW option.\n    Single character keys are mapped to single-dash options,\n    e.g. 'b=20' yields '-b 20',\n    while multiple character keys map to double-dash options:\n        'quiet=True' yields '--quiet'\n    Boolean values are interpreted as flags: present if True, absent if False.\n    All other values are treated as option arguments, as in the -b example above.\n    If an option argument is a list, that option is repeated multiple times,\n    e.g. 'q=['ab', 'bc']' yields '-q ab -q bc'\n\n    q_colon is handled specially, mapping to '--q:'.\n\n    Run 'vw -h' for a listing of most options.\n\n    Defaults are well-suited for use with Wabbit Wappa:\n    vw --predictions /dev/stdout --quiet --save_resume\n\n    NOTE: This function makes no attempt to validate the inputs or\n    ensure they are compatible with Wabbit Wappa.\n\n    Outputs a command line string.\n    \"\"\"\n    args = ['vw']\n    if q_colon:\n        kwargs['q:'] = q_colon\n    kwargs['predictions'] = predictions\n    kwargs['quiet'] = quiet\n    kwargs['save_resume'] = save_resume\n    for key, value in kwargs.items():\n        if len(key)==1:\n            option = '-{}'.format(key)\n        else:\n            option = '--{}'.format(key)\n        if value is True:\n            arg_list = [option]\n        elif isinstance(value, basestring):\n            arg_list = ['{} {}'.format(option, value)]\n        elif hasattr(value, '__getitem__'):  # Listlike value\n            arg_list = [ '{} {}'.format(option, subvalue) for subvalue in value ]\n        else:\n            arg_list = ['{} {}'.format(option, value)]\n        args.extend(arg_list)\n    command = ' '.join(args)\n    return command", "response": "Construct a command line for a VW with the specified prediction and save_resume options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_features(self, features):\n        for feature in features:\n            if isinstance(feature, basestring):\n                label = feature\n                value = None\n            else:\n                label, value = feature\n            self.add_feature(label, value)", "response": "Add features to this namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a feature to the list of features.", "response": "def add_feature(self, label, value=None):\n        \"\"\"\n        label: A VW label (not containing characters from escape_dict.keys(),\n            unless 'escape' mode is on)\n        value: float giving the weight or magnitude of this feature\n        \"\"\"\n        if self.escape:\n            label = escape_vw_string(label)\n        elif self.validate:\n            validate_vw_string(label)\n        feature = (label, value)\n        self.features.append(feature)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexporting this namespace to a string suitable for incorporation in a VW example line", "response": "def to_string(self):\n        \"\"\"Export this namespace to a string suitable for incorporation\n        in a VW example line, e.g.\n        'MetricFeatures:3.28 height:1.5 length:2.0 '\n        \"\"\"\n        if self._string is None:\n            tokens = []\n            if self.name:\n                if self.scale:\n                    token = self.name + ':' + str(self.scale)\n                else:\n                    token = self.name\n            else:\n                token = ''  # Spacing element to indicate next string is a feature\n            tokens.append(token)\n            for label, value in self.features:\n                if value is None:\n                    token = label\n                else:\n                    token = label + ':' + str(value)\n                tokens.append(token)\n            tokens.append('')  # Spacing element to separate from next pipe character\n            output = ' '.join(tokens)\n            if self.cache_string:\n                self._string = output\n        else:\n            output = self._string\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexporting the features from this namespace as a list of feature tokens with the namespace name prepended by delimiter.", "response": "def export_features(self, delimiter='\\\\'):\n        \"\"\"Export the features from this namespace as a list of feature tokens\n        with the namespace name prepended (delimited by 'delimiter').\n\n        Example:\n        >>> namespace = Namespace('name1', features=['feature1', 'feature2'])\n        >>> print namespace.export_features()\n        ['name1\\\\feature1', 'name1\\\\feature2']\n        \"\"\"\n        result_list = []\n        for feature in self.features:\n            result = '{}{}{}'.format(self.name, delimiter, feature)\n            result_list.append(result)\n        return result_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_line(self, line, parse_result=True):\n        self.vw_process.sendline(line)  # Send line, along with newline\n        result = self._get_response(parse_result=parse_result)\n        return result", "response": "Send a line of text to the VW instance returning a VWResult object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_response(self, parse_result=True):\n        # expect_exact is faster than just exact, and fine for our purpose\n        # (http://pexpect.readthedocs.org/en/latest/api/pexpect.html#pexpect.spawn.expect_exact)\n        # searchwindowsize and other attributes may also affect efficiency\n        self.vw_process.expect_exact('\\r\\n', searchwindowsize=-1)  # Wait until process outputs a complete line\n        if parse_result:\n            output = self.vw_process.before\n            result_struct = VWResult(output, active_mode=self.active_mode)\n        else:\n            result_struct = None\n        return result_struct", "response": "Get the response from the process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_example(self,\n                     *args,\n                     **kwargs\n                     ):\n        \"\"\"Send a labeled or unlabeled example to the VW instance.\n        If 'parse_result' kwarg is False, ignore the result and return None.\n\n        All other parameters are passed to self.send_line().\n\n        Returns a VWResult object.\n        \"\"\"\n        # Pop out the keyword argument 'parse_result' if given\n        parse_result = kwargs.pop('parse_result', True)\n        line = self.make_line(*args, **kwargs)\n        result = self.send_line(line, parse_result=parse_result)\n        return result", "response": "Send a labeled or unlabeled example to the VW instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes and returns an example string in VW syntax.", "response": "def make_line(self,\n                  response=None,\n                  importance=None,\n                  base=None,\n                  tag=None,\n                  features=None,\n                  namespaces=None,\n                  ):\n        \"\"\"Makes and returns an example string in VW syntax.\n        If given, 'response', 'importance', 'base', and 'tag' are used\n        to label the example.  Features for the example come from\n        any given features or namespaces, as well as any previously\n        added namespaces (using them up in the process).\n        \"\"\"\n        if namespaces is not None:\n            self.add_namespaces(namespaces)\n        if features is not None:\n            namespace = Namespace(features=features)\n            self.add_namespace(namespace)\n        substrings = []\n        tokens = []\n        if response is not None:\n            token = str(response)\n            tokens.append(token)\n            if importance is not None:  # Check only if response is given\n                token = str(importance)\n                tokens.append(token)\n                if base is not None:  # Check only if importance is given\n                    token = str(base)\n                    tokens.append(token)\n        if tag is not None: \n            token = \"'\" + str(tag)  # Tags are unambiguous if given a ' prefix\n            tokens.append(token)\n        else:\n            token = \"\"  # Spacing element to avoid ambiguity in parsing\n            tokens.append(token)\n        substring = ' '.join(tokens)\n        substrings.append(substring)\n        if self.namespaces:\n            for namespace in self.namespaces:\n                substring = namespace.to_string()\n                substrings.append(substring)\n        else:\n            substrings.append('')  # For correct syntax\n        line = '|'.join(substrings)\n        self._line = line\n        self.namespaces = []  # Reset namespaces after their use\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_namespace(self, *args, **kwargs):\n        if args and isinstance(args[0], Namespace):\n            namespace = args[0]\n        elif isinstance(kwargs.get('namespace'), Namespace):\n            namespace = kwargs.get('namespace')\n        else:\n            namespace = Namespace(*args, **kwargs)\n        self.namespaces.append(namespace)\n        return self", "response": "Adds a namespace to the list of namespaces for this VW instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_prediction(self, features=None, tag=None, namespaces=None):\n        if features is not None:\n            namespace = Namespace(features=features)\n            self.add_namespace(namespace)\n        result = self.send_example(tag=tag, namespaces=namespaces)\n        return result", "response": "Send an unlabeled example to the trained VW instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npassing a command example to the VW subprocess requesting that the current model be serialized to model_filename immediately.", "response": "def save_model(self, model_filename):\n        \"\"\"Pass a \"command example\" to the VW subprocess requesting\n        that the current model be serialized to model_filename immediately.\n        \"\"\"\n        line = \"save_{}|\".format(model_filename)\n        self.vw_process.sendline(line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassign taxonomy to each sequence in data file.", "response": "def assign_taxonomy(dataPath, reference_sequences_fp, id_to_taxonomy_fp, read_1_seqs_fp, read_2_seqs_fp, single_ok=False, no_single_ok_generic=False,\n                    header_id_regex=None, read_id_regex = \"\\S+\\s+(\\S+)\", amplicon_id_regex = \"(\\S+)\\s+(\\S+?)\\/\",\n                    output_fp=None, log_path=None, HALT_EXEC=False, base_tmp_dir = '/tmp'):\n    \"\"\"Assign taxonomy to each sequence in data with the RTAX classifier\n\n        # data: open fasta file object or list of fasta lines\n        dataPath: path to a fasta file\n\n        output_fp: path to write output; if not provided, result will be\n         returned in a dict of {seq_id:(taxonomy_assignment,confidence)}\n    \"\"\"\n\n    usearch_command = \"usearch\"\n    if not (exists(usearch_command) or app_path(usearch_command)):\n        raise ApplicationNotFoundError,\\\n         \"Cannot find %s. Is it installed? Is it in your path?\"\\\n         % usearch_command\n\n    my_tmp_dir = get_tmp_filename(tmp_dir=base_tmp_dir,prefix='rtax_',suffix='',result_constructor=str)\n    os.makedirs(my_tmp_dir)\n\n\n    try:\n        # RTAX classifier doesn't necessarily preserve identifiers\n        # it reports back only the id extracted as $1 using header_id_regex\n        # since rtax takes the original unclustered sequence files as input,\n        # the usual case is that the regex extracts the amplicon ID from the second field\n\n\n\n        # Use lookup table\n        read_1_id_to_orig_id = {}\n        readIdExtractor = re.compile(read_id_regex)  # OTU clustering produces \">clusterID read_1_id\"\n        data = open(dataPath,'r')\n        for seq_id, seq in parse_fasta(data):\n            # apply the regex\n            extract = readIdExtractor.match(seq_id)\n            if extract is None:\n                stderr.write(\"Matched no ID with read_id_regex \" + read_id_regex +\" in '\" + seq_id + \"' from file \" + dataPath + \"\\n\")\n            else:\n                read_1_id_to_orig_id[extract.group(1)] = seq_id\n                #stderr.write(extract.group(1) + \" => \" +  seq_id + \"\\n\")\n            #seq_id_lookup[seq_id.split()[1]] = seq_id\n        data.close()\n\n\n\n        # make list of amplicon IDs to pass to RTAX\n\n        id_list_fp = open(my_tmp_dir+\"/ampliconIdsToClassify\", \"w\")\n\n        # Establish mapping of amplicon IDs to read_1 IDs\n        # simultaneously write the amplicon ID file for those IDs found in the input mapping above\n\n        amplicon_to_read_1_id = {}\n        ampliconIdExtractor = re.compile(amplicon_id_regex)  # split_libraries produces >read_1_id ampliconID/1 ...  // see also assign_taxonomy 631\n        read_1_data = open(read_1_seqs_fp,'r')\n        for seq_id, seq in parse_fasta(read_1_data):\n            # apply the regex\n            extract = ampliconIdExtractor.match(seq_id)\n            if extract is None:\n                stderr.write(\"Matched no ID with amplicon_id_regex \" + amplicon_id_regex + \" in '\" + seq_id + \"' from file \" + read_1_seqs_fp + \"\\n\")\n            else:\n                read_1_id = extract.group(1)\n                amplicon_id = extract.group(2)\n                try:\n                    amplicon_to_read_1_id[amplicon_id] = read_1_id\n                    bogus = read_1_id_to_orig_id[read_1_id]  # verify that the id is valid\n                    id_list_fp.write('%s\\n' % (amplicon_id))\n                except KeyError:\n                    pass\n        data.close()\n        id_list_fp.close()\n\n        app = Rtax(HALT_EXEC=HALT_EXEC)\n\n        temp_output_file = tempfile.NamedTemporaryFile(\n            prefix='RtaxAssignments_', suffix='.txt')\n        app.Parameters['-o'].on(temp_output_file.name)\n        app.Parameters['-r'].on(reference_sequences_fp)\n        app.Parameters['-t'].on(id_to_taxonomy_fp)\n        # app.Parameters['-d'].on(delimiter)\n        app.Parameters['-l'].on(id_list_fp.name)  # these are amplicon IDs\n        app.Parameters['-a'].on(read_1_seqs_fp)\n        if read_2_seqs_fp is not None:\n            app.Parameters['-b'].on(read_2_seqs_fp)\n        app.Parameters['-i'].on(header_id_regex)\n        app.Parameters['-m'].on(my_tmp_dir)\n        if single_ok: app.Parameters['-f'].on();\n        if no_single_ok_generic: app.Parameters['-g'].on();\n        #app.Parameters['-v'].on()\n\n        app_result = app()\n\n        if log_path:\n            f=open(log_path, 'a')\n            errString=''.join(app_result['StdErr'].readlines()) + '\\n'\n            f.write(errString)\n            f.close()\n\n        assignments = {}\n\n        # restore original sequence IDs with spaces\n\n        for line in app_result['Assignments']:\n            toks = line.strip().split('\\t')\n            rtax_id = toks.pop(0)\n            if len(toks):\n                bestpcid = toks.pop(0)  # ignored\n            lineage = toks\n\n            # RTAX does not provide a measure of confidence.  We could pass one in,\n            # based on the choice of primers, or even look it up on the fly in the tables\n            # from the \"optimal primers\" paper; but it would be the same for every\n            # query sequence anyway.\n            # we could also return bestpcid, but that's not the same thing as confidence.\n            confidence = 1.0\n\n            read_1_id = amplicon_to_read_1_id[rtax_id]\n            orig_id = read_1_id_to_orig_id[read_1_id]\n            if lineage:\n                assignments[orig_id] = (';'.join(lineage), confidence)\n            else:\n                assignments[orig_id] = ('Unclassified', 1.0)\n\n        if output_fp:\n            try:\n                output_file = open(output_fp, 'w')\n            except OSError:\n                raise OSError(\"Can't open output file for writing: %s\" % output_fp)\n            for seq_id, assignment in assignments.items():\n                lineage, confidence = assignment\n                output_file.write(\n                    '%s\\t%s\\t%1.3f\\n' % (seq_id, lineage, confidence))\n            output_file.close()\n            return None\n        else:\n            return assignments\n    finally:\n        try:\n            rmtree(my_tmp_dir)\n        except OSError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate through an iterator yielding items in adjacent pairs of tokens.", "response": "def pair_looper(iterator):\n    '''\n    Loop through iterator yielding items in adjacent pairs\n    '''\n    left = START\n    for item in iterator:\n        if left is not START:\n            yield (left, item)\n        left = item"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef batch_gen(data, batch_size):\n    '''\n    Usage::\n        for batch in batch_gen(iter, 100):\n            do_something(batch)\n    '''\n    data = data or []\n    for i in range(0, len(data), batch_size):\n        yield data[i:i + batch_size]", "response": "Generator that yields the data from the specified batch_size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_stale_pids(pids, pid_dir='/tmp', prefix='', multi=False):\n    'check for and remove any pids which have no corresponding process'\n    if isinstance(pids, (int, float, long)):\n        pids = [pids]\n    pids = str2list(pids, map_=unicode)\n    procs = map(unicode, os.listdir('/proc'))\n    running = [pid for pid in pids if pid in procs]\n    logger.warn(\n        \"Found %s pids running: %s\" % (len(running),\n                                       running))\n    prefix = prefix.rstrip('.') if prefix else None\n    for pid in pids:\n        if prefix:\n            _prefix = prefix\n        else:\n            _prefix = unicode(pid)\n        # remove non-running procs\n        if pid in running:\n            continue\n        if multi:\n            pid_file = '%s%s.pid' % (_prefix, pid)\n        else:\n            pid_file = '%s.pid' % (_prefix)\n        path = os.path.join(pid_dir, pid_file)\n        if os.path.exists(path):\n            logger.debug(\"Removing pidfile: %s\" % path)\n            try:\n                remove_file(path)\n            except OSError as e:\n                logger.warn(e)\n    return running", "response": "check for and remove any pids which have no corresponding process"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetaches a process from the controlling terminal and run it in the background as a daemon. Modified version of: code.activestate.com/recipes/278731-creating-a-daemon-the-python-way/ author = \"Chad J. Schroeder\" copyright = \"Copyright (C) 2005 Chad J. Schroeder\"", "response": "def daemonize(pid_file=None, cwd=None):\n    \"\"\"\n    Detach a process from the controlling terminal and run it in the\n    background as a daemon.\n\n    Modified version of:\n        code.activestate.com/recipes/278731-creating-a-daemon-the-python-way/\n\n    author = \"Chad J. Schroeder\"\n    copyright = \"Copyright (C) 2005 Chad J. Schroeder\"\n    \"\"\"\n    cwd = cwd or '/'\n    try:\n        pid = os.fork()\n    except OSError as e:\n        raise Exception(\"%s [%d]\" % (e.strerror, e.errno))\n\n    if (pid == 0):   # The first child.\n        os.setsid()\n        try:\n            pid = os.fork()    # Fork a second child.\n        except OSError as e:\n            raise Exception(\"%s [%d]\" % (e.strerror, e.errno))\n        if (pid == 0):    # The second child.\n            os.chdir(cwd)\n            os.umask(0)\n        else:\n            os._exit(0)    # Exit parent (the first child) of the second child.\n    else:\n        os._exit(0)   # Exit parent of the first child.\n\n    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]\n    if (maxfd == resource.RLIM_INFINITY):\n        maxfd = 1024\n\n    # Iterate through and close all file descriptors.\n    for fd in range(0, maxfd):\n        try:\n            os.close(fd)\n        except OSError:   # ERROR, fd wasn't open to begin with (ignored)\n            pass\n\n    os.open('/dev/null', os.O_RDWR)  # standard input (0)\n\n    # Duplicate standard input to standard output and standard error.\n    os.dup2(0, 1)            # standard output (1)\n    os.dup2(0, 2)            # standard error (2)\n\n    pid_file = pid_file or '%s.pid' % os.getpid()\n    write_file(pid_file, os.getpid())\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning pkg mod and class name for a given cube name.", "response": "def cube_pkg_mod_cls(cube):\n    '''\n    Used to dynamically importing cube classes\n    based on string slug name.\n\n    Converts 'pkg_mod' -> pkg, mod, Cls\n\n    eg: tw_tweet -> tw, tweet, Tweet\n\n    Assumes `Metrique Cube Naming Convention` is used\n\n    :param cube: cube name to use when searching for cube pkg.mod.class to load\n    '''\n    _cube = cube.split('_')\n    pkg = _cube[0]\n    mod = '_'.join(_cube[1:])\n    _cls = ''.join([s[0].upper() + s[1:] for s in _cube[1:]])\n    return pkg, mod, _cls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dt2ts(dt, drop_micro=False):\n    ''' convert datetime objects to timestamp seconds (float) '''\n    is_true(HAS_DATEUTIL, \"`pip install python_dateutil` required\")\n    if is_empty(dt, except_=False):\n        ts = None\n    elif isinstance(dt, (int, long, float)):  # its a ts already\n        ts = float(dt)\n    elif isinstance(dt, basestring):  # convert to datetime first\n        try:\n            parsed_dt = float(dt)\n        except (TypeError, ValueError):\n            parsed_dt = dt_parse(dt)\n        ts = dt2ts(parsed_dt)\n    else:\n        assert isinstance(dt, (datetime, date))\n        # keep micros; see: http://stackoverflow.com/questions/7031031\n        ts = ((\n            timegm(dt.timetuple()) * 1000.0) +\n            (dt.microsecond / 1000.0)) / 1000.0\n    if ts is None:\n        pass\n    elif drop_micro:\n        ts = float(int(ts))\n    else:\n        ts = float(ts)\n    return ts", "response": "convert datetime objects to timestamp seconds"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_timezone_converter(from_timezone, to_tz=None, tz_aware=False):\n    '''\n    return a function that converts a given\n    datetime object from a timezone to utc\n\n    :param from_timezone: timezone name as string\n    '''\n    if not from_timezone:\n        return None\n    is_true(HAS_DATEUTIL, \"`pip install python_dateutil` required\")\n    is_true(HAS_PYTZ, \"`pip install pytz` required\")\n    from_tz = pytz.timezone(from_timezone)\n    return partial(_get_timezone_converter, from_tz=from_tz, to_tz=to_tz,\n                   tz_aware=tz_aware)", "response": "Returns a function that converts a given datetime object from a timezone to utc\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a git repo clone it locally and return the path to the cloned repository.", "response": "def git_clone(uri, pull=True, reflect=False, cache_dir=None, chdir=True):\n    '''\n    Given a git repo, clone (cache) it locally.\n\n    :param uri: git repo uri\n    :param pull: whether to pull after cloning (or loading cache)\n    '''\n    cache_dir = cache_dir or CACHE_DIR\n    # make the uri safe for filesystems\n    repo_path = os.path.expanduser(os.path.join(cache_dir, safestr(uri)))\n    if not os.path.exists(repo_path):\n        from_cache = False\n        logger.info(\n            'Locally caching git repo [%s] to [%s]' % (uri, repo_path))\n        cmd = 'git clone %s %s' % (uri, repo_path)\n        sys_call(cmd)\n    else:\n        from_cache = True\n        logger.info(\n            'GIT repo loaded from local cache [%s])' % (repo_path))\n    if pull and not from_cache:\n        os.chdir(repo_path)\n        cmd = 'git pull'\n        sys_call(cmd, cwd=repo_path)\n    if chdir:\n        os.chdir(repo_path)\n    if reflect:\n        if not HAS_DULWICH:\n            raise RuntimeError(\"`pip install dulwich` required!\")\n        return Repo(repo_path)\n    else:\n        return repo_path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_empty(value, msg=None, except_=None, inc_zeros=True):\n    '''\n    is defined, but null or empty like value\n    '''\n    if hasattr(value, 'empty'):\n        # dataframes must check for .empty\n        # since they don't define truth value attr\n        # take the negative, since below we're\n        # checking for cases where value 'is_null'\n        value = not bool(value.empty)\n    elif inc_zeros and value in ZEROS:\n        # also consider 0, 0.0, 0L as 'empty'\n        # will check for the negative below\n        value = True\n    else:\n        pass\n    _is_null = is_null(value, except_=False)\n    result = bool(_is_null or not value)\n    if except_:\n        return is_true(result, msg=msg, except_=except_)\n    else:\n        return bool(result)", "response": "is_empty - Check if value is empty"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts datetime. datetime to timestamp", "response": "def json_encode_default(obj):\n    '''\n    Convert datetime.datetime to timestamp\n\n    :param obj: value to (possibly) convert\n    '''\n    if isinstance(obj, (datetime, date)):\n        result = dt2ts(obj)\n    else:\n        result = json_encoder.default(obj)\n    return to_encoding(result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jsonhash(obj, root=True, exclude=None, hash_func=_jsonhash_sha1):\n    '''\n    calculate the objects hash based on all field values\n    '''\n    if isinstance(obj, Mapping):\n        # assumption: using in against set() is faster than in against list()\n        if root and exclude:\n            obj = {k: v for k, v in obj.iteritems() if k not in exclude}\n        # frozenset's don't guarantee order; use sorted tuples\n        # which means different python interpreters can return\n        # back frozensets with different hash values even when\n        # the content of the object is exactly the same\n        result = sorted(\n            (k, jsonhash(v, False)) for k, v in obj.iteritems())\n    elif isinstance(obj, list):\n        # FIXME: should lists be sorted for consistent hashes?\n        # when the object is the same, just different list order?\n        result = tuple(jsonhash(e, False) for e in obj)\n    else:\n        result = obj\n    if root:\n        result = unicode(hash_func(result))\n    return result", "response": "calculate the objects hash based on all field values\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(path, filetype=None, as_df=False, retries=None,\n         _oid=None, quiet=False, **kwargs):\n    '''Load multiple files from various file types automatically.\n\n    Supports glob paths, eg::\n\n        path = 'data/*.csv'\n\n    Filetypes are autodetected by common extension strings.\n\n    Currently supports loadings from:\n        * csv (pd.read_csv)\n        * json (pd.read_json)\n\n    :param path: path to config json file\n    :param filetype: override filetype autodetection\n    :param kwargs: additional filetype loader method kwargs\n    '''\n    is_true(HAS_PANDAS, \"`pip install pandas` required\")\n    set_oid = set_oid_func(_oid)\n\n    # kwargs are for passing ftype load options (csv.delimiter, etc)\n    # expect the use of globs; eg, file* might result in fileN (file1,\n    # file2, file3), etc\n    if not isinstance(path, basestring):\n        # assume we're getting a raw dataframe\n        objects = path\n        if not isinstance(objects, pd.DataFrame):\n            raise ValueError(\"loading raw values must be DataFrames\")\n    elif re.match('https?://', path):\n        logger.debug('Saving %s to tmp file' % path)\n        _path = urlretrieve(path, retries)\n        logger.debug('%s saved to tmp file: %s' % (path, _path))\n        try:\n            objects = load_file(_path, filetype, **kwargs)\n        finally:\n            remove_file(_path)\n    else:\n        path = re.sub('^file://', '', path)\n        path = os.path.expanduser(path)\n        # assume relative to cwd if not already absolute path\n        path = path if os.path.isabs(path) else pjoin(os.getcwd(), path)\n        files = sorted(glob.glob(os.path.expanduser(path)))\n        if not files:\n            raise IOError(\"failed to load: %s\" % path)\n        # buid up a single dataframe by concatting\n        # all globbed files together\n        objects = []\n        [objects.extend(load_file(ds, filetype, **kwargs))\n            for ds in files]\n\n    if is_empty(objects, except_=False) and not quiet:\n        raise RuntimeError(\"no objects extracted!\")\n    else:\n        logger.debug(\"Data loaded successfully from %s\" % path)\n\n    if set_oid:\n        # set _oids, if we have a _oid generator func defined\n        objects = [set_oid(o) for o in objects]\n\n    if as_df:\n        return pd.DataFrame(objects)\n    else:\n        return objects", "response": "Load multiple files from various file types automatically."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the given cube from the given package.", "response": "def _load_cube_pkg(pkg, cube):\n    '''\n    NOTE: all items in fromlist must be strings\n    '''\n    try:\n        # First, assume the cube module is available\n        # with the name exactly as written\n        fromlist = map(str, [cube])\n        mcubes = __import__(pkg, fromlist=fromlist)\n        return getattr(mcubes, cube)\n    except AttributeError:\n        # if that fails, try to guess the cube module\n        # based on cube 'standard naming convention'\n        # ie, group_cube -> from group.cube import CubeClass\n        _pkg, _mod, _cls = cube_pkg_mod_cls(cube)\n        fromlist = map(str, [_cls])\n        mcubes = __import__('%s.%s.%s' % (pkg, _pkg, _mod),\n                            fromlist=fromlist)\n        return getattr(mcubes, _cls)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_file(rel_path, paths=None, raw=False, as_list=False, as_iter=False,\n              *args, **kwargs):\n    '''\n        find a file that lives somewhere within a set of paths and\n        return its contents. Default paths include 'static_dir'\n    '''\n    if not rel_path:\n        raise ValueError(\"rel_path can not be null!\")\n    paths = str2list(paths)\n    # try looking the file up in a directory called static relative\n    # to SRC_DIR, eg assuming metrique git repo is in ~/metrique\n    # we'd look in ~/metrique/static\n    paths.extend([STATIC_DIR, os.path.join(SRC_DIR, 'static')])\n    paths = [os.path.expanduser(p) for p in set(paths)]\n    for path in paths:\n        path = os.path.join(path, rel_path)\n        logger.debug(\"trying to read: %s \" % path)\n        if os.path.exists(path):\n            break\n    else:\n        raise IOError(\"path %s does not exist!\" % rel_path)\n    args = args if args else ['rU']\n    fd = open(path, *args, **kwargs)\n    if raw:\n        return fd\n\n    if as_iter:\n        return read_in_chunks(fd)\n    else:\n        fd_lines = fd.readlines()\n\n    if as_list:\n        return fd_lines\n    else:\n        return ''.join(fd_lines)", "response": "read a file from a set of paths and return its contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rupdate(source, target):\n    ''' recursively update nested dictionaries\n        see: http://stackoverflow.com/a/3233356/1289080\n    '''\n    for k, v in target.iteritems():\n        if isinstance(v, Mapping):\n            r = rupdate(source.get(k, {}), v)\n            source[k] = r\n        else:\n            source[k] = target[k]\n    return source", "response": "recursively update nested dictionaries\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting back an alphanumeric only version of source", "response": "def safestr(str_):\n    ''' get back an alphanumeric only version of source '''\n    str_ = str_ or \"\"\n    return \"\".join(x for x in str_ if x.isalnum())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ts2dt(ts, milli=False, tz_aware=False):\n    ''' convert timestamp int's (seconds) to datetime objects '''\n    # anything already a datetime will still be returned\n    # tz_aware, if set to true\n    is_true(HAS_DATEUTIL, \"`pip install python_dateutil` required\")\n    if isinstance(ts, (datetime, date)):\n        pass\n    elif is_empty(ts, except_=False):\n        return None  # its not a timestamp\n    elif isinstance(ts, (int, float, long)) and ts < 0:\n        return None\n    elif isinstance(ts, basestring):\n        try:\n            ts = float(ts)\n        except (TypeError, ValueError):\n            # maybe we have a date like string already?\n            try:\n                ts = dt_parse(ts)\n            except Exception:\n                raise TypeError(\n                    \"unable to derive datetime from timestamp string: %s\" % ts)\n    elif milli:\n        ts = float(ts) / 1000.  # convert milli to seconds\n    else:\n        ts = float(ts)  # already in seconds\n    return _get_datetime(ts, tz_aware)", "response": "convert timestamp int s to datetime objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef urlretrieve(uri, saveas=None, retries=3, cache_dir=None):\n    '''urllib.urlretrieve wrapper'''\n    retries = int(retries) if retries else 3\n    # FIXME: make random filename (saveas) in cache_dir...\n    # cache_dir = cache_dir or CACHE_DIR\n    while retries:\n        try:\n            _path, headers = urllib.urlretrieve(uri, saveas)\n        except Exception as e:\n            retries -= 1\n            logger.warn(\n                'Failed getting uri \"%s\": %s (retry:%s in 1s)' % (\n                    uri, e, retries))\n            time.sleep(.2)\n            continue\n        else:\n            break\n    else:\n        raise RuntimeError(\"Failed to retrieve uri: %s\" % uri)\n    return _path", "response": "Wrapper for urllib. urlretrieve"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite your forwards methods here.", "response": "def forwards(self, orm):\n        \"Write your forwards methods here.\"\n        for category in orm['document_library.DocumentCategory'].objects.all():\n            category.is_published = True\n            category.save()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reverse_media_url(target_type, url_string, *args, **kwargs):\n    '''\n    Given a target type and an resource URL, generates a valid URL to this via\n    '''\n    args_str = '<%s>' % '><'.join(args)\n    kwargs_str = '<%s>' % '><'.join('%s:%s' % pair for pair in kwargs.items())\n    url_str = ''.join([url_string, args_str, kwargs_str])\n    normalized_url = str(ResourceURL(url_str))\n\n    query_tuples = []\n\n    if singletons.settings.SECURITY and 'Sha1' in singletons.settings.SECURITY:\n        secret = singletons.settings.HMAC_SECRET\n        digest = get_hmac_sha1_digest(secret, normalized_url, target_type)\n        query_tuples.append(('digest', digest))\n\n    # Add in URL as last querystring argument\n    query_tuples.append(('url', normalized_url))\n\n    querystring = urlencode(query_tuples)\n    scheme = singletons.settings.EXTERNAL_SCHEME\n    host = singletons.settings.EXTERNAL_HOST\n    port = singletons.settings.EXTERNAL_PORT\n    if not host:\n        host = singletons.settings.HOST\n    if not port:\n        port = singletons.settings.PORT\n\n    port_suffix = ':%s' % port if port != 80 else ''\n\n    typestring_normalized = str(TypeString(target_type))\n    return '%s://%s%s/media/%s/?%s' % (\n        scheme,\n        host,\n        port_suffix,\n        typestring_normalized,\n        querystring,\n    )", "response": "Generates a valid URL to this via\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck ISBN is a string and passes basic sanity checks.", "response": "def _isbn_cleanse(isbn, checksum=True):\n    \"\"\"Check ISBN is a string, and passes basic sanity checks.\n\n    Args:\n        isbn (str): SBN, ISBN-10 or ISBN-13\n        checksum (bool): ``True`` if ``isbn`` includes checksum character\n\n    Returns:\n        ``str``: ISBN with hyphenation removed, including when called with a\n            SBN\n\n    Raises:\n        TypeError: ``isbn`` is not a ``str`` type\n        IsbnError: Incorrect length for ``isbn``\n        IsbnError: Incorrect SBN or ISBN formatting\n\n    \"\"\"\n    if not isinstance(isbn, string_types):\n        raise TypeError('ISBN must be a string, received %r' % isbn)\n\n    if PY2 and isinstance(isbn, str):  # pragma: Python 2\n        isbn = unicode(isbn)\n        uni_input = False\n    else:  # pragma: Python 3\n        uni_input = True\n\n    for dash in DASHES:\n        isbn = isbn.replace(dash, unicode())\n\n    if checksum:\n        if not isbn[:-1].isdigit():\n            raise IsbnError('non-digit parts')\n        if len(isbn) == 9:\n            isbn = '0' + isbn\n        if len(isbn) == 10:\n            if not (isbn[-1].isdigit() or isbn[-1] in 'Xx'):\n                raise IsbnError('non-digit or X checksum')\n        elif len(isbn) == 13:\n            if not isbn[-1].isdigit():\n                raise IsbnError('non-digit checksum')\n            if not isbn.startswith(('978', '979')):\n                raise IsbnError('invalid Bookland region')\n        else:\n            raise IsbnError('ISBN must be either 10 or 13 characters long')\n    else:\n        if len(isbn) == 8:\n            isbn = '0' + isbn\n        elif len(isbn) == 12 and not isbn[:3].startswith(('978', '979')):\n            raise IsbnError('invalid Bookland region')\n        if not isbn.isdigit():\n            raise IsbnError('non-digit parts')\n        if not len(isbn) in (9, 12):\n            raise IsbnError('ISBN must be either 9 or 12 characters long '\n                            'without checksum')\n    if PY2 and not uni_input:  # pragma: Python 2\n        # Sadly, type ping-pong is required to maintain backwards compatibility\n        # with previous pyisbn releases for Python 2 users.\n        return str(isbn)\n    else:  # pragma: Python 3\n        return isbn"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate ISBN checksum. Args: isbn (str): SBN, ISBN-10 or ISBN-13 Returns: ``str``: Checksum for given ISBN or SBN", "response": "def calculate_checksum(isbn):\n    \"\"\"Calculate ISBN checksum.\n\n    Args:\n        isbn (str): SBN, ISBN-10 or ISBN-13\n\n    Returns:\n        ``str``: Checksum for given ISBN or SBN\n\n    \"\"\"\n    isbn = [int(i) for i in _isbn_cleanse(isbn, checksum=False)]\n    if len(isbn) == 9:\n        products = [x * y for x, y in zip(isbn, range(1, 10))]\n        check = sum(products) % 11\n        if check == 10:\n            check = 'X'\n    else:\n        # As soon as Python 2.4 support is dumped\n        # [(isbn[i] if i % 2 == 0 else isbn[i] * 3) for i in range(12)]\n        products = []\n        for i in range(12):\n            if i % 2 == 0:\n                products.append(isbn[i])\n            else:\n                products.append(isbn[i] * 3)\n        check = 10 - sum(products) % 10\n        if check == 10:\n            check = 0\n    return str(check)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts ISBN - 10 or ISBN - 13 to ISBN - 13.", "response": "def convert(isbn, code='978'):\n    \"\"\"Convert ISBNs between ISBN-10 and ISBN-13.\n\n    Note:\n        No attempt to hyphenate converted ISBNs is made, because the\n        specification requires that *any* hyphenation must be correct but\n        allows ISBNs without hyphenation.\n\n    Args:\n        isbn (str): SBN, ISBN-10 or ISBN-13\n        code (str): EAN Bookland code\n\n    Returns:\n        ``str``: Converted ISBN-10 or ISBN-13\n\n    Raise:\n        IsbnError: When ISBN-13 isn't convertible to an ISBN-10\n\n    \"\"\"\n    isbn = _isbn_cleanse(isbn)\n    if len(isbn) == 10:\n        isbn = code + isbn[:-1]\n        return isbn + calculate_checksum(isbn)\n    else:\n        if isbn.startswith('978'):\n            return isbn[3:-1] + calculate_checksum(isbn[3:-1])\n        else:\n            raise IsbnError('Only ISBN-13s with 978 Bookland code can be '\n                            'converted to ISBN-10.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate_checksum(self):\n        if len(self.isbn) in (9, 12):\n            return calculate_checksum(self.isbn)\n        else:\n            return calculate_checksum(self.isbn[:-1])", "response": "Calculate ISBN checksum.\n\n        Returns:\n            ``str``: ISBN checksum value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_url(self, site='amazon', country='us'):\n        try:\n            try:\n                url, tlds = URL_MAP[site]\n            except ValueError:\n                tlds = None\n                url = URL_MAP[site]\n        except KeyError:\n            raise SiteError(site)\n        inject = {'isbn': self._isbn}\n        if tlds:\n            if country not in tlds:\n                raise CountryError(country)\n            tld = tlds[country]\n            if not tld:\n                tld = country\n            inject['tld'] = tld\n        return url % inject", "response": "Generate a link to an online book site."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _tokenize(self, text, token_class=None):\n        token_class = token_class or Token\n        tokens = {}\n\n        for i, match in enumerate(self.regex.finditer(text)):\n            value = match.group(0)\n\n            try:\n                token = tokens[value]\n            except KeyError:\n                type = match.lastgroup\n                token = token_class(value, type=type)\n                tokens[value] = token\n\n            yield token", "response": "Tokenizes a text into a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_cli_facter_results(facter_results):\n    '''Parse key value pairs printed with \"=>\" separators.\n    YAML is preferred output scheme for facter.\n\n    >>> list(_parse_cli_facter_results(\"\"\"foo => bar\n    ... baz => 1\n    ... foo_bar => True\"\"\"))\n    [('foo', 'bar'), ('baz', '1'), ('foo_bar', 'True')]\n    >>> list(_parse_cli_facter_results(\"\"\"foo => bar\n    ... babababababababab\n    ... baz => 2\"\"\"))\n    [('foo', 'bar\\nbabababababababab'), ('baz', '2')]\n    >>> list(_parse_cli_facter_results(\"\"\"3434\"\"\"))\n    Traceback (most recent call last):\n        ...\n    ValueError: parse error\n\n\n    Uses a generator interface:\n    >>> _parse_cli_facter_results(\"foo => bar\").next()\n    ('foo', 'bar')\n    '''\n    last_key, last_value = None, []\n    for line in filter(None, facter_results.splitlines()):\n        res = line.split(six.u(\" => \"), 1)\n        if len(res)==1:\n            if not last_key:\n                raise ValueError(\"parse error\")\n            else:\n                last_value.append(res[0])\n        else:\n            if last_key:\n                yield last_key, os.linesep.join(last_value)\n            last_key, last_value = res[0], [res[1]]\n    else:\n        if last_key:\n            yield last_key, os.linesep.join(last_value)", "response": "Parse the facter results and yield the key value pairs printed with \"= > separators."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_facter(self, key=None):\n        args = [self.facter_path]\n        #this seems to not cause problems, but leaving it separate\n        args.append(\"--puppet\")\n        if self.external_dir is not None:\n            args.append('--external-dir')\n            args.append(self.external_dir)\n        if self.uses_yaml:\n            args.append(\"--yaml\")\n        if key is not None:\n            args.append(key)\n        proc = subprocess.Popen(args, stdout=subprocess.PIPE)\n        results = proc.stdout.read()\n        if self.uses_yaml:\n            parsed_results = yaml.load(results)\n            if key is not None:\n                return parsed_results[key]\n            else:\n                return parsed_results\n        results = results.decode()\n        if key is not None:\n            return results.strip()\n        else:\n            return dict(_parse_cli_facter_results(results))", "response": "Run the facter executable with an optional specfic\n        fact. Output is parsed to yaml if available and akey is passed. Returns a dictionary if no key is given and the value if a key is passed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_cache(self):\n        if not self.cache_enabled:\n            return False\n        if self._cache is None:\n            self.build_cache()\n        return True", "response": "Returns True if the cache is available."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lookup(self, fact, cache=True):\n        if (not cache) or (not self.has_cache()):\n            val =  self.run_facter(fact)\n            if val is None or val == '':\n                raise KeyError(fact)\n            return val\n        return self._cache[fact]", "response": "Return the value of a given fact and raise a KeyError if it is not available."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset some of the state in the class for multi - searches.", "response": "def _reset(self) -> None:\n        \"\"\"Reset some of the state in the class for multi-searches.\"\"\"\n        self.project: str = namesgenerator.get_random_name()\n        self._processed: List = list()\n        self.results: List = list()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the basic setup of the tool prior to user control.", "response": "def _config_bootstrap(self) -> None:\n        \"\"\"Handle the basic setup of the tool prior to user control.\n\n        Bootstrap will load all the available modules for searching and set\n        them up for use by this main class.\n        \"\"\"\n        if self.output:\n            self.folder: str = os.getcwd() + \"/\" + self.project\n            os.mkdir(self.folder)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing the work items.", "response": "def _job_handler(self) -> bool:\n        \"\"\"Process the work items.\"\"\"\n        while True:\n            try:\n                task = self._unfullfilled.get_nowait()\n            except queue.Empty:\n                break\n            else:\n                self._log.debug(\"Job: %s\" % str(task))\n                engine = self._dyn_loader(task['engine'], task)\n                task['start_time'] = now_time()\n                results = engine.search()\n                task['end_time'] = now_time()\n                duration: str = str((task['end_time'] - task['start_time']).seconds)\n                task['duration'] = duration\n                task.update({'results': results})\n                self._fulfilled.put(task)\n        return True"}
